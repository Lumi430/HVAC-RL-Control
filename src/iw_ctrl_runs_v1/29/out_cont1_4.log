Using TensorFlow backend.
[2017-11-02 09:39:31,143] A3C_AGENT_MAIN INFO:Namespace(act_func='6', action_space='iw_af5_1', agent_num=5, clip_norm=5.0, decay_steps=1000000, dropout_prob=0.5, end_e=0.0, env='IW-v570202', err_penalty_scl=0.15, eval_epi_num=1, eval_freq=250000, gamma=0.99, h_regu_frac=0.01, init_e=0.0, is_warm_start=True, job_mode='Train', learning_rate=0.0001, max_interactions=15000000, model_dir='a3c-res-v0.1/IW-v5702-run1/model_data/model.ckpt-15000000', num_threads=16, output='a3c-res-v0.1/IW-v570202-run5', p_loss_frac=1.0, reward_func='10', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=0.9, rwd_p_para=0.1, save_freq=500000, save_scope='all', state_dim=13, test_env='IW-eval-v570202', test_mode='Multiple', train_freq=5, v_loss_frac=0.5, window_len=24)
[2017-11-02 09:39:31,143] A3C_AGENT_MAIN INFO:Start compiling...
2017-11-02 09:39:34.549882: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549898: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549912: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549914: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549916: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[2017-11-02 09:39:36,110] A3C_AGENT_MAIN INFO:Start the learning...
[2017-11-02 09:39:36,112] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['IW-v570202'] ...
[2017-11-02 09:39:36,112] Making new env: IW-v570202
[2017-11-02 09:39:36,139] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:36,139] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2017-11-02 09:39:36,140] Making new env: IW-v570202
[2017-11-02 09:39:36,145] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:36,147] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res2/Eplus-env-sub_run1
[2017-11-02 09:39:37,141] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:37,141] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2017-11-02 09:39:37,142] Making new env: IW-v570202
[2017-11-02 09:39:37,154] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:37,157] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res3/Eplus-env-sub_run1
[2017-11-02 09:39:38,142] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:38,144] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2017-11-02 09:39:38,144] Making new env: IW-v570202
[2017-11-02 09:39:38,151] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:38,152] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res4/Eplus-env-sub_run1
[2017-11-02 09:39:39,145] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:39,145] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2017-11-02 09:39:39,145] Making new env: IW-v570202
[2017-11-02 09:39:39,152] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:39,155] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res5/Eplus-env-sub_run1
[2017-11-02 09:39:40,146] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:40,147] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2017-11-02 09:39:40,147] Making new env: IW-v570202
[2017-11-02 09:39:40,154] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:40,156] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res6/Eplus-env-sub_run1
[2017-11-02 09:39:41,148] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:41,149] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2017-11-02 09:39:41,149] Making new env: IW-v570202
[2017-11-02 09:39:41,160] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:41,162] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res7/Eplus-env-sub_run1
[2017-11-02 09:39:42,150] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:42,151] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2017-11-02 09:39:42,151] Making new env: IW-v570202
[2017-11-02 09:39:42,162] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:42,165] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res8/Eplus-env-sub_run1
[2017-11-02 09:39:43,152] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:43,153] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2017-11-02 09:39:43,153] Making new env: IW-v570202
[2017-11-02 09:39:43,165] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:43,168] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res9/Eplus-env-sub_run1
[2017-11-02 09:39:44,153] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:44,153] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2017-11-02 09:39:44,154] Making new env: IW-v570202
[2017-11-02 09:39:44,166] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:44,169] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res10/Eplus-env-sub_run1
[2017-11-02 09:39:45,154] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:45,155] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2017-11-02 09:39:45,155] Making new env: IW-v570202
[2017-11-02 09:39:45,167] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:45,170] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res11/Eplus-env-sub_run1
[2017-11-02 09:39:46,156] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:46,157] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2017-11-02 09:39:46,157] Making new env: IW-v570202
[2017-11-02 09:39:46,171] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:46,174] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res12/Eplus-env-sub_run1
[2017-11-02 09:39:47,158] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:47,159] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2017-11-02 09:39:47,159] Making new env: IW-v570202
[2017-11-02 09:39:47,175] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:47,185] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res13/Eplus-env-sub_run1
[2017-11-02 09:39:48,160] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:48,161] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2017-11-02 09:39:48,161] Making new env: IW-v570202
[2017-11-02 09:39:48,173] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:48,176] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res14/Eplus-env-sub_run1
[2017-11-02 09:39:49,161] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:49,162] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2017-11-02 09:39:49,162] Making new env: IW-v570202
[2017-11-02 09:39:49,174] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:49,176] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res15/Eplus-env-sub_run1
[2017-11-02 09:39:50,163] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:50,163] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2017-11-02 09:39:50,164] Making new env: IW-v570202
[2017-11-02 09:39:50,174] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:50,177] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res16/Eplus-env-sub_run1
[2017-11-02 09:39:51,164] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:51,165] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2017-11-02 09:39:51,165] Making new env: IW-v570202
[2017-11-02 09:39:51,181] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:51,192] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res17/Eplus-env-sub_run1
[2017-11-02 09:40:24,485] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 09:40:24,485] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:40:24,488] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run1
[2017-11-02 09:41:02,050] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.28252757e-05   3.18736166e-01   2.37650216e-01   3.63286793e-01
   8.02871883e-02   5.14919066e-06   2.95183736e-06   3.79793414e-06
   4.97814153e-06]
[2017-11-02 09:41:03,785] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10477369  0.12697582  0.15794802  0.13980746  0.09610155  0.12415372
  0.09362306  0.09706853  0.05954813]
[2017-11-02 09:41:08,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.19946255e-03   3.73847157e-01   1.90802649e-01   3.58670533e-01
   7.34801963e-02   5.82307466e-12   2.60209541e-12   3.66819856e-12
   3.45965205e-12]
[2017-11-02 09:41:10,688] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.63415781e-05   3.21877360e-01   2.00796604e-01   3.84426385e-01
   9.28533822e-02   6.33277697e-09   3.01964209e-09   3.36803696e-09
   3.68436281e-09]
[2017-11-02 09:41:18,505] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30946940e-14   1.85919041e-03   8.93111632e-04   3.05128703e-03
   5.08802070e-04   3.04039150e-01   1.66716695e-01   2.12791860e-01
   3.10139894e-01]
[2017-11-02 09:41:20,073] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.14060298e-14   3.07285669e-03   1.45701785e-03   4.84669069e-03
   8.31147016e-04   3.07508767e-01   1.72876224e-01   2.15792343e-01
   2.93615013e-01]
[2017-11-02 09:41:21,876] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.24947918e-10   1.82918295e-01   7.77010620e-02   2.24794313e-01
   4.74962592e-02   1.44899130e-01   9.26221311e-02   1.09322213e-01
   1.20246634e-01]
[2017-11-02 09:41:22,390] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.98328407e-22   1.01993525e-08   3.77982978e-09   1.29456277e-08
   2.45246201e-09   2.94950157e-01   2.03745633e-01   2.22952828e-01
   2.78351307e-01]
[2017-11-02 09:41:24,244] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.52805485e-11   1.41464859e-01   4.74064872e-02   1.54857516e-01
   2.67529860e-02   1.99254051e-01   1.14953972e-01   1.40629798e-01
   1.74680457e-01]
[2017-11-02 09:41:30,744] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.16412743e-20   6.53800925e-09   9.49592494e-09   1.55836783e-08
   3.30441563e-09   3.52797478e-01   1.99724674e-01   1.98806420e-01
   2.48671368e-01]
[2017-11-02 09:41:36,400] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.69405476e-30   1.12059355e-13   5.30705783e-14   1.88997486e-13
   3.51900922e-14   2.76442856e-01   2.02818558e-01   2.09953949e-01
   3.10784608e-01]
[2017-11-02 09:41:43,772] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28845245e-01   2.64631569e-01   2.40211919e-01   2.84537077e-01
   8.17741454e-02   4.41206880e-12   1.58224735e-12   1.61180574e-12
   1.06450981e-12]
[2017-11-02 09:42:06,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37029797e-01   2.47203037e-01   2.47622088e-01   2.81677902e-01
   8.64671469e-02   2.86249774e-11   9.51384110e-12   9.91655803e-12
   4.39675423e-12]
[2017-11-02 09:42:26,030] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.68557192e-04   3.28458339e-01   2.39902243e-01   3.52035016e-01
   7.94355422e-02   1.12680894e-07   6.07089206e-08   7.82234579e-08
   8.73698269e-08]
[2017-11-02 09:42:27,112] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28429225e-02   3.21096361e-01   2.39834085e-01   3.43719512e-01
   8.25071558e-02   3.75264403e-12   1.70422129e-12   2.25060660e-12
   2.06064527e-12]
[2017-11-02 09:42:30,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30113706e-01   2.35688180e-01   2.84806550e-01   2.57316977e-01
   9.20745656e-02   1.13392016e-08   4.27716440e-09   4.95270980e-09
   2.49469556e-09]
[2017-11-02 09:42:30,751] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.13363207e-16   6.68382345e-05   5.26704753e-05   1.16276504e-04
   2.48399429e-05   3.20855528e-01   1.74220011e-01   1.95501596e-01
   3.09162289e-01]
[2017-11-02 09:42:34,630] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.79499213e-27   3.50830281e-12   1.65488012e-12   4.90869845e-12
   8.38243049e-13   2.69474089e-01   2.03335240e-01   2.08303347e-01
   3.18887293e-01]
[2017-11-02 09:42:39,016] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.44381521e-36   1.10079062e-17   1.39601717e-17   3.33953261e-17
   6.07830843e-18   3.23084176e-01   1.95363343e-01   1.77403286e-01
   3.04149270e-01]
[2017-11-02 09:42:40,266] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00100232  0.22695528  0.26091322  0.26256865  0.09324251  0.05872258
  0.03448647  0.03833093  0.02377808]
[2017-11-02 09:42:41,193] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17244408e-05   2.47832239e-01   2.94002861e-01   3.66803646e-01
   9.12893191e-02   2.71662975e-05   1.11916370e-05   1.21569365e-05
   9.74633895e-06]
[2017-11-02 09:42:44,668] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.02014550e-04   3.81073356e-01   1.92339256e-01   3.43379229e-01
   8.31061751e-02   7.84525866e-09   4.37167680e-09   5.35343103e-09
   4.24837499e-09]
[2017-11-02 09:42:49,068] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.46419321e-09   1.16272151e-01   1.02272183e-01   1.88598782e-01
   4.02249098e-02   1.87273920e-01   1.12837650e-01   1.04895778e-01
   1.47624597e-01]
[2017-11-02 09:42:50,910] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12436826  0.15277146  0.18944806  0.16113153  0.10127898  0.08750349
  0.07136748  0.06769231  0.04443851]
[2017-11-02 09:42:51,205] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12544468  0.1663375   0.22207785  0.18517894  0.10670095  0.06533281
  0.05175926  0.04801964  0.02914828]
[2017-11-02 09:42:56,200] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.86623642e-14   2.86329276e-04   1.30771441e-04   3.14010860e-04
   7.07528816e-05   3.07793379e-01   2.10409924e-01   2.29074910e-01
   2.51919955e-01]
[2017-11-02 09:42:56,895] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.77811832e-05   3.87941331e-01   1.87630519e-01   3.55018556e-01
   6.93802088e-02   5.52161339e-07   3.13003170e-07   3.71326308e-07
   3.86165397e-07]
[2017-11-02 09:42:58,925] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.24996342e-08   3.69039237e-01   1.59450039e-01   3.89414549e-01
   7.30282813e-02   2.89770239e-03   1.76404743e-03   1.96853746e-03
   2.43750494e-03]
[2017-11-02 09:42:59,055] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.26172915e-27   5.72230718e-12   2.21816272e-12   7.28951881e-12
   1.19902157e-12   2.73796290e-01   2.02328816e-01   2.08159789e-01
   3.15715164e-01]
[2017-11-02 09:43:03,548] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.39305881e-17   2.93549931e-07   3.74037967e-07   5.69322481e-07
   1.32713680e-07   3.53763163e-01   2.25322366e-01   1.96472690e-01
   2.24440485e-01]
[2017-11-02 09:43:05,035] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.63810531e-05   2.94520736e-01   2.82198191e-01   3.30850691e-01
   9.23024863e-02   2.22926919e-05   1.07031710e-05   1.09024531e-05
   7.66650464e-06]
[2017-11-02 09:43:08,704] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.34519607e-01   3.12271506e-01   1.95128486e-01   2.78673947e-01
   7.94064626e-02   9.80829025e-13   4.10539549e-13   5.96967083e-13
   4.04557274e-13]
[2017-11-02 09:43:12,449] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.81501358e-10   8.15983629e-04   9.34509735e-04   1.30375917e-03
   3.89320950e-04   3.20529491e-01   2.41811782e-01   2.11005345e-01
   2.23209798e-01]
[2017-11-02 09:43:14,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11955263  0.18932657  0.28473157  0.23105283  0.11438119  0.02449842
  0.01372917  0.01502881  0.00769881]
[2017-11-02 09:43:17,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.74048994e-07   2.98020869e-01   2.22276062e-01   3.77228379e-01
   8.77018273e-02   4.37094970e-03   2.87030288e-03   3.19054420e-03
   4.34064213e-03]
[2017-11-02 09:43:17,440] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.69770941e-06   3.10015470e-01   2.40825832e-01   3.67439717e-01
   8.14768076e-02   6.79307850e-05   4.14063070e-05   5.13347768e-05
   7.38248564e-05]
[2017-11-02 09:43:18,552] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.33919157e-03   3.11336070e-01   2.56759346e-01   3.47362876e-01
   8.32025111e-02   5.90313975e-09   3.03085002e-09   3.90900734e-09
   4.42266446e-09]
[2017-11-02 09:43:22,312] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13270339  0.14357665  0.17587286  0.16245335  0.09667248  0.0961088
  0.07050433  0.07683697  0.04527113]
[2017-11-02 09:43:26,404] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14933728  0.12572701  0.14890297  0.14538623  0.10163717  0.10532612
  0.08203855  0.09143983  0.05020486]
[2017-11-02 09:43:29,292] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0947002   0.09773389  0.13491972  0.11923623  0.10525832  0.11764742
  0.12025119  0.1177215   0.09253152]
[2017-11-02 09:43:30,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12727849  0.12692334  0.14738874  0.1422388   0.09388508  0.1134325
  0.08830678  0.10033896  0.06020725]
[2017-11-02 09:43:32,611] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11672171  0.11223304  0.14357509  0.12911589  0.1088408   0.11105293
  0.10287127  0.10349435  0.07209488]
[2017-11-02 09:43:34,707] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06523711  0.21029095  0.34071928  0.26996952  0.09995704  0.00437722
  0.00263179  0.00358227  0.00323491]
[2017-11-02 09:43:35,258] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11334954  0.14780691  0.20882556  0.18339306  0.10446154  0.08606615
  0.05927387  0.06065799  0.03616531]
[2017-11-02 09:43:37,962] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.17086142e-14   1.13752023e-04   7.97821485e-05   1.79186580e-04
   3.82442813e-05   2.77234823e-01   1.95759743e-01   2.11505339e-01
   3.15089136e-01]
[2017-11-02 09:43:41,528] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.61287919e-01   2.20932648e-01   2.61097997e-01   2.55333930e-01
   1.01347312e-01   1.04349716e-07   4.32538805e-08   4.38008207e-08
   1.78836235e-08]
[2017-11-02 09:43:42,010] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14321859  0.15170468  0.17503284  0.14928551  0.10567389  0.09550665
  0.0727733   0.0689097   0.03789483]
[2017-11-02 09:43:45,032] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37543620e-03   3.14243287e-01   2.77737945e-01   3.17976594e-01
   8.86647925e-02   6.60935711e-07   3.66845939e-07   4.30794955e-07
   4.22385284e-07]
[2017-11-02 09:43:45,089] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.28071336e-07   3.12577218e-01   2.21403703e-01   3.35418075e-01
   8.40520337e-02   1.40606575e-02   9.38372687e-03   1.04257418e-02
   1.26779592e-02]
[2017-11-02 09:43:45,694] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.26778433e-01   2.49436304e-01   2.27596551e-01   2.23058239e-01
   7.31304139e-02   4.44955964e-12   1.66666680e-12   2.11514270e-12
   1.26041029e-12]
[2017-11-02 09:43:46,175] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86399204e-02   2.71391124e-01   2.74782985e-01   2.72083551e-01
   8.31024423e-02   5.72111247e-10   2.54808147e-10   3.22510962e-10
   2.93680941e-10]
[2017-11-02 09:43:47,888] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10161884  0.10732946  0.13339417  0.11567578  0.1111881   0.11251442
  0.12221994  0.1068032   0.08925614]
[2017-11-02 09:43:49,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12737598  0.21235171  0.28595328  0.24684024  0.11767058  0.00318967
  0.0021207   0.00257332  0.00192456]
[2017-11-02 09:43:50,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00840993e-01   2.33683690e-01   3.07087064e-01   2.66130984e-01
   9.22506973e-02   2.28676845e-06   1.20194795e-06   1.67267820e-06
   1.47718106e-06]
[2017-11-02 09:43:52,583] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12501822  0.11456114  0.15064983  0.13224165  0.11417045  0.09791965
  0.09797551  0.09753846  0.06992505]
[2017-11-02 09:43:52,900] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17742012  0.1336382   0.17601392  0.16235463  0.10554547  0.08954589
  0.05993908  0.06681728  0.02872532]
[2017-11-02 09:43:52,971] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14897069  0.13328607  0.16870902  0.15816645  0.10450377  0.10142288
  0.06952176  0.07670344  0.03871595]
[2017-11-02 09:43:54,061] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.13123648e-01   2.18031585e-01   3.09342057e-01   2.64112234e-01
   9.53854769e-02   1.71526005e-06   8.74066188e-07   1.27795454e-06
   1.12025293e-06]
[2017-11-02 09:43:54,228] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.76107953e-02   2.62985826e-01   3.10109526e-01   2.95863420e-01
   9.34291407e-02   3.97995962e-07   1.95024256e-07   3.06105420e-07
   3.32695379e-07]
[2017-11-02 09:43:54,313] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10880338  0.16886032  0.2431069   0.2163599   0.11866811  0.05181517
  0.03464351  0.0355081   0.02223456]
[2017-11-02 09:43:54,621] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11783111  0.16024955  0.24153499  0.22144467  0.11680805  0.05451405
  0.03275524  0.03577547  0.0190868 ]
[2017-11-02 09:43:54,727] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08962225  0.1218429   0.18112758  0.16440409  0.09485769  0.12301326
  0.07821257  0.09149733  0.05542231]
[2017-11-02 09:44:00,130] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.01943398e-13   1.04635218e-02   5.90111408e-03   1.72256529e-02
   3.15170619e-03   2.73122102e-01   1.80853546e-01   1.95447892e-01
   3.13834429e-01]
[2017-11-02 09:44:02,729] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30013481e-01   2.28752494e-01   2.83322006e-01   2.67982036e-01
   8.99299979e-02   1.62063185e-09   6.15958340e-10   7.19425408e-10
   4.51953169e-10]
[2017-11-02 09:44:02,767] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.20960444e-02   2.45969638e-01   3.05479586e-01   2.88970798e-01
   9.74838063e-02   4.68767034e-08   1.90834974e-08   2.23536318e-08
   1.44067362e-08]
[2017-11-02 09:44:10,407] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.36845764e-12   5.08163832e-02   2.31584702e-02   7.19672143e-02
   1.23501476e-02   2.51650631e-01   1.54957056e-01   1.74707413e-01
   2.60392725e-01]
[2017-11-02 09:44:11,514] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97845675e-33   8.83658737e-15   3.31714132e-15   1.50885299e-14
   2.31573789e-15   2.64905661e-01   1.89348429e-01   1.97161794e-01
   3.48584056e-01]
[2017-11-02 09:44:18,688] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.36718109e-01   3.12468946e-01   1.98341757e-01   2.74196237e-01
   7.82749578e-02   1.93097305e-14   7.01414728e-15   9.32419205e-15
   7.56260746e-15]
[2017-11-02 09:44:20,477] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.32623991e-05   3.72538060e-01   1.67006388e-01   3.67894590e-01
   9.24777091e-02   2.23316296e-10   1.07338159e-10   1.44051895e-10
   1.53670368e-10]
[2017-11-02 09:44:23,762] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.01941783e-12   5.53527176e-02   1.76772196e-02   6.47237524e-02
   1.10922074e-02   2.53012806e-01   1.57056093e-01   1.89081907e-01
   2.52003342e-01]
[2017-11-02 09:44:24,669] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.81549017e-24   4.56093696e-09   1.15837029e-09   5.74589132e-09
   9.39394673e-10   2.83239365e-01   1.87873706e-01   2.27610067e-01
   3.01276803e-01]
[2017-11-02 09:44:29,723] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.64300948e-01   2.72482485e-01   2.34726191e-01   2.53544062e-01
   7.49463364e-02   3.66148653e-13   1.35781943e-13   1.63061147e-13
   1.29421769e-13]
[2017-11-02 09:44:33,934] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.55008786e-04   3.86367261e-01   1.85008034e-01   3.48489612e-01
   7.97800720e-02   3.23116311e-09   1.76640258e-09   2.21722241e-09
   1.84345050e-09]
[2017-11-02 09:44:35,936] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.05764557e-07   3.55449021e-01   1.89290985e-01   3.79171103e-01
   7.60522187e-02   1.16321762e-05   7.14366752e-06   7.68746031e-06
   9.41599956e-06]
[2017-11-02 09:44:37,115] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.85948159e-02   3.38374645e-01   2.33499989e-01   3.10244799e-01
   7.92857260e-02   1.12608959e-11   4.87319950e-12   5.64800940e-12
   4.93606328e-12]
[2017-11-02 09:44:40,286] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.26949713e-01   2.27173820e-01   2.91999787e-01   2.57769525e-01
   9.61063579e-02   3.96589741e-07   1.73410641e-07   1.92370308e-07
   1.11612643e-07]
[2017-11-02 09:44:47,739] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09879687e-01   3.05459261e-01   2.08489552e-01   3.03656161e-01
   7.25153014e-02   4.82972020e-14   1.76134166e-14   2.56301074e-14
   2.12682163e-14]
[2017-11-02 09:44:49,733] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.54941022e-01   2.72669554e-01   2.22359717e-01   2.69443512e-01
   8.05862099e-02   9.85634317e-12   3.58304619e-12   3.48326251e-12
   1.90398717e-12]
[2017-11-02 09:44:55,511] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.53771508e-02   3.65136623e-01   2.07465276e-01   3.23601723e-01
   8.84192064e-02   1.47641500e-11   6.61968267e-12   8.89458212e-12
   6.50820934e-12]
[2017-11-02 09:44:57,478] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.59388510e-05   3.94076020e-01   1.74614206e-01   3.59577626e-01
   7.17162192e-02   1.95062473e-08   1.03698126e-08   1.22141515e-08
   1.25964865e-08]
[2017-11-02 09:45:00,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0944766   0.18399236  0.28187215  0.23781513  0.10917374  0.03539988
  0.02044088  0.02327655  0.01355267]
[2017-11-02 09:45:03,182] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.34991050e-01   3.25104028e-01   1.81722388e-01   2.75298208e-01
   8.28843266e-02   1.94664841e-14   7.70386884e-15   1.06938054e-14
   9.18171518e-15]
[2017-11-02 09:45:20,422] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.14809012e-02   2.67086565e-01   3.18402380e-01   2.85743058e-01
   1.06661201e-01   2.70462391e-04   1.34274247e-04   1.43157929e-04
   7.79679322e-05]
[2017-11-02 09:45:24,121] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.56111552e-26   2.38757417e-11   1.05168391e-11   3.63517584e-11
   7.13474982e-12   2.91141599e-01   1.98335424e-01   2.25960732e-01
   2.84562260e-01]
[2017-11-02 09:45:27,455] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.41341289e-07   4.09651011e-01   1.39725953e-01   3.83272707e-01
   6.73447251e-02   1.91569620e-06   9.69199505e-07   1.25186648e-06
   1.37025677e-06]
[2017-11-02 09:45:27,974] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.61328288e-15   3.01013119e-04   9.44783678e-05   3.08584305e-04
   4.83506446e-05   3.16651911e-01   1.87289685e-01   2.23166719e-01
   2.72139221e-01]
[2017-11-02 09:45:33,366] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.26964495e-01   3.15503746e-01   2.11809486e-01   2.61438102e-01
   8.42841417e-02   3.45960348e-12   1.42203003e-12   2.01994064e-12
   1.36197184e-12]
[2017-11-02 09:45:33,426] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.45760281e-08   3.37131262e-01   1.86045259e-01   3.76039714e-01
   9.49443579e-02   1.88552879e-03   1.18616165e-03   1.35701837e-03
   1.41060213e-03]
[2017-11-02 09:45:34,289] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.26621126e-08   3.49077821e-01   1.91998199e-01   3.60967487e-01
   9.03247893e-02   2.51371600e-03   1.57578185e-03   1.74766826e-03
   1.79447187e-03]
[2017-11-02 09:45:38,131] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10635757  0.21281873  0.29364476  0.24213786  0.11068892  0.01345722
  0.00831996  0.00816278  0.00441221]
[2017-11-02 09:45:39,309] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14344093  0.13001217  0.1580338   0.14460565  0.10847622  0.09805469
  0.08577576  0.08205116  0.04954964]
[2017-11-02 09:45:39,699] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13080829  0.12346284  0.14799526  0.13472167  0.11254077  0.09943192
  0.09756511  0.09020476  0.06326935]
[2017-11-02 09:45:42,149] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.13004743e-12   2.44842703e-03   1.44309457e-03   2.89531588e-03
   6.52879942e-04   3.08560342e-01   2.16351941e-01   2.18358442e-01
   2.49289483e-01]
[2017-11-02 09:45:42,293] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.91773579e-19   8.32958023e-08   4.50335591e-08   1.07091111e-07
   2.29143655e-08   2.95510769e-01   2.17417732e-01   2.17331484e-01
   2.69739777e-01]
[2017-11-02 09:45:42,973] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91909206e-02   2.92335689e-01   2.41734296e-01   2.93050259e-01
   7.36888051e-02   3.60097260e-12   1.44091716e-12   1.82310287e-12
   1.54083885e-12]
[2017-11-02 09:45:46,576] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.31908347e-15   3.16455589e-05   3.62989776e-05   6.30741051e-05
   1.42883864e-05   3.64761710e-01   2.09637687e-01   1.80393890e-01
   2.45061383e-01]
[2017-11-02 09:45:47,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0939234   0.12200885  0.15946466  0.14080869  0.09919078  0.11908071
  0.0985938   0.09765949  0.06926958]
[2017-11-02 09:45:47,843] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21027479  0.17940736  0.22806661  0.19209677  0.10403958  0.03364952
  0.02201408  0.02220884  0.00824255]
[2017-11-02 09:45:59,506] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.23661384e-01   2.96498895e-01   2.41486311e-01   2.58871496e-01
   7.94819817e-02   8.43914591e-11   3.41420052e-11   4.58394538e-11
   3.16364747e-11]
[2017-11-02 09:46:09,000] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10720898  0.10908499  0.13855045  0.12039194  0.1070004   0.1142303
  0.11412032  0.10777505  0.08163749]
[2017-11-02 09:46:12,761] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.53216104e-10   1.73111692e-01   1.01959854e-01   2.34967798e-01
   4.74027097e-02   1.31451502e-01   8.69186074e-02   9.13125798e-02
   1.32875234e-01]
[2017-11-02 09:46:16,895] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.77411482e-01   1.95831999e-01   2.67235994e-01   2.43888006e-01
   1.14080615e-01   6.94970018e-04   3.69862537e-04   3.51155322e-04
   1.35935639e-04]
[2017-11-02 09:46:18,466] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.40612755e-20   5.42260885e-08   3.15536326e-08   8.40639345e-08
   1.71858048e-08   2.89695948e-01   2.00795174e-01   2.14765355e-01
   2.94743329e-01]
[2017-11-02 09:46:21,257] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.73371707e-02   3.53943259e-01   2.18191251e-01   3.04467052e-01
   7.60612488e-02   4.07769277e-13   1.57192279e-13   2.04451934e-13
   1.71128614e-13]
[2017-11-02 09:46:34,136] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.73742421e-07   3.22848409e-01   2.10014164e-01   3.72834384e-01
   8.94208774e-02   1.55495049e-03   9.84999118e-04   1.09042774e-03
   1.25157495e-03]
[2017-11-02 09:46:36,211] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.08639982e-03   3.40062350e-01   2.40148887e-01   3.39885980e-01
   7.78163671e-02   2.41352827e-09   1.18349719e-09   1.47371781e-09
   1.46801715e-09]
[2017-11-02 09:46:37,208] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09975161  0.11195306  0.13620184  0.12084942  0.10097174  0.12548794
  0.12036358  0.10650572  0.07791515]
[2017-11-02 09:46:38,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10885359  0.11337045  0.13742992  0.12523834  0.10960548  0.11224066
  0.11606913  0.0998527   0.07733966]
[2017-11-02 09:46:39,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12349281  0.17410959  0.25152344  0.22373262  0.10228583  0.04677898
  0.02992741  0.0311355   0.01701379]
[2017-11-02 09:46:44,685] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.48880675e-01   2.59098172e-01   2.52536803e-01   2.57572681e-01
   8.19116756e-02   3.20579639e-11   1.32151104e-11   1.71633194e-11
   1.43735700e-11]
[2017-11-02 09:46:50,505] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   4.29051630e-19   1.33552355e-19   6.06705391e-19
   7.11763068e-20   2.73823053e-01   1.89949736e-01   2.03941852e-01
   3.32285345e-01]
[2017-11-02 09:46:53,619] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10174189  0.13277696  0.16166653  0.14448914  0.10600106  0.11278116
  0.09126105  0.08851568  0.06076653]
[2017-11-02 09:47:04,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10625781  0.19951327  0.29198489  0.25371763  0.11536068  0.01318335
  0.00797508  0.00773234  0.00427498]
[2017-11-02 09:47:10,151] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.85910627e-04   2.71293461e-01   2.83148497e-01   3.40766639e-01
   1.03989817e-01   1.68382205e-04   1.02044854e-04   1.38414471e-04
   2.06889410e-04]
[2017-11-02 09:47:14,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.98927268e-01   2.71781057e-01   2.01834977e-01   2.54218429e-01
   7.32382312e-02   1.83901356e-14   6.07062626e-15   9.18274263e-15
   5.81157818e-15]
[2017-11-02 09:47:15,802] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.68518201e-01   2.01503783e-01   2.53841937e-01   2.70182401e-01
   1.05950348e-01   1.69441500e-06   7.38463825e-07   6.81978122e-07
   2.29085060e-07]
[2017-11-02 09:47:16,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11830069  0.11504323  0.14737763  0.13282828  0.11237632  0.10474046
  0.10205726  0.09725007  0.07002603]
[2017-11-02 09:47:19,962] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11180989  0.10986732  0.14238919  0.12563261  0.11523267  0.10167153
  0.11001998  0.10134974  0.082027  ]
[2017-11-02 09:47:21,181] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.29448455e-02   2.53245920e-01   3.17510694e-01   3.08089614e-01
   1.08187579e-01   6.46765830e-06   3.65419578e-06   5.11532426e-06
   6.12149415e-06]
[2017-11-02 09:47:22,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.03724936e-01   2.64098644e-01   2.19035685e-01   2.40468219e-01
   7.26725087e-02   2.29514514e-13   8.13553326e-14   1.09083702e-13
   6.63435710e-14]
[2017-11-02 09:47:25,016] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.66682658e-19   2.40280087e-07   1.13016377e-07   2.94307483e-07
   5.38367146e-08   2.91059405e-01   2.05599919e-01   2.12022811e-01
   2.91317105e-01]
[2017-11-02 09:47:32,909] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07365023  0.16058484  0.2241182   0.20845295  0.1002923   0.07688005
  0.05783696  0.05764643  0.04053814]
[2017-11-02 09:47:38,093] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1598964   0.12718812  0.17111897  0.15019961  0.11867294  0.07800432
  0.07313055  0.07685387  0.04493522]
[2017-11-02 09:47:42,141] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.07887515e-05   3.18611592e-01   2.52647072e-01   3.31389606e-01
   9.68808681e-02   1.08429682e-04   6.54995383e-05   9.00959712e-05
   1.16074523e-04]
[2017-11-02 09:47:42,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.05513528e-03   3.40875149e-01   2.43575305e-01   3.27371538e-01
   8.71228725e-02   5.57036950e-09   2.88519941e-09   3.32454508e-09
   3.32439321e-09]
[2017-11-02 09:47:52,324] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.98601002e-09   5.32616228e-02   3.50911580e-02   6.46114871e-02
   1.47669911e-02   2.43986383e-01   1.63784713e-01   1.78169534e-01
   2.46328101e-01]
[2017-11-02 09:47:52,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.09954572e-04   3.55985284e-01   2.25107118e-01   3.34774613e-01
   8.38229731e-02   4.44992345e-08   2.65794124e-08   2.93633207e-08
   2.69658624e-08]
[2017-11-02 09:47:52,615] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.88054465e-17   1.61230764e-06   1.00895636e-06   2.13420140e-06
   4.45908142e-07   2.88738877e-01   2.09749132e-01   2.06006303e-01
   2.95500457e-01]
[2017-11-02 09:47:54,595] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.27624999e-21   1.63665153e-08   9.05805386e-09   2.40622438e-08
   4.31491287e-09   2.72837758e-01   2.04995632e-01   1.95024073e-01
   3.27142507e-01]
[2017-11-02 09:48:02,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11236882  0.20710251  0.26942927  0.25083122  0.10969882  0.01649207
  0.01222122  0.01289145  0.00896467]
[2017-11-02 09:48:03,128] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.11043968e-03   2.81141043e-01   3.03402096e-01   3.05893689e-01
   1.04227655e-01   3.71178525e-04   2.39243498e-04   3.04033048e-04
   3.10626201e-04]
[2017-11-02 09:48:05,582] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.45974443e-19   5.99428915e-07   3.20029727e-07   8.71286034e-07
   1.62425863e-07   2.85182446e-01   2.00565204e-01   1.98379830e-01
   3.15870553e-01]
[2017-11-02 09:48:14,407] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.96902031e-02   3.30917120e-01   2.16643557e-01   2.86927283e-01
   8.58218670e-02   1.06901875e-11   4.65532734e-12   6.10420438e-12
   4.27816550e-12]
[2017-11-02 09:48:37,848] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1669398   0.13647935  0.16910297  0.15743832  0.11700246  0.07693329
  0.06621852  0.07038298  0.03950229]
[2017-11-02 09:48:38,162] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09286996  0.09777176  0.12928489  0.1159559   0.11069782  0.11378123
  0.12316842  0.11436258  0.10210748]
[2017-11-02 09:48:39,366] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13645494  0.12217728  0.15485096  0.13846585  0.12010612  0.08736397
  0.09028535  0.08707318  0.06322234]
[2017-11-02 09:48:44,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.14092040e-26   1.40475027e-11   6.67599092e-12   1.83549755e-11
   3.31971451e-12   2.73947090e-01   2.07329512e-01   2.10453153e-01
   3.08270276e-01]
[2017-11-02 09:48:51,631] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.16292739e-01   2.53575057e-01   2.25496471e-01   2.23022446e-01
   8.16133544e-02   1.15784049e-11   4.29804282e-12   5.96960892e-12
   4.03646691e-12]
[2017-11-02 09:48:53,324] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.04328230e-07   3.19708765e-01   2.09526211e-01   3.75205964e-01
   7.99859762e-02   4.33321064e-03   2.64839386e-03   3.34813888e-03
   5.24330512e-03]
[2017-11-02 09:48:53,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19648449e-01   2.94254482e-01   2.29834482e-01   2.76291549e-01
   7.99710602e-02   4.03234249e-13   1.58463954e-13   2.22928487e-13
   1.77687970e-13]
[2017-11-02 09:48:57,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11533892  0.11778978  0.14690608  0.12871821  0.11070012  0.1065767
  0.10590839  0.09814242  0.06991937]
[2017-11-02 09:48:58,155] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10364059  0.1067481   0.13911986  0.12301194  0.11214559  0.10876822
  0.11559936  0.10598367  0.08498276]
[2017-11-02 09:49:06,444] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08602602  0.09465137  0.12048206  0.11024364  0.10465028  0.12609926
  0.13751954  0.11627449  0.10405338]
[2017-11-02 09:49:09,532] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18512577  0.16234103  0.23814094  0.20143795  0.09465332  0.04727025
  0.02631287  0.03212834  0.01258951]
[2017-11-02 09:49:10,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0971083   0.18440855  0.28083143  0.23508424  0.10308377  0.0324739
  0.02198233  0.02620223  0.01882523]
[2017-11-02 09:49:13,140] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13037175  0.12263888  0.15164837  0.13687125  0.11008324  0.1010142
  0.0951291   0.09137682  0.06086636]
[2017-11-02 09:49:18,318] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.73579348e-06   3.20395410e-01   2.15859517e-01   3.81269336e-01
   8.24603140e-02   3.30975081e-06   2.01424632e-06   2.27621445e-06
   2.99691669e-06]
[2017-11-02 09:49:25,816] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21578875  0.16686699  0.19770679  0.17288324  0.10814589  0.05360456
  0.03520572  0.03589639  0.01390165]
[2017-11-02 09:49:26,470] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.54822317e-06   2.26958886e-01   1.84902400e-01   2.56284952e-01
   7.43241459e-02   7.07293153e-02   4.61348295e-02   5.62287942e-02
   8.44351798e-02]
[2017-11-02 09:49:27,100] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.18252382e-01   3.00822914e-01   2.35506922e-01   2.56746650e-01
   8.86710733e-02   2.01421144e-10   9.30555355e-11   1.20134666e-10
   8.24917010e-11]
[2017-11-02 09:49:36,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.61983182e-03   3.12538087e-01   2.84625620e-01   3.04944307e-01
   9.51951817e-02   2.54064016e-05   1.50202141e-05   1.83515549e-05
   1.80951811e-05]
[2017-11-02 09:49:51,019] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19890429e-01   3.11199963e-01   1.99252710e-01   2.97302723e-01
   7.23541901e-02   2.20892183e-14   7.95805835e-15   1.18227851e-14
   9.08922087e-15]
[2017-11-02 09:49:52,478] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09214781  0.15513305  0.20457147  0.17800415  0.10677107  0.08850552
  0.06249916  0.06784685  0.04452086]
[2017-11-02 09:49:59,748] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.42513652e-05   3.66926879e-01   2.22790241e-01   3.26939642e-01
   8.32480937e-02   3.20553966e-07   1.86621165e-07   2.03092227e-07
   1.85267794e-07]
[2017-11-02 09:50:03,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08143034  0.14559008  0.19086201  0.1660542   0.10671119  0.09984478
  0.07425341  0.07993107  0.05532282]
[2017-11-02 09:50:08,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15702754  0.12577103  0.16799812  0.14917657  0.11824767  0.08034222
  0.07499653  0.07877518  0.04766506]
[2017-11-02 09:50:22,572] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.48311165e-02   2.35195041e-01   3.11442584e-01   2.57691175e-01
   9.97277498e-02   3.79941164e-04   2.34878185e-04   2.84187438e-04
   2.13334279e-04]
[2017-11-02 09:50:24,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.16474628  0.20475808  0.21951586  0.18627654  0.11517961  0.03763964
  0.03092128  0.02589805  0.01506465]
[2017-11-02 09:50:44,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1263593   0.11991466  0.15040037  0.13816053  0.10660407  0.10662095
  0.09328336  0.09653534  0.06212151]
[2017-11-02 09:50:54,367] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17812696  0.13473891  0.17902105  0.16216479  0.11519402  0.07041347
  0.05926446  0.06666181  0.03441451]
[2017-11-02 09:50:55,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08871988  0.093107    0.12850127  0.11325023  0.11131214  0.11111105
  0.12537929  0.11843941  0.11017974]
[2017-11-02 09:50:57,848] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.88894023e-02   2.60700852e-01   3.07980865e-01   2.75626093e-01
   1.06754132e-01   1.55430353e-05   9.32873354e-06   1.22957399e-05
   1.14636887e-05]
[2017-11-02 09:51:10,791] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09723308  0.09949675  0.13641967  0.11904365  0.11423755  0.10636621
  0.11824663  0.1119701   0.09698636]
[2017-11-02 09:51:12,766] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.16936392  0.12785795  0.15493788  0.14808461  0.1058634   0.0958968
  0.07339618  0.08229411  0.04230518]
[2017-11-02 09:51:12,956] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14590806  0.12437855  0.15482438  0.14224918  0.09154339  0.11572036
  0.0802445   0.09659342  0.04853809]
[2017-11-02 09:51:13,137] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10840995  0.11947292  0.16388611  0.14482525  0.08376712  0.12718433
  0.0859747   0.1047164   0.06176318]
[2017-11-02 09:51:13,868] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.64763890e-04   2.77166992e-01   2.74737418e-01   2.99698114e-01
   9.31998342e-02   1.72481276e-02   1.18964938e-02   1.26658771e-02
   1.31224860e-02]
[2017-11-02 09:51:24,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09749714  0.10408868  0.13854679  0.12302669  0.10912603  0.1146081
  0.11760041  0.10966916  0.08583701]
[2017-11-02 09:51:25,710] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07933952  0.09840985  0.13510582  0.1221681   0.09717971  0.13804778
  0.12101109  0.12250621  0.08623187]
[2017-11-02 09:51:30,489] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.93322148e-08   3.19347950e-04   6.03257387e-04   6.02332992e-04
   1.90068269e-04   3.31855834e-01   1.82058543e-01   2.73460746e-01
   2.10909829e-01]
[2017-11-02 09:51:30,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   2.44850691e-25   6.09182057e-25   1.11970522e-24
   1.45410533e-25   2.38696769e-01   1.19943708e-01   2.38838837e-01
   4.02520657e-01]
[2017-11-02 09:51:31,857] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.33449343e-02   2.34146908e-01   3.04761380e-01   2.80074745e-01
   8.76720548e-02   2.33303528e-08   1.08339062e-08   1.93524663e-08
   2.29598900e-08]
[2017-11-02 09:51:32,334] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14294854  0.20559084  0.29245552  0.2430709   0.11275595  0.00103239
  0.00062328  0.00084361  0.000679  ]
[2017-11-02 09:51:33,828] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09892802  0.10281296  0.13599555  0.11792399  0.10919986  0.11323758
  0.11991841  0.11173511  0.0902485 ]
[2017-11-02 09:51:37,217] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12614277  0.16355376  0.20954385  0.19609351  0.10821631  0.06300342
  0.04643454  0.05106982  0.03594198]
[2017-11-02 09:51:37,669] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11302493  0.11360697  0.13582277  0.13187289  0.08720772  0.13114722
  0.10110023  0.11566132  0.07055592]
[2017-11-02 09:51:52,069] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47632605e-07   1.39143094e-01   1.40270799e-01   2.02866390e-01
   5.82553744e-02   1.16489261e-01   6.87380433e-02   9.49974582e-02
   1.79239422e-01]
[2017-11-02 09:51:52,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.23110414e-03   3.34948003e-01   2.38588884e-01   3.36264074e-01
   8.89679715e-02   4.19655910e-09   2.19107665e-09   2.87296142e-09
   2.85491319e-09]
[2017-11-02 09:51:58,570] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00260003  0.21182226  0.26580629  0.25986093  0.10316858  0.05785025
  0.03580786  0.03823056  0.0248532 ]
[2017-11-02 09:52:04,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.62112945e-01   2.63375849e-01   1.90817311e-01   2.09287405e-01
   7.44065493e-02   3.98983553e-13   1.38578968e-13   1.93767826e-13
   9.10933452e-14]
[2017-11-02 09:52:14,555] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11275283  0.11365255  0.13858813  0.12638128  0.10986773  0.11088435
  0.11001263  0.10044602  0.07741448]
[2017-11-02 09:52:19,650] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12660861  0.12082137  0.14649002  0.13028124  0.11309297  0.10118445
  0.10208936  0.09256402  0.06686787]
[2017-11-02 09:52:25,263] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.182567    0.13337463  0.15959321  0.1480033   0.09120932  0.10015301
  0.06610083  0.0822188   0.03677992]
[2017-11-02 09:52:27,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10748103  0.1084433   0.13706583  0.12108713  0.11446426  0.10366163
  0.11482835  0.10397886  0.08898959]
[2017-11-02 09:52:27,939] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11833749  0.1157427   0.14848198  0.1313131   0.11776871  0.09603847
  0.10278555  0.09548268  0.07404933]
[2017-11-02 09:52:28,388] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10080083  0.10422061  0.13975017  0.12407608  0.11358401  0.10767814
  0.11452357  0.10744508  0.08792156]
[2017-11-02 09:52:28,689] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09434751  0.09909417  0.13546814  0.11891776  0.11155023  0.11108397
  0.11968231  0.11366881  0.09618707]
[2017-11-02 09:52:29,922] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09831771  0.10379173  0.1344572   0.11907773  0.10838573  0.12271035
  0.11677701  0.11190031  0.08458221]
[2017-11-02 09:52:30,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13825639  0.10589794  0.14265165  0.12834162  0.10667774  0.10944587
  0.09955242  0.10178184  0.06739454]
[2017-11-02 09:52:31,912] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15370981  0.11284573  0.1427429   0.129795    0.10950523  0.10220988
  0.09284074  0.09471575  0.06163501]
[2017-11-02 09:52:33,288] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11181701  0.108433    0.13287935  0.11911091  0.10776456  0.10895637
  0.11653217  0.10683868  0.08766797]
[2017-11-02 09:52:35,632] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14751428  0.1223494   0.16458072  0.14531596  0.11406241  0.08756001
  0.08003205  0.08610687  0.05247819]
[2017-11-02 09:52:37,760] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15161015  0.12120961  0.14586325  0.13959311  0.09050207  0.1210615
  0.08229078  0.09919632  0.04867325]
[2017-11-02 09:52:38,696] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10209927  0.11334495  0.14957967  0.13628428  0.07787299  0.13934489
  0.0933254   0.1171798   0.07096884]
[2017-11-02 09:52:41,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08420759  0.09214693  0.12487518  0.11072744  0.10431245  0.12583587
  0.13197199  0.12115074  0.10477186]
[2017-11-02 09:52:43,328] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1052768   0.10541183  0.14019775  0.12524508  0.11290029  0.1063649
  0.11354081  0.106024    0.08503862]
[2017-11-02 09:52:44,450] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12550318  0.11829216  0.1541353   0.13879859  0.11441982  0.09749769
  0.09536495  0.09247549  0.06351282]
[2017-11-02 09:52:44,474] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12087892  0.11619138  0.15043281  0.13542679  0.11456861  0.09915276
  0.09989022  0.09498089  0.06847758]
[2017-11-02 09:52:44,866] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09460787  0.09791031  0.13300788  0.11752892  0.11229607  0.1100892
  0.12132794  0.11355825  0.09967361]
[2017-11-02 09:52:47,034] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17790347e-10   6.73789019e-03   3.79794021e-03   6.70814048e-03
   1.62785035e-03   2.86122292e-01   2.21520290e-01   2.09539264e-01
   2.63946414e-01]
[2017-11-02 09:52:48,343] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.17414130e-14   1.29382577e-04   6.44224565e-05   1.44242018e-04
   2.67057148e-05   2.97333986e-01   2.17414722e-01   2.01868907e-01
   2.83017606e-01]
[2017-11-02 09:52:58,794] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.85736605e-04   3.36769670e-01   2.53656894e-01   3.23004574e-01
   8.56830701e-02   2.52153871e-08   1.35407605e-08   1.56050710e-08
   1.45402002e-08]
[2017-11-02 09:52:59,439] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.42424482e-06   3.10375601e-01   2.53611267e-01   3.48831594e-01
   8.67317393e-02   1.50761858e-04   9.89882756e-05   9.26396460e-05
   1.04017796e-04]
[2017-11-02 09:53:00,562] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09200741  0.1400566   0.18655193  0.16071111  0.10244884  0.10841742
  0.07818254  0.08112969  0.05049442]
[2017-11-02 09:53:09,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17684029  0.17864862  0.23763533  0.19915406  0.10803434  0.03909701
  0.02581228  0.02470167  0.01007644]
[2017-11-02 09:53:11,219] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.12032650e-09   4.23831912e-03   3.45715717e-03   5.06858062e-03
   1.15055242e-03   2.70073056e-01   1.99446529e-01   2.14033663e-01
   3.02532107e-01]
[2017-11-02 09:53:11,522] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.41877842e-02   2.64243215e-01   3.15881550e-01   2.88831651e-01
   8.68540853e-02   6.02466628e-07   3.08683298e-07   3.90236067e-07
   3.78738008e-07]
[2017-11-02 09:53:12,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.16961969e-08   1.37000293e-01   9.94121060e-02   1.67879328e-01
   3.40313725e-02   1.55284315e-01   1.17515609e-01   1.14312686e-01
   1.74564213e-01]
[2017-11-02 09:53:12,778] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47777304e-04   3.13266575e-01   2.65573978e-01   3.38489443e-01
   8.25136155e-02   2.87040393e-06   1.75293007e-06   1.81108715e-06
   2.11550218e-06]
[2017-11-02 09:53:17,963] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15160145  0.13529412  0.1635405   0.14429232  0.1042507   0.09715954
  0.08182357  0.07845771  0.04358001]
[2017-11-02 09:53:18,861] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12078661  0.1154261   0.14447278  0.129173    0.11161692  0.1031164
  0.10309438  0.09870282  0.07361095]
[2017-11-02 09:53:19,772] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11985105  0.11639296  0.14482354  0.13013904  0.11000669  0.10523433
  0.10290938  0.09869554  0.07194751]
[2017-11-02 09:53:21,495] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10652402  0.22825493  0.29621884  0.25417095  0.1112621   0.00118319
  0.00076795  0.00091417  0.00070384]
[2017-11-02 09:53:24,495] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10823545  0.13257694  0.1622057   0.14447635  0.10037445  0.10762836
  0.09507105  0.08613645  0.06329523]
[2017-11-02 09:53:37,534] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.168304    0.1192512   0.14952174  0.13807811  0.11162259  0.09545911
  0.08151909  0.08531753  0.05092653]
[2017-11-02 09:53:43,993] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11039323  0.14556934  0.18256466  0.16638309  0.10310684  0.09719712
  0.07212957  0.07455773  0.04809844]
[2017-11-02 09:53:46,207] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09496918  0.09852637  0.13426486  0.11710141  0.11385829  0.10768563
  0.11991476  0.11334303  0.10033653]
[2017-11-02 09:53:46,258] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0991293   0.10154301  0.13710549  0.11933513  0.11522385  0.10501962
  0.11673494  0.11033644  0.09557223]
[2017-11-02 09:53:50,376] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17867364  0.11150549  0.15927157  0.13349329  0.11761277  0.08319888
  0.07939771  0.08485115  0.05199555]
[2017-11-02 09:53:54,317] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08922078  0.0942043   0.13346881  0.11694545  0.11143486  0.1127123
  0.12259987  0.11754769  0.10186593]
[2017-11-02 09:53:54,513] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09065732  0.09542067  0.13446772  0.11743257  0.11172117  0.11210154
  0.12170341  0.11662142  0.09987419]
[2017-11-02 09:53:54,877] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10561687  0.1071905   0.14482032  0.12685294  0.11534064  0.10385019
  0.11026809  0.10422485  0.08183558]
[2017-11-02 09:53:55,604] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14065523  0.12120222  0.16296606  0.15004578  0.11328491  0.10197396
  0.07664334  0.08662378  0.0466047 ]
[2017-11-02 09:53:56,134] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18025023  0.11449187  0.1667182   0.14142324  0.11495336  0.08262867
  0.07448111  0.08012459  0.04492863]
[2017-11-02 09:53:57,198] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1026042   0.11391006  0.15334065  0.1289717   0.07631198  0.14047971
  0.09566025  0.11896804  0.06975346]
[2017-11-02 09:54:00,758] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11680639  0.11489135  0.14110895  0.12822875  0.11087435  0.10567887
  0.10713769  0.0991149   0.07615873]
[2017-11-02 09:54:01,033] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09609129  0.10307872  0.13022743  0.11829445  0.10416713  0.12356901
  0.12268107  0.1121997   0.08969122]
[2017-11-02 09:54:05,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13081461  0.11653326  0.14408502  0.13240534  0.1123941   0.10017744
  0.09964006  0.09463214  0.069318  ]
[2017-11-02 09:54:20,765] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12015133  0.11275919  0.1437875   0.1254034   0.11493164  0.10025223
  0.10756233  0.09870964  0.07644279]
[2017-11-02 09:54:22,634] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09572116  0.09890992  0.13488501  0.11857967  0.1143639   0.10761275
  0.11878476  0.11246637  0.09867646]
[2017-11-02 09:54:25,329] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.30219522  0.14322199  0.1838004   0.17595451  0.10251322  0.03559207
  0.02193345  0.02660298  0.00818622]
[2017-11-02 09:54:25,742] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.24128859  0.14083852  0.17262381  0.1600824   0.10519005  0.06409763
  0.04292302  0.05230129  0.02065476]
[2017-11-02 09:54:27,928] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.26040071  0.1518261   0.18839033  0.17908911  0.11083348  0.03623353
  0.02830857  0.03191377  0.01300439]
[2017-11-02 09:54:31,262] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0769811   0.08423863  0.12064395  0.10567867  0.10461416  0.11783688
  0.13503057  0.12887779  0.12609829]
[2017-11-02 09:54:33,160] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12422385  0.10077479  0.14041239  0.13144086  0.10478859  0.11727442
  0.10336805  0.10633965  0.07137734]
[2017-11-02 09:54:34,035] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -14624.4167
[2017-11-02 09:54:34,035] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, -14624.416699102812]
[2017-11-02 09:54:38,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   8.51007998e-24   6.78068783e-24   3.02575299e-23
   3.12867777e-24   1.37776986e-01   1.16794288e-01   1.60709351e-01
   5.84719300e-01], sum to 1.0000
[2017-11-02 09:54:38,436] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [7.199999999999999, 96.0, 4.933333333333334, 215.0, 0.0, 0.0, 12.2, 17.25556046077312, 21.5, 21.04647348279439, 21.5, 0.0, 41.30177343424362], 
actual action is [12.2, 25], 
sim time next is 6900.0000, 
raw observation next is [7.2, 96.0, 5.016666666666667, 217.5, 0.0, 0.0, 12.2, 16.59538415846841, 25.0, 21.12718770476935, 21.5, 0.0, 39.09426395586159], 
processed observation next is [1.0, 0.043478260869565216, 0.5179487179487179, 0.96, 0.45606060606060606, 0.6041666666666666, 0.0, 0.0, 0.7033333333333334, 0.1659538415846841, 1.0, 0.44674110068133593, 0.5, 0.0, 0.45993251712778344], 
reward next is -0.4672. 
=============================================
[2017-11-02 09:54:41,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   5.51508094e-19   3.44872277e-19   6.67992134e-19
   1.43304220e-19   1.17968976e-01   9.54846442e-02   1.15099169e-01
   6.71447217e-01], sum to 1.0000
[2017-11-02 09:54:41,744] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [7.616666666666667, 93.5, 5.016666666666667, 236.6666666666667, 0.0, 0.0, 2.575, 19.65331921531847, 18.0, 21.13042472995032, 21.5, 0.0, 0.0], 
actual action is [12.616666666666667, 19.0], 
sim time next is 14100.0000, 
raw observation next is [7.658333333333334, 93.25, 5.058333333333334, 238.3333333333333, 0.0, 0.0, 12.61666666666667, 18.21858529515906, 19.0, 20.92760681007625, 21.5, 0.0, 56.20183591881556], 
processed observation next is [1.0, 0.13043478260869565, 0.5297008547008547, 0.9325, 0.4598484848484849, 0.6620370370370369, 0.0, 0.0, 0.7102777777777779, 0.1821858529515906, 0.14285714285714285, 0.41822954429660697, 0.5, 0.0, 0.6611980696331242], 
reward next is -0.6768. 
=============================================
[2017-11-02 09:54:45,713] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.99310738e-01   1.04858540e-01   2.05077633e-01   2.01019034e-01
   8.97340700e-02   5.71590820e-18   1.15528346e-18   2.33701519e-18
   2.63367814e-18], sum to 1.0000
[2017-11-02 09:54:45,737] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 6.1, 240.8333333333333, 0.0, 0.0, 12.7, 12.50737677887561, 22.5, 21.08714901357485, 21.5, 0.0, 56.50812795383061], 
actual action is [2.7, 18], 
sim time next is 25800.0000, 
raw observation next is [7.7, 93.0, 6.1, 241.6666666666667, 0.0, 0.0, 2.7, 13.30457226593987, 18.0, 21.30584865251162, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.5307692307692308, 0.93, 0.5545454545454546, 0.6712962962962964, 0.0, 0.0, 0.545, 0.1330457226593987, 0.0, 0.4722640932159458, 0.5, 0.0, 0.0], 
reward next is -0.0277. 
=============================================
[2017-11-02 09:54:51,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.27689570e-01   1.01440161e-01   3.23766321e-01   2.79197723e-01
   1.67906255e-01   2.28600544e-17   4.59951918e-18   6.18800705e-18
   2.55298791e-17], sum to 1.0000
[2017-11-02 09:54:51,646] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [7.699999999999999, 93.0, 6.949999999999999, 254.1666666666667, 36.58333333333333, 0.0, 12.7, 12.65552363160629, 25.0, 21.47420314181142, 22.7, 1.0, 53.09225036251046], 
actual action is [12.7, 24.5], 
sim time next is 34200.0000, 
raw observation next is [7.7, 93.0, 6.9, 255.0, 38.0, 0.0, 12.7, 11.32748075010561, 24.5, 21.57181294408172, 22.7, 1.0, 72.66964107053747], 
processed observation next is [1.0, 0.391304347826087, 0.5307692307692308, 0.93, 0.6272727272727273, 0.7083333333333334, 0.10052910052910052, 0.0, 0.7116666666666667, 0.11327480750105609, 0.9285714285714286, 0.5102589920116744, 0.6714285714285714, 1.0, 0.854936953771029], 
reward next is -0.7808. 
=============================================
[2017-11-02 09:54:53,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-39.76344681]
 [-40.16292572]
 [-38.65913773]
 [-40.25600052]
 [-39.63707352]], R is [[-40.95020294]
 [-41.54070282]
 [-42.12529755]
 [-42.70404434]
 [-43.27700424]].
[2017-11-02 09:55:04,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-35.67015839]
 [-34.45108414]
 [-33.99980927]
 [-35.05715942]
 [-34.49189758]], R is [[-34.50370407]
 [-34.17221069]
 [-34.2491684 ]
 [-34.66082764]
 [-34.32892609]].
[2017-11-02 09:55:06,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-35.58026123]
 [-35.50847626]
 [-35.31624985]
 [-36.68490982]
 [-35.42177963]], R is [[-36.28139877]
 [-35.91858673]
 [-35.55940247]
 [-35.34952545]
 [-35.15369034]].
[2017-11-02 09:55:09,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.80641580e-01   3.77088152e-02   3.39539424e-02   3.50895338e-02
   1.26062250e-02   4.15739758e-16   1.02985219e-17   3.06707355e-17
   7.03392041e-18], sum to 1.0000
[2017-11-02 09:55:09,257] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [0.4333333333333333, 95.66666666666666, 3.7, 273.3333333333334, 0.0, 0.0, 5.45, 12.79570995440225, 20.0, 21.68152120935058, 21.5, 0.0, 32.34597475328299], 
actual action is [5.433333333333334, 19.0], 
sim time next is 80700.0000, 
raw observation next is [0.4166666666666666, 95.58333333333333, 3.725, 274.1666666666666, 0.0, 0.0, 5.433333333333334, 12.60468652447269, 19.0, 21.84832039627514, 21.5, 0.0, 30.73864952118231], 
processed observation next is [1.0, 0.9565217391304348, 0.344017094017094, 0.9558333333333333, 0.3386363636363636, 0.7615740740740738, 0.0, 0.0, 0.5905555555555556, 0.1260468652447269, 0.14285714285714285, 0.5497600566107346, 0.5, 0.0, 0.36163117083743895], 
reward next is -0.3255. 
=============================================
[2017-11-02 09:55:15,178] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-55.65169907]
 [-52.78945923]
 [-52.78824234]
 [-55.04367447]
 [-53.87755203]], R is [[-55.34055328]
 [-55.78714752]
 [-56.22927475]
 [-56.66698074]
 [-57.10031128]].
[2017-11-02 09:55:24,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.92006123e-01   7.39569718e-04   8.57549370e-04
   6.39671134e-03], sum to 1.0000
[2017-11-02 09:55:24,721] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.199999999999999, 69.16666666666667, 6.449999999999999, 253.3333333333333, 0.0, 0.0, -2.149999999999999, 23.99965850929032, 19.0, 19.78991155129929, 21.5, 0.0, 33.09405688723532], 
actual action is [-2.1999999999999993, 19.5], 
sim time next is 111300.0000, 
raw observation next is [-7.25, 68.58333333333333, 6.274999999999999, 251.6666666666667, 0.0, 0.0, -2.199999999999999, 24.55769026019487, 19.5, 19.76658293066865, 21.5, 0.0, 31.40441052047416], 
processed observation next is [0.0, 0.2608695652173913, 0.14743589743589744, 0.6858333333333333, 0.5704545454545453, 0.6990740740740742, 0.0, 0.0, 0.4633333333333333, 0.2455769026019487, 0.21428571428571427, 0.2523689900955216, 0.5, 0.0, 0.36946365318204893], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:32,991] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.56813931
  0.0083206   0.00285245  0.42068765], sum to 1.0000
[2017-11-02 09:55:33,365] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.799999999999999, 69.66666666666666, 8.2, 253.3333333333333, 69.16666666666666, 5.999999999999998, -2.799999999999999, 18.13727853740484, 24.0, 21.27591257909248, 22.7, 1.0, 68.04341641467514], 
actual action is [-2.799999999999999, 24.5], 
sim time next is 121500.0000, 
raw observation next is [-7.8, 70.75, 8.075, 252.5, 81.25, 9.0, -2.799999999999999, 17.72520691622832, 24.5, 21.32114545224468, 22.7, 1.0, 68.15366088337741], 
processed observation next is [0.0, 0.391304347826087, 0.13333333333333333, 0.7075, 0.734090909090909, 0.7013888888888888, 0.21494708994708994, 0.009, 0.45333333333333337, 0.1772520691622832, 0.9285714285714286, 0.4744493503206684, 0.6714285714285714, 1.0, 0.8018077750985578], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:36,030] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-61.55015182]
 [-64.09460449]
 [-63.9481926 ]
 [-62.84288788]
 [-66.17499542]], R is [[-66.40373993]
 [-66.73970032]
 [-67.07230377]
 [-67.40158081]
 [-67.72756195]].
[2017-11-02 09:55:43,984] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.16178687e-02   3.28472927e-02   6.59352958e-01   2.61345685e-01
   1.48361912e-02   2.31065217e-27   6.10512006e-30   5.68469632e-30
   3.69762269e-29], sum to 1.0000
[2017-11-02 09:55:44,138] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.7, 63.75, 7.283333333333333, 260.8333333333333, 46.83333333333334, 27.5, -1.7, 18.53203464586498, 24.0, 21.33266042729337, 22.7, 1.0, 67.83752701970559], 
actual action is [-1.7000000000000002, 23.0], 
sim time next is 144000.0000, 
raw observation next is [-6.7, 64.0, 7.2, 260.0, 44.0, 24.0, -1.7, 17.81308768363918, 23.0, 21.53925160390362, 22.7, 1.0, 65.97998705364058], 
processed observation next is [0.0, 0.6956521739130435, 0.16153846153846155, 0.64, 0.6545454545454545, 0.7222222222222222, 0.1164021164021164, 0.024, 0.4716666666666667, 0.17813087683639178, 0.7142857142857143, 0.5056073719862313, 0.6714285714285714, 1.0, 0.7762351418075363], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:48,586] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7617: loss 41.8203
[2017-11-02 09:55:49,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   2.06830712e-37   1.57410435e-36   2.21415973e-36
   7.22992880e-38   5.74015081e-01   2.43693613e-03   2.33173626e-03
   4.21216279e-01], sum to 1.0000
[2017-11-02 09:55:49,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.149999999999999, 69.25, 7.2, 267.5, 20.25, 2.25, -2.1, 20.02347137473607, 24.5, 21.51662168454448, 22.7, 1.0, 69.84001405641477], 
actual action is [-2.1499999999999986, 25.0], 
sim time next is 147000.0000, 
raw observation next is [-7.199999999999999, 69.83333333333334, 7.199999999999999, 268.3333333333333, 18.0, 2.0, -2.149999999999999, 19.24499141300193, 25.0, 21.53989763869147, 22.7, 1.0, 70.30744181924908], 
processed observation next is [0.0, 0.6956521739130435, 0.14871794871794874, 0.6983333333333335, 0.6545454545454544, 0.7453703703703703, 0.047619047619047616, 0.002, 0.46416666666666667, 0.1924499141300193, 1.0, 0.5056996626702102, 0.6714285714285714, 1.0, 0.8271463743441068], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:50,671] A3C_AGENT_WORKER-Thread-8 INFO:Local step 500, global step 7762: loss 7.5547
[2017-11-02 09:55:50,893] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.73023772e-01   1.13049662e-03   7.66895711e-04
   2.50787847e-02], sum to 1.0000
[2017-11-02 09:55:51,001] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 7.2, 270.0, 0.0, 0.0, -2.25, 19.60864925557982, 23.5, 21.85754694678246, 22.7, 1.0, 51.10406294163386], 
actual action is [-2.3, 24.0], 
sim time next is 147900.0000, 
raw observation next is [-7.3, 70.16666666666666, 7.241666666666666, 270.0, 0.0, 0.0, -2.3, 18.88250195453481, 24.0, 21.76844691921568, 22.7, 1.0, 70.29431753237178], 
processed observation next is [0.0, 0.7391304347826086, 0.14615384615384616, 0.7016666666666665, 0.6583333333333333, 0.75, 0.0, 0.0, 0.46166666666666667, 0.1888250195453481, 0.8571428571428571, 0.5383495598879543, 0.6714285714285714, 1.0, 0.8269919709690797], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:51,549] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7832: loss -55.5274
[2017-11-02 09:55:52,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.71673846e-01   4.50621621e-04   3.61775368e-04
   2.75138393e-02], sum to 1.0000
[2017-11-02 09:55:52,136] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.149999999999999, 69.25, 7.2, 267.5, 20.25, 2.25, -2.1, 22.03188902529894, 21.5, 21.35424547289571, 22.7, 1.0, 50.45818429127437], 
actual action is [-2.1499999999999986, 22.0], 
sim time next is 147000.0000, 
raw observation next is [-7.199999999999999, 69.83333333333334, 7.199999999999999, 268.3333333333333, 18.0, 2.0, -2.149999999999999, 21.07625199830029, 22.0, 21.30040523720892, 22.7, 1.0, 67.51136465957978], 
processed observation next is [0.0, 0.6956521739130435, 0.14871794871794874, 0.6983333333333335, 0.6545454545454544, 0.7453703703703703, 0.047619047619047616, 0.002, 0.46416666666666667, 0.21076251998300288, 0.5714285714285714, 0.47148646245841724, 0.6714285714285714, 1.0, 0.7942513489362327], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:52,457] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7895: loss 72.4510
[2017-11-02 09:55:52,525] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7899: loss -90.4024
[2017-11-02 09:55:53,201] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 7945: loss -69.9089
[2017-11-02 09:55:53,788] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7987: loss -47.7961
[2017-11-02 09:55:54,133] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 8012: loss -11.4881
[2017-11-02 09:55:54,209] A3C_AGENT_WORKER-Thread-7 INFO:Local step 500, global step 8018: loss -49.0602
[2017-11-02 09:55:54,973] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8062: loss -161.6560
[2017-11-02 09:55:55,142] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8074: loss -3.0593
[2017-11-02 09:55:55,252] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8080: loss -185.9503
[2017-11-02 09:55:55,309] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-121.54837036]
 [-130.43457031]
 [-123.27184296]
 [-119.70581818]
 [-122.94532013]], R is [[-123.39573669]
 [-123.16178131]
 [-122.93016815]
 [-122.7008667 ]
 [-122.47386169]].
[2017-11-02 09:55:55,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8096: loss 24.3210
[2017-11-02 09:55:55,947] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8119: loss 239.1296
[2017-11-02 09:55:57,135] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8187: loss 52.4126
[2017-11-02 09:55:57,313] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8200: loss 23.9263
[2017-11-02 09:56:00,871] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.84426141e-01   6.18549762e-04   1.31523702e-03
   1.36399930e-02], sum to 1.0000
[2017-11-02 09:56:00,923] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 68.0, 5.016666666666667, 260.8333333333333, 0.0, 0.0, -3.4, 21.43653246392159, 22.0, 21.36711168510679, 21.5, 0.0, 52.89862220144429], 
actual action is [-3.4000000000000004, 22.5], 
sim time next is 162000.0000, 
raw observation next is [-8.4, 68.0, 5.1, 260.0, 0.0, 0.0, -3.4, 21.06027405083808, 22.5, 21.41007058279397, 21.5, 0.0, 42.03157657857578], 
processed observation next is [0.0, 0.9130434782608695, 0.11794871794871795, 0.68, 0.4636363636363636, 0.7222222222222222, 0.0, 0.0, 0.44333333333333336, 0.2106027405083808, 0.6428571428571429, 0.48715294039913865, 0.5, 0.0, 0.49448913621853857], 
reward next is -0.4579. 
=============================================
[2017-11-02 09:56:03,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-80.9090271 ]
 [-78.64864349]
 [-83.60351562]
 [-78.73403931]
 [-79.67655182]], R is [[-85.17233276]
 [-84.81245422]
 [-84.96433258]
 [-85.11469269]
 [-85.2635498 ]].
[2017-11-02 09:56:08,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   7.62808487e-19   1.66572017e-18   4.82803403e-19
   1.79433091e-19   9.90649760e-01   1.59261550e-03   1.25173794e-03
   6.50600949e-03], sum to 1.0000
[2017-11-02 09:56:08,385] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.816666666666666, 73.5, 4.016666666666667, 230.0, 0.0, 0.0, -3.775, 18.34310652978485, 25.0, 21.32591182796611, 21.5, 0.0, 46.45976553551743], 
actual action is [-3.8166666666666664, 25], 
sim time next is 176100.0000, 
raw observation next is [-8.858333333333334, 73.75, 4.058333333333333, 230.0, 0.0, 0.0, -3.816666666666666, 18.41896236339376, 25.0, 21.30435387980088, 21.5, 0.0, 46.50797430216021], 
processed observation next is [0.16666666666666666, 0.0, 0.10619658119658117, 0.7375, 0.3689393939393939, 0.6388888888888888, 0.0, 0.0, 0.4363888888888889, 0.1841896236339376, 1.0, 0.47205055425726833, 0.5, 0.0, 0.5471526388489436], 
reward next is -0.5204. 
=============================================
[2017-11-02 09:56:10,617] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.94837701e-01   1.26102555e-03   5.92077849e-04
   3.30920517e-03], sum to 1.0000
[2017-11-02 09:56:10,797] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 4.1, 230.0, 0.0, 0.0, -3.858333333333334, 16.21058711166711, 25.0, 21.59078785026939, 21.5, 0.0, 46.39070378495582], 
actual action is [-3.9000000000000004, 25], 
sim time next is 176700.0000, 
raw observation next is [-8.9, 74.0, 4.008333333333333, 227.5, 0.0, 0.0, -3.9, 16.28945881679537, 25.0, 21.56662943538568, 21.5, 0.0, 46.41965808552626], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.10512820512820512, 0.74, 0.3643939393939393, 0.6319444444444444, 0.0, 0.0, 0.435, 0.1628945881679537, 1.0, 0.5095184907693826, 0.5, 0.0, 0.5461136245356031], 
reward next is -0.4915. 
=============================================
[2017-11-02 09:56:44,648] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.57481900e-03   8.53935373e-04   9.13824333e-05
   9.94479895e-01], sum to 1.0000
[2017-11-02 09:56:44,970] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.95, 59.75, 7.300000000000001, 230.0, 71.25, 0.0, 2.1, 11.24747529655541, 25.0, 23.53774025798595, 22.7, 1.0, 62.73678326366598], 
actual action is [2.05, 25], 
sim time next is 228000.0000, 
raw observation next is [-3.0, 60.0, 7.166666666666667, 230.0, 66.16666666666667, 0.0, 2.05, 11.20292280138263, 25.0, 23.55240867210624, 22.7, 1.0, 62.7029316741099], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2564102564102564, 0.6, 0.6515151515151515, 0.6388888888888888, 0.17504409171075838, 0.0, 0.5341666666666666, 0.11202922801382631, 1.0, 0.7932012388723199, 0.6714285714285714, 1.0, 0.7376815491071753], 
reward next is -0.6751. 
=============================================
[2017-11-02 09:56:46,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.07644992e-02   4.55797603e-03   7.29098800e-04
   9.83948410e-01], sum to 1.0000
[2017-11-02 09:56:47,032] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 65.0, 7.2, 210.0, 139.0, 0.0, 0.458333333333333, 11.896910324727, 25.0, 23.08735792542682, 22.7, 1.0, 63.3780748310615], 
actual action is [0.5, 25], 
sim time next is 219900.0000, 
raw observation next is [-4.408333333333333, 64.75, 7.149999999999999, 210.0, 140.6666666666667, 0.0, 0.5, 11.78241016225976, 25.0, 23.1255053233452, 22.7, 1.0, 63.16026895851718], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.2202991452991453, 0.6475, 0.6499999999999999, 0.5833333333333334, 0.3721340388007056, 0.0, 0.5083333333333333, 0.1178241016225976, 1.0, 0.7322150461921717, 0.6714285714285714, 1.0, 0.743061987747261], 
reward next is -0.6805. 
=============================================
[2017-11-02 09:56:52,173] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.99806357e-03   1.95970852e-03   6.95885028e-05
   9.94972587e-01], sum to 1.0000
[2017-11-02 09:56:52,520] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.15, 60.75, 6.766666666666667, 230.0, 52.83333333333333, 0.0, 1.9, 10.77465903589847, 25.0, 23.65292776184384, 22.7, 1.0, 62.43078681966943], 
actual action is [1.85, 25], 
sim time next is 229200.0000, 
raw observation next is [-3.2, 61.0, 6.633333333333333, 230.0, 49.66666666666667, 0.0, 1.85, 10.74176285423623, 25.0, 23.66174431175651, 22.7, 1.0, 62.36518566455568], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2512820512820513, 0.61, 0.603030303030303, 0.6388888888888888, 0.13139329805996475, 0.0, 0.5308333333333334, 0.1074176285423623, 1.0, 0.8088206159652158, 0.6714285714285714, 1.0, 0.7337080666418315], 
reward next is -0.6711. 
=============================================
[2017-11-02 09:56:55,471] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.17329781e-29   7.03045174e-28   1.38315790e-29
   3.78549994e-30   4.46707942e-02   4.79393937e-02   2.50849058e-03
   9.04881299e-01], sum to 1.0000
[2017-11-02 09:56:55,729] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 65.0, 6.016666666666666, 220.0, 0.0, 0.0, 1.6, 10.99094278695215, 25.0, 23.69561900054259, 22.7, 1.0, 41.44922420531673], 
actual action is [1.6, 25], 
sim time next is 240000.0000, 
raw observation next is [-3.4, 65.0, 5.933333333333334, 220.0, 0.0, 0.0, 1.6, 11.08114505057453, 25.0, 23.63016904617339, 22.7, 1.0, 53.55674539802196], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.24615384615384614, 0.65, 0.5393939393939394, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.11081145050574531, 1.0, 0.8043098637390556, 0.6714285714285714, 1.0, 0.6300793576237878], 
reward next is -0.5782. 
=============================================
[2017-11-02 09:57:09,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.21126324e-01   2.02095266e-02   8.34622264e-01   1.89249329e-02
   5.11694606e-03   3.71713183e-23   2.06020066e-23   2.50732852e-24
   8.57248361e-24], sum to 1.0000
[2017-11-02 09:57:09,616] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.399999999999999, 79.5, 6.283333333333333, 273.3333333333333, 0.0, 0.0, 0.6500000000000004, 24.05375877989568, 24.5, 20.60295631212622, 21.5, 0.0, 24.34077930717801], 
actual action is [0.6000000000000014, 23.5], 
sim time next is 258900.0000, 
raw observation next is [-4.45, 79.25, 6.191666666666666, 276.6666666666666, 0.0, 0.0, 0.6000000000000014, 23.30445261208829, 23.5, 20.60529102955788, 21.5, 0.0, 41.5286593499639], 
processed observation next is [0.16666666666666666, 1.0, 0.21923076923076926, 0.7925, 0.5628787878787879, 0.7685185185185183, 0.0, 0.0, 0.51, 0.23304452612088292, 0.7857142857142857, 0.3721844327939827, 0.5, 0.0, 0.4885724629407518], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:12,445] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.47967602e-03   3.69433919e-03   9.90764141e-01   9.65668994e-04
   9.61819314e-05   1.91396964e-31   4.73236775e-32   1.95107068e-32
   1.46016511e-31], sum to 1.0000
[2017-11-02 09:57:12,507] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.4, 69.5, 7.35, 296.6666666666666, 0.0, 0.0, -4.35, 25.75470244006913, 19.5, 19.86709631233584, 21.5, 0.0, 31.53038367650501], 
actual action is [-4.4, 18.5], 
sim time next is 273300.0000, 
raw observation next is [-9.45, 69.75, 7.525, 298.3333333333334, 0.0, 0.0, -4.4, 26.32262700316983, 18.5, 19.84039112634895, 21.5, 0.0, 29.84477599931757], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.09102564102564105, 0.6975, 0.6840909090909091, 0.8287037037037039, 0.0, 0.0, 0.4266666666666667, 0.2632262700316983, 0.07142857142857142, 0.2629130180498502, 0.5, 0.0, 0.3511150117566773], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:13,943] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   2.88618381e-21   2.62282677e-18   2.58337149e-21
   1.48936219e-22   8.33488554e-02   3.20574455e-02   1.28390389e-02
   8.71754646e-01], sum to 1.0000
[2017-11-02 09:57:14,053] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.633333333333333, 67.66666666666667, 5.683333333333334, 280.0, 0.0, 0.0, -13.5, 30.32990679467698, 18.0, 19.90610474305253, 21.5, 0.0, 0.0], 
actual action is [-3.633333333333333, 23.0], 
sim time next is 269700.0000, 
raw observation next is [-8.766666666666667, 67.33333333333333, 5.641666666666667, 280.0, 0.0, 0.0, -3.633333333333333, 28.72606967578081, 23.0, 19.74577880736191, 21.5, 0.0, 62.31076838504559], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.10854700854700852, 0.6733333333333333, 0.5128787878787878, 0.7777777777777778, 0.0, 0.0, 0.43944444444444447, 0.2872606967578081, 0.7142857142857143, 0.24939697248027265, 0.5, 0.0, 0.7330678633534775], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:15,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.13711685e-19   4.42354009e-03   9.93694723e-01   1.19348988e-03
   6.67388304e-05   8.76088088e-05   2.58245091e-05   2.88956107e-05
   4.79103794e-04], sum to 1.0000
[2017-11-02 09:57:15,252] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.1, 68.0, 5.766666666666667, 263.3333333333334, 0.0, 0.0, -7.050000000000001, 24.26687782432506, 25.0, 19.80996137578873, 21.5, 0.0, 48.91138745468631], 
actual action is [-7.1, 24.0], 
sim time next is 283500.0000, 
raw observation next is [-12.15, 67.75, 5.85, 265.0, 0.0, 0.0, -7.1, 24.34392587172935, 24.0, 19.80373810963576, 21.5, 0.0, 48.95236756454701], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.021794871794871787, 0.6775, 0.5318181818181817, 0.7361111111111112, 0.0, 0.0, 0.38166666666666665, 0.2434392587172935, 0.8571428571428571, 0.2576768728051085, 0.5, 0.0, 0.5759102066417295], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:15,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.34583598e-02   3.59416381e-03   9.72407758e-01   5.07030170e-04
   3.25759866e-05   5.49479441e-37   3.60193681e-38   9.23668629e-38
   4.14870127e-37], sum to 1.0000
[2017-11-02 09:57:15,572] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.866666666666667, 69.0, 7.533333333333333, 286.6666666666667, 0.0, 0.0, -14.775, 28.36350968365624, 18.0, 20.10882699305799, 21.5, 0.0, 0.0], 
actual action is [-14.866666666666667, 18], 
sim time next is 275100.0000, 
raw observation next is [-9.958333333333332, 68.75, 7.491666666666666, 283.3333333333333, 0.0, 0.0, -14.86666666666667, 31.71519340502054, 18.0, 19.93981644647124, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.07799145299145302, 0.6875, 0.681060606060606, 0.787037037037037, 0.0, 0.0, 0.2522222222222222, 0.31715193405020536, 0.0, 0.27711663521017726, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:20,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.04447377e-02   4.20909375e-02   9.34766114e-01   2.63005635e-03
   6.81481761e-05   2.00209812e-36   4.52712226e-37   9.55179919e-37
   8.45852416e-36], sum to 1.0000
[2017-11-02 09:57:20,248] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-10.05, 68.5, 7.45, 280.0, 0.0, 0.0, -4.958333333333332, 23.71504064452576, 24.0, 20.26177296962214, 21.5, 0.0, 44.92656476351554], 
actual action is [-5.050000000000001, 23.0], 
sim time next is 275700.0000, 
raw observation next is [-10.14166666666667, 68.25, 7.408333333333333, 276.6666666666667, 0.0, 0.0, -5.050000000000001, 23.62788745796977, 23.0, 20.22509985954559, 21.5, 0.0, 50.43287054990827], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.07329059829059822, 0.6825, 0.6734848484848485, 0.7685185185185186, 0.0, 0.0, 0.41583333333333333, 0.2362788745796977, 0.7142857142857143, 0.3178714085065129, 0.5, 0.0, 0.5933278888224502], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:22,850] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-109.69056702]
 [-110.77324677]
 [-108.6726532 ]
 [-109.79374695]
 [-108.29410553]], R is [[-102.25848389]
 [-102.23590088]
 [-102.21353912]
 [-102.19140625]
 [-102.16949463]].
[2017-11-02 09:57:29,677] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.91922225e-10   6.20390959e-02   8.99608016e-01   3.69255915e-02
   1.42731087e-03   1.06001050e-13   1.44529029e-14   1.05192539e-14
   4.45262283e-14], sum to 1.0000
[2017-11-02 09:57:29,971] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.1, 65.66666666666667, 5.6, 246.6666666666667, 84.16666666666667, 383.5, -7.15, 18.41164577203844, 25.0, 21.41627216644314, 22.7, 1.0, 55.69411012250985], 
actual action is [-7.1, 24.0], 
sim time next is 293100.0000, 
raw observation next is [-12.05, 65.33333333333333, 5.6, 248.3333333333333, 89.58333333333333, 383.25, -7.1, 18.13924500238657, 24.0, 21.41258837402069, 22.7, 1.0, 64.65532818917816], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.024358974358974342, 0.6533333333333333, 0.509090909090909, 0.6898148148148147, 0.23699294532627865, 0.38325, 0.38166666666666665, 0.1813924500238657, 0.8571428571428571, 0.4875126248600985, 0.6714285714285714, 1.0, 0.7606509198726843], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:31,257] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15636: loss -65.8423
[2017-11-02 09:57:35,201] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1000, global step 15840: loss 49.1587
[2017-11-02 09:57:35,333] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15847: loss -381.0505
[2017-11-02 09:57:36,506] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15906: loss -40.2543
[2017-11-02 09:57:36,512] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15906: loss -133.7090
[2017-11-02 09:57:36,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15917: loss -20.5012
[2017-11-02 09:57:37,097] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 15938: loss -0.6747
[2017-11-02 09:57:37,173] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15943: loss -110.4725
[2017-11-02 09:57:38,500] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16034: loss -10.8479
[2017-11-02 09:57:38,925] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16062: loss 117.6686
[2017-11-02 09:57:39,082] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16069: loss -30.6229
[2017-11-02 09:57:39,542] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1000, global step 16101: loss -44.3895
[2017-11-02 09:57:39,873] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 16122: loss -42.3942
[2017-11-02 09:57:39,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16128: loss 10.2137
[2017-11-02 09:57:39,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  7.34712677e-20   7.02310801e-02   8.86636853e-01   4.27901335e-02
   3.25969711e-04   1.41397104e-05   1.15532572e-07   2.51132491e-07
   1.50448045e-06], sum to 1.0000
[2017-11-02 09:57:40,107] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-10.6, 56.33333333333334, 7.533333333333333, 263.3333333333334, 102.8333333333333, 633.6666666666667, -5.6, 16.41655889360368, 21.0, 22.19633746297017, 22.7, 1.0, 36.70958598424681], 
actual action is [-5.6, 20.0], 
sim time next is 300300.0000, 
raw observation next is [-10.6, 55.41666666666666, 7.616666666666665, 264.1666666666666, 104.4166666666667, 645.8333333333333, -5.6, 17.08478759673563, 20.0, 22.11729436439696, 22.7, 1.0, 34.23407703469626], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.06153846153846155, 0.5541666666666666, 0.6924242424242423, 0.7337962962962961, 0.27623456790123463, 0.6458333333333333, 0.4066666666666666, 0.1708478759673563, 0.2857142857142857, 0.588184909199566, 0.6714285714285714, 1.0, 0.40275384746701487], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:40,193] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16145: loss 16.6818
[2017-11-02 09:57:42,797] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16302: loss 236.9585
[2017-11-02 09:58:09,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.98212099e-01   5.32047998e-04   2.47788033e-04
   1.00817182e-03], sum to 1.0000
[2017-11-02 09:58:09,558] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-14.2, 67.5, 5.1, 265.0, 0.0, 0.0, -9.15, 28.13596833705003, 25.0, 20.07694671047135, 21.5, 0.0, 49.13839548566223], 
actual action is [-9.2, 25], 
sim time next is 347700.0000, 
raw observation next is [-14.25, 67.75, 5.1, 264.1666666666667, 0.0, 0.0, -9.2, 28.20927212372225, 25.0, 20.06500192556497, 21.5, 0.0, 49.09290888830639], 
processed observation next is [0.5, 0.0, -0.03205128205128205, 0.6775, 0.4636363636363636, 0.7337962962962964, 0.0, 0.0, 0.3466666666666667, 0.2820927212372225, 1.0, 0.29500027508071014, 0.5, 0.0, 0.5775636339800752], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:10,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-131.74899292]
 [-122.6782608 ]
 [-134.2338562 ]
 [-131.30363464]
 [-131.78701782]], R is [[-135.53079224]
 [-135.17549133]
 [-134.82373047]
 [-134.47549438]
 [-134.1307373 ]].
[2017-11-02 09:58:14,409] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99465644e-01   1.39494194e-04   1.82619515e-05
   3.76601267e-04], sum to 1.0000
[2017-11-02 09:58:14,518] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 69.0, 7.066666666666666, 260.0, 0.0, 0.0, -10.0, 43.37911741974797, 20.0, 18.5325238789464, 21.5, 0.0, 31.932774142297], 
actual action is [-10.0, 20.5], 
sim time next is 353400.0000, 
raw observation next is [-15.0, 69.0, 6.933333333333334, 260.0, 0.0, 0.0, -10.0, 43.34307038955045, 20.5, 18.47077353709398, 21.5, 0.0, 45.33605083980123], 
processed observation next is [0.5, 0.08695652173913043, -0.05128205128205128, 0.69, 0.6303030303030304, 0.7222222222222222, 0.0, 0.0, 0.3333333333333333, 0.4334307038955045, 0.35714285714285715, 0.06725336244199706, 0.5, 0.0, 0.5333653039976616], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:15,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99119461e-01   3.09979019e-04   6.70622176e-05
   5.03452786e-04], sum to 1.0000
[2017-11-02 09:58:15,743] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-14.875, 69.0, 6.675000000000001, 260.0, 0.0, 0.0, -9.83333333333333, 39.79987060649081, 20.0, 18.84309693348132, 21.5, 0.0, 37.54207628591882], 
actual action is [-9.875, 20.5], 
sim time next is 352200.0000, 
raw observation next is [-14.91666666666667, 69.0, 6.85, 260.0, 0.0, 0.0, -9.875, 39.94362113024903, 20.5, 18.83255837364007, 21.5, 0.0, 45.7969226643612], 
processed observation next is [0.5, 0.043478260869565216, -0.04914529914529922, 0.69, 0.6227272727272727, 0.7222222222222222, 0.0, 0.0, 0.33541666666666664, 0.3994362113024903, 0.35714285714285715, 0.11893691052000983, 0.5, 0.0, 0.538787325463073], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:16,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99623537e-01   1.23017468e-04   9.55465657e-06
   2.43874223e-04], sum to 1.0000
[2017-11-02 09:58:16,781] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 69.0, 6.933333333333334, 260.0, 0.0, 0.0, -10.0, 45.53278554534108, 18.5, 18.45053782809955, 21.5, 0.0, 51.4117909167413], 
actual action is [-10.0, 19.0], 
sim time next is 353700.0000, 
raw observation next is [-15.0, 69.0, 6.800000000000001, 260.0, 0.0, 0.0, -10.0, 45.95286298766304, 19.0, 18.35992228876924, 21.5, 0.0, 34.43069690291265], 
processed observation next is [0.5, 0.08695652173913043, -0.05128205128205128, 0.69, 0.6181818181818183, 0.7222222222222222, 0.0, 0.0, 0.3333333333333333, 0.4595286298766304, 0.14285714285714285, 0.05141746982417723, 0.5, 0.0, 0.40506702238720765], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:33,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.98913050e-01   5.81582950e-04   1.00737561e-04
   4.04624967e-04], sum to 1.0000
[2017-11-02 09:58:33,836] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.23333333333333, 82.0, 4.933333333333334, 233.3333333333334, 36.66666666666666, 694.5, -10.325, 35.41660044681006, 24.0, 19.68217701791811, 22.7, 1.0, 65.23320935744913], 
actual action is [-10.23333333333333, 24.5], 
sim time next is 379500.0000, 
raw observation next is [-15.14166666666667, 80.0, 4.766666666666666, 231.6666666666666, 37.83333333333334, 716.25, -10.23333333333333, 34.80053209969825, 24.5, 19.76730521808962, 22.7, 1.0, 64.97272665197228], 
processed observation next is [0.5, 0.391304347826087, -0.05491452991452998, 0.8, 0.43333333333333324, 0.6435185185185184, 0.10008818342151678, 0.71625, 0.3294444444444445, 0.3480053209969825, 0.9285714285714286, 0.25247217401280303, 0.6714285714285714, 1.0, 0.764385019434968], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:40,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-102.29763794]
 [-105.13561249]
 [-107.51331329]
 [-104.50480652]
 [-105.64883423]], R is [[-105.07196045]
 [-105.02124023]
 [-104.97103119]
 [-104.92132568]
 [-104.87211609]].
[2017-11-02 09:58:55,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0240059
  0.91589469  0.05622571  0.00387367], sum to 1.0000
[2017-11-02 09:58:56,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-9.625, 40.5, 5.475, 212.5, 0.0, 0.0, -4.583333333333334, 26.05475672187945, 25.0, 21.38451776711636, 22.7, 1.0, 65.02583447516237], 
actual action is [-4.625, 25], 
sim time next is 415200.0000, 
raw observation next is [-9.666666666666668, 40.66666666666667, 5.433333333333334, 210.0, 0.0, 0.0, -4.625, 26.00776134164615, 25.0, 21.39472164557236, 22.7, 1.0, 65.00028069393557], 
processed observation next is [0.5, 0.8260869565217391, 0.08547008547008544, 0.40666666666666673, 0.49393939393939396, 0.5833333333333334, 0.0, 0.0, 0.42291666666666666, 0.2600776134164615, 1.0, 0.4849602350817658, 0.6714285714285714, 1.0, 0.7647091846345361], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:59:06,783] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00524496
  0.94239974  0.0415023   0.01085299], sum to 1.0000
[2017-11-02 09:59:06,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00569485
  0.9508543   0.03590921  0.00754169], sum to 1.0000
[2017-11-02 09:59:06,934] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-11.7, 54.0, 4.058333333333333, 190.0, 0.0, 0.0, -6.699999999999999, 27.20294717290648, 25.0, 20.61745311865855, 21.5, 0.0, 47.70530206294728], 
actual action is [-6.699999999999999, 25], 
sim time next is 432000.0000, 
raw observation next is [-11.7, 54.0, 4.1, 190.0, 0.0, 0.0, -6.699999999999999, 27.31377944982188, 25.0, 20.59139987980152, 21.5, 0.0, 47.75611198001137], 
processed observation next is [0.6666666666666666, 0.0, 0.033333333333333354, 0.54, 0.3727272727272727, 0.5277777777777778, 0.0, 0.0, 0.38833333333333336, 0.2731377944982188, 1.0, 0.3701999828287888, 0.5, 0.0, 0.5618366115295456], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:59:06,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-10.875, 50.25, 3.15, 197.5, 0.0, 0.0, -5.78333333333333, 23.66117932810939, 25.0, 21.31785376243794, 21.5, 0.0, 46.34235978532839], 
actual action is [-5.875, 25], 
sim time next is 426000.0000, 
raw observation next is [-10.96666666666667, 50.66666666666667, 3.2, 196.6666666666667, 0.0, 0.0, -5.875, 23.7546139506962, 25.0, 21.29324538808721, 21.5, 0.0, 46.40537170222341], 
processed observation next is [0.5, 0.9565217391304348, 0.05213675213675204, 0.5066666666666667, 0.29090909090909095, 0.5462962962962964, 0.0, 0.0, 0.40208333333333335, 0.237546139506962, 1.0, 0.4704636268696016, 0.5, 0.0, 0.5459455494379225], 
reward next is -0.5209. 
=============================================
[2017-11-02 09:59:14,619] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23284: loss 1.8325
[2017-11-02 09:59:15,486] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23379: loss 1.7083
[2017-11-02 09:59:15,827] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 23417: loss -25.1104
[2017-11-02 09:59:16,621] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23505: loss 1.5728
[2017-11-02 09:59:16,845] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1500, global step 23531: loss 1.0905
[2017-11-02 09:59:18,738] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23737: loss -37.1460
[2017-11-02 09:59:19,965] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23859: loss 3.3842
[2017-11-02 09:59:20,050] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-110.92807007]
 [-110.32891083]
 [-109.79460144]
 [-108.89787292]
 [-108.1441803 ]], R is [[-107.69704437]
 [-107.62007141]
 [-107.54386902]
 [-107.46842957]
 [-107.39374542]].
[2017-11-02 09:59:20,142] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23877: loss -1.1617
[2017-11-02 09:59:20,780] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23932: loss -99.3314
[2017-11-02 09:59:22,307] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24058: loss 4.0297
[2017-11-02 09:59:24,194] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24208: loss 1.2998
[2017-11-02 09:59:25,130] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24268: loss 7.0242
[2017-11-02 09:59:25,686] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1500, global step 24312: loss 10.0365
[2017-11-02 09:59:27,654] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24442: loss -3.0027
[2017-11-02 09:59:27,958] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24462: loss 153.2652
[2017-11-02 09:59:28,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24510: loss -45.3117
[2017-11-02 09:59:51,663] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00211412
  0.1146967   0.65170753  0.23148167], sum to 1.0000
[2017-11-02 09:59:51,865] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.2, 36.33333333333333, 4.1, 166.6666666666667, 87.66666666666667, 0.0, 4.75, 12.17941325310314, 25.0, 23.55931375241461, 22.7, 1.0, 60.22968929113744], 
actual action is [4.8, 25], 
sim time next is 485100.0000, 
raw observation next is [-0.15, 36.5, 4.1, 167.5, 84.5, 0.0, 4.8, 12.04678626591764, 25.0, 23.5917134714399, 22.7, 1.0, 60.05330579106197], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3294871794871795, 0.365, 0.3727272727272727, 0.4652777777777778, 0.22354497354497355, 0.0, 0.58, 0.1204678626591764, 1.0, 0.7988162102056998, 0.6714285714285714, 1.0, 0.7065094798948467], 
reward next is -0.6479. 
=============================================
[2017-11-02 10:00:01,983] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00256096
  0.06330116  0.92195141  0.0121864 ], sum to 1.0000
[2017-11-02 10:00:02,171] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.1, 96.0, 5.516666666666666, 138.3333333333333, 0.0, 0.0, 6.1, 10.35915192286125, 25.0, 23.9288250768365, 22.7, 1.0, 54.02623182420434], 
actual action is [6.1, 25], 
sim time next is 501000.0000, 
raw observation next is [1.1, 96.0, 5.433333333333334, 136.6666666666667, 0.0, 0.0, 6.1, 10.18275616908339, 25.0, 23.89496601344801, 22.7, 1.0, 63.23784236828355], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.96, 0.49393939393939396, 0.37962962962962976, 0.0, 0.0, 0.6016666666666667, 0.1018275616908339, 1.0, 0.8421380019211442, 0.6714285714285714, 1.0, 0.7439746160974535], 
reward next is -0.6798. 
=============================================
[2017-11-02 10:00:06,104] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01137498
  0.0400922   0.93950814  0.00902475], sum to 1.0000
[2017-11-02 10:00:06,293] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.1, 42.25, 6.016666666666666, 168.3333333333333, 11.66666666666667, 0.0, 6.1, 9.881416800901645, 25.0, 24.01752946232771, 22.7, 1.0, 60.1591838132925], 
actual action is [6.1, 25], 
sim time next is 493200.0000, 
raw observation next is [1.1, 43.0, 6.1, 170.0, 10.0, 0.0, 6.1, 9.92261027351146, 25.0, 24.04228046948427, 22.7, 1.0, 52.45399403044022], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.36153846153846153, 0.43, 0.5545454545454546, 0.4722222222222222, 0.026455026455026454, 0.0, 0.6016666666666667, 0.09922610273511459, 1.0, 0.8631829242120383, 0.6714285714285714, 1.0, 0.6171058121228261], 
reward next is -0.5653. 
=============================================
[2017-11-02 10:00:06,476] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-50.64907455]
 [-50.7475853 ]
 [-50.24901962]
 [-50.31851578]
 [-50.0163002 ]], R is [[-49.8299942 ]
 [-49.6546669 ]
 [-49.49523926]
 [-49.3515358 ]
 [-49.26465607]].
[2017-11-02 10:00:11,603] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0145164
  0.07528454  0.89067352  0.0195256 ], sum to 1.0000
[2017-11-02 10:00:11,794] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.9, 93.33333333333334, 5.1, 176.6666666666667, 0.0, 0.0, 7.850000000000001, 7.900872186855868, 25.0, 24.01800015414725, 21.5, 0.0, 44.41556937278173], 
actual action is [7.9, 25], 
sim time next is 512700.0000, 
raw observation next is [2.95, 93.66666666666666, 4.975, 175.8333333333333, 0.0, 0.0, 7.9, 7.829129362103664, 25.0, 24.06190264212612, 21.5, 0.0, 38.77294635666093], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.40897435897435896, 0.9366666666666665, 0.4522727272727272, 0.4884259259259258, 0.0, 0.0, 0.6316666666666666, 0.07829129362103665, 1.0, 0.865986091732303, 0.5, 0.0, 0.4561523100783639], 
reward next is -0.4105. 
=============================================
[2017-11-02 10:00:13,217] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01476518
  0.11928371  0.85214126  0.01380978], sum to 1.0000
[2017-11-02 10:00:13,325] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [3.466666666666667, 96.33333333333333, 4.433333333333334, 183.3333333333333, 0.0, 0.0, 8.425, 7.509404885953999, 25.0, 23.96627784594652, 21.5, 0.0, 44.26646785601054], 
actual action is [8.466666666666667, 25], 
sim time next is 516300.0000, 
raw observation next is [3.508333333333333, 96.41666666666666, 4.516666666666666, 186.6666666666667, 0.0, 0.0, 8.466666666666667, 7.373695139175005, 25.0, 24.01306129775191, 21.5, 0.0, 43.83134389221292], 
processed observation next is [0.6666666666666666, 1.0, 0.4232905982905983, 0.9641666666666666, 0.41060606060606053, 0.5185185185185186, 0.0, 0.0, 0.6411111111111112, 0.07373695139175006, 1.0, 0.8590087568217015, 0.5, 0.0, 0.515662869320152], 
reward next is -0.4641. 
=============================================
[2017-11-02 10:00:22,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-50.15872955]
 [-50.12380981]
 [-49.87891006]
 [-49.29667664]
 [-49.40091705]], R is [[-48.81895065]
 [-48.80189133]
 [-48.78826141]
 [-48.77630997]
 [-48.76715469]].
[2017-11-02 10:00:35,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01109801
  0.42938077  0.5063976   0.05312366], sum to 1.0000
[2017-11-02 10:00:35,229] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.35, 88.66666666666666, 6.6, 321.6666666666666, 138.4166666666667, 106.1666666666667, 4.7, 6.023303407299764, 25.0, 24.12746517775342, 22.7, 1.0, 46.04059243007238], 
actual action is [4.65, 25], 
sim time next is 553200.0000, 
raw observation next is [-0.4, 88.33333333333334, 6.6, 323.3333333333334, 132.8333333333333, 109.3333333333333, 4.65, 6.03496336321266, 25.0, 24.10344849264473, 22.7, 1.0, 46.62242125217819], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.3230769230769231, 0.8833333333333334, 0.6, 0.8981481481481484, 0.35141093474426793, 0.1093333333333333, 0.5775, 0.0603496336321266, 1.0, 0.8719212132349615, 0.6714285714285714, 1.0, 0.5484990735550376], 
reward next is -0.4997. 
=============================================
[2017-11-02 10:00:46,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   1.62794187e-35   1.31979248e-34   1.61788803e-35
   6.93216727e-36   2.20905840e-02   6.46251738e-01   2.91021913e-01
   4.06357683e-02], sum to 1.0000
[2017-11-02 10:00:46,401] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.8, 87.0, 5.1, 270.0, 0.0, 0.0, 2.2, 6.958020848060922, 25.0, 23.85330746687717, 21.5, 0.0, 48.35300052402713], 
actual action is [2.2, 25], 
sim time next is 590700.0000, 
raw observation next is [-2.8, 86.66666666666667, 5.183333333333334, 270.8333333333333, 0.0, 0.0, 2.2, 6.87463110415635, 25.0, 23.85947362063053, 21.5, 0.0, 48.15500873840708], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.2615384615384615, 0.8666666666666667, 0.47121212121212125, 0.7523148148148148, 0.0, 0.0, 0.5366666666666667, 0.06874631104156351, 1.0, 0.8370676600900759, 0.5, 0.0, 0.5665295145694951], 
reward next is -0.5099. 
=============================================
[2017-11-02 10:00:48,496] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.06090599
  0.59886557  0.29363269  0.04659575], sum to 1.0000
[2017-11-02 10:00:48,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 83.0, 6.1, 296.6666666666667, 109.0, 204.3333333333333, 3.8, 6.955554369694564, 25.0, 24.25742727566611, 22.7, 1.0, 46.04320317780256], 
actual action is [3.8, 25], 
sim time next is 573300.0000, 
raw observation next is [-1.2, 83.0, 6.1, 295.0, 106.75, 171.5, 3.8, 6.953212965335538, 25.0, 24.36353203653827, 22.7, 1.0, 45.80988553262279], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.3025641025641026, 0.83, 0.5545454545454546, 0.8194444444444444, 0.2824074074074074, 0.1715, 0.5633333333333332, 0.06953212965335538, 1.0, 0.909076005219753, 0.6714285714285714, 1.0, 0.5389398297955623], 
reward next is -0.4920. 
=============================================
[2017-11-02 10:00:49,826] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2000, global step 31262: loss -0.0064
[2017-11-02 10:00:51,019] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31403: loss 0.6795
[2017-11-02 10:00:51,667] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 31473: loss -0.0913
[2017-11-02 10:00:52,938] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31628: loss 0.0113
[2017-11-02 10:00:53,125] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31647: loss 1.6226
[2017-11-02 10:00:53,816] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31718: loss 0.4277
[2017-11-02 10:00:54,891] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31839: loss 0.0057
[2017-11-02 10:00:55,133] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 31863: loss 0.6345
[2017-11-02 10:00:57,498] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32130: loss -3.2133
[2017-11-02 10:00:57,698] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32150: loss -1.0772
[2017-11-02 10:00:58,993] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32292: loss -4.3975
[2017-11-02 10:00:59,240] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32323: loss 0.5708
[2017-11-02 10:00:59,976] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2000, global step 32403: loss 0.0288
[2017-11-02 10:01:00,936] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32509: loss 0.6665
[2017-11-02 10:01:01,769] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32598: loss 0.0947
[2017-11-02 10:01:02,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32696: loss 0.1628
[2017-11-02 10:01:03,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02759528
  0.67926675  0.26151329  0.03162463], sum to 1.0000
[2017-11-02 10:01:03,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.5, 68.58333333333333, 5.4, 251.6666666666667, 0.0, 0.0, 0.5, 6.878021342716201, 25.0, 22.66967045899647, 21.5, 0.0, 46.01132673326361], 
actual action is [0.5, 25], 
sim time next is 622800.0000, 
raw observation next is [-4.5, 68.0, 5.1, 250.0, 0.0, 0.0, 0.5, 6.890696196857446, 25.0, 22.66049315206962, 21.5, 0.0, 45.8206764556968], 
processed observation next is [1.0, 0.21739130434782608, 0.21794871794871795, 0.68, 0.4636363636363636, 0.6944444444444444, 0.0, 0.0, 0.5083333333333333, 0.06890696196857446, 1.0, 0.6657847360099457, 0.5, 0.0, 0.5390667818317271], 
reward next is -0.4852. 
=============================================
[2017-11-02 10:01:12,434] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.18454775
  0.16031829  0.41154164  0.24359235], sum to 1.0000
[2017-11-02 10:01:13,097] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.9, 66.5, 9.075, 250.0, 126.25, 38.25, 1.100000000000001, 6.481548126827071, 25.0, 23.6175830558953, 22.7, 1.0, 63.52852442896431], 
actual action is [1.1, 25], 
sim time next is 640200.0000, 
raw observation next is [-3.9, 66.0, 9.116666666666665, 250.0, 123.3333333333333, 34.00000000000001, 1.1, 6.473936831049019, 25.0, 23.65622020256132, 22.7, 1.0, 63.54315468464075], 
processed observation next is [1.0, 0.391304347826087, 0.23333333333333334, 0.66, 0.8287878787878786, 0.6944444444444444, 0.32627865961199287, 0.03400000000000001, 0.5183333333333333, 0.0647393683104902, 1.0, 0.8080314575087603, 0.6714285714285714, 1.0, 0.7475665257016558], 
reward next is -0.6793. 
=============================================
[2017-11-02 10:01:19,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01013222
  0.12121087  0.56832743  0.30032957], sum to 1.0000
[2017-11-02 10:01:19,577] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.483333333333333, 65.0, 8.783333333333333, 241.6666666666667, 96.33333333333333, 12.66666666666666, 1.475, 6.56547681959124, 25.0, 23.88549585715483, 22.7, 1.0, 63.36242707898575], 
actual action is [1.516666666666667, 25], 
sim time next is 644100.0000, 
raw observation next is [-3.441666666666666, 65.0, 8.741666666666665, 240.8333333333333, 95.41666666666666, 15.83333333333333, 1.516666666666667, 6.563228149226648, 25.0, 23.90500125499466, 22.7, 1.0, 63.27497252006172], 
processed observation next is [1.0, 0.43478260869565216, 0.2450854700854701, 0.65, 0.7946969696969696, 0.6689814814814814, 0.25242504409171074, 0.01583333333333333, 0.5252777777777777, 0.06563228149226648, 1.0, 0.8435716078563799, 0.6714285714285714, 1.0, 0.7444114414124908], 
reward next is -0.6765. 
=============================================
[2017-11-02 10:01:23,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.16357531e-05   1.01167761e-01   7.58240998e-01   1.28016889e-01
   1.24826832e-02   1.63602194e-12   9.83190872e-12   1.37133005e-11
   2.92151264e-12], sum to 1.0000
[2017-11-02 10:01:23,258] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.025, 59.25, 6.124999999999999, 252.5, 164.5, 94.75, 2.883333333333333, 7.304164547642478, 22.5, 23.81667441101903, 22.7, 1.0, 30.67328719990186], 
actual action is [2.975, 21.5], 
sim time next is 652800.0000, 
raw observation next is [-1.933333333333333, 59.33333333333334, 6.3, 253.3333333333333, 170.3333333333333, 94.16666666666666, 2.975, 7.468256303939195, 21.5, 23.76346082067571, 22.7, 1.0, 28.73055811288812], 
processed observation next is [1.0, 0.5652173913043478, 0.28376068376068375, 0.5933333333333334, 0.5727272727272728, 0.7037037037037036, 0.4506172839506172, 0.09416666666666666, 0.5495833333333333, 0.07468256303939196, 0.5, 0.8233515458108158, 0.6714285714285714, 1.0, 0.3380065660339779], 
reward next is -0.3117. 
=============================================
[2017-11-02 10:01:27,137] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.44756216e-07   2.57938448e-02   9.00070906e-01   3.84714417e-02
   3.56628858e-02   6.21651424e-08   1.62157036e-07   2.23305761e-07
   5.83292810e-08], sum to 1.0000
[2017-11-02 10:01:27,221] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.225, 64.0, 8.325, 242.5, 91.75, 28.5, 1.716666666666666, 12.63977804687659, 19.0, 21.54396982849111, 22.7, 1.0, 96.68815727713375], 
actual action is [-8.225, 18.0], 
sim time next is 645600.0000, 
raw observation next is [-3.166666666666667, 63.66666666666667, 8.2, 243.3333333333334, 90.83333333333334, 31.66666666666667, -8.225, 13.33905244159387, 18.0, 21.6360023903366, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.25213675213675213, 0.6366666666666667, 0.7454545454545454, 0.6759259259259262, 0.240299823633157, 0.03166666666666667, 0.36291666666666667, 0.13339052441593868, 0.0, 0.5194289129052285, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:01:39,832] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.94189024e-01   1.09158061e-03   4.12511779e-03   3.46143381e-04
   2.48209340e-04   8.61793145e-20   4.71545268e-19   5.29186574e-19
   4.06894615e-19], sum to 1.0000
[2017-11-02 10:01:39,929] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.399999999999999, 69.0, 4.058333333333333, 240.0, 0.0, 0.0, 1.6, 11.66294608519412, 19.0, 22.26946967600328, 21.5, 0.0, 47.34625489787017], 
actual action is [-8.399999999999999, 18], 
sim time next is 681000.0000, 
raw observation next is [-3.4, 69.0, 4.016666666666667, 240.0, 0.0, 0.0, -8.399999999999999, 12.85015628533594, 18.0, 22.3405587881581, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.24615384615384614, 0.69, 0.36515151515151517, 0.6666666666666666, 0.0, 0.0, 0.36000000000000004, 0.1285015628533594, 0.0, 0.6200798268797284, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:01:43,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  8.26798379e-01   5.60757741e-02   9.25097689e-02   1.12374453e-02
   1.33786416e-02   2.45159478e-15   1.32600729e-14   1.39265794e-14
   3.44182754e-15], sum to 1.0000
[2017-11-02 10:01:43,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 64.0, 4.1, 243.3333333333333, 0.0, 0.0, -7.591666666666666, 16.13905175976909, 18.0, 22.28008465080057, 21.5, 0.0, 0.0], 
actual action is [-7.633333333333333, 18], 
sim time next is 675900.0000, 
raw observation next is [-2.675, 64.25, 3.975, 242.5, 0.0, 0.0, -7.633333333333333, 18.10458418444485, 18.0, 22.03259207490789, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.26474358974358975, 0.6425, 0.3613636363636364, 0.6736111111111112, 0.0, 0.0, 0.37277777777777776, 0.1810458418444485, 0.0, 0.5760845821296984, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:01:55,936] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00099218
  0.01391067  0.78069383  0.20440334], sum to 1.0000
[2017-11-02 10:01:56,000] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.341666666666666, 75.91666666666666, 4.558333333333333, 259.1666666666666, 0.0, 0.0, -7.383333333333333, 26.69319167617289, 18.0, 20.07480710418132, 21.5, 0.0, 0.0], 
actual action is [2.658333333333334, 20.0], 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 4.6, 260.0, 0.0, 0.0, 2.658333333333334, 25.46028055307579, 20.0, 19.95403951250999, 21.5, 0.0, 49.87187434686825], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.76, 0.41818181818181815, 0.7222222222222222, 0.0, 0.0, 0.5443055555555555, 0.2546028055307579, 0.2857142857142857, 0.2791485017871414, 0.5, 0.0, 0.5867279334925677], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:00,328] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.54611557e-21   1.53621951e-08   1.60708646e-06   1.62113576e-08
   7.50292202e-08   2.05108132e-02   5.23682088e-02   1.70175031e-01
   7.56944299e-01], sum to 1.0000
[2017-11-02 10:02:00,785] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 76.0, 4.391666666666666, 260.0, 26.58333333333333, 0.0, 2.7, 13.73599322051593, 19.0, 21.74872697286389, 22.7, 1.0, 63.21585779654628], 
actual action is [2.7, 24.0], 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 4.35, 260.0, 29.0, 0.0, 2.7, 13.54877585241202, 24.0, 21.87927117937116, 22.7, 1.0, 53.52891438063176], 
processed observation next is [0.0, 0.34782608695652173, 0.27435897435897433, 0.76, 0.39545454545454545, 0.7222222222222222, 0.07671957671957672, 0.0, 0.545, 0.1354877585241202, 0.8571428571428571, 0.5541815970530227, 0.6714285714285714, 1.0, 0.6297519338897855], 
reward next is -0.5803. 
=============================================
[2017-11-02 10:02:01,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-67.52735138]
 [-66.35111237]
 [-65.90734863]
 [-66.64792633]
 [-65.44174957]], R is [[-65.76851654]
 [-66.11083221]
 [-66.44972229]
 [-66.78522491]
 [-67.11737061]].
[2017-11-02 10:02:07,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.27232027e-01   3.61298886e-03   6.32242188e-02   1.12459296e-03
   4.80619259e-03   7.40388949e-22   1.56110196e-21   4.71696634e-21
   2.53190898e-21], sum to 1.0000
[2017-11-02 10:02:07,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.95, 71.33333333333334, 4.683333333333334, 260.0, 104.1666666666667, 50.58333333333334, 3.0, 14.006881835989, 23.0, 22.17054202486536, 22.7, 1.0, 54.43250360719684], 
actual action is [-6.95, 18.0], 
sim time next is 726000.0000, 
raw observation next is [-1.9, 70.66666666666666, 4.766666666666666, 260.0, 107.3333333333333, 52.16666666666666, -6.95, 15.29414982695886, 18.0, 22.14003555267503, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.2846153846153846, 0.7066666666666666, 0.43333333333333324, 0.7222222222222222, 0.28395061728395055, 0.05216666666666666, 0.38416666666666666, 0.15294149826958858, 0.0, 0.5914336503821472, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:09,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.92418112e-03   2.92784460e-02   8.81860137e-01   8.04665219e-03
   7.88906366e-02   4.19567394e-16   1.02746928e-15   4.29791082e-15
   2.73684159e-15], sum to 1.0000
[2017-11-02 10:02:09,540] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.3, 76.0, 4.1, 260.0, 65.0, 24.5, 2.7, 15.06533513101496, 25.0, 21.54240757885562, 22.7, 1.0, 66.22319348242527], 
actual action is [2.7, 24.0], 
sim time next is 723900.0000, 
raw observation next is [-2.25, 75.33333333333333, 4.183333333333333, 260.0, 71.0, 28.58333333333334, 2.7, 14.21279443881499, 24.0, 21.76716644295997, 22.7, 1.0, 63.86322594916941], 
processed observation next is [0.0, 0.391304347826087, 0.27564102564102566, 0.7533333333333333, 0.38030303030303025, 0.7222222222222222, 0.18783068783068782, 0.02858333333333334, 0.545, 0.1421279443881499, 0.8571428571428571, 0.538166634708567, 0.6714285714285714, 1.0, 0.7513320699902284], 
reward next is -0.6904. 
=============================================
[2017-11-02 10:02:17,598] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 39269: loss -15.8088
[2017-11-02 10:02:19,482] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39468: loss 24.7323
[2017-11-02 10:02:19,750] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 39497: loss -105.0350
[2017-11-02 10:02:20,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.35468804e-20   4.30391278e-10   1.92311358e-08   5.95445748e-10
   1.94679850e-09   1.83982745e-01   1.84123173e-01   2.75761306e-01
   3.56132716e-01], sum to 1.0000
[2017-11-02 10:02:20,470] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39588: loss -7.7351
[2017-11-02 10:02:20,478] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.1416666666666666, 54.08333333333333, 6.766666666666666, 250.0, 127.0833333333333, 476.5, 4.766666666666667, 14.3920746551149, 19.0, 22.29743063050103, 22.7, 1.0, 44.41688904377412], 
actual action is [4.858333333333333, 20.0], 
sim time next is 736200.0000, 
raw observation next is [-0.04999999999999999, 53.5, 6.9, 250.0, 131.0, 449.0, 4.858333333333333, 14.19785204595059, 20.0, 22.30382499994462, 22.7, 1.0, 27.53089064479656], 
processed observation next is [0.0, 0.5217391304347826, 0.33205128205128204, 0.535, 0.6272727272727273, 0.6944444444444444, 0.34656084656084657, 0.449, 0.5809722222222222, 0.1419785204595059, 0.2857142857142857, 0.6148321428492315, 0.6714285714285714, 1.0, 0.32389283111525363], 
reward next is -0.3057. 
=============================================
[2017-11-02 10:02:20,793] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.86753012e-33   5.67938362e-18   1.13458581e-15   5.82756641e-18
   8.91011626e-17   1.21257916e-01   3.74093860e-01   3.25932175e-01
   1.78716049e-01], sum to 1.0000
[2017-11-02 10:02:20,852] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.9, 55.25, 4.35, 337.5, 0.0, 0.0, 1.1, 16.96693778349751, 19.0, 22.01689652962761, 22.7, 1.0, 30.76452730267448], 
actual action is [1.1, 20.0], 
sim time next is 757200.0000, 
raw observation next is [-3.9, 55.0, 4.433333333333334, 336.6666666666667, 0.0, 0.0, 1.1, 17.29489966336142, 20.0, 21.92254674018589, 22.7, 1.0, 21.50157255291366], 
processed observation next is [0.0, 0.782608695652174, 0.23333333333333334, 0.55, 0.40303030303030307, 0.9351851851851852, 0.0, 0.0, 0.5183333333333333, 0.1729489966336142, 0.2857142857142857, 0.5603638200265557, 0.6714285714285714, 1.0, 0.2529596770931019], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:21,199] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39685: loss -72.1951
[2017-11-02 10:02:21,541] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 39724: loss -17.8138
[2017-11-02 10:02:23,462] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39910: loss -24.4788
[2017-11-02 10:02:23,697] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39937: loss 36.6499
[2017-11-02 10:02:24,322] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40011: loss -15.0695
[2017-11-02 10:02:25,687] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40173: loss 56.1740
[2017-11-02 10:02:26,577] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40272: loss -47.4739
[2017-11-02 10:02:26,825] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 40296: loss 61.5220
[2017-11-02 10:02:26,906] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40302: loss -78.6565
[2017-11-02 10:02:26,926] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40305: loss 4.0965
[2017-11-02 10:02:27,561] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40369: loss -37.9949
[2017-11-02 10:02:30,280] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40628: loss -19.9798
[2017-11-02 10:02:54,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   5.37232963e-25   3.42580913e-24   3.64675487e-24
   1.43656975e-24   5.67736244e-03   3.45317600e-03   5.43588936e-01
   4.47280556e-01], sum to 1.0000
[2017-11-02 10:02:54,641] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 75.0, 2.583333333333333, 78.33333333333334, 69.66666666666666, 0.0, -11.2, 23.0368708171291, 18.0, 20.98541047604237, 22.7, 1.0, 0.0], 
actual action is [-1.2000000000000002, 23.0], 
sim time next is 813300.0000, 
raw observation next is [-6.2, 75.0, 2.541666666666667, 79.16666666666666, 71.83333333333334, 0.0, -1.2, 20.73497061830174, 23.0, 20.84640489385628, 22.7, 1.0, 91.16019885197208], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.17435897435897435, 0.75, 0.23106060606060608, 0.21990740740740738, 0.19003527336860673, 0.0, 0.48000000000000004, 0.2073497061830174, 0.7142857142857143, 0.4066292705508973, 0.6714285714285714, 1.0, 1.0724729276702598], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:55,863] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.77051411e-04   3.64130363e-02   2.25328341e-01   5.94676554e-01
   1.34033322e-01   1.40051910e-04   4.22880039e-05   7.11088022e-03
   1.97848049e-03], sum to 1.0000
[2017-11-02 10:02:55,900] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 71.0, 2.041666666666667, 60.0, 100.4166666666667, 0.0, -9.5, 24.50923480691247, 18.0, 20.72578984834011, 22.7, 1.0, 0.0], 
actual action is [-9.5, 18.0], 
sim time next is 817800.0000, 
raw observation next is [-4.5, 71.0, 2.083333333333333, 60.0, 102.3333333333333, 0.0, -9.5, 26.30770642650072, 18.0, 20.67264018350776, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.18939393939393936, 0.16666666666666666, 0.2707231040564373, 0.0, 0.3416666666666667, 0.2630770642650072, 0.0, 0.3818057405011085, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:57,191] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.26225385e-02   3.97607125e-02   2.68828392e-01   4.22642559e-01
   2.36084640e-01   6.54854375e-07   1.66211009e-07   4.71901149e-05
   1.30866374e-05], sum to 1.0000
[2017-11-02 10:02:57,464] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 71.66666666666666, 2.5, 61.66666666666666, 103.5833333333333, 0.0, 0.5, 22.49715511183218, 20.0, 20.76378483372615, 22.7, 1.0, 73.60487480705288], 
actual action is [0.5, 19.5], 
sim time next is 821400.0000, 
raw observation next is [-4.5, 72.33333333333334, 2.5, 63.33333333333333, 102.6666666666667, 0.0, 0.5, 21.89329936140065, 19.5, 20.8845286719196, 22.7, 1.0, 39.46808235499877], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.21794871794871795, 0.7233333333333334, 0.22727272727272727, 0.1759259259259259, 0.27160493827160503, 0.0, 0.5083333333333333, 0.2189329936140065, 0.21428571428571427, 0.4120755245599429, 0.6714285714285714, 1.0, 0.46433038064704435], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:07,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.24428135e-03   4.43357101e-04   9.65273261e-01
   3.20390239e-02], sum to 1.0000
[2017-11-02 10:03:08,159] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 71.0, 2.041666666666667, 60.0, 100.4166666666667, 0.0, 0.5, 20.29958831126208, 20.0, 21.45539260180761, 22.7, 1.0, 69.33676900593129], 
actual action is [0.5, 22.0], 
sim time next is 817800.0000, 
raw observation next is [-4.5, 71.0, 2.083333333333333, 60.0, 102.3333333333333, 0.0, 0.5, 20.20220105989178, 22.0, 21.42427029844852, 22.7, 1.0, 44.26857851461377], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.18939393939393936, 0.16666666666666666, 0.2707231040564373, 0.0, 0.5083333333333333, 0.2020220105989178, 0.5714285714285714, 0.4891814712069313, 0.6714285714285714, 1.0, 0.5208068060542796], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:16,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.40209417e-26   9.58637082e-17   2.78799651e-16   3.00378868e-15
   4.86479662e-16   2.07050312e-02   3.08486237e-03   5.19269288e-01
   4.56940860e-01], sum to 1.0000
[2017-11-02 10:03:17,008] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.899999999999999, 79.58333333333333, 2.591666666666666, 89.16666666666667, 72.33333333333334, 0.0, 1.1, 15.95927114362849, 25.0, 22.18992171169524, 22.7, 1.0, 54.04217389767562], 
actual action is [1.100000000000001, 25], 
sim time next is 828600.0000, 
raw observation next is [-3.9, 80.16666666666667, 2.683333333333334, 88.33333333333333, 69.66666666666666, 0.0, 1.100000000000001, 15.52590741403991, 25.0, 22.2330478391369, 22.7, 1.0, 61.93863533226075], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.23333333333333334, 0.8016666666666667, 0.243939393939394, 0.24537037037037035, 0.1843033509700176, 0.0, 0.5183333333333333, 0.1552590741403991, 1.0, 0.6047211198767002, 0.6714285714285714, 1.0, 0.7286898274383617], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:20,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.35535812e-02   5.31464524e-04   1.81621835e-01
   8.04293096e-01], sum to 1.0000
[2017-11-02 10:03:20,316] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 82.66666666666667, 4.016666666666667, 80.0, 42.33333333333334, 0.0, 1.1, 14.05673622864064, 25.0, 22.70391828202103, 22.7, 1.0, 54.03518592656492], 
actual action is [1.1, 25], 
sim time next is 834900.0000, 
raw observation next is [-3.9, 82.33333333333333, 4.058333333333333, 80.0, 40.66666666666667, 0.0, 1.1, 13.74940867424879, 25.0, 22.70244440815494, 22.7, 1.0, 62.89744544911186], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.23333333333333334, 0.8233333333333333, 0.3689393939393939, 0.2222222222222222, 0.10758377425044093, 0.0, 0.5183333333333333, 0.13749408674248792, 1.0, 0.6717777725935627, 0.6714285714285714, 1.0, 0.7399699464601396], 
reward next is -0.6797. 
=============================================
[2017-11-02 10:03:23,605] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.19261344e-02   5.62050554e-04   3.55940759e-01
   6.01571023e-01], sum to 1.0000
[2017-11-02 10:03:23,861] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.483333333333333, 83.5, 3.6, 68.33333333333333, 0.0, 0.0, 1.475, 12.54693256424457, 25.0, 22.99705041008853, 22.7, 1.0, 61.09607865431297], 
actual action is [1.516666666666667, 25], 
sim time next is 849300.0000, 
raw observation next is [-3.441666666666666, 83.25, 3.6, 69.16666666666666, 0.0, 0.0, 1.516666666666667, 12.43404301692511, 25.0, 23.03478809769961, 22.7, 1.0, 61.04964095283258], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.2450854700854701, 0.8325, 0.32727272727272727, 0.1921296296296296, 0.0, 0.0, 0.5252777777777777, 0.12434043016925109, 1.0, 0.7192554425285158, 0.6714285714285714, 1.0, 0.7182310700333245], 
reward next is -0.6588. 
=============================================
[2017-11-02 10:03:28,247] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   2.37515286e-28   1.19411576e-27   4.53164575e-27
   1.55989396e-27   2.83862725e-02   1.10489572e-03   4.52517569e-01
   5.17991304e-01], sum to 1.0000
[2017-11-02 10:03:28,355] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 80.0, 1.75, 60.0, 0.0, 0.0, 2.7, 9.934157662536316, 25.0, 23.01038922265673, 21.5, 0.0, 42.54314720930232], 
actual action is [2.7, 25], 
sim time next is 865200.0000, 
raw observation next is [-2.3, 80.0, 1.833333333333333, 60.00000000000001, 0.0, 0.0, 2.7, 9.89338429559123, 25.0, 23.00938905914995, 21.5, 0.0, 42.57721619841639], 
processed observation next is [0.3333333333333333, 0.0, 0.27435897435897433, 0.8, 0.16666666666666663, 0.16666666666666669, 0.0, 0.0, 0.545, 0.0989338429559123, 1.0, 0.7156270084499928, 0.5, 0.0, 0.5009084258637222], 
reward next is -0.4508. 
=============================================
[2017-11-02 10:03:32,905] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.02305677e-34   3.45478446e-23   2.36437744e-22   7.56736419e-22
   2.41956085e-22   4.52279560e-02   1.66827242e-03   5.65434396e-01
   3.87669384e-01], sum to 1.0000
[2017-11-02 10:03:33,116] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 82.33333333333333, 4.008333333333333, 60.83333333333334, 0.0, 0.0, 1.1, 10.54487062721634, 25.0, 23.61717631048806, 22.7, 1.0, 60.66482910385249], 
actual action is [1.1, 25], 
sim time next is 842400.0000, 
raw observation next is [-3.9, 82.0, 4.1, 60.0, 0.0, 0.0, 1.1, 10.51082871773744, 25.0, 23.62544298935807, 22.7, 1.0, 60.73549985983697], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.23333333333333334, 0.82, 0.3727272727272727, 0.16666666666666666, 0.0, 0.0, 0.5183333333333333, 0.10510828717737439, 1.0, 0.8036347127654386, 0.6714285714285714, 1.0, 0.7145352924686702], 
reward next is -0.6536. 
=============================================
[2017-11-02 10:03:50,664] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 46948: loss -1.9222
[2017-11-02 10:03:52,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.83293545
  0.00087845  0.1535987   0.01258739], sum to 1.0000
[2017-11-02 10:03:52,764] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.575, 78.25, 2.5, 60.0, 0.0, 0.0, 3.383333333333333, 7.43480259976026, 25.0, 23.26477502428266, 21.5, 0.0, 42.86298531051641], 
actual action is [3.425, 25], 
sim time next is 876000.0000, 
raw observation next is [-1.533333333333333, 78.0, 2.5, 60.00000000000001, 0.0, 0.0, 3.425, 7.420839006966644, 25.0, 23.25805727261642, 21.5, 0.0, 42.85062819145793], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.294017094017094, 0.78, 0.22727272727272727, 0.16666666666666669, 0.0, 0.0, 0.5570833333333333, 0.07420839006966644, 1.0, 0.7511510389452027, 0.5, 0.0, 0.5041250375465639], 
reward next is -0.4537. 
=============================================
[2017-11-02 10:03:53,472] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3000, global step 47143: loss -2.8558
[2017-11-02 10:03:55,730] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-51.04373932]
 [-50.89429855]
 [-50.70888138]
 [-50.80519867]
 [-51.2817421 ]], R is [[-50.82506943]
 [-50.77002716]
 [-50.71562195]
 [-50.66184998]
 [-50.60871124]].
[2017-11-02 10:03:57,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.70814962e-15   1.84360925e-12   5.57058002e-12   1.76687224e-11
   7.39785750e-12   6.27844393e-01   6.65816944e-03   2.82491177e-01
   8.30062479e-02], sum to 1.0000
[2017-11-02 10:03:57,395] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.45, 77.5, 2.5, 60.0, 0.0, 0.0, 3.508333333333334, 7.320610424820642, 25.0, 23.26962520385971, 21.5, 0.0, 42.81760879637938], 
actual action is [3.55, 25], 
sim time next is 876900.0000, 
raw observation next is [-1.408333333333333, 77.25, 2.5, 60.0, 0.0, 0.0, 3.55, 7.306501825816238, 25.0, 23.26371063583948, 21.5, 0.0, 42.80928732894533], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.2972222222222222, 0.7725, 0.22727272727272727, 0.16666666666666666, 0.0, 0.0, 0.5591666666666666, 0.07306501825816239, 1.0, 0.7519586622627829, 0.5, 0.0, 0.5036386744581803], 
reward next is -0.4533. 
=============================================
[2017-11-02 10:04:00,751] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47595: loss 1.8932
[2017-11-02 10:04:01,061] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3000, global step 47615: loss 1.1600
[2017-11-02 10:04:01,079] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47615: loss -2.4408
[2017-11-02 10:04:03,582] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3000, global step 47766: loss 0.0836
[2017-11-02 10:04:05,460] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3000, global step 47884: loss -0.0473
[2017-11-02 10:04:08,918] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48114: loss 0.5620
[2017-11-02 10:04:09,614] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48159: loss 0.0148
[2017-11-02 10:04:10,589] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48231: loss 0.0953
[2017-11-02 10:04:15,464] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48583: loss 0.3333
[2017-11-02 10:04:16,885] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3000, global step 48697: loss 0.0787
[2017-11-02 10:04:19,404] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48900: loss 0.0302
[2017-11-02 10:04:20,022] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48957: loss 0.6423
[2017-11-02 10:04:20,671] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 49020: loss 1.3003
[2017-11-02 10:04:22,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.83742476e-01   5.89850417e-04   9.13881883e-03
   6.52882829e-03], sum to 1.0000
[2017-11-02 10:04:22,761] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [4.5, 92.83333333333333, 3.683333333333333, 150.0, 30.0, 0.0, 9.45, 6.72132897078396, 25.0, 24.31914537342085, 22.7, 1.0, 39.99050763419502], 
actual action is [9.5, 25], 
sim time next is 922500.0000, 
raw observation next is [4.550000000000001, 92.75, 3.725, 150.0, 27.0, 0.0, 9.5, 6.719127050372341, 25.0, 24.31596581386489, 22.7, 1.0, 39.94651130026632], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.45, 0.9275, 0.3386363636363636, 0.4166666666666667, 0.07142857142857142, 0.0, 0.6583333333333333, 0.06719127050372341, 1.0, 0.9022808305521269, 0.6714285714285714, 1.0, 0.46995895647372143], 
reward next is -0.4297. 
=============================================
[2017-11-02 10:04:23,129] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 49241: loss 0.0557
[2017-11-02 10:04:33,858] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-29.97206306]
 [-30.23311424]
 [-30.11425972]
 [-29.80710411]
 [-30.24709129]], R is [[-30.72011185]
 [-30.64230537]
 [-30.55904198]
 [-30.47029305]
 [-30.38780212]].
[2017-11-02 10:04:33,961] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.44953004e-38   5.56068750e-38   9.90271729e-38
   4.66630595e-38   9.95938897e-01   4.19746793e-04   3.22291907e-03
   4.18493320e-04], sum to 1.0000
[2017-11-02 10:04:34,078] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [5.416666666666667, 90.16666666666667, 4.933333333333334, 153.3333333333333, 0.0, 0.0, 10.375, 5.806242957364423, 25.0, 24.21546681566614, 21.5, 0.0, 26.4292158277752], 
actual action is [10.416666666666668, 25], 
sim time next is 953700.0000, 
raw observation next is [5.458333333333333, 89.58333333333333, 5.016666666666667, 156.6666666666667, 0.0, 0.0, 10.41666666666667, 5.798859231095481, 25.0, 24.18607534839191, 21.5, 0.0, 25.23386047857811], 
processed observation next is [0.5, 0.0, 0.4732905982905983, 0.8958333333333333, 0.45606060606060606, 0.43518518518518534, 0.0, 0.0, 0.6736111111111112, 0.05798859231095481, 1.0, 0.8837250497702728, 0.5, 0.0, 0.29686894680680126], 
reward next is -0.2672. 
=============================================
[2017-11-02 10:04:40,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.08820676e-28   7.86953139e-21   1.86353275e-20   3.53086407e-20
   1.82609491e-20   9.49328780e-01   1.05097853e-02   3.47284116e-02
   5.43297129e-03], sum to 1.0000
[2017-11-02 10:04:40,773] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [5.0, 97.66666666666666, 4.516666666666666, 120.0, 0.0, 0.0, 10.0, 6.697301516323135, 25.0, 24.40212833027561, 21.5, 0.0, 30.01020511167724], 
actual action is [10.0, 25], 
sim time next is 942000.0000, 
raw observation next is [5.0, 97.33333333333334, 4.433333333333334, 120.0, 0.0, 0.0, 10.0, 6.684379457933986, 25.0, 24.45138666805604, 21.5, 0.0, 28.56309071105398], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.46153846153846156, 0.9733333333333334, 0.40303030303030307, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.06684379457933985, 1.0, 0.9216266668651484, 0.5, 0.0, 0.33603636130651743], 
reward next is -0.3024. 
=============================================
[2017-11-02 10:04:47,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.89484847e-01   1.23453152e-03   1.96196861e-03   3.18390899e-03
   2.15204083e-03   1.53101666e-03   2.24639705e-04   1.73651701e-04
   5.34821338e-05], sum to 1.0000
[2017-11-02 10:04:47,279] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.458333333333333, 89.58333333333333, 5.016666666666667, 156.6666666666667, 0.0, 0.0, 0.416666666666667, 8.773446615506263, 18.0, 23.05669815097734, 21.5, 0.0, 0.0], 
actual action is [0.45833333333333304, 18], 
sim time next is 954000.0000, 
raw observation next is [5.5, 89.0, 5.1, 160.0, 0.0, 0.0, 0.458333333333333, 9.144173633368837, 18.0, 22.91858322343597, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.47435897435897434, 0.89, 0.4636363636363636, 0.4444444444444444, 0.0, 0.0, 0.5076388888888889, 0.09144173633368836, 0.0, 0.7026547462051386, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:04:56,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.29501525  0.08374308  0.14924034  0.11906742  0.11837902  0.10468175
  0.05115793  0.05087496  0.0278402 ], sum to 1.0000
[2017-11-02 10:04:56,489] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.40833333333333, 86.0, 6.266666666666666, 201.6666666666667, 127.3333333333333, 0.0, 7.366666666666671, 16.54741103081171, 18.0, 20.7842890605369, 22.7, 1.0, 0.0], 
actual action is [7.40833333333333, 18], 
sim time next is 995400.0000, 
raw observation next is [12.45, 86.0, 6.4, 200.0, 128.0, 0.0, 7.40833333333333, 16.55467050562906, 18.0, 20.78621902867653, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.6525641025641026, 0.86, 0.5818181818181819, 0.5555555555555556, 0.3386243386243386, 0.0, 0.6234722222222222, 0.16554670505629057, 0.0, 0.39803128981093294, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:05:00,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  7.46844947e-01   3.78888324e-02   6.48545623e-02   5.66907190e-02
   8.62546116e-02   3.95959569e-03   1.48450036e-03   1.39179535e-03
   6.30411552e-04], sum to 1.0000
[2017-11-02 10:05:00,174] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 5.183333333333334, 210.0, 0.0, 0.0, 9.4, 9.737804989546001, 18.0, 22.85511411581488, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1048500.0000, 
raw observation next is [14.4, 77.0, 5.225, 210.0, 0.0, 0.0, 9.4, 9.749644567180273, 18.0, 22.85403231813427, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.7025641025641025, 0.77, 0.475, 0.5833333333333334, 0.0, 0.0, 0.6566666666666666, 0.09749644567180273, 0.0, 0.6934331883048956, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:00,912] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 54128: loss 0.2005
[2017-11-02 10:05:02,133] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3500, global step 54356: loss 0.3266
[2017-11-02 10:05:02,673] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  7.95047343e-01   3.13022807e-02   5.51118515e-02   6.06033839e-02
   5.70951626e-02   4.26082202e-04   1.74301691e-04   1.73701657e-04
   6.59045618e-05], sum to 1.0000
[2017-11-02 10:05:02,695] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.5, 75.5, 7.016666666666667, 206.6666666666667, 35.66666666666666, 0.0, 10.5, 14.17085407669858, 18.0, 21.26975453670589, 22.7, 1.0, 0.0], 
actual action is [10.5, 18], 
sim time next is 1008900.0000, 
raw observation next is [15.5, 75.75, 6.925000000000001, 205.0, 33.0, 0.0, 10.5, 14.27374303241703, 18.0, 21.25636162214243, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.7307692307692307, 0.7575, 0.6295454545454546, 0.5694444444444444, 0.0873015873015873, 0.0, 0.675, 0.1427374303241703, 0.0, 0.4651945174489183, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0143. 
=============================================
[2017-11-02 10:05:04,735] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 54805: loss 1.9150
[2017-11-02 10:05:06,031] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3500, global step 55066: loss -5.0668
[2017-11-02 10:05:06,546] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55182: loss 0.8124
[2017-11-02 10:05:06,625] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.83307242e-01   3.02919932e-03   4.47004009e-03   5.94329555e-03
   3.25015397e-03   5.15192156e-09   3.77659548e-09   1.98363792e-09
   4.69676686e-10], sum to 1.0000
[2017-11-02 10:05:06,648] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.65833333333333, 81.75, 3.891666666666667, 192.5, 0.0, 0.0, 7.75, 11.94607157539302, 18.0, 21.98182338201327, 21.5, 0.0, 0.0], 
actual action is [7.65833333333333, 18], 
sim time next is 1064400.0000, 
raw observation next is [12.56666666666667, 82.0, 3.933333333333333, 190.0, 0.0, 0.0, 7.65833333333333, 12.00772262766787, 18.0, 21.96839744926204, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.6555555555555557, 0.82, 0.35757575757575755, 0.5277777777777778, 0.0, 0.0, 0.6276388888888889, 0.1200772262766787, 0.0, 0.5669139213231483, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:06,912] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3500, global step 55245: loss -55.1951
[2017-11-02 10:05:07,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-7.59549046]
 [-8.30506325]
 [-7.24756718]
 [-7.42828941]
 [-7.16037655]], R is [[-7.92598772]
 [-7.85814238]
 [-7.79081583]
 [-7.99645805]
 [-8.51396656]].
[2017-11-02 10:05:07,806] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.90970850e-01   2.00835289e-03   2.50466587e-03   2.94123730e-03
   1.57478743e-03   1.34042777e-08   6.58486421e-09   4.92687091e-09
   1.23788246e-09], sum to 1.0000
[2017-11-02 10:05:07,821] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.225, 180.0, 0.0, 0.0, 19.4, 12.28668763589601, 18.5, 21.22995689644403, 21.5, 0.0, 27.62993833311272], 
actual action is [9.4, 18], 
sim time next is 1033200.0000, 
raw observation next is [14.4, 75.0, 4.1, 180.0, 0.0, 0.0, 9.4, 12.48578317187626, 18.0, 21.24982312459501, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5, 0.0, 0.0, 0.6566666666666666, 0.12485783171876261, 0.0, 0.46426044637071584, 0.5, 0.0, 0.0], 
reward next is -0.0357. 
=============================================
[2017-11-02 10:05:09,092] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3500, global step 55668: loss -35.9994
[2017-11-02 10:05:10,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55942: loss -5.8596
[2017-11-02 10:05:12,107] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56259: loss -142.4538
[2017-11-02 10:05:12,735] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56403: loss -106.9921
[2017-11-02 10:05:13,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.76869166e-01   4.75974940e-03   8.78409110e-03   7.91943353e-03
   1.66759442e-03   4.14443523e-12   2.39346000e-12   2.10170813e-12
   4.91670073e-13], sum to 1.0000
[2017-11-02 10:05:13,253] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.1, 185.8333333333333, 0.0, 0.0, 9.4, 10.89071158916104, 18.0, 22.54688018456707, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1035600.0000, 
raw observation next is [14.4, 75.0, 4.1, 186.6666666666667, 0.0, 0.0, 9.4, 11.04842239193426, 18.0, 22.52906442670126, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5185185185185186, 0.0, 0.0, 0.6566666666666666, 0.1104842239193426, 0.0, 0.6470092038144658, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:13,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.67359155e-01   1.37159690e-01   1.86570436e-01   1.48719683e-01
   5.78471161e-02   8.29993805e-04   6.66298263e-04   6.16667327e-04
   2.31012629e-04], sum to 1.0000
[2017-11-02 10:05:13,337] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.98333333333333, 49.83333333333334, 3.0, 186.6666666666667, 23.66666666666667, 0.9999999999999998, 13.125, 7.617163996444309, 18.0, 24.11134639113112, 22.7, 1.0, 0.0], 
actual action is [12.98333333333333, 18], 
sim time next is 1097700.0000, 
raw observation next is [17.84166666666667, 49.91666666666666, 3.0, 188.3333333333333, 20.83333333333334, 1.25, 12.98333333333333, 7.62555674323665, 18.0, 24.09274206267125, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.7908119658119659, 0.4991666666666666, 0.2727272727272727, 0.523148148148148, 0.0551146384479718, 0.00125, 0.7163888888888889, 0.0762555674323665, 0.0, 0.8703917232387498, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0076. 
=============================================
[2017-11-02 10:05:14,163] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3500, global step 56680: loss -4.0450
[2017-11-02 10:05:14,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.82253492e-01   2.70517217e-03   8.05252604e-03   6.19484717e-03
   7.93933112e-04   6.23098198e-13   1.98356536e-13   3.15982890e-13
   5.29230014e-14], sum to 1.0000
[2017-11-02 10:05:14,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 5.141666666666667, 210.0, 0.0, 0.0, 9.4, 11.54703823691087, 18.0, 21.97398569202984, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1048200.0000, 
raw observation next is [14.4, 77.0, 5.183333333333334, 210.0, 0.0, 0.0, 9.4, 11.79745928953115, 18.0, 21.97295424043522, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.7025641025641025, 0.77, 0.47121212121212125, 0.5833333333333334, 0.0, 0.0, 0.6566666666666666, 0.1179745928953115, 0.0, 0.567564891490746, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:15,060] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56837: loss 4.0941
[2017-11-02 10:05:15,243] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.40007641e-02   1.97725177e-01   4.35391545e-01   3.17917705e-01
   3.47454101e-02   8.39711356e-05   3.38508762e-05   9.67889209e-05
   4.73371438e-06], sum to 1.0000
[2017-11-02 10:05:15,283] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [14.05, 77.58333333333333, 4.725, 204.1666666666667, 0.0, 0.0, 19.1, 12.34416935861967, 20.5, 21.05083450964982, 21.5, 0.0, 13.8846457870114], 
actual action is [19.05, 20.0], 
sim time next is 1053600.0000, 
raw observation next is [14.0, 77.66666666666667, 4.6, 203.3333333333333, 0.0, 0.0, 19.05, 12.22464442730912, 20.0, 21.10201219910495, 21.5, 0.0, 12.63340225301782], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.6923076923076923, 0.7766666666666667, 0.41818181818181815, 0.5648148148148147, 0.0, 0.0, 0.8175, 0.1222464442730912, 0.2857142857142857, 0.4431445998721359, 0.5, 0.0, 0.14862826180020966], 
reward next is -0.1906. 
=============================================
[2017-11-02 10:05:17,096] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 57195: loss 1.1622
[2017-11-02 10:05:17,798] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 57316: loss 13.9201
[2017-11-02 10:05:18,635] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 57463: loss 2.4500
[2017-11-02 10:05:19,745] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 57648: loss 26.5772
[2017-11-02 10:05:24,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.38348186e-01   1.03201173e-01   8.49214122e-02   4.23268639e-02
   2.67335363e-02   1.97356124e-03   1.42033212e-03   8.27796408e-04
   2.47167191e-04], sum to 1.0000
[2017-11-02 10:05:24,826] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [19.25, 50.25, 4.574999999999999, 177.5, 128.0, 0.0, 14.2, 8.943185619707814, 18.0, 22.446869264253, 22.7, 1.0, 0.0], 
actual action is [14.25, 18], 
sim time next is 1090200.0000, 
raw observation next is [19.3, 49.83333333333334, 4.75, 178.3333333333333, 124.0, 0.0, 14.25, 8.945914668686703, 18.0, 22.44364877437902, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.8282051282051281, 0.4983333333333334, 0.4318181818181818, 0.49537037037037024, 0.328042328042328, 0.0, 0.7375, 0.08945914668686702, 0.0, 0.6348069677684316, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0089. 
=============================================
[2017-11-02 10:05:38,151] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-5.13791227]
 [-5.20321655]
 [-5.21851683]
 [-5.4217062 ]
 [-5.40038872]], R is [[-5.28682804]
 [-5.24785566]
 [-5.20918894]
 [-5.17082357]
 [-5.13275766]].
[2017-11-02 10:05:44,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 61884: loss 0.1223
[2017-11-02 10:05:48,052] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4000, global step 62539: loss 0.2611
[2017-11-02 10:05:48,254] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 62571: loss 0.2574
[2017-11-02 10:05:49,002] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4000, global step 62730: loss 0.4852
[2017-11-02 10:05:50,778] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.32163596e-01   4.28525805e-02   1.55471973e-02   7.50953518e-03
   1.92672538e-03   1.21039363e-07   2.05110965e-07   4.54262228e-08
   8.74614781e-09], sum to 1.0000
[2017-11-02 10:05:50,779] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63164: loss 0.4530
[2017-11-02 10:05:50,784] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [16.1, 79.33333333333333, 6.8, 130.0, 0.0, 0.0, 11.1, 10.66473568419419, 18.0, 21.88510440065297, 22.7, 1.0, 0.0], 
actual action is [11.100000000000001, 18], 
sim time next is 1212300.0000, 
raw observation next is [16.1, 79.5, 6.749999999999999, 130.0, 0.0, 0.0, 11.1, 10.67507417087126, 18.0, 21.87954401118588, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.7461538461538462, 0.795, 0.6136363636363635, 0.3611111111111111, 0.0, 0.0, 0.685, 0.10675074170871261, 0.0, 0.5542205730265545, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:05:51,161] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4000, global step 63269: loss 1.6247
[2017-11-02 10:05:53,113] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63793: loss -0.0907
[2017-11-02 10:05:53,973] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4000, global step 63994: loss -1.3795
[2017-11-02 10:05:55,202] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64292: loss -0.3013
[2017-11-02 10:05:57,195] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4000, global step 64739: loss 1.0487
[2017-11-02 10:05:58,270] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64978: loss -0.0321
[2017-11-02 10:05:58,614] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 65065: loss -0.2031
[2017-11-02 10:05:59,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.76363242e-01   2.73041546e-01   1.26143783e-01   7.78270736e-02
   4.42654341e-02   9.06584493e-04   9.43698979e-04   3.82098428e-04
   1.26562940e-04], sum to 1.0000
[2017-11-02 10:05:59,270] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [16.6, 75.0, 8.325, 125.0, 0.0, 0.0, 11.6, 11.74326757324387, 18.0, 21.55496432891425, 22.7, 1.0, 0.0], 
actual action is [11.600000000000001, 18], 
sim time next is 1203600.0000, 
raw observation next is [16.6, 75.0, 8.2, 126.6666666666667, 0.0, 0.0, 11.6, 11.77316995317998, 18.0, 21.54570025213058, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.758974358974359, 0.75, 0.7454545454545454, 0.35185185185185197, 0.0, 0.0, 0.6933333333333334, 0.11773169953179981, 0.0, 0.5065286074472256, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0118. 
=============================================
[2017-11-02 10:05:59,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 65299: loss 0.2237
[2017-11-02 10:06:00,008] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 65301: loss -0.3805
[2017-11-02 10:06:00,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.34722099  0.26557034  0.1681833   0.11097299  0.07434249  0.01305946
  0.01230882  0.00602131  0.00232023], sum to 1.0000
[2017-11-02 10:06:00,232] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [14.4, 97.33333333333334, 3.933333333333334, 330.0, 96.0, 0.0, 9.4, 11.27480962003733, 18.0, 21.54672914601891, 22.7, 1.0, 0.0], 
actual action is [9.4, 18.0], 
sim time next is 1251900.0000, 
raw observation next is [14.4, 97.0, 3.85, 332.5, 96.5, 0.0, 9.4, 11.28987055158501, 18.0, 21.54334112864036, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7025641025641025, 0.97, 0.35000000000000003, 0.9236111111111112, 0.2552910052910053, 0.0, 0.6566666666666666, 0.11289870551585009, 0.0, 0.5061915898057657, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0113. 
=============================================
[2017-11-02 10:06:00,878] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 65471: loss 1.3251
[2017-11-02 10:06:01,236] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 65544: loss -0.8281
[2017-11-02 10:06:21,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.66788593e-01   7.98428237e-01   2.03278270e-02   1.43076517e-02
   1.47713872e-04   4.32862326e-25   6.35271738e-24   2.41992648e-25
   1.38005324e-25], sum to 1.0000
[2017-11-02 10:06:21,266] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [5.5, 100.0, 6.991666666666666, 287.5, 0.0, 0.0, 0.5, 15.82048319109178, 18.0, 21.03403020660399, 21.5, 0.0, 0.0], 
actual action is [0.5, 18], 
sim time next is 1291200.0000, 
raw observation next is [5.5, 100.0, 7.333333333333332, 280.0, 0.0, 0.0, 0.5, 16.29728541516962, 18.0, 20.98086429845047, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.47435897435897434, 1.0, 0.6666666666666665, 0.7777777777777778, 0.0, 0.0, 0.5083333333333333, 0.16297285415169618, 0.0, 0.4258377569214957, 0.5, 0.0, 0.0], 
reward next is -0.0742. 
=============================================
[2017-11-02 10:06:22,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.35522805e-15   4.39473212e-01   4.14122753e-02   1.08297747e-02
   2.26382515e-04   2.06128545e-02   4.69719470e-01   8.65112897e-03
   9.07488633e-03], sum to 1.0000
[2017-11-02 10:06:22,946] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.1, 92.0, 6.1, 251.6666666666667, 0.0, 0.0, 7.15, 15.59509855497787, 21.0, 20.59512054868945, 21.5, 0.0, 21.05681014945818], 
actual action is [7.1, 19.0], 
sim time next is 1311300.0000, 
raw observation next is [2.05, 92.0, 6.1, 252.5, 0.0, 0.0, 7.1, 15.70718558226544, 19.0, 20.58680981583733, 21.5, 0.0, 19.40100816285095], 
processed observation next is [0.0, 0.17391304347826086, 0.3858974358974359, 0.92, 0.5545454545454546, 0.7013888888888888, 0.0, 0.0, 0.6183333333333334, 0.1570718558226544, 0.14285714285714285, 0.369544259405333, 0.5, 0.0, 0.22824715485707], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:06:26,932] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.20586502e-15   2.00968096e-03   6.83029473e-04   1.57597839e-04
   1.34780439e-05   1.69758588e-01   5.38077593e-01   5.03400601e-02
   2.38960013e-01], sum to 1.0000
[2017-11-02 10:06:26,962] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.1, 92.0, 5.933333333333334, 273.3333333333334, 115.3333333333333, 0.0, 6.1, 13.00616285593244, 19.0, 22.08014701569538, 22.7, 1.0, 12.21006806186959], 
actual action is [6.1, 20.0], 
sim time next is 1340700.0000, 
raw observation next is [1.1, 92.0, 5.766666666666666, 274.1666666666666, 114.1666666666667, 0.0, 6.1, 13.24237619599672, 20.0, 22.01026317133782, 22.7, 1.0, 11.58871062757622], 
processed observation next is [0.0, 0.5217391304347826, 0.36153846153846153, 0.92, 0.5242424242424242, 0.7615740740740738, 0.30202821869488544, 0.0, 0.6016666666666667, 0.1324237619599672, 0.2857142857142857, 0.5728947387625455, 0.6714285714285714, 1.0, 0.136337772089132], 
reward next is -0.1359. 
=============================================
[2017-11-02 10:06:31,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 70193: loss 78.4387
[2017-11-02 10:06:36,140] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4500, global step 70820: loss -27.7244
[2017-11-02 10:06:37,223] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 70967: loss 184.9178
[2017-11-02 10:06:39,483] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4500, global step 71312: loss 1.8601
[2017-11-02 10:06:39,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71331: loss -3.7140
[2017-11-02 10:06:39,987] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4500, global step 71368: loss 27.2824
[2017-11-02 10:06:41,933] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.58454263e-01   3.81062508e-01   2.82198131e-01   7.32996985e-02
   4.98536741e-03   4.45943279e-20   2.04397699e-19   4.16034245e-21
   2.16250377e-20], sum to 1.0000
[2017-11-02 10:06:42,020] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 6.433333333333334, 298.3333333333333, 0.0, 0.0, 5.5, 9.490769864090149, 20.0, 21.93643259142665, 22.7, 1.0, 51.77537784672005], 
actual action is [-4.5, 18], 
sim time next is 1365300.0000, 
raw observation next is [0.5, 96.0, 6.35, 297.5, 0.0, 0.0, -4.5, 10.31537042506316, 18.0, 22.15216779162984, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.34615384615384615, 0.96, 0.5772727272727273, 0.8263888888888888, 0.0, 0.0, 0.425, 0.1031537042506316, 0.0, 0.5931668273756914, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0103. 
=============================================
[2017-11-02 10:06:42,139] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71664: loss 19.7060
[2017-11-02 10:06:43,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71861: loss -50.2697
[2017-11-02 10:06:46,337] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4500, global step 72239: loss -26.7788
[2017-11-02 10:06:49,759] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72613: loss 77.6487
[2017-11-02 10:06:50,141] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72657: loss 50.2956
[2017-11-02 10:06:51,278] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72808: loss -17.3970
[2017-11-02 10:06:51,448] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4500, global step 72835: loss 3.5689
[2017-11-02 10:06:51,818] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72875: loss 10.0734
[2017-11-02 10:06:51,873] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72879: loss -9.6450
[2017-11-02 10:06:52,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.44760977e-05   3.41622680e-01   5.90613425e-01   5.87505437e-02
   8.91886372e-03   3.69294179e-12   2.76208084e-11   2.94661702e-13
   5.29280179e-12], sum to 1.0000
[2017-11-02 10:06:52,954] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.1, 92.66666666666667, 6.466666666666667, 290.0, 39.66666666666667, 0.0, -3.9, 10.2833184456401, 18.0, 22.57869416654244, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1352700.0000, 
raw observation next is [1.1, 92.75, 6.374999999999999, 290.0, 37.5, 0.0, -3.9, 10.65436224362834, 18.0, 22.6409301003651, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.36153846153846153, 0.9275, 0.5795454545454545, 0.8055555555555556, 0.0992063492063492, 0.0, 0.435, 0.1065436224362834, 0.0, 0.6629900143378714, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:06:53,515] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 73057: loss 16.8124
[2017-11-02 10:06:56,382] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.03997861e-03   2.99281508e-01   6.49396122e-01   4.13097739e-02
   5.97270625e-03   9.20407812e-16   2.53892451e-15   2.99105598e-17
   6.17630908e-16], sum to 1.0000
[2017-11-02 10:06:56,496] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.35, 97.91666666666666, 2.875, 258.3333333333333, 0.0, 0.0, 4.7, 10.57418964500963, 23.0, 22.07860631183017, 21.5, 0.0, 62.63203812915793], 
actual action is [4.65, 22.0], 
sim time next is 1395600.0000, 
raw observation next is [-0.4, 98.33333333333333, 2.7, 266.6666666666667, 0.0, 0.0, 4.65, 10.46024017125626, 22.0, 21.96201518014223, 21.5, 0.0, 34.77026808022548], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.3230769230769231, 0.9833333333333333, 0.24545454545454548, 0.7407407407407408, 0.0, 0.0, 0.5775, 0.10460240171256259, 0.5714285714285714, 0.5660021685917472, 0.5, 0.0, 0.4090619774144174], 
reward next is -0.3682. 
=============================================
[2017-11-02 10:06:57,444] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99750316e-01   8.13273364e-05   1.51185552e-04   1.55405542e-05
   1.58321313e-06   6.71385679e-29   2.01039088e-28   2.43004794e-30
   5.64742664e-29], sum to 1.0000
[2017-11-02 10:06:57,538] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 5.683333333333333, 281.6666666666666, 0.0, 0.0, -4.5, 11.76359624645229, 18.0, 22.82617909451553, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 1361400.0000, 
raw observation next is [0.5, 96.0, 5.766666666666667, 283.3333333333334, 0.0, 0.0, -4.5, 13.11878897017948, 18.0, 22.50486796744199, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.34615384615384615, 0.96, 0.5242424242424243, 0.7870370370370373, 0.0, 0.0, 0.425, 0.1311878897017948, 0.0, 0.643552566777427, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0131. 
=============================================
[2017-11-02 10:06:58,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99713004e-01   1.03926526e-04   1.57567265e-04   2.22491199e-05
   3.21803100e-06   3.46240171e-28   6.03659582e-28   1.11925449e-29
   2.16671572e-28], sum to 1.0000
[2017-11-02 10:06:58,419] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 2.5, 360.0, 9.0, 0.0, -5.6, 15.72117380217466, 18.0, 21.52914038105036, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1411500.0000, 
raw observation next is [-0.6, 99.99999999999999, 2.458333333333333, 331.6666666666667, 10.5, 0.0, -5.6, 16.18538512040792, 18.0, 21.38217238537975, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 0.9999999999999999, 0.22348484848484845, 0.9212962962962964, 0.027777777777777776, 0.0, 0.4066666666666666, 0.1618538512040792, 0.0, 0.4831674836256786, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:10,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.50274829e-35   4.11928864e-35   2.04594127e-37
   2.60071690e-37   4.50793445e-01   5.05111277e-01   5.64838992e-03
   3.84469070e-02], sum to 1.0000
[2017-11-02 10:07:10,197] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.3, 97.5, 3.05, 250.0, 0.0, 0.0, 4.75, 15.47079987462473, 18.5, 21.09560083957181, 21.5, 0.0, 59.23644793399168], 
actual action is [4.7, 19.5], 
sim time next is 1395300.0000, 
raw observation next is [-0.35, 97.91666666666666, 2.875, 258.3333333333333, 0.0, 0.0, 4.7, 15.18421301004311, 19.5, 21.01591816174631, 21.5, 0.0, 32.74285031756096], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.3243589743589744, 0.9791666666666665, 0.26136363636363635, 0.7175925925925926, 0.0, 0.0, 0.5783333333333334, 0.1518421301004311, 0.21428571428571427, 0.4308454516780443, 0.5, 0.0, 0.3852100037360113], 
reward next is -0.4158. 
=============================================
[2017-11-02 10:07:12,780] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.96046233e-02   1.36282548e-01   8.31095040e-01   1.10274432e-02
   1.99030875e-03   8.87651332e-22   2.73499293e-21   3.00721571e-23
   3.21221207e-22], sum to 1.0000
[2017-11-02 10:07:12,923] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 100.0, 3.325, 345.0, 0.0, 0.0, -5.6, 11.31951987783393, 18.0, 22.09403036588319, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1408800.0000, 
raw observation next is [-0.6, 100.0, 3.233333333333333, 346.6666666666667, 0.0, 0.0, -5.6, 12.63216128532892, 18.0, 22.10497540740156, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.317948717948718, 1.0, 0.2939393939393939, 0.962962962962963, 0.0, 0.0, 0.4066666666666666, 0.1263216128532892, 0.0, 0.586425058200223, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0126. 
=============================================
[2017-11-02 10:07:17,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.99994993e-01   1.36194490e-06   3.48124604e-06   2.08593491e-07
   1.72083059e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:17,094] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 99.99999999999999, 3.508333333333333, 341.6666666666666, 0.0, 0.0, -5.6, 14.63190371187814, 18.0, 21.10547175278196, 21.5, 0.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1408200.0000, 
raw observation next is [-0.6, 100.0, 3.416666666666667, 343.3333333333334, 0.0, 0.0, -5.6, 16.19805421283907, 18.0, 21.07395269828924, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.317948717948718, 1.0, 0.3106060606060606, 0.9537037037037039, 0.0, 0.0, 0.4066666666666666, 0.16198054212839072, 0.0, 0.4391360997556057, 0.5, 0.0, 0.0], 
reward next is -0.0609. 
=============================================
[2017-11-02 10:07:18,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.48629682e-03   3.54262561e-01   5.88661253e-01   4.52019162e-02
   4.38795844e-03   2.50573894e-19   9.73206218e-19   1.76845609e-20
   5.04523046e-19], sum to 1.0000
[2017-11-02 10:07:18,275] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.3499999999999999, 97.91666666666666, 2.208333333333333, 157.5, 43.66666666666666, 0.0, -5.4, 14.93003354279095, 18.0, 21.78778218110059, 22.7, 1.0, 0.0], 
actual action is [-5.35, 18], 
sim time next is 1416600.0000, 
raw observation next is [-0.3, 97.5, 2.25, 185.0, 46.0, 0.0, -5.35, 15.51207908610062, 18.0, 21.73815633890147, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.32564102564102565, 0.975, 0.20454545454545456, 0.5138888888888888, 0.12169312169312169, 0.0, 0.41083333333333333, 0.1551207908610062, 0.0, 0.5340223341287812, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:19,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.14128881e-27   1.27432043e-09   2.31066721e-09   8.07689679e-11
   9.56732003e-12   7.01455101e-02   2.95233518e-01   7.05041504e-03
   6.27570510e-01], sum to 1.0000
[2017-11-02 10:07:20,071] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.3499999999999999, 97.91666666666666, 2.208333333333333, 157.5, 43.66666666666666, 0.0, -5.4, 14.74388653639469, 18.0, 21.19356399995094, 22.7, 1.0, 0.0], 
actual action is [4.65, 23.0], 
sim time next is 1416600.0000, 
raw observation next is [-0.3, 97.5, 2.25, 185.0, 46.0, 0.0, 4.65, 13.89754308146965, 23.0, 21.31858896823022, 22.7, 1.0, 37.72226710805126], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.32564102564102565, 0.975, 0.20454545454545456, 0.5138888888888888, 0.12169312169312169, 0.0, 0.5775, 0.1389754308146965, 0.7142857142857143, 0.4740841383186028, 0.6714285714285714, 1.0, 0.44379137774177957], 
reward next is -0.4133. 
=============================================
[2017-11-02 10:07:24,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-31.33129883]
 [-31.87112808]
 [-32.56492615]
 [-32.39326477]
 [-32.46318054]], R is [[-31.25654793]
 [-31.80643272]
 [-31.97783661]
 [-31.82945824]
 [-31.82286453]].
[2017-11-02 10:07:26,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.30221448e-27   1.46744839e-09   1.96823025e-09   1.02582401e-10
   1.46062225e-11   3.02585155e-01   5.33457458e-01   9.64294281e-03
   1.54314443e-01], sum to 1.0000
[2017-11-02 10:07:26,338] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.6, 92.0, 1.666666666666667, 186.6666666666667, 0.0, 0.0, -3.4, 17.34533881820777, 18.0, 21.17139254543813, 21.5, 0.0, 0.0], 
actual action is [6.6, 19.0], 
sim time next is 1471500.0000, 
raw observation next is [1.6, 92.0, 1.875, 210.0, 0.0, 0.0, 6.6, 17.0903949192039, 19.0, 21.12019727863653, 21.5, 0.0, 29.67225118435947], 
processed observation next is [0.3333333333333333, 0.0, 0.37435897435897436, 0.92, 0.17045454545454544, 0.5833333333333334, 0.0, 0.0, 0.61, 0.170903949192039, 0.14285714285714285, 0.4457424683766474, 0.5, 0.0, 0.3490853080512879], 
reward next is -0.3684. 
=============================================
[2017-11-02 10:07:31,127] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 78150: loss 38.9882
[2017-11-02 10:07:39,121] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5000, global step 79088: loss 23.6058
[2017-11-02 10:07:39,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79154: loss -5.9902
[2017-11-02 10:07:39,641] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79160: loss 8.1382
[2017-11-02 10:07:43,063] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5000, global step 79597: loss 62.6531
[2017-11-02 10:07:43,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-32.75443649]
 [-31.4433136 ]
 [-31.74973297]
 [-31.24187469]
 [-31.75724602]], R is [[-30.81072235]
 [-31.08518791]
 [-30.77433586]
 [-30.46659279]
 [-30.58859634]].
[2017-11-02 10:07:43,875] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79720: loss 11.9115
[2017-11-02 10:07:44,696] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79856: loss -11.1761
[2017-11-02 10:07:45,071] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5000, global step 79915: loss -83.8637
[2017-11-02 10:07:45,948] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80066: loss -19.5830
[2017-11-02 10:07:46,890] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5000, global step 80239: loss -183.5683
[2017-11-02 10:07:48,921] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80605: loss -138.0118
[2017-11-02 10:07:49,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.62607743e-19   1.12516144e-19   7.35450887e-21
   1.61744577e-21   2.02804029e-01   7.17468381e-01   1.29111297e-02
   6.68164641e-02], sum to 1.0000
[2017-11-02 10:07:49,312] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, -3.9, 23.84773499278872, 18.0, 20.16268537822132, 22.7, 1.0, 0.0], 
actual action is [6.1, 19.0], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, 6.1, 20.29957708189389, 19.0, 20.12797275834634, 22.7, 1.0, 75.85476451906435], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.6016666666666667, 0.2029957708189389, 0.14285714285714285, 0.3039961083351912, 0.6714285714285714, 1.0, 0.8924089943419334], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:50,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99988556e-01   7.45980924e-06   2.51478809e-06   1.44385695e-06
   5.47777290e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:50,338] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, 6.1, 21.62381185009116, 19.0, 20.31029892983119, 22.7, 1.0, 51.55877587939803], 
actual action is [-3.9, 18], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, -3.9, 22.46168837329514, 18.0, 20.31281585104623, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.435, 0.22461688373295138, 0.0, 0.3304022644351759, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:50,687] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80930: loss 12.0177
[2017-11-02 10:07:50,955] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80955: loss 85.3874
[2017-11-02 10:07:51,732] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-19.58183479]
 [-19.37526131]
 [-23.00914574]
 [-22.38502312]
 [-20.11676216]], R is [[-18.81581306]
 [-18.63809586]
 [-18.46231842]
 [-18.28847122]
 [-18.11653328]].
[2017-11-02 10:07:51,832] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99982834e-01   1.21758358e-05   3.49248330e-06   1.37764596e-06
   9.27143304e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:51,845] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 81059: loss 119.9539
[2017-11-02 10:07:51,848] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, -3.9, 24.26988313766037, 18.0, 20.21615918874355, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, -3.9, 25.51833789460747, 18.0, 20.11757292995636, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.435, 0.2551833789460747, 0.0, 0.3025104185651943, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:52,857] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 81215: loss 4.4634
[2017-11-02 10:07:53,896] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5000, global step 81378: loss -3.2915
[2017-11-02 10:07:56,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99308109e-01   4.24094527e-04   1.16547606e-04   1.33426904e-04
   1.78780647e-05   3.88343799e-25   3.97892960e-25   4.44235494e-26
   3.34866339e-26], sum to 1.0000
[2017-11-02 10:07:56,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.033333333333333, 94.0, 1.0, 46.66666666666667, 90.0, 706.6666666666666, -1.058333333333334, 13.3692731280638, 18.0, 22.51500383403704, 22.7, 1.0, 0.0], 
actual action is [-0.9666666666666668, 18], 
sim time next is 1511100.0000, 
raw observation next is [4.125, 93.75, 0.75, 35.0, 91.0, 706.0, -0.9666666666666668, 13.26732298849205, 18.0, 22.54146722123, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.4391025641025641, 0.9375, 0.06818181818181818, 0.09722222222222222, 0.24074074074074073, 0.706, 0.48388888888888887, 0.1326732298849205, 0.0, 0.6487810316042858, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:08:04,547] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   7.44361280e-38   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.09357452e-02   9.68137562e-01   1.03499638e-02
   1.05766691e-02], sum to 1.0000
[2017-11-02 10:08:04,610] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [4.516666666666667, 85.41666666666666, 2.883333333333333, 90.0, 0.0, 0.0, -0.5, 16.93351668611997, 18.0, 20.93779165781799, 21.5, 0.0, 0.0], 
actual action is [9.516666666666666, 19.0], 
sim time next is 1568400.0000, 
raw observation next is [4.533333333333333, 85.33333333333334, 2.866666666666666, 90.0, 0.0, 0.0, 9.516666666666666, 16.35022278430492, 19.0, 20.84801632249611, 21.5, 0.0, 33.92535348093717], 
processed observation next is [0.5, 0.13043478260869565, 0.44957264957264953, 0.8533333333333334, 0.2606060606060605, 0.25, 0.0, 0.0, 0.6586111111111111, 0.16350222784304919, 0.14285714285714285, 0.4068594746423016, 0.5, 0.0, 0.39912180565808436], 
reward next is -0.4524. 
=============================================
[2017-11-02 10:08:05,464] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00554886
  0.98472679  0.00565312  0.00407129], sum to 1.0000
[2017-11-02 10:08:05,486] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [4.658333333333333, 84.41666666666666, 2.741666666666667, 90.0, 0.0, 0.0, 9.65, 18.91091381610538, 19.5, 20.49363354789363, 21.5, 0.0, 10.39650329903321], 
actual action is [9.658333333333333, 20.5], 
sim time next is 1572000.0000, 
raw observation next is [4.666666666666667, 84.33333333333334, 2.733333333333333, 90.0, 0.0, 0.0, 9.658333333333333, 19.25640310865533, 20.5, 20.44444092623161, 21.5, 0.0, 10.02532820134914], 
processed observation next is [0.5, 0.17391304347826086, 0.45299145299145305, 0.8433333333333334, 0.24848484848484845, 0.25, 0.0, 0.0, 0.6609722222222222, 0.19256403108655332, 0.35714285714285715, 0.3492058466045158, 0.5, 0.0, 0.11794503766293106], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:06,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.74814506e-35   8.18904542e-14   2.17180942e-15   7.17781649e-15
   8.20911722e-16   2.16014888e-02   9.67547178e-01   5.59055014e-03
   5.26081864e-03], sum to 1.0000
[2017-11-02 10:08:06,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [6.324999999999999, 77.5, 3.725, 105.0, 0.0, 0.0, 11.41666666666667, 15.45323454270451, 22.0, 20.89189706792796, 21.5, 0.0, 13.44109764701117], 
actual action is [11.325, 23.0], 
sim time next is 1549200.0000, 
raw observation next is [6.233333333333333, 78.0, 3.766666666666667, 106.6666666666667, 0.0, 0.0, 11.325, 14.69898646166163, 23.0, 20.87143964498544, 21.5, 0.0, 36.8501958923317], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.4931623931623932, 0.78, 0.34242424242424246, 0.2962962962962964, 0.0, 0.0, 0.6887500000000001, 0.14698986461661628, 0.7142857142857143, 0.41020566356934857, 0.5, 0.0, 0.4335317163803729], 
reward next is -0.4800. 
=============================================
[2017-11-02 10:08:09,238] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99994755e-01   3.13823602e-06   1.10509625e-07   1.81527412e-06
   1.23829125e-07   8.17030875e-33   8.19275305e-32   9.79922397e-34
   8.58101142e-34], sum to 1.0000
[2017-11-02 10:08:09,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 82.0, 3.933333333333334, 123.3333333333333, 0.0, 0.0, 0.375, 14.77510772274261, 18.0, 21.50894191072649, 21.5, 0.0, 0.0], 
actual action is [0.3333333333333339, 18], 
sim time next is 1553100.0000, 
raw observation next is [5.291666666666666, 82.0, 3.891666666666666, 124.1666666666667, 0.0, 0.0, 0.3333333333333339, 15.58957114990151, 18.0, 21.48580509705797, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 1.0, 0.46901709401709396, 0.82, 0.35378787878787876, 0.3449074074074075, 0.0, 0.0, 0.5055555555555556, 0.1558957114990151, 0.0, 0.4979721567225671, 0.5, 0.0, 0.0], 
reward next is -0.0020. 
=============================================
[2017-11-02 10:08:09,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.49978517e-07   7.78572023e-01   1.91995297e-02   1.64789036e-01
   3.42237316e-02   2.20616086e-04   2.87192781e-03   6.86949716e-05
   5.37861815e-05], sum to 1.0000
[2017-11-02 10:08:09,295] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [10.13333333333333, 62.66666666666667, 5.800000000000001, 156.6666666666667, 0.0, 0.0, 5.225, 14.12309078790137, 18.0, 21.48144663238067, 22.7, 1.0, 0.0], 
actual action is [5.133333333333329, 18], 
sim time next is 1621500.0000, 
raw observation next is [10.04166666666667, 63.08333333333333, 5.449999999999999, 158.3333333333333, 0.0, 0.0, 5.133333333333329, 14.42576572739794, 18.0, 21.39257944991812, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5908119658119659, 0.6308333333333332, 0.49545454545454537, 0.43981481481481466, 0.0, 0.0, 0.5855555555555554, 0.1442576572739794, 0.0, 0.48465420713116003, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0144. 
=============================================
[2017-11-02 10:08:17,300] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999046e-01   7.53426946e-07   4.01170404e-08   2.30956303e-07
   4.21836717e-08   2.01918617e-27   4.30878631e-26   4.15045462e-28
   3.55712087e-28], sum to 1.0000
[2017-11-02 10:08:17,316] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.975000000000001, 62.75, 5.1, 112.5, 204.0, 128.25, 3.833333333333334, 13.54236797358316, 18.0, 21.93198401331663, 22.7, 1.0, 0.0], 
actual action is [3.9750000000000014, 18], 
sim time next is 1594200.0000, 
raw observation next is [9.116666666666667, 62.16666666666666, 5.1, 111.6666666666667, 205.3333333333333, 141.6666666666667, 3.975000000000001, 13.37250253039468, 18.0, 21.96997159955009, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.5670940170940171, 0.6216666666666666, 0.4636363636363636, 0.3101851851851853, 0.5432098765432097, 0.14166666666666672, 0.56625, 0.1337250253039468, 0.0, 0.567138799935727, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 10:08:17,476] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 85572: loss -100.5131
[2017-11-02 10:08:19,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99996543e-01   2.71608747e-06   9.71414025e-08   4.80340532e-07
   9.12169256e-08   1.24743253e-25   2.51311659e-24   3.50675358e-26
   1.30554831e-26], sum to 1.0000
[2017-11-02 10:08:19,962] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.38333333333333, 53.5, 6.283333333333333, 143.3333333333333, 33.66666666666667, 24.66666666666667, 7.475, 8.951225404854945, 18.0, 22.91800752928814, 22.7, 1.0, 0.0], 
actual action is [7.383333333333329, 18], 
sim time next is 1616100.0000, 
raw observation next is [12.29166666666667, 53.75, 6.191666666666666, 141.6666666666667, 29.58333333333334, 21.58333333333334, 7.383333333333329, 8.978633044768287, 18.0, 22.89513748412397, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.6485042735042736, 0.5375, 0.5628787878787879, 0.39351851851851866, 0.07826278659611995, 0.02158333333333334, 0.6230555555555555, 0.08978633044768287, 0.0, 0.699305354874853, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0090. 
=============================================
[2017-11-02 10:08:22,234] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5500, global step 86390: loss -50.6115
[2017-11-02 10:08:22,613] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   3.34626567e-22   2.00157737e-24   6.81936016e-24
   1.39111420e-24   1.09019084e-03   9.98362005e-01   1.98018111e-04
   3.49788344e-04], sum to 1.0000
[2017-11-02 10:08:22,638] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [7.325, 75.5, 7.575, 120.0, 0.0, 0.0, 2.366666666666667, 23.00069116317854, 18.0, 19.45549391348126, 21.5, 0.0, 0.0], 
actual action is [12.325, 19.0], 
sim time next is 1630200.0000, 
raw observation next is [7.283333333333333, 75.66666666666667, 7.616666666666667, 120.0, 0.0, 0.0, 12.325, 23.06152392729355, 19.0, 19.42384050946776, 21.5, 0.0, 7.619291502891101], 
processed observation next is [0.5, 0.8695652173913043, 0.52008547008547, 0.7566666666666667, 0.6924242424242425, 0.3333333333333333, 0.0, 0.0, 0.7054166666666667, 0.2306152392729355, 0.14285714285714285, 0.2034057870668227, 0.5, 0.0, 0.08963872356342471], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:24,871] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 86819: loss -12.5739
[2017-11-02 10:08:25,256] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99991655e-01   5.30161151e-06   3.32578395e-07   2.28332806e-06
   3.79364707e-07   1.58560820e-21   1.75092971e-20   4.12269589e-22
   2.87415576e-22], sum to 1.0000
[2017-11-02 10:08:25,325] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.61666666666667, 49.66666666666666, 7.024999999999999, 136.6666666666667, 160.25, 72.33333333333334, 8.43333333333334, 12.63087444895173, 18.0, 22.0707565388578, 22.7, 1.0, 0.0], 
actual action is [8.61666666666667, 18], 
sim time next is 1602000.0000, 
raw observation next is [13.8, 49.0, 7.2, 140.0, 162.5, 62.0, 8.61666666666667, 12.60467282238093, 18.0, 22.06519131654625, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.6871794871794872, 0.49, 0.6545454545454545, 0.3888888888888889, 0.4298941798941799, 0.062, 0.6436111111111112, 0.1260467282238093, 0.0, 0.5807416166494644, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0126. 
=============================================
[2017-11-02 10:08:26,298] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87085: loss 87.3450
[2017-11-02 10:08:29,216] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5500, global step 87560: loss 213.4645
[2017-11-02 10:08:29,550] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5500, global step 87600: loss -364.2876
[2017-11-02 10:08:31,462] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87893: loss 159.8339
[2017-11-02 10:08:31,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87920: loss -4.4293
[2017-11-02 10:08:32,834] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88136: loss 43.7014
[2017-11-02 10:08:35,389] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5500, global step 88488: loss -39.9499
[2017-11-02 10:08:36,019] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88549: loss -39.8894
[2017-11-02 10:08:37,875] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99945998e-01   2.45754509e-05   1.09891812e-06   2.52659593e-05
   3.13071746e-06   2.44233767e-29   1.62966460e-26   3.42716939e-30
   3.54525147e-30], sum to 1.0000
[2017-11-02 10:08:37,877] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88715: loss 417.8937
[2017-11-02 10:08:37,900] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.85, 231.6666666666666, 81.66666666666667, 0.0, 6.1, 11.78909812608369, 19.0, 22.49788075345614, 22.7, 1.0, 32.49226562577604], 
actual action is [-3.9, 18], 
sim time next is 1693800.0000, 
raw observation next is [1.1, 88.0, 6.9, 230.0, 80.0, 0.0, -3.9, 12.34354786760922, 18.0, 22.5279475694593, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.36153846153846153, 0.88, 0.6272727272727273, 0.6388888888888888, 0.21164021164021163, 0.0, 0.435, 0.1234354786760922, 0.0, 0.6468496527799, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0123. 
=============================================
[2017-11-02 10:08:38,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.85295484e-09   7.60268390e-01   2.52253339e-02   1.56145111e-01
   4.19951156e-02   2.95087993e-05   1.63245164e-02   6.22704829e-06
   5.77421270e-06], sum to 1.0000
[2017-11-02 10:08:39,099] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [4.575, 92.0, 7.7, 250.0, 0.0, 0.0, 9.716666666666667, 14.15467082973085, 19.0, 20.80097607913025, 22.7, 1.0, 25.25431331930719], 
actual action is [-0.4249999999999998, 18], 
sim time next is 1668000.0000, 
raw observation next is [4.433333333333334, 92.0, 7.7, 250.0, 0.0, 0.0, -0.4249999999999998, 15.4565170003669, 18.0, 20.72499606074639, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.44700854700854703, 0.92, 0.7000000000000001, 0.6944444444444444, 0.0, 0.0, 0.49291666666666667, 0.15456517000366898, 0.0, 0.3892851515351983, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:40,327] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 89016: loss 61.5063
[2017-11-02 10:08:41,101] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5500, global step 89128: loss 54.2766
[2017-11-02 10:08:42,007] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 89263: loss -174.2468
[2017-11-02 10:08:43,186] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 89462: loss -16.3707
[2017-11-02 10:08:44,689] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   6.41745229e-13   3.99139408e-14   7.13040412e-13
   5.38052269e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:08:44,777] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 7.575, 237.5, 0.0, 0.0, -3.9, 23.01539115437125, 18.0, 20.74885326528489, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1713000.0000, 
raw observation next is [1.1, 88.0, 7.616666666666667, 238.3333333333333, 0.0, 0.0, -3.9, 23.95192519698118, 18.0, 20.64739458301725, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.88, 0.6924242424242425, 0.6620370370370369, 0.0, 0.0, 0.435, 0.2395192519698118, 0.0, 0.37819922614532125, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:48,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.61146999e-06   9.99854326e-01   3.63545369e-05
   1.05684441e-04], sum to 1.0000
[2017-11-02 10:08:49,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.5, 92.0, 8.7, 247.5, 0.0, 0.0, -4.5, 26.26024428155825, 18.0, 19.93502250429392, 21.5, 0.0, 0.0], 
actual action is [5.5, 19.0], 
sim time next is 1729200.0000, 
raw observation next is [0.5, 92.0, 8.7, 246.6666666666667, 0.0, 0.0, 5.5, 25.44248849184235, 19.0, 19.92311170298843, 21.5, 0.0, 37.58268286986797], 
processed observation next is [0.8333333333333334, 0.0, 0.34615384615384615, 0.92, 0.7909090909090909, 0.6851851851851853, 0.0, 0.0, 0.5916666666666667, 0.2544248849184235, 0.14285714285714285, 0.27473024328406126, 0.5, 0.0, 0.4421492102337409], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:49,986] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-91.06332397]
 [-94.24360657]
 [-97.46411133]
 [-92.98303223]
 [-90.82104492]], R is [[-91.34546661]
 [-91.43201447]
 [-91.51769257]
 [-91.60251617]
 [-91.68649292]].
[2017-11-02 10:08:50,417] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-118.73893738]
 [-119.08853149]
 [-107.63809204]
 [-111.34016418]
 [-111.03089905]], R is [[-114.94807434]
 [-114.79859161]
 [-114.65060425]
 [-114.50409698]
 [-114.35905457]].
[2017-11-02 10:09:01,124] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.52325473e-05   9.99630809e-01   2.05740536e-04
   1.08212706e-04], sum to 1.0000
[2017-11-02 10:09:01,343] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.6, 84.33333333333333, 9.533333333333333, 250.0, 0.0, 0.0, 4.4, 16.82125048551058, 20.0, 20.72812174979041, 21.5, 0.0, 48.51497538456263], 
actual action is [4.4, 21.0], 
sim time next is 1745100.0000, 
raw observation next is [-0.6, 84.0, 9.575, 250.0, 0.0, 0.0, 4.4, 16.54757770217177, 21.0, 20.83800494707392, 21.5, 0.0, 42.4641527821178], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.317948717948718, 0.84, 0.8704545454545454, 0.6944444444444444, 0.0, 0.0, 0.5733333333333334, 0.16547577702171767, 0.42857142857142855, 0.40542927815341706, 0.5, 0.0, 0.4995782680249153], 
reward next is -0.5442. 
=============================================
[2017-11-02 10:09:01,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   3.06066472e-35   3.63420950e-37   1.97015892e-36
   1.05740768e-33   1.44256672e-04   9.99589503e-01   2.13366773e-04
   5.29041245e-05], sum to 1.0000
[2017-11-02 10:09:01,730] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.5, 92.0, 8.2, 240.0, 0.0, 0.0, 5.5, 18.29134985947126, 20.0, 20.92217016256524, 21.5, 0.0, 23.53140773249872], 
actual action is [5.5, 21.0], 
sim time next is 1721100.0000, 
raw observation next is [0.4583333333333333, 92.25, 8.241666666666665, 240.0, 0.0, 0.0, 5.5, 18.9169297037435, 21.0, 20.87954639922356, 21.5, 0.0, 22.79105338562747], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.3450854700854701, 0.9225, 0.7492424242424242, 0.6666666666666666, 0.0, 0.0, 0.5916666666666667, 0.18916929703743499, 0.42857142857142855, 0.4113637713176515, 0.5, 0.0, 0.26813003983091144], 
reward next is -0.3300. 
=============================================
[2017-11-02 10:09:02,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-79.98878479]
 [-77.52418518]
 [-79.51000977]
 [-81.14012909]
 [-82.53195953]], R is [[-80.01891327]
 [-80.21872711]
 [-80.41654205]
 [-80.61238098]
 [-80.80625916]].
[2017-11-02 10:09:16,742] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.49247663e-14   2.39146539e-15   1.08223223e-14
   8.08523279e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:09:16,945] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.95, 84.66666666666666, 9.2, 250.0, 61.75, 0.0, 3.1, 15.240439012506, 25.0, 21.23800818959085, 22.7, 1.0, 45.83124497471122], 
actual action is [3.05, 20.0], 
sim time next is 1762200.0000, 
raw observation next is [-2.0, 85.0, 9.2, 250.0, 65.0, 0.0, 3.05, 14.89889465203885, 20.0, 21.38387356882702, 22.7, 1.0, 56.69881970313654], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.28205128205128205, 0.85, 0.8363636363636363, 0.6944444444444444, 0.17195767195767195, 0.0, 0.5508333333333333, 0.1489889465203885, 0.2857142857142857, 0.4834105098324315, 0.6714285714285714, 1.0, 0.6670449376839593], 
reward next is -0.6152. 
=============================================
[2017-11-02 10:09:20,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.83563184e-03   1.01141185e-02   1.63753575e-03   2.54914607e-03
   9.82863605e-01   1.03685650e-22   3.32067432e-23   8.16203534e-24
   8.34840061e-22], sum to 1.0000
[2017-11-02 10:09:20,502] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 83.33333333333333, 9.241666666666665, 250.8333333333333, 121.9166666666667, 0.0, -7.3, 14.76352900093187, 18.0, 21.92908430649495, 22.7, 1.0, 0.0], 
actual action is [-7.3, 18.0], 
sim time next is 1771200.0000, 
raw observation next is [-2.3, 83.0, 9.2, 250.0, 122.5, 0.0, -7.3, 16.72198671290928, 18.0, 21.85455130824431, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.27435897435897433, 0.83, 0.8363636363636363, 0.6944444444444444, 0.32407407407407407, 0.0, 0.3783333333333333, 0.16721986712909281, 0.0, 0.5506501868920444, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:09:25,121] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 94651: loss 126.4120
[2017-11-02 10:09:30,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.06818106e-25   2.29187940e-08   9.58285113e-08   2.90651503e-09
   7.68053269e-07   7.38865435e-02   1.47989970e-02   5.68050379e-03
   9.05633032e-01], sum to 1.0000
[2017-11-02 10:09:30,594] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 84.0, 9.325, 252.5, 120.75, 0.0, -7.3, 15.7234709664621, 18.0, 22.08548941227658, 22.7, 1.0, 0.0], 
actual action is [2.7, 23.0], 
sim time next is 1770600.0000, 
raw observation next is [-2.3, 83.66666666666667, 9.283333333333331, 251.6666666666667, 121.3333333333333, 0.0, 2.7, 13.86337406162871, 23.0, 21.94656706582222, 22.7, 1.0, 97.16025729057873], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.27435897435897433, 0.8366666666666667, 0.8439393939393938, 0.6990740740740742, 0.3209876543209876, 0.0, 0.545, 0.13863374061628708, 0.7142857142857143, 0.5637952951174598, 0.6714285714285714, 1.0, 1.1430618504773968], 
reward next is -1.0426. 
=============================================
[2017-11-02 10:09:33,663] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6000, global step 95216: loss 39.6269
[2017-11-02 10:09:35,678] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95348: loss -49.0502
[2017-11-02 10:09:35,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95351: loss 58.5360
[2017-11-02 10:09:36,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.13086857e-20   4.49080659e-07   2.03691689e-05   6.56068124e-08
   1.32060213e-05   1.75977141e-01   1.57538541e-02   4.00489429e-03
   8.04230034e-01], sum to 1.0000
[2017-11-02 10:09:36,589] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 85.66666666666667, 9.533333333333333, 256.6666666666667, 115.3333333333333, 0.0, 2.7, 10.68481808746183, 24.0, 22.42905015695743, 22.7, 1.0, 64.57125460665414], 
actual action is [2.7, 24.5], 
sim time next is 1769100.0000, 
raw observation next is [-2.3, 85.33333333333333, 9.491666666666665, 255.8333333333333, 117.1666666666667, 0.0, 2.7, 10.44824335977663, 24.5, 22.53019004453655, 22.7, 1.0, 64.37767300768142], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.27435897435897433, 0.8533333333333333, 0.8628787878787878, 0.710648148148148, 0.3099647266313934, 0.0, 0.545, 0.1044824335977663, 0.9285714285714286, 0.6471700063623642, 0.6714285714285714, 1.0, 0.7573843883256638], 
reward next is -0.6921. 
=============================================
[2017-11-02 10:09:36,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95421: loss 19.5737
[2017-11-02 10:09:37,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.14324976e-24   5.28996180e-10   1.79158679e-08   7.28436408e-11
   1.53673394e-08   1.67976871e-01   1.78445783e-02   4.64510312e-03
   8.09533417e-01], sum to 1.0000
[2017-11-02 10:09:37,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.483333333333333, 86.16666666666667, 9.533333333333333, 250.0, 40.66666666666666, 0.0, 1.558333333333334, 11.979467787068, 25.0, 22.75512082217267, 22.7, 1.0, 65.88410405527], 
actual action is [1.516666666666667, 25], 
sim time next is 1786500.0000, 
raw observation next is [-3.525, 85.75, 9.45, 250.0, 37.5, 0.0, 1.516666666666667, 11.72728020953634, 25.0, 22.77018468008044, 22.7, 1.0, 66.75866129613145], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.24294871794871795, 0.8575, 0.859090909090909, 0.6944444444444444, 0.0992063492063492, 0.0, 0.5252777777777777, 0.11727280209536341, 1.0, 0.6814549542972058, 0.6714285714285714, 1.0, 0.7853960152486053], 
reward next is -0.7186. 
=============================================
[2017-11-02 10:09:38,647] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6000, global step 95558: loss -8.2777
[2017-11-02 10:09:41,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.04707732
  0.00211451  0.00101233  0.94979578], sum to 1.0000
[2017-11-02 10:09:42,037] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.2, 82.5, 8.45, 245.0, 0.0, 0.0, 0.8500000000000014, 10.59853144631717, 25.0, 23.28868508031329, 22.7, 1.0, 63.97420939810313], 
actual action is [0.7999999999999998, 25], 
sim time next is 1794900.0000, 
raw observation next is [-4.25, 82.58333333333334, 8.408333333333333, 245.8333333333333, 0.0, 0.0, 0.7999999999999998, 10.56082923675282, 25.0, 23.30888469781329, 22.7, 1.0, 63.94417481107654], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.22435897435897437, 0.8258333333333334, 0.7643939393939394, 0.6828703703703702, 0.0, 0.0, 0.5133333333333333, 0.1056082923675282, 1.0, 0.7584120996876129, 0.6714285714285714, 1.0, 0.752284409542077], 
reward next is -0.6876. 
=============================================
[2017-11-02 10:09:46,302] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96074: loss 27.3964
[2017-11-02 10:09:48,258] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6000, global step 96221: loss 1.1511
[2017-11-02 10:09:49,320] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96303: loss 0.1748
[2017-11-02 10:09:52,345] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6000, global step 96532: loss 0.1457
[2017-11-02 10:09:55,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   4.03830706e-29   9.04423154e-28   1.26811823e-30
   3.35778784e-28   5.39383441e-02   2.22182181e-03   9.45120584e-03
   9.34388578e-01], sum to 1.0000
[2017-11-02 10:09:55,054] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96740: loss 0.0366
[2017-11-02 10:09:55,164] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 83.0, 9.575, 250.0, 0.0, 0.0, 0.5, 8.917481597832978, 25.0, 23.67709416156361, 21.5, 0.0, 47.75294667719135], 
actual action is [0.5, 25], 
sim time next is 1800000.0000, 
raw observation next is [-4.5, 83.0, 9.7, 250.0, 0.0, 0.0, 0.5, 8.898467871913995, 25.0, 23.66608833694734, 21.5, 0.0, 47.8011292654365], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.21794871794871795, 0.83, 0.8818181818181817, 0.6944444444444444, 0.0, 0.0, 0.5083333333333333, 0.08898467871913995, 1.0, 0.8094411909924771, 0.5, 0.0, 0.5623662266521942], 
reward next is -0.5061. 
=============================================
[2017-11-02 10:09:55,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96749: loss 0.9530
[2017-11-02 10:09:57,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.27252901
  0.05606475  0.02205735  0.64934891], sum to 1.0000
[2017-11-02 10:09:57,486] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.958333333333333, 85.75, 8.783333333333333, 240.8333333333333, 0.0, 0.0, 0.08333333333333304, 8.697696328722593, 25.0, 23.46706126527901, 21.5, 0.0, 47.6910323371233], 
actual action is [0.04166666666666696, 25], 
sim time next is 1803600.0000, 
raw observation next is [-5.0, 86.0, 8.7, 240.0, 0.0, 0.0, 0.04166666666666696, 8.691384455857145, 25.0, 23.45008304505805, 21.5, 0.0, 47.66562975722849], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.20512820512820512, 0.86, 0.7909090909090909, 0.6666666666666666, 0.0, 0.0, 0.5006944444444444, 0.08691384455857146, 1.0, 0.7785832921511501, 0.5, 0.0, 0.5607721147909234], 
reward next is -0.5047. 
=============================================
[2017-11-02 10:10:00,065] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 97107: loss 5.6813
[2017-11-02 10:10:01,687] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 97225: loss -1.2364
[2017-11-02 10:10:04,183] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6000, global step 97433: loss 12.4033
[2017-11-02 10:10:05,419] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 97547: loss 9.5055
[2017-11-02 10:10:07,997] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.82605531e-14   6.39711699e-13   9.41663604e-14
   3.17686930e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:10:08,041] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 71.0, 7.783333333333333, 240.0, 175.3333333333333, 54.66666666666666, 0.5, 19.95838453923189, 19.0, 21.15144356506179, 22.7, 1.0, 79.5984808223297], 
actual action is [-9.5, 18], 
sim time next is 1864500.0000, 
raw observation next is [-4.5, 71.0, 7.741666666666667, 240.0, 176.6666666666667, 58.33333333333334, -9.5, 21.13247992617007, 18.0, 21.14335213558592, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.21794871794871795, 0.71, 0.7037878787878789, 0.6666666666666666, 0.46737213403880085, 0.05833333333333334, 0.3416666666666667, 0.2113247992617007, 0.0, 0.449050305083703, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:10:19,550] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-80.56426239]
 [-80.26311493]
 [-80.04972076]
 [-79.52565765]
 [-81.36893463]], R is [[-79.78635406]
 [-79.58970642]
 [-79.39836884]
 [-79.20790863]
 [-78.97956848]].
[2017-11-02 10:10:20,220] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-83.58181763]
 [-85.07683563]
 [-79.96875   ]
 [-83.02320099]
 [-80.43252563]], R is [[-80.57939911]
 [-80.77360535]
 [-80.96587372]
 [-81.15621948]
 [-81.3446579 ]].
[2017-11-02 10:10:35,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-62.93253708]
 [-62.23078537]
 [-63.04800797]
 [-62.38901901]
 [-62.95936203]], R is [[-62.6243515 ]
 [-62.49840927]
 [-62.37442017]
 [-62.25268936]
 [-62.13407516]].
[2017-11-02 10:10:37,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.46425553e-38   8.36787475e-20   6.63751540e-19   3.18490902e-19
   5.31923456e-18   1.63431335e-02   8.04066420e-01   4.78566326e-02
   1.31733775e-01], sum to 1.0000
[2017-11-02 10:10:37,813] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 77.0, 8.2, 243.3333333333334, 124.6666666666667, 58.16666666666666, -0.5999999999999996, 13.02195042140091, 25.0, 22.33689308833354, 22.7, 1.0, 45.61507425017853], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1851900.0000, 
raw observation next is [-5.6, 76.75, 8.2, 244.1666666666666, 122.3333333333333, 54.58333333333334, -0.5999999999999996, 13.1473346378016, 25.0, 22.32839856148775, 22.7, 1.0, 56.15590541041327], 
processed observation next is [1.0, 0.43478260869565216, 0.18974358974358976, 0.7675, 0.7454545454545454, 0.6782407407407406, 0.3236331569664902, 0.054583333333333345, 0.49, 0.131473346378016, 1.0, 0.6183426516411069, 0.6714285714285714, 1.0, 0.6606577107107443], 
reward next is -0.6077. 
=============================================
[2017-11-02 10:10:50,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-55.17500305]
 [-56.44522476]
 [-57.3824234 ]
 [-58.18151474]
 [-56.48182297]], R is [[-56.18557739]
 [-56.29700089]
 [-56.41321945]
 [-56.53894424]
 [-56.66769409]].
[2017-11-02 10:11:01,967] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 101996: loss 50.2543
[2017-11-02 10:11:06,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00113284
  0.98299003  0.00270827  0.01316886], sum to 1.0000
[2017-11-02 10:11:06,883] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6500, global step 102575: loss 4.6315
[2017-11-02 10:11:06,942] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.9, 86.0, 3.6, 220.0, 59.0, 285.0, -3.949999999999999, 24.24542522491354, 21.0, 19.9576138770289, 22.7, 1.0, 20.58683604212832], 
actual action is [-3.9000000000000004, 22.0], 
sim time next is 1933500.0000, 
raw observation next is [-8.766666666666666, 85.41666666666666, 3.641666666666667, 219.1666666666667, 63.33333333333334, 329.0, -3.9, 22.18033493423093, 22.0, 19.97876361964382, 22.7, 1.0, 61.98270400396465], 
processed observation next is [0.0, 0.391304347826087, 0.10854700854700858, 0.8541666666666665, 0.3310606060606061, 0.6087962962962964, 0.16754850088183423, 0.329, 0.435, 0.2218033493423093, 0.5714285714285714, 0.2826805170919745, 0.6714285714285714, 1.0, 0.7292082823995841], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:11:07,281] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 102614: loss 82.4349
[2017-11-02 10:11:09,652] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99997973e-01   3.65771413e-08   1.00111708e-06   1.29108614e-07
   9.82053280e-07   8.15154844e-29   3.44903277e-27   1.14437217e-28
   2.75881159e-28], sum to 1.0000
[2017-11-02 10:11:09,729] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.5, 73.33333333333333, 5.183333333333334, 220.0, 211.6666666666667, 85.33333333333331, -0.5499999999999998, 14.27770926634545, 19.0, 22.31965542772326, 22.7, 1.0, 23.24510348119224], 
actual action is [-10.5, 18], 
sim time next is 1941300.0000, 
raw observation next is [-5.449999999999999, 72.5, 5.225, 220.0, 216.75, 66.5, -10.5, 14.99485971074225, 18.0, 22.26613144333724, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.1935897435897436, 0.725, 0.475, 0.6111111111111112, 0.5734126984126984, 0.0665, 0.325, 0.1499485971074225, 0.0, 0.6094473490481772, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0150. 
=============================================
[2017-11-02 10:11:12,899] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103148: loss -16.8911
[2017-11-02 10:11:14,682] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6500, global step 103312: loss 45.3296
[2017-11-02 10:11:17,893] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103565: loss -17.8354
[2017-11-02 10:11:22,099] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  8.78025744e-29   7.85511674e-16   7.63691766e-15   4.62992021e-16
   1.05969878e-14   1.03973215e-02   9.79119003e-01   6.32325280e-03
   4.16032691e-03], sum to 1.0000
[2017-11-02 10:11:22,415] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.05, 77.0, 4.35, 260.0, 0.0, 0.0, 0.04166666666666696, 9.018239998007536, 25.0, 23.35935337850861, 22.7, 1.0, 61.6609383019284], 
actual action is [-0.04999999999999982, 25], 
sim time next is 1971300.0000, 
raw observation next is [-5.141666666666667, 78.0, 4.308333333333333, 260.0, 0.0, 0.0, -0.04999999999999982, 9.028475861122242, 25.0, 23.36475056353182, 22.7, 1.0, 61.63683211010908], 
processed observation next is [0.0, 0.8260869565217391, 0.2014957264957265, 0.78, 0.3916666666666666, 0.7222222222222222, 0.0, 0.0, 0.49916666666666665, 0.09028475861122243, 1.0, 0.766392937647403, 0.6714285714285714, 1.0, 0.725139201295401], 
reward next is -0.6617. 
=============================================
[2017-11-02 10:11:23,615] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103971: loss 10.3158
[2017-11-02 10:11:26,137] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6500, global step 104204: loss 25.4254
[2017-11-02 10:11:28,986] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.31498806e-03   9.96292412e-01   8.93324905e-04
   4.99339076e-04], sum to 1.0000
[2017-11-02 10:11:29,093] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 84.33333333333334, 2.833333333333333, 246.6666666666667, 0.0, 0.0, -0.7499999999999991, 10.76652413538454, 25.0, 21.90201940492178, 21.5, 0.0, 44.47044319514609], 
actual action is [-0.7999999999999998, 25], 
sim time next is 2003100.0000, 
raw observation next is [-5.85, 84.66666666666666, 2.791666666666667, 248.3333333333333, 0.0, 0.0, -0.7999999999999998, 10.75386307672991, 25.0, 21.9054770539437, 21.5, 0.0, 44.44620586743118], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.18333333333333335, 0.8466666666666666, 0.25378787878787884, 0.6898148148148147, 0.0, 0.0, 0.48666666666666664, 0.10753863076729911, 1.0, 0.5579252934205284, 0.5, 0.0, 0.5228965396168375], 
reward next is -0.4706. 
=============================================
[2017-11-02 10:11:29,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.38230359e-03   9.96999264e-01   4.44626377e-04
   1.73873937e-04], sum to 1.0000
[2017-11-02 10:11:29,264] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 83.0, 4.199999999999999, 257.5, 0.0, 0.0, -0.6000000000000014, 10.03163280587909, 25.0, 22.68413260025964, 21.5, 0.0, 45.43772966752734], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1984800.0000, 
raw observation next is [-5.6, 83.0, 4.066666666666666, 256.6666666666667, 0.0, 0.0, -0.5999999999999996, 10.01934695515278, 25.0, 22.67942590895108, 21.5, 0.0, 45.35895210004082], 
processed observation next is [0.0, 1.0, 0.18974358974358976, 0.83, 0.3696969696969697, 0.712962962962963, 0.0, 0.0, 0.49, 0.1001934695515278, 1.0, 0.6684894155644402, 0.5, 0.0, 0.5336347305887155], 
reward next is -0.4803. 
=============================================
[2017-11-02 10:11:29,532] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104449: loss -2.2982
[2017-11-02 10:11:31,017] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104578: loss -48.2519
[2017-11-02 10:11:32,290] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104716: loss -31.0212
[2017-11-02 10:11:32,592] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6500, global step 104758: loss 2.8968
[2017-11-02 10:11:34,101] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6500, global step 104950: loss 1.8761
[2017-11-02 10:11:35,965] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 105126: loss 54.9883
[2017-11-02 10:11:36,296] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 105161: loss 35.4915
[2017-11-02 10:11:38,371] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 105348: loss 50.6937
[2017-11-02 10:11:44,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.88571234e-35   7.28557031e-20   3.41759719e-20   3.29340891e-21
   3.04375808e-20   1.51766296e-02   9.76646125e-01   2.82630604e-03
   5.35096135e-03], sum to 1.0000
[2017-11-02 10:11:44,731] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 79.66666666666667, 4.433333333333334, 256.6666666666667, 0.0, 0.0, -0.7499999999999991, 10.8169771870228, 25.0, 22.33978264106647, 21.5, 0.0, 46.44318058675461], 
actual action is [-0.7999999999999998, 25], 
sim time next is 1977900.0000, 
raw observation next is [-5.85, 80.08333333333333, 4.391666666666666, 258.3333333333333, 0.0, 0.0, -0.7999999999999998, 10.58134967847273, 25.0, 22.40682411801815, 21.5, 0.0, 46.02622152535623], 
processed observation next is [0.0, 0.9130434782608695, 0.18333333333333335, 0.8008333333333333, 0.3992424242424242, 0.7175925925925926, 0.0, 0.0, 0.48666666666666664, 0.1058134967847273, 1.0, 0.6295463025740214, 0.5, 0.0, 0.5414849591218379], 
reward next is -0.4873. 
=============================================
[2017-11-02 10:11:54,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02943116
  0.92151934  0.01578706  0.03326247], sum to 1.0000
[2017-11-02 10:11:55,048] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 83.0, 4.433333333333334, 263.3333333333333, 0.0, 0.0, -10.85, 12.94072315911324, 18.0, 22.3846070843145, 21.5, 0.0, 0.0], 
actual action is [-0.7999999999999998, 19.0], 
sim time next is 1982700.0000, 
raw observation next is [-5.749999999999999, 83.0, 4.475, 262.5, 0.0, 0.0, -0.7999999999999998, 12.64814447382977, 19.0, 22.23357468200294, 21.5, 0.0, 49.4286479795695], 
processed observation next is [0.0, 0.9565217391304348, 0.18589743589743593, 0.83, 0.4068181818181818, 0.7291666666666666, 0.0, 0.0, 0.48666666666666664, 0.1264814447382977, 0.14285714285714285, 0.6047963831432769, 0.5, 0.0, 0.5815135056419941], 
reward next is -0.5234. 
=============================================
[2017-11-02 10:11:58,273] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  5.35629551e-14   7.50472609e-08   3.70944448e-08   1.34429197e-08
   3.16338102e-08   2.90715843e-01   2.17443928e-01   4.36271168e-02
   4.48213041e-01], sum to 1.0000
[2017-11-02 10:11:58,382] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 2.666666666666667, 256.6666666666667, 0.0, 0.0, -1.2, 15.18802868652859, 25.0, 20.88616897557592, 21.5, 0.0, 48.33964856719816], 
actual action is [-1.2000000000000002, 25], 
sim time next is 2010300.0000, 
raw observation next is [-6.199999999999999, 87.0, 2.583333333333333, 255.8333333333333, 0.0, 0.0, -1.2, 14.7480521499335, 25.0, 20.89654380846903, 21.5, 0.0, 48.09932529834153], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.17435897435897438, 0.87, 0.23484848484848483, 0.710648148148148, 0.0, 0.0, 0.48000000000000004, 0.147480521499335, 1.0, 0.4137919726384328, 0.5, 0.0, 0.5658744152746062], 
reward next is -0.5955. 
=============================================
[2017-11-02 10:12:02,156] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   3.69912625e-26   2.32760513e-26   5.32942179e-27
   1.97565391e-26   2.34058976e-01   8.90831053e-02   4.05419916e-02
   6.36315942e-01], sum to 1.0000
[2017-11-02 10:12:02,243] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 87.0, 2.75, 257.5, 0.0, 0.0, -1.2, 12.59508642533536, 20.0, 21.40110884520712, 21.5, 0.0, 46.92532008688205], 
actual action is [-1.2000000000000002, 25.0], 
sim time next is 2010000.0000, 
raw observation next is [-6.2, 87.0, 2.666666666666667, 256.6666666666667, 0.0, 0.0, -1.2, 12.5856750337788, 25.0, 21.40704323403346, 21.5, 0.0, 39.29239231099469], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.17435897435897435, 0.87, 0.24242424242424246, 0.712962962962963, 0.0, 0.0, 0.48000000000000004, 0.125856750337788, 1.0, 0.48672046200477986, 0.5, 0.0, 0.46226343895287875], 
reward next is -0.4293. 
=============================================
[2017-11-02 10:12:05,509] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99987841e-01   2.87425587e-06   4.96232997e-06   2.39027077e-06
   1.96258611e-06   5.62717191e-15   5.01318197e-16   7.73996314e-16
   5.83476899e-16], sum to 1.0000
[2017-11-02 10:12:05,574] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.116666666666666, 86.58333333333333, 4.808333333333333, 240.0, 26.66666666666666, 0.0, -1.133333333333334, 17.64636688064407, 24.0, 20.93352577765266, 22.7, 1.0, 23.62384264836788], 
actual action is [-1.1166666666666663, 19.0], 
sim time next is 2017800.0000, 
raw observation next is [-6.1, 86.5, 4.85, 240.0, 29.0, 0.0, -1.116666666666666, 17.01156697215022, 19.0, 20.89372431535621, 22.7, 1.0, 49.86989488495328], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.17692307692307693, 0.865, 0.44090909090909086, 0.6666666666666666, 0.07671957671957672, 0.0, 0.48138888888888887, 0.1701156697215022, 0.14285714285714285, 0.4133891879080299, 0.6714285714285714, 1.0, 0.5867046457053328], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:11,975] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 109830: loss -10.9369
[2017-11-02 10:12:13,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   2.32630565e-29   7.95769818e-29   3.74305162e-30
   7.18065376e-30   3.06150943e-01   2.73137782e-02   5.40106475e-01
   1.26428738e-01], sum to 1.0000
[2017-11-02 10:12:14,046] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 83.0, 3.6, 260.0, 0.0, 0.0, 1.100000000000001, 10.43175767794187, 25.0, 22.52836052555977, 21.5, 0.0, 44.65692749552393], 
actual action is [1.1, 25], 
sim time next is 2065800.0000, 
raw observation next is [-3.9, 82.66666666666667, 3.6, 260.0, 0.0, 0.0, 1.1, 10.30691085170349, 25.0, 22.56258304805082, 21.5, 0.0, 44.60363945732264], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.23333333333333334, 0.8266666666666667, 0.32727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5183333333333333, 0.10306910851703491, 1.0, 0.651797578292974, 0.5, 0.0, 0.5247486994979135], 
reward next is -0.4723. 
=============================================
[2017-11-02 10:12:16,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 110409: loss -3.3555
[2017-11-02 10:12:17,893] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7000, global step 110683: loss 2.2676
[2017-11-02 10:12:17,930] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.19869228
  0.01500683  0.76511329  0.02118758], sum to 1.0000
[2017-11-02 10:12:17,930] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7000, global step 110692: loss -10.0156
[2017-11-02 10:12:17,993] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.3, 84.66666666666666, 5.266666666666667, 246.6666666666667, 0.0, 0.0, 0.75, 10.10787569152676, 25.0, 22.68001396852133, 21.5, 0.0, 45.54896517580958], 
actual action is [0.7000000000000002, 25], 
sim time next is 2069100.0000, 
raw observation next is [-4.35, 85.0, 5.475, 245.0, 0.0, 0.0, 0.7000000000000002, 10.10881615036791, 25.0, 22.67528423746553, 21.5, 0.0, 45.68704109485509], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.2217948717948718, 0.85, 0.4977272727272727, 0.6805555555555556, 0.0, 0.0, 0.5116666666666666, 0.1010881615036791, 1.0, 0.6678977482093613, 0.5, 0.0, 0.5374946011159423], 
reward next is -0.4837. 
=============================================
[2017-11-02 10:12:19,026] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 110817: loss 2.7347
[2017-11-02 10:12:19,937] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-51.87228012]
 [-51.60419846]
 [-51.95064163]
 [-51.83728027]
 [-51.66189194]], R is [[-53.6178894 ]
 [-53.56760788]
 [-53.51712036]
 [-53.46664429]
 [-53.41647339]].
[2017-11-02 10:12:23,574] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111530: loss 4.7542
[2017-11-02 10:12:26,033] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111959: loss 1.2393
[2017-11-02 10:12:27,366] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7000, global step 112249: loss -25.7469
[2017-11-02 10:12:28,533] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.91832313e-26   1.91043543e-16   2.02429143e-15   2.56747889e-16
   2.10410197e-16   4.32279170e-01   1.01957142e-01   3.56626421e-01
   1.09137312e-01], sum to 1.0000
[2017-11-02 10:12:28,609] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.699999999999999, 80.91666666666666, 4.225, 245.8333333333333, 0.0, 0.0, -1.700000000000001, 22.47127097891705, 25.0, 19.73168611989851, 21.5, 0.0, 47.08063331930657], 
actual action is [-1.6999999999999993, 25], 
sim time next is 2097000.0000, 
raw observation next is [-6.7, 80.5, 4.05, 245.0, 0.0, 0.0, -1.699999999999999, 21.24685594343595, 25.0, 19.72443185392168, 21.5, 0.0, 54.25411735724764], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.16153846153846155, 0.805, 0.36818181818181817, 0.6805555555555556, 0.0, 0.0, 0.4716666666666667, 0.2124685594343595, 1.0, 0.24634740770309702, 0.5, 0.0, 0.638283733614678], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:28,963] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112592: loss -24.6178
[2017-11-02 10:12:28,998] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7000, global step 112601: loss -51.5588
[2017-11-02 10:12:30,142] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112794: loss -67.6392
[2017-11-02 10:12:30,256] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112811: loss -14.8253
[2017-11-02 10:12:32,073] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 113093: loss -108.4868
[2017-11-02 10:12:32,923] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 113212: loss 38.8291
[2017-11-02 10:12:33,668] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7000, global step 113296: loss 79.4063
[2017-11-02 10:12:34,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 113358: loss 120.3798
[2017-11-02 10:12:36,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   7.95335342e-14   6.58489322e-13   5.43579396e-13
   3.79271186e-13   1.61714056e-30   1.03395768e-30   1.46901209e-30
   8.95331804e-30], sum to 1.0000
[2017-11-02 10:12:36,884] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.8, 82.0, 2.625, 232.5, 148.5, 97.75, -2.8, 9.478383209526328, 25.0, 22.46330819035477, 22.7, 1.0, 64.08305555389978], 
actual action is [-2.8, 20.0], 
sim time next is 2107200.0000, 
raw observation next is [-7.8, 82.0, 2.666666666666667, 233.3333333333333, 157.0, 104.5, -2.8, 8.94329077948975, 20.0, 22.74691071021029, 22.7, 1.0, 62.0376136101712], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.13333333333333333, 0.82, 0.24242424242424246, 0.648148148148148, 0.41534391534391535, 0.1045, 0.4533333333333333, 0.0894329077948975, 0.2857142857142857, 0.6781301014586129, 0.6714285714285714, 1.0, 0.72985427776672], 
reward next is -0.6658. 
=============================================
[2017-11-02 10:12:47,261] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.13911866e-11   1.21003083e-10   5.75533891e-11
   3.92192667e-11   4.99570859e-27   3.03023526e-27   1.90671802e-27
   3.65147011e-26], sum to 1.0000
[2017-11-02 10:12:47,360] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 2.591666666666667, 259.1666666666666, 18.25, 109.1666666666667, -10.6, 20.33368631490176, 18.0, 20.79690411380507, 22.7, 1.0, 0.0], 
actual action is [-10.6, 18], 
sim time next is 2188800.0000, 
raw observation next is [-5.6, 75.0, 2.5, 260.0, 21.5, 131.0, -10.6, 22.17659986459895, 18.0, 20.74388772695224, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.34782608695652173, 0.18974358974358976, 0.75, 0.22727272727272727, 0.7222222222222222, 0.056878306878306875, 0.131, 0.3233333333333333, 0.22176599864598948, 0.0, 0.39198396099317734, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:50,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.39731701e-14   6.64346486e-12   2.05195947e-11   1.64407273e-11
   2.87436359e-11   9.98033676e-03   1.07217263e-02   5.84121309e-02
   9.20885861e-01], sum to 1.0000
[2017-11-02 10:12:50,728] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.35, 70.25, 6.925000000000001, 265.0, 136.5, 0.0, -9.4, 14.87646244917394, 18.0, 22.12988922644314, 22.7, 1.0, 0.0], 
actual action is [0.6500000000000004, 23.0], 
sim time next is 2200800.0000, 
raw observation next is [-4.300000000000001, 70.0, 6.833333333333334, 266.6666666666667, 138.6666666666667, 0.0, 0.6500000000000004, 14.00173942903718, 23.0, 22.10694840996847, 22.7, 1.0, 53.57036509952856], 
processed observation next is [0.5, 0.4782608695652174, 0.22307692307692306, 0.7, 0.6212121212121212, 0.7407407407407408, 0.3668430335097003, 0.0, 0.5108333333333334, 0.1400173942903718, 0.7142857142857143, 0.5867069157097815, 0.6714285714285714, 1.0, 0.6302395894062184], 
reward next is -0.5812. 
=============================================
[2017-11-02 10:12:51,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   1.20699089e-27   4.06852007e-27   1.65965857e-27
   3.59923296e-27   2.69687697e-02   1.76930279e-02   4.96849678e-02
   9.05653298e-01], sum to 1.0000
[2017-11-02 10:12:51,988] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 78.66666666666666, 3.0, 270.0, 0.0, 0.0, -1.2, 18.33569055981301, 25.0, 20.61801027350589, 21.5, 0.0, 46.9976499345468], 
actual action is [-1.2000000000000002, 25], 
sim time next is 2181600.0000, 
raw observation next is [-6.2, 79.0, 3.0, 270.0, 0.0, 0.0, -1.2, 17.99822874060989, 25.0, 20.64375300032563, 21.5, 0.0, 46.59504882796637], 
processed observation next is [0.5, 0.2608695652173913, 0.17435897435897435, 0.79, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.1799822874060989, 1.0, 0.3776790000465188, 0.5, 0.0, 0.5481770450348985], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:54,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99997139e-01   2.12695085e-07   1.23282291e-06   4.42834903e-07
   1.02736215e-06   2.49884377e-18   7.62616116e-19   9.01657990e-19
   3.10028022e-17], sum to 1.0000
[2017-11-02 10:12:54,965] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 80.0, 3.6, 273.3333333333334, 0.0, 0.0, -12.3, 21.12135453860202, 18.0, 20.60616588168019, 21.5, 0.0, 0.0], 
actual action is [-12.3, 18], 
sim time next is 2162700.0000, 
raw observation next is [-7.3, 79.75, 3.6, 272.5, 0.0, 0.0, -12.3, 23.47472482524247, 18.0, 20.56041260337907, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.0, 0.14615384615384616, 0.7975, 0.32727272727272727, 0.7569444444444444, 0.0, 0.0, 0.295, 0.23474724825242468, 0.0, 0.36577322905415294, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:13:00,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-68.5300827 ]
 [-68.5275116 ]
 [-67.82234955]
 [-67.68682861]
 [-67.38568878]], R is [[-68.63578033]
 [-68.94942474]
 [-69.25993347]
 [-69.56733704]
 [-68.88570404]].
[2017-11-02 10:13:00,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02684219
  0.02035576  0.22885817  0.72394383], sum to 1.0000
[2017-11-02 10:13:00,691] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.616666666666667, 77.5, 5.85, 261.6666666666667, 0.0, 0.0, -11.575, 18.01979132306944, 18.0, 21.46581455932414, 21.5, 0.0, 0.0], 
actual action is [-1.6166666666666671, 20.0], 
sim time next is 2246100.0000, 
raw observation next is [-6.658333333333333, 77.75, 5.975, 260.8333333333333, 0.0, 0.0, -1.616666666666667, 17.26958870833159, 20.0, 21.31721046568787, 21.5, 0.0, 58.28116841246906], 
processed observation next is [0.5, 1.0, 0.1626068376068376, 0.7775, 0.5431818181818181, 0.724537037037037, 0.0, 0.0, 0.47305555555555556, 0.1726958870833159, 0.2857142857142857, 0.47388720938398166, 0.5, 0.0, 0.6856608048525772], 
reward next is -0.6432. 
=============================================
[2017-11-02 10:13:01,841] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 117714: loss -5.5621
[2017-11-02 10:13:04,611] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.57048713e-11   3.69422315e-09   3.07160430e-09   2.46810328e-09
   5.95328498e-09   4.22515087e-02   4.85659316e-02   6.46797776e-01
   2.62384772e-01], sum to 1.0000
[2017-11-02 10:13:04,670] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 69.75, 6.949999999999999, 262.5, 0.0, 0.0, 0.0, 11.51583748343992, 20.0, 22.52380562579543, 21.5, 0.0, 47.21886346146639], 
actual action is [0.0, 22.0], 
sim time next is 2233800.0000, 
raw observation next is [-5.0, 69.5, 6.9, 265.0, 0.0, 0.0, 0.0, 11.53719823676332, 22.0, 22.55124004103997, 21.5, 0.0, 41.55074263599816], 
processed observation next is [0.5, 0.8695652173913043, 0.20512820512820512, 0.695, 0.6272727272727273, 0.7361111111111112, 0.0, 0.0, 0.5, 0.1153719823676332, 0.5714285714285714, 0.6501771487199959, 0.5, 0.0, 0.48883226630586074], 
reward next is -0.4399. 
=============================================
[2017-11-02 10:13:04,717] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   3.71013498e-10   4.65184780e-10   6.95432711e-10
   8.46205550e-10   1.47836272e-20   1.15931835e-20   1.51216965e-19
   7.76168449e-20], sum to 1.0000
[2017-11-02 10:13:04,868] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.775, 67.25, 5.975, 277.5, 131.75, 0.0, 1.183333333333334, 10.31932658922165, 20.0, 22.89137439158586, 22.7, 1.0, 51.49235614495576], 
actual action is [-8.775, 18], 
sim time next is 2204400.0000, 
raw observation next is [-3.733333333333333, 67.0, 5.933333333333334, 276.6666666666667, 130.5, 0.0, -8.775, 11.36481933667319, 18.0, 22.94329781333767, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.23760683760683762, 0.67, 0.5393939393939394, 0.7685185185185186, 0.34523809523809523, 0.0, 0.35375, 0.11364819336673189, 0.0, 0.7061854019053813, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0114. 
=============================================
[2017-11-02 10:13:05,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02277047
  0.02984731  0.91462934  0.03275285], sum to 1.0000
[2017-11-02 10:13:05,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 76.25, 4.933333333333333, 265.8333333333333, 0.0, 0.0, -1.7, 14.318038732052, 25.0, 21.58271150837266, 21.5, 0.0, 46.94711318370394], 
actual action is [-1.7000000000000002, 25], 
sim time next is 2248800.0000, 
raw observation next is [-6.700000000000001, 76.0, 4.766666666666667, 266.6666666666667, 0.0, 0.0, -1.7, 14.21912835617539, 25.0, 21.59456967918205, 21.5, 0.0, 46.80233178535507], 
processed observation next is [0.6666666666666666, 0.0, 0.16153846153846152, 0.76, 0.43333333333333335, 0.7407407407407408, 0.0, 0.0, 0.4716666666666667, 0.1421912835617539, 1.0, 0.5135099541688645, 0.5, 0.0, 0.5506156680630009], 
reward next is -0.4956. 
=============================================
[2017-11-02 10:13:06,081] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 118239: loss -0.2898
[2017-11-02 10:13:07,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-54.37002182]
 [-54.61729813]
 [-54.28763962]
 [-55.08122635]
 [-53.79742813]], R is [[-55.32396317]
 [-55.77072525]
 [-56.21302032]
 [-56.65089035]
 [-57.0843811 ]].
[2017-11-02 10:13:08,134] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7500, global step 118479: loss 0.8331
[2017-11-02 10:13:09,380] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7500, global step 118651: loss 1.0003
[2017-11-02 10:13:09,446] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 118658: loss 0.1050
[2017-11-02 10:13:13,010] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-43.04409409]
 [-42.77671432]
 [-43.44225693]
 [-42.56076813]
 [-42.47411346]], R is [[-43.4826889 ]
 [-43.57704163]
 [-43.67392731]
 [-43.76473236]
 [-43.85768127]].
[2017-11-02 10:13:16,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.68541079e-29   4.10819865e-20   2.96372383e-20   1.76594385e-20
   6.27496951e-20   4.46501235e-03   2.93446898e-01   6.34524524e-01
   6.75635636e-02], sum to 1.0000
[2017-11-02 10:13:16,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 68.5, 6.016666666666666, 276.6666666666667, 0.0, 0.0, 0.5, 11.37840066692846, 20.0, 22.52115562996395, 22.7, 1.0, 63.26064616455421], 
actual action is [0.5, 22.0], 
sim time next is 2224500.0000, 
raw observation next is [-4.5, 68.25, 6.058333333333333, 278.3333333333333, 0.0, 0.0, 0.5, 11.3731759819051, 22.0, 22.51931903036435, 22.7, 1.0, 37.39638565980915], 
processed observation next is [0.5, 0.7391304347826086, 0.21794871794871795, 0.6825, 0.5507575757575757, 0.7731481481481481, 0.0, 0.0, 0.5083333333333333, 0.113731759819051, 0.5714285714285714, 0.6456170043377644, 0.6714285714285714, 1.0, 0.4399574783506959], 
reward next is -0.4073. 
=============================================
[2017-11-02 10:13:17,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119868: loss 38.7036
[2017-11-02 10:13:18,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00357645
  0.0656624   0.81223136  0.11852971], sum to 1.0000
[2017-11-02 10:13:19,050] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 77.25, 5.6, 262.5, 0.0, 0.0, -1.700000000000001, 12.26149619239217, 20.0, 21.97741322084285, 21.5, 0.0, 59.35233586359587], 
actual action is [-1.7000000000000002, 22.0], 
sim time next is 2247600.0000, 
raw observation next is [-6.700000000000001, 77.0, 5.433333333333334, 263.3333333333334, 0.0, 0.0, -1.7, 12.29318797178467, 22.0, 21.91730286094128, 21.5, 0.0, 38.54353905425925], 
processed observation next is [0.6666666666666666, 0.0, 0.16153846153846152, 0.77, 0.49393939393939396, 0.7314814814814817, 0.0, 0.0, 0.4716666666666667, 0.1229318797178467, 0.5714285714285714, 0.5596146944201829, 0.5, 0.0, 0.4534534006383441], 
reward next is -0.4081. 
=============================================
[2017-11-02 10:13:19,831] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120208: loss -16.8166
[2017-11-02 10:13:20,034] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7500, global step 120235: loss -21.2964
[2017-11-02 10:13:21,782] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120534: loss -30.2445
[2017-11-02 10:13:22,389] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7500, global step 120669: loss -15.5582
[2017-11-02 10:13:23,568] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120883: loss 8.8352
[2017-11-02 10:13:23,613] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120890: loss 2.8783
[2017-11-02 10:13:23,684] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120905: loss 39.1846
[2017-11-02 10:13:25,192] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 121171: loss -0.5272
[2017-11-02 10:13:25,889] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 121283: loss 0.1227
[2017-11-02 10:13:26,263] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7500, global step 121333: loss 0.7055
[2017-11-02 10:13:30,511] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00199777
  0.9115994   0.07232747  0.01407534], sum to 1.0000
[2017-11-02 10:13:30,637] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.2, 53.0, 2.0, 235.0, 0.0, 0.0, 3.8, 7.854263864564979, 18.5, 23.71838728139478, 22.7, 1.0, 52.16737927454468], 
actual action is [3.8, 19.5], 
sim time next is 2313300.0000, 
raw observation next is [-1.2, 53.16666666666667, 2.0, 237.5, 0.0, 0.0, 3.8, 7.943225388870391, 19.5, 23.62743522241846, 22.7, 1.0, 37.1639682000123], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3025641025641026, 0.5316666666666667, 0.18181818181818182, 0.6597222222222222, 0.0, 0.0, 0.5633333333333332, 0.07943225388870391, 0.21428571428571427, 0.8039193174883513, 0.6714285714285714, 1.0, 0.43722315529426237], 
reward next is -0.4014. 
=============================================
[2017-11-02 10:13:34,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   7.82349384e-32   6.44722446e-32   3.62872608e-32
   1.76412797e-31   3.54530080e-03   9.75006640e-01   1.23343505e-02
   9.11367312e-03], sum to 1.0000
[2017-11-02 10:13:34,484] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.116666666666667, 85.5, 2.916666666666667, 271.6666666666667, 82.33333333333334, 31.33333333333334, -3.258333333333333, 10.64155928377467, 19.0, 22.50043111604463, 22.7, 1.0, 70.20794034401523], 
actual action is [-3.116666666666667, 20.0], 
sim time next is 2279700.0000, 
raw observation next is [-7.975000000000001, 84.75, 2.875, 267.5, 87.0, 33.25, -3.116666666666667, 10.41760063453642, 20.0, 22.58245626928778, 22.7, 1.0, 46.04425789518248], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.1288461538461538, 0.8475, 0.26136363636363635, 0.7430555555555556, 0.23015873015873015, 0.03325, 0.44805555555555554, 0.1041760063453642, 0.2857142857142857, 0.654636609898254, 0.6714285714285714, 1.0, 0.5416971517080292], 
reward next is -0.4979. 
=============================================
[2017-11-02 10:13:34,824] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00400975
  0.98169345  0.01152638  0.00277036], sum to 1.0000
[2017-11-02 10:13:34,895] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.7, 54.5, 1.125, 202.5, 0.0, 0.0, 3.3, 8.02001849718301, 23.0, 23.5324261013015, 21.5, 0.0, 27.57537286797765], 
actual action is [3.3, 24.0], 
sim time next is 2323200.0000, 
raw observation next is [-1.7, 54.66666666666667, 1.0, 180.0, 0.0, 0.0, 3.3, 8.115657715678186, 24.0, 23.51143329880083, 21.5, 0.0, 26.48056335098547], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.28974358974358977, 0.5466666666666667, 0.09090909090909091, 0.5, 0.0, 0.0, 0.5549999999999999, 0.08115657715678186, 0.8571428571428571, 0.7873476141144045, 0.5, 0.0, 0.31153603942335845], 
reward next is -0.2804. 
=============================================
[2017-11-02 10:13:41,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.00447063e-08   3.10893782e-08   7.36097494e-09   9.16479603e-09
   1.78820265e-08   1.14274956e-02   9.56138015e-01   1.69921387e-02
   1.54422736e-02], sum to 1.0000
[2017-11-02 10:13:41,215] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.7833333333333332, 46.0, 2.083333333333333, 211.6666666666667, 187.6666666666667, 66.0, -5.875, 13.30956264939642, 18.0, 22.26779280632314, 22.7, 1.0, 0.0], 
actual action is [4.216666666666667, 19.0], 
sim time next is 2296500.0000, 
raw observation next is [-0.6916666666666667, 45.5, 2.041666666666667, 210.8333333333333, 179.3333333333333, 65.25, 4.216666666666667, 12.85400032315918, 19.0, 22.22642824221891, 22.7, 1.0, 25.83199271648226], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.3155982905982906, 0.455, 0.18560606060606064, 0.585648148148148, 0.47442680776014096, 0.06525, 0.5702777777777778, 0.12854000323159182, 0.14285714285714285, 0.6037754631741298, 0.6714285714285714, 1.0, 0.3039057966644972], 
reward next is -0.2864. 
=============================================
[2017-11-02 10:13:47,304] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.13473054e-12   1.24936433e-12   2.09190846e-12
   3.91823076e-12   1.48449540e-26   9.05710850e-27   7.98309302e-26
   9.32296387e-27], sum to 1.0000
[2017-11-02 10:13:47,384] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 64.0, 5.433333333333334, 60.0, 136.0, 435.0, -7.675, 14.64421244081161, 18.0, 21.54530664623903, 22.7, 1.0, 0.0], 
actual action is [-7.633333333333333, 18], 
sim time next is 2370300.0000, 
raw observation next is [-2.591666666666666, 63.75, 5.516666666666666, 57.5, 137.5, 442.5, -7.633333333333333, 15.64290214537621, 18.0, 21.65899807068274, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.26688034188034193, 0.6375, 0.5015151515151515, 0.1597222222222222, 0.3637566137566138, 0.4425, 0.37277777777777776, 0.1564290214537621, 0.0, 0.522714010097534, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:13:48,069] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 125042: loss 11.8795
[2017-11-02 10:13:52,213] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 126023: loss -193.5075
[2017-11-02 10:13:52,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.04198989
  0.06501935  0.7370556   0.15593523], sum to 1.0000
[2017-11-02 10:13:52,457] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.3, 62.5, 2.416666666666667, 26.66666666666667, 0.0, 0.0, 2.7, 16.00393357088811, 20.0, 21.366304811437, 21.5, 0.0, 54.32382725332126], 
actual action is [2.7, 21.0], 
sim time next is 2336100.0000, 
raw observation next is [-2.3, 62.25, 2.458333333333333, 28.33333333333333, 0.0, 0.0, 2.7, 15.72456069819457, 21.0, 21.40541964826252, 21.5, 0.0, 34.22440473121391], 
processed observation next is [0.8333333333333334, 0.0, 0.27435897435897433, 0.6225, 0.22348484848484845, 0.07870370370370369, 0.0, 0.0, 0.545, 0.1572456069819457, 0.42857142857142855, 0.4864885211803599, 0.5, 0.0, 0.4026400556613401], 
reward next is -0.3759. 
=============================================
[2017-11-02 10:13:55,055] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8000, global step 126529: loss 38.3153
[2017-11-02 10:13:56,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 126727: loss 77.6087
[2017-11-02 10:13:56,973] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8000, global step 126827: loss 62.5713
[2017-11-02 10:14:01,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   6.38675744e-12   6.27185424e-13   6.00163452e-12
   5.37064403e-12   4.40603630e-29   4.81668940e-29   9.46521924e-29
   5.29781805e-27], sum to 1.0000
[2017-11-02 10:14:01,496] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.3, 68.33333333333333, 5.516666666666667, 70.0, 93.0, 240.0, 1.65, 13.85627087923801, 23.0, 21.88723846689305, 22.7, 1.0, 59.94440781473313], 
actual action is [-8.3, 18.0], 
sim time next is 2366100.0000, 
raw observation next is [-3.25, 68.0, 5.475, 70.0, 100.0, 270.0, -8.3, 15.17075063045326, 18.0, 21.90133597320378, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.25, 0.68, 0.4977272727272727, 0.19444444444444445, 0.26455026455026454, 0.27, 0.36166666666666664, 0.15170750630453259, 0.0, 0.5573337104576827, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:04,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-56.5346756 ]
 [-57.08356476]
 [-56.95478439]
 [-55.81662369]
 [-56.57408905]], R is [[-57.79166412]
 [-58.21374893]
 [-58.63161087]
 [-59.04529572]
 [-59.45484161]].
[2017-11-02 10:14:06,361] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8000, global step 128188: loss 38.7763
[2017-11-02 10:14:06,625] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128239: loss -8.9891
[2017-11-02 10:14:08,596] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128566: loss 28.8767
[2017-11-02 10:14:08,855] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8000, global step 128605: loss 39.3974
[2017-11-02 10:14:09,874] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128774: loss 24.4987
[2017-11-02 10:14:11,194] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 129000: loss 0.1817
[2017-11-02 10:14:11,797] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 129094: loss 12.4191
[2017-11-02 10:14:11,875] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 129110: loss -42.0748
[2017-11-02 10:14:12,622] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 129220: loss 47.5465
[2017-11-02 10:14:13,114] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8000, global step 129296: loss -71.6911
[2017-11-02 10:14:13,477] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 129353: loss -23.1916
[2017-11-02 10:14:19,555] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.76625957e-24   1.64217679e-16   2.35037994e-17   7.50926074e-17
   1.07676873e-16   4.77205038e-01   9.15530045e-03   1.60910636e-01
   3.52729023e-01], sum to 1.0000
[2017-11-02 10:14:19,614] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 59.75, 3.808333333333333, 64.16666666666666, 0.0, 0.0, -4.5, 21.57339486896891, 25.0, 20.06971504895785, 21.5, 0.0, 46.78024637499787], 
actual action is [-4.5, 25], 
sim time next is 2446200.0000, 
raw observation next is [-9.5, 59.5, 3.85, 65.0, 0.0, 0.0, -4.5, 21.56363100135659, 25.0, 20.08133967537539, 21.5, 0.0, 46.80345165396488], 
processed observation next is [1.0, 0.30434782608695654, 0.08974358974358974, 0.595, 0.35000000000000003, 0.18055555555555555, 0.0, 0.0, 0.425, 0.2156363100135659, 1.0, 0.29733423933934133, 0.5, 0.0, 0.5506288429878221], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:26,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.08849599e-15   3.26805799e-16   5.02333355e-15
   1.34896212e-15   0.00000000e+00   0.00000000e+00   6.28290944e-38
   2.21069729e-38], sum to 1.0000
[2017-11-02 10:14:26,178] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.666666666666666, 51.33333333333334, 4.516666666666666, 70.0, 47.0, 499.0, -2.85, 19.23282871678771, 20.5, 20.90384738173395, 22.7, 1.0, 51.89392208206362], 
actual action is [-12.666666666666666, 18], 
sim time next is 2451300.0000, 
raw observation next is [-7.483333333333333, 50.66666666666666, 4.558333333333333, 70.0, 48.75, 519.75, -12.66666666666667, 20.80626696114292, 18.0, 20.93683000824683, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.14145299145299145, 0.5066666666666666, 0.4143939393939393, 0.19444444444444445, 0.12896825396825398, 0.51975, 0.2888888888888888, 0.20806266961142922, 0.0, 0.41954714403526133, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:33,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 132776: loss 58.8766
[2017-11-02 10:14:33,047] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   9.36503477e-29   5.72772054e-30   1.97600051e-29
   3.07500054e-29   1.87592596e-01   3.06189768e-02   5.81700623e-01
   2.00087786e-01], sum to 1.0000
[2017-11-02 10:14:33,118] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 57.0, 2.25, 75.0, 0.0, 0.0, 2.7, 12.33433412285879, 20.0, 21.74201609633239, 21.5, 0.0, 47.30412609198257], 
actual action is [2.7, 25.0], 
sim time next is 2524800.0000, 
raw observation next is [-2.3, 57.00000000000001, 2.333333333333333, 76.66666666666667, 0.0, 0.0, 2.7, 12.31503145199308, 25.0, 21.72013125989242, 21.5, 0.0, 32.50538961650875], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.5700000000000001, 0.2121212121212121, 0.21296296296296297, 0.0, 0.0, 0.545, 0.1231503145199308, 1.0, 0.5314473228417741, 0.5, 0.0, 0.3824163484295147], 
reward next is -0.3442. 
=============================================
[2017-11-02 10:14:37,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.50685407e-04   5.93941841e-05   7.73137253e-06   3.93855589e-05
   2.22238068e-05   3.55282485e-01   6.99101835e-02   3.94873351e-01
   1.79554567e-01], sum to 1.0000
[2017-11-02 10:14:37,815] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.05, 33.5, 4.449999999999999, 60.0, 0.0, 0.0, 3.9, 15.20854187862816, 18.5, 21.8952739575291, 21.5, 0.0, 53.48148797101806], 
actual action is [3.95, 20.5], 
sim time next is 2499600.0000, 
raw observation next is [-1.0, 33.66666666666667, 4.233333333333333, 60.00000000000001, 0.0, 0.0, 3.95, 14.91465065230513, 20.5, 21.93558335301122, 21.5, 0.0, 33.3956454561098], 
processed observation next is [1.0, 0.9565217391304348, 0.3076923076923077, 0.3366666666666667, 0.38484848484848483, 0.16666666666666669, 0.0, 0.0, 0.5658333333333334, 0.1491465065230513, 0.35714285714285715, 0.5622261932873174, 0.5, 0.0, 0.3928899465424682], 
reward next is -0.3536. 
=============================================
[2017-11-02 10:14:38,217] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 134073: loss 8.2070
[2017-11-02 10:14:38,541] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-36.10106277]
 [-35.07095718]
 [-35.2112236 ]
 [-35.52928162]
 [-35.37573242]], R is [[-35.19832993]
 [-34.84634781]
 [-34.84957123]
 [-35.08029556]
 [-34.72949219]].
[2017-11-02 10:14:39,009] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8500, global step 134299: loss 19.4001
[2017-11-02 10:14:39,671] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 134497: loss 72.2554
[2017-11-02 10:14:40,517] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8500, global step 134758: loss -114.5018
[2017-11-02 10:14:41,846] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.75739043e-10   9.75437370e-11   4.93210917e-10
   1.66979000e-10   2.22457446e-20   4.43940676e-22   1.23797737e-21
   3.48474294e-22], sum to 1.0000
[2017-11-02 10:14:41,860] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.05, 33.5, 4.725, 92.5, 0.0, 0.0, -3.766666666666667, 16.25261135066221, 18.0, 21.78686307036512, 22.7, 1.0, 0.0], 
actual action is [-3.95, 18], 
sim time next is 2569800.0000, 
raw observation next is [0.8666666666666667, 34.0, 4.683333333333333, 64.99999999999999, 0.0, 0.0, -3.95, 16.83881383771971, 18.0, 21.72356693192492, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.35555555555555557, 0.34, 0.4257575757575757, 0.18055555555555552, 0.0, 0.0, 0.4341666666666667, 0.1683881383771971, 0.0, 0.5319381331321316, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:44,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135944: loss -37.2024
[2017-11-02 10:14:45,117] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.08707062
  0.01209635  0.3809281   0.51990485], sum to 1.0000
[2017-11-02 10:14:45,185] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.883333333333333, 46.0, 3.683333333333333, 325.0, 0.0, 0.0, 3.208333333333333, 21.35594597039704, 20.0, 20.05627115101867, 21.5, 0.0, 38.43173903428384], 
actual action is [3.116666666666667, 22.0], 
sim time next is 2578500.0000, 
raw observation next is [-1.975, 47.0, 3.725, 322.5, 0.0, 0.0, 3.116666666666667, 19.73614506969369, 22.0, 20.34017021248508, 21.5, 0.0, 45.93025333080698], 
processed observation next is [0.0, 0.8695652173913043, 0.2826923076923077, 0.47, 0.3386363636363636, 0.8958333333333334, 0.0, 0.0, 0.5519444444444445, 0.19736145069693692, 0.5714285714285714, 0.33431003035501156, 0.5, 0.0, 0.5403559215389057], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:46,179] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8500, global step 136217: loss -55.6473
[2017-11-02 10:14:48,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136538: loss 40.5303
[2017-11-02 10:14:49,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   1.30200822e-16   2.92867366e-17   5.80677349e-16
   1.53170794e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:14:49,377] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.9, 80.5, 5.1, 240.0, 0.0, 0.0, -0.8499999999999996, 19.6417807137577, 25.0, 20.44529213759629, 21.5, 0.0, 43.43348027403177], 
actual action is [-0.9000000000000004, 20.0], 
sim time next is 2608500.0000, 
raw observation next is [-5.95, 80.91666666666667, 5.1, 240.0, 0.0, 0.0, -0.9000000000000004, 19.30509746045245, 20.0, 20.48376237533266, 21.5, 0.0, 47.18838621166054], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.18076923076923077, 0.8091666666666667, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.48500000000000004, 0.1930509746045245, 0.2857142857142857, 0.3548231964760942, 0.5, 0.0, 0.5551574848430653], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:49,883] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.09804421e-10   3.19415037e-08   3.76214793e-09   4.11126955e-08
   3.29594556e-08   1.55050486e-01   1.01325596e-02   6.15507253e-02
   7.73266196e-01], sum to 1.0000
[2017-11-02 10:14:50,046] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 54.66666666666667, 2.0, 26.66666666666667, 43.5, 15.0, 2.2, 16.24874293676829, 25.0, 21.22909827305193, 22.7, 1.0, 76.85943367621735], 
actual action is [2.2, 25], 
sim time next is 2535900.0000, 
raw observation next is [-2.8, 54.83333333333333, 2.0, 25.83333333333333, 47.25, 16.5, 2.2, 14.29775740871445, 25.0, 21.45949315681691, 22.7, 1.0, 68.2429474049493], 
processed observation next is [0.0, 0.34782608695652173, 0.2615384615384615, 0.5483333333333333, 0.18181818181818182, 0.07175925925925924, 0.125, 0.0165, 0.5366666666666667, 0.1429775740871445, 1.0, 0.49421330811670167, 0.6714285714285714, 1.0, 0.8028582047641095], 
reward next is -0.7369. 
=============================================
[2017-11-02 10:14:51,062] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8500, global step 137074: loss 44.3058
[2017-11-02 10:14:51,301] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 137124: loss 12.8031
[2017-11-02 10:14:51,815] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 137226: loss -10.1945
[2017-11-02 10:14:51,905] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 137241: loss 30.3580
[2017-11-02 10:14:52,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 137288: loss 1.0658
[2017-11-02 10:14:52,951] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 137500: loss 29.1609
[2017-11-02 10:14:53,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.95749167e-10   5.95163988e-11   4.74229434e-10
   2.14169849e-10   1.36435349e-22   2.87401371e-23   5.51787188e-23
   4.11066961e-22], sum to 1.0000
[2017-11-02 10:14:53,585] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 4.199999999999999, 347.5, 103.0, 303.75, -1.7, 12.61566035932446, 18.0, 23.04839848689596, 22.7, 1.0, 0.0], 
actual action is [-1.7000000000000002, 18], 
sim time next is 2562600.0000, 
raw observation next is [3.3, 29.0, 4.333333333333333, 348.3333333333334, 99.33333333333334, 288.0, -1.7, 12.69689162516293, 18.0, 23.03381910891022, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.41794871794871796, 0.29, 0.3939393939393939, 0.9675925925925929, 0.2627865961199295, 0.288, 0.4716666666666667, 0.12696891625162932, 0.0, 0.7191170155586027, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0127. 
=============================================
[2017-11-02 10:14:53,873] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8500, global step 137756: loss -10.8240
[2017-11-02 10:14:54,797] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 138003: loss 6.8281
[2017-11-02 10:15:05,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   4.44445514e-15   1.93986173e-15   4.98407298e-14
   1.45159933e-14   3.08321679e-36   6.30420772e-37   1.08089159e-36
   4.17442197e-34], sum to 1.0000
[2017-11-02 10:15:05,862] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.149999999999999, 78.75, 6.374999999999999, 237.5, 0.0, 0.0, -2.1, 19.13698287769955, 25.0, 20.53063859614546, 21.5, 0.0, 36.34618297367916], 
actual action is [-2.1499999999999986, 20.0], 
sim time next is 2616600.0000, 
raw observation next is [-7.199999999999999, 78.83333333333334, 6.283333333333333, 235.0, 0.0, 0.0, -2.149999999999999, 19.24049442980801, 20.0, 20.52261298654609, 21.5, 0.0, 43.4727631424124], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.14871794871794874, 0.7883333333333334, 0.5712121212121212, 0.6527777777777778, 0.0, 0.0, 0.46416666666666667, 0.19240494429808008, 0.2857142857142857, 0.36037328379229855, 0.5, 0.0, 0.5114442722636753], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:08,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-88.58201599]
 [-88.64775085]
 [-89.62199402]
 [-87.08802032]
 [-86.20114899]], R is [[-86.6653595 ]
 [-86.79870605]
 [-86.93071747]
 [-87.061409  ]
 [-87.1907959 ]].
[2017-11-02 10:15:08,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.88825210e-03   1.93510292e-04   6.09109586e-04
   9.97309089e-01], sum to 1.0000
[2017-11-02 10:15:08,562] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.658333333333333, 78.41666666666667, 7.024999999999999, 258.3333333333333, 0.0, 0.0, -11.61666666666667, 21.06587223915611, 18.0, 20.73578838293596, 21.5, 0.0, 0.0], 
actual action is [-1.6583333333333332, 23.0], 
sim time next is 2613600.0000, 
raw observation next is [-6.7, 78.0, 7.2, 260.0, 0.0, 0.0, -1.658333333333333, 20.0011976594241, 23.0, 20.58574292554865, 21.5, 0.0, 64.94043206426804], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.16153846153846155, 0.78, 0.6545454545454545, 0.7222222222222222, 0.0, 0.0, 0.4723611111111111, 0.200011976594241, 0.7142857142857143, 0.3693918465069501, 0.5, 0.0, 0.7640050831090357], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:09,157] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 140654: loss -19.2774
[2017-11-02 10:15:09,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.45307899e-26   2.91785990e-20   2.89224852e-21   7.15071790e-20
   8.99532485e-20   2.48477049e-03   6.38102822e-04   1.52141473e-03
   9.95355725e-01], sum to 1.0000
[2017-11-02 10:15:10,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.816666666666666, 64.5, 7.449999999999999, 223.3333333333333, 132.3333333333333, 213.6666666666667, -9.908333333333333, 13.5144562708643, 18.0, 22.73072546874164, 22.7, 1.0, 0.0], 
actual action is [0.18333333333333357, 23.0], 
sim time next is 2628900.0000, 
raw observation next is [-4.725, 64.25, 7.575, 225.0, 137.25, 229.0, 0.1833333333333336, 11.92994697930802, 23.0, 22.62974136952487, 22.7, 1.0, 78.86241533319823], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.21217948717948718, 0.6425, 0.6886363636363636, 0.625, 0.3630952380952381, 0.229, 0.5030555555555556, 0.1192994697930802, 0.7142857142857143, 0.6613916242178384, 0.6714285714285714, 1.0, 0.927793121567038], 
reward next is -0.8469. 
=============================================
[2017-11-02 10:15:14,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.94216149e-13   9.21648283e-14   2.29498929e-12
   8.72436455e-13   5.67329387e-25   2.12701872e-25   8.33206721e-26
   6.92375427e-25], sum to 1.0000
[2017-11-02 10:15:14,673] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.991666666666667, 62.25, 8.575, 238.3333333333333, 182.0, 231.6666666666667, -9.083333333333332, 15.09605561933375, 18.0, 22.59456913128522, 22.7, 1.0, 0.0], 
actual action is [-8.991666666666667, 18], 
sim time next is 2631600.0000, 
raw observation next is [-3.9, 62.0, 8.7, 240.0, 188.0, 223.0, -8.991666666666667, 15.66365322171692, 18.0, 22.49370439216415, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.23333333333333334, 0.62, 0.7909090909090909, 0.6666666666666666, 0.4973544973544973, 0.223, 0.3501388888888889, 0.1566365322171692, 0.0, 0.6419577703091645, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:18,208] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9000, global step 142251: loss -77.0778
[2017-11-02 10:15:18,809] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 142409: loss -5.3044
[2017-11-02 10:15:18,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   7.64197493e-17   9.70264330e-18   4.41001722e-16
   1.14087701e-16   3.26379968e-37   9.39614005e-38   5.49847769e-38
   1.17591732e-37], sum to 1.0000
[2017-11-02 10:15:18,991] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 7.475, 231.6666666666667, 69.33333333333333, 120.5, -4.5, 14.28583469930246, 18.0, 22.50366248037079, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 2652000.0000, 
raw observation next is [0.5, 50.0, 7.299999999999999, 233.3333333333333, 63.66666666666666, 117.0, -4.5, 14.66753549449563, 18.0, 22.43890349881494, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.34615384615384615, 0.5, 0.6636363636363636, 0.648148148148148, 0.16843033509700173, 0.117, 0.425, 0.1466753549449563, 0.0, 0.6341290712592773, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 10:15:19,388] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 142565: loss -123.1611
[2017-11-02 10:15:19,891] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   6.23089930e-16   2.05485799e-16   5.01812388e-15
   1.78414192e-15   3.29218832e-35   2.78009494e-35   1.45298535e-35
   2.89427441e-34], sum to 1.0000
[2017-11-02 10:15:19,917] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 6.6, 240.0, 41.0, 103.0, 5.5, 15.55527165242131, 23.0, 21.8031480790496, 22.7, 1.0, 43.64367414695609], 
actual action is [-4.5, 18.0], 
sim time next is 2653500.0000, 
raw observation next is [0.4083333333333333, 50.33333333333333, 6.475, 239.1666666666667, 35.33333333333333, 99.5, -4.5, 16.61131094023747, 18.0, 21.83655335557303, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.3438034188034188, 0.5033333333333333, 0.5886363636363636, 0.664351851851852, 0.09347442680776012, 0.0995, 0.425, 0.1661131094023747, 0.0, 0.5480790507961473, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:20,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.29399836e-04   7.11958055e-05   1.34378515e-05   1.95095767e-04
   1.54710709e-04   2.33882628e-02   3.48622352e-02   2.72486843e-02
   9.13936973e-01], sum to 1.0000
[2017-11-02 10:15:20,816] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 62.0, 7.999999999999999, 240.0, 0.0, 0.0, 3.8, 17.07933577831741, 25.0, 21.23473805302113, 22.7, 1.0, 71.74523364036565], 
actual action is [3.8, 25], 
sim time next is 2663100.0000, 
raw observation next is [-1.2, 62.25, 8.174999999999999, 240.0, 0.0, 0.0, 3.8, 15.38827693681567, 25.0, 21.35253771407197, 22.7, 1.0, 74.3636399517622], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3025641025641026, 0.6225, 0.743181818181818, 0.6666666666666666, 0.0, 0.0, 0.5633333333333332, 0.1538827693681567, 1.0, 0.47893395915313874, 0.6714285714285714, 1.0, 0.8748663523736729], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:22,137] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9000, global step 142992: loss -6.5401
[2017-11-02 10:15:23,027] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-63.64768982]
 [-62.55807877]
 [-64.06117249]
 [-64.06697083]
 [-63.32047653]], R is [[-64.88238525]
 [-64.74172974]
 [-64.6129303 ]
 [-64.48628998]
 [-64.29928589]].
[2017-11-02 10:15:26,344] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143548: loss -161.1622
[2017-11-02 10:15:26,909] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9000, global step 143657: loss -49.0784
[2017-11-02 10:15:29,087] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144035: loss -121.9077
[2017-11-02 10:15:31,741] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144550: loss 18.6129
[2017-11-02 10:15:32,246] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144642: loss -392.1910
[2017-11-02 10:15:32,247] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144642: loss 30.3848
[2017-11-02 10:15:32,493] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9000, global step 144682: loss 206.2199
[2017-11-02 10:15:34,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144990: loss -159.1192
[2017-11-02 10:15:34,637] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9000, global step 145029: loss 21.7805
[2017-11-02 10:15:34,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.85134941e-27   4.46491845e-17   1.01994579e-17   5.98258907e-17
   7.17052350e-18   1.01301225e-03   1.14736408e-02   2.77794302e-01
   7.09719062e-01], sum to 1.0000
[2017-11-02 10:15:34,747] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 59.0, 1.5, 70.0, 0.0, 0.0, -1.0, 17.04108788829262, 25.0, 20.97161896711858, 21.5, 0.0, 45.62846441951908], 
actual action is [-1.0, 25], 
sim time next is 2775900.0000, 
raw observation next is [-6.0, 58.99999999999999, 1.591666666666667, 69.16666666666666, 0.0, 0.0, -1.0, 16.60981096899501, 25.0, 21.04643154128109, 21.5, 0.0, 44.84292601364908], 
processed observation next is [0.5, 0.13043478260869565, 0.1794871794871795, 0.59, 0.14469696969696974, 0.1921296296296296, 0.0, 0.0, 0.48333333333333334, 0.1660981096899501, 1.0, 0.43520450589729875, 0.5, 0.0, 0.527563835454695], 
reward next is -0.5396. 
=============================================
[2017-11-02 10:15:35,694] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 145179: loss 23.2849
[2017-11-02 10:15:37,106] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 145378: loss 3.5588
[2017-11-02 10:15:37,187] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.13466178e-16   5.55866364e-17   6.26369112e-16
   2.28545189e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:15:37,222] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.166666666666667, 54.83333333333333, 1.5, 288.3333333333334, 0.0, 0.0, 0.916666666666667, 15.59213581684534, 22.0, 21.86137430912395, 22.7, 1.0, 37.23041236376295], 
actual action is [-9.166666666666668, 18], 
sim time next is 2744100.0000, 
raw observation next is [-4.25, 55.25, 1.5, 262.5, 0.0, 0.0, -9.166666666666668, 17.814880836805, 18.0, 21.84001651648783, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.22435897435897437, 0.5525, 0.13636363636363635, 0.7291666666666666, 0.0, 0.0, 0.3472222222222222, 0.17814880836805, 0.0, 0.5485737880696898, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:44,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   9.76966446e-14   1.27016670e-13   2.09082339e-12
   5.80106709e-14   7.10227818e-36   4.01169877e-35   3.21404997e-34
   7.11763712e-34], sum to 1.0000
[2017-11-02 10:15:44,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 60.66666666666666, 1.9, 53.33333333333333, 0.0, 0.0, -11.0, 18.40002830260794, 18.0, 21.6019111175323, 21.5, 0.0, 0.0], 
actual action is [-11.0, 18], 
sim time next is 2756700.0000, 
raw observation next is [-6.0, 60.25, 1.95, 52.5, 0.0, 0.0, -11.0, 20.70578488126224, 18.0, 21.48712956315092, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.1794871794871795, 0.6025, 0.17727272727272728, 0.14583333333333334, 0.0, 0.0, 0.31666666666666665, 0.2070578488126224, 0.0, 0.49816136616441703, 0.5, 0.0, 0.0], 
reward next is -0.0018. 
=============================================
[2017-11-02 10:15:45,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-64.04896545]
 [-63.79737473]
 [-64.96237183]
 [-64.12556458]
 [-63.58773422]], R is [[-64.88051605]
 [-65.23171234]
 [-65.57939911]
 [-65.92360687]
 [-66.26437378]].
[2017-11-02 10:15:55,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.05774264e-12   1.93620009e-09   1.77415638e-09   1.59325282e-08
   1.26256527e-09   6.78493921e-03   3.36791240e-02   2.14338318e-01
   7.45197594e-01], sum to 1.0000
[2017-11-02 10:15:55,360] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 59.0, 2.933333333333334, 58.33333333333333, 0.0, 0.0, -11.0, 17.22513423840248, 18.0, 21.83516533053916, 21.5, 0.0, 0.0], 
actual action is [-1.0, 23.0], 
sim time next is 2760900.0000, 
raw observation next is [-6.0, 59.0, 3.016666666666667, 59.16666666666667, 0.0, 0.0, -1.0, 16.55667530772543, 23.0, 21.69058871479021, 21.5, 0.0, 55.36340437747886], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.1794871794871795, 0.59, 0.2742424242424243, 0.16435185185185186, 0.0, 0.0, 0.48333333333333334, 0.16556675307725432, 0.7142857142857143, 0.5272269592557441, 0.5, 0.0, 0.6513341691468101], 
reward next is -0.5862. 
=============================================
[2017-11-02 10:15:55,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 148628: loss 20.7884
[2017-11-02 10:16:02,444] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9500, global step 149967: loss -11.1491
[2017-11-02 10:16:04,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 150214: loss -8.4477
[2017-11-02 10:16:04,854] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 150322: loss 46.9565
[2017-11-02 10:16:06,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  6.39434997e-14   2.16027798e-13   7.96664438e-14   3.40283812e-12
   2.59025277e-13   5.89575246e-03   1.26716709e-02   1.92471862e-01
   7.88960755e-01], sum to 1.0000
[2017-11-02 10:16:07,106] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.9999999999999999, 46.0, 3.1, 93.33333333333333, 133.8333333333333, 750.0, -4.25, 18.1567031301714, 18.0, 22.12960039381179, 22.7, 1.0, 0.0], 
actual action is [6.0, 23.0], 
sim time next is 2807100.0000, 
raw observation next is [1.25, 45.5, 3.225, 97.5, 138.25, 743.5, 6.0, 14.90646657377569, 23.0, 22.04115402463906, 22.7, 1.0, 87.4545135077831], 
processed observation next is [0.5, 0.4782608695652174, 0.36538461538461536, 0.455, 0.2931818181818182, 0.2708333333333333, 0.36574074074074076, 0.7435, 0.6, 0.1490646657377569, 0.7142857142857143, 0.5773077178055799, 0.6714285714285714, 1.0, 1.0288766295033307], 
reward next is -0.9409. 
=============================================
[2017-11-02 10:16:07,131] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9500, global step 150732: loss 37.4820
[2017-11-02 10:16:08,528] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-40.22081375]
 [-39.52638626]
 [-41.00276566]
 [-39.41436386]
 [-39.86009598]], R is [[-40.27880096]
 [-40.69565582]
 [-40.30205536]
 [-39.9115715 ]
 [-39.52410507]].
[2017-11-02 10:16:09,384] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151276: loss 47.9178
[2017-11-02 10:16:11,082] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9500, global step 151813: loss 20.2707
[2017-11-02 10:16:13,898] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152319: loss 87.6107
[2017-11-02 10:16:16,191] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152887: loss 49.6738
[2017-11-02 10:16:16,262] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9500, global step 152907: loss 61.4812
[2017-11-02 10:16:16,338] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152927: loss -131.6525
[2017-11-02 10:16:16,497] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152976: loss 22.5899
[2017-11-02 10:16:16,927] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 153100: loss 30.2854
[2017-11-02 10:16:17,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.28501800e-02   5.80982378e-05   4.60591800e-05   5.54476981e-04
   7.60523908e-05   5.01217041e-03   7.19295740e-02   3.27802449e-01
   5.71670890e-01], sum to 1.0000
[2017-11-02 10:16:17,924] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.0, 76.66666666666667, 7.033333333333333, 130.0, 0.0, 0.0, 6.0, 19.03038406256741, 21.0, 21.19577123720885, 21.5, 0.0, 38.7733677933517], 
actual action is [6.0, 22.0], 
sim time next is 2857500.0000, 
raw observation next is [1.0, 77.25, 6.95, 130.0, 0.0, 0.0, 6.0, 19.27709312534489, 22.0, 21.15882186789271, 21.5, 0.0, 32.78071853005051], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.358974358974359, 0.7725, 0.6318181818181818, 0.3611111111111111, 0.0, 0.0, 0.6, 0.1927709312534489, 0.5714285714285714, 0.45126026684181547, 0.5, 0.0, 0.3856555121182413], 
reward next is -0.3958. 
=============================================
[2017-11-02 10:16:18,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 153537: loss 82.4999
[2017-11-02 10:16:18,955] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9500, global step 153634: loss 40.0425
[2017-11-02 10:16:21,332] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 154117: loss 53.7023
[2017-11-02 10:16:21,727] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   2.72998137e-16   3.09290798e-16   5.12741484e-15
   7.21694888e-16   0.00000000e+00   7.47800796e-38   3.76431199e-38
   2.53217188e-37], sum to 1.0000
[2017-11-02 10:16:21,833] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666666, 98.83333333333334, 4.683333333333333, 121.6666666666667, 58.66666666666666, 0.0, 5.25, 10.28827883086326, 23.0, 22.84154319713204, 22.7, 1.0, 68.60974787030946], 
actual action is [-4.833333333333333, 18.0], 
sim time next is 2886900.0000, 
raw observation next is [0.08333333333333337, 99.41666666666666, 4.641666666666666, 120.8333333333333, 61.08333333333334, 0.0, -4.833333333333333, 11.00287935691483, 18.0, 22.88908573825536, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.3354700854700855, 0.9941666666666665, 0.4219696969696969, 0.33564814814814803, 0.16159611992945327, 0.0, 0.41944444444444445, 0.1100287935691483, 0.0, 0.6984408197507658, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0110. 
=============================================
[2017-11-02 10:16:22,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   1.70499644e-30   7.57280544e-31   4.38158542e-30
   1.17612489e-30   2.97587551e-02   6.36891901e-01   1.91603482e-01
   1.41745955e-01], sum to 1.0000
[2017-11-02 10:16:23,017] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.0, 93.0, 4.1, 110.0, 0.0, 0.0, -4.0, 20.61674367085944, 18.0, 20.7182073596513, 21.5, 0.0, 0.0], 
actual action is [6.0, 19.0], 
sim time next is 2869500.0000, 
raw observation next is [1.0, 93.58333333333333, 4.183333333333333, 111.6666666666667, 0.0, 0.0, 6.0, 19.31138701584262, 19.0, 20.6261955072965, 21.5, 0.0, 62.66273883629937], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.358974358974359, 0.9358333333333333, 0.38030303030303025, 0.3101851851851853, 0.0, 0.0, 0.6, 0.19311387015842618, 0.14285714285714285, 0.375170786756643, 0.5, 0.0, 0.7372086921917573], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:25,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.28965118e-34   8.05652598e-24   3.69914273e-24   2.32242796e-23
   6.06433508e-24   2.58056730e-01   4.18152183e-01   7.95722753e-02
   2.44218841e-01], sum to 1.0000
[2017-11-02 10:16:25,205] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.166666666666667, 79.16666666666667, 7.949999999999999, 260.0, 0.0, 0.0, 3.916666666666667, 12.22956806287975, 18.5, 22.04143048133505, 21.5, 0.0, 42.74846086451987], 
actual action is [3.833333333333333, 19.0], 
sim time next is 2931300.0000, 
raw observation next is [-1.25, 79.75, 7.824999999999999, 260.0, 0.0, 0.0, 3.833333333333333, 12.16473809106789, 19.0, 22.06586214501749, 21.5, 0.0, 40.98295697799279], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.30128205128205127, 0.7975, 0.7113636363636363, 0.7222222222222222, 0.0, 0.0, 0.5638888888888889, 0.1216473809106789, 0.14285714285714285, 0.5808374492882129, 0.5, 0.0, 0.4821524350352093], 
reward next is -0.4339. 
=============================================
[2017-11-02 10:16:34,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   3.58843099e-20   3.91068892e-20   8.00242183e-19
   4.32636108e-20   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:34,433] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666667, 92.41666666666667, 9.341666666666667, 250.0, 0.0, 0.0, 5.0, 24.64727353234836, 19.0, 20.14747149624781, 22.7, 1.0, 4.932446279271009], 
actual action is [-5.166666666666667, 18], 
sim time next is 2918400.0000, 
raw observation next is [-0.3333333333333333, 92.33333333333333, 9.433333333333334, 250.0, 0.0, 0.0, -5.166666666666667, 25.26739046123922, 18.0, 20.07030849914685, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3247863247863248, 0.9233333333333333, 0.8575757575757575, 0.6944444444444444, 0.0, 0.0, 0.41388888888888886, 0.2526739046123922, 0.0, 0.2957583570209787, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:34,582] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 156999: loss -116.2296
[2017-11-02 10:16:34,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.9601965
  0.01015787  0.01741677  0.01222882], sum to 1.0000
[2017-11-02 10:16:34,928] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 85.0, 8.75, 255.0, 0.0, 0.0, -6.0, 30.64981916743956, 18.0, 19.39766716054579, 22.7, 1.0, 0.0], 
actual action is [4.0, 18.5], 
sim time next is 2921700.0000, 
raw observation next is [-1.0, 83.83333333333333, 8.575, 255.8333333333333, 0.0, 0.0, 4.0, 30.65481924221704, 18.5, 19.34470526916179, 22.7, 1.0, 14.75509289567445], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.3076923076923077, 0.8383333333333333, 0.7795454545454544, 0.710648148148148, 0.0, 0.0, 0.5666666666666667, 0.3065481924221704, 0.07142857142857142, 0.19210075273739843, 0.6714285714285714, 1.0, 0.17358932818440528], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:35,132] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-67.14446259]
 [-67.71973419]
 [-65.50917053]
 [-64.87150574]
 [-67.91646576]], R is [[-62.51775742]
 [-62.89258194]
 [-63.26365662]
 [-63.63101959]
 [-63.99470901]].
[2017-11-02 10:16:38,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   3.91578534e-17   7.11311138e-17   1.00166845e-15
   6.71035052e-17   0.00000000e+00   0.00000000e+00   1.04349147e-37
   1.37348673e-37], sum to 1.0000
[2017-11-02 10:16:38,536] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 6.175000000000001, 280.0, 0.0, 0.0, 2.0, 18.03969275947576, 25.0, 20.73415764496262, 21.5, 0.0, 42.87751269501418], 
actual action is [2.0, 20.0], 
sim time next is 2951400.0000, 
raw observation next is [-3.0, 84.0, 6.350000000000001, 280.0, 0.0, 0.0, 2.0, 17.52090770190568, 20.0, 20.78368885420486, 21.5, 0.0, 48.35054372621657], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.5772727272727274, 0.7777777777777778, 0.0, 0.0, 0.5333333333333333, 0.1752090770190568, 0.2857142857142857, 0.39766983631498015, 0.5, 0.0, 0.5688299261907832], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:39,404] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03257681
  0.02209376  0.86614937  0.07917997], sum to 1.0000
[2017-11-02 10:16:39,458] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10000, global step 158080: loss -171.2275
[2017-11-02 10:16:39,476] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 77.0, 4.6, 280.0, 0.0, 0.0, -9.0, 28.43739378761464, 18.0, 19.90891356564573, 21.5, 0.0, 0.0], 
actual action is [1.0, 20.0], 
sim time next is 2961300.0000, 
raw observation next is [-4.0, 77.0, 4.6, 280.0, 0.0, 0.0, 1.0, 27.02543604459577, 20.0, 19.75826959637991, 21.5, 0.0, 71.64345934893032], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.23076923076923078, 0.77, 0.41818181818181815, 0.7777777777777778, 0.0, 0.0, 0.5166666666666667, 0.27025436044595774, 0.2857142857142857, 0.25118137091141585, 0.5, 0.0, 0.8428642276344743], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:39,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.31068948e-23   2.57577758e-23   9.10156865e-22
   2.81756534e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:39,670] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.916666666666667, 84.08333333333334, 4.733333333333333, 278.3333333333333, 0.0, 0.0, -7.833333333333333, 26.96449006413749, 18.0, 20.10252993926642, 21.5, 0.0, 0.0], 
actual action is [-7.916666666666667, 18], 
sim time next is 2948400.0000, 
raw observation next is [-3.0, 84.0, 4.6, 280.0, 0.0, 0.0, -7.916666666666667, 29.08933340166707, 18.0, 19.97460409954481, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.41818181818181815, 0.7777777777777778, 0.0, 0.0, 0.3680555555555555, 0.29089333401667067, 0.0, 0.28208629993497275, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:42,106] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 158684: loss -13.1159
[2017-11-02 10:16:42,541] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 158756: loss -105.4648
[2017-11-02 10:16:44,237] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10000, global step 159049: loss -44.7792
[2017-11-02 10:16:45,600] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159262: loss -4.2496
[2017-11-02 10:16:47,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  7.07347333e-01   1.67853625e-06   1.14578063e-06   8.55372855e-05
   3.15030638e-06   2.60776747e-03   9.43542719e-02   2.89172810e-02
   1.66681916e-01], sum to 1.0000
[2017-11-02 10:16:47,578] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 5.908333333333333, 274.1666666666666, 249.75, 317.9166666666667, -8.0, 19.1081637586208, 18.0, 21.65811671273072, 22.7, 1.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 2979600.0000, 
raw observation next is [-3.0, 65.0, 5.866666666666667, 273.3333333333334, 243.5, 351.8333333333333, -8.0, 20.24430739582207, 18.0, 21.58969978775577, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.2564102564102564, 0.65, 0.5333333333333333, 0.7592592592592595, 0.6441798941798942, 0.35183333333333333, 0.36666666666666664, 0.2024430739582207, 0.0, 0.5128142553936813, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:50,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   1.85609385e-36   5.94657079e-37   8.49182672e-36
   1.73440464e-36   2.54988912e-02   7.60466829e-02   1.61364645e-01
   7.37089753e-01], sum to 1.0000
[2017-11-02 10:16:50,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 71.0, 1.75, 24.16666666666666, 0.0, 0.0, 0.0, 17.01860968294936, 25.0, 21.36820953578478, 21.5, 0.0, 39.32482674550968], 
actual action is [0.0, 25], 
sim time next is 3029400.0000, 
raw observation next is [-5.0, 71.0, 1.8, 25.0, 0.0, 0.0, 0.0, 16.74866205357864, 25.0, 21.3586106750835, 21.5, 0.0, 45.21450821351471], 
processed observation next is [1.0, 0.043478260869565216, 0.20512820512820512, 0.71, 0.16363636363636364, 0.06944444444444445, 0.0, 0.0, 0.5, 0.16748662053578642, 1.0, 0.4798015250119287, 0.5, 0.0, 0.531935390747232], 
reward next is -0.4989. 
=============================================
[2017-11-02 10:16:52,713] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10000, global step 160338: loss -8.0861
[2017-11-02 10:16:52,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.49196960e-22   1.67123275e-22   1.32802983e-20
   2.34662466e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:52,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 56.66666666666667, 4.833333333333333, 253.3333333333333, 78.5, 634.8333333333334, -6.416666666666667, 15.71493164548411, 18.0, 22.30966007086439, 22.7, 1.0, 0.0], 
actual action is [-6.333333333333333, 18], 
sim time next is 2994300.0000, 
raw observation next is [-1.25, 56.25, 5.050000000000001, 257.5, 76.25, 618.75, -6.333333333333333, 16.38173213193927, 18.0, 22.25061298499855, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.30128205128205127, 0.5625, 0.45909090909090916, 0.7152777777777778, 0.20171957671957672, 0.61875, 0.3944444444444445, 0.1638173213193927, 0.0, 0.6072304264283643, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:53,054] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160406: loss 60.2198
[2017-11-02 10:16:54,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-78.95678711]
 [-78.17741394]
 [-76.5462265 ]
 [-78.76947784]
 [-76.53187561]], R is [[-76.67449951]
 [-76.90775299]
 [-76.15271759]
 [-75.40439606]
 [-75.19260406]].
[2017-11-02 10:16:54,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160713: loss -30.6148
[2017-11-02 10:16:55,159] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160829: loss 44.6703
[2017-11-02 10:16:56,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.17979624e-17   5.12995281e-17   1.27452402e-15
   5.36401713e-17   1.03029292e-36   2.70924651e-36   2.45628007e-36
   8.44807500e-36], sum to 1.0000
[2017-11-02 10:16:56,082] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 73.75, 3.1, 30.0, 0.0, 0.0, -1.0, 21.52933494848502, 22.0, 20.20982783362064, 21.5, 0.0, 40.49985004254074], 
actual action is [-11.0, 18], 
sim time next is 3050400.0000, 
raw observation next is [-6.0, 72.66666666666667, 3.1, 33.33333333333334, 0.0, 0.0, -11.0, 24.10944723237614, 18.0, 20.24252135560981, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.1794871794871795, 0.7266666666666667, 0.2818181818181818, 0.09259259259259262, 0.0, 0.0, 0.31666666666666665, 0.2410944723237614, 0.0, 0.3203601936585443, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:56,403] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10000, global step 161073: loss 11.3743
[2017-11-02 10:16:56,596] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 161120: loss -7.3748
[2017-11-02 10:16:56,921] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 161188: loss -10.8377
[2017-11-02 10:16:57,987] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 161404: loss -66.0719
[2017-11-02 10:16:59,459] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10000, global step 161696: loss 6.6296
[2017-11-02 10:17:00,689] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 161941: loss 4.4507
[2017-11-02 10:17:06,122] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-48.99343109]
 [-48.96157074]
 [-49.19911194]
 [-49.78742981]
 [-48.62319946]], R is [[-49.44449615]
 [-49.35947418]
 [-49.3528595 ]
 [-49.3599968 ]
 [-49.28119659]].
[2017-11-02 10:17:06,415] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.52160549
  0.20395221  0.12136247  0.15307981], sum to 1.0000
[2017-11-02 10:17:06,460] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 96.0, 4.6, 95.0, 0.0, 0.0, 4.0, 11.57028719908616, 19.5, 22.69730091091073, 21.5, 0.0, 36.3300336272559], 
actual action is [4.0, 24.5], 
sim time next is 3098100.0000, 
raw observation next is [-1.0, 96.66666666666666, 4.6, 95.83333333333334, 0.0, 0.0, 4.0, 11.5404220058684, 24.5, 22.75958509583112, 21.5, 0.0, 32.05939367128691], 
processed observation next is [1.0, 0.8695652173913043, 0.3076923076923077, 0.9666666666666666, 0.41818181818181815, 0.2662037037037037, 0.0, 0.0, 0.5666666666666667, 0.115404220058684, 0.9285714285714286, 0.6799407279758743, 0.5, 0.0, 0.3771693373092578], 
reward next is -0.3395. 
=============================================
[2017-11-02 10:17:11,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.16888538e-11   5.47137405e-11   6.96645797e-11
   3.40805301e-11   1.63302222e-23   4.31270849e-24   4.28202061e-24
   1.90861393e-23], sum to 1.0000
[2017-11-02 10:17:11,722] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 92.0, 4.808333333333333, 90.0, 0.0, 0.0, 4.0, 11.03231203137435, 20.0, 22.90820110570951, 21.5, 0.0, 46.20626405396297], 
actual action is [-6.0, 18], 
sim time next is 3094800.0000, 
raw observation next is [-1.0, 92.0, 4.766666666666667, 90.0, 0.0, 0.0, -6.0, 11.99782007964585, 18.0, 23.00760046235158, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3076923076923077, 0.92, 0.43333333333333335, 0.25, 0.0, 0.0, 0.4, 0.1199782007964585, 0.0, 0.7153714946216542, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:12,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-49.95063019]
 [-48.98101044]
 [-49.24435425]
 [-48.68025208]
 [-49.44340515]], R is [[-50.35266876]
 [-50.84914398]
 [-51.34065247]
 [-51.82724762]
 [-52.30897522]].
[2017-11-02 10:17:13,060] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 164401: loss 3.3417
[2017-11-02 10:17:14,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-42.81797791]
 [-42.06270599]
 [-41.54441071]
 [-41.8454628 ]
 [-39.98720932]], R is [[-40.99336243]
 [-41.08478928]
 [-41.20298767]
 [-41.33148575]
 [-41.33478546]].
[2017-11-02 10:17:15,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.96414441
  0.00830187  0.02462195  0.00293171], sum to 1.0000
[2017-11-02 10:17:15,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 3.1, 100.0, 112.5, 811.0, 1.916666666666667, 18.39757241045611, 22.0, 21.61800637917242, 22.7, 1.0, 10.64414713621141], 
actual action is [2.0, 22.5], 
sim time next is 3067500.0000, 
raw observation next is [-2.916666666666667, 54.58333333333333, 3.1, 97.49999999999999, 112.75, 812.0, 2.0, 18.72488386007567, 22.5, 21.56638299473848, 22.7, 1.0, 10.23906705274581], 
processed observation next is [1.0, 0.5217391304347826, 0.2585470085470085, 0.5458333333333333, 0.2818181818181818, 0.2708333333333333, 0.29828042328042326, 0.812, 0.5333333333333333, 0.18724883860075672, 0.6428571428571429, 0.5094832849626398, 0.6714285714285714, 1.0, 0.12045961238524482], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:16,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.33186476e-15   3.35659167e-15   8.17136157e-15
   2.14664153e-15   5.41999108e-37   1.70703814e-37   1.40520013e-37
   1.25355430e-37], sum to 1.0000
[2017-11-02 10:17:16,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.083333333333333, 99.99999999999999, 1.375, 45.83333333333333, 0.0, 0.0, 6.0, 15.71019229933153, 20.0, 21.49960698190861, 21.5, 0.0, 34.62931940761788], 
actual action is [-3.916666666666667, 18], 
sim time next is 3118200.0000, 
raw observation next is [1.166666666666667, 100.0, 1.25, 41.66666666666667, 0.0, 0.0, -3.916666666666667, 16.56498882855075, 18.0, 21.45658651129359, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.3632478632478633, 1.0, 0.11363636363636363, 0.11574074074074076, 0.0, 0.0, 0.4347222222222222, 0.1656498882855075, 0.0, 0.49379807304194145, 0.5, 0.0, 0.0], 
reward next is -0.0062. 
=============================================
[2017-11-02 10:17:17,241] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10500, global step 165512: loss 1.1583
[2017-11-02 10:17:19,735] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 166260: loss 3.3344
[2017-11-02 10:17:20,245] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10500, global step 166406: loss 20.7939
[2017-11-02 10:17:20,369] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 166442: loss 6.4352
[2017-11-02 10:17:21,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   2.78699130e-09   4.33214886e-09   9.57645163e-09
   4.34910419e-09   2.24199245e-16   3.96775114e-17   4.15423570e-17
   4.73286177e-17], sum to 1.0000
[2017-11-02 10:17:21,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 3.6, 200.0, 98.16666666666667, 749.0, 2.0, 7.005212107159457, 18.0, 23.89308447882935, 22.7, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 3163500.0000, 
raw observation next is [7.0, 100.0, 3.6, 200.0, 96.75, 742.0, 2.0, 6.988365437584465, 18.0, 23.93845043498519, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 1.0, 0.32727272727272727, 0.5555555555555556, 0.25595238095238093, 0.742, 0.5333333333333333, 0.06988365437584465, 0.0, 0.8483500621407413, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0070. 
=============================================
[2017-11-02 10:17:22,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167153: loss 0.6916
[2017-11-02 10:17:24,138] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.38254231
  0.01869439  0.44786558  0.15089776], sum to 1.0000
[2017-11-02 10:17:24,197] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 100.0, 3.35, 95.0, 0.0, 0.0, 5.0, 25.5396795197376, 22.0, 20.46522150224672, 21.5, 0.0, 16.07714325770068], 
actual action is [5.0, 22.5], 
sim time next is 3108900.0000, 
raw observation next is [0.0, 100.0, 3.308333333333334, 92.5, 0.0, 0.0, 5.0, 24.53867623230494, 22.5, 20.42380256321822, 21.5, 0.0, 38.45155023064413], 
processed observation next is [1.0, 1.0, 0.3333333333333333, 1.0, 0.30075757575757583, 0.2569444444444444, 0.0, 0.0, 0.5833333333333334, 0.2453867623230494, 0.6428571428571429, 0.3462575090311744, 0.5, 0.0, 0.4523711791840486], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:24,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99999523e-01   6.71178597e-08   1.42723010e-07   1.70853568e-07
   8.94365115e-08   1.82482298e-13   2.62682163e-14   1.69485953e-13
   9.96082896e-14], sum to 1.0000
[2017-11-02 10:17:24,521] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 100.0, 2.325, 340.0, 0.0, 0.0, -2.0, 13.88212850917279, 18.0, 20.87926907308897, 21.5, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 3185400.0000, 
raw observation next is [3.0, 100.0, 2.416666666666667, 340.0, 0.0, 0.0, -2.0, 14.24417241446212, 18.0, 20.86266633498365, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.41025641025641024, 1.0, 0.21969696969696972, 0.9444444444444444, 0.0, 0.0, 0.4666666666666667, 0.1424417241446212, 0.0, 0.40895233356909294, 0.5, 0.0, 0.0], 
reward next is -0.0910. 
=============================================
[2017-11-02 10:17:25,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   4.26663201e-15   5.30488815e-15   1.58805447e-14
   4.75933583e-15   5.84235329e-36   2.23803893e-36   7.03282830e-36
   5.98528268e-36], sum to 1.0000
[2017-11-02 10:17:25,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 14.13151332608232, 25.0, 20.33450250826686, 22.0, 1.0, 70.8081818498045], 
actual action is [2.0, 20.0], 
sim time next is 3222900.0000, 
raw observation next is [-3.0, 92.0, 5.1, 267.5, 0.0, 0.0, 2.0, 13.09649095235479, 20.0, 20.65587076873092, 22.0, 1.0, 52.2441600835602], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.92, 0.4636363636363636, 0.7430555555555556, 0.0, 0.0, 0.5333333333333333, 0.1309649095235479, 0.2857142857142857, 0.379410109818703, 0.5714285714285714, 1.0, 0.6146371774536494], 
reward next is -0.5663. 
=============================================
[2017-11-02 10:17:26,534] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10500, global step 168396: loss 0.5406
[2017-11-02 10:17:27,143] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168587: loss 2.0356
[2017-11-02 10:17:27,212] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.01885145e-09   1.20126997e-09   1.47668577e-09
   1.02209030e-09   4.75175428e-22   1.73468090e-22   6.90237793e-22
   1.20329503e-20], sum to 1.0000
[2017-11-02 10:17:27,222] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.416666666666667, 97.08333333333334, 3.6, 307.5, 0.0, 0.0, -3.5, 14.94524441417865, 18.0, 21.5034471457281, 20.8, 0.0, 0.0], 
actual action is [-3.583333333333333, 18], 
sim time next is 3199200.0000, 
raw observation next is [1.333333333333333, 97.66666666666666, 3.6, 310.0, 0.0, 0.0, -3.583333333333333, 15.61143431794352, 18.0, 21.405185067443, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.3675213675213675, 0.9766666666666666, 0.32727272727272727, 0.8611111111111112, 0.0, 0.0, 0.4402777777777778, 0.1561143431794352, 0.0, 0.4864550096347143, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:27,413] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168664: loss 0.2490
[2017-11-02 10:17:29,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 169243: loss 1.3115
[2017-11-02 10:17:29,560] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99991417e-01   1.26355417e-06   2.22336644e-06   3.26862028e-06
   1.75753985e-06   5.09944864e-11   1.55614601e-11   2.08112260e-11
   1.07810469e-10], sum to 1.0000
[2017-11-02 10:17:29,572] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.833333333333334, 100.0, 5.616666666666666, 160.0, 88.33333333333334, 477.0, 1.75, 14.01995407727281, 18.0, 22.06763351519534, 22.7, 1.0, 0.0], 
actual action is [1.833333333333334, 18], 
sim time next is 3142500.0000, 
raw observation next is [6.916666666666666, 100.0, 5.358333333333333, 160.0, 89.66666666666666, 498.25, 1.833333333333334, 13.98551240332193, 18.0, 22.082456083505, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.5106837606837606, 1.0, 0.4871212121212121, 0.4444444444444444, 0.23721340388007053, 0.49825, 0.5305555555555556, 0.1398551240332193, 0.0, 0.5832080119292858, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0140. 
=============================================
[2017-11-02 10:17:30,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 169554: loss 0.8239
[2017-11-02 10:17:30,841] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10500, global step 169722: loss 2.0476
[2017-11-02 10:17:31,134] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 169829: loss 1.3761
[2017-11-02 10:17:31,617] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10500, global step 169992: loss 1.6063
[2017-11-02 10:17:31,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 170041: loss 0.4262
[2017-11-02 10:17:34,071] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   5.58206740e-14   1.07738457e-13   1.35949168e-13
   3.33737791e-14   1.46939021e-34   1.96578885e-34   5.35123829e-34
   3.05070888e-33], sum to 1.0000
[2017-11-02 10:17:34,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   5.78386297e-11   8.61267169e-11   9.90647148e-11
   3.72341810e-11   3.33936608e-28   4.72437549e-28   9.01714911e-28
   3.50592089e-27], sum to 1.0000
[2017-11-02 10:17:34,097] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5, 100.0, 4.35, 295.0, 0.0, 0.0, 4.583333333333333, 14.79285703331917, 23.0, 20.58456322805168, 20.8, 0.0, 101.3921528121153], 
actual action is [-5.5, 18.0], 
sim time next is 3206100.0000, 
raw observation next is [-0.5833333333333334, 100.0, 4.225, 295.8333333333333, 0.0, 0.0, -5.5, 15.59803297055206, 18.0, 20.76000102118353, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.31837606837606836, 1.0, 0.38409090909090904, 0.8217592592592592, 0.0, 0.0, 0.4083333333333333, 0.1559803297055206, 0.0, 0.3942858601690758, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0057. 
=============================================
[2017-11-02 10:17:34,100] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 100.0, 3.016666666666667, 323.3333333333334, 0.0, 0.0, -2.75, 12.61720196644569, 18.0, 21.72409020879828, 21.5, 0.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 3189300.0000, 
raw observation next is [2.083333333333333, 100.0, 3.058333333333334, 321.6666666666667, 0.0, 0.0, -2.833333333333333, 13.15839168028734, 18.0, 21.64946593098716, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.3867521367521367, 1.0, 0.27803030303030307, 0.8935185185185186, 0.0, 0.0, 0.4527777777777778, 0.1315839168028734, 0.0, 0.5213522758553084, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:34,371] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 171018: loss 0.5385
[2017-11-02 10:17:35,557] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.98035371e-01   2.50024368e-06   2.30586443e-06   2.86234763e-06
   1.61595460e-06   1.16349453e-04   8.08047043e-05   7.93940388e-04
   9.64126259e-04], sum to 1.0000
[2017-11-02 10:17:35,584] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 77.0, 5.1, 310.0, 34.0, 307.5, -8.916666666666668, 14.51198060033711, 18.0, 21.88129812478289, 22.0, 1.0, 0.0], 
actual action is [-9.0, 18], 
sim time next is 3258300.0000, 
raw observation next is [-4.0, 76.0, 5.016666666666667, 310.8333333333333, 29.83333333333333, 273.5833333333333, -9.0, 15.4283237831425, 18.0, 21.82760194582755, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.23076923076923078, 0.76, 0.45606060606060606, 0.8634259259259258, 0.07892416225749557, 0.2735833333333333, 0.35, 0.154283237831425, 0.0, 0.5468002779753641, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:37,577] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.09614896e-17   4.02571986e-12   3.98501631e-12   2.88566957e-12
   2.23423211e-12   1.01636551e-01   6.89430460e-02   1.84602529e-01
   6.44817889e-01], sum to 1.0000
[2017-11-02 10:17:37,659] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.75, 100.0, 3.975, 297.5, 0.0, 0.0, -5.666666666666667, 17.27151845595328, 18.0, 20.91256812943881, 20.8, 0.0, 0.0], 
actual action is [4.25, 23.0], 
sim time next is 3207000.0000, 
raw observation next is [-0.8333333333333334, 100.0, 3.85, 298.3333333333333, 0.0, 0.0, 4.25, 15.82761006792991, 23.0, 20.88029647885863, 20.8, 0.0, 55.42856349241761], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.31196581196581197, 1.0, 0.35000000000000003, 0.8287037037037036, 0.0, 0.0, 0.5708333333333333, 0.1582761006792991, 0.7142857142857143, 0.41147092555123266, 0.4000000000000001, 0.0, 0.652100746969619], 
reward next is -0.5869. 
=============================================
[2017-11-02 10:17:38,729] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   2.25948519e-13   3.12885758e-13   8.15312390e-13
   1.54290534e-13   1.86755000e-35   1.34699441e-35   1.74921509e-35
   2.20151926e-35], sum to 1.0000
[2017-11-02 10:17:38,753] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666667, 100.0, 4.85, 291.6666666666667, 0.0, 0.0, -5.083333333333333, 18.79075802529865, 18.0, 20.22986909803039, 20.8, 0.0, 0.0], 
actual action is [-5.166666666666667, 18], 
sim time next is 3204900.0000, 
raw observation next is [-0.25, 100.0, 4.725, 292.5, 0.0, 0.0, -5.166666666666667, 19.74708570925601, 18.0, 20.234321202887, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.3269230769230769, 1.0, 0.4295454545454545, 0.8125, 0.0, 0.0, 0.41388888888888886, 0.1974708570925601, 0.0, 0.3191887432695713, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0808. 
=============================================
[2017-11-02 10:17:39,706] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 172718: loss -78.7692
[2017-11-02 10:17:40,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   5.89204141e-13   7.58170978e-13   2.20767588e-12
   4.23210891e-13   5.06875368e-33   1.73299789e-33   7.45828390e-33
   3.12639180e-33], sum to 1.0000
[2017-11-02 10:17:40,731] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 5.1, 269.1666666666667, 0.0, 0.0, 2.0, 17.91704713064209, 23.5, 20.45608088608346, 22.0, 1.0, 70.47810737683746], 
actual action is [2.0, 18.5], 
sim time next is 3222600.0000, 
raw observation next is [-3.0, 92.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 16.86762990679978, 18.5, 20.55003182807358, 22.0, 1.0, 49.76715697650502], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.92, 0.4636363636363636, 0.7453703703703703, 0.0, 0.0, 0.5333333333333333, 0.1686762990679978, 0.07142857142857142, 0.3642902611533683, 0.5714285714285714, 1.0, 0.5854959644294708], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:41,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   2.25804499e-14   3.35996252e-14   7.27639045e-14
   1.35999407e-14   7.39083750e-36   2.41399628e-36   1.46214852e-35
   1.03979715e-35], sum to 1.0000
[2017-11-02 10:17:41,915] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 71.16666666666666, 5.741666666666666, 331.6666666666667, 0.0, 0.0, -12.0, 18.70345888672108, 18.0, 21.11280780556271, 20.8, 0.0, 0.0], 
actual action is [-12.0, 18], 
sim time next is 3286800.0000, 
raw observation next is [-7.0, 70.0, 5.7, 330.0, 0.0, 0.0, -12.0, 21.15648421012687, 18.0, 21.02900513590782, 20.8, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.15384615384615385, 0.7, 0.5181818181818182, 0.9166666666666666, 0.0, 0.0, 0.3, 0.2115648421012687, 0.0, 0.43271501941540286, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:44,111] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11000, global step 173808: loss -12.8133
[2017-11-02 10:17:44,738] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 174002: loss -267.8194
[2017-11-02 10:17:44,995] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   5.00235873e-14   3.35965488e-14   9.89750409e-14
   2.97050016e-14   5.72432602e-29   2.17928317e-29   1.14314901e-27
   6.82670244e-29], sum to 1.0000
[2017-11-02 10:17:45,072] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 82.0, 6.783333333333333, 258.3333333333334, 110.3333333333333, 771.6666666666666, -7.55, 14.16619716490613, 18.0, 22.30043816836623, 22.0, 1.0, 0.0], 
actual action is [-7.5, 18], 
sim time next is 3236100.0000, 
raw observation next is [-2.45, 81.0, 6.741666666666667, 259.1666666666666, 110.6666666666667, 776.5833333333333, -7.5, 14.23520180471849, 18.0, 22.28616695667752, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.27051282051282055, 0.81, 0.6128787878787879, 0.7199074074074071, 0.2927689594356262, 0.7765833333333333, 0.375, 0.1423520180471849, 0.0, 0.6123095652396456, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:17:45,574] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11000, global step 174250: loss 0.5454
[2017-11-02 10:17:46,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.45471154e-03   9.10501927e-04   5.04764088e-04   3.42626212e-04
   3.62814259e-04   1.55881615e-02   4.95528476e-03   9.13303614e-01
   6.25774115e-02], sum to 1.0000
[2017-11-02 10:17:46,768] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 67.0, 4.266666666666667, 318.3333333333334, 0.0, 0.0, 1.0, 16.31275513054737, 19.0, 21.24833995205496, 22.0, 1.0, 48.25888433561532], 
actual action is [1.0, 21.0], 
sim time next is 3261300.0000, 
raw observation next is [-4.0, 66.0, 4.183333333333333, 319.1666666666667, 0.0, 0.0, 1.0, 15.36229875510024, 21.0, 21.30828074309249, 22.0, 1.0, 50.96140654074158], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.23076923076923078, 0.66, 0.38030303030303025, 0.8865740740740742, 0.0, 0.0, 0.5166666666666667, 0.1536229875510024, 0.42857142857142855, 0.4726115347274984, 0.5714285714285714, 1.0, 0.599545959302842], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:46,913] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 174621: loss -207.5890
[2017-11-02 10:17:49,233] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175218: loss 127.6579
[2017-11-02 10:17:53,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176271: loss 3.1795
[2017-11-02 10:17:53,986] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11000, global step 176273: loss -3.7691
[2017-11-02 10:17:54,120] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176301: loss 1.1357
[2017-11-02 10:17:54,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.33156148e-27   4.68364811e-19   3.97641670e-19   2.09785579e-19
   2.33405062e-19   5.60066141e-02   1.52051887e-02   8.83716881e-01
   4.50713001e-02], sum to 1.0000
[2017-11-02 10:17:54,581] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.166666666666667, 66.0, 3.1, 168.3333333333333, 0.0, 0.0, 0.916666666666667, 22.90575852670105, 20.0, 20.50225617524146, 20.8, 0.0, 56.25624311723973], 
actual action is [0.833333333333333, 22.0], 
sim time next is 3363300.0000, 
raw observation next is [-4.25, 66.5, 3.1, 167.5, 0.0, 0.0, 0.833333333333333, 22.72013993443753, 22.0, 20.50252607101654, 20.8, 0.0, 31.52312728943306], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.22435897435897437, 0.665, 0.2818181818181818, 0.4652777777777778, 0.0, 0.0, 0.5138888888888888, 0.2272013993443753, 0.5714285714285714, 0.35750372443093426, 0.4000000000000001, 0.0, 0.37086032105215366], 
reward next is -0.3763. 
=============================================
[2017-11-02 10:17:55,306] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176596: loss -15.4023
[2017-11-02 10:17:55,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   2.11662476e-11   3.72796585e-11   3.74324217e-11
   1.27217559e-11   5.62589960e-26   6.64310615e-26   2.44653219e-24
   3.54224825e-25], sum to 1.0000
[2017-11-02 10:17:55,476] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.416666666666666, 73.5, 3.1, 164.1666666666667, 0.0, 0.0, -10.33333333333333, 22.68098828490216, 18.0, 20.64901490989127, 20.8, 0.0, 0.0], 
actual action is [-10.416666666666666, 18], 
sim time next is 3367800.0000, 
raw observation next is [-5.5, 74.0, 3.1, 165.0, 0.0, 0.0, -10.41666666666667, 25.17416100534252, 18.0, 20.59003643229631, 20.8, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 1.0, 0.19230769230769232, 0.74, 0.2818181818181818, 0.4583333333333333, 0.0, 0.0, 0.3263888888888888, 0.2517416100534252, 0.0, 0.37000520461375835, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0300. 
=============================================
[2017-11-02 10:17:55,675] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176685: loss -87.7080
[2017-11-02 10:17:57,048] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176966: loss 87.3385
[2017-11-02 10:17:57,745] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11000, global step 177113: loss 29.2170
[2017-11-02 10:17:57,859] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 177134: loss 13.5767
[2017-11-02 10:17:58,828] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11000, global step 177294: loss -4.8506
[2017-11-02 10:18:02,036] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 177773: loss 0.7356
[2017-11-02 10:18:08,037] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999523e-01   8.06267408e-08   9.37057791e-08   1.25633989e-07
   6.06192785e-08   1.48243912e-13   4.75348060e-12   8.48509457e-11
   4.70211717e-12], sum to 1.0000
[2017-11-02 10:18:08,075] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.166666666666667, 46.66666666666667, 5.1, 223.3333333333333, 78.0, 616.3333333333334, -7.25, 15.74239794504046, 18.0, 22.16279026193547, 22.0, 1.0, 0.0], 
actual action is [-7.166666666666667, 18], 
sim time next is 3340500.0000, 
raw observation next is [-2.083333333333333, 46.33333333333334, 5.1, 221.6666666666667, 75.75, 601.9166666666666, -7.166666666666667, 15.97203572696861, 18.0, 22.14796751004039, 22.0, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.2799145299145299, 0.46333333333333343, 0.4636363636363636, 0.6157407407407409, 0.2003968253968254, 0.6019166666666667, 0.38055555555555554, 0.1597203572696861, 0.0, 0.5925667871486274, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:09,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-68.38537598]
 [-67.89758301]
 [-67.60417175]
 [-68.86851501]
 [-68.94946289]], R is [[-69.29692841]
 [-69.10499573]
 [-68.91425323]
 [-68.72302246]
 [-68.52742767]].
[2017-11-02 10:18:14,102] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 180594: loss -20.1167
[2017-11-02 10:18:18,844] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11500, global step 181789: loss 12.9678
[2017-11-02 10:18:19,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.30264375e-13   2.21301208e-13   5.29498700e-13
   1.41567666e-13   8.66603088e-33   1.43013919e-32   3.36827327e-32
   1.12792040e-32], sum to 1.0000
[2017-11-02 10:18:19,398] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.583333333333333, 62.91666666666666, 4.6, 184.1666666666667, 0.0, 0.0, 2.333333333333333, 17.7501572050836, 22.0, 21.13835311662675, 22.0, 1.0, 45.69035383544946], 
actual action is [-7.583333333333333, 18], 
sim time next is 3396600.0000, 
raw observation next is [-2.5, 62.5, 4.6, 185.0, 2.0, 107.0, -7.583333333333333, 19.77878718256328, 18.0, 21.19833163696351, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.30434782608695654, 0.2692307692307692, 0.625, 0.41818181818181815, 0.5138888888888888, 0.005291005291005291, 0.107, 0.3736111111111111, 0.19778787182563282, 0.0, 0.4569045195662156, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:20,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   8.39944552e-16   2.86702680e-16   1.39373787e-15
   4.52231949e-16   1.63560917e-31   1.32982195e-31   3.26792084e-31
   3.42884150e-32], sum to 1.0000
[2017-11-02 10:18:20,129] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 67.0, 8.2, 216.6666666666667, 52.83333333333334, 447.6666666666667, -3.0, 12.26693396223711, 18.0, 22.35944074046187, 22.0, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 3429900.0000, 
raw observation next is [2.0, 67.0, 8.2, 217.5, 48.75, 415.0, -3.0, 12.47407302557438, 18.0, 22.32980959931749, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.38461538461538464, 0.67, 0.7454545454545454, 0.6041666666666666, 0.12896825396825398, 0.415, 0.45, 0.12474073025574381, 0.0, 0.618544228473927, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 10:18:20,360] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11500, global step 182097: loss 37.1075
[2017-11-02 10:18:21,209] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 182260: loss -26.7464
[2017-11-02 10:18:22,259] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 182483: loss 2.0839
[2017-11-02 10:18:23,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.19179503e-16   5.97596369e-17   3.73223945e-16
   6.42419963e-17   2.49021190e-32   7.90615166e-32   5.64770485e-33
   5.80975850e-33], sum to 1.0000
[2017-11-02 10:18:23,399] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 46.0, 9.65, 227.5, 116.5, 813.75, 8.0, 11.55930564432577, 24.5, 22.58056188536528, 22.0, 1.0, 47.38691304132805], 
actual action is [8.0, 19.5], 
sim time next is 3414000.0000, 
raw observation next is [3.0, 46.33333333333334, 9.433333333333334, 226.6666666666667, 116.6666666666667, 814.8333333333334, 8.0, 10.49933210142428, 19.5, 22.6348467392647, 22.0, 1.0, 43.32834436558334], 
processed observation next is [0.5, 0.5217391304347826, 0.41025641025641024, 0.46333333333333343, 0.8575757575757575, 0.6296296296296298, 0.30864197530864207, 0.8148333333333334, 0.6333333333333333, 0.1049933210142428, 0.21428571428571427, 0.6621209627520999, 0.5714285714285714, 1.0, 0.5097452278303922], 
reward next is -0.4693. 
=============================================
[2017-11-02 10:18:24,090] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 182904: loss -0.0472
[2017-11-02 10:18:26,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.07826552e-11   1.33722183e-11   3.13218063e-11
   7.34304111e-12   7.71448107e-21   1.09869304e-20   2.24209789e-21
   1.62863189e-21], sum to 1.0000
[2017-11-02 10:18:26,288] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 67.0, 7.2, 260.0, 0.0, 0.0, 6.0, 13.25850371631552, 19.0, 21.26914893165371, 20.8, 0.0, 58.62089824663666], 
actual action is [-4.0, 18], 
sim time next is 3470700.0000, 
raw observation next is [0.9166666666666666, 67.41666666666666, 7.283333333333333, 260.0, 0.0, 0.0, -4.0, 14.61954602976623, 18.0, 21.316461212252, 20.8, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.35683760683760685, 0.6741666666666666, 0.6621212121212121, 0.7222222222222222, 0.0, 0.0, 0.43333333333333335, 0.1461954602976623, 0.0, 0.4737801731788573, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:18:27,030] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99947906e-01   9.76412866e-06   7.68338941e-06   1.19577844e-05
   4.43948238e-06   4.25639882e-06   6.70054851e-06   2.30373553e-06
   5.05861135e-06], sum to 1.0000
[2017-11-02 10:18:27,056] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-37.3752861 ]
 [-36.811409  ]
 [-36.87651825]
 [-36.90394592]
 [-36.74664307]], R is [[-38.04278564]
 [-37.67791748]
 [-37.30113983]
 [-36.92812729]
 [-37.21723557]].
[2017-11-02 10:18:27,059] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 78.99999999999999, 6.566666666666666, 210.0, 0.0, 0.0, -4.0, 21.43016237893999, 18.0, 20.795836922548, 22.0, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 3442200.0000, 
raw observation next is [1.0, 79.00000000000001, 6.433333333333334, 210.0, 0.0, 0.0, -4.0, 22.60733380472081, 18.0, 20.72177668581648, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.358974358974359, 0.7900000000000001, 0.5848484848484848, 0.5833333333333334, 0.0, 0.0, 0.43333333333333335, 0.22607333804720808, 0.0, 0.3888252408309256, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:28,333] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.15675834e-16   4.03403544e-16   1.28577526e-15
   2.06958445e-16   3.16731236e-34   5.00452210e-34   2.73890643e-34
   1.98647387e-34], sum to 1.0000
[2017-11-02 10:18:28,351] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.583333333333333, 72.0, 5.908333333333333, 215.8333333333333, 0.0, 0.0, -3.333333333333333, 24.33655953096037, 18.0, 20.3554271864397, 22.0, 1.0, 0.0], 
actual action is [-3.416666666666667, 18], 
sim time next is 3436200.0000, 
raw observation next is [1.5, 73.0, 5.95, 215.0, 0.0, 0.0, -3.416666666666667, 24.96169989415359, 18.0, 20.26954398424778, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.3717948717948718, 0.73, 0.5409090909090909, 0.5972222222222222, 0.0, 0.0, 0.44305555555555554, 0.24961699894153588, 0.0, 0.32422056917825415, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:28,491] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11500, global step 184380: loss 42.7501
[2017-11-02 10:18:28,653] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184426: loss 20.9203
[2017-11-02 10:18:28,973] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184512: loss -0.4024
[2017-11-02 10:18:29,418] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184625: loss -123.3545
[2017-11-02 10:18:29,655] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184686: loss -14.8867
[2017-11-02 10:18:30,151] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11500, global step 184823: loss 46.0384
[2017-11-02 10:18:30,776] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184967: loss -5.7895
[2017-11-02 10:18:31,148] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11500, global step 185051: loss -61.0266
[2017-11-02 10:18:31,934] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 185250: loss 0.2851
[2017-11-02 10:18:32,369] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-19.66341209]
 [-18.76362038]
 [-19.36914253]
 [-19.55253983]
 [-19.19919777]], R is [[-19.14858055]
 [-18.97017479]
 [-19.39599991]
 [-20.20203972]
 [-21.00001907]].
[2017-11-02 10:18:34,699] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 186108: loss 39.2160
[2017-11-02 10:18:41,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.74602997e-01   3.24418390e-04   1.43555226e-02
   1.07170651e-02], sum to 1.0000
[2017-11-02 10:18:41,514] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 69.5, 3.375, 310.0, 0.0, 0.0, -8.0, 27.8014242046544, 18.0, 19.97721140734435, 21.5, 0.0, 0.0], 
actual action is [2.0, 18.5], 
sim time next is 3550800.0000, 
raw observation next is [-3.0, 69.0, 3.633333333333334, 306.6666666666667, 0.0, 0.0, 2.0, 27.62006880177538, 18.5, 19.88638892076835, 21.5, 0.0, 33.0218207076156], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.2564102564102564, 0.69, 0.3303030303030304, 0.8518518518518519, 0.0, 0.0, 0.5333333333333333, 0.27620068801775377, 0.07142857142857142, 0.2694841315383358, 0.5, 0.0, 0.38849200832488945], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:42,897] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.82083797e-01   7.20537500e-05   9.40957107e-03
   8.43468588e-03], sum to 1.0000
[2017-11-02 10:18:42,935] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 70.0, 3.1, 276.6666666666667, 0.0, 0.0, -11.0, 32.3902770247611, 18.0, 19.45523761531435, 21.5, 0.0, 0.0], 
actual action is [-1.0, 18.5], 
sim time next is 3565500.0000, 
raw observation next is [-6.0, 70.0, 3.225, 275.8333333333333, 0.0, 0.0, -1.0, 32.50787407892199, 18.5, 19.33031008754481, 21.5, 0.0, 33.17444956622243], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.1794871794871795, 0.7, 0.2931818181818182, 0.7662037037037036, 0.0, 0.0, 0.48333333333333334, 0.32507874078921994, 0.07142857142857142, 0.19004429822068708, 0.5, 0.0, 0.390287641955558], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:44,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.03214786e-17   1.34449565e-18   6.43187148e-18
   2.61398255e-18   7.43049427e-30   6.03177772e-32   4.19609354e-31
   3.98578866e-32], sum to 1.0000
[2017-11-02 10:18:44,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 8.783333333333335, 260.0, 57.91666666666666, 493.8333333333333, -2.0, 10.45665403880816, 18.0, 22.9078548753442, 22.0, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 3516000.0000, 
raw observation next is [3.0, 49.0, 8.566666666666666, 260.0, 53.83333333333334, 462.6666666666667, -2.0, 10.5968220002458, 18.0, 22.92469532039456, 22.0, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.41025641025641024, 0.49, 0.7787878787878788, 0.7222222222222222, 0.14241622574955912, 0.46266666666666667, 0.4666666666666667, 0.105968220002458, 0.0, 0.7035279029135084, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0106. 
=============================================
[2017-11-02 10:18:44,737] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 189107: loss -2.7557
[2017-11-02 10:18:47,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.28857044e-09   6.21570781e-11   3.14574027e-11   4.01365226e-11
   2.76494556e-11   9.40317988e-01   3.62947932e-03   1.24953464e-02
   4.35571782e-02], sum to 1.0000
[2017-11-02 10:18:48,021] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.25, 70.0, 4.85, 290.0, 91.0, 487.75, -1.333333333333334, 22.13500228350535, 18.5, 20.48040040331338, 22.7, 1.0, 81.59638298223582], 
actual action is [-1.25, 19.0], 
sim time next is 3574200.0000, 
raw observation next is [-6.166666666666666, 70.0, 4.933333333333334, 290.0, 92.0, 508.6666666666666, -1.25, 21.1966646190759, 19.0, 20.61390208840924, 22.7, 1.0, 55.26106999846727], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.17521367521367523, 0.7, 0.4484848484848485, 0.8055555555555556, 0.24338624338624337, 0.5086666666666666, 0.4791666666666667, 0.211966646190759, 0.14285714285714285, 0.3734145840584629, 0.6714285714285714, 1.0, 0.6501302352760855], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:49,011] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12000, global step 190107: loss 31.3040
[2017-11-02 10:18:50,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-34.31914139]
 [-33.46832275]
 [-33.01854706]
 [-32.9153595 ]
 [-34.06440353]], R is [[-37.6366539 ]
 [-38.26028824]
 [-38.87768555]
 [-38.85598755]
 [-38.89196014]].
[2017-11-02 10:18:51,231] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 190577: loss -139.6836
[2017-11-02 10:18:52,613] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12000, global step 190907: loss -152.8328
[2017-11-02 10:18:53,502] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.18004718e-30   9.24341518e-23   2.41423433e-23   1.94974404e-23
   2.73668754e-23   7.98066631e-02   2.82802968e-03   4.16922420e-02
   8.75673056e-01], sum to 1.0000
[2017-11-02 10:18:53,617] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.916666666666667, 69.58333333333333, 5.149999999999999, 287.5, 95.0, 571.4166666666667, -11.0, 23.6682594346008, 18.0, 20.53795143941004, 22.7, 1.0, 0.0], 
actual action is [-0.916666666666667, 23.0], 
sim time next is 3575400.0000, 
raw observation next is [-5.833333333333333, 69.16666666666667, 5.2, 285.0, 96.0, 592.3333333333334, -0.916666666666667, 22.27336326044233, 23.0, 20.52744736102201, 22.7, 1.0, 55.92082418369589], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.18376068376068377, 0.6916666666666668, 0.4727272727272727, 0.7916666666666666, 0.25396825396825395, 0.5923333333333334, 0.4847222222222222, 0.2227336326044233, 0.7142857142857143, 0.3610639087174299, 0.6714285714285714, 1.0, 0.6578920492199517], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:53,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-69.16181183]
 [-79.00823212]
 [-77.23888397]
 [-84.58675385]
 [-85.03212738]], R is [[-74.50461578]
 [-74.75956726]
 [-75.01197052]
 [-75.26184845]
 [-75.50923157]].
[2017-11-02 10:18:53,854] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191146: loss 102.1235
[2017-11-02 10:18:54,161] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191209: loss 274.2633
[2017-11-02 10:18:59,844] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12000, global step 192335: loss -0.8086
[2017-11-02 10:19:00,113] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192407: loss 65.1106
[2017-11-02 10:19:00,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192520: loss -61.8584
[2017-11-02 10:19:01,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192890: loss 328.2422
[2017-11-02 10:19:02,336] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12000, global step 193077: loss 192.7205
[2017-11-02 10:19:02,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 193118: loss 67.3276
[2017-11-02 10:19:03,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.75415550e-11   9.34067046e-10   2.47623189e-09   4.25447177e-10
   3.51719182e-10   8.13416541e-01   2.15896703e-02   1.10393465e-01
   5.46003841e-02], sum to 1.0000
[2017-11-02 10:19:03,060] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12000, global step 193336: loss -274.9456
[2017-11-02 10:19:03,143] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 23.83687374407866, 25.0, 20.93077262714274, 21.5, 0.0, 36.08902688271026], 
actual action is [4.0, 25], 
sim time next is 3616500.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 20.91563094943416, 25.0, 20.96214941623058, 21.5, 0.0, 63.87714839076795], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.2091563094943416, 1.0, 0.4231642023186544, 0.5, 0.0, 0.7514958634207994], 
reward next is -0.7532. 
=============================================
[2017-11-02 10:19:03,422] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 193474: loss 13.0786
[2017-11-02 10:19:03,817] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 193610: loss -52.5225
[2017-11-02 10:19:04,852] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   5.68258027e-12   3.20215555e-11   1.07226051e-11
   3.27760323e-12   1.51063141e-25   1.25934094e-27   4.27369401e-26
   1.63229111e-26], sum to 1.0000
[2017-11-02 10:19:04,867] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 3.1, 170.0, 0.0, 0.0, 13.0, 23.31101903955321, 18.5, 21.01533047344739, 21.5, 0.0, 19.96877094321941], 
actual action is [4.0, 18], 
sim time next is 3629100.0000, 
raw observation next is [9.0, 25.0, 3.141666666666667, 170.0, 0.0, 0.0, 4.0, 23.82727983119417, 18.0, 21.0434451238341, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5641025641025641, 0.25, 0.28560606060606064, 0.4722222222222222, 0.0, 0.0, 0.5666666666666667, 0.23827279831194167, 0.0, 0.43477787483344293, 0.5, 0.0, 0.0], 
reward next is -0.0652. 
=============================================
[2017-11-02 10:19:05,211] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  6.10665871e-35   6.34114795e-23   1.21336867e-22   1.44562847e-23
   1.80858227e-23   6.78556204e-01   2.29253853e-03   2.77935535e-01
   4.12157252e-02], sum to 1.0000
[2017-11-02 10:19:05,303] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 25.9558715691657, 24.0, 20.14904482750162, 21.5, 0.0, 70.05464863039268], 
actual action is [4.0, 25], 
sim time next is 3615000.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.68909036986441, 25.0, 20.32934346413455, 21.5, 0.0, 59.8865763644295], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.2268909036986441, 1.0, 0.3327633520192213, 0.5, 0.0, 0.7045479572285823], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:05,735] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.85363397e-14   1.19810073e-13   7.12129466e-14
   2.02904608e-14   6.31880445e-35   2.09309615e-36   4.28688354e-35
   1.40905555e-35], sum to 1.0000
[2017-11-02 10:19:05,752] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 18.59056431143464, 20.5, 21.38182416908902, 21.5, 0.0, 39.91153771004537], 
actual action is [-6.0, 18], 
sim time next is 3617100.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, -6.0, 19.81732571851081, 18.0, 21.48618015161107, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.4, 0.1981732571851081, 0.0, 0.4980257359444385, 0.5, 0.0, 0.0], 
reward next is -0.0020. 
=============================================
[2017-11-02 10:19:06,794] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.55623233
  0.0013791   0.43126836  0.01112029], sum to 1.0000
[2017-11-02 10:19:06,848] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [9.0, 25.0, 3.1, 170.0, 0.0, 0.0, 13.0, 23.74276388045526, 20.0, 20.78994885324058, 21.5, 0.0, 64.37295503958161], 
actual action is [14.0, 20.5], 
sim time next is 3629100.0000, 
raw observation next is [9.0, 25.0, 3.141666666666667, 170.0, 0.0, 0.0, 14.0, 22.28876381331322, 20.5, 20.95372202938983, 21.5, 0.0, 29.76415672637739], 
processed observation next is [1.0, 0.0, 0.5641025641025641, 0.25, 0.28560606060606064, 0.4722222222222222, 0.0, 0.0, 0.7333333333333333, 0.2228876381331322, 0.35714285714285715, 0.42196028991283285, 0.5, 0.0, 0.35016654972208694], 
reward next is -0.3932. 
=============================================
[2017-11-02 10:19:07,412] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 194832: loss 1.0698
[2017-11-02 10:19:09,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.98345985e-20   1.04604375e-19   6.52045410e-20
   9.14525069e-21   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:09,520] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 58.99999999999999, 5.016666666666667, 251.6666666666667, 35.41666666666666, 313.75, -1.0, 15.98010650472652, 18.0, 21.98952827873061, 22.7, 1.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 3690600.0000, 
raw observation next is [4.0, 59.0, 4.933333333333334, 253.3333333333333, 31.33333333333333, 284.0, -1.0, 16.36083904732616, 18.0, 21.94300560163686, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4358974358974359, 0.59, 0.4484848484848485, 0.7037037037037036, 0.08289241622574954, 0.284, 0.48333333333333334, 0.1636083904732616, 0.0, 0.5632865145195513, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:11,532] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-56.61439133]
 [-58.12146759]
 [-56.86539078]
 [-59.28170395]
 [-56.03392792]], R is [[-55.79149246]
 [-55.24613571]
 [-55.16177368]
 [-54.62306976]
 [-54.08916855]].
[2017-11-02 10:19:13,619] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 196891: loss -13.9996
[2017-11-02 10:19:14,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-64.3821106 ]
 [-65.17749023]
 [-65.5340271 ]
 [-67.04013824]
 [-63.82969666]], R is [[-66.77072144]
 [-67.10301208]
 [-67.43198395]
 [-67.75766754]
 [-68.08009338]].
[2017-11-02 10:19:15,126] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12500, global step 197450: loss -209.5737
[2017-11-02 10:19:15,903] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   1.56717030e-16   3.35455461e-16   3.43788042e-16
   6.00851424e-17   1.66329406e-31   7.12415606e-34   5.15641999e-32
   1.99709805e-32], sum to 1.0000
[2017-11-02 10:19:15,924] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 6.2, 240.0, 113.0, 795.5, 2.0, 12.40014652029015, 20.5, 22.51681272156744, 22.7, 1.0, 19.80352560320729], 
actual action is [-8.0, 18], 
sim time next is 3755100.0000, 
raw observation next is [-2.916666666666667, 70.5, 6.241666666666667, 240.8333333333333, 113.3333333333333, 799.9166666666667, -8.0, 12.72561870504081, 18.0, 22.57260414091619, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.2585470085470085, 0.705, 0.5674242424242425, 0.6689814814814814, 0.2998236331569664, 0.7999166666666667, 0.36666666666666664, 0.12725618705040811, 0.0, 0.6532291629880272, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0127. 
=============================================
[2017-11-02 10:19:19,600] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   9.95472368e-13   2.21807577e-12   1.47247037e-12
   3.92231169e-13   1.32283823e-26   3.92957501e-28   2.86930990e-26
   2.65004494e-27], sum to 1.0000
[2017-11-02 10:19:19,799] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 72.0, 5.783333333333333, 276.6666666666667, 32.99999999999999, 233.6666666666666, 1.0, 18.95232262656082, 25.0, 20.6798452575063, 22.7, 1.0, 73.59752460476399], 
actual action is [1.0, 20.0], 
sim time next is 3743700.0000, 
raw observation next is [-4.0, 71.5, 5.741666666666666, 278.3333333333333, 39.99999999999999, 258.0833333333333, 1.0, 17.77447151532182, 20.0, 20.8339063984327, 22.7, 1.0, 51.23312349174719], 
processed observation next is [0.0, 0.30434782608695654, 0.23076923076923078, 0.715, 0.521969696969697, 0.7731481481481481, 0.1058201058201058, 0.25808333333333333, 0.5166666666666667, 0.1777447151532182, 0.2857142857142857, 0.4048437712046713, 0.6714285714285714, 1.0, 0.6027426293146728], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:20,569] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 198989: loss 73.6182
[2017-11-02 10:19:21,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.63517871e-16   8.60283190e-16   6.86547732e-16
   5.49859974e-17   0.00000000e+00   0.00000000e+00   1.45264036e-37
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:21,869] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 23.53683661021357, 22.0, 20.11504506345579, 21.5, 0.0, 33.32675108801453], 
actual action is [-8.0, 18], 
sim time next is 3729300.0000, 
raw observation next is [-3.0, 65.0, 5.1, 269.1666666666667, 0.0, 0.0, -8.0, 25.00433355852069, 18.0, 20.17227832331261, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.2564102564102564, 0.65, 0.4636363636363636, 0.7476851851851852, 0.0, 0.0, 0.36666666666666664, 0.25004333558520686, 0.0, 0.3103254747589444, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:21,913] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12500, global step 199358: loss 111.3865
[2017-11-02 10:19:21,972] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199378: loss 4.8288
[2017-11-02 10:19:22,198] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199436: loss 62.2199
[2017-11-02 10:19:22,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.55269835e-16   8.28943712e-16   7.08730255e-16
   5.36041724e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:22,438] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 4.725, 277.5, 0.0, 0.0, -8.0, 27.32375903454413, 18.0, 20.07199055436642, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 3732600.0000, 
raw observation next is [-3.0, 65.0, 4.683333333333333, 278.3333333333333, 0.0, 0.0, -8.0, 29.4271570713551, 18.0, 19.94811002385915, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2564102564102564, 0.65, 0.4257575757575757, 0.7731481481481481, 0.0, 0.0, 0.36666666666666664, 0.29427157071355103, 0.0, 0.2783014319798787, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,008] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.65671238e-02   1.74296423e-04   9.69382644e-01
   3.87601997e-03], sum to 1.0000
[2017-11-02 10:19:25,042] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 65.0, 6.7, 270.0, 0.0, 0.0, 2.0, 31.54844889289715, 20.0, 19.05929846838925, 21.5, 0.0, 36.79251077979669], 
actual action is [2.0, 22.0], 
sim time next is 3737100.0000, 
raw observation next is [-3.083333333333333, 66.0, 6.658333333333333, 269.1666666666667, 0.0, 0.0, 2.0, 31.44936522957344, 22.0, 19.05746247281106, 21.5, 0.0, 23.99762552011929], 
processed observation next is [0.0, 0.2608695652173913, 0.2542735042735043, 0.66, 0.6053030303030303, 0.7476851851851852, 0.0, 0.0, 0.5333333333333333, 0.3144936522957344, 0.5714285714285714, 0.15106606754443724, 0.5, 0.0, 0.2823250061190505], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,279] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.99405228e-19   3.24522124e-18   3.03282814e-18
   1.00076498e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:25,309] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.416666666666667, 70.0, 6.491666666666666, 265.8333333333333, 0.0, 0.0, 1.666666666666667, 29.22112305348767, 22.0, 18.93384805284882, 21.5, 0.0, 66.76207094929062], 
actual action is [-8.416666666666668, 18], 
sim time next is 3738600.0000, 
raw observation next is [-3.5, 71.0, 6.45, 265.0, 0.0, 0.0, -8.416666666666668, 30.65163307987584, 18.0, 19.084816138229, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.24358974358974358, 0.71, 0.5863636363636364, 0.7361111111111112, 0.0, 0.0, 0.3597222222222222, 0.3065163307987584, 0.0, 0.1549737340327145, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,628] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200437: loss -10.9413
[2017-11-02 10:19:25,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.16071382e-16   1.07463335e-15   8.09543587e-16
   4.86554618e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:25,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.25, 66.75, 4.475, 305.0, 0.0, 0.0, -7.0, 24.79982712919686, 18.0, 20.68481041806573, 21.5, 0.0, 0.0], 
actual action is [-7.25, 18], 
sim time next is 3711000.0000, 
raw observation next is [-2.5, 66.16666666666667, 4.516666666666666, 306.6666666666667, 0.0, 0.0, -7.25, 26.10855629088771, 18.0, 20.67095049766957, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2692307692307692, 0.6616666666666667, 0.41060606060606053, 0.8518518518518519, 0.0, 0.0, 0.37916666666666665, 0.2610855629088771, 0.0, 0.38156435680993844, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,917] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12500, global step 200515: loss 5.1275
[2017-11-02 10:19:26,667] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200695: loss 53.6359
[2017-11-02 10:19:27,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200788: loss -1.1842
[2017-11-02 10:19:27,462] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12500, global step 200882: loss 38.1482
[2017-11-02 10:19:28,262] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 201073: loss 60.7558
[2017-11-02 10:19:28,777] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12500, global step 201204: loss 19.2769
[2017-11-02 10:19:28,847] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 201220: loss -141.8388
[2017-11-02 10:19:30,090] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 201575: loss -147.5149
[2017-11-02 10:19:36,324] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.05512127e-11   2.13797632e-10   3.07009938e-11
   1.16290202e-12   7.41976991e-27   1.83938944e-27   5.87645286e-24
   9.63679816e-26], sum to 1.0000
[2017-11-02 10:19:36,395] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 76.5, 4.558333333333333, 220.0, 0.0, 0.0, 2.0, 17.75491872267448, 25.0, 20.7973287348411, 21.5, 0.0, 58.01731820808845], 
actual action is [2.0, 20.0], 
sim time next is 3794400.0000, 
raw observation next is [-3.0, 77.0, 4.6, 220.0, 0.0, 0.0, 2.0, 16.65805846548043, 20.0, 20.9300407140658, 21.5, 0.0, 39.07899924935622], 
processed observation next is [0.0, 0.9565217391304348, 0.2564102564102564, 0.77, 0.41818181818181815, 0.6111111111111112, 0.0, 0.0, 0.5333333333333333, 0.1665805846548043, 0.2857142857142857, 0.4185772448665429, 0.5, 0.0, 0.45975293234536735], 
reward next is -0.4952. 
=============================================
[2017-11-02 10:19:36,556] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 203047: loss 34.4911
[2017-11-02 10:19:47,969] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 204648: loss 86.5549
[2017-11-02 10:19:52,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.23256621e-16   1.50662216e-15   2.67726045e-16
   2.05856783e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:52,753] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.583333333333334, 61.91666666666667, 5.35, 155.8333333333333, 0.0, 0.0, -11.5, 23.20506433043878, 18.0, 20.17161335357242, 21.5, 0.0, 0.0], 
actual action is [-11.583333333333334, 18], 
sim time next is 3912000.0000, 
raw observation next is [-6.666666666666666, 62.33333333333333, 5.3, 126.6666666666667, 0.0, 0.0, -11.58333333333333, 26.1528836332415, 18.0, 20.05920712734814, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.1623931623931624, 0.6233333333333333, 0.4818181818181818, 0.35185185185185197, 0.0, 0.0, 0.3069444444444445, 0.261528836332415, 0.0, 0.2941724467640202, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:54,871] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13000, global step 205609: loss -28.2170
[2017-11-02 10:20:02,621] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 206800: loss 80.0694
[2017-11-02 10:20:03,016] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 206847: loss 21.2342
[2017-11-02 10:20:03,242] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13000, global step 206881: loss -51.5897
[2017-11-02 10:20:06,954] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207470: loss -77.9760
[2017-11-02 10:20:10,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   9.23825748e-17   5.14765692e-16   2.07502320e-16
   2.33636767e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:20:10,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 2.725, 347.5, 0.0, 0.0, 3.0, 25.99831607109887, 22.0, 19.9787413965511, 21.5, 0.0, 22.41757541662042], 
actual action is [-7.0, 18], 
sim time next is 3896400.0000, 
raw observation next is [-2.0, 65.0, 2.933333333333334, 346.6666666666667, 0.0, 0.0, -7.0, 27.04576328129081, 18.0, 19.99664144766506, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.28205128205128205, 0.65, 0.2666666666666667, 0.962962962962963, 0.0, 0.0, 0.38333333333333336, 0.2704576328129081, 0.0, 0.28523449252357985, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:10,798] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-35.5450592 ]
 [-35.81684875]
 [-37.83666611]
 [-40.91237259]
 [-46.11975479]], R is [[-41.48830032]
 [-42.07341766]
 [-42.65268326]
 [-43.22615814]
 [-43.79389572]].
[2017-11-02 10:20:11,249] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208102: loss -74.9472
[2017-11-02 10:20:11,739] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13000, global step 208169: loss -30.8742
[2017-11-02 10:20:12,206] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.44066392e-02   1.78122864e-05   9.45497096e-01
   7.84860313e-05], sum to 1.0000
[2017-11-02 10:20:12,304] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.833333333333333, 70.0, 5.016666666666667, 340.0, 0.0, 0.0, 2.25, 26.08262454340635, 20.0, 20.01016447113307, 21.5, 0.0, 56.35246528581182], 
actual action is [2.166666666666667, 22.0], 
sim time next is 3902100.0000, 
raw observation next is [-2.916666666666667, 70.5, 5.058333333333334, 340.0, 0.0, 0.0, 2.166666666666667, 25.44851257068176, 22.0, 20.052155435504, 21.5, 0.0, 28.96146985160053], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.2585470085470085, 0.705, 0.4598484848484849, 0.9444444444444444, 0.0, 0.0, 0.5361111111111111, 0.2544851257068176, 0.5714285714285714, 0.2931650622148574, 0.5, 0.0, 0.34072317472471214], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:12,766] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208312: loss -46.5830
[2017-11-02 10:20:13,505] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208437: loss -119.6547
[2017-11-02 10:20:14,777] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13000, global step 208612: loss -34.4206
[2017-11-02 10:20:15,316] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208691: loss -39.1819
[2017-11-02 10:20:15,732] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13000, global step 208756: loss -21.2937
[2017-11-02 10:20:16,303] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.80728073e-08   1.23200703e-08   6.87769042e-09
   4.58236871e-09   7.19174220e-10   7.43050500e-12   7.88557775e-10
   2.03461336e-12], sum to 1.0000
[2017-11-02 10:20:16,316] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 49.0, 3.183333333333334, 296.6666666666667, 117.6666666666667, 798.3333333333334, -1.0, 11.08704572168418, 18.5, 22.88830536915185, 22.7, 1.0, 40.30642731206357], 
actual action is [-11.0, 18], 
sim time next is 3928500.0000, 
raw observation next is [-6.0, 49.0, 3.225, 270.0, 118.25, 801.25, -11.0, 11.5391536648214, 18.0, 22.90074740915466, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.1794871794871795, 0.49, 0.2931818181818182, 0.75, 0.31283068783068785, 0.80125, 0.31666666666666665, 0.115391536648214, 0.0, 0.7001067727363802, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0115. 
=============================================
[2017-11-02 10:20:16,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208845: loss 1.6252
[2017-11-02 10:20:17,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208941: loss -48.1817
[2017-11-02 10:20:28,438] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.58311881e-14   8.86046014e-15   9.62381047e-15
   4.38651343e-15   7.07229010e-30   8.48957302e-32   1.28050914e-29
   3.59306629e-32], sum to 1.0000
[2017-11-02 10:20:28,462] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 49.0, 3.475, 110.0, 119.75, 816.25, -11.0, 10.05557353353115, 18.0, 23.51865541345956, 22.7, 1.0, 0.0], 
actual action is [-11.0, 18], 
sim time next is 3930600.0000, 
raw observation next is [-6.0, 49.0, 3.516666666666667, 83.33333333333331, 119.6666666666667, 818.3333333333334, -11.0, 10.49513580065516, 18.0, 23.43991280931138, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.1794871794871795, 0.49, 0.31969696969696976, 0.23148148148148143, 0.31657848324515, 0.8183333333333334, 0.31666666666666665, 0.10495135800655159, 0.0, 0.7771304013301972, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0105. 
=============================================
[2017-11-02 10:20:28,589] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 210342: loss 106.8551
[2017-11-02 10:20:34,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   3.17327371e-12   2.58111327e-12   1.84576464e-12
   1.24921178e-12   7.47558956e-14   1.37998740e-16   3.82048858e-14
   1.49107032e-15], sum to 1.0000
[2017-11-02 10:20:34,896] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.833333333333334, 43.33333333333334, 2.600000000000001, 116.6666666666667, 108.3333333333333, 753.3333333333334, -3.916666666666666, 14.36034073773626, 19.0, 22.46291278889231, 22.7, 1.0, 27.0171742352784], 
actual action is [-13.833333333333334, 18], 
sim time next is 4011300.0000, 
raw observation next is [-8.75, 43.0, 2.6, 120.0, 109.25, 760.25, -13.83333333333333, 15.01507826655605, 18.0, 22.50316843153049, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.10897435897435898, 0.43, 0.23636363636363636, 0.3333333333333333, 0.289021164021164, 0.76025, 0.26944444444444454, 0.15015078266556048, 0.0, 0.6433097759329272, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:40,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.14415072e-15   1.99936410e-15   1.88178576e-15
   6.37788228e-16   5.41099519e-33   4.81149582e-35   1.58022029e-32
   1.00549193e-32], sum to 1.0000
[2017-11-02 10:20:40,897] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.75, 20.5, 1.9, 60.0, 92.75, 732.5, -6.833333333333333, 14.15254130347458, 18.0, 22.39039714836531, 22.7, 1.0, 0.0], 
actual action is [-6.75, 18], 
sim time next is 4029600.0000, 
raw observation next is [-1.666666666666667, 20.66666666666667, 2.033333333333333, 63.33333333333334, 91.5, 725.6666666666667, -6.75, 14.12336578392713, 18.0, 22.44431612800078, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.29059829059829057, 0.20666666666666672, 0.18484848484848485, 0.17592592592592596, 0.24206349206349206, 0.7256666666666668, 0.3875, 0.1412336578392713, 0.0, 0.6349023040001113, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0141. 
=============================================
[2017-11-02 10:20:46,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[ -75.50553894]
 [ -76.90077209]
 [ -96.42882538]
 [ -94.76527405]
 [-100.073349  ]], R is [[-74.73484802]
 [-74.98750305]
 [-75.23762512]
 [-75.48525238]
 [-75.73040009]].
[2017-11-02 10:20:48,381] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13500, global step 212915: loss 108.2698
[2017-11-02 10:20:50,916] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-74.17179108]
 [-73.54226685]
 [-75.65028381]
 [-75.73925781]
 [-76.5715332 ]], R is [[-72.71204376]
 [-72.98492432]
 [-73.25507355]
 [-73.52252197]
 [-73.78730011]].
[2017-11-02 10:20:51,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-88.24212646]
 [-86.34049225]
 [-90.82637787]
 [-87.74214935]
 [-86.67502594]], R is [[-87.89809418]
 [-88.01911163]
 [-88.13892365]
 [-88.25753784]
 [-88.37496185]].
[2017-11-02 10:20:55,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.93079126e-01   6.76325783e-07   5.64945955e-03
   1.27076171e-03], sum to 1.0000
[2017-11-02 10:20:55,215] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-13.08333333333333, 63.5, 1.375, 9.166666666666666, 0.0, 0.0, -18.0, 34.45104716754836, 18.0, 19.11111993596538, 21.5, 0.0, 0.0], 
actual action is [-8.08333333333333, 18.5], 
sim time next is 3996600.0000, 
raw observation next is [-13.16666666666667, 64.0, 1.25, 8.333333333333334, 0.0, 0.0, -8.08333333333333, 34.05991327924379, 18.5, 18.95152402744102, 21.5, 0.0, 48.43734841781303], 
processed observation next is [0.5, 0.2608695652173913, -0.004273504273504349, 0.64, 0.11363636363636363, 0.02314814814814815, 0.0, 0.0, 0.36527777777777787, 0.34059913279243786, 0.07142857142857142, 0.13593200392014587, 0.5, 0.0, 0.5698511578566239], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:57,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-54.94434738]
 [-54.04138184]
 [-76.44363403]
 [-75.1916275 ]
 [-77.27340698]], R is [[-57.90265656]
 [-58.32363129]
 [-58.74039459]
 [-59.15299225]
 [-59.5614624 ]].
[2017-11-02 10:20:59,696] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13500, global step 214078: loss -12.2846
[2017-11-02 10:21:07,786] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   3.73072206e-13   2.39034703e-12   4.83145045e-13
   9.16263864e-14   6.49520500e-28   7.73713485e-31   6.36491295e-28
   1.93738830e-26], sum to 1.0000
[2017-11-02 10:21:07,888] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 41.0, 3.141666666666667, 139.1666666666667, 0.0, 0.0, -1.0, 20.24956605877135, 25.0, 20.78711685376989, 21.5, 0.0, 42.0662801539339], 
actual action is [-1.0, 20.0], 
sim time next is 4068000.0000, 
raw observation next is [-6.0, 41.0, 3.1, 140.0, 0.0, 0.0, -1.0, 19.78670809973074, 20.0, 20.83809440057635, 21.5, 0.0, 46.04721850571779], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.1794871794871795, 0.41, 0.2818181818181818, 0.3888888888888889, 0.0, 0.0, 0.48333333333333334, 0.19786708099730738, 0.2857142857142857, 0.4054420572251927, 0.5, 0.0, 0.5417319824202093], 
reward next is -0.5821. 
=============================================
[2017-11-02 10:21:09,690] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13500, global step 215208: loss 192.7398
[2017-11-02 10:21:11,149] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13500, global step 215372: loss -25.5084
[2017-11-02 10:21:11,566] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13500, global step 215428: loss 17.7826
[2017-11-02 10:21:13,770] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13500, global step 215759: loss -13.7333
[2017-11-02 10:21:13,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   9.10861221e-16   3.48074134e-16   4.39470127e-16
   3.25253664e-16   2.58219539e-28   4.99896069e-30   4.04295969e-29
   4.08125115e-28], sum to 1.0000
[2017-11-02 10:21:14,052] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.583333333333333, 23.16666666666666, 2.808333333333334, 66.66666666666667, 63.08333333333333, 518.4166666666666, -6.5, 10.16112057707003, 18.0, 23.63566590640768, 22.7, 1.0, 0.0], 
actual action is [-6.583333333333333, 18], 
sim time next is 4034400.0000, 
raw observation next is [-1.666666666666667, 23.33333333333334, 2.766666666666667, 63.33333333333333, 59.16666666666667, 488.8333333333334, -6.583333333333333, 10.43937916669188, 18.0, 23.55667142282114, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.29059829059829057, 0.2333333333333334, 0.2515151515151515, 0.1759259259259259, 0.15652557319223986, 0.48883333333333345, 0.3902777777777778, 0.10439379166691881, 0.0, 0.7938102032601628, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0104. 
=============================================
[2017-11-02 10:21:15,513] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.65896008e-08   4.50031017e-08   1.55336828e-08
   5.42776579e-09   9.42785008e-14   3.10519250e-15   3.56892013e-14
   1.35724862e-12], sum to 1.0000
[2017-11-02 10:21:15,606] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 38.33333333333334, 2.933333333333334, 130.0, 0.0, 0.0, -1.0, 15.22406859686022, 25.0, 21.56243594207152, 21.5, 0.0, 46.67537084857686], 
actual action is [-1.0, 20.0], 
sim time next is 4062300.0000, 
raw observation next is [-6.0, 38.66666666666667, 3.016666666666667, 130.0, 0.0, 0.0, -1.0, 14.78231481950856, 20.0, 21.61720829875223, 21.5, 0.0, 46.28257483096814], 
processed observation next is [0.6666666666666666, 0.0, 0.1794871794871795, 0.3866666666666667, 0.2742424242424243, 0.3611111111111111, 0.0, 0.0, 0.48333333333333334, 0.1478231481950856, 0.2857142857142857, 0.5167440426788902, 0.5, 0.0, 0.544500880364331], 
reward next is -0.4901. 
=============================================
[2017-11-02 10:21:15,996] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13500, global step 216093: loss 147.6115
[2017-11-02 10:21:19,108] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13500, global step 216450: loss 48.6470
[2017-11-02 10:21:19,144] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13500, global step 216452: loss 8.2971
[2017-11-02 10:21:19,257] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13500, global step 216465: loss 39.4643
[2017-11-02 10:21:20,007] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13500, global step 216555: loss 15.4179
[2017-11-02 10:21:21,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13500, global step 216718: loss -23.6226
[2017-11-02 10:21:21,621] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13500, global step 216760: loss -22.4234
[2017-11-02 10:21:22,123] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13500, global step 216828: loss 69.6214
[2017-11-02 10:21:23,206] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13500, global step 216965: loss 19.5934
[2017-11-02 10:21:35,064] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.02534090e-15   9.37826832e-16   1.15150678e-15
   8.20011643e-16   1.57837317e-29   1.42720860e-30   1.07331004e-30
   4.98553718e-29], sum to 1.0000
[2017-11-02 10:21:35,075] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.416666666666667, 32.66666666666666, 2.1, 227.5, 106.8333333333333, 797.0, -1.666666666666667, 10.88436426110661, 18.0, 23.04593480424446, 22.7, 1.0, 0.0], 
actual action is [-1.583333333333333, 18], 
sim time next is 4113000.0000, 
raw observation next is [3.5, 33.0, 2.1, 225.0, 106.0, 794.0, -1.583333333333333, 10.78411850412194, 18.0, 23.0958886336876, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.4230769230769231, 0.33, 0.19090909090909092, 0.625, 0.2804232804232804, 0.794, 0.47361111111111115, 0.1078411850412194, 0.0, 0.7279840905268001, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0108. 
=============================================
[2017-11-02 10:21:38,024] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13500, global step 218811: loss 12.3704
[2017-11-02 10:21:41,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.80721997e-14   1.41343659e-14   1.53141744e-14
   1.33385226e-14   7.58270506e-25   9.18203649e-26   1.32105877e-25
   2.05309452e-24], sum to 1.0000
[2017-11-02 10:21:41,497] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.833333333333333, 34.33333333333334, 2.1, 215.0, 102.0, 761.0, -1.25, 10.18527914175437, 18.0, 23.45598159601039, 22.7, 1.0, 0.0], 
actual action is [-1.166666666666667, 18], 
sim time next is 4114500.0000, 
raw observation next is [3.916666666666667, 34.66666666666666, 2.1, 212.5, 101.0, 752.75, -1.166666666666667, 10.07193098297971, 18.0, 23.49865764314284, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.4337606837606838, 0.34666666666666657, 0.19090909090909092, 0.5902777777777778, 0.2671957671957672, 0.75275, 0.4805555555555555, 0.1007193098297971, 0.0, 0.7855225204489769, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0101. 
=============================================
[2017-11-02 10:21:43,401] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-4.52988386]
 [-5.9500556 ]
 [-4.84054804]
 [-5.27604532]
 [-5.59875154]], R is [[-4.65907955]
 [-4.62635183]
 [-4.59395981]
 [-4.56189632]
 [-4.53015184]].
[2017-11-02 10:21:48,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14000, global step 220473: loss -233.5378
[2017-11-02 10:21:49,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   3.82479232e-13   6.83384447e-13   3.11694464e-13
   1.31320844e-13   5.31547035e-27   7.76141631e-28   2.38056477e-27
   1.72477411e-25], sum to 1.0000
[2017-11-02 10:21:49,340] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.833333333333333, 37.5, 1.925, 284.1666666666666, 0.0, 0.0, 8.0, 15.50963149194227, 23.0, 21.34991351710735, 22.7, 1.0, 66.12440764827359], 
actual action is [-2.166666666666667, 18.0], 
sim time next is 4129800.0000, 
raw observation next is [2.666666666666667, 38.0, 1.75, 258.3333333333334, 0.0, 0.0, -2.166666666666667, 16.09870915292382, 18.0, 21.4346751191923, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.4017094017094017, 0.38, 0.1590909090909091, 0.7175925925925929, 0.0, 0.0, 0.46388888888888885, 0.1609870915292382, 0.0, 0.4906678741703284, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:00,385] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14000, global step 222246: loss -79.0669
[2017-11-02 10:22:06,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00613892
  0.00144175  0.00602533  0.98639399], sum to 1.0000
[2017-11-02 10:22:07,065] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666666, 49.33333333333333, 3.433333333333334, 336.6666666666667, 0.0, 0.0, 0.4166666666666661, 23.42791320001479, 23.0, 19.94956015195887, 21.5, 0.0, 61.77320937448273], 
actual action is [0.3333333333333339, 25], 
sim time next is 4171500.0000, 
raw observation next is [-4.75, 49.25, 3.475, 337.5, 0.0, 0.0, 0.3333333333333339, 22.47378263887184, 25.0, 19.96477231457709, 21.5, 0.0, 52.20718638971506], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.21153846153846154, 0.4925, 0.3159090909090909, 0.9375, 0.0, 0.0, 0.5055555555555556, 0.2247378263887184, 1.0, 0.28068175922529853, 0.5, 0.0, 0.6142021928201772], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:07,368] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14000, global step 223167: loss -62.9907
[2017-11-02 10:22:08,333] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14000, global step 223286: loss -17.0109
[2017-11-02 10:22:08,613] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14000, global step 223323: loss 38.6578
[2017-11-02 10:22:08,840] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-47.6086731 ]
 [-48.42660904]
 [-48.9163475 ]
 [-48.41316223]
 [-49.8308754 ]], R is [[-48.37583923]
 [-48.89208221]
 [-49.4031601 ]
 [-49.9091301 ]
 [-50.41003799]].
[2017-11-02 10:22:09,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   1.35959707e-18   1.26280556e-18   1.19757214e-18
   9.05631663e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.57033003e-38], sum to 1.0000
[2017-11-02 10:22:09,802] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 39.5, 3.683333333333333, 275.0, 53.33333333333334, 421.0, -2.75, 16.83833714889381, 18.0, 22.58309853873734, 22.7, 1.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 4208100.0000, 
raw observation next is [2.083333333333333, 39.75, 3.641666666666667, 272.5, 49.66666666666667, 388.75, -2.833333333333333, 17.42321975187698, 18.0, 22.47714183422746, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.3867521367521367, 0.3975, 0.3310606060606061, 0.7569444444444444, 0.13139329805996475, 0.38875, 0.4527777777777778, 0.1742321975187698, 0.0, 0.6395916906039228, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:12,443] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14000, global step 223767: loss 16.6856
[2017-11-02 10:22:14,087] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14000, global step 223978: loss -75.3432
[2017-11-02 10:22:15,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14000, global step 224170: loss 105.4971
[2017-11-02 10:22:17,038] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14000, global step 224395: loss -15.2181
[2017-11-02 10:22:18,741] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14000, global step 224650: loss -3.4962
[2017-11-02 10:22:19,021] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   5.96573987e-16   6.21836215e-16   9.10027740e-16
   6.29857829e-16   3.41592459e-35   6.14086457e-35   1.47307680e-35
   5.13337327e-34], sum to 1.0000
[2017-11-02 10:22:19,054] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 42.33333333333333, 4.475, 254.1666666666667, 184.75, 126.4166666666667, -3.0, 15.28659870743857, 18.0, 22.43447797713293, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4200000.0000, 
raw observation next is [2.0, 42.66666666666667, 4.6, 253.3333333333333, 182.5, 163.8333333333333, -3.0, 15.8541298961656, 18.0, 22.41634679023441, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.38461538461538464, 0.4266666666666667, 0.41818181818181815, 0.7037037037037036, 0.4828042328042328, 0.16383333333333328, 0.45, 0.158541298961656, 0.0, 0.6309066843192015, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:19,433] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14000, global step 224757: loss -85.9502
[2017-11-02 10:22:19,683] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14000, global step 224790: loss -63.2741
[2017-11-02 10:22:19,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14000, global step 224807: loss 0.9164
[2017-11-02 10:22:20,019] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14000, global step 224841: loss -21.6549
[2017-11-02 10:22:20,770] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-39.50560379]
 [-40.29600906]
 [-39.89154816]
 [-39.5532341 ]
 [-40.84485245]], R is [[-40.29840088]
 [-39.90842438]
 [-39.52207565]
 [-39.89686584]
 [-39.51252747]].
[2017-11-02 10:22:23,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14000, global step 225270: loss 4.7795
[2017-11-02 10:22:24,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   6.28607545e-15   1.30056996e-14   1.24624999e-14
   6.52611950e-15   7.24516017e-33   2.57774156e-32   2.41537236e-33
   4.64794434e-33], sum to 1.0000
[2017-11-02 10:22:24,861] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.5, 41.66666666666667, 3.433333333333334, 253.3333333333333, 0.0, 0.0, 6.525, 18.09935369105467, 19.0, 21.95823538066601, 22.7, 1.0, 24.8056347440748], 
actual action is [-3.5, 18], 
sim time next is 4214700.0000, 
raw observation next is [1.475, 41.75, 3.425, 252.5, 0.0, 0.0, -3.5, 18.76292393871377, 18.0, 21.94132398170643, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.37115384615384617, 0.4175, 0.31136363636363634, 0.7013888888888888, 0.0, 0.0, 0.44166666666666665, 0.1876292393871377, 0.0, 0.5630462831009184, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:36,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.15112413e-16   5.49036539e-16   1.88806212e-16
   8.44290546e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.04762048e-38], sum to 1.0000
[2017-11-02 10:22:36,254] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 5.7, 241.6666666666667, 0.0, 0.0, -2.0, 23.76779950737041, 18.0, 20.73107713918876, 21.5, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4243200.0000, 
raw observation next is [3.0, 45.0, 5.7, 243.3333333333333, 0.0, 0.0, -2.0, 24.99913868269318, 18.0, 20.72597322004734, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.41025641025641024, 0.45, 0.5181818181818182, 0.6759259259259258, 0.0, 0.0, 0.4666666666666667, 0.24999138682693178, 0.0, 0.38942474572104857, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:39,357] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14000, global step 227450: loss 4.8208
[2017-11-02 10:22:40,309] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.10834683
  0.05139541  0.38015783  0.46009982], sum to 1.0000
[2017-11-02 10:22:40,585] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [3.0, 49.0, 5.1, 220.0, 18.33333333333333, 8.833333333333332, -2.0, 24.77850009493559, 18.0, 20.33262434942724, 21.5, 0.0, 0.0], 
actual action is [8.0, 20.0], 
sim time next is 4261500.0000, 
raw observation next is [3.0, 49.0, 5.1, 220.0, 27.5, 13.25, 8.0, 23.44015343607195, 20.0, 20.36358745495042, 21.5, 0.0, 43.16855513995353], 
processed observation next is [1.0, 0.30434782608695654, 0.41025641025641024, 0.49, 0.4636363636363636, 0.6111111111111112, 0.07275132275132275, 0.01325, 0.6333333333333333, 0.23440153436071948, 0.2857142857142857, 0.33765535070720276, 0.5, 0.0, 0.5078653545876887], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:41,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   2.95313253e-35   6.69654795e-35   5.05560756e-36
   2.26881057e-35   4.52467501e-02   3.68910283e-02   3.96615893e-01
   5.21246314e-01], sum to 1.0000
[2017-11-02 10:22:41,868] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.0, 49.0, 5.1, 220.0, 0.0, 0.0, -2.0, 25.8138769986254, 18.0, 20.59961593900387, 21.5, 0.0, 0.0], 
actual action is [8.0, 23.0], 
sim time next is 4259400.0000, 
raw observation next is [3.0, 49.0, 5.1, 220.0, 0.0, 0.0, 8.0, 23.35551273996565, 23.0, 20.50264492272004, 21.5, 0.0, 65.12650554581636], 
processed observation next is [1.0, 0.30434782608695654, 0.41025641025641024, 0.49, 0.4636363636363636, 0.6111111111111112, 0.0, 0.0, 0.6333333333333333, 0.2335551273996565, 0.7142857142857143, 0.3575207032457201, 0.5, 0.0, 0.7661941828919572], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:44,051] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99999523e-01   9.44701761e-10   2.79721490e-09   8.04404821e-10
   9.18378817e-10   2.65994116e-10   5.27960287e-10   1.50130841e-08
   4.56920986e-07], sum to 1.0000
[2017-11-02 10:22:44,061] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.95, 57.0, 6.925, 265.0, 104.5, 630.25, 1.933333333333334, 16.32336509972252, 18.0, 22.345019820004, 22.7, 1.0, 0.0], 
actual action is [1.9500000000000002, 18], 
sim time next is 4290600.0000, 
raw observation next is [6.966666666666667, 56.66666666666667, 6.883333333333333, 266.6666666666666, 100.6666666666667, 622.0, 1.95, 16.24938964196572, 18.0, 22.36267131876036, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.511965811965812, 0.5666666666666668, 0.6257575757575757, 0.7407407407407405, 0.26631393298059974, 0.622, 0.5325, 0.1624938964196572, 0.0, 0.6232387598229084, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:44,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 228144: loss 133.2294
[2017-11-02 10:22:54,532] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 229720: loss 3.7617
[2017-11-02 10:22:59,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   4.88142801e-15   3.23292113e-14   2.14899408e-14
   1.02201361e-14   2.18472909e-27   8.57224870e-28   1.35760593e-27
   1.16316878e-26], sum to 1.0000
[2017-11-02 10:22:59,181] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 5.7, 240.0, 0.0, 0.0, 8.0, 32.40558287568238, 23.0, 19.76417243547051, 21.5, 0.0, 23.80517088746772], 
actual action is [-2.0, 18.0], 
sim time next is 4251900.0000, 
raw observation next is [3.0, 45.33333333333334, 5.566666666666666, 239.1666666666667, 0.0, 0.0, -2.0, 33.23019819600501, 18.0, 19.73122134892293, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.41025641025641024, 0.4533333333333334, 0.506060606060606, 0.664351851851852, 0.0, 0.0, 0.4666666666666667, 0.3323019819600501, 0.0, 0.2473173355604185, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:01,348] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 230762: loss -141.5170
[2017-11-02 10:23:03,190] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 231057: loss 6.4171
[2017-11-02 10:23:05,734] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14500, global step 231350: loss 40.7207
[2017-11-02 10:23:06,340] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   3.23614642e-11   7.17839052e-11   8.60610333e-11
   2.94339934e-11   6.43994044e-28   7.39989518e-28   4.43949482e-28
   5.52502231e-27], sum to 1.0000
[2017-11-02 10:23:06,382] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.3, 57.0, 4.1, 190.0, 99.5, 584.0, 1.024999999999999, 15.61416588836284, 18.0, 21.99662111904254, 22.7, 1.0, 0.0], 
actual action is [1.2999999999999998, 18], 
sim time next is 4352700.0000, 
raw observation next is [6.608333333333333, 55.75, 4.058333333333333, 190.0, 100.75, 599.5, 1.3, 15.02717884180738, 18.0, 22.05421421961504, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5027777777777778, 0.5575, 0.3689393939393939, 0.5277777777777778, 0.2665343915343915, 0.5995, 0.5216666666666667, 0.15027178841807382, 0.0, 0.5791734599450058, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:08,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.18216429e-15   1.93708134e-15   2.16374206e-15
   1.14481437e-15   8.19910248e-34   7.61028634e-34   9.46855373e-34
   1.58640515e-32], sum to 1.0000
[2017-11-02 10:23:08,659] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.416666666666667, 75.0, 6.183333333333334, 258.3333333333333, 0.0, 0.0, -2.5, 22.20698661288348, 18.0, 20.61580560860954, 21.5, 0.0, 0.0], 
actual action is [-2.583333333333333, 18], 
sim time next is 4430400.0000, 
raw observation next is [2.333333333333333, 76.0, 5.966666666666667, 256.6666666666667, 0.0, 0.0, -2.583333333333333, 22.90281242266921, 18.0, 20.5318950470505, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.39316239316239315, 0.76, 0.5424242424242425, 0.712962962962963, 0.0, 0.0, 0.4569444444444445, 0.2290281242266921, 0.0, 0.36169929243578586, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:09,485] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 231792: loss 32.6189
[2017-11-02 10:23:11,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.05576201e-10   2.84136215e-10   3.61402852e-10
   1.13498558e-10   1.62139694e-22   2.64547597e-22   3.35769393e-22
   3.28781918e-21], sum to 1.0000
[2017-11-02 10:23:11,620] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 232058: loss 2.7790
[2017-11-02 10:23:11,649] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 7.050000000000001, 250.0, 30.0, 58.0, -3.0, 15.69056281465175, 18.0, 21.76606549207226, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4434600.0000, 
raw observation next is [2.0, 80.0, 7.266666666666667, 250.0, 39.99999999999999, 77.33333333333331, -3.0, 16.80704087029855, 18.0, 21.70627749905407, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.38461538461538464, 0.8, 0.6606060606060606, 0.6944444444444444, 0.1058201058201058, 0.07733333333333331, 0.45, 0.1680704087029855, 0.0, 0.5294682141505815, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:12,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99993682e-01   1.23968493e-06   1.68797112e-06   2.05186325e-06
   1.33187655e-06   3.21066958e-13   2.71688867e-13   8.90632579e-14
   1.35071601e-13], sum to 1.0000
[2017-11-02 10:23:12,359] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.525, 33.25, 4.866666666666666, 254.1666666666667, 110.6666666666667, 52.41666666666669, 8.6, 7.266616360469384, 18.0, 25.32438934517166, 22.7, 1.0, 0.0], 
actual action is [8.525, 18], 
sim time next is 4375800.0000, 
raw observation next is [13.45, 33.5, 4.9, 255.0, 103.0, 0.0, 8.525, 7.272426278212295, 18.0, 25.28531589007869, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.6782051282051282, 0.335, 0.4454545454545455, 0.7083333333333334, 0.2724867724867725, 0.0, 0.6420833333333333, 0.07272426278212295, 0.0, 1.0407594128683841, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0073. 
=============================================
[2017-11-02 10:23:13,752] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 232353: loss 33.5899
[2017-11-02 10:23:16,421] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 232737: loss 63.5197
[2017-11-02 10:23:16,555] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 232751: loss -101.2873
[2017-11-02 10:23:16,563] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 232756: loss -18.5484
[2017-11-02 10:23:17,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.25830985e-10   2.54496035e-10   4.47090864e-10
   1.50067778e-10   2.88868873e-22   6.85807449e-22   1.24032600e-22
   1.18580107e-21], sum to 1.0000
[2017-11-02 10:23:17,633] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.991666666666667, 74.08333333333333, 4.508333333333333, 190.0, 38.33333333333333, 204.5833333333333, 7.983333333333333, 16.33991704253587, 23.0, 21.09402336049426, 22.7, 1.0, 88.76090630895483], 
actual action is [-2.008333333333333, 18.0], 
sim time next is 4348800.0000, 
raw observation next is [3.0, 74.0, 4.6, 190.0, 46.0, 245.5, -2.008333333333333, 16.98403759821364, 18.0, 21.27537336546413, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.41025641025641024, 0.74, 0.41818181818181815, 0.5277777777777778, 0.12169312169312169, 0.2455, 0.46652777777777776, 0.1698403759821364, 0.0, 0.46791048078059, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:18,174] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 232963: loss 1.4405
[2017-11-02 10:23:20,176] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14500, global step 233255: loss 19.8326
[2017-11-02 10:23:21,129] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 233425: loss 44.5044
[2017-11-02 10:23:21,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-17.12337112]
 [-18.59667397]
 [-18.14731026]
 [-17.92577553]
 [-17.02705002]], R is [[-18.71695709]
 [-19.52978706]
 [-20.33448982]
 [-21.13114548]
 [-21.91983414]].
[2017-11-02 10:23:21,854] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 233546: loss 28.8628
[2017-11-02 10:23:22,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99994755e-01   9.52387779e-07   1.29522130e-06   1.94759400e-06
   1.05466370e-06   6.21976559e-12   6.19079180e-12   1.69994823e-12
   2.45907244e-12], sum to 1.0000
[2017-11-02 10:23:22,101] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.575, 29.5, 4.1, 242.5, 115.75, 844.75, 9.58333333333333, 7.226962516467014, 18.0, 24.35702834446646, 22.7, 1.0, 0.0], 
actual action is [9.575, 18], 
sim time next is 4368000.0000, 
raw observation next is [14.56666666666667, 29.66666666666667, 4.133333333333334, 243.3333333333334, 115.5, 843.8333333333334, 9.575, 7.179839072257007, 18.0, 24.36782205672187, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.7068376068376069, 0.2966666666666667, 0.3757575757575758, 0.6759259259259262, 0.3055555555555556, 0.8438333333333333, 0.6595833333333334, 0.07179839072257006, 0.0, 0.9096888652459815, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0072. 
=============================================
[2017-11-02 10:23:34,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   9.38100726e-12   6.76307491e-12   8.96016508e-12
   6.31851689e-12   1.24559862e-22   3.59722618e-22   2.10825652e-22
   2.93748436e-21], sum to 1.0000
[2017-11-02 10:23:34,676] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 85.33333333333333, 5.533333333333333, 266.6666666666667, 179.3333333333333, 50.16666666666666, -3.875, 14.98373201719036, 18.0, 22.15032465505664, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 4441500.0000, 
raw observation next is [1.075, 85.5, 5.425, 267.5, 186.5, 59.75, -3.9, 15.02831877094141, 18.0, 22.14033673583714, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.3608974358974359, 0.855, 0.49318181818181817, 0.7430555555555556, 0.4933862433862434, 0.05975, 0.435, 0.1502831877094141, 0.0, 0.5914766765481626, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:35,812] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-27.36604691]
 [-28.34878159]
 [-26.57177353]
 [-25.50333405]
 [-29.47651291]], R is [[-28.14083672]
 [-28.85942841]
 [-29.57083511]
 [-30.27512741]
 [-30.97237587]].
[2017-11-02 10:23:39,514] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14500, global step 236213: loss 64.2007
[2017-11-02 10:23:39,794] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 236255: loss -43.4250
[2017-11-02 10:23:41,005] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   9.56275725e-10   2.00176631e-09   1.56641677e-09
   1.01129305e-09   1.98920685e-16   2.72856550e-16   7.99895034e-17
   1.72066898e-15], sum to 1.0000
[2017-11-02 10:23:41,048] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.533333333333334, 68.0, 7.433333333333334, 270.0, 0.0, 0.0, -1.4, 15.24696827012183, 18.0, 21.47074126456013, 21.5, 0.0, 0.0], 
actual action is [-1.466666666666666, 18], 
sim time next is 4425900.0000, 
raw observation next is [3.466666666666666, 68.0, 7.466666666666667, 270.0, 0.0, 0.0, -1.466666666666666, 16.03784187161616, 18.0, 21.33770668860909, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.42222222222222217, 0.68, 0.6787878787878788, 0.75, 0.0, 0.0, 0.47555555555555556, 0.1603784187161616, 0.0, 0.4768152412298698, 0.5, 0.0, 0.0], 
reward next is -0.0232. 
=============================================
[2017-11-02 10:23:41,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-25.95946503]
 [-23.13039398]
 [-22.83390045]
 [-22.88772202]
 [-25.14754486]], R is [[-21.09643936]
 [-20.89772415]
 [-20.70054817]
 [-20.50486565]
 [-20.3106308 ]].
[2017-11-02 10:23:46,839] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   6.59571009e-11   4.85714177e-11   6.24069199e-11
   4.17984085e-11   2.39473407e-22   3.09381882e-22   2.01527632e-22
   1.08908243e-21], sum to 1.0000
[2017-11-02 10:23:46,916] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.766666666666667, 81.33333333333334, 7.266666666666667, 253.3333333333333, 100.0, 193.3333333333333, -3.175, 11.21020171596969, 18.0, 22.27609054738331, 22.7, 1.0, 0.0], 
actual action is [-3.233333333333333, 18], 
sim time next is 4436700.0000, 
raw observation next is [1.708333333333333, 81.66666666666666, 7.158333333333333, 254.1666666666667, 110.0, 212.6666666666667, -3.233333333333333, 11.50470963711606, 18.0, 22.27664510702243, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.37713675213675213, 0.8166666666666665, 0.6507575757575758, 0.7060185185185186, 0.291005291005291, 0.21266666666666673, 0.44611111111111107, 0.11504709637116059, 0.0, 0.6109493010032041, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0115. 
=============================================
[2017-11-02 10:23:48,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-6.86431551]
 [-5.71595144]
 [-5.33683062]
 [-5.41535664]
 [-6.13524055]], R is [[-6.53781891]
 [-6.47984743]
 [-6.42247963]
 [-6.36573792]
 [-6.30961895]].
[2017-11-02 10:23:49,948] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   2.42590774e-11   2.78564914e-11   2.91541791e-11
   1.86711688e-11   3.88598246e-23   5.85566780e-23   1.85622568e-23
   2.19084265e-23], sum to 1.0000
[2017-11-02 10:23:50,046] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 7.533333333333333, 290.0, 0.0, 0.0, 5.0, 13.33429680332284, 24.0, 21.95784378508159, 22.7, 1.0, 34.32415997785604], 
actual action is [5.0, 19.0], 
sim time next is 4472700.0000, 
raw observation next is [0.0, 72.0, 7.616666666666665, 290.0, 0.0, 0.0, 5.0, 12.74542688154981, 19.0, 21.96800880106043, 22.7, 1.0, 52.28012985363664], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.3333333333333333, 0.72, 0.6924242424242423, 0.8055555555555556, 0.0, 0.0, 0.5833333333333334, 0.1274542688154981, 0.14285714285714285, 0.5668584001514902, 0.6714285714285714, 1.0, 0.6150603512192545], 
reward next is -0.5663. 
=============================================
[2017-11-02 10:23:51,208] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 237899: loss -158.4002
[2017-11-02 10:23:52,399] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.45770175e-11   2.77780188e-10   2.14940316e-10   1.13203384e-10
   1.73888764e-10   3.68055403e-01   2.49639884e-01   1.53152317e-01
   2.29152352e-01], sum to 1.0000
[2017-11-02 10:23:52,457] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 8.2, 296.6666666666667, 0.0, 0.0, -5.0, 15.00785105463581, 18.0, 21.94973249320342, 22.7, 1.0, 0.0], 
actual action is [5.0, 18.5], 
sim time next is 4477500.0000, 
raw observation next is [0.0, 72.0, 8.2, 297.5, 0.0, 0.0, 5.0, 14.01099902711674, 18.5, 21.86779517203215, 22.7, 1.0, 64.84653148457573], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3333333333333333, 0.72, 0.7454545454545454, 0.8263888888888888, 0.0, 0.0, 0.5833333333333334, 0.1401099902711674, 0.07142857142857142, 0.5525421674331642, 0.6714285714285714, 1.0, 0.7629003704067734], 
reward next is -0.7006. 
=============================================
[2017-11-02 10:23:57,378] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 238749: loss 51.2979
[2017-11-02 10:23:57,463] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 238762: loss -263.0826
[2017-11-02 10:23:59,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.37668124e-23   1.41481263e-16   1.42360470e-16   2.83542228e-17
   5.73978377e-17   2.80892793e-02   4.83152121e-02   3.40270966e-01
   5.83324552e-01], sum to 1.0000
[2017-11-02 10:23:59,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.46983198e-11   3.24752378e-11   2.11094822e-11
   8.31694782e-12   8.96282729e-28   1.62538704e-27   5.98400878e-27
   1.49335591e-26], sum to 1.0000
[2017-11-02 10:23:59,182] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.225, 72.0, 8.85, 310.0, 0.0, 0.0, 4.8, 20.84732204141083, 23.0, 20.36326794820507, 21.5, 0.0, 86.5191677954709], 
actual action is [4.775, 25], 
sim time next is 4488600.0000, 
raw observation next is [-0.25, 72.0, 8.8, 310.0, 0.0, 0.0, 4.775, 18.24221708395179, 25.0, 20.52293816378511, 21.5, 0.0, 62.64713765360523], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.3269230769230769, 0.72, 0.8, 0.8611111111111112, 0.0, 0.0, 0.5795833333333333, 0.1824221708395179, 1.0, 0.3604197376835871, 0.5, 0.0, 0.7370251488659438], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:59,185] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.266666666666666, 63.83333333333333, 5.666666666666666, 254.1666666666667, 0.0, 0.0, 2.333333333333334, 15.11839409697999, 18.0, 21.57289207540845, 22.7, 1.0, 0.0], 
actual action is [2.2666666666666657, 18], 
sim time next is 4408200.0000, 
raw observation next is [7.199999999999999, 64.0, 5.7, 255.0, 0.0, 0.0, 2.266666666666666, 15.20481130160057, 18.0, 21.55619479480943, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.5179487179487179, 0.64, 0.5181818181818182, 0.7083333333333334, 0.0, 0.0, 0.5377777777777778, 0.1520481130160057, 0.0, 0.5080278278299184, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:00,057] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15000, global step 239136: loss 197.4989
[2017-11-02 10:24:01,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.67902643e-17   1.14255323e-17   9.09089939e-18
   5.41617889e-18   7.58094846e-38   3.12691031e-37   1.99785593e-36
   2.32867641e-35], sum to 1.0000
[2017-11-02 10:24:01,281] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 49.66666666666666, 4.1, 340.0, 112.6666666666667, 63.33333333333333, -3.0, 15.99954147208659, 18.0, 22.17381789996055, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4552200.0000, 
raw observation next is [2.0, 50.0, 4.1, 340.0, 109.0, 68.0, -3.0, 16.07287648350622, 18.0, 22.13502653636358, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.38461538461538464, 0.5, 0.3727272727272727, 0.9444444444444444, 0.28835978835978837, 0.068, 0.45, 0.1607287648350622, 0.0, 0.5907180766233685, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:01,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   2.08745815e-14   3.37156925e-14   1.46352013e-14
   6.09490477e-15   9.67001620e-33   2.58459469e-32   1.12009589e-31
   1.15026429e-30], sum to 1.0000
[2017-11-02 10:24:02,033] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 7.366666666666666, 290.0, 0.0, 0.0, -5.0, 16.83102605293441, 18.0, 21.41829450902957, 22.7, 1.0, 0.0], 
actual action is [-5.0, 18], 
sim time next is 4472100.0000, 
raw observation next is [0.0, 72.0, 7.45, 290.0, 0.0, 0.0, -5.0, 17.84457311339185, 18.0, 21.34533746435216, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.3333333333333333, 0.72, 0.6772727272727272, 0.8055555555555556, 0.0, 0.0, 0.4166666666666667, 0.17844573113391848, 0.0, 0.47790535205030843, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:03,002] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 239510: loss -105.8458
[2017-11-02 10:24:04,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 239702: loss 56.3158
[2017-11-02 10:24:07,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.28217711e-04   1.73756962e-05   1.46653319e-05   6.28519092e-06
   8.49567550e-06   3.59450467e-02   8.64463672e-02   1.47036776e-01
   7.30396807e-01], sum to 1.0000
[2017-11-02 10:24:07,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.4, 72.5, 8.35, 310.0, 0.0, 0.0, -5.383333333333333, 17.76558332146903, 18.0, 21.47769484301103, 21.5, 0.0, 0.0], 
actual action is [4.6, 23.0], 
sim time next is 4491300.0000, 
raw observation next is [-0.4166666666666667, 72.58333333333333, 8.291666666666666, 310.0, 0.0, 0.0, 4.6, 16.04951946964498, 23.0, 21.35640513272742, 21.5, 0.0, 65.95301559206743], 
processed observation next is [0.16666666666666666, 1.0, 0.32264957264957267, 0.7258333333333333, 0.7537878787878788, 0.8611111111111112, 0.0, 0.0, 0.5766666666666667, 0.1604951946964498, 0.7142857142857143, 0.47948644753248865, 0.5, 0.0, 0.7759178304949109], 
reward next is -0.7188. 
=============================================
[2017-11-02 10:24:07,551] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 239972: loss 21.6854
[2017-11-02 10:24:09,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  5.91902052e-22   2.12999736e-17   8.24929689e-18   4.29289078e-18
   8.83185786e-18   2.17601359e-02   7.58854672e-02   2.05248266e-01
   6.97106063e-01], sum to 1.0000
[2017-11-02 10:24:09,639] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.0, 80.0, 7.7, 250.0, 60.0, 116.0, -3.0, 13.71133929184643, 18.0, 21.97727299160401, 22.7, 1.0, 0.0], 
actual action is [7.0, 20.0], 
sim time next is 4435500.0000, 
raw observation next is [1.941666666666667, 80.33333333333333, 7.591666666666667, 250.8333333333333, 70.0, 135.3333333333333, 7.0, 11.22849548036331, 20.0, 21.9866005335753, 22.7, 1.0, 67.56080797156538], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.3831196581196581, 0.8033333333333332, 0.6901515151515152, 0.6967592592592591, 0.18518518518518517, 0.13533333333333328, 0.6166666666666667, 0.11228495480363311, 0.2857142857142857, 0.5695143619393284, 0.6714285714285714, 1.0, 0.7948330349595927], 
reward next is -0.7266. 
=============================================
[2017-11-02 10:24:11,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   8.35011909e-16   1.39526994e-15   1.98229194e-15
   1.32999525e-15   0.00000000e+00   6.67812829e-38   3.34100551e-38
   9.11428007e-38], sum to 1.0000
[2017-11-02 10:24:11,088] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 6.758333333333334, 310.0, 0.0, 0.0, 4.4, 15.54744077361133, 20.0, 20.88877773837025, 21.5, 0.0, 42.41720577632081], 
actual action is [-5.6, 18], 
sim time next is 4500000.0000, 
raw observation next is [-0.6, 73.0, 6.7, 310.0, 0.0, 0.0, -5.6, 16.53187451396033, 18.0, 21.12270683219156, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.317948717948718, 0.73, 0.6090909090909091, 0.8611111111111112, 0.0, 0.0, 0.4066666666666666, 0.1653187451396033, 0.0, 0.44610097602736587, 0.5, 0.0, 0.0], 
reward next is -0.0539. 
=============================================
[2017-11-02 10:24:11,182] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 240373: loss 0.0442
[2017-11-02 10:24:11,230] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 240375: loss 13.2009
[2017-11-02 10:24:14,633] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 240846: loss 5.2832
[2017-11-02 10:24:15,677] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 240974: loss -14.0298
[2017-11-02 10:24:15,846] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 240986: loss -53.3233
[2017-11-02 10:24:16,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.10933031e-27   2.38046166e-20   1.09890549e-20   5.17646679e-21
   2.00289862e-20   4.91775125e-02   2.23595977e-01   5.32107294e-01
   1.95119128e-01], sum to 1.0000
[2017-11-02 10:24:16,573] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.6, 73.0, 7.050000000000001, 310.0, 0.0, 0.0, 4.4, 15.94102945896927, 20.0, 21.27515379839002, 21.5, 0.0, 48.20871456300182], 
actual action is [4.4, 22.0], 
sim time next is 4498500.0000, 
raw observation next is [-0.6, 73.0, 6.991666666666667, 310.0, 0.0, 0.0, 4.4, 15.72633963708961, 22.0, 21.3074007949973, 21.5, 0.0, 33.01955901401758], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.317948717948718, 0.73, 0.6356060606060606, 0.8611111111111112, 0.0, 0.0, 0.5733333333333334, 0.15726339637089612, 0.5714285714285714, 0.4724858278567571, 0.5, 0.0, 0.3884654001649127], 
reward next is -0.3771. 
=============================================
[2017-11-02 10:24:16,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.06691907e-29   1.36487915e-24   2.10695281e-25   1.64420504e-25
   9.16560229e-25   1.11580621e-02   1.86593920e-01   6.12565219e-01
   1.89682797e-01], sum to 1.0000
[2017-11-02 10:24:16,858] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.583333333333333, 50.25, 3.516666666666667, 310.0, 248.4166666666667, 53.41666666666667, -2.5, 12.76752391055759, 18.0, 22.53077001540478, 22.7, 1.0, 0.0], 
actual action is [7.583333333333333, 20.0], 
sim time next is 4542000.0000, 
raw observation next is [2.666666666666667, 50.0, 3.433333333333333, 310.0, 249.8333333333333, 58.83333333333333, 7.583333333333333, 11.23465851966474, 20.0, 22.51280008257293, 22.7, 1.0, 57.86096083133543], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.4017094017094017, 0.5, 0.3121212121212121, 0.8611111111111112, 0.6609347442680775, 0.05883333333333333, 0.6263888888888889, 0.11234658519664739, 0.2857142857142857, 0.6446857260818472, 0.6714285714285714, 1.0, 0.6807171862510051], 
reward next is -0.6239. 
=============================================
[2017-11-02 10:24:17,181] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 241147: loss -10.1588
[2017-11-02 10:24:18,080] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15000, global step 241270: loss 2.5777
[2017-11-02 10:24:21,362] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   9.59259424e-36   4.93513230e-36   1.87236488e-36
   1.07271429e-35   8.15488398e-02   1.03333063e-01   5.98646522e-01
   2.16471612e-01], sum to 1.0000
[2017-11-02 10:24:21,444] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.9166666666666666, 73.0, 5.516666666666667, 300.0, 0.0, 0.0, 4.075, 15.44429270571075, 19.5, 21.04591595000127, 21.5, 0.0, 50.66292178467585], 
actual action is [4.083333333333333, 24.5], 
sim time next is 4506900.0000, 
raw observation next is [-0.9083333333333333, 73.0, 5.458333333333334, 300.0, 0.0, 0.0, 4.083333333333333, 14.79122374809873, 24.5, 21.18452499022106, 21.5, 0.0, 40.83807903852489], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.31004273504273505, 0.73, 0.49621212121212127, 0.8333333333333334, 0.0, 0.0, 0.5680555555555556, 0.1479122374809873, 0.9285714285714286, 0.4549321414601515, 0.5, 0.0, 0.4804479886885281], 
reward next is -0.4775. 
=============================================
[2017-11-02 10:24:30,004] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.26588477e-27   6.20876194e-21   4.16772932e-21   2.48593240e-21
   6.86220393e-21   1.83697820e-01   8.84733424e-02   1.65734455e-01
   5.62094390e-01], sum to 1.0000
[2017-11-02 10:24:30,082] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.583333333333333, 69.33333333333333, 0.0, 0.0, 0.0, 0.0, -6.541666666666667, 13.53606075976493, 18.0, 21.73931354097247, 21.5, 0.0, 0.0], 
actual action is [3.416666666666667, 20.0], 
sim time next is 4594500.0000, 
raw observation next is [-1.625, 69.5, 0.0, 0.0, 0.0, 0.0, 3.416666666666667, 12.66631858348471, 20.0, 21.72286064967324, 21.5, 0.0, 54.22748885501018], 
processed observation next is [0.5, 0.17391304347826086, 0.2916666666666667, 0.695, 0.0, 0.0, 0.0, 0.0, 0.5569444444444444, 0.1266631858348471, 0.2857142857142857, 0.5318372356676058, 0.5, 0.0, 0.6379704571177668], 
reward next is -0.5742. 
=============================================
[2017-11-02 10:24:34,503] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15000, global step 243378: loss 19.8869
[2017-11-02 10:24:37,723] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.66791112e-11   1.86455469e-11   2.46313282e-11
   1.70876768e-11   4.05314603e-24   3.12524958e-24   3.32620164e-24
   7.92938054e-24], sum to 1.0000
[2017-11-02 10:24:37,809] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, -3.0, 12.28977202174517, 18.0, 22.11776107921671, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4561200.0000, 
raw observation next is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, -3.0, 13.11620819471204, 18.0, 22.17061281422675, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.38461538461538464, 0.52, 0.2818181818181818, 0.9444444444444444, 0.0, 0.0, 0.45, 0.1311620819471204, 0.0, 0.5958018306038214, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0131. 
=============================================
[2017-11-02 10:24:38,181] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 243906: loss 8.2314
[2017-11-02 10:24:44,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.18153560e-11   2.07733310e-11   2.39398935e-11
   1.40340795e-11   1.77776829e-31   1.83213078e-31   2.87189774e-31
   1.81825541e-30], sum to 1.0000
[2017-11-02 10:24:44,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.08585381268332, 23.0, 21.37308279072636, 21.5, 0.0, 77.62178810194092], 
actual action is [-4.0, 18.0], 
sim time next is 4572600.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, -4.0, 16.19200569590109, 18.0, 21.53710171027454, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.43333333333333335, 0.1619200569590109, 0.0, 0.5053002443249345, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:24:50,187] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 245603: loss 14.0486
[2017-11-02 10:24:53,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-14.16205788]
 [-14.4144001 ]
 [-12.63282681]
 [-17.56111145]
 [-16.70965958]], R is [[-15.91987419]
 [-15.77509308]
 [-15.63165665]
 [-15.48953438]
 [-15.34864998]].
[2017-11-02 10:24:56,265] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 246352: loss 6.0725
[2017-11-02 10:24:59,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-25.19816017]
 [-19.79620552]
 [-18.14678574]
 [-18.9941082 ]
 [-23.20381927]], R is [[-26.05017281]
 [-25.80323029]
 [-25.55829048]
 [-25.31523895]
 [-25.07388115]].
[2017-11-02 10:24:59,711] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15500, global step 246836: loss 3.5976
[2017-11-02 10:25:01,442] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 247042: loss 3.9954
[2017-11-02 10:25:03,629] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 247320: loss 10.4327
[2017-11-02 10:25:07,718] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 247902: loss 4.8518
[2017-11-02 10:25:07,788] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 247913: loss 5.3775
[2017-11-02 10:25:13,820] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 248667: loss 8.9818
[2017-11-02 10:25:14,814] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 248774: loss 11.8283
[2017-11-02 10:25:15,377] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 248849: loss 14.7130
[2017-11-02 10:25:17,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 249133: loss -20.4331
[2017-11-02 10:25:17,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 249211: loss 5.7030
[2017-11-02 10:25:18,019] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 249216: loss 4.6915
[2017-11-02 10:25:18,154] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15500, global step 249234: loss 1.2115
[2017-11-02 10:25:24,561] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:40

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=00hr 44min 59.97sec

[2017-11-02 10:25:24,567] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:25:24,567] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:25:25,562] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:25:25,565] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run2
[2017-11-02 10:26:13,069] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.96460605  0.00234091  0.00601579  0.00213038  0.00397401  0.00118907
  0.01464587  0.00180407  0.00329377]
[2017-11-02 10:26:15,515] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20474905e-01   2.55968844e-05   1.64240246e-05   1.11483769e-05
   2.72860198e-05   6.44619614e-02   6.58918083e-01   8.72900859e-02
   6.87745363e-02]
[2017-11-02 10:26:16,343] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.90608387e-09   1.69411693e-10   7.27297597e-11   5.40745677e-11
   1.64821976e-10   7.41642863e-02   7.79584229e-01   9.53102335e-02
   5.09412140e-02]
[2017-11-02 10:26:21,073] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.09211642e-09   6.82501593e-08   1.10824907e-07   3.34191625e-08
   8.13836678e-08   6.47963658e-02   6.78539991e-01   1.07544251e-01
   1.49119154e-01]
[2017-11-02 10:26:28,146] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   5.48352084e-08   4.54169999e-08   4.70478305e-08
   6.48625686e-08   2.90608065e-10   2.06467865e-09   2.41364095e-10
   1.44592061e-10]
[2017-11-02 10:26:34,943] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.66166990e-14   5.19064128e-14   4.70052904e-14   3.82080333e-14
   7.46298436e-14   8.96006078e-02   8.11970234e-01   7.55480528e-02
   2.28810906e-02]
[2017-11-02 10:26:37,460] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.84971370e-15   3.78631751e-13   3.51215259e-13   1.85960649e-13
   4.61973829e-13   8.51849914e-02   7.44287789e-01   9.54434350e-02
   7.50837773e-02]
[2017-11-02 10:26:42,368] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.51895530e-15   4.63035079e-12   4.19621499e-12   1.64376293e-12
   3.61074603e-12   7.20517337e-02   6.92468524e-01   1.15652494e-01
   1.19827285e-01]
[2017-11-02 10:26:43,034] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.60821457e-07   3.10673357e-07   2.20058482e-07   8.34585308e-08
   1.93745123e-07   8.25173110e-02   6.63913667e-01   1.48329169e-01
   1.05238914e-01]
[2017-11-02 10:27:11,761] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.06570690e-10   2.38123832e-09   1.79066384e-09   6.04501560e-10
   1.80437776e-09   6.57004416e-02   7.09630430e-01   1.24108106e-01
   1.00561030e-01]
[2017-11-02 10:27:41,422] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.03428736
  0.68674916  0.20050296  0.0784606 ]
[2017-11-02 10:27:50,260] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.04912213
  0.86025149  0.07814797  0.01247853]
[2017-11-02 10:28:13,996] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.04598191
  0.68722022  0.17106263  0.09573515]
[2017-11-02 10:28:17,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.21776373e-34   2.14425509e-25   7.36840336e-26   3.17588806e-26
   1.92327136e-25   6.80455938e-02   7.57504165e-01   1.12524241e-01
   6.19259737e-02]
[2017-11-02 10:28:26,125] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99310732e-01   4.23220655e-07   1.48800382e-07   1.50407431e-07
   3.83867899e-07   5.46049087e-05   5.42973110e-04   6.49796420e-05
   2.56225012e-05]
[2017-11-02 10:28:27,710] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.42873604e-12   7.01728714e-13   8.74382218e-13
   1.43327776e-12   1.00812172e-19   8.89308494e-19   1.05540685e-19
   4.91679290e-20]
[2017-11-02 10:28:30,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.27357156e-05   2.26594566e-05   3.40688566e-05   1.08026725e-05
   2.56131352e-05   7.32923672e-02   6.71602368e-01   1.22158661e-01
   1.32820681e-01]
[2017-11-02 10:28:31,410] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99958158e-01   7.71754276e-06   1.72600940e-05   6.70900681e-06
   1.01358546e-05   2.21350549e-10   2.12467643e-09   3.25551364e-10
   4.73717843e-10]
[2017-11-02 10:28:33,965] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993086e-01   1.25085694e-06   2.75556840e-06   1.10286715e-06
   1.74514332e-06   4.72351628e-12   5.35259094e-11   7.19481332e-12
   1.01466223e-11]
[2017-11-02 10:28:35,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.43140696e-09   6.76662069e-08   1.08189710e-07   3.35463071e-08
   8.60565237e-08   6.21648207e-02   6.94958210e-01   1.03782915e-01
   1.39093742e-01]
[2017-11-02 10:28:44,035] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97553647e-01   4.28301049e-04   6.76016032e-04   2.42228154e-04
   4.87421552e-04   4.42505516e-05   4.23401623e-04   7.32401386e-05
   7.14475318e-05]
[2017-11-02 10:28:44,928] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.72218132e-08   1.73366544e-07   2.64481542e-07   8.10225060e-08
   1.98341567e-07   6.82847649e-02   6.86376214e-01   1.13458611e-01
   1.31879643e-01]
[2017-11-02 10:28:49,926] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.98794999e-23   7.54827455e-17   6.66987227e-17   1.73093681e-17
   6.70374697e-17   6.31170496e-02   6.95300400e-01   1.21653870e-01
   1.19928740e-01]
[2017-11-02 10:28:54,681] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.53636584e-08   1.04464021e-10   4.90779813e-11   4.09311716e-11
   1.20207982e-10   6.58083186e-02   8.31410110e-01   7.33070225e-02
   2.94744428e-02]
[2017-11-02 10:28:56,714] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.47992710e-16   1.71931923e-15   7.45269668e-16   5.24618803e-16
   1.92061629e-15   6.33477420e-02   8.27292442e-01   7.88760409e-02
   3.04837562e-02]
[2017-11-02 10:29:02,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.20611201e-05   2.74886588e-05   3.45627814e-05   1.12017315e-05
   2.10056514e-05   5.90029806e-02   6.47880435e-01   1.26682892e-01
   1.66247338e-01]
[2017-11-02 10:29:03,122] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.77826953e-10   1.49264778e-08   2.04844284e-08   6.10938500e-09
   1.65549103e-08   7.21780583e-02   6.82844698e-01   1.23094164e-01
   1.21883035e-01]
[2017-11-02 10:29:07,297] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94433224e-01   1.05245900e-03   9.35077027e-04   4.04732593e-04
   6.81200356e-04   1.89070153e-04   1.72254886e-03   2.95837701e-04
   2.85853312e-04]
[2017-11-02 10:29:08,902] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99927282e-01   2.25622935e-05   2.37159038e-05   1.06154748e-05
   1.58576095e-05   6.81576307e-09   6.20012344e-08   1.03582849e-08
   1.04443059e-08]
[2017-11-02 10:29:09,145] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.05480581e-17   5.79504272e-13   4.94452515e-13   1.52061089e-13
   4.25101523e-13   6.99907988e-02   6.79843307e-01   1.21488124e-01
   1.28677800e-01]
[2017-11-02 10:29:12,414] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.69162042e-04   1.42375791e-06   1.70469116e-06   1.38802056e-06
   1.92566472e-06   1.20333977e-01   7.25839674e-01   9.32426453e-02
   6.04080968e-02]
[2017-11-02 10:29:12,475] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.23349351e-02   2.83127993e-05   3.52358475e-05   2.95865630e-05
   3.86812972e-05   1.18398935e-01   7.10667372e-01   9.05610174e-02
   5.79058938e-02]
[2017-11-02 10:29:13,896] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.10683435e-10   1.61240160e-10   1.98916744e-10
   1.87567739e-10   2.09896353e-15   1.28431997e-14   1.19968188e-15
   4.36556122e-16]
[2017-11-02 10:29:14,435] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.36026821e-07   1.72650427e-09   2.37560371e-09   2.09166995e-09
   3.02863024e-09   1.20111324e-01   7.77152836e-01   7.64663219e-02
   2.62692608e-02]
[2017-11-02 10:29:17,614] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.23741493e-16   2.52307138e-12   2.40246755e-12   8.77101018e-13
   1.65255114e-12   7.43337423e-02   6.50528371e-01   1.27154097e-01
   1.47983760e-01]
[2017-11-02 10:29:34,808] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.44198299e-05   1.33101096e-07   5.92944147e-08   5.25014912e-08
   1.23083367e-07   9.48544815e-02   7.52812445e-01   1.00517049e-01
   5.17512187e-02]
[2017-11-02 10:29:43,235] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.40873371e-05   3.83260849e-05   4.02709484e-05   1.44121695e-05
   2.47943153e-05   8.72238651e-02   6.13151670e-01   1.42041385e-01
   1.57451153e-01]
[2017-11-02 10:29:44,442] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.15232910e-12   1.23276434e-09   1.14241938e-09   3.83445747e-10
   8.84573081e-10   7.81828314e-02   6.47345781e-01   1.30015805e-01
   1.44455597e-01]
[2017-11-02 10:29:45,374] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.42785567e-17   1.29358091e-12   1.12838460e-12   3.49941484e-13
   9.08732399e-13   7.98188746e-02   6.34624004e-01   1.35929868e-01
   1.49627283e-01]
[2017-11-02 10:29:48,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.57136698e-09   3.22291838e-09   2.46492116e-09
   2.63127231e-09   2.54493325e-16   1.72019644e-15   3.33617796e-16
   3.07005636e-16]
[2017-11-02 10:29:51,570] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.38112058e-10   5.17789978e-11   2.09563894e-11   1.61730993e-11
   4.54694546e-11   8.63122642e-02   7.53125191e-01   1.03157341e-01
   5.74051924e-02]
[2017-11-02 10:29:51,878] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19226999e-04   2.29853413e-07   9.78561729e-08   8.28368414e-08
   1.98581873e-07   9.32649449e-02   7.35064685e-01   1.08778536e-01
   6.27720132e-02]
[2017-11-02 10:29:58,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.92895352e-09   1.02015818e-09   1.16733501e-09
   2.41695042e-09   5.77292970e-11   5.25420984e-10   6.69140438e-11
   3.36814222e-11]
[2017-11-02 10:30:00,507] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.20135362e-13   6.20787167e-13   4.17311341e-13
   2.36005659e-13   6.77839942e-32   5.89059403e-31   1.24795664e-31
   2.15023025e-31]
[2017-11-02 10:30:00,610] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.15070425e-13   4.72111445e-13   3.14436465e-13
   1.78282383e-13   2.74826553e-32   2.46442367e-31   5.03635676e-32
   8.66018544e-32]
[2017-11-02 10:30:00,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.85288186e-13   2.79273241e-13   1.88252002e-13
   1.03292192e-13   3.60604051e-33   3.35872708e-32   6.67414689e-33
   1.15883378e-32]
[2017-11-02 10:30:00,857] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.86450711e-13   1.27497817e-12   7.82237935e-13
   4.53083941e-13   3.40484760e-31   3.01394118e-30   6.31370899e-31
   1.12688079e-30]
[2017-11-02 10:30:04,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99298453e-01   1.87667087e-04   2.74331949e-04   1.00001336e-04
   1.37358846e-04   1.41698877e-07   1.33605784e-06   2.87018082e-07
   4.67100648e-07]
[2017-11-02 10:30:04,549] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.40560675e-01   9.61194310e-05   5.16756154e-05   3.70641283e-05
   8.65826441e-05   1.35474782e-02   1.13611810e-01   1.84405148e-02
   1.35681676e-02]
[2017-11-02 10:30:06,154] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.03903328e-13   4.77457971e-13   3.54091864e-13
   1.41671397e-13   1.10073129e-36   1.04364383e-35   2.19455034e-36
   3.63435891e-36]
[2017-11-02 10:30:06,708] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.49657657e-13   2.77336802e-13   2.21105442e-13
   9.95749029e-14   5.31660189e-36   4.96938285e-35   1.02677401e-35
   1.66478871e-35]
[2017-11-02 10:30:06,951] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.07260553e-14   1.03166180e-13   8.47327918e-14
   4.02048966e-14   1.47564629e-36   1.46027565e-35   2.71214183e-36
   4.36771557e-36]
[2017-11-02 10:30:06,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.33187757e-14   1.08209652e-13   8.85826785e-14
   4.19061114e-14   1.53424200e-36   1.51585363e-35   2.82336736e-36
   4.56365736e-36]
[2017-11-02 10:30:07,076] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.91169298e-14   1.01908262e-13   8.27093588e-14
   3.91013414e-14   1.34975579e-36   1.34489956e-35   2.47116711e-36
   4.08210646e-36]
[2017-11-02 10:30:07,169] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.14831401e-14   1.07830554e-13   8.65306633e-14
   4.05128066e-14   1.20240430e-36   1.20556014e-35   2.21899634e-36
   3.65683242e-36]
[2017-11-02 10:30:08,045] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.64899803e-15   1.56405947e-15   2.30279946e-15
   3.34626168e-15   6.53692116e-26   5.92527428e-25   7.11484251e-26
   4.07525020e-26]
[2017-11-02 10:30:08,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.40220983e-14   4.28724032e-14   3.20825181e-14
   1.53146420e-14   4.66548535e-37   5.20121453e-36   8.68149823e-37
   1.49149240e-36]
[2017-11-02 10:30:09,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99976873e-01   5.23609151e-06   1.01181195e-05   3.54594545e-06
   4.21502864e-06   3.00092555e-11   3.16495885e-10   5.96350122e-11
   1.03156476e-10]
[2017-11-02 10:30:12,430] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.29642153e-15   3.06437896e-11   3.88249606e-11   1.18923673e-11
   2.70744295e-11   6.88065663e-02   6.69238508e-01   1.09310210e-01
   1.52644724e-01]
[2017-11-02 10:30:12,510] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.72787179e-03   8.93292890e-04   1.29261345e-03   4.74960281e-04
   7.58058450e-04   7.23958015e-02   6.61890388e-01   1.06365725e-01
   1.50201276e-01]
[2017-11-02 10:30:13,494] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.58818709e-08   1.00225691e-07   1.54372785e-07   7.61035537e-08
   1.23709341e-07   9.46960747e-02   6.58083737e-01   1.02216028e-01
   1.45003647e-01]
[2017-11-02 10:30:17,131] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.70516941e-12   9.84081653e-12   6.66208495e-12
   3.66939725e-12   2.58297481e-27   2.29467527e-26   3.55082202e-27
   5.20661833e-27]
[2017-11-02 10:30:18,559] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.77036655e-01   3.21801566e-03   5.38045261e-03   2.02154112e-03
   2.78904289e-03   7.34929519e-04   6.24810392e-03   1.07668375e-03
   1.49455376e-03]
[2017-11-02 10:30:28,709] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98992145e-01   2.80974287e-04   3.78970173e-04   1.52404522e-04
   1.93795451e-04   1.60355071e-07   1.08836252e-06   2.45911650e-07
   2.97650729e-07]
[2017-11-02 10:30:34,747] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.06348473e-14   9.27124148e-15   1.98731277e-14
   2.05791940e-14   5.26701041e-26   3.93109530e-25   5.00606970e-26
   2.19146623e-26]
[2017-11-02 10:30:35,239] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.15691005e-12   2.52009112e-12   5.06840186e-12
   5.28205778e-12   1.44766089e-23   7.37407358e-23   1.45239579e-23
   5.35285788e-24]
[2017-11-02 10:30:40,867] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.97725328e-16   2.26413230e-16   5.71814367e-16
   6.56669651e-16   6.79844995e-30   6.23725533e-29   6.73710908e-30
   1.93599537e-30]
[2017-11-02 10:30:40,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.19905963e-15   3.19683840e-16   7.79576567e-16
   9.02670306e-16   1.08185661e-29   9.49704704e-29   1.10947415e-29
   3.35163983e-30]
[2017-11-02 10:30:41,059] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.95064649e-16   1.87096939e-16   4.50523854e-16
   5.21501616e-16   3.48728210e-30   3.15597145e-29   3.69625302e-30
   1.21044330e-30]
[2017-11-02 10:30:41,519] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.21792075e-15   3.92688879e-15   7.78147823e-15
   7.61375724e-15   1.06384955e-29   8.10814641e-29   1.31749286e-29
   5.82870284e-30]
[2017-11-02 10:30:41,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.01127959e-12   6.24490390e-12   5.03894452e-12
   2.08432533e-12   1.13347586e-32   8.53763839e-32   2.45752229e-32
   3.35473216e-32]
[2017-11-02 10:30:43,022] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96928871e-01   5.53341175e-04   1.25944137e-03   4.79857001e-04
   7.43875105e-04   2.22089079e-06   2.27549372e-05   3.24313328e-06
   6.42930263e-06]
[2017-11-02 10:30:49,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.70506722e-07   1.35214805e-06   2.31169224e-06   7.02706416e-07
   1.73275203e-06   6.97545707e-02   6.83092058e-01   1.15741715e-01
   1.31404936e-01]
[2017-11-02 10:30:51,998] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.94161188e-13   8.95487781e-11   1.55170904e-10   4.24161851e-11
   1.23140498e-10   6.29516691e-02   6.89258754e-01   1.07510068e-01
   1.40279487e-01]
[2017-11-02 10:30:58,571] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.48573331e-10   5.78119663e-10   6.00929195e-10
   1.07710729e-09   9.00652654e-13   8.55402554e-12   9.10490867e-13
   5.52678996e-13]
[2017-11-02 10:30:59,667] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.82142983e-13   1.15925620e-13   1.42269294e-13
   2.14185047e-13   3.26781296e-21   3.44170498e-20   3.09428072e-21
   1.50932118e-21]
[2017-11-02 10:31:34,774] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.29222083e-04   7.30382671e-05   7.21873439e-05   2.55653995e-05
   5.73511388e-05   6.97950721e-02   6.90554261e-01   1.22958586e-01
   1.15734726e-01]
[2017-11-02 10:31:42,856] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.22144697e-10   5.66830784e-11   6.06101141e-11   4.97820153e-11
   7.95441560e-11   1.13743797e-01   7.59338081e-01   8.87244493e-02
   3.81936990e-02]
[2017-11-02 10:31:45,961] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.19525146  0.00299493  0.00374549  0.00173397  0.00214273  0.06254911
  0.51997483  0.09279774  0.11880971]
[2017-11-02 10:31:54,592] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.27861118  0.00389101  0.00343936  0.00137055  0.00254176  0.05426733
  0.47807363  0.09246974  0.08533543]
[2017-11-02 10:31:58,670] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99952197e-01   1.08473091e-06   6.78620779e-07   6.68630094e-07
   1.16058982e-06   4.28522162e-06   3.36442172e-05   3.97335452e-06
   2.32308980e-06]
[2017-11-02 10:31:58,782] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.75713125e-11   1.09162705e-11   5.01800598e-12   3.92308321e-12
   1.04119283e-11   8.98740664e-02   7.62958288e-01   9.62209105e-02
   5.09468243e-02]
[2017-11-02 10:32:14,885] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99572217e-01   5.29390888e-07   2.30808411e-07   2.48211421e-07
   5.09545487e-07   3.72538780e-05   3.35974677e-04   3.74979682e-05
   1.55060479e-05]
[2017-11-02 10:32:15,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.30100458e-03   5.47052323e-08   2.08005488e-08   2.13771614e-08
   5.47286092e-08   6.91187680e-02   8.30655694e-01   7.42759109e-02
   2.16485299e-02]
[2017-11-02 10:32:15,847] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.46082764e-05   2.70338596e-09   9.63451430e-10   9.54379686e-10
   2.61989164e-09   7.09216073e-02   8.28320205e-01   7.81445205e-02
   2.25891806e-02]
[2017-11-02 10:32:17,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.64227709e-17   1.95154646e-14   9.88754180e-15   4.86728044e-15
   1.60941867e-14   7.50773251e-02   7.22869039e-01   1.19541965e-01
   8.25116858e-02]
[2017-11-02 10:32:29,406] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.04388874e-07   3.94467392e-09   2.17878826e-09   1.63557623e-09
   4.13032542e-09   8.95159394e-02   7.32995033e-01   1.05494879e-01
   7.19939619e-02]
[2017-11-02 10:32:31,682] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.95994277e-02   5.16312184e-07   2.18153801e-07   2.07175162e-07
   5.44104182e-07   6.89966157e-02   7.75865614e-01   7.59214759e-02
   2.96153650e-02]
[2017-11-02 10:32:39,329] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.48475169e-06   3.75288187e-06   4.06291292e-06   1.35854009e-06
   3.12142424e-06   7.34813735e-02   6.70831978e-01   1.28003180e-01
   1.27667680e-01]
[2017-11-02 10:32:50,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999642e-01   1.07963736e-08   4.57091387e-09   5.11044007e-09
   1.10733342e-08   2.53656864e-08   2.68970950e-07   2.63439635e-08
   1.01863016e-08]
[2017-11-02 10:32:53,179] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.68548003e-21   3.79284159e-15   3.57491695e-15   9.42328283e-16
   2.29528543e-15   6.29000887e-02   5.93256652e-01   1.49505198e-01
   1.94338068e-01]
[2017-11-02 10:32:59,193] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.60538710e-10   1.70315690e-08   1.72071086e-08   5.61658675e-09
   1.42221595e-08   7.11157620e-02   6.72548473e-01   1.22047357e-01
   1.34288460e-01]
[2017-11-02 10:33:05,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.70172381e-04   4.81525442e-09   1.62883584e-09   1.57247093e-09
   4.81290430e-09   6.28223941e-02   8.39426398e-01   7.46763274e-02
   2.29046382e-02]
[2017-11-02 10:33:10,908] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.89863325e-10   3.08255181e-08   3.30729719e-08   1.05707558e-08
   2.46859901e-08   7.74441585e-02   6.47739768e-01   1.31620422e-01
   1.43195629e-01]
[2017-11-02 10:33:14,037] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.09722051e-19   1.95289324e-14   1.21502379e-14   3.73353700e-15
   1.40807649e-14   6.65079355e-02   7.03641534e-01   1.30829632e-01
   9.90209654e-02]
[2017-11-02 10:33:21,914] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.30686806e-11   1.43875103e-11   2.04338040e-11
   3.99074523e-11   1.46097178e-13   1.57597427e-12   1.42590936e-13
   4.64254896e-14]
[2017-11-02 10:33:32,507] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.17524621e-12   6.52488155e-13   1.30760550e-12
   8.22735706e-13   9.41787200e-26   5.72931827e-25   6.35380867e-26
   1.72462189e-26]
[2017-11-02 10:33:35,661] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.47218529e-09   1.56839008e-07   1.66720042e-07   5.70291228e-08
   1.02738312e-07   8.34908709e-02   6.28664136e-01   1.37884423e-01
   1.49960145e-01]
[2017-11-02 10:33:38,294] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.70130687e-14   9.06877698e-11   7.13338694e-11   2.34074028e-11
   6.10672485e-11   7.09063560e-02   6.71796978e-01   1.29932076e-01
   1.27364531e-01]
[2017-11-02 10:33:46,364] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999285e-01   6.01165251e-09   2.03217154e-09   2.57911736e-09
   5.61100544e-09   5.35976312e-08   6.08433197e-07   5.54984965e-08
   1.72746777e-08]
[2017-11-02 10:34:09,444] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.09373730e-18   6.87335551e-13   5.51010138e-13   1.74167918e-13
   4.10063720e-13   9.19838920e-02   5.97180247e-01   1.62330955e-01
   1.48504823e-01]
[2017-11-02 10:34:17,665] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.64837705e-15   1.15784957e-15   2.65909392e-15
   3.21885416e-15   1.70395727e-26   1.50989407e-25   1.67431783e-26
   5.89285375e-27]
[2017-11-02 10:34:23,021] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.72144485e-08   3.31846479e-07   4.67393392e-07   1.45136781e-07
   3.38618833e-07   7.35076442e-02   6.46526575e-01   1.22326940e-01
   1.57637537e-01]
[2017-11-02 10:34:31,899] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97541218e-03   2.37011482e-04   3.58586898e-04   1.11812878e-04
   2.02986659e-04   5.46609275e-02   6.46246433e-01   1.16624773e-01
   1.78582028e-01]
[2017-11-02 10:34:43,090] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20499067e-01   4.03826483e-08   1.39882745e-08   1.59634155e-08
   4.54200588e-08   4.95161451e-02   7.65585601e-01   5.19844033e-02
   1.24146342e-02]
[2017-11-02 10:34:53,304] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.79886492e-18   1.83566405e-14   1.04960706e-14   4.31942588e-15
   1.30100559e-14   7.56571144e-02   6.80609584e-01   1.32321224e-01
   1.11412048e-01]
[2017-11-02 10:34:58,090] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37202088e-12   1.75962001e-13   4.26319712e-14   3.73639921e-14
   1.37307253e-13   6.69523254e-02   8.17989469e-01   8.66586119e-02
   2.83996221e-02]
[2017-11-02 10:34:58,912] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.04162417e-08   3.39254541e-07   4.43498720e-07   1.26129578e-07
   2.58959091e-07   5.43824919e-02   6.50255620e-01   1.22522928e-01
   1.72837749e-01]
[2017-11-02 10:35:01,655] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.27022449e-12   7.56605611e-10   1.03554676e-09   3.11449838e-10
   7.86481269e-10   6.91005662e-02   6.58013165e-01   1.13497257e-01
   1.59389004e-01]
[2017-11-02 10:35:06,272] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.07876760e-11   5.68394880e-11   1.06015294e-10
   7.66377656e-11   1.90499988e-22   7.44391516e-22   1.00108039e-22
   2.66411896e-23]
[2017-11-02 10:35:07,265] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.08861250e-10   2.86574542e-10   5.02677788e-10
   3.64559882e-10   6.65438025e-22   2.38903251e-21   3.36960131e-22
   1.01861544e-22]
[2017-11-02 10:35:08,001] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.22758664e-10   2.33795400e-10   1.50269422e-10
   6.76821446e-11   5.10182971e-25   3.44542889e-24   6.77369369e-25
   1.18516165e-24]
[2017-11-02 10:35:11,323] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99504924e-01   1.37975469e-04   1.75844340e-04   7.21972028e-05
   1.06440370e-04   2.11658218e-07   1.86815612e-06   3.30777169e-07
   4.03265688e-07]
[2017-11-02 10:35:13,904] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.95330199e-11   6.12484369e-11   7.68579297e-11
   9.81618883e-11   1.90659043e-16   1.42114023e-15   1.60575517e-16
   9.44320505e-17]
[2017-11-02 10:35:21,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.43317459e-07   5.92066385e-07   5.10907341e-07   1.81481582e-07
   4.15935574e-07   7.34155327e-02   6.79996490e-01   1.30223945e-01
   1.16362087e-01]
[2017-11-02 10:35:24,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.86128036e-20   2.33734591e-15   1.29934187e-15   4.60166425e-16
   1.42879085e-15   7.13818595e-02   6.71162009e-01   1.47650868e-01
   1.09805197e-01]
[2017-11-02 10:35:29,389] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.17247811e-10   1.01206821e-10   1.33513783e-10
   2.48858739e-10   1.33625167e-13   1.20164859e-12   1.44544993e-13
   5.59895758e-14]
[2017-11-02 10:35:29,804] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.31231933e-07   4.00651106e-06   4.15557270e-06   1.44809815e-06
   1.90738501e-06   7.03971088e-02   5.37237287e-01   1.68652445e-01
   2.23701090e-01]
[2017-11-02 10:35:35,773] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00654431e-20   4.43247852e-15   3.37380169e-15   9.81472746e-16
   3.05915817e-15   7.23460391e-02   6.61112547e-01   1.35523662e-01
   1.31017745e-01]
[2017-11-02 10:35:39,302] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.42048184e-09   2.37585107e-09   2.79653345e-09
   5.33774847e-09   4.23193786e-10   3.77073439e-09   4.13895446e-10
   1.86773763e-10]
[2017-11-02 10:35:39,572] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.45377579e-15   1.62388487e-15   3.32833677e-15
   4.66343815e-15   3.24766343e-24   2.97140458e-23   2.91438666e-24
   1.08729990e-24]
[2017-11-02 10:35:39,617] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.70514381e-15   4.40625030e-16   1.01261010e-15
   1.29277874e-15   3.57167683e-26   3.42677479e-25   3.26956283e-26
   1.14527527e-26]
[2017-11-02 10:35:39,676] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.06796392e-15   2.41089188e-16   5.91263408e-16
   7.20418621e-16   3.28026738e-27   3.19948147e-26   3.07607643e-27
   1.00085254e-27]
[2017-11-02 10:35:40,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.25670172e-16   1.84646512e-16   4.35385311e-16
   5.00819665e-16   2.98145541e-29   3.01392123e-28   2.99011156e-29
   1.04247714e-29]
[2017-11-02 10:35:41,026] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996781e-01   9.22890592e-07   1.25598717e-06   5.37627784e-07
   4.93686287e-07   2.63901883e-13   2.20652359e-12   5.59123765e-13
   8.20501490e-13]
[2017-11-02 10:35:44,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.65598946e-15   1.64824075e-11   2.41226917e-11   7.00982761e-12
   2.08688067e-11   6.06518909e-02   6.90026760e-01   1.03576146e-01
   1.45745188e-01]
[2017-11-02 10:35:49,640] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.94997854e-16   7.92605257e-17   2.08900149e-16
   2.58556225e-16   3.76648558e-28   3.83947115e-27   3.51632630e-28
   9.61016774e-29]
[2017-11-02 10:35:50,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.18191187e-15   2.85741853e-16   7.42471018e-16
   8.74097397e-16   1.48777077e-28   1.43632639e-27   1.33440259e-28
   3.42702923e-29]
[2017-11-02 10:35:50,907] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0149697   0.00289149  0.00385652  0.00127653  0.00157866  0.06623106
  0.54743332  0.14551206  0.21625066]
[2017-11-02 10:35:56,233] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30892687e-14   2.03932340e-11   1.76822983e-11   5.42332889e-12
   1.54855000e-11   7.03136921e-02   6.78450942e-01   1.27702981e-01
   1.23532467e-01]
[2017-11-02 10:36:04,941] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.03116209  0.00387087  0.00769156  0.00260592  0.00479801  0.0611261
  0.61284667  0.09599772  0.17990102]
[2017-11-02 10:36:05,299] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.87172961  0.00965689  0.01976875  0.00699968  0.01222572  0.00516171
  0.05206465  0.00796247  0.0144305 ]
[2017-11-02 10:36:11,736] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99966025e-01   7.13456802e-06   1.34677393e-05   5.20989443e-06
   8.15390194e-06   4.75154915e-10   4.62026639e-09   7.28826999e-10
   9.10339804e-10]
[2017-11-02 10:36:17,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.18138483e-12   5.21876813e-12   8.90319762e-12
   6.77443605e-12   1.77977239e-21   1.06436997e-20   1.16784453e-21
   3.70349445e-22]
[2017-11-02 10:36:17,746] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.67849759e-12   9.57771536e-12   1.49186982e-11
   1.28650398e-11   2.41614520e-19   1.41487951e-18   1.59643842e-19
   4.97626881e-20]
[2017-11-02 10:36:20,315] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.78811424e-09   1.26492372e-08   6.37851327e-09
   5.74564885e-09   1.29456816e-18   8.97347862e-18   1.85240357e-18
   2.02289025e-18]
[2017-11-02 10:36:22,598] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.19084176e-07   1.57515615e-06   1.58339742e-06   5.39678240e-07
   1.22456333e-06   6.86508268e-02   6.81018054e-01   1.20096825e-01
   1.30228683e-01]
[2017-11-02 10:36:28,441] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.10755860e-14   3.05677102e-15   6.56567298e-15
   8.29067463e-15   1.55996394e-25   1.36548707e-24   1.51853530e-25
   5.81086529e-26]
[2017-11-02 10:36:29,521] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.47049452e-12   2.11928175e-12   1.82481764e-12
   8.62667088e-13   4.47993092e-29   3.36011797e-28   8.92709696e-29
   1.34568950e-28]
[2017-11-02 10:36:32,926] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.27744818  0.0064811   0.007321    0.00278179  0.00488443  0.05315591
  0.46281266  0.08629636  0.09881856]
[2017-11-02 10:36:55,713] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.21300971e-14   1.69207520e-14   3.99407476e-14
   4.87798651e-14   8.62253861e-25   6.22232301e-24   8.05304809e-25
   2.60997761e-25]
[2017-11-02 10:36:55,843] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.31467233e-14   1.18190793e-14   2.78916447e-14
   3.33401858e-14   4.43430548e-25   3.30424744e-24   4.07598291e-25
   1.31622970e-25]
[2017-11-02 10:37:19,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99894381e-01   2.51139882e-05   4.07578082e-05   1.58493476e-05
   2.38581270e-05   1.54809843e-09   1.26039756e-08   2.36042408e-09
   2.77312329e-09]
[2017-11-02 10:37:19,359] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98791158e-01   2.88828480e-04   4.51543339e-04   1.68297425e-04
   2.78408581e-04   1.72063687e-06   1.43356683e-05   2.70504256e-06
   3.10902237e-06]
[2017-11-02 10:37:30,053] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.22504726  0.00906976  0.01345013  0.00486507  0.00785258  0.05069369
  0.49036476  0.07865261  0.12000414]
[2017-11-02 10:37:30,110] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   1.11457632e-06   1.99941655e-06   9.15343719e-07
   9.79895049e-07   2.43860433e-13   2.24263576e-12   3.27389889e-13
   5.15087972e-13]
[2017-11-02 10:37:34,805] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.12615306e-10   8.04113373e-11   1.38498060e-10
   1.04263438e-10   5.74821366e-24   2.27519776e-23   3.20131608e-24
   1.05674574e-24]
[2017-11-02 10:37:39,154] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.79824610e-16   2.67219969e-16   5.82238907e-16
   6.79585333e-16   3.86971543e-28   3.96885127e-27   3.72237745e-28
   1.50370110e-28]
[2017-11-02 10:37:43,108] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06882853  0.00275668  0.00428347  0.00143395  0.00262451  0.0661554
  0.6083352   0.10788337  0.13769887]
[2017-11-02 10:37:43,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995828e-01   8.92831736e-07   1.61626542e-06   6.54866312e-07
   8.95943288e-07   5.90641956e-13   5.53366858e-12   8.95441707e-13
   1.15924750e-12]
[2017-11-02 10:37:44,177] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.18303423e-04   1.14934883e-04   1.75527748e-04   5.79182451e-05
   1.18768025e-04   6.64515868e-02   6.77951038e-01   1.09570190e-01
   1.45041779e-01]
[2017-11-02 10:37:47,619] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.20922323e-17   2.78043728e-13   2.20798084e-13   8.67988881e-14
   1.96399849e-13   7.99645856e-02   6.20675743e-01   1.39581949e-01
   1.59777716e-01]
[2017-11-02 10:37:51,264] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999642e-01   1.08230587e-07   1.58656391e-07   7.18094526e-08
   5.63071545e-08   2.85506404e-16   2.24376360e-15   5.81563822e-16
   8.60860654e-16]
[2017-11-02 10:37:52,142] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97534156e-01   6.79000746e-04   9.27517714e-04   4.16155613e-04
   4.39333351e-04   3.05977949e-07   1.97360737e-06   5.43205488e-07
   8.95922426e-07]
[2017-11-02 10:37:58,995] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.00733493e-13   2.30390875e-13   5.07352515e-13
   5.55316427e-13   1.00875724e-25   6.18901218e-25   9.74622857e-26
   2.93618867e-26]
[2017-11-02 10:37:59,104] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.74309534e-13   2.30693421e-13   5.15467985e-13
   5.39793850e-13   1.23591750e-25   7.44876141e-25   1.20706639e-25
   3.62825480e-26]
[2017-11-02 10:37:59,971] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98228371e-01   4.91771789e-04   7.23803416e-04   3.00880201e-04
   2.53761158e-04   1.04887576e-07   7.19823561e-07   2.32518701e-07
   4.14699173e-07]
[2017-11-02 10:38:01,840] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.84721345e-14   3.16712184e-10   3.30456135e-10   1.07329250e-10
   2.44474940e-10   7.86149278e-02   6.17543399e-01   1.26041025e-01
   1.77800596e-01]
[2017-11-02 10:38:05,222] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999523e-01   5.86109543e-08   3.00527105e-08   3.06753911e-08
   5.98984187e-08   1.71894872e-08   1.59847076e-07   1.76186195e-08
   1.08744098e-08]
[2017-11-02 10:38:14,434] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.18864622e-05   7.27999895e-06   7.59684735e-06   2.62475919e-06
   6.45523505e-06   6.55880496e-02   7.12405622e-01   1.15054429e-01
   1.06896155e-01]
[2017-11-02 10:38:17,393] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   7.23621107e-10   2.55960309e-10   3.37894018e-10
   7.79894094e-10   1.35532634e-08   1.82740635e-07   1.31860780e-08
   3.36565309e-09]
[2017-11-02 10:38:18,635] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.16748580e-11   9.87872978e-12   1.53023427e-11
   3.84372291e-11   5.62647914e-11   7.24372506e-10   5.66334445e-11
   1.50697007e-11]
[2017-11-02 10:38:29,322] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.83783336e-11   5.93642193e-12   8.68131001e-12
   1.82330869e-11   3.81639734e-13   4.71217466e-12   3.78069375e-13
   1.13794485e-13]
[2017-11-02 10:38:33,330] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14524609  0.01269185  0.01305762  0.00541539  0.00725104  0.07106651
  0.48907223  0.11377556  0.14242373]
[2017-11-02 10:38:37,956] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.95860150e-11   2.49528766e-11   4.49267047e-11
   3.19181383e-11   1.60284409e-21   7.72531843e-21   1.04276779e-21
   3.00587029e-22]
[2017-11-02 10:38:45,103] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.88783781e-06   2.90714333e-08   1.35264884e-08   1.24573818e-08
   2.69096656e-08   1.07899323e-01   7.19705880e-01   1.09384641e-01
   6.30082190e-02]
[2017-11-02 10:38:45,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.75185135e-11   1.12385656e-11   2.09746300e-11
   2.23826374e-11   6.10658918e-22   2.79425569e-21   6.17480179e-22
   2.01952443e-22]
[2017-11-02 10:38:47,989] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.43095341e-12   1.86700291e-11   1.24875032e-11
   5.09087911e-12   7.49057591e-29   5.14173799e-28   1.52003395e-28
   3.24800381e-28]
[2017-11-02 10:38:53,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984622e-01   3.49718221e-06   6.23364031e-06   2.51931033e-06
   3.24989878e-06   2.28314828e-12   1.73930887e-11   3.41082089e-12
   4.65763105e-12]
[2017-11-02 10:38:54,314] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00431997  0.001267    0.00186732  0.00066395  0.00118908  0.07126535
  0.62739801  0.11051276  0.18151654]
[2017-11-02 10:38:58,254] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98333275e-01   1.01872763e-06   4.80684434e-07   4.53328596e-07
   1.01978515e-06   1.29385022e-04   1.31675031e-03   1.43803030e-04
   7.38384406e-05]
[2017-11-02 10:38:58,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.46683248e-03   7.93165896e-07   3.55571103e-07   3.03042839e-07
   7.70171710e-07   7.81452134e-02   7.75060654e-01   9.11326632e-02
   4.91923988e-02]
[2017-11-02 10:38:59,265] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   4.26848565e-08   2.32953408e-08   2.19133529e-08
   4.34020571e-08   4.89400831e-09   4.40962999e-08   5.53447954e-09
   3.17159587e-09]
[2017-11-02 10:39:04,139] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.12661311e-10   3.05703338e-08   3.24042055e-08   1.05822506e-08
   2.42785170e-08   7.26003647e-02   6.58695757e-01   1.23795487e-01
   1.44908369e-01]
[2017-11-02 10:39:08,224] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.91890128e-16   1.56458976e-16   4.09356280e-16
   4.94200050e-16   1.45930625e-28   1.44966952e-27   1.32778124e-28
   3.39838885e-29]
[2017-11-02 10:39:08,799] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.45858323e-15   1.19179981e-15   2.99271182e-15
   3.60538558e-15   4.03850682e-28   3.44861869e-27   3.59872505e-28
   7.99829136e-29]
[2017-11-02 10:39:16,357] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.15472916e-16   8.10015821e-17   2.06176753e-16
   2.78799148e-16   2.30809723e-27   2.25152859e-26   2.27064983e-27
   6.38358773e-28]
[2017-11-02 10:39:28,591] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.43636058e-10   6.40349884e-10   1.05408449e-09
   8.67913408e-10   2.23035245e-20   6.99222493e-20   1.09953161e-20
   2.83185646e-21]
[2017-11-02 10:39:30,176] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.32709893e-10   1.47366952e-09   1.15814469e-09
   3.94267424e-10   2.25613695e-26   1.20662451e-25   3.34679169e-26
   5.14971265e-26]
[2017-11-02 10:39:31,138] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99973297e-01   6.64553090e-06   1.05946028e-05   4.84301927e-06
   4.67728432e-06   1.32124899e-12   9.14278115e-12   1.95017808e-12
   3.39758863e-12]
[2017-11-02 10:39:32,538] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.27505325e-13   7.88351657e-14   1.72897422e-13
   1.80835883e-13   1.73745875e-26   1.11203565e-25   1.56368687e-26
   5.05783678e-27]
[2017-11-02 10:39:34,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.94120458e-12   4.21816922e-12   3.34949776e-12
   1.23896097e-12   2.49486003e-33   1.89856238e-32   5.96207135e-33
   9.02555730e-33]
[2017-11-02 10:39:34,636] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.94274544e-12   4.22396623e-12   3.35451025e-12
   1.24013354e-12   2.48429931e-33   1.89104524e-32   5.93447919e-33
   8.98680419e-33]
[2017-11-02 10:39:36,147] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.57106341e-14   2.68075848e-14   5.93283899e-14
   5.34272571e-14   6.31172021e-28   4.09558594e-27   7.54607567e-28
   3.24463536e-28]
[2017-11-02 10:39:36,732] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.60403036e-14   4.16321903e-15   1.00638373e-14
   1.19836061e-14   5.18333037e-28   3.69159478e-27   5.17763877e-28
   1.31251235e-28]
[2017-11-02 10:39:37,583] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.38909149e-02   1.13407765e-07   1.36001281e-08   1.67468315e-08
   6.15121394e-08   5.33373356e-02   7.58096993e-01   8.29844400e-02
   2.16901079e-02]
[2017-11-02 10:39:37,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.52731035e-14   3.60328358e-14   2.36157732e-14
   8.98188232e-15   0.00000000e+00   1.10366121e-37   2.27586621e-38
   3.41418692e-38]
[2017-11-02 10:39:39,010] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.41218629e-14   4.17161312e-15   9.93748710e-15
   1.17636630e-14   2.20731370e-27   1.51086693e-26   2.47743616e-27
   7.94838318e-28]
[2017-11-02 10:39:39,421] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.21569142e-19   3.35234750e-20   1.07013125e-19
   1.33668600e-19   3.97685007e-36   6.13000445e-35   4.41893108e-36
   9.86177359e-37]
[2017-11-02 10:39:39,884] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.60913647e-15   2.00730512e-14   1.51510088e-14
   6.29183315e-15   0.00000000e+00   3.05075932e-38   0.00000000e+00
   0.00000000e+00]
[2017-11-02 10:39:46,075] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.66767351e-08   1.98679656e-10   7.26542784e-11   6.06901057e-11
   1.90555918e-10   6.69404864e-02   8.15253198e-01   8.26856941e-02
   3.51204760e-02]
[2017-11-02 10:39:46,186] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   9.74478542e-09   4.32369518e-09   4.55726479e-09
   1.00228705e-08   1.64063341e-08   1.94348374e-07   1.79672170e-08
   7.76590259e-09]
[2017-11-02 10:39:56,690] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.60099059e-12   2.12555085e-09   2.46884446e-09   7.53828666e-10
   1.75254378e-09   7.56320432e-02   6.40919566e-01   1.26690760e-01
   1.56757623e-01]
[2017-11-02 10:40:00,575] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.60698867e-11   2.55844061e-11   4.27322136e-11
   2.77021999e-11   4.15255749e-24   1.97883865e-23   2.83690139e-24
   1.16803429e-24]
[2017-11-02 10:40:01,749] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.77189064e-01   5.56551432e-03   8.69427528e-03   3.67073016e-03
   3.51162557e-03   1.23998252e-04   7.81376613e-04   1.77879672e-04
   2.85624817e-04]
[2017-11-02 10:40:03,196] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.49080474e-19   1.87148176e-13   1.66229687e-13   4.85427060e-14
   1.25561020e-13   7.58358613e-02   6.16877913e-01   1.37707099e-01
   1.69579163e-01]
[2017-11-02 10:40:05,427] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.64935664e-15   4.69816512e-16   1.19118169e-15
   1.25545381e-15   4.81275411e-31   4.33774154e-30   4.47709029e-31
   1.10549331e-31]
[2017-11-02 10:40:05,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.53021665e-11   1.51827467e-10   1.10700324e-10
   4.02941638e-11   5.61960659e-29   3.33712502e-28   1.22406823e-28
   1.96221374e-28]
[2017-11-02 10:40:08,363] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.28284115e-15   8.37640728e-16   2.11336097e-15
   2.43915377e-15   7.62739126e-30   6.23078661e-29   7.43117436e-30
   1.67505538e-30]
[2017-11-02 10:40:08,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.07828442e-11   5.05139923e-11   3.92264485e-11
   1.46860614e-11   3.59502848e-31   2.45061608e-30   8.51185522e-31
   1.33058889e-30]
[2017-11-02 10:40:09,817] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.04804765e-16   1.85731614e-16   4.36396271e-16
   4.76342054e-16   5.09850691e-31   4.68435214e-30   5.38246732e-31
   2.13453905e-31]
[2017-11-02 10:40:11,339] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91724889e-08   6.03845422e-07   8.80280652e-07   2.90595978e-07
   6.64977904e-07   6.55997396e-02   6.74447656e-01   1.05759948e-01
   1.54190063e-01]
[2017-11-02 10:40:11,609] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.41680276e-08   1.60907220e-07   2.32147869e-07   7.54041878e-08
   1.79007159e-07   6.54570386e-02   6.77348554e-01   1.06839024e-01
   1.50354832e-01]
[2017-11-02 10:40:14,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.61775140e-15   4.19831907e-16   1.00387179e-15
   1.18711720e-15   1.26999721e-28   1.21364921e-27   1.22268686e-28
   3.71773512e-29]
[2017-11-02 10:40:19,465] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.81183403e-02   4.98571524e-07   1.61704477e-07   1.81233133e-07
   4.60540747e-07   8.60572979e-02   7.71810412e-01   8.35165754e-02
   3.04960981e-02]
[2017-11-02 10:40:20,958] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99690056e-01   8.09090416e-05   1.21811492e-04   4.62866628e-05
   6.09765048e-05   5.00866770e-09   3.80364256e-08   8.21817459e-09
   1.05594324e-08]
[2017-11-02 10:40:22,948] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99882221e-01   2.85636779e-05   4.43646786e-05   1.82155618e-05
   2.66421575e-05   1.12928600e-09   9.95433069e-09   1.71409098e-09
   2.42619835e-09]
[2017-11-02 10:40:26,850] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.78062546  0.01994445  0.03191591  0.0118012   0.0182474   0.0100529
  0.08500833  0.01519425  0.02721012]
[2017-11-02 10:40:29,667] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99540210e-01   1.08881948e-04   1.80378163e-04   8.98403378e-05
   7.99739573e-05   7.24145153e-08   5.36399227e-07   9.68189369e-08
   1.47248784e-07]
[2017-11-02 10:40:32,927] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.87415033e-17   3.38773085e-12   2.78616128e-12   9.58181451e-13
   2.08393806e-12   8.42187852e-02   5.88783801e-01   1.46180198e-01
   1.80817187e-01]
[2017-11-02 10:40:33,789] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.46133466e-09   4.63228256e-09   5.41651346e-09
   7.09601178e-09   4.02391336e-13   2.44792901e-12   3.53875810e-13
   2.53599225e-13]
[2017-11-02 10:40:33,929] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.27393495e-12   1.20955893e-12   1.64180746e-12
   2.03486165e-12   5.33535453e-21   3.67072641e-20   4.77951663e-21
   2.81385175e-21]
[2017-11-02 10:40:34,080] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.71357045e-13   2.22975636e-13   3.58714360e-13
   5.68520057e-13   8.13119705e-20   6.79115283e-19   8.20498092e-20
   3.62320359e-20]
[2017-11-02 10:40:36,871] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99991655e-01   1.99514329e-06   3.29465934e-06   1.51819552e-06
   1.56629267e-06   8.59850385e-14   5.89361079e-13   1.19849294e-13
   1.93835345e-13]
[2017-11-02 10:40:37,624] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.82877123  0.01192906  0.0168083   0.00632813  0.01075729  0.00916113
  0.08068869  0.01429291  0.02126325]
[2017-11-02 10:40:38,937] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.69282944e-16   6.82060046e-17   1.80501345e-16
   2.15979081e-16   1.33079632e-31   1.37735852e-30   1.45900913e-31
   4.69611991e-32]
[2017-11-02 10:40:39,252] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.17186485e-13   7.95044098e-14   1.76609080e-13
   1.86553450e-13   4.15272520e-27   2.60600693e-26   3.97661046e-27
   1.17473070e-27]
[2017-11-02 10:40:40,001] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.77050907e-12   1.55371549e-11   1.07363580e-11
   4.17577474e-12   6.85576752e-31   5.05325837e-30   1.39742721e-30
   2.81281937e-30]
[2017-11-02 10:40:40,610] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99894738e-01   3.10779651e-05   3.59982987e-05   2.04137959e-05
   1.77932779e-05   8.84290363e-10   4.54179228e-09   1.49088364e-09
   2.12700701e-09]
[2017-11-02 10:40:41,565] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.05072328e-16   4.82620911e-17   1.33459398e-16
   1.56163229e-16   2.56643830e-32   2.67910985e-31   2.49378599e-32
   5.08067834e-33]
[2017-11-02 10:40:43,865] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.60910735e-15   2.38563399e-15   6.02463238e-15
   6.94320318e-15   1.26477148e-27   9.89974214e-27   1.16370523e-27
   3.21075127e-28]
[2017-11-02 10:40:46,544] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.85796318e-16   1.19500877e-16   3.20308818e-16
   3.82798303e-16   3.01044799e-30   2.78989881e-29   3.19523063e-30
   8.95553380e-31]
[2017-11-02 10:40:46,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.40677975e-18   5.92624141e-19   1.84613933e-18
   2.38879008e-18   4.07983783e-34   5.32028229e-33   4.24546820e-34
   7.64756249e-35]
[2017-11-02 10:40:48,460] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.25302023e-14   1.17045774e-14   2.00008975e-14
   1.72050586e-14   3.38803337e-29   2.59594340e-28   3.94412517e-29
   2.28575189e-29]
[2017-11-02 10:40:50,282] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.45652700e-11   5.14019383e-11   3.87233301e-11
   1.57323009e-11   1.96233995e-29   1.27902079e-28   4.10775489e-29
   7.46684002e-29]
[2017-11-02 10:40:51,202] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.57553466e-11   2.52169830e-11   4.45539612e-11
   2.86689197e-11   5.27213887e-25   2.42586403e-24   3.53544433e-25
   1.56870032e-25]
[2017-11-02 10:40:51,275] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.06544702e-11   3.70629950e-11   6.34458111e-11
   4.01223776e-11   1.51829850e-24   6.78153112e-24   1.00154540e-24
   4.56154233e-25]
[2017-11-02 10:40:51,562] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.51489002e-11   4.94855892e-11   8.50609860e-11
   5.38227587e-11   1.16846215e-24   5.16904500e-24   7.53863486e-25
   3.52553204e-25]
[2017-11-02 10:40:56,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99886394e-01   2.63664533e-05   4.60294978e-05   1.80413699e-05
   2.31302565e-05   6.07758177e-10   4.89076646e-09   9.20182541e-10
   1.37517464e-09]
[2017-11-02 10:40:57,427] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.59698391  0.0126205   0.01978588  0.00721579  0.01259742  0.02462994
  0.22785851  0.03848554  0.0598226 ]
[2017-11-02 10:40:57,791] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94900823e-01   1.15697307e-03   1.76223612e-03   6.83812308e-04
   1.11680035e-03   2.73392434e-05   2.49359204e-04   4.19233911e-05
   6.07807597e-05]
[2017-11-02 10:40:58,397] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.92990335e-09   3.87006294e-09   1.85732985e-09
   2.01463624e-09   1.83833686e-20   1.65537917e-19   2.61200631e-20
   3.95944444e-20]
[2017-11-02 10:40:59,634] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.49281037e-17   3.12604602e-18   8.37288429e-18
   9.13874269e-18   2.61665748e-32   3.42099137e-31   2.64863328e-32
   8.37202211e-33]
[2017-11-02 10:40:59,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.04654112e-17   4.49647771e-18   1.26615858e-17
   1.35392013e-17   2.76906906e-33   3.55326552e-32   2.70393327e-33
   7.06354050e-34]
[2017-11-02 10:41:00,581] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.49965434e-12   7.46801492e-12   5.08622051e-12
   2.05564602e-12   4.78405277e-31   3.64750894e-30   9.66464184e-31
   1.88153463e-30]
[2017-11-02 10:41:03,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.78804888e-16   2.13932398e-16   5.55779715e-16
   6.22101919e-16   1.75190502e-29   1.73238747e-28   1.62316714e-29
   4.52570441e-30]
[2017-11-02 10:41:04,687] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.06822623e-11   7.66003511e-11   5.73482581e-11
   2.18088325e-11   1.02628716e-30   6.78187266e-30   2.15910006e-30
   3.12893801e-30]
[2017-11-02 10:41:04,898] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.03355128e-11   4.82419937e-11   3.44307326e-11
   1.30385555e-11   3.31957498e-30   2.23621200e-29   6.70040733e-30
   1.14528667e-29]
[2017-11-02 10:41:05,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.81154453e-10   3.05541481e-10   1.84930460e-10
   1.33864655e-10   2.14795051e-24   1.32670627e-23   2.74987090e-24
   4.34480960e-24]
[2017-11-02 10:41:07,468] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.34602039e-15   1.69171940e-15   4.14306684e-15
   5.15156883e-15   3.50240375e-28   2.77866432e-27   3.26350346e-28
   6.46181395e-29]
[2017-11-02 10:41:08,137] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.87606915e-12   2.14347116e-11   1.67535916e-11
   6.55859872e-12   2.29458070e-32   1.69134430e-31   5.02745004e-32
   7.26373283e-32]
[2017-11-02 10:41:08,518] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -19458.2734
[2017-11-02 10:41:08,518] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 250000, evaluation results [250000.0, -19458.27338010617]
[2017-11-02 10:41:09,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   3.39607669e-17   8.30288297e-17   7.82463162e-17
   5.33756389e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:09,220] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 72.0, 1.0, 213.3333333333334, 0.0, 0.0, -3.5, 15.58978534464604, 18.0, 21.53928805392152, 21.5, 0.0, 0.0], 
actual action is [-3.666666666666667, 18], 
sim time next is 4677900.0000, 
raw observation next is [1.166666666666667, 74.5, 0.8749999999999999, 186.6666666666666, 0.0, 0.0, -3.666666666666667, 17.12736973852981, 18.0, 21.51754772940013, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.3632478632478633, 0.745, 0.07954545454545453, 0.5185185185185184, 0.0, 0.0, 0.4388888888888889, 0.1712736973852981, 0.0, 0.5025068184857326, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:41:12,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-32.81018448]
 [-34.79334641]
 [-33.36060715]
 [-33.24949646]
 [-33.59140778]], R is [[-33.10428619]
 [-33.77324295]
 [-34.43551254]
 [-34.10598755]
 [-33.77925873]].
[2017-11-02 10:41:12,751] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-48.21146774]
 [-45.64338303]
 [-47.88190842]
 [-48.63516998]
 [-48.43313599]], R is [[-47.53513718]
 [-47.13495636]
 [-47.3481102 ]
 [-46.93582153]
 [-46.53562164]].
[2017-11-02 10:41:14,599] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15500, global step 251545: loss 4.0550
[2017-11-02 10:41:14,714] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   1.08405384e-15   1.67338855e-15   1.79123413e-15
   9.72362483e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:14,742] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 78.16666666666667, 3.6, 331.6666666666666, 0.0, 0.0, -8.0, 18.29825208568497, 18.0, 21.45181506516306, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 4748100.0000, 
raw observation next is [-3.0, 77.58333333333333, 3.6, 330.8333333333334, 0.0, 0.0, -8.0, 20.56819680322801, 18.0, 21.31244214656013, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2564102564102564, 0.7758333333333333, 0.32727272727272727, 0.9189814814814817, 0.0, 0.0, 0.36666666666666664, 0.2056819680322801, 0.0, 0.47320602093716146, 0.5, 0.0, 0.0], 
reward next is -0.0268. 
=============================================
[2017-11-02 10:41:15,072] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99981165e-01   3.31914771e-06   7.45656780e-06   2.88795286e-06
   4.99420048e-06   1.62669878e-09   2.56689141e-08   6.28604502e-10
   1.05740838e-07], sum to 1.0000
[2017-11-02 10:41:15,120] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 3.1, 325.0, 0.0, 0.0, -1.0, 18.57707281302084, 25.0, 20.68441788599006, 21.5, 0.0, 46.49179453357443], 
actual action is [-1.0, 20.0], 
sim time next is 4764900.0000, 
raw observation next is [-6.0, 92.0, 3.183333333333334, 327.5, 0.0, 0.0, -1.0, 18.3354158140849, 20.0, 20.70847586850539, 21.5, 0.0, 45.97411364677654], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.2893939393939395, 0.9097222222222222, 0.0, 0.0, 0.48333333333333334, 0.183354158140849, 0.2857142857142857, 0.38692512407219837, 0.5, 0.0, 0.5408719252561945], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:19,886] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16000, global step 252838: loss 18.2121
[2017-11-02 10:41:20,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.74954981e-19   5.76728999e-20   1.73149026e-19
   1.02493526e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:20,268] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 72.66666666666667, 4.633333333333333, 333.3333333333334, 185.8333333333333, 5.0, -3.25, 13.17227446765718, 18.0, 22.50631297423135, 22.7, 1.0, 0.0], 
actual action is [-3.333333333333333, 18], 
sim time next is 4717500.0000, 
raw observation next is [1.583333333333333, 72.58333333333333, 4.766666666666666, 334.1666666666666, 190.9166666666667, 5.5, -3.333333333333333, 13.32738112438291, 18.0, 22.57041503363374, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3739316239316239, 0.7258333333333333, 0.43333333333333324, 0.9282407407407405, 0.5050705467372135, 0.0055, 0.4444444444444445, 0.1332738112438291, 0.0, 0.6529164333762486, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:41:21,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.29945374e-16   4.22273320e-16   6.22405739e-16
   3.33292165e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.19973653e-38], sum to 1.0000
[2017-11-02 10:41:21,680] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 3.1, 325.0, 0.0, 0.0, -1.0, 18.87469199407235, 25.0, 20.55381651569731, 21.5, 0.0, 41.05366515035939], 
actual action is [-1.0, 20.0], 
sim time next is 4764900.0000, 
raw observation next is [-6.0, 92.0, 3.183333333333334, 327.5, 0.0, 0.0, -1.0, 18.63195421803354, 20.0, 20.64323750776511, 21.5, 0.0, 42.04889871333257], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.2893939393939395, 0.9097222222222222, 0.0, 0.0, 0.48333333333333334, 0.1863195421803354, 0.2857142857142857, 0.3776053582521587, 0.5, 0.0, 0.49469292603920667], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:25,064] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16000, global step 253967: loss -55.0230
[2017-11-02 10:41:28,034] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16000, global step 254614: loss -18.6516
[2017-11-02 10:41:28,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   6.21342977e-16   3.37509172e-16   8.07865403e-16
   3.55915489e-16   9.83405947e-35   3.60913500e-34   5.81316682e-35
   2.17419692e-33], sum to 1.0000
[2017-11-02 10:41:28,354] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 3.6, 332.5, 134.25, 1.5, -4.0, 16.20294478694687, 18.0, 22.0979301218842, 22.7, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 4710000.0000, 
raw observation next is [1.0, 86.0, 3.766666666666667, 333.3333333333334, 125.5, 0.9999999999999998, -4.0, 16.91395039437538, 18.0, 21.87544055403739, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.358974358974359, 0.86, 0.34242424242424246, 0.9259259259259262, 0.33201058201058203, 0.0009999999999999998, 0.43333333333333335, 0.1691395039437538, 0.0, 0.5536343648624842, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:30,772] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16000, global step 255254: loss 89.8877
[2017-11-02 10:41:30,886] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16000, global step 255281: loss 3.2323
[2017-11-02 10:41:31,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.26887514e-13   4.62040614e-11   4.43662641e-11   1.72346633e-11
   2.01789020e-11   4.16161399e-03   1.56035302e-02   7.12900748e-03
   9.73105788e-01], sum to 1.0000
[2017-11-02 10:41:31,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.5, 84.5, 3.35, 355.0, 124.0, 419.0, -0.583333333333333, 13.20658131080951, 25.0, 21.6956474079579, 22.7, 1.0, 56.40129194956656], 
actual action is [-0.5, 25], 
sim time next is 4782900.0000, 
raw observation next is [-5.416666666666667, 83.25, 3.391666666666667, 355.8333333333333, 128.1666666666667, 419.1666666666667, -0.5, 12.54777643214309, 25.0, 21.83221482788007, 22.7, 1.0, 62.72932091736577], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.19444444444444445, 0.8325, 0.30833333333333335, 0.9884259259259258, 0.33906525573192253, 0.4191666666666667, 0.49166666666666664, 0.1254777643214309, 1.0, 0.5474592611257242, 0.6714285714285714, 1.0, 0.7379920107925384], 
reward next is -0.6767. 
=============================================
[2017-11-02 10:41:32,513] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16000, global step 255595: loss 190.7143
[2017-11-02 10:41:36,925] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16000, global step 256388: loss 0.6549
[2017-11-02 10:41:37,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16000, global step 256416: loss 62.2842
[2017-11-02 10:41:37,608] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16000, global step 256556: loss -105.7261
[2017-11-02 10:41:38,435] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   4.27784461e-15   1.92582321e-15   3.80293611e-15
   1.98647035e-15   3.94197235e-30   8.96726373e-30   1.50338985e-30
   7.23735434e-30], sum to 1.0000
[2017-11-02 10:41:38,457] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 5.0, 346.6666666666667, 139.5, 739.5, -2.0, 13.03033908691043, 18.0, 22.90683902435446, 22.7, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4805100.0000, 
raw observation next is [3.0, 37.0, 5.175000000000001, 345.0, 135.25, 738.25, -2.0, 13.41010675606702, 18.0, 22.85543923701719, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.41025641025641024, 0.37, 0.4704545454545455, 0.9583333333333334, 0.3578042328042328, 0.73825, 0.4666666666666667, 0.1341010675606702, 0.0, 0.6936341767167414, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 10:41:38,589] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  8.60306609e-05   3.52588074e-08   1.49231418e-08   1.34162654e-08
   1.94337684e-08   2.17198297e-01   2.37804294e-01   7.14323074e-02
   4.73479033e-01], sum to 1.0000
[2017-11-02 10:41:38,605] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16000, global step 256851: loss -8.7268
[2017-11-02 10:41:38,628] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.25, 45.25, 3.1, 360.0, 129.75, 811.75, 3.5, 14.6018687518582, 19.0, 22.15652760199194, 22.7, 1.0, 54.29167341173808], 
actual action is [3.75, 21.0], 
sim time next is 4792800.0000, 
raw observation next is [-1.0, 45.0, 3.1, 360.0, 127.1666666666667, 820.8333333333334, 3.75, 14.08808651125764, 21.0, 22.18300088066937, 22.7, 1.0, 28.85002540160166], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.3076923076923077, 0.45, 0.2818181818181818, 1.0, 0.33641975308641986, 0.8208333333333334, 0.5625, 0.1408808651125764, 0.42857142857142855, 0.5975715543813384, 0.6714285714285714, 1.0, 0.3394120635482548], 
reward next is -0.3196. 
=============================================
[2017-11-02 10:41:39,008] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16000, global step 256982: loss -0.1890
[2017-11-02 10:41:39,336] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0490889
  0.0752961   0.05124728  0.82436776], sum to 1.0000
[2017-11-02 10:41:39,405] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 71.0, 2.6, 315.0, 0.0, 0.0, 1.0, 17.65529924859822, 25.0, 20.70826601500326, 21.5, 0.0, 58.10333265461524], 
actual action is [1.0, 25], 
sim time next is 4758600.0000, 
raw observation next is [-4.0, 71.0, 2.6, 313.3333333333334, 0.0, 0.0, 1.0, 16.33545560873921, 25.0, 20.83527399036212, 21.5, 0.0, 51.05090380839776], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.23076923076923078, 0.71, 0.23636363636363636, 0.8703703703703707, 0.0, 0.0, 0.5166666666666667, 0.1633545560873921, 1.0, 0.4050391414803026, 0.5, 0.0, 0.6005988683340914], 
reward next is -0.6355. 
=============================================
[2017-11-02 10:41:39,615] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16000, global step 257144: loss 72.7707
[2017-11-02 10:41:39,939] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16000, global step 257234: loss 9.3336
[2017-11-02 10:41:40,576] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16000, global step 257435: loss -4.9472
[2017-11-02 10:41:41,277] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16000, global step 257636: loss 0.5874
[2017-11-02 10:41:41,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.80082242e-11   4.81375773e-11   4.83038679e-11
   1.90214216e-11   6.33294395e-28   1.87326578e-27   2.33616747e-28
   1.29729601e-27], sum to 1.0000
[2017-11-02 10:41:41,937] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 3.516666666666667, 21.66666666666666, 0.0, 0.0, 4.0, 15.74511831458977, 19.0, 21.87078761166754, 21.5, 0.0, 45.04940587997285], 
actual action is [-6.0, 18], 
sim time next is 4831800.0000, 
raw observation next is [-1.0, 55.0, 3.433333333333334, 23.33333333333334, 0.0, 0.0, -6.0, 16.93857862972861, 18.0, 21.8938330729217, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.3076923076923077, 0.55, 0.3121212121212122, 0.06481481481481483, 0.0, 0.0, 0.4, 0.1693857862972861, 0.0, 0.5562618675602431, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:41:48,803] A3C_AGENT_WORKER-Thread-9 INFO:Local step 16000, global step 259699: loss 17.1572
[2017-11-02 10:41:49,311] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.65307465e-13   3.35841381e-13   3.65700065e-13
   1.02538420e-13   4.17098411e-34   2.95748024e-33   2.74602024e-34
   4.14736154e-33], sum to 1.0000
[2017-11-02 10:41:49,327] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 61.66666666666667, 2.266666666666667, 26.66666666666667, 0.0, 0.0, -8.25, 25.74279246093091, 18.0, 20.09029482259164, 21.0, 0.0, 0.0], 
actual action is [-8.333333333333332, 18], 
sim time next is 4861500.0000, 
raw observation next is [-3.416666666666667, 62.08333333333333, 2.308333333333334, 25.83333333333333, 0.0, 0.0, -8.333333333333332, 28.04180546768505, 18.0, 20.07290559932125, 21.0, 0.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2457264957264957, 0.6208333333333332, 0.20984848484848492, 0.07175925925925924, 0.0, 0.0, 0.3611111111111111, 0.2804180546768505, 0.0, 0.296129371331607, 0.42857142857142855, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:49,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99999046e-01   1.80374656e-07   4.21861074e-07   2.35763181e-07
   1.48154967e-07   6.82071207e-13   4.59178875e-12   5.40799068e-13
   1.99866460e-11], sum to 1.0000
[2017-11-02 10:41:49,497] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 68.0, 2.35, 35.0, 0.0, 0.0, 1.0, 23.45092666115535, 25.0, 19.96974989879535, 21.0, 0.0, 57.09545857070881], 
actual action is [1.0, 20.0], 
sim time next is 4865700.0000, 
raw observation next is [-4.0, 68.5, 2.308333333333334, 37.5, 11.75000000000001, 26.08333333333335, 1.0, 22.03342424751334, 20.0, 20.13190337271288, 21.0, 0.0, 41.02138509482258], 
processed observation next is [1.0, 0.30434782608695654, 0.23076923076923078, 0.685, 0.20984848484848492, 0.10416666666666667, 0.031084656084656114, 0.02608333333333335, 0.5166666666666667, 0.22033424247513342, 0.2857142857142857, 0.30455762467326863, 0.42857142857142855, 0.0, 0.48260453052732444], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:49,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   1.10285127e-18   1.67550024e-18   2.39462935e-18
   4.03001490e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.52036259e-38], sum to 1.0000
[2017-11-02 10:41:49,769] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 5.175000000000001, 345.0, 135.25, 738.25, -2.0, 18.35784069235899, 18.0, 22.04776892220992, 22.7, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4805400.0000, 
raw observation next is [3.0, 37.0, 5.35, 343.3333333333334, 131.0, 737.0, -2.0, 18.42805772441384, 18.0, 22.03181900957651, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.41025641025641024, 0.37, 0.48636363636363633, 0.9537037037037039, 0.34656084656084657, 0.737, 0.4666666666666667, 0.1842805772441384, 0.0, 0.5759741442252155, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:50,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16500, global step 260206: loss 217.6163
[2017-11-02 10:41:55,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.62662886e-18   7.54306331e-18   9.68371161e-18
   1.20035301e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:55,127] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 62.5, 2.6, 75.0, 207.0, 179.0, -7.583333333333333, 22.62023256882917, 18.0, 21.24466979269362, 22.2, 1.0, 0.0], 
actual action is [-7.5, 18], 
sim time next is 4872900.0000, 
raw observation next is [-2.416666666666667, 62.08333333333333, 2.683333333333334, 75.83333333333334, 214.75, 177.75, -7.5, 23.76730918002605, 18.0, 21.23124208563598, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.27136752136752135, 0.6208333333333332, 0.243939393939394, 0.21064814814814817, 0.5681216931216931, 0.17775, 0.375, 0.2376730918002605, 0.0, 0.46160601223371145, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:55,201] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16500, global step 261272: loss -327.2401
[2017-11-02 10:41:56,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   7.46084884e-17   5.74578182e-16   7.57161163e-16
   8.09175802e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   3.45495938e-38], sum to 1.0000
[2017-11-02 10:41:56,781] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.75, 44.75, 2.475, 57.5, 50.25, 219.5, -2.166666666666667, 23.44474259883561, 18.0, 21.83068276957082, 22.2, 1.0, 0.0], 
actual action is [-2.25, 18], 
sim time next is 4900800.0000, 
raw observation next is [2.666666666666667, 44.66666666666667, 2.433333333333334, 56.66666666666667, 44.5, 208.6666666666667, -2.25, 23.75479819430605, 18.0, 21.79111741742513, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4017094017094017, 0.4466666666666667, 0.22121212121212128, 0.1574074074074074, 0.11772486772486772, 0.20866666666666672, 0.4625, 0.2375479819430605, 0.0, 0.5415882024893044, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:57,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.27306366e-19   4.42016627e-19   8.10268388e-19
   1.14116687e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:57,721] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 44.16666666666667, 3.433333333333334, 70.0, 248.0, 378.6666666666667, -2.916666666666667, 22.04902520211808, 18.0, 21.84124242777696, 22.2, 1.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 4889700.0000, 
raw observation next is [2.25, 44.25, 3.35, 70.0, 245.0, 377.5, -2.833333333333333, 22.36763887610409, 18.0, 21.80410523219345, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.391025641025641, 0.4425, 0.30454545454545456, 0.19444444444444445, 0.6481481481481481, 0.3775, 0.4527777777777778, 0.22367638876104087, 0.0, 0.5434436045990643, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:58,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16500, global step 262210: loss 211.9012
[2017-11-02 10:41:58,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16500, global step 262329: loss 119.1459
[2017-11-02 10:41:59,478] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16500, global step 262634: loss -80.8140
[2017-11-02 10:42:01,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.69491767e-14   9.17383032e-14   8.56008786e-14
   3.49967722e-14   2.07823146e-31   4.08552842e-31   7.56947009e-32
   1.12478123e-29], sum to 1.0000
[2017-11-02 10:42:01,114] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333333, 45.33333333333334, 1.7, 63.33333333333334, 0.0, 0.0, 4.75, 27.85111058607846, 23.0, 20.2449593978358, 21.0, 0.0, 92.36980529433565], 
actual action is [-5.333333333333333, 18.0], 
sim time next is 4929900.0000, 
raw observation next is [-0.4166666666666667, 45.91666666666666, 1.75, 61.66666666666666, 0.0, 0.0, -5.333333333333333, 28.86373401425579, 18.0, 20.4413125849644, 21.0, 0.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.32264957264957267, 0.45916666666666656, 0.1590909090909091, 0.17129629629629628, 0.0, 0.0, 0.41111111111111115, 0.28863734014255793, 0.0, 0.34875894070920005, 0.42857142857142855, 0.0, 0.0], 
reward next is -0.0798. 
=============================================
[2017-11-02 10:42:01,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   3.95759336e-17   1.19910021e-16   1.58825877e-16
   2.92260215e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   5.23325169e-38], sum to 1.0000
[2017-11-02 10:42:01,596] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 2.6, 60.0, 79.00000000000001, 273.6666666666667, -2.0, 23.40424541932743, 18.0, 21.88163717842523, 22.2, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4899300.0000, 
raw observation next is [3.0, 45.0, 2.6, 60.0, 73.25, 262.8333333333334, -2.0, 23.6884651610672, 18.0, 21.84592968359832, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.41025641025641024, 0.45, 0.23636363636363636, 0.16666666666666666, 0.19378306878306878, 0.2628333333333334, 0.4666666666666667, 0.236884651610672, 0.0, 0.5494185262283315, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:02,077] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16500, global step 263426: loss -94.0540
[2017-11-02 10:42:04,485] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16500, global step 264181: loss -10.5037
[2017-11-02 10:42:04,880] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16500, global step 264307: loss -113.4729
[2017-11-02 10:42:05,996] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16500, global step 264630: loss -57.0101
[2017-11-02 10:42:06,206] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16500, global step 264687: loss 3.0326
[2017-11-02 10:42:06,696] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16500, global step 264814: loss 67.8316
[2017-11-02 10:42:07,216] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.75505638e-12   7.71703368e-10   1.86181481e-09   5.74269354e-10
   9.20765519e-10   5.23969997e-04   2.01989268e-03   8.06503987e-04
   9.96649683e-01], sum to 1.0000
[2017-11-02 10:42:07,283] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.416666666666667, 47.66666666666666, 2.391666666666667, 15.83333333333333, 0.0, 0.0, -7.333333333333333, 25.69462597870145, 18.0, 20.83495595428035, 21.0, 0.0, 0.0], 
actual action is [2.583333333333333, 23.0], 
sim time next is 4944600.0000, 
raw observation next is [-2.5, 48.0, 2.35, 15.0, 0.0, 0.0, 2.583333333333333, 23.59218746145441, 23.0, 20.69572049694522, 21.0, 0.0, 68.2376101004262], 
processed observation next is [0.0, 0.21739130434782608, 0.2692307692307692, 0.48, 0.21363636363636365, 0.041666666666666664, 0.0, 0.0, 0.5430555555555556, 0.2359218746145441, 0.7142857142857143, 0.3851029281350315, 0.42857142857142855, 0.0, 0.8027954129461905], 
reward next is -0.7660. 
=============================================
[2017-11-02 10:42:08,431] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16500, global step 265252: loss -38.5576
[2017-11-02 10:42:08,721] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16500, global step 265349: loss 0.0344
[2017-11-02 10:42:09,650] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16500, global step 265630: loss -113.5760
[2017-11-02 10:42:11,183] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16500, global step 266142: loss -118.6126
[2017-11-02 10:42:12,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99983191e-01   3.38678865e-06   5.30739408e-06   3.23120321e-06
   4.73708951e-06   2.47357853e-13   4.54530456e-13   1.83652518e-13
   2.08791213e-11], sum to 1.0000
[2017-11-02 10:42:12,187] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.833333333333333, 63.41666666666666, 0.0, 0.0, 0.0, 0.0, -7.666666666666667, 25.52712664126232, 18.0, 20.08602226956767, 21.0, 0.0, 0.0], 
actual action is [-7.833333333333333, 18], 
sim time next is 5036400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 0.0, 0.0, -7.833333333333333, 27.55576059669545, 18.0, 20.05132064492007, 21.0, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.65, 0.0, 0.0, 0.0, 0.0, 0.36944444444444446, 0.2755576059669545, 0.0, 0.2930458064171531, 0.42857142857142855, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:14,626] A3C_AGENT_WORKER-Thread-16 INFO:Local step 17000, global step 267396: loss 21.6701
[2017-11-02 10:42:15,959] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-46.83808136]
 [-46.53705978]
 [-46.94546509]
 [-46.70332336]
 [-46.15302658]], R is [[-46.39778137]
 [-46.93380356]
 [-47.46446609]
 [-47.98982239]
 [-48.50992584]].
[2017-11-02 10:42:16,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   4.91709659e-11   1.70683936e-11   3.47866597e-11
   4.12157392e-11   1.01896756e-25   1.22230176e-25   4.98062154e-26
   8.79773180e-26], sum to 1.0000
[2017-11-02 10:42:16,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99985933e-01   3.28921556e-06   3.18150501e-06   2.97600536e-06
   4.47351613e-06   9.90267313e-10   6.43259224e-10   1.82433457e-10
   9.03438879e-10], sum to 1.0000
[2017-11-02 10:42:16,326] A3C_AGENT_WORKER-Thread-9 INFO:Local step 16500, global step 268074: loss 5.9250
[2017-11-02 10:42:16,336] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 1.5, 360.0, 0.0, 0.0, -4.0, 20.33333295934334, 18.0, 21.27841569391629, 21.0, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 5018700.0000, 
raw observation next is [0.8333333333333333, 41.25, 1.5, 357.5, 0.0, 0.0, -4.0, 21.73025350889932, 18.0, 21.16726086928023, 21.0, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.3547008547008547, 0.4125, 0.13636363636363635, 0.9930555555555556, 0.0, 0.0, 0.43333333333333335, 0.2173025350889932, 0.0, 0.4524658384686044, 0.42857142857142855, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:42:16,337] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.75, 24.25, 2.85, 32.5, 121.5, 863.75, 1.666666666666666, 14.81289097982695, 18.0, 22.82094486542907, 22.2, 1.0, 0.0], 
actual action is [1.75, 18], 
sim time next is 4971000.0000, 
raw observation next is [6.833333333333334, 24.16666666666666, 2.933333333333334, 31.66666666666666, 121.0, 863.3333333333334, 1.75, 14.80053363459749, 18.0, 22.80281204802021, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5085470085470086, 0.2416666666666666, 0.2666666666666667, 0.08796296296296295, 0.3201058201058201, 0.8633333333333334, 0.5291666666666667, 0.1480053363459749, 0.0, 0.6861160068600302, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0148. 
=============================================
[2017-11-02 10:42:17,829] A3C_AGENT_WORKER-Thread-6 INFO:Local step 17000, global step 268679: loss 6.9999
[2017-11-02 10:42:18,508] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   7.89598508e-12   4.74044502e-12   1.00113563e-11
   7.52222503e-12   1.63360839e-30   8.44378319e-30   1.34725984e-30
   4.34171453e-30], sum to 1.0000
[2017-11-02 10:42:18,528] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666666, 35.25, 4.016666666666666, 64.16666666666666, 106.75, 703.9166666666667, -5.333333333333333, 20.97644745617905, 18.0, 21.78024575689199, 22.2, 1.0, 0.0], 
actual action is [-5.166666666666667, 18], 
sim time next is 4959000.0000, 
raw observation next is [0.0, 34.5, 4.1, 65.0, 108.0, 717.0, -5.166666666666667, 20.78322295291042, 18.0, 21.82176944232372, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3333333333333333, 0.345, 0.3727272727272727, 0.18055555555555555, 0.2857142857142857, 0.717, 0.41388888888888886, 0.2078322295291042, 0.0, 0.5459670631891029, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:20,082] A3C_AGENT_WORKER-Thread-10 INFO:Local step 17000, global step 269592: loss 37.1041
[2017-11-02 10:42:20,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 17000, global step 269661: loss 3.3468
[2017-11-02 10:42:21,554] A3C_AGENT_WORKER-Thread-8 INFO:Local step 17000, global step 270176: loss 4.0015
[2017-11-02 10:42:23,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-58.3647728 ]
 [-57.20541382]
 [-59.23365021]
 [-55.32365417]
 [-60.60853577]], R is [[-55.77090836]
 [-56.21319962]
 [-56.65106964]
 [-57.08456039]
 [-57.51371384]].
[2017-11-02 10:42:24,220] A3C_AGENT_WORKER-Thread-13 INFO:Local step 17000, global step 271314: loss 4.9201
[2017-11-02 10:42:24,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03770472
  0.1297837   0.09223849  0.74027306], sum to 1.0000
[2017-11-02 10:42:24,685] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 65.0, 1.5, 350.0, 78.0, 317.0, -7.083333333333333, 21.80442095233744, 18.0, 21.21903587020166, 22.2, 1.0, 0.0], 
actual action is [3.0, 23.0], 
sim time next is 5040300.0000, 
raw observation next is [-1.75, 63.49999999999999, 1.375, 320.8333333333333, 81.16666666666667, 353.0, 3.0, 17.77610631373075, 23.0, 21.28196056746762, 22.2, 1.0, 85.38840933340549], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.28846153846153844, 0.6349999999999999, 0.125, 0.8912037037037036, 0.21472663139329806, 0.353, 0.55, 0.1777610631373075, 0.7142857142857143, 0.4688515096382316, 0.5999999999999999, 1.0, 1.0045695215694763], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:24,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   2.90989732e-10   4.69765754e-11   1.33831973e-10
   2.37317777e-10   4.83420118e-19   1.23645469e-18   4.89208056e-19
   3.15471150e-19], sum to 1.0000
[2017-11-02 10:42:24,772] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.833333333333332, 25.16666666666667, 1.25, 175.0, 122.0, 863.3333333333334, 3.75, 11.98149838635897, 18.0, 23.16142368661448, 22.2, 1.0, 0.0], 
actual action is [3.833333333333332, 18], 
sim time next is 5057700.0000, 
raw observation next is [8.916666666666668, 25.08333333333333, 1.375, 192.5, 121.5, 862.9166666666667, 3.833333333333332, 11.95053578517352, 18.0, 23.14480616757162, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.561965811965812, 0.2508333333333333, 0.125, 0.5347222222222222, 0.32142857142857145, 0.8629166666666668, 0.5638888888888888, 0.11950535785173519, 0.0, 0.7349723096530886, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0120. 
=============================================
[2017-11-02 10:42:25,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   3.53116003e-09   7.41256390e-10   1.86938509e-09
   3.02645087e-09   7.73606837e-17   2.52651585e-16   7.77156236e-17
   5.08475268e-17], sum to 1.0000
[2017-11-02 10:42:25,100] A3C_AGENT_WORKER-Thread-4 INFO:Local step 17000, global step 271705: loss 3.1679
[2017-11-02 10:42:25,106] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 17.83333333333334, 2.683333333333334, 251.6666666666667, 72.66666666666666, 560.5833333333334, 7.0, 7.705069459904957, 18.0, 25.12947289395769, 22.2, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5071200.0000, 
raw observation next is [12.0, 17.66666666666666, 2.766666666666667, 253.3333333333333, 69.33333333333333, 536.1666666666666, 7.0, 7.694031148837698, 18.0, 25.1272999475104, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.6410256410256411, 0.1766666666666666, 0.2515151515151515, 0.7037037037037036, 0.18342151675485008, 0.5361666666666667, 0.6166666666666667, 0.07694031148837698, 0.0, 1.0181857067872002, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0077. 
=============================================
[2017-11-02 10:42:25,969] A3C_AGENT_WORKER-Thread-17 INFO:Local step 17000, global step 272145: loss 11.6508
[2017-11-02 10:42:26,426] A3C_AGENT_WORKER-Thread-5 INFO:Local step 17000, global step 272383: loss 10.7263
[2017-11-02 10:42:27,344] A3C_AGENT_WORKER-Thread-2 INFO:Local step 17000, global step 272830: loss 12.3311
[2017-11-02 10:42:27,751] A3C_AGENT_WORKER-Thread-12 INFO:Local step 17000, global step 273026: loss 4.0067
[2017-11-02 10:42:28,541] A3C_AGENT_WORKER-Thread-14 INFO:Local step 17000, global step 273424: loss 6.1754
[2017-11-02 10:42:28,656] A3C_AGENT_WORKER-Thread-7 INFO:Local step 17000, global step 273477: loss 46.9661
[2017-11-02 10:42:29,791] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.51074254e-14   2.58696601e-14   6.44632798e-14
   8.34369601e-14   1.81887943e-23   2.70541204e-23   1.59038648e-24
   7.01561534e-24], sum to 1.0000
[2017-11-02 10:42:29,800] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.0, 40.0, 4.1, 175.0, 0.0, 0.0, 4.833333333333332, 28.93491460701209, 18.0, 20.16554347038843, 19.4, 0.0, 0.0], 
actual action is [5.0, 18], 
sim time next is 5121300.0000, 
raw observation next is [10.16666666666667, 39.83333333333333, 4.1, 175.8333333333333, 0.0, 0.0, 5.0, 29.04081257558595, 18.0, 20.15123015081072, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.5940170940170941, 0.39833333333333326, 0.3727272727272727, 0.4884259259259258, 0.0, 0.0, 0.5833333333333334, 0.2904081257558595, 0.0, 0.30731859297295977, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:42:31,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 17000, global step 274656: loss 6.8181
[2017-11-02 10:42:32,382] A3C_AGENT_WORKER-Thread-11 INFO:Local step 17000, global step 275295: loss 2.9481
[2017-11-02 10:42:32,492] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.06920554e-16   8.04890411e-17   3.68808230e-16
   2.97814455e-16   6.04193076e-33   6.54423684e-32   6.46426604e-33
   2.33313471e-32], sum to 1.0000
[2017-11-02 10:42:32,506] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 70.5, 6.991666666666666, 288.3333333333333, 104.25, 0.0, -3.0, 21.87713676937356, 18.0, 21.41359341529395, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5225400.0000, 
raw observation next is [2.0, 70.0, 6.95, 290.0, 105.0, 0.0, -3.0, 22.36244001342981, 18.0, 21.43145629952613, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.38461538461538464, 0.7, 0.6318181818181818, 0.8055555555555556, 0.2777777777777778, 0.0, 0.45, 0.2236244001342981, 0.0, 0.490208042789447, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:33,640] A3C_AGENT_WORKER-Thread-16 INFO:Local step 17500, global step 275953: loss 24.5980
[2017-11-02 10:42:35,116] A3C_AGENT_WORKER-Thread-6 INFO:Local step 17500, global step 276639: loss 21.0175
[2017-11-02 10:42:35,452] A3C_AGENT_WORKER-Thread-9 INFO:Local step 17000, global step 276810: loss 10.8200
[2017-11-02 10:42:37,879] A3C_AGENT_WORKER-Thread-10 INFO:Local step 17500, global step 277892: loss 7.8097
[2017-11-02 10:42:37,923] A3C_AGENT_WORKER-Thread-3 INFO:Local step 17500, global step 277911: loss 5.5195
[2017-11-02 10:42:38,427] A3C_AGENT_WORKER-Thread-8 INFO:Local step 17500, global step 278225: loss 5.8399
[2017-11-02 10:42:39,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   3.99103862e-24   8.49943036e-23   4.47069121e-23
   1.20224248e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:39,100] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 79.16666666666666, 6.516666666666667, 320.0, 0.0, 0.0, -5.0, 48.67874047838885, 18.0, 18.57720788832951, 22.2, 1.0, 0.0], 
actual action is [-5.0, 18], 
sim time next is 5259300.0000, 
raw observation next is [0.0, 78.58333333333334, 6.608333333333333, 320.0, 0.0, 0.0, -5.0, 49.17126319654234, 18.0, 18.52603813278372, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.3333333333333333, 0.7858333333333334, 0.6007575757575757, 0.8888888888888888, 0.0, 0.0, 0.4166666666666667, 0.4917126319654234, 0.0, 0.0751483046833888, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:40,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 17500, global step 279398: loss 12.3049
[2017-11-02 10:42:40,950] A3C_AGENT_WORKER-Thread-4 INFO:Local step 17500, global step 279443: loss 10.2652
[2017-11-02 10:42:42,120] A3C_AGENT_WORKER-Thread-17 INFO:Local step 17500, global step 279858: loss 57.3684
[2017-11-02 10:42:42,654] A3C_AGENT_WORKER-Thread-5 INFO:Local step 17500, global step 280033: loss -29.5691
[2017-11-02 10:42:42,898] A3C_AGENT_WORKER-Thread-2 INFO:Local step 17500, global step 280120: loss -11.2803
[2017-11-02 10:42:44,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 17500, global step 280831: loss -57.3898
[2017-11-02 10:42:45,596] A3C_AGENT_WORKER-Thread-7 INFO:Local step 17500, global step 281027: loss 71.5376
[2017-11-02 10:42:46,587] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   6.55508369e-16   1.21690185e-15   1.98489487e-15
   1.84753005e-15   2.14526305e-33   3.40880960e-32   2.46940066e-32
   1.21629788e-31], sum to 1.0000
[2017-11-02 10:42:46,605] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.666666666666667, 32.66666666666667, 3.6, 315.0, 57.33333333333333, 407.3333333333333, 2.833333333333333, 15.40269030145219, 18.0, 22.97200599548598, 22.2, 1.0, 0.0], 
actual action is [2.666666666666667, 18], 
sim time next is 5332500.0000, 
raw observation next is [7.5, 33.0, 3.6, 312.5, 53.75, 385.5, 2.666666666666667, 15.87406643522186, 18.0, 22.90975649946934, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.5256410256410257, 0.33, 0.32727272727272727, 0.8680555555555556, 0.1421957671957672, 0.3855, 0.5444444444444444, 0.1587406643522186, 0.0, 0.701393785638477, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:46,700] A3C_AGENT_WORKER-Thread-14 INFO:Local step 17500, global step 281410: loss 6.3167
[2017-11-02 10:42:46,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-94.90412903]
 [-97.07363129]
 [-93.92081451]
 [-93.9551239 ]
 [-95.07939911]], R is [[-95.04515839]
 [-95.0947113 ]
 [-95.14376831]
 [-95.19232941]
 [-95.24040985]].
[2017-11-02 10:42:47,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.82728910e-22   4.06536976e-21   1.83610024e-21
   5.21080690e-21   1.35149590e-38   1.44998294e-37   1.30043510e-38
   5.66260288e-36], sum to 1.0000
[2017-11-02 10:42:47,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.75, 69.75, 4.35, 322.5, 0.0, 0.0, -6.666666666666667, 61.22117149790597, 18.0, 17.59469464430443, 19.4, 0.0, 0.0], 
actual action is [-6.75, 18], 
sim time next is 5280600.0000, 
raw observation next is [-1.833333333333333, 70.16666666666667, 4.266666666666667, 321.6666666666667, 0.0, 0.0, -6.75, 62.04393842396089, 18.0, 17.50713429602139, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.28632478632478636, 0.7016666666666667, 0.3878787878787879, 0.8935185185185186, 0.0, 0.0, 0.3875, 0.6204393842396089, 0.0, -0.0704093862826584, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:47,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-105.73895264]
 [-105.82648468]
 [-102.43011475]
 [-102.39738464]
 [-102.82751465]], R is [[-107.33450317]
 [-107.2611618 ]
 [-107.18855286]
 [-107.1166687 ]
 [-107.04550171]].
[2017-11-02 10:42:47,980] A3C_AGENT_WORKER-Thread-15 INFO:Local step 17500, global step 281953: loss 31.3729
[2017-11-02 10:42:49,107] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-93.67996216]
 [-92.72927094]
 [-95.04138184]
 [-94.01973724]
 [-92.01680756]], R is [[-91.80930328]
 [-91.89121246]
 [-91.97229767]
 [-92.05257416]
 [-92.13204956]].
[2017-11-02 10:42:49,870] A3C_AGENT_WORKER-Thread-11 INFO:Local step 17500, global step 282722: loss 3.3868
[2017-11-02 10:42:50,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   9.93427599e-28   1.98255209e-27   4.59552538e-27
   4.03208995e-27   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:50,644] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.25, 73.5, 3.85, 337.5, 213.25, 377.0, -5.333333333333333, 34.86748080481158, 18.0, 20.37044141987571, 22.2, 1.0, 0.0], 
actual action is [-5.25, 18], 
sim time next is 5305800.0000, 
raw observation next is [-0.1666666666666666, 73.0, 3.766666666666667, 338.3333333333334, 211.6666666666667, 408.0, -5.25, 35.11415422686532, 18.0, 20.38583025901663, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.32905982905982906, 0.73, 0.34242424242424246, 0.9398148148148151, 0.5599647266313934, 0.408, 0.4125, 0.3511415422686532, 0.0, 0.3408328941452327, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:51,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 17500, global step 283402: loss 4.3218
[2017-11-02 10:42:53,742] A3C_AGENT_WORKER-Thread-16 INFO:Local step 18000, global step 284360: loss 4.6015
[2017-11-02 10:42:54,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   2.68434761e-31   3.33034171e-31   8.38782270e-31
   8.03994784e-31   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:54,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 29.33333333333333, 3.433333333333334, 240.0, 138.0, 819.1666666666666, 5.16666666666667, 39.26644909468003, 18.0, 19.91704806977517, 20.56, 1.0, 0.0], 
actual action is [5.33333333333333, 18], 
sim time next is 5406300.0000, 
raw observation next is [10.5, 29.0, 3.475, 240.0, 137.0, 816.25, 5.33333333333333, 38.85958416929172, 18.0, 19.95254843424566, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.6025641025641025, 0.29, 0.3159090909090909, 0.6666666666666666, 0.36243386243386244, 0.81625, 0.5888888888888888, 0.3885958416929172, 0.0, 0.27893549060652284, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:54,525] A3C_AGENT_WORKER-Thread-6 INFO:Local step 18000, global step 284668: loss 6.1618
[2017-11-02 10:42:55,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   9.59975012e-24   3.84598721e-23   7.01751918e-23
   3.99968225e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:55,637] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.66666666666667, 30.66666666666667, 4.433333333333334, 270.0, 60.0, 304.3333333333333, 5.75, 28.38801997038327, 18.0, 21.20155937442999, 20.56, 1.0, 0.0], 
actual action is [5.66666666666667, 18], 
sim time next is 5419500.0000, 
raw observation next is [10.58333333333333, 30.58333333333333, 4.391666666666666, 270.0, 53.5, 297.6666666666667, 5.66666666666667, 28.5427675535633, 18.0, 21.17694421441969, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.6047008547008546, 0.3058333333333333, 0.3992424242424242, 0.75, 0.14153439153439154, 0.2976666666666667, 0.5944444444444446, 0.28542767553563303, 0.0, 0.4538491734885274, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:57,424] A3C_AGENT_WORKER-Thread-10 INFO:Local step 18000, global step 285880: loss 6.9096
[2017-11-02 10:42:58,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 18000, global step 286201: loss 7.0160
[2017-11-02 10:42:59,196] A3C_AGENT_WORKER-Thread-8 INFO:Local step 18000, global step 286634: loss 5.7799
[2017-11-02 10:43:01,835] A3C_AGENT_WORKER-Thread-4 INFO:Local step 18000, global step 287694: loss -16.1597
[2017-11-02 10:43:02,072] A3C_AGENT_WORKER-Thread-13 INFO:Local step 18000, global step 287789: loss 7.0729
[2017-11-02 10:43:04,023] A3C_AGENT_WORKER-Thread-17 INFO:Local step 18000, global step 288561: loss 1.3799
[2017-11-02 10:43:04,036] A3C_AGENT_WORKER-Thread-5 INFO:Local step 18000, global step 288562: loss 1.2719
[2017-11-02 10:43:04,587] A3C_AGENT_WORKER-Thread-2 INFO:Local step 18000, global step 288829: loss 1.3297
[2017-11-02 10:43:05,121] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-89.83005524]
 [-91.86005402]
 [-92.42162323]
 [-90.41402435]
 [-89.54827118]], R is [[-90.10388947]
 [-90.20285034]
 [-90.3008194 ]
 [-90.39781189]
 [-90.49383545]].
[2017-11-02 10:43:06,633] A3C_AGENT_WORKER-Thread-12 INFO:Local step 18000, global step 289758: loss 1.0079
[2017-11-02 10:43:06,958] A3C_AGENT_WORKER-Thread-7 INFO:Local step 18000, global step 289919: loss 3.9015
[2017-11-02 10:43:07,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   7.63559927e-23   2.84650878e-22   4.43223204e-22
   3.11029099e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,181] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.66666666666667, 40.0, 4.433333333333334, 316.6666666666666, 142.1666666666667, 834.3333333333334, 7.58333333333333, 28.6585392453169, 18.0, 21.22115449483727, 20.56, 1.0, 0.0], 
actual action is [7.66666666666667, 18], 
sim time next is 5489100.0000, 
raw observation next is [12.75, 39.5, 4.35, 317.5, 141.75, 834.0, 7.66666666666667, 28.5132771717114, 18.0, 21.23485050001734, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6602564102564102, 0.395, 0.39545454545454545, 0.8819444444444444, 0.375, 0.834, 0.6277777777777779, 0.285132771717114, 0.0, 0.4621215000024773, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,503] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.46903758e-26   7.53314093e-26   9.80709351e-26
   4.27291132e-26   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,514] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.583333333333333, 58.75, 4.391666666666666, 284.1666666666666, 0.0, 0.0, 0.6666666666666661, 50.48903940143433, 18.0, 18.91327869325331, 20.56, 1.0, 0.0], 
actual action is [0.583333333333333, 18], 
sim time next is 5455800.0000, 
raw observation next is [5.5, 59.5, 4.35, 285.0, 0.0, 0.0, 0.583333333333333, 50.65994208653741, 18.0, 18.89351862302565, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.47435897435897434, 0.595, 0.39545454545454545, 0.7916666666666666, 0.0, 0.0, 0.5097222222222222, 0.5065994208653741, 0.0, 0.12764551757509274, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,517] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.30328902e-18   2.19655661e-17   1.13872421e-17
   7.69841197e-18   7.68004642e-34   1.64132017e-33   3.69506134e-34
   1.82131588e-31], sum to 1.0000
[2017-11-02 10:43:07,523] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.5, 59.5, 4.35, 285.0, 0.0, 0.0, 0.583333333333333, 50.65994208653741, 18.0, 18.89351862302565, 20.56, 1.0, 0.0], 
actual action is [0.5, 18], 
sim time next is 5456100.0000, 
raw observation next is [5.416666666666667, 60.25, 4.308333333333333, 285.8333333333334, 0.0, 0.0, 0.5, 50.86051622120635, 18.0, 18.87315088594841, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.47222222222222227, 0.6025, 0.3916666666666666, 0.7939814814814817, 0.0, 0.0, 0.5083333333333333, 0.5086051622120635, 0.0, 0.12473584084977267, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   9.21184811e-28   7.50036238e-27   9.04385117e-27
   4.29030400e-27   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,577] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 1.091666666666667, 327.5, 0.0, 0.0, -6.0, 59.93994309355896, 18.0, 17.71948387166684, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 5369400.0000, 
raw observation next is [-1.0, 55.0, 1.15, 325.0, 0.0, 0.0, -6.0, 61.02411194457157, 18.0, 17.62757369689492, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.3076923076923077, 0.55, 0.10454545454545454, 0.9027777777777778, 0.0, 0.0, 0.4, 0.6102411194457157, 0.0, -0.05320375758643995, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:08,830] A3C_AGENT_WORKER-Thread-14 INFO:Local step 18000, global step 290848: loss 1.9727
[2017-11-02 10:43:08,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 18000, global step 290861: loss 22.7264
[2017-11-02 10:43:09,298] A3C_AGENT_WORKER-Thread-16 INFO:Local step 18500, global step 291098: loss 8.8417
[2017-11-02 10:43:09,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   2.82807733e-14   7.61233795e-14   1.21681948e-13
   6.34677383e-14   2.21063159e-29   4.71833968e-29   4.30489037e-29
   2.33759386e-28], sum to 1.0000
[2017-11-02 10:43:09,815] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 37.0, 4.6, 330.0, 22.5, 164.0, 7.08333333333333, 23.59827766399136, 18.0, 21.1870534581019, 19.4, 0.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5508300.0000, 
raw observation next is [11.91666666666667, 37.16666666666666, 4.558333333333333, 330.8333333333333, 18.75, 136.6666666666667, 7.0, 24.00962413074539, 18.0, 21.13599280565469, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6388888888888891, 0.3716666666666666, 0.4143939393939393, 0.9189814814814814, 0.0496031746031746, 0.13666666666666671, 0.6166666666666667, 0.2400962413074539, 0.0, 0.44799897223638446, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:10,953] A3C_AGENT_WORKER-Thread-6 INFO:Local step 18500, global step 291823: loss 4.0716
[2017-11-02 10:43:11,633] A3C_AGENT_WORKER-Thread-11 INFO:Local step 18000, global step 292148: loss 4.5346
[2017-11-02 10:43:12,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   3.99382764e-23   2.12038693e-22   4.47736700e-22
   1.47945574e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:12,404] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.416666666666667, 66.33333333333334, 0.625, 99.99999999999999, 0.0, 0.0, -1.5, 46.33107177889953, 18.0, 18.77586655196176, 19.4, 0.0, 0.0], 
actual action is [-1.583333333333333, 18], 
sim time next is 5542800.0000, 
raw observation next is [3.333333333333333, 66.66666666666666, 0.5, 80.00000000000001, 0.0, 0.0, -1.583333333333333, 46.61574599844152, 18.0, 18.747240228015, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.41880341880341876, 0.6666666666666665, 0.045454545454545456, 0.22222222222222227, 0.0, 0.0, 0.47361111111111115, 0.46615745998441516, 0.0, 0.10674860400214266, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0933. 
=============================================
[2017-11-02 10:43:12,769] A3C_AGENT_WORKER-Thread-9 INFO:Local step 18000, global step 292730: loss 1.2422
[2017-11-02 10:43:12,960] A3C_AGENT_WORKER-Thread-10 INFO:Local step 18500, global step 292836: loss -1.8183
[2017-11-02 10:43:13,826] A3C_AGENT_WORKER-Thread-3 INFO:Local step 18500, global step 293285: loss 135.5925
[2017-11-02 10:43:14,428] A3C_AGENT_WORKER-Thread-8 INFO:Local step 18500, global step 293604: loss 2.3302
[2017-11-02 10:43:14,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   1.42893879e-18   1.01595977e-17   1.27827190e-17
   4.22817713e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:14,948] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.5, 31.0, 3.85, 270.0, 0.0, 0.0, 4.583333333333332, 29.5975513282859, 18.0, 21.37879435054493, 20.56, 1.0, 0.0], 
actual action is [4.5, 18], 
sim time next is 5423700.0000, 
raw observation next is [9.416666666666666, 31.16666666666666, 3.808333333333333, 270.0, 0.0, 0.0, 4.5, 30.02913793209569, 18.0, 21.32024368782974, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.5747863247863247, 0.3116666666666666, 0.3462121212121212, 0.75, 0.0, 0.0, 0.575, 0.3002913793209569, 0.0, 0.47432052683282017, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:16,173] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   2.51092888e-18   2.34637110e-17   2.81527480e-17
   7.71299186e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:16,196] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.916666666666667, 64.33333333333333, 3.1, 350.0, 0.0, 0.0, -1.0, 40.20820913519096, 18.0, 19.51071547653932, 20.56, 1.0, 0.0], 
actual action is [-1.083333333333333, 18], 
sim time next is 5533800.0000, 
raw observation next is [3.833333333333333, 64.66666666666667, 3.1, 350.0, 0.0, 0.0, -1.083333333333333, 40.50097857387089, 18.0, 19.47711785614235, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.4316239316239316, 0.6466666666666667, 0.2818181818181818, 0.9722222222222222, 0.0, 0.0, 0.48194444444444445, 0.4050097857387089, 0.0, 0.21101683659176423, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:17,123] A3C_AGENT_WORKER-Thread-4 INFO:Local step 18500, global step 295044: loss 9.3694
[2017-11-02 10:43:17,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-90.01504517]
 [-89.34649658]
 [-89.15139771]
 [-88.42768097]
 [-89.51269531]], R is [[-89.67198181]
 [-89.77526093]
 [-89.87751007]
 [-89.97873688]
 [-90.07894897]].
[2017-11-02 10:43:17,893] A3C_AGENT_WORKER-Thread-13 INFO:Local step 18500, global step 295473: loss 13.0244
[2017-11-02 10:43:18,494] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   7.93250127e-23   4.14797024e-22   4.84355244e-22
   1.58548142e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:18,508] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.583333333333333, 71.08333333333333, 3.808333333333333, 170.0, 0.0, 0.0, -1.333333333333333, 41.45021958414252, 18.0, 18.64953474316433, 22.2, 1.0, 0.0], 
actual action is [-1.416666666666667, 18], 
sim time next is 5639400.0000, 
raw observation next is [3.5, 71.5, 3.85, 170.0, 0.0, 0.0, -1.416666666666667, 41.72353886354691, 18.0, 18.62713155605537, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.4230769230769231, 0.715, 0.35000000000000003, 0.4722222222222222, 0.0, 0.0, 0.47638888888888886, 0.41723538863546916, 0.0, 0.08959022229362443, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:19,012] A3C_AGENT_WORKER-Thread-5 INFO:Local step 18500, global step 296109: loss 5.2403
[2017-11-02 10:43:19,338] A3C_AGENT_WORKER-Thread-17 INFO:Local step 18500, global step 296292: loss 10.5591
[2017-11-02 10:43:19,506] A3C_AGENT_WORKER-Thread-2 INFO:Local step 18500, global step 296389: loss 1.9044
[2017-11-02 10:43:20,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   3.37868758e-15   2.34298478e-14   2.63244016e-14
   7.36555710e-15   1.79305992e-37   2.63641907e-37   4.31302538e-37
   1.59750828e-37], sum to 1.0000
[2017-11-02 10:43:20,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 50.33333333333334, 2.6, 157.5, 0.0, 0.0, 3.0, 23.34013093039983, 18.0, 20.48150977678855, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5614800.0000, 
raw observation next is [8.0, 50.66666666666666, 2.6, 160.0, 0.0, 0.0, 3.0, 23.55781735919475, 18.0, 20.45037864342168, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5384615384615384, 0.5066666666666666, 0.23636363636363636, 0.4444444444444444, 0.0, 0.0, 0.55, 0.2355781735919475, 0.0, 0.35005409191738274, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:21,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.03359090e-15   1.05703325e-14   1.04344396e-14
   2.49022393e-15   3.15296370e-36   2.03334694e-36   1.29574762e-35
   7.16781931e-36], sum to 1.0000
[2017-11-02 10:43:21,035] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.5, 58.0, 2.975, 162.5, 0.0, 0.0, 1.666666666666667, 25.68857551710643, 18.0, 20.14497116207397, 22.2, 1.0, 0.0], 
actual action is [1.5, 18], 
sim time next is 5619000.0000, 
raw observation next is [6.333333333333333, 58.66666666666666, 3.016666666666667, 161.6666666666667, 0.0, 0.0, 1.5, 25.92196792222624, 18.0, 20.1156380042813, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.4957264957264957, 0.5866666666666666, 0.2742424242424243, 0.4490740740740742, 0.0, 0.0, 0.525, 0.2592196792222624, 0.0, 0.3022340006116145, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:21,332] A3C_AGENT_WORKER-Thread-7 INFO:Local step 18500, global step 297375: loss -51.1337
[2017-11-02 10:43:21,674] A3C_AGENT_WORKER-Thread-12 INFO:Local step 18500, global step 297567: loss 8.9389
[2017-11-02 10:43:22,449] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   7.78773259e-18   4.27135025e-17   7.82988654e-17
   2.22217754e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:22,474] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 73.0, 0.0, 0.0, 75.08333333333334, 230.8333333333333, -3.0, 49.41690020878165, 18.0, 18.30607765273188, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5557200.0000, 
raw observation next is [2.0, 73.0, 0.0, 0.0, 78.16666666666666, 261.6666666666667, -3.0, 49.91623660894226, 18.0, 18.30621289111858, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.38461538461538464, 0.73, 0.0, 0.0, 0.2067901234567901, 0.26166666666666666, 0.45, 0.49916236608942266, 0.0, 0.04374469873122574, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:23,665] A3C_AGENT_WORKER-Thread-14 INFO:Local step 18500, global step 298654: loss 1.8962
[2017-11-02 10:43:24,088] A3C_AGENT_WORKER-Thread-15 INFO:Local step 18500, global step 298888: loss 4.3348
[2017-11-02 10:43:24,542] A3C_AGENT_WORKER-Thread-16 INFO:Local step 19000, global step 299141: loss 27.7761
[2017-11-02 10:43:24,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.63505773e-10   1.36458622e-09   9.63099600e-10
   4.14021789e-10   4.10558375e-26   1.76460435e-26   4.99874193e-26
   7.76636643e-27], sum to 1.0000
[2017-11-02 10:43:24,831] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 37.0, 2.1, 350.0, 0.0, 0.0, 7.16666666666667, 10.43330075023683, 18.0, 23.21577079395722, 22.2, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5598300.0000, 
raw observation next is [12.0, 36.75, 2.1, 327.5, 0.0, 0.0, 7.0, 10.67845436213906, 18.0, 23.14276018815308, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.6410256410256411, 0.3675, 0.19090909090909092, 0.9097222222222222, 0.0, 0.0, 0.6166666666666667, 0.1067845436213906, 0.0, 0.7346800268790113, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:43:25,148] A3C_AGENT_WORKER-Thread-6 INFO:Local step 19000, global step 299500: loss 8.6782
[2017-11-02 10:43:25,644] A3C_AGENT_WORKER-Thread-11 INFO:Local step 18500, global step 299792: loss 20.1701
[2017-11-02 10:43:26,210] A3C_AGENT_WORKER-Thread-9 INFO:Local step 18500, global step 300102: loss 15.5553
[2017-11-02 10:43:26,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-33.41356659]
 [-31.75720215]
 [-34.39923477]
 [-31.38718414]
 [-31.86919785]], R is [[-32.03498459]
 [-31.71463585]
 [-31.39748955]
 [-31.08351517]
 [-30.77268028]].
[2017-11-02 10:43:27,383] A3C_AGENT_WORKER-Thread-10 INFO:Local step 19000, global step 300748: loss 4.9754
[2017-11-02 10:43:27,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-36.76369858]
 [-38.74815369]
 [-38.30179977]
 [-37.74213409]
 [-38.22413254]], R is [[-38.91717148]
 [-38.52799988]
 [-38.14271927]
 [-37.7612915 ]
 [-37.38367844]].
[2017-11-02 10:43:28,916] A3C_AGENT_WORKER-Thread-3 INFO:Local step 19000, global step 301583: loss 2.2623
[2017-11-02 10:43:29,159] A3C_AGENT_WORKER-Thread-8 INFO:Local step 19000, global step 301715: loss 5.5815
[2017-11-02 10:43:30,469] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-29.63217926]
 [-32.07052231]
 [-29.93665886]
 [-29.02351761]
 [-34.2812233 ]], R is [[-29.93619537]
 [-29.64441299]
 [-29.35559082]
 [-29.0696888 ]
 [-28.78668213]].
[2017-11-02 10:43:31,840] A3C_AGENT_WORKER-Thread-4 INFO:Local step 19000, global step 303266: loss 2.5803
[2017-11-02 10:43:32,736] A3C_AGENT_WORKER-Thread-13 INFO:Local step 19000, global step 303779: loss 3.1461
[2017-11-02 10:43:33,196] A3C_AGENT_WORKER-Thread-2 INFO:Local step 19000, global step 304053: loss 1.7418
[2017-11-02 10:43:33,211] A3C_AGENT_WORKER-Thread-5 INFO:Local step 19000, global step 304053: loss 6.8971
[2017-11-02 10:43:34,006] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.96766925e-01   7.63620017e-04   5.94272453e-04   1.05754787e-03
   8.15453299e-04   1.18608193e-06   4.84558655e-07   4.58868982e-07
   6.07005575e-08], sum to 1.0000
[2017-11-02 10:43:34,049] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [24.08333333333333, 43.33333333333333, 5.149999999999999, 239.1666666666667, 139.0833333333333, 797.0833333333333, 19.0, 15.77603701499973, 18.0, 26.65075357633275, 19.4, 0.0, 0.0], 
actual action is [19.08333333333333, 18], 
sim time next is 5753400.0000, 
raw observation next is [24.16666666666666, 42.66666666666667, 5.2, 238.3333333333333, 137.6666666666667, 795.6666666666667, 19.08333333333333, 16.35628039903921, 18.0, 26.76090050589405, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.9529914529914527, 0.4266666666666667, 0.4727272727272727, 0.6620370370370369, 0.36419753086419765, 0.7956666666666667, 0.8180555555555554, 0.1635628039903921, 0.0, 1.2515572151277214, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:34,118] A3C_AGENT_WORKER-Thread-17 INFO:Local step 19000, global step 304593: loss 6.6027
[2017-11-02 10:43:36,484] A3C_AGENT_WORKER-Thread-12 INFO:Local step 19000, global step 305905: loss -1.1190
[2017-11-02 10:43:36,910] A3C_AGENT_WORKER-Thread-7 INFO:Local step 19000, global step 306140: loss -1.4944
[2017-11-02 10:43:38,163] A3C_AGENT_WORKER-Thread-14 INFO:Local step 19000, global step 306845: loss -0.1669
[2017-11-02 10:43:38,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99960661e-01   9.36229208e-06   8.86620364e-06   1.14180075e-05
   9.78722437e-06   5.98514023e-13   2.57135025e-13   3.01287180e-13
   3.75371324e-14], sum to 1.0000
[2017-11-02 10:43:38,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 19500, global step 306916: loss 24.4047
[2017-11-02 10:43:38,276] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [22.41666666666666, 35.41666666666666, 6.324999999999999, 230.0, 138.0, 772.8333333333333, 17.33333333333334, 6.734837153573365, 18.0, 25.30043138898715, 22.2, 1.0, 0.0], 
actual action is [17.41666666666666, 18], 
sim time next is 5668200.0000, 
raw observation next is [22.5, 35.5, 6.45, 230.0, 138.0, 767.0, 17.41666666666666, 6.785469239473829, 18.0, 25.37761761038848, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.9102564102564102, 0.355, 0.5863636363636364, 0.6388888888888888, 0.36507936507936506, 0.767, 0.7902777777777776, 0.06785469239473829, 0.0, 1.05394537291264, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0068. 
=============================================
[2017-11-02 10:43:38,421] A3C_AGENT_WORKER-Thread-6 INFO:Local step 19500, global step 306993: loss 15.0586
[2017-11-02 10:43:38,786] A3C_AGENT_WORKER-Thread-15 INFO:Local step 19000, global step 307201: loss -5.8405
[2017-11-02 10:43:39,291] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.46550485  0.0678421   0.19685392  0.11589962  0.05317903  0.02683856
  0.02235003  0.03542852  0.01610337], sum to 1.0000
[2017-11-02 10:43:39,314] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.0, 55.0, 5.016666666666667, 200.0, 0.0, 0.0, 22.0, 7.400507268503524, 20.0, 24.4382435089357, 19.4, 0.0, 39.31509248219977], 
actual action is [12.0, 18], 
sim time next is 5811300.0000, 
raw observation next is [17.0, 55.0, 4.975, 200.0, 0.0, 0.0, 12.0, 7.351779074859953, 18.0, 24.49695334668942, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.2608695652173913, 0.7692307692307693, 0.55, 0.4522727272727272, 0.5555555555555556, 0.0, 0.0, 0.7, 0.07351779074859953, 0.0, 0.9281361923842029, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:40,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-3.53125262]
 [-3.63840723]
 [-3.2014451 ]
 [-3.57755709]
 [-3.33466911]], R is [[-3.66966915]
 [-3.63297248]
 [-3.59664273]
 [-3.56067634]
 [-3.52506971]].
[2017-11-02 10:43:40,730] A3C_AGENT_WORKER-Thread-11 INFO:Local step 19000, global step 308308: loss 1.4757
[2017-11-02 10:43:41,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 19500, global step 308537: loss 17.3191
[2017-11-02 10:43:41,248] A3C_AGENT_WORKER-Thread-9 INFO:Local step 19000, global step 308602: loss -0.8031
[2017-11-02 10:43:42,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 19500, global step 309269: loss 41.0426
[2017-11-02 10:43:42,744] A3C_AGENT_WORKER-Thread-8 INFO:Local step 19500, global step 309503: loss 48.7446
[2017-11-02 10:43:43,782] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.98429716e-01   6.02838809e-05   1.03512837e-03   4.06278559e-04
   6.85392442e-05   2.05697767e-14   7.39850584e-15   1.12988596e-14
   2.71586715e-15], sum to 1.0000
[2017-11-02 10:43:43,812] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [22.08333333333333, 40.75, 3.558333333333333, 220.8333333333333, 0.0, 0.0, 17.16666666666667, 25.87387039032333, 18.0, 27.45247714890319, 19.4, 0.0, 0.0], 
actual action is [17.08333333333333, 18], 
sim time next is 5770800.0000, 
raw observation next is [22.0, 41.0, 3.6, 220.0, 0.0, 0.0, 17.08333333333333, 25.51043049891827, 18.0, 27.38693606057092, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.8974358974358975, 0.41, 0.32727272727272727, 0.6111111111111112, 0.0, 0.0, 0.7847222222222221, 0.25510430498918274, 0.0, 1.3409908657958458, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:44,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   9.93560269e-13   4.81052698e-11   2.44851847e-11
   9.88811246e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:44,207] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [23.0, 38.0, 3.1, 230.0, 24.5, 177.0, 18.16666666666667, 34.65459815178401, 18.0, 28.6150255044909, 22.2, 1.0, 0.0], 
actual action is [18.0, 18], 
sim time next is 5767500.0000, 
raw observation next is [22.91666666666666, 38.24999999999999, 3.141666666666667, 229.1666666666667, 20.41666666666666, 147.5, 18.0, 33.78163385018523, 18.0, 28.5389827324267, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.9209401709401707, 0.38249999999999995, 0.28560606060606064, 0.6365740740740742, 0.05401234567901233, 0.1475, 0.8, 0.3378163385018523, 0.0, 1.5055689617752428, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:45,089] A3C_AGENT_WORKER-Thread-4 INFO:Local step 19500, global step 310885: loss 3.7797
[2017-11-02 10:43:46,408] A3C_AGENT_WORKER-Thread-13 INFO:Local step 19500, global step 311685: loss 10.9276
[2017-11-02 10:43:46,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.26396084e-01   1.94467641e-02   1.55191138e-01   8.00667703e-02
   1.86426491e-02   9.62393533e-05   4.93748812e-05   8.79749277e-05
   2.30399801e-05], sum to 1.0000
[2017-11-02 10:43:46,534] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.5, 50.5, 4.35, 185.0, 0.0, 0.0, 12.58333333333333, 9.891866484810475, 18.0, 25.07056797439325, 22.2, 1.0, 0.0], 
actual action is [12.5, 18], 
sim time next is 5794500.0000, 
raw observation next is [17.41666666666667, 50.75, 4.308333333333333, 185.8333333333333, 0.0, 0.0, 12.5, 9.786948950409533, 18.0, 25.05016778524015, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.77991452991453, 0.5075, 0.3916666666666666, 0.5162037037037036, 0.0, 0.0, 0.7083333333333334, 0.09786948950409532, 0.0, 1.0071668264628784, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0098. 
=============================================
[2017-11-02 10:43:46,849] A3C_AGENT_WORKER-Thread-5 INFO:Local step 19500, global step 311968: loss 8.5061
[2017-11-02 10:43:47,691] A3C_AGENT_WORKER-Thread-2 INFO:Local step 19500, global step 312475: loss 5.9884
[2017-11-02 10:43:48,038] A3C_AGENT_WORKER-Thread-17 INFO:Local step 19500, global step 312672: loss 2.1797
[2017-11-02 10:43:50,301] A3C_AGENT_WORKER-Thread-7 INFO:Local step 19500, global step 314080: loss 36.1558
[2017-11-02 10:43:50,563] A3C_AGENT_WORKER-Thread-12 INFO:Local step 19500, global step 314239: loss 1.9275
[2017-11-02 10:43:51,440] A3C_AGENT_WORKER-Thread-14 INFO:Local step 19500, global step 314734: loss 2.0990
[2017-11-02 10:43:52,418] A3C_AGENT_WORKER-Thread-15 INFO:Local step 19500, global step 315266: loss 32.9408
[2017-11-02 10:43:53,083] A3C_AGENT_WORKER-Thread-6 INFO:Local step 20000, global step 315608: loss -313.3749
[2017-11-02 10:43:53,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.25822982  0.06652871  0.36361411  0.17358105  0.06414181  0.01958268
  0.01607675  0.0286018   0.00964334], sum to 1.0000
[2017-11-02 10:43:53,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.583333333333332, 68.91666666666666, 4.391666666666666, 298.3333333333334, 0.0, 0.0, 3.666666666666668, 5.242886947853994, 18.0, 22.53617793366424, 19.4, 0.0, 0.0], 
actual action is [3.583333333333332, 18], 
sim time next is 5880600.0000, 
raw observation next is [8.5, 68.5, 4.35, 300.0, 0.0, 0.0, 3.583333333333332, 5.257055923988847, 18.0, 22.51002308045716, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.5512820512820513, 0.685, 0.39545454545454545, 0.8333333333333334, 0.0, 0.0, 0.5597222222222221, 0.052570559239888466, 0.0, 0.64428901149388, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:53,656] A3C_AGENT_WORKER-Thread-16 INFO:Local step 20000, global step 315920: loss -19.0895
[2017-11-02 10:43:53,947] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-1.20235372]
 [-0.9604876 ]
 [-1.15086043]
 [-1.30399823]
 [-1.10359466]], R is [[-1.42167282]
 [-1.41841805]
 [-1.41536868]
 [-1.41253173]
 [-1.40991688]].
[2017-11-02 10:43:54,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.96363103e-01   8.86625261e-04   1.11958582e-03   8.66588962e-04
   7.63561053e-04   1.96532014e-07   1.43765050e-07   1.52247523e-07
   3.41933379e-08], sum to 1.0000
[2017-11-02 10:43:54,098] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 57.0, 4.183333333333334, 347.5, 128.1666666666667, 423.0, 3.0, 5.957573312809279, 18.0, 23.16221340119987, 19.4, 0.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5935200.0000, 
raw observation next is [8.0, 57.0, 4.266666666666667, 350.0, 121.3333333333333, 416.0, 3.0, 5.94764980295469, 18.0, 23.1680053531277, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.5384615384615384, 0.57, 0.3878787878787879, 0.9722222222222222, 0.3209876543209876, 0.416, 0.55, 0.059476498029546895, 0.0, 0.738286479018243, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:54,255] A3C_AGENT_WORKER-Thread-11 INFO:Local step 19500, global step 316208: loss 2.6638
[2017-11-02 10:43:54,479] A3C_AGENT_WORKER-Thread-9 INFO:Local step 19500, global step 316314: loss 1.0245
[2017-11-02 10:43:55,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.63380735e-07   2.96763801e-07   7.08278094e-06   3.97404983e-06
   1.94639620e-06   9.07906830e-01   3.29636969e-02   5.59329949e-02
   3.18279723e-03], sum to 1.0000
[2017-11-02 10:43:55,461] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [3.333333333333333, 100.0, 2.766666666666667, 353.3333333333334, 177.8333333333333, 0.0, -1.75, 46.34907891137051, 18.0, 18.77812352964702, 20.56, 1.0, 0.0], 
actual action is [8.333333333333332, 18.5], 
sim time next is 6009900.0000, 
raw observation next is [3.416666666666667, 100.0, 2.933333333333333, 354.1666666666666, 176.9166666666667, 0.0, 8.333333333333332, 41.32665673342515, 18.5, 18.7528790770214, 20.56, 1.0, 73.41086338029436], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.42094017094017094, 1.0, 0.26666666666666666, 0.9837962962962961, 0.4680335097001765, 0.0, 0.6388888888888888, 0.41326656733425154, 0.07142857142857142, 0.10755415386020013, 0.36571428571428555, 1.0, 0.8636572162387571], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:56,423] A3C_AGENT_WORKER-Thread-10 INFO:Local step 20000, global step 317255: loss 87.4977
[2017-11-02 10:43:56,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  6.97635114e-01   4.15180661e-02   1.34980902e-01   8.63553211e-02
   3.93325128e-02   6.79777586e-05   4.89989761e-05   4.68065446e-05
   1.42775862e-05], sum to 1.0000
[2017-11-02 10:43:56,458] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 64.0, 2.1, 316.6666666666667, 90.00000000000001, 0.0, 0.0, 12.27944982338872, 18.0, 20.5665766525945, 19.4, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 5904900.0000, 
raw observation next is [5.0, 64.0, 2.1, 315.0, 93.0, 0.0, 0.0, 11.96177051258663, 18.0, 20.64680283638245, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.46153846153846156, 0.64, 0.19090909090909092, 0.875, 0.24603174603174602, 0.0, 0.5, 0.11961770512586631, 0.0, 0.3781146909117784, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:57,959] A3C_AGENT_WORKER-Thread-3 INFO:Local step 20000, global step 317995: loss 11.4473
[2017-11-02 10:43:58,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.19901748  0.08707508  0.39650604  0.18688725  0.07087949  0.01582462
  0.01345666  0.02170283  0.00865054], sum to 1.0000
[2017-11-02 10:43:58,614] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.333333333333334, 62.0, 2.766666666666667, 326.6666666666667, 0.0, 0.0, 1.416666666666666, 7.125141222051801, 18.0, 21.60605022724224, 19.4, 0.0, 0.0], 
actual action is [1.333333333333334, 18], 
sim time next is 5892300.0000, 
raw observation next is [6.25, 61.5, 2.725, 330.0, 0.0, 0.0, 1.333333333333334, 7.232927452039942, 18.0, 21.5736645201882, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.4935897435897436, 0.615, 0.24772727272727274, 0.9166666666666666, 0.0, 0.0, 0.5222222222222223, 0.07232927452039942, 0.0, 0.5105235028840285, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:59,243] A3C_AGENT_WORKER-Thread-8 INFO:Local step 20000, global step 318559: loss 292.3623
[2017-11-02 10:44:01,486] A3C_AGENT_WORKER-Thread-4 INFO:Local step 20000, global step 319278: loss 1785.5681
[2017-11-02 10:44:04,036] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99924064e-01   1.14865138e-07   4.41991051e-06   7.03930273e-05
   9.25220377e-07   6.53744909e-18   5.10426620e-17   3.69784409e-17
   2.49180777e-18], sum to 1.0000
[2017-11-02 10:44:04,041] A3C_AGENT_WORKER-Thread-13 INFO:Local step 20000, global step 319979: loss -33.5396
[2017-11-02 10:44:04,061] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 3.766666666666667, 246.6666666666667, 0.0, 0.0, -4.0, 31.080137465217, 18.0, 19.12881552411473, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 5978700.0000, 
raw observation next is [1.0, 86.0, 3.725, 275.0, 0.0, 0.0, -4.0, 32.71627668516479, 18.0, 18.96659404374463, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.358974358974359, 0.86, 0.3386363636363636, 0.7638888888888888, 0.0, 0.0, 0.43333333333333335, 0.3271627668516479, 0.0, 0.13808486339209022, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0619. 
=============================================
[2017-11-02 10:44:05,083] A3C_AGENT_WORKER-Thread-5 INFO:Local step 20000, global step 320265: loss -24.8212
[2017-11-02 10:44:06,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999166e-01   1.01126468e-10   1.60723115e-08   8.92970945e-07
   1.09293374e-09   3.90818995e-30   1.47299648e-28   1.21657769e-27
   1.15889201e-29], sum to 1.0000
[2017-11-02 10:44:06,251] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 3.066666666666666, 14.16666666666667, 0.0, 0.0, -3.0, 24.12991640426555, 18.0, 19.1342178071912, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5952600.0000, 
raw observation next is [2.0, 80.0, 3.0, 15.0, 0.0, 0.0, -3.0, 24.43586347082307, 18.0, 19.10395018635953, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.38461538461538464, 0.8, 0.2727272727272727, 0.041666666666666664, 0.0, 0.0, 0.45, 0.2443586347082307, 0.0, 0.15770716947993282, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:06,638] A3C_AGENT_WORKER-Thread-2 INFO:Local step 20000, global step 320647: loss -54.3584
[2017-11-02 10:44:07,033] A3C_AGENT_WORKER-Thread-17 INFO:Local step 20000, global step 320757: loss 87.1473
[2017-11-02 10:44:08,464] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-90.34597778]
 [-85.7006073 ]
 [-87.05731201]
 [-85.13450623]
 [-85.66706848]], R is [[-89.9066391 ]
 [-90.00757599]
 [-90.10749817]
 [-90.2064209 ]
 [-90.30435944]].
[2017-11-02 10:44:09,716] A3C_AGENT_WORKER-Thread-7 INFO:Local step 20000, global step 321429: loss -37.2831
[2017-11-02 10:44:11,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 20000, global step 321796: loss -115.8394
[2017-11-02 10:44:12,340] A3C_AGENT_WORKER-Thread-12 INFO:Local step 20000, global step 322037: loss 54.6901
[2017-11-02 10:44:12,568] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-78.82019806]
 [-76.72580719]
 [-75.18088531]
 [-85.3200531 ]
 [-84.83330536]], R is [[-78.69782257]
 [-78.22932434]
 [-77.44702911]
 [-76.67256165]
 [-75.90583801]].
[2017-11-02 10:44:12,750] A3C_AGENT_WORKER-Thread-14 INFO:Local step 20000, global step 322133: loss 112.6670
[2017-11-02 10:44:13,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99915719e-01   4.24319140e-08   5.02904913e-06   7.87492318e-05
   4.82446524e-07   1.71654390e-16   1.63848211e-15   8.78915606e-15
   1.53719804e-16], sum to 1.0000
[2017-11-02 10:44:13,693] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.25, 100.0, 2.6, 352.5, 178.75, 0.0, -1.833333333333333, 29.06234032078585, 18.0, 20.2278169161327, 20.56, 1.0, 0.0], 
actual action is [-1.75, 18], 
sim time next is 6009600.0000, 
raw observation next is [3.333333333333333, 100.0, 2.766666666666667, 353.3333333333334, 177.8333333333333, 0.0, -1.75, 29.56552844260617, 18.0, 20.18381631009061, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.41880341880341876, 1.0, 0.2515151515151515, 0.9814814814814817, 0.470458553791887, 0.0, 0.4708333333333333, 0.2956552844260617, 0.0, 0.31197375858437276, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:14,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 20000, global step 322788: loss 134.4304
[2017-11-02 10:44:14,999] A3C_AGENT_WORKER-Thread-9 INFO:Local step 20000, global step 322805: loss 115.8343
[2017-11-02 10:44:16,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   2.86943971e-12   5.97856209e-10   1.46179495e-08
   2.50146362e-11   2.84444121e-33   2.68256370e-33   2.09416155e-33
   1.08501561e-34], sum to 1.0000
[2017-11-02 10:44:16,741] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.416666666666666, 97.08333333333333, 1.75, 159.1666666666667, 0.0, 0.0, 1.333333333333333, 36.14707554619915, 18.0, 19.48290419790056, 19.4, 0.0, 0.0], 
actual action is [1.416666666666666, 18], 
sim time next is 6031800.0000, 
raw observation next is [6.5, 96.5, 1.8, 185.0, 0.0, 0.0, 1.416666666666666, 36.45893012905155, 18.0, 19.4848531772341, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.5, 0.965, 0.16363636363636364, 0.5138888888888888, 0.0, 0.0, 0.523611111111111, 0.36458930129051553, 0.0, 0.21212188246201436, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:44:18,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-39.02795792]
 [-40.60638046]
 [-40.52429962]
 [-39.77461624]
 [-42.64696121]], R is [[-40.96496201]
 [-40.59728241]
 [-40.2313118 ]
 [-39.86688232]
 [-39.50378036]].
[2017-11-02 10:44:18,742] A3C_AGENT_WORKER-Thread-6 INFO:Local step 20500, global step 323994: loss -8.1551
[2017-11-02 10:44:20,622] A3C_AGENT_WORKER-Thread-16 INFO:Local step 20500, global step 324498: loss 0.6851
[2017-11-02 10:44:25,092] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99641538e-01   2.98573255e-08   2.24727842e-06   3.55947530e-04
   2.93611635e-07   4.40314885e-13   1.03586559e-13   5.92612973e-11
   1.62279668e-13], sum to 1.0000
[2017-11-02 10:44:25,131] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 6.2, 330.0, 130.5, 0.0, 4.0, 28.10529589767519, 19.0, 20.33073497790326, 20.56, 1.0, 70.3339422042077], 
actual action is [-6.0, 18], 
sim time next is 6091500.0000, 
raw observation next is [-1.0, 78.0, 6.241666666666667, 329.1666666666667, 129.75, 0.0, -6.0, 29.57693929851997, 18.0, 20.4676827529192, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3076923076923077, 0.78, 0.5674242424242425, 0.9143518518518519, 0.34325396825396826, 0.0, 0.4, 0.2957693929851997, 0.0, 0.35252610755988556, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:25,657] A3C_AGENT_WORKER-Thread-10 INFO:Local step 20500, global step 325435: loss 94.3796
[2017-11-02 10:44:29,576] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.63624807e-32   2.19463115e-24   8.08143127e-23   1.79369818e-20
   1.84001112e-23   1.12669449e-03   5.36241423e-05   9.98277426e-01
   5.42179972e-04], sum to 1.0000
[2017-11-02 10:44:29,609] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.0, 52.0, 5.833333333333334, 310.0, 171.1666666666667, 227.3333333333333, -3.0, 30.2698684470441, 18.0, 20.77884831985458, 20.56, 1.0, 0.0], 
actual action is [7.0, 20.0], 
sim time next is 6107100.0000, 
raw observation next is [2.0, 52.0, 5.741666666666666, 310.0, 161.5833333333333, 234.1666666666667, 7.0, 28.87249001795874, 20.0, 20.72777818120061, 20.56, 1.0, 33.13414716773921], 
processed observation next is [1.0, 0.6956521739130435, 0.38461538461538464, 0.52, 0.521969696969697, 0.8611111111111112, 0.42746913580246904, 0.23416666666666672, 0.6166666666666667, 0.2887249001795874, 0.2857142857142857, 0.3896825973143727, 0.36571428571428555, 1.0, 0.3898134960910495], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:29,795] A3C_AGENT_WORKER-Thread-8 INFO:Local step 20500, global step 326500: loss 238.1097
[2017-11-02 10:44:29,929] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-75.03417969]
 [-74.38314819]
 [-72.48001099]
 [-71.90705872]
 [-70.90908813]], R is [[-68.68501282]
 [-68.99816132]
 [-69.30818176]
 [-69.61509705]
 [-69.91894531]].
[2017-11-02 10:44:30,187] A3C_AGENT_WORKER-Thread-3 INFO:Local step 20500, global step 326593: loss 46.2362
[2017-11-02 10:44:31,491] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   4.62062517e-13   3.11350182e-11   2.20052399e-09
   1.92656828e-12   2.77619508e-35   1.08472120e-35   1.05243231e-33
   4.01465149e-36], sum to 1.0000
[2017-11-02 10:44:31,504] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 47.0, 2.266666666666667, 183.3333333333333, 0.0, 0.0, 1.0, 26.74026007335554, 18.0, 20.53585442276168, 22.2, 1.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6200700.0000, 
raw observation next is [6.0, 47.0, 2.308333333333334, 184.1666666666667, 0.0, 0.0, 1.0, 27.13886405691137, 18.0, 20.48343359941861, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.48717948717948717, 0.47, 0.20984848484848492, 0.5115740740740742, 0.0, 0.0, 0.5166666666666667, 0.2713886405691137, 0.0, 0.3547762284883729, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:33,536] A3C_AGENT_WORKER-Thread-4 INFO:Local step 20500, global step 327515: loss 58.3958
[2017-11-02 10:44:35,833] A3C_AGENT_WORKER-Thread-13 INFO:Local step 20500, global step 328079: loss 148.6582
[2017-11-02 10:44:36,193] A3C_AGENT_WORKER-Thread-5 INFO:Local step 20500, global step 328181: loss 6.0240
[2017-11-02 10:44:37,302] A3C_AGENT_WORKER-Thread-7 INFO:Local step 20500, global step 328473: loss 42.4434
[2017-11-02 10:44:37,515] A3C_AGENT_WORKER-Thread-17 INFO:Local step 20500, global step 328523: loss -1.6202
[2017-11-02 10:44:39,031] A3C_AGENT_WORKER-Thread-2 INFO:Local step 20500, global step 328919: loss 23.0672
[2017-11-02 10:44:40,157] A3C_AGENT_WORKER-Thread-15 INFO:Local step 20500, global step 329278: loss 147.5588
[2017-11-02 10:44:41,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 20500, global step 329672: loss -23.3509
[2017-11-02 10:44:43,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.72979313e-02   4.65172570e-06   1.45961705e-04   4.88191564e-03
   2.20140682e-05   8.30847491e-03   2.55974545e-03   8.96765649e-01
   1.36989129e-05], sum to 1.0000
[2017-11-02 10:44:43,474] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 43.29821987718269, 20.0, 18.5400780465721, 19.4, 0.0, 100.497156416691], 
actual action is [2.0, 22.0], 
sim time next is 6143400.0000, 
raw observation next is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 38.91420801202413, 22.0, 18.73928374471598, 19.4, 0.0, 63.13818523730034], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.71, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5333333333333333, 0.3891420801202413, 0.5714285714285714, 0.10561196353085427, 0.1999999999999998, 0.0, 0.7428021792623569], 
reward next is -0.7629. 
=============================================
[2017-11-02 10:44:44,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.41481296e-13   1.30493468e-12   1.93941530e-10
   5.50625138e-13   2.49762915e-27   2.09392142e-26   4.93744159e-23
   1.07588656e-26], sum to 1.0000
[2017-11-02 10:44:44,338] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 44.0, 4.1, 210.0, 263.5, 468.5, 1.916666666666666, 14.53786224720442, 18.0, 22.28536686185976, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6185100.0000, 
raw observation next is [6.999999999999999, 43.99999999999999, 4.058333333333333, 210.0, 270.4166666666667, 428.0833333333334, 2.0, 14.44736806782693, 18.0, 22.30381824355852, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 0.43999999999999995, 0.3689393939393939, 0.5833333333333334, 0.7153880070546738, 0.4280833333333334, 0.5333333333333333, 0.1444736806782693, 0.0, 0.6148311776512172, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0144. 
=============================================
[2017-11-02 10:44:44,463] A3C_AGENT_WORKER-Thread-11 INFO:Local step 20500, global step 330694: loss 4.0147
[2017-11-02 10:44:44,725] A3C_AGENT_WORKER-Thread-12 INFO:Local step 20500, global step 330789: loss 9.1967
[2017-11-02 10:44:44,779] A3C_AGENT_WORKER-Thread-9 INFO:Local step 20500, global step 330809: loss 116.8342
[2017-11-02 10:44:45,406] A3C_AGENT_WORKER-Thread-6 INFO:Local step 21000, global step 331060: loss 56.2546
[2017-11-02 10:44:45,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   5.54296886e-11   6.13267881e-10   3.49597862e-08
   2.39617409e-10   4.93905020e-20   6.11585343e-19   3.74481414e-18
   5.86220574e-19], sum to 1.0000
[2017-11-02 10:44:45,908] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 44.0, 3.891666666666666, 210.0, 298.0833333333333, 266.4166666666667, 2.0, 15.29946383024414, 18.0, 22.16141840735889, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6186600.0000, 
raw observation next is [7.0, 44.0, 3.85, 210.0, 305.0, 226.0, 2.0, 15.22398937156119, 18.0, 22.18424871516814, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 0.44, 0.35000000000000003, 0.5833333333333334, 0.8068783068783069, 0.226, 0.5333333333333333, 0.1522398937156119, 0.0, 0.5977498164525912, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:45,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99999881e-01   1.15476032e-10   8.36653191e-10   6.44659295e-08
   5.37454303e-10   3.48296073e-15   4.66214117e-14   5.09089570e-13
   5.71775632e-14], sum to 1.0000
[2017-11-02 10:44:45,959] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 50.33333333333334, 6.0, 210.0, 143.8333333333333, 846.3333333333334, 5.75, 14.15009630654616, 18.0, 22.5246097790595, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6263100.0000, 
raw observation next is [11.25, 49.5, 6.300000000000001, 212.5, 143.75, 847.5, 6.0, 14.0934828621868, 18.0, 22.52494395005282, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.6217948717948718, 0.495, 0.5727272727272728, 0.5902777777777778, 0.3802910052910053, 0.8475, 0.6, 0.140934828621868, 0.0, 0.6464205642932599, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0141. 
=============================================
[2017-11-02 10:44:47,682] A3C_AGENT_WORKER-Thread-16 INFO:Local step 21000, global step 331961: loss 84.4276
[2017-11-02 10:44:49,187] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   4.36902638e-16   9.78431644e-15   2.51234363e-13
   1.27779536e-15   9.28037723e-36   9.13643801e-34   3.70321401e-36
   3.25990685e-36], sum to 1.0000
[2017-11-02 10:44:49,198] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 67.0, 4.308333333333333, 184.1666666666667, 0.0, 0.0, -4.0, 44.96751863819478, 18.0, 18.59782395020427, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 6237000.0000, 
raw observation next is [1.0, 67.0, 4.35, 185.0, 0.0, 0.0, -4.0, 46.1815732458164, 18.0, 18.52432895925332, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.358974358974359, 0.67, 0.39545454545454545, 0.5138888888888888, 0.0, 0.0, 0.43333333333333335, 0.46181573245816404, 0.0, 0.0749041370361887, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:50,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 21000, global step 332936: loss 34.8099
[2017-11-02 10:44:51,795] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.75132721e-18   7.46221534e-17   2.28870962e-14
   6.41579647e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:44:51,837] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 72.66666666666667, 2.533333333333333, 190.0, 71.83333333333333, 69.49999999999999, -3.416666666666667, 36.23163380341082, 18.0, 19.47794184822978, 22.2, 1.0, 0.0], 
actual action is [-3.333333333333333, 18], 
sim time next is 6248700.0000, 
raw observation next is [1.75, 72.75, 2.275, 190.0, 82.75, 104.25, -3.333333333333333, 36.9302385958561, 18.0, 19.45733109001452, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.3782051282051282, 0.7275, 0.20681818181818182, 0.5277777777777778, 0.21891534391534392, 0.10425, 0.4444444444444445, 0.369302385958561, 0.0, 0.20819015571636004, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:52,978] A3C_AGENT_WORKER-Thread-8 INFO:Local step 21000, global step 334145: loss 32.1887
[2017-11-02 10:44:53,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 21000, global step 334320: loss 4.9139
[2017-11-02 10:44:53,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   1.03598411e-13   7.87531498e-13   3.96052191e-10
   1.49279054e-13   2.31911162e-27   7.98452862e-25   2.28035677e-25
   7.33840381e-24], sum to 1.0000
[2017-11-02 10:44:53,732] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 63.0, 4.1, 163.3333333333333, 198.3333333333333, 172.8333333333333, 0.1666666666666661, 23.80990618305795, 18.0, 21.35581643552604, 22.2, 1.0, 0.0], 
actual action is [0.3333333333333339, 18], 
sim time next is 6255900.0000, 
raw observation next is [5.5, 62.25, 4.225, 165.0, 202.5, 219.25, 0.3333333333333339, 23.83292083616794, 18.0, 21.30794441671967, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.47435897435897434, 0.6225, 0.38409090909090904, 0.4583333333333333, 0.5357142857142857, 0.21925, 0.5055555555555556, 0.2383292083616794, 0.0, 0.4725634881028102, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:53,913] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   5.45792015e-14   4.52143184e-12   6.71326772e-10
   1.66167305e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:44:53,924] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.666666666666667, 57.33333333333334, 3.1, 190.0, 0.0, 0.0, 1.75, 27.75966675803836, 18.0, 20.19012428094384, 22.2, 1.0, 0.0], 
actual action is [1.666666666666667, 18], 
sim time next is 6308700.0000, 
raw observation next is [6.583333333333333, 57.66666666666666, 3.1, 190.0, 0.0, 0.0, 1.666666666666667, 27.97430749519495, 18.0, 20.16640405917906, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.0, 0.5021367521367521, 0.5766666666666665, 0.2818181818181818, 0.5277777777777778, 0.0, 0.0, 0.5277777777777778, 0.2797430749519495, 0.0, 0.30948629416843737, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:55,670] A3C_AGENT_WORKER-Thread-4 INFO:Local step 21000, global step 335275: loss 81.3218
[2017-11-02 10:44:58,148] A3C_AGENT_WORKER-Thread-7 INFO:Local step 21000, global step 336462: loss 6.3155
[2017-11-02 10:44:58,321] A3C_AGENT_WORKER-Thread-5 INFO:Local step 21000, global step 336548: loss 14.0552
[2017-11-02 10:44:58,360] A3C_AGENT_WORKER-Thread-13 INFO:Local step 21000, global step 336565: loss 35.0302
[2017-11-02 10:44:59,335] A3C_AGENT_WORKER-Thread-17 INFO:Local step 21000, global step 337046: loss 4.0863
[2017-11-02 10:45:00,724] A3C_AGENT_WORKER-Thread-6 INFO:Local step 21500, global step 337792: loss 10.3640
[2017-11-02 10:45:00,889] A3C_AGENT_WORKER-Thread-2 INFO:Local step 21000, global step 337883: loss 48.0289
[2017-11-02 10:45:00,891] A3C_AGENT_WORKER-Thread-15 INFO:Local step 21000, global step 337883: loss 34.7769
[2017-11-02 10:45:01,530] A3C_AGENT_WORKER-Thread-14 INFO:Local step 21000, global step 338265: loss 8.0511
[2017-11-02 10:45:02,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.87707028e-13   2.49636227e-12   1.34573706e-11
   5.53218983e-13   1.01444682e-37   4.77742026e-36   3.25019352e-38
   4.47050392e-38], sum to 1.0000
[2017-11-02 10:45:02,077] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.083333333333334, 59.66666666666667, 3.1, 190.0, 0.0, 0.0, 1.166666666666666, 31.91439608221798, 18.0, 19.83518845952506, 22.2, 1.0, 0.0], 
actual action is [1.083333333333334, 18], 
sim time next is 6310800.0000, 
raw observation next is [6.0, 60.0, 3.1, 190.0, 0.0, 0.0, 1.083333333333334, 32.15043457346499, 18.0, 19.80895768096151, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.48717948717948717, 0.6, 0.2818181818181818, 0.5277777777777778, 0.0, 0.0, 0.5180555555555556, 0.3215043457346499, 0.0, 0.2584225258516441, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:03,158] A3C_AGENT_WORKER-Thread-16 INFO:Local step 21500, global step 339202: loss 0.2817
[2017-11-02 10:45:03,616] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99226928e-01   4.98448135e-05   3.04801157e-04   3.70035472e-04
   4.83473850e-05   4.09377006e-16   1.23911158e-15   2.27449655e-16
   7.54664335e-17], sum to 1.0000
[2017-11-02 10:45:03,629] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.0, 47.0, 4.85, 192.5, 0.0, 0.0, 9.0, 12.42971568388056, 18.0, 21.61670796873378, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 6405600.0000, 
raw observation next is [14.0, 47.0, 4.766666666666667, 193.3333333333333, 0.0, 0.0, 9.0, 12.4805063396959, 18.0, 21.60708680207852, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.13043478260869565, 0.6923076923076923, 0.47, 0.43333333333333335, 0.5370370370370369, 0.0, 0.0, 0.65, 0.124805063396959, 0.0, 0.5152981145826457, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 10:45:03,824] A3C_AGENT_WORKER-Thread-12 INFO:Local step 21000, global step 339613: loss 9.2390
[2017-11-02 10:45:03,992] A3C_AGENT_WORKER-Thread-11 INFO:Local step 21000, global step 339717: loss 7.4480
[2017-11-02 10:45:04,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 21000, global step 339924: loss 14.6752
[2017-11-02 10:45:04,716] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   3.64385524e-13   1.31380540e-12   2.71872152e-12
   1.35746029e-13   5.68586730e-30   2.01667645e-29   1.09358132e-31
   4.81703126e-32], sum to 1.0000
[2017-11-02 10:45:04,724] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 95.33333333333334, 6.783333333333333, 341.6666666666667, 0.0, 0.0, -6.0, 43.24253484876867, 18.0, 17.53542721035662, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 6496800.0000, 
raw observation next is [-1.0, 94.66666666666666, 6.866666666666667, 343.3333333333333, 0.0, 0.0, -6.0, 44.50735602729551, 18.0, 17.50593997736037, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.3076923076923077, 0.9466666666666665, 0.6242424242424243, 0.9537037037037036, 0.0, 0.0, 0.4, 0.4450735602729551, 0.0, -0.07058000323423284, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:04,773] A3C_AGENT_WORKER-Thread-10 INFO:Local step 21500, global step 340174: loss 4.2069
[2017-11-02 10:45:05,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   3.33040440e-09   6.61342481e-10   1.83899940e-09
   1.14730980e-09   9.78309027e-14   2.80725882e-13   2.90585359e-14
   3.88754030e-15], sum to 1.0000
[2017-11-02 10:45:05,636] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.25, 40.66666666666666, 6.533333333333333, 224.1666666666667, 152.25, 782.9166666666666, 9.0, 14.23728934559373, 18.0, 22.39396858231016, 22.2, 1.0, 0.0], 
actual action is [9.25, 18], 
sim time next is 6345000.0000, 
raw observation next is [14.5, 40.0, 6.7, 225.0, 150.0, 800.0, 9.25, 13.90422245305797, 18.0, 22.45211076859963, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.43478260869565216, 0.7051282051282052, 0.4, 0.6090909090909091, 0.625, 0.3968253968253968, 0.8, 0.6541666666666667, 0.1390422245305797, 0.0, 0.6360158240856616, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 10:45:07,462] A3C_AGENT_WORKER-Thread-3 INFO:Local step 21500, global step 341679: loss 0.0242
[2017-11-02 10:45:07,534] A3C_AGENT_WORKER-Thread-8 INFO:Local step 21500, global step 341723: loss 9.2584
[2017-11-02 10:45:07,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99993563e-01   2.09057703e-06   1.24839778e-06   1.91698769e-06
   1.13461704e-06   2.44997653e-13   3.80857780e-13   6.02935602e-14
   2.42085032e-14], sum to 1.0000
[2017-11-02 10:45:07,846] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [18.08333333333334, 33.83333333333333, 5.95, 220.8333333333333, 37.91666666666667, 141.1666666666667, 13.16666666666666, 6.451452520318807, 18.0, 24.44801497381961, 22.2, 1.0, 0.0], 
actual action is [13.08333333333334, 18], 
sim time next is 6372000.0000, 
raw observation next is [18.0, 34.0, 5.7, 220.0, 32.5, 121.0, 13.08333333333334, 6.437091237137609, 18.0, 24.39358690897077, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.7948717948717948, 0.34, 0.5181818181818182, 0.6111111111111112, 0.08597883597883597, 0.121, 0.7180555555555557, 0.06437091237137609, 0.0, 0.9133695584243959, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0064. 
=============================================
[2017-11-02 10:45:09,606] A3C_AGENT_WORKER-Thread-4 INFO:Local step 21500, global step 342875: loss 1.1422
[2017-11-02 10:45:11,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-8.48625278]
 [-8.36796856]
 [-8.2950964 ]
 [-9.1328516 ]
 [-9.44636726]], R is [[-8.28521729]
 [-8.21064281]
 [-8.13674927]
 [-8.06353092]
 [-7.99098206]].
[2017-11-02 10:45:11,979] A3C_AGENT_WORKER-Thread-13 INFO:Local step 21500, global step 344262: loss 0.9091
[2017-11-02 10:45:12,074] A3C_AGENT_WORKER-Thread-5 INFO:Local step 21500, global step 344328: loss 3.0390
[2017-11-02 10:45:12,574] A3C_AGENT_WORKER-Thread-7 INFO:Local step 21500, global step 344629: loss -1.5070
[2017-11-02 10:45:13,254] A3C_AGENT_WORKER-Thread-17 INFO:Local step 21500, global step 344990: loss 0.3783
[2017-11-02 10:45:14,013] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.80854414e-13   1.81033452e-11   7.83498960e-11
   1.17811122e-10   1.96095510e-37   4.72349130e-36   0.00000000e+00
   8.55946117e-38], sum to 1.0000
[2017-11-02 10:45:14,046] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.875, 63.5, 2.55, 65.0, 0.0, 0.0, -10.83333333333333, 63.12124601114687, 18.0, 16.90693054995764, 19.4, 0.0, 0.0], 
actual action is [-10.875, 18], 
sim time next is 6576600.0000, 
raw observation next is [-5.916666666666666, 63.66666666666666, 2.566666666666667, 66.66666666666667, 0.0, 0.0, -10.875, 64.83928823001439, 18.0, 16.94041181070921, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.18162393162393164, 0.6366666666666666, 0.23333333333333336, 0.1851851851851852, 0.0, 0.0, 0.31875, 0.6483928823001439, 0.0, -0.15136974132725559, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:14,164] A3C_AGENT_WORKER-Thread-2 INFO:Local step 21500, global step 345510: loss 0.4249
[2017-11-02 10:45:14,723] A3C_AGENT_WORKER-Thread-14 INFO:Local step 21500, global step 345829: loss 9.9662
[2017-11-02 10:45:14,780] A3C_AGENT_WORKER-Thread-15 INFO:Local step 21500, global step 345862: loss 6.5301
[2017-11-02 10:45:16,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   3.30808400e-15   8.16585027e-14   2.83575951e-13
   3.89132560e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:16,079] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.916666666666667, 54.08333333333334, 2.808333333333334, 39.16666666666668, 0.0, 0.0, -8.833333333333332, 56.11833422419326, 18.0, 17.671733365795, 19.4, 0.0, 0.0], 
actual action is [-8.916666666666668, 18], 
sim time next is 6562800.0000, 
raw observation next is [-4.0, 54.0, 2.6, 10.0, 0.0, 0.0, -8.916666666666668, 57.61714367643913, 18.0, 17.58724748144612, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.23076923076923078, 0.54, 0.23636363636363636, 0.027777777777777776, 0.0, 0.0, 0.35138888888888886, 0.5761714367643913, 0.0, -0.05896464550769715, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:17,293] A3C_AGENT_WORKER-Thread-11 INFO:Local step 21500, global step 347141: loss 67.8563
[2017-11-02 10:45:17,376] A3C_AGENT_WORKER-Thread-12 INFO:Local step 21500, global step 347181: loss 23.7765
[2017-11-02 10:45:17,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.38550389e-01   3.07938568e-02   5.51895276e-02   4.35979292e-02
   3.16168480e-02   8.18211847e-05   1.10520712e-04   4.43667741e-05
   1.47338878e-05], sum to 1.0000
[2017-11-02 10:45:17,463] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 100.0, 4.6, 180.0, 119.5, 0.0, 6.0, 8.848896431230049, 18.0, 21.80559502593556, 19.4, 0.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6444300.0000, 
raw observation next is [11.0, 99.99999999999999, 4.216666666666666, 165.0, 118.75, 0.0, 6.0, 8.889922056366505, 18.0, 21.78265604711057, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.6153846153846154, 0.9999999999999999, 0.38333333333333325, 0.4583333333333333, 0.31415343915343913, 0.0, 0.6, 0.08889922056366505, 0.0, 0.5403794353015101, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:45:18,003] A3C_AGENT_WORKER-Thread-9 INFO:Local step 21500, global step 347471: loss 2.2970
[2017-11-02 10:45:18,485] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.92871456e-12   1.73562965e-12   2.57127739e-11
   9.20124654e-12   1.00255709e-34   8.93975576e-33   8.78672385e-35
   1.00598967e-34], sum to 1.0000
[2017-11-02 10:45:18,508] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 51.66666666666666, 5.649999999999999, 339.9999999999999, 126.6666666666667, 767.4166666666667, -3.0, 22.80831616608955, 18.0, 21.34643983229221, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 6534600.0000, 
raw observation next is [2.0, 51.33333333333334, 5.6, 340.0000000000001, 125.3333333333333, 762.3333333333334, -3.0, 22.61471366517574, 18.0, 21.34389913068911, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.38461538461538464, 0.5133333333333334, 0.509090909090909, 0.9444444444444448, 0.33156966490299816, 0.7623333333333334, 0.45, 0.2261471366517574, 0.0, 0.47769987581272993, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:19,360] A3C_AGENT_WORKER-Thread-6 INFO:Local step 22000, global step 348014: loss 58.2301
[2017-11-02 10:45:22,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 22000, global step 349262: loss 48.6075
[2017-11-02 10:45:23,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   4.60579713e-10   1.85320287e-10   2.27231700e-09
   9.64511471e-10   2.00150578e-25   2.11579068e-21   2.02397348e-23
   3.40486124e-23], sum to 1.0000
[2017-11-02 10:45:23,490] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6666666666666667, 60.00000000000001, 7.9, 336.6666666666667, 274.5, 552.6666666666666, -5.75, 30.03927667070831, 18.0, 20.14022459882145, 22.2, 1.0, 0.0], 
actual action is [-5.666666666666667, 18], 
sim time next is 6521100.0000, 
raw observation next is [-0.5833333333333333, 59.99999999999999, 8.075, 338.3333333333333, 270.75, 595.8333333333334, -5.666666666666667, 30.12255548569571, 18.0, 20.08368304935159, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.31837606837606836, 0.6, 0.734090909090909, 0.9398148148148148, 0.7162698412698413, 0.5958333333333333, 0.40555555555555556, 0.3012255548569571, 0.0, 0.2976690070502269, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:24,455] A3C_AGENT_WORKER-Thread-10 INFO:Local step 22000, global step 349873: loss -185.0105
[2017-11-02 10:45:25,892] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.58640568e-05   9.99647021e-01   2.59133929e-04
   3.80030797e-05], sum to 1.0000
[2017-11-02 10:45:25,953] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.166666666666667, 54.83333333333334, 3.558333333333333, 105.8333333333333, 101.6666666666667, 467.75, -10.33333333333333, 38.67986744326045, 18.0, 19.2714816821913, 19.4, 0.0, 0.0], 
actual action is [-0.16666666666666696, 19.0], 
sim time next is 6595200.0000, 
raw observation next is [-5.0, 54.0, 3.6, 110.0, 104.0, 492.5, -0.166666666666667, 36.87875169073572, 19.0, 19.23249509714838, 19.4, 0.0, 62.06141320540256], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.20512820512820512, 0.54, 0.32727272727272727, 0.3055555555555556, 0.2751322751322751, 0.4925, 0.4972222222222222, 0.36878751690735717, 0.14285714285714285, 0.1760707281640543, 0.1999999999999998, 0.0, 0.730134273004736], 
reward next is -0.6811. 
=============================================
[2017-11-02 10:45:26,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   8.01252619e-13   2.82677365e-13   4.08402565e-12
   4.51138530e-13   4.74400842e-27   5.08423283e-23   1.48848266e-25
   4.43472610e-26], sum to 1.0000
[2017-11-02 10:45:26,346] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.25, 51.0, 5.1, 357.5, 41.25, 310.5, -4.666666666666667, 21.25849144285257, 18.0, 21.16764764166647, 22.2, 1.0, 0.0], 
actual action is [-4.75, 18], 
sim time next is 6544200.0000, 
raw observation next is [0.1666666666666666, 51.0, 5.1, 358.3333333333333, 36.66666666666667, 276.0000000000001, -4.75, 22.06084486616657, 18.0, 21.06732104762575, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.3376068376068376, 0.51, 0.4636363636363636, 0.9953703703703703, 0.09700176366843034, 0.27600000000000013, 0.42083333333333334, 0.22060844866166568, 0.0, 0.4381887210893929, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:27,974] A3C_AGENT_WORKER-Thread-3 INFO:Local step 22000, global step 350983: loss 127.3375
[2017-11-02 10:45:28,066] A3C_AGENT_WORKER-Thread-8 INFO:Local step 22000, global step 351019: loss -70.9133
[2017-11-02 10:45:29,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.82997846e-05   9.99948025e-01   3.21288862e-05
   1.54377847e-06], sum to 1.0000
[2017-11-02 10:45:29,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.99212289e-16   1.23852363e-16   8.88784154e-16
   1.72762005e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:29,147] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 47.5, 5.1, 120.0, 0.0, 0.0, -2.916666666666667, 49.09181935211235, 18.0, 18.87118930728144, 19.4, 0.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 6650100.0000, 
raw observation next is [2.25, 47.25, 5.1, 120.0, 0.0, 0.0, -2.833333333333333, 49.49648973397463, 18.0, 18.88011504200668, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.391025641025641, 0.4725, 0.4636363636363636, 0.3333333333333333, 0.0, 0.0, 0.4527777777777778, 0.49496489733974625, 0.0, 0.12573072028666843, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0743. 
=============================================
[2017-11-02 10:45:29,222] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.833333333333334, 63.33333333333333, 2.533333333333333, 63.33333333333333, 0.0, 0.0, -10.79166666666667, 56.51736836123947, 18.0, 17.60672354386774, 19.4, 0.0, 0.0], 
actual action is [-0.8333333333333339, 19.0], 
sim time next is 6576300.0000, 
raw observation next is [-5.875, 63.5, 2.55, 65.0, 0.0, 0.0, -0.8333333333333339, 51.75884979262435, 19.0, 17.63040471101596, 19.4, 0.0, 80.18537810063958], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.18269230769230768, 0.635, 0.2318181818181818, 0.18055555555555555, 0.0, 0.0, 0.48611111111111105, 0.5175884979262435, 0.14285714285714285, -0.05279932699772009, 0.1999999999999998, 0.0, 0.9433573894192891], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:29,482] A3C_AGENT_WORKER-Thread-4 INFO:Local step 22000, global step 351536: loss -99.3698
[2017-11-02 10:45:30,939] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-84.18602753]
 [-84.43808746]
 [-83.18393707]
 [-82.02167511]
 [-85.4812851 ]], R is [[-84.54214478]
 [-84.69672394]
 [-84.84975433]
 [-85.00125885]
 [-85.15124512]].
[2017-11-02 10:45:31,265] A3C_AGENT_WORKER-Thread-5 INFO:Local step 22000, global step 352106: loss 46.5493
[2017-11-02 10:45:33,223] A3C_AGENT_WORKER-Thread-7 INFO:Local step 22000, global step 352701: loss -30.1450
[2017-11-02 10:45:33,815] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99997735e-01   3.65870591e-07   1.05710320e-07   8.48911100e-07
   9.35938431e-07   1.23194532e-12   3.81900556e-08   8.14686079e-12
   2.05721052e-12], sum to 1.0000
[2017-11-02 10:45:33,827] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.999999999999999, 55.99999999999999, 4.975, 130.0, 167.1666666666667, 2.5, 2.0, 30.9918989356306, 18.0, 20.74932850930116, 20.56, 1.0, 0.0], 
actual action is [1.9999999999999991, 18], 
sim time next is 6693000.0000, 
raw observation next is [7.0, 56.0, 4.85, 130.0, 158.3333333333333, 2.0, 1.999999999999999, 32.26749741555542, 18.0, 20.69813273215413, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5128205128205128, 0.56, 0.44090909090909086, 0.3611111111111111, 0.41887125220458543, 0.002, 0.5333333333333333, 0.3226749741555542, 0.0, 0.3854475331648755, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:33,981] A3C_AGENT_WORKER-Thread-13 INFO:Local step 22000, global step 352894: loss -71.4567
[2017-11-02 10:45:34,706] A3C_AGENT_WORKER-Thread-17 INFO:Local step 22000, global step 353078: loss 63.0657
[2017-11-02 10:45:35,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 22000, global step 353189: loss 87.4913
[2017-11-02 10:45:37,229] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-49.78839874]
 [-49.7041626 ]
 [-52.48843002]
 [-49.13278961]
 [-50.55735779]], R is [[-49.10279465]
 [-48.75006866]
 [-48.50049973]
 [-48.0154953 ]
 [-47.92034149]].
[2017-11-02 10:45:37,993] A3C_AGENT_WORKER-Thread-14 INFO:Local step 22000, global step 353773: loss -21.0365
[2017-11-02 10:45:38,065] A3C_AGENT_WORKER-Thread-15 INFO:Local step 22000, global step 353794: loss 16.7722
[2017-11-02 10:45:40,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.14809695e-05   9.99961495e-01   6.92643380e-06
   1.38145225e-07], sum to 1.0000
[2017-11-02 10:45:40,540] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.833333333333333, 49.33333333333333, 4.825, 98.33333333333333, 119.0, 649.8333333333333, 1.0, 24.51648398576416, 20.0, 20.84389267667028, 20.56, 1.0, 39.69300934883285], 
actual action is [1.166666666666667, 21.0], 
sim time next is 6597600.0000, 
raw observation next is [-3.666666666666667, 48.66666666666667, 5.0, 96.66666666666667, 120.0, 658.6666666666667, 1.166666666666667, 24.65795276734935, 21.0, 20.88124700341271, 20.56, 1.0, 34.29163260650049], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.2393162393162393, 0.4866666666666667, 0.45454545454545453, 0.26851851851851855, 0.31746031746031744, 0.6586666666666667, 0.5194444444444445, 0.2465795276734935, 0.42857142857142855, 0.41160671477324434, 0.36571428571428555, 1.0, 0.40343097184118226], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:41,568] A3C_AGENT_WORKER-Thread-11 INFO:Local step 22000, global step 354805: loss 7.7806
[2017-11-02 10:45:41,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   5.88858684e-11   7.27389980e-12   2.78453510e-10
   9.41338257e-11   3.76689867e-15   1.46847170e-11   1.33035613e-14
   1.47486859e-15], sum to 1.0000
[2017-11-02 10:45:42,024] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 44.25, 5.425000000000001, 90.0, 127.0, 720.5, 2.333333333333333, 16.51200989242831, 25.0, 22.14115650245325, 20.56, 1.0, 62.72969118289375], 
actual action is [2.5, 20.0], 
sim time next is 6600000.0000, 
raw observation next is [-2.333333333333333, 43.66666666666667, 5.333333333333334, 90.0, 128.0, 729.3333333333333, 2.5, 16.06583842107203, 20.0, 22.29298897464108, 20.56, 1.0, 50.14453236068061], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.27350427350427353, 0.4366666666666667, 0.4848484848484849, 0.25, 0.3386243386243386, 0.7293333333333333, 0.5416666666666666, 0.1606583842107203, 0.2857142857142857, 0.61328413923444, 0.36571428571428555, 1.0, 0.5899356748315365], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:42,066] A3C_AGENT_WORKER-Thread-12 INFO:Local step 22000, global step 354988: loss -35.6634
[2017-11-02 10:45:42,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 22000, global step 355039: loss -37.4909
[2017-11-02 10:45:42,811] A3C_AGENT_WORKER-Thread-6 INFO:Local step 22500, global step 355307: loss 12.2194
[2017-11-02 10:45:44,416] A3C_AGENT_WORKER-Thread-16 INFO:Local step 22500, global step 356005: loss 5.2013
[2017-11-02 10:45:46,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 22500, global step 356925: loss 1.8160
[2017-11-02 10:45:46,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   8.44388002e-15   8.00280456e-15   2.87068512e-14
   2.10049433e-14   0.00000000e+00   2.60022297e-37   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:46,778] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 45.66666666666666, 4.6, 125.8333333333333, 0.0, 0.0, -3.0, 42.25792489869571, 18.0, 19.62378145508422, 20.56, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 6643800.0000, 
raw observation next is [2.0, 46.0, 4.6, 125.0, 0.0, 0.0, -3.0, 42.53719177182855, 18.0, 19.59658665320232, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.38461538461538464, 0.46, 0.41818181818181815, 0.3472222222222222, 0.0, 0.0, 0.45, 0.42537191771828553, 0.0, 0.2280838076003313, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:48,817] A3C_AGENT_WORKER-Thread-3 INFO:Local step 22500, global step 358095: loss 1.0625
[2017-11-02 10:45:49,262] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   5.11831354e-13   1.39670922e-13   7.11755351e-12
   6.05868220e-12   2.46119177e-31   5.80184778e-27   7.92857059e-30
   1.01043433e-29], sum to 1.0000
[2017-11-02 10:45:49,273] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.16666666666667, 53.5, 6.433333333333334, 118.3333333333333, 117.0, 15.33333333333334, 7.25, 23.36129173911206, 18.0, 21.81221016795316, 20.56, 1.0, 0.0], 
actual action is [7.16666666666667, 18], 
sim time next is 6713700.0000, 
raw observation next is [12.08333333333333, 53.75, 6.566666666666666, 119.1666666666667, 108.25, 13.41666666666667, 7.16666666666667, 23.59066224478273, 18.0, 21.77426664466512, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.643162393162393, 0.5375, 0.5969696969696969, 0.3310185185185186, 0.2863756613756614, 0.01341666666666667, 0.6194444444444446, 0.2359066224478273, 0.0, 0.5391809492378741, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:49,883] A3C_AGENT_WORKER-Thread-8 INFO:Local step 22500, global step 358562: loss 18.0588
[2017-11-02 10:45:50,181] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.16336904e-09   2.02895079e-09   3.31205907e-09
   2.70626881e-08   4.07826615e-19   1.31977024e-16   1.23423862e-20
   1.03984075e-20], sum to 1.0000
[2017-11-02 10:45:50,195] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 4.1, 110.0, 0.0, 0.0, 7.0, 54.69188104027315, 19.0, 17.66088019414582, 19.4, 0.0, 92.84863611226233], 
actual action is [-3.0, 18], 
sim time next is 6670200.0000, 
raw observation next is [2.0, 52.0, 4.1, 110.0, 0.0, 0.0, -3.0, 55.29925169356282, 18.0, 17.8110833307087, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.38461538461538464, 0.52, 0.3727272727272727, 0.3055555555555556, 0.0, 0.0, 0.45, 0.5529925169356282, 0.0, -0.02698809561304267, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:50,819] A3C_AGENT_WORKER-Thread-4 INFO:Local step 22500, global step 359037: loss 0.6236
[2017-11-02 10:45:51,287] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.22978583e-16   3.94997854e-16   2.84757230e-15
   1.59656351e-15   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,302] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.5, 72.5, 7.2, 130.0, 0.0, 0.0, 1.583333333333333, 38.38673215239356, 18.0, 19.61467044429538, 20.56, 1.0, 0.0], 
actual action is [1.5, 18], 
sim time next is 6734100.0000, 
raw observation next is [6.416666666666666, 72.91666666666666, 7.283333333333333, 130.0, 0.0, 0.0, 1.5, 38.618682358692, 18.0, 19.58763021955292, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4978632478632478, 0.7291666666666665, 0.6621212121212121, 0.3611111111111111, 0.0, 0.0, 0.525, 0.38618682358691997, 0.0, 0.22680431707898865, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:51,406] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.86610814e-15   2.64008328e-14   1.92005957e-13
   6.09804769e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,416] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.25, 73.75, 7.45, 130.0, 0.0, 0.0, 1.333333333333334, 39.08960559755273, 18.0, 19.53282473323548, 20.56, 1.0, 0.0], 
actual action is [1.25, 18], 
sim time next is 6735000.0000, 
raw observation next is [6.166666666666666, 74.16666666666666, 7.533333333333333, 130.0, 0.0, 0.0, 1.25, 39.32846480099948, 18.0, 19.50509812579623, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4914529914529914, 0.7416666666666666, 0.6848484848484848, 0.3611111111111111, 0.0, 0.0, 0.5208333333333334, 0.39328464800999474, 0.0, 0.2150140179708901, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:51,585] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   9.14451095e-15   1.61079985e-14   1.86212184e-13
   5.25748743e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,595] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.266666666666667, 65.5, 5.425, 120.0, 73.08333333333333, 0.0, 0.2000000000000002, 44.46714551862868, 18.0, 18.86535001343576, 19.4, 0.0, 0.0], 
actual action is [0.2666666666666666, 18], 
sim time next is 6768600.0000, 
raw observation next is [5.333333333333334, 65.0, 5.450000000000001, 120.0, 79.66666666666667, 0.0, 0.2666666666666666, 43.34936924451858, 18.0, 18.97664981173094, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.47008547008547014, 0.65, 0.49545454545454554, 0.3333333333333333, 0.2107583774250441, 0.0, 0.5044444444444445, 0.43349369244518576, 0.0, 0.13952140167584862, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0605. 
=============================================
[2017-11-02 10:45:52,320] A3C_AGENT_WORKER-Thread-5 INFO:Local step 22500, global step 359798: loss 4.9170
[2017-11-02 10:45:52,663] A3C_AGENT_WORKER-Thread-7 INFO:Local step 22500, global step 359970: loss 132.0398
[2017-11-02 10:45:53,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.50749419e-15   3.88623544e-15   2.86158833e-14
   1.91871868e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:53,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 70.0, 6.7, 130.0, 0.0, 0.0, 2.083333333333333, 38.69604836525768, 18.0, 19.73422192701759, 20.56, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6732300.0000, 
raw observation next is [6.916666666666666, 70.41666666666666, 6.783333333333333, 130.0, 0.0, 0.0, 2.0, 38.90199564135857, 18.0, 19.70949486591163, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5106837606837606, 0.7041666666666666, 0.6166666666666667, 0.3611111111111111, 0.0, 0.0, 0.5333333333333333, 0.38901995641358567, 0.0, 0.24421355227308997, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:53,479] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-86.34331512]
 [-87.48840332]
 [-89.50649261]
 [-85.97711182]
 [-86.87807465]], R is [[-88.03953552]
 [-88.15914154]
 [-88.27754974]
 [-88.39477539]
 [-88.51082611]].
[2017-11-02 10:45:54,915] A3C_AGENT_WORKER-Thread-17 INFO:Local step 22500, global step 361099: loss 11.1426
[2017-11-02 10:45:54,990] A3C_AGENT_WORKER-Thread-13 INFO:Local step 22500, global step 361135: loss 15.1187
[2017-11-02 10:45:55,631] A3C_AGENT_WORKER-Thread-2 INFO:Local step 22500, global step 361458: loss 11.7649
[2017-11-02 10:45:56,079] A3C_AGENT_WORKER-Thread-15 INFO:Local step 22500, global step 361733: loss 1.7384
[2017-11-02 10:45:56,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.65105757e-14   1.76033328e-13   1.90063980e-12
   3.19631881e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:56,220] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 70.0, 5.1, 110.0, 14.0, 0.0, 0.08333333333333304, 52.40038230970158, 18.0, 18.28191506293974, 19.4, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 6764700.0000, 
raw observation next is [5.016666666666667, 69.66666666666666, 5.125, 110.8333333333333, 16.16666666666667, 0.0, 0.0, 51.79740596124874, 18.0, 18.26655681795721, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.46196581196581193, 0.6966666666666665, 0.4659090909090909, 0.3078703703703703, 0.042768959435626114, 0.0, 0.5, 0.5179740596124874, 0.0, 0.03807954542245844, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:56,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   4.07127577e-17   5.16041456e-17   5.07682802e-16
   2.45394497e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:56,427] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.833333333333333, 76.0, 5.1, 120.0, 0.0, 0.0, 0.75, 49.34981340404683, 18.0, 18.46241327669179, 19.4, 0.0, 0.0], 
actual action is [0.833333333333333, 18], 
sim time next is 6749700.0000, 
raw observation next is [5.916666666666667, 75.5, 5.1, 120.0, 0.0, 0.0, 0.833333333333333, 49.44752810129558, 18.0, 18.45263323217292, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.4850427350427351, 0.755, 0.4636363636363636, 0.3333333333333333, 0.0, 0.0, 0.5138888888888888, 0.4944752810129558, 0.0, 0.06466189031041734, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:56,467] A3C_AGENT_WORKER-Thread-14 INFO:Local step 22500, global step 361958: loss 6.4571
[2017-11-02 10:45:57,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.55757066e-20   4.44807125e-21   3.45252883e-19
   2.07320813e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:57,121] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.7, 87.75, 1.875, 55.0, 60.5, 33.25, -2.333333333333333, 37.36436417101884, 18.0, 18.68231288329707, 22.2, 1.0, 0.0], 
actual action is [-2.3, 18], 
sim time next is 6852000.0000, 
raw observation next is [2.733333333333333, 87.66666666666667, 1.9, 56.66666666666667, 67.0, 35.83333333333334, -2.3, 37.79439507463839, 18.0, 19.11202397397822, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.4034188034188034, 0.8766666666666667, 0.17272727272727273, 0.1574074074074074, 0.17724867724867724, 0.03583333333333334, 0.46166666666666667, 0.37794395074638387, 0.0, 0.1588605677111745, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:57,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-43.02247238]
 [-43.21686554]
 [-41.91981125]
 [-41.05225754]
 [-41.75622177]], R is [[-39.72795486]
 [-39.33067703]
 [-38.9373703 ]
 [-38.54799652]
 [-38.16251755]].
[2017-11-02 10:45:57,807] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.59870883e-15   1.18068611e-15   1.21404165e-14
   3.97111704e-15   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:57,818] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 74.0, 4.6, 99.16666666666666, 0.0, 0.0, -2.0, 53.21178462607729, 18.0, 17.73198486244781, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6808200.0000, 
raw observation next is [3.0, 74.0, 4.6, 98.33333333333334, 0.0, 0.0, -2.0, 53.37742439954534, 18.0, 17.71925266306165, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.41025641025641024, 0.74, 0.41818181818181815, 0.2731481481481482, 0.0, 0.0, 0.4666666666666667, 0.5337742439954534, 0.0, -0.04010676241976441, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:58,199] A3C_AGENT_WORKER-Thread-11 INFO:Local step 22500, global step 362914: loss 2.1169
[2017-11-02 10:45:58,490] A3C_AGENT_WORKER-Thread-6 INFO:Local step 23000, global step 363074: loss 90.8179
[2017-11-02 10:45:59,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 22500, global step 363428: loss 1.3622
[2017-11-02 10:45:59,662] A3C_AGENT_WORKER-Thread-9 INFO:Local step 22500, global step 363719: loss 16.3311
[2017-11-02 10:46:00,043] A3C_AGENT_WORKER-Thread-16 INFO:Local step 23000, global step 363888: loss 1.4877
[2017-11-02 10:46:00,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   6.52355236e-16   1.90361909e-15   1.38242308e-14
   1.27931291e-14   5.57122219e-35   2.86966751e-36   7.28138627e-37
   4.09747160e-37], sum to 1.0000
[2017-11-02 10:46:00,410] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 81.0, 0.75, 10.0, 0.0, 0.0, -1.0, 45.19611328663204, 18.0, 18.30837989682106, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 6903300.0000, 
raw observation next is [4.0, 81.0, 0.875, 11.66666666666667, 0.0, 0.0, -1.0, 45.7234792653293, 18.0, 18.3372342534063, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.4358974358974359, 0.81, 0.07954545454545454, 0.03240740740740741, 0.0, 0.0, 0.48333333333333334, 0.45723479265329303, 0.0, 0.04817632191518584, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:00,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[ -98.24332428]
 [ -99.2071228 ]
 [ -99.61338806]
 [-100.86457825]
 [-100.74329376]], R is [[-101.00154877]
 [-100.99153137]
 [-100.98162079]
 [-100.97180176]
 [-100.96208191]].
[2017-11-02 10:46:02,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 23000, global step 364811: loss -19.6543
[2017-11-02 10:46:04,715] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.98434484e-01   1.08633564e-08   8.44674553e-10   4.55247751e-08
   1.05874122e-07   6.18002610e-04   6.34574535e-05   8.48222582e-04
   3.56899509e-05], sum to 1.0000
[2017-11-02 10:46:04,729] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 75.0, 3.6, 80.0, 102.0, 0.0, 11.0, 21.23908090474331, 20.0, 21.6194731687406, 22.2, 1.0, 32.91565410796977], 
actual action is [1.0, 18], 
sim time next is 6879900.0000, 
raw observation next is [6.0, 76.0, 3.683333333333333, 80.83333333333333, 99.83333333333334, 0.0, 1.0, 21.61968448907701, 18.0, 21.63456069230265, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.48717948717948717, 0.76, 0.33484848484848484, 0.22453703703703703, 0.2641093474426808, 0.0, 0.5166666666666667, 0.2161968448907701, 0.0, 0.5192229560432357, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:05,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-110.20001984]
 [-111.65457916]
 [-111.20436859]
 [-111.76131439]
 [-112.61479187]], R is [[-109.35295105]
 [-109.2594223 ]
 [-109.16683197]
 [-109.07516479]
 [-108.98441315]].
[2017-11-02 10:46:05,184] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-113.85440063]
 [-118.3008728 ]
 [-111.47615051]
 [-111.21341705]
 [-110.50746155]], R is [[-115.27780914]
 [-115.12503052]
 [-114.97377777]
 [-114.82404327]
 [-114.67580414]].
[2017-11-02 10:46:07,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 23000, global step 366360: loss 699.8016
[2017-11-02 10:46:07,736] A3C_AGENT_WORKER-Thread-8 INFO:Local step 23000, global step 366543: loss 370.3983
[2017-11-02 10:46:07,809] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.49205197e-11   2.34990742e-11   1.40246148e-10
   1.56064842e-10   3.21119873e-24   5.95338781e-26   6.39563494e-26
   1.45965306e-26], sum to 1.0000
[2017-11-02 10:46:07,820] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 79.5, 1.65, 20.0, 0.0, 0.0, -1.0, 37.61591158640623, 18.0, 19.44401395288551, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 6906000.0000, 
raw observation next is [4.0, 79.0, 1.7, 20.0, 0.0, 0.0, -1.0, 38.32964537233143, 18.0, 19.38471796406289, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.4358974358974359, 0.79, 0.15454545454545454, 0.05555555555555555, 0.0, 0.0, 0.48333333333333334, 0.3832964537233143, 0.0, 0.1978168520089843, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0022. 
=============================================
[2017-11-02 10:46:08,644] A3C_AGENT_WORKER-Thread-4 INFO:Local step 23000, global step 366843: loss 15.3593
[2017-11-02 10:46:10,620] A3C_AGENT_WORKER-Thread-7 INFO:Local step 23000, global step 367466: loss 269.5137
[2017-11-02 10:46:11,447] A3C_AGENT_WORKER-Thread-5 INFO:Local step 23000, global step 367778: loss 101.7625
[2017-11-02 10:46:11,626] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.43521168e-15   1.77718608e-15   1.40239442e-14
   1.55686350e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:46:11,634] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.5, 78.0, 1.8, 40.0, 0.0, 0.0, -1.416666666666667, 43.70668497114338, 18.0, 18.69059709231362, 19.4, 0.0, 0.0], 
actual action is [-1.5, 18], 
sim time next is 6910500.0000, 
raw observation next is [3.416666666666667, 78.5, 1.75, 43.33333333333333, 0.0, 0.0, -1.5, 43.91179499054409, 18.0, 18.67496331862622, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 1.0, 0.42094017094017094, 0.785, 0.1590909090909091, 0.12037037037037036, 0.0, 0.0, 0.475, 0.4391179499054409, 0.0, 0.09642333123231696, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:13,833] A3C_AGENT_WORKER-Thread-17 INFO:Local step 23000, global step 368602: loss 0.4207
[2017-11-02 10:46:14,999] A3C_AGENT_WORKER-Thread-13 INFO:Local step 23000, global step 369064: loss 30.5083
[2017-11-02 10:46:15,767] A3C_AGENT_WORKER-Thread-2 INFO:Local step 23000, global step 369279: loss 68.6805
[2017-11-02 10:46:16,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99858618e-01   3.34569989e-07   9.38642870e-08   2.12269401e-06
   3.22961796e-06   9.24084452e-06   5.90563322e-05   3.03653883e-06
   6.42421292e-05], sum to 1.0000
[2017-11-02 10:46:16,747] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.083333333333333, 86.5, 4.1, 80.83333333333333, 170.75, 0.0, 9.0, 21.68346664930505, 19.5, 21.08541157236147, 22.2, 1.0, 18.76256973413335], 
actual action is [-0.916666666666667, 18], 
sim time next is 6869400.0000, 
raw observation next is [4.166666666666667, 86.0, 4.1, 81.66666666666667, 175.0, 0.0, -0.916666666666667, 21.79565900134057, 18.0, 21.13614115050435, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.4401709401709402, 0.86, 0.3727272727272727, 0.22685185185185186, 0.46296296296296297, 0.0, 0.4847222222222222, 0.2179565900134057, 0.0, 0.44802016435776437, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:17,243] A3C_AGENT_WORKER-Thread-14 INFO:Local step 23000, global step 369918: loss 61.2455
[2017-11-02 10:46:18,025] A3C_AGENT_WORKER-Thread-15 INFO:Local step 23000, global step 370271: loss 40.2186
[2017-11-02 10:46:18,668] A3C_AGENT_WORKER-Thread-9 INFO:Local step 23000, global step 370596: loss 402.0614
[2017-11-02 10:46:18,870] A3C_AGENT_WORKER-Thread-6 INFO:Local step 23500, global step 370682: loss 3.3802
[2017-11-02 10:46:19,413] A3C_AGENT_WORKER-Thread-11 INFO:Local step 23000, global step 370917: loss -54.6825
[2017-11-02 10:46:20,231] A3C_AGENT_WORKER-Thread-12 INFO:Local step 23000, global step 371273: loss 55.4817
[2017-11-02 10:46:20,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 23500, global step 371556: loss 30.0115
[2017-11-02 10:46:22,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.32995899e-16   5.80236429e-17   2.70221404e-16
   4.23641517e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:46:22,057] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 2.516666666666667, 341.6666666666667, 0.0, 0.0, -2.0, 48.81060911976659, 18.0, 18.40812455281237, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6933300.0000, 
raw observation next is [3.0, 87.0, 2.558333333333334, 340.8333333333333, 0.0, 0.0, -2.0, 49.34324424594212, 18.0, 18.36848004619216, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.87, 0.23257575757575763, 0.9467592592592592, 0.0, 0.0, 0.4666666666666667, 0.4934324424594212, 0.0, 0.052640006598880164, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:22,542] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   4.53909826e-10   1.23551269e-09   6.95536562e-09
   2.84386847e-09   6.43989805e-26   9.70230813e-26   1.72805201e-27
   9.17618412e-27], sum to 1.0000
[2017-11-02 10:46:22,550] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 87.0, 2.166666666666667, 250.0, 0.0, 0.0, 3.0, 24.62482312844694, 18.0, 20.3488870456795, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 7004400.0000, 
raw observation next is [8.0, 87.0, 2.033333333333333, 250.0, 0.0, 0.0, 3.0, 24.75069932269134, 18.0, 20.33135504356242, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.5384615384615384, 0.87, 0.18484848484848485, 0.6944444444444444, 0.0, 0.0, 0.55, 0.24750699322691339, 0.0, 0.3330507205089174, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:22,702] A3C_AGENT_WORKER-Thread-10 INFO:Local step 23500, global step 372290: loss 10.4236
[2017-11-02 10:46:26,778] A3C_AGENT_WORKER-Thread-3 INFO:Local step 23500, global step 373887: loss 8.8891
[2017-11-02 10:46:27,385] A3C_AGENT_WORKER-Thread-8 INFO:Local step 23500, global step 374116: loss 4.0659
[2017-11-02 10:46:28,690] A3C_AGENT_WORKER-Thread-4 INFO:Local step 23500, global step 374551: loss 5.3379
[2017-11-02 10:46:28,924] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.94446754e-01   2.75123492e-03   2.74251658e-03
   5.95561396e-05], sum to 1.0000
[2017-11-02 10:46:28,949] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [13.0, 67.0, 2.1, 100.8333333333333, 264.0833333333334, 445.75, 18.0, 9.02736208385367, 25.0, 25.91868153676583, 22.2, 1.0, 3.624872640941602], 
actual action is [18.0, 25], 
sim time next is 7052400.0000, 
raw observation next is [13.0, 67.0, 2.1, 80.0, 252.5, 476.5, 18.0, 9.229462845695009, 25.0, 25.96289130377827, 22.2, 1.0, 3.434849068178862], 
processed observation next is [0.5, 0.6521739130434783, 0.6666666666666666, 0.67, 0.19090909090909092, 0.2222222222222222, 0.667989417989418, 0.4765, 0.8, 0.09229462845695009, 1.0, 1.137555900539753, 0.5999999999999999, 1.0, 0.040409989037398376], 
reward next is -0.0456. 
=============================================
[2017-11-02 10:46:29,715] A3C_AGENT_WORKER-Thread-7 INFO:Local step 23500, global step 374929: loss 0.3496
[2017-11-02 10:46:32,061] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99943495e-01   8.80202333e-06   1.90676883e-06   2.82931001e-06
   5.40047449e-06   3.59484584e-05   1.01918806e-06   4.79524147e-07
   1.21446362e-07], sum to 1.0000
[2017-11-02 10:46:32,073] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 87.0, 2.1, 90.0, 0.0, 0.0, 2.083333333333333, 15.8831535460001, 18.0, 20.85275814271414, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7095900.0000, 
raw observation next is [6.999999999999999, 87.0, 2.1, 87.5, 0.0, 0.0, 2.0, 16.07157658516075, 18.0, 20.82274357121727, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5128205128205128, 0.87, 0.19090909090909092, 0.24305555555555555, 0.0, 0.0, 0.5333333333333333, 0.1607157658516075, 0.0, 0.40324908160246714, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:32,669] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99939919e-01   2.49059976e-05   1.18874677e-05   1.32962787e-05
   1.00224779e-05   1.95068872e-09   1.17080068e-10   4.56300622e-11
   4.76307101e-12], sum to 1.0000
[2017-11-02 10:46:32,683] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.666666666666668, 83.0, 0.7, 23.33333333333333, 0.0, 0.0, 3.75, 10.50238091150198, 18.0, 22.02384311725401, 22.2, 1.0, 0.0], 
actual action is [3.666666666666668, 18], 
sim time next is 7086300.0000, 
raw observation next is [8.583333333333332, 83.5, 0.8750000000000001, 29.16666666666667, 0.0, 0.0, 3.666666666666668, 10.61602184596839, 18.0, 21.99388361528633, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.0, 0.5534188034188033, 0.835, 0.07954545454545456, 0.08101851851851853, 0.0, 0.0, 0.5611111111111112, 0.1061602184596839, 0.0, 0.5705548021837613, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0106. 
=============================================
[2017-11-02 10:46:33,067] A3C_AGENT_WORKER-Thread-5 INFO:Local step 23500, global step 376467: loss 0.6631
[2017-11-02 10:46:33,182] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.38400052e-25   4.82177877e-21   1.09838089e-22   2.85961018e-22
   1.27846327e-21   9.50268269e-01   2.83803493e-02   1.92535706e-02
   2.09788606e-03], sum to 1.0000
[2017-11-02 10:46:33,206] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [11.0, 71.0, 0.0, 0.0, 48.33333333333334, 201.0, 16.0, 7.884319953577074, 25.0, 24.79650222003436, 22.2, 1.0, 3.287610408569517], 
actual action is [16.0, 25], 
sim time next is 6976500.0000, 
raw observation next is [11.0, 71.0, 0.0, 0.0, 42.41666666666666, 178.75, 16.0, 7.808708594612864, 25.0, 24.73164145073931, 22.2, 1.0, 3.068237000782201], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.6153846153846154, 0.71, 0.0, 0.0, 0.11221340388007052, 0.17875, 0.7666666666666667, 0.07808708594612863, 1.0, 0.9616630643913301, 0.5999999999999999, 1.0, 0.03609690589155531], 
reward next is -0.0403. 
=============================================
[2017-11-02 10:46:33,480] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99954343e-01   1.77319998e-05   2.93326320e-06   4.98143299e-06
   9.71040663e-06   9.56365329e-06   4.95098618e-07   1.77380713e-07
   6.35081463e-08], sum to 1.0000
[2017-11-02 10:46:33,504] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.083333333333333, 87.0, 3.1, 110.8333333333333, 63.33333333333334, 287.25, 2.0, 20.94877794008844, 18.0, 20.18930181937206, 19.4, 0.0, 0.0], 
actual action is [2.083333333333333, 18], 
sim time next is 7110600.0000, 
raw observation next is [7.166666666666667, 87.0, 3.1, 111.6666666666667, 71.66666666666669, 310.0, 2.083333333333333, 19.75693569880101, 18.0, 20.29515902218029, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.5170940170940171, 0.87, 0.2818181818181818, 0.3101851851851853, 0.18959435626102297, 0.31, 0.5347222222222222, 0.1975693569880101, 0.0, 0.32787986031146993, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:46:33,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 23500, global step 376929: loss 1.6836
[2017-11-02 10:46:34,895] A3C_AGENT_WORKER-Thread-6 INFO:Local step 24000, global step 377324: loss 0.9788
[2017-11-02 10:46:35,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-24.79932404]
 [-24.39108276]
 [-25.12760735]
 [-24.14592743]
 [-23.2800312 ]], R is [[-23.55336189]
 [-23.36631203]
 [-23.16399193]
 [-22.96359253]
 [-22.76524734]].
[2017-11-02 10:46:36,575] A3C_AGENT_WORKER-Thread-2 INFO:Local step 23500, global step 378081: loss -3.7486
[2017-11-02 10:46:37,640] A3C_AGENT_WORKER-Thread-13 INFO:Local step 23500, global step 378594: loss -2.1890
[2017-11-02 10:46:37,782] A3C_AGENT_WORKER-Thread-14 INFO:Local step 23500, global step 378661: loss -13.3876
[2017-11-02 10:46:38,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 23500, global step 378947: loss 0.6639
[2017-11-02 10:46:38,961] A3C_AGENT_WORKER-Thread-9 INFO:Local step 23500, global step 379289: loss 0.0816
[2017-11-02 10:46:38,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 24000, global step 379310: loss 0.4413
[2017-11-02 10:46:39,456] A3C_AGENT_WORKER-Thread-11 INFO:Local step 23500, global step 379563: loss 0.2753
[2017-11-02 10:46:39,975] A3C_AGENT_WORKER-Thread-10 INFO:Local step 24000, global step 379845: loss 0.1760
[2017-11-02 10:46:40,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.94254053e-01   2.70137028e-03   1.56689610e-03   1.45641781e-04
   1.33212260e-03   2.05413839e-10   3.12965515e-10   7.12006634e-11
   1.25519482e-11], sum to 1.0000
[2017-11-02 10:46:40,084] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 72.66666666666666, 0.5, 3.333333333333334, 0.0, 0.0, 6.0, 7.147132948537422, 18.0, 23.45075359461401, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 7073100.0000, 
raw observation next is [11.0, 72.25, 0.375, 2.5, 0.0, 0.0, 6.0, 7.146587102195141, 18.0, 23.42089793552109, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.6153846153846154, 0.7225, 0.03409090909090909, 0.006944444444444444, 0.0, 0.0, 0.6, 0.0714658710219514, 0.0, 0.7744139907887272, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0071. 
=============================================
[2017-11-02 10:46:40,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 23500, global step 380036: loss 0.4176
[2017-11-02 10:46:41,107] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.82212007e-01   1.10378200e-02   2.31502997e-03   1.33749199e-04
   4.30135243e-03   5.78196879e-10   6.28211205e-10   1.45867970e-10
   1.84330294e-11], sum to 1.0000
[2017-11-02 10:46:41,119] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.0, 67.0, 3.600000000000001, 160.0, 0.0, 0.0, 9.0, 9.95916810274243, 18.0, 25.26014000049365, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7169100.0000, 
raw observation next is [14.0, 67.0, 3.6, 160.0, 0.0, 0.0, 9.0, 9.881454110916634, 18.0, 25.23977094107637, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.6923076923076923, 0.67, 0.32727272727272727, 0.4444444444444444, 0.0, 0.0, 0.65, 0.09881454110916633, 0.0, 1.0342529915823384, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0099. 
=============================================
[2017-11-02 10:46:41,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.71375346e-01   1.66586936e-02   3.85188102e-03   3.40369559e-04
   7.77365547e-03   2.72316525e-09   3.28907768e-09   6.33060382e-10
   1.21187269e-10], sum to 1.0000
[2017-11-02 10:46:41,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 87.0, 2.1, 85.0, 0.0, 0.0, 1.999999999999999, 13.14183225619153, 18.0, 21.48271885142575, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7096500.0000, 
raw observation next is [7.0, 87.0, 2.1, 82.5, 0.0, 0.0, 2.0, 13.29233242545056, 18.0, 21.45422622067127, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5128205128205128, 0.87, 0.19090909090909092, 0.22916666666666666, 0.0, 0.0, 0.5333333333333333, 0.1329233242545056, 0.0, 0.4934608886673243, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:46:43,088] A3C_AGENT_WORKER-Thread-3 INFO:Local step 24000, global step 381679: loss 0.0109
[2017-11-02 10:46:43,870] A3C_AGENT_WORKER-Thread-8 INFO:Local step 24000, global step 382128: loss 0.3686
[2017-11-02 10:46:44,730] A3C_AGENT_WORKER-Thread-7 INFO:Local step 24000, global step 382624: loss 0.1480
[2017-11-02 10:46:44,751] A3C_AGENT_WORKER-Thread-4 INFO:Local step 24000, global step 382632: loss 0.4165
[2017-11-02 10:46:46,226] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.97319758e-01   2.43913545e-03   3.54592521e-06   1.16554554e-06
   2.36344989e-04   5.34253674e-12   4.83719662e-12   4.42331024e-12
   2.37508906e-13], sum to 1.0000
[2017-11-02 10:46:46,245] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333333, 60.66666666666667, 7.483333333333333, 231.6666666666667, 356.5833333333333, 360.6666666666667, 16.66666666666667, 12.19511760912652, 18.0, 26.43547760398531, 22.2, 1.0, 0.0], 
actual action is [16.83333333333333, 18], 
sim time next is 7214400.0000, 
raw observation next is [22.0, 60.0, 7.7, 230.0, 359.5, 352.0, 16.83333333333333, 12.32406685444405, 18.0, 26.4559634610458, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.8974358974358975, 0.6, 0.7000000000000001, 0.6388888888888888, 0.951058201058201, 0.352, 0.7805555555555554, 0.1232406685444405, 0.0, 1.2079947801494002, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0123. 
=============================================
[2017-11-02 10:46:47,427] A3C_AGENT_WORKER-Thread-5 INFO:Local step 24000, global step 384114: loss 0.4807
[2017-11-02 10:46:47,960] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-6.10933113]
 [-6.31583118]
 [-5.99641705]
 [-6.42991543]
 [-6.84621906]], R is [[-6.24689579]
 [-6.19202042]
 [-6.13762426]
 [-6.08370972]
 [-6.03026867]].
[2017-11-02 10:46:48,233] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.99755824e-01   2.22181767e-01   3.88558544e-02   2.12461427e-02
   1.17960252e-01   7.00987854e-08   4.00753919e-08   2.99647418e-08
   6.18140428e-09], sum to 1.0000
[2017-11-02 10:46:48,248] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.83333333333333, 43.5, 2.600000000000001, 193.3333333333333, 0.0, 0.0, 5.91666666666667, 8.602955215292472, 18.0, 22.24382580983583, 20.56, 1.0, 0.0], 
actual action is [5.83333333333333, 18], 
sim time next is 7334100.0000, 
raw observation next is [10.75, 43.75, 2.6, 195.0, 0.0, 0.0, 5.83333333333333, 8.70536811595947, 18.0, 22.21323758842093, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.6089743589743589, 0.4375, 0.23636363636363636, 0.5416666666666666, 0.0, 0.0, 0.5972222222222221, 0.08705368115959469, 0.0, 0.601891084060133, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0087. 
=============================================
[2017-11-02 10:46:48,669] A3C_AGENT_WORKER-Thread-17 INFO:Local step 24000, global step 384810: loss 1.4890
[2017-11-02 10:46:49,602] A3C_AGENT_WORKER-Thread-6 INFO:Local step 24500, global step 385362: loss 22.2722
[2017-11-02 10:46:50,127] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.43050471e-01   3.83897901e-01   9.77259204e-02   5.35955727e-02
   2.21729219e-01   4.16563410e-07   2.82940334e-07   2.04063426e-07
   4.39433236e-08], sum to 1.0000
[2017-11-02 10:46:50,170] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [13.58333333333333, 47.0, 5.475, 298.3333333333334, 0.0, 0.0, 8.66666666666667, 7.101332433113134, 18.0, 24.48597039509069, 20.56, 1.0, 0.0], 
actual action is [8.58333333333333, 18], 
sim time next is 7255800.0000, 
raw observation next is [13.5, 47.0, 5.65, 300.0, 0.0, 0.0, 8.58333333333333, 7.031825326503093, 18.0, 24.45730771971202, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.6794871794871795, 0.47, 0.5136363636363637, 0.8333333333333334, 0.0, 0.0, 0.6430555555555555, 0.07031825326503094, 0.0, 0.9224725313874315, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0070. 
=============================================
[2017-11-02 10:46:50,603] A3C_AGENT_WORKER-Thread-2 INFO:Local step 24000, global step 385970: loss -0.0141
[2017-11-02 10:46:50,645] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-1.05650461]
 [-1.16961372]
 [-1.15774143]
 [-0.87389672]
 [-1.02047813]], R is [[-1.1796819 ]
 [-1.1747303 ]
 [-1.16977668]
 [-1.16481721]
 [-1.1598562 ]].
[2017-11-02 10:46:50,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.35742921e-01   3.51378053e-01   9.12646949e-02   5.09128459e-02
   1.70700133e-01   5.94533276e-07   3.75904108e-07   2.67044442e-07
   5.82666821e-08], sum to 1.0000
[2017-11-02 10:46:50,804] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.0, 67.0, 4.6, 184.1666666666667, 0.0, 0.0, 9.0, 6.226587474624503, 18.0, 22.79792314518868, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7188000.0000, 
raw observation next is [14.0, 67.0, 4.6, 183.3333333333333, 0.0, 0.0, 9.0, 6.247527790996812, 18.0, 22.78444205473844, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.6923076923076923, 0.67, 0.41818181818181815, 0.5092592592592591, 0.0, 0.0, 0.65, 0.06247527790996812, 0.0, 0.6834917221054917, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0062. 
=============================================
[2017-11-02 10:46:51,855] A3C_AGENT_WORKER-Thread-13 INFO:Local step 24000, global step 386754: loss 0.2582
[2017-11-02 10:46:51,902] A3C_AGENT_WORKER-Thread-14 INFO:Local step 24000, global step 386784: loss -0.3379
[2017-11-02 10:46:51,942] A3C_AGENT_WORKER-Thread-15 INFO:Local step 24000, global step 386813: loss -1.0728
[2017-11-02 10:46:52,957] A3C_AGENT_WORKER-Thread-11 INFO:Local step 24000, global step 387413: loss 0.3419
[2017-11-02 10:46:53,028] A3C_AGENT_WORKER-Thread-9 INFO:Local step 24000, global step 387450: loss -0.3087
[2017-11-02 10:46:53,227] A3C_AGENT_WORKER-Thread-16 INFO:Local step 24500, global step 387568: loss -5.4232
[2017-11-02 10:46:53,669] A3C_AGENT_WORKER-Thread-12 INFO:Local step 24000, global step 387815: loss 0.3443
[2017-11-02 10:46:53,786] A3C_AGENT_WORKER-Thread-10 INFO:Local step 24500, global step 387880: loss -7.1923
[2017-11-02 10:46:56,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-12.3452177 ]
 [ -4.64176846]
 [ -5.31040573]
 [ -3.6302166 ]
 [ -3.52752447]], R is [[-7.67579556]
 [-7.61211729]
 [-7.5488863 ]
 [-7.48610258]
 [-7.42377377]].
[2017-11-02 10:46:56,646] A3C_AGENT_WORKER-Thread-3 INFO:Local step 24500, global step 389559: loss 0.8556
[2017-11-02 10:46:57,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.95933744e-01   6.76548302e-01   2.91251708e-02   1.33907516e-02
   8.49750713e-02   1.17397713e-05   7.50015170e-06   6.46149147e-06
   1.14479280e-06], sum to 1.0000
[2017-11-02 10:46:57,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [11.91666666666667, 43.91666666666666, 7.533333333333334, 300.0, 148.4166666666667, 867.25, 6.83333333333333, 7.295784744100931, 18.0, 22.84088683850992, 22.2, 1.0, 0.0], 
actual action is [6.91666666666667, 18], 
sim time next is 7300800.0000, 
raw observation next is [12.0, 44.0, 7.7, 300.0, 148.5, 868.5, 6.91666666666667, 7.29262101580319, 18.0, 22.83588519347917, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6410256410256411, 0.44, 0.7000000000000001, 0.8333333333333334, 0.39285714285714285, 0.8685, 0.6152777777777778, 0.0729262101580319, 0.0, 0.690840741925596, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0073. 
=============================================
[2017-11-02 10:46:57,774] A3C_AGENT_WORKER-Thread-8 INFO:Local step 24500, global step 390215: loss -3.6875
[2017-11-02 10:46:58,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.86134785e-01   4.84043479e-01   1.21027835e-01   8.77938047e-02
   1.21000133e-01   4.16413952e-11   3.15401941e-11   2.45088672e-11
   6.09004297e-12], sum to 1.0000
[2017-11-02 10:46:58,675] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [9.25, 84.25, 4.05, 287.5, 99.25, 11.0, 4.166666666666666, 13.56919302240943, 18.0, 21.33169837093581, 20.56, 1.0, 0.0], 
actual action is [4.25, 18], 
sim time next is 7406400.0000, 
raw observation next is [9.333333333333334, 83.33333333333334, 4.033333333333333, 290.0, 91.16666666666666, 9.0, 4.25, 13.86003123871515, 18.0, 21.2394085762173, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5726495726495727, 0.8333333333333335, 0.36666666666666664, 0.8055555555555556, 0.2411816578483245, 0.009, 0.5708333333333333, 0.1386003123871515, 0.0, 0.46277265374532867, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 10:46:58,745] A3C_AGENT_WORKER-Thread-7 INFO:Local step 24500, global step 390785: loss 18.0435
[2017-11-02 10:46:58,837] A3C_AGENT_WORKER-Thread-4 INFO:Local step 24500, global step 390847: loss 91.8811
[2017-11-02 10:47:01,391] A3C_AGENT_WORKER-Thread-5 INFO:Local step 24500, global step 392281: loss 302.1888
[2017-11-02 10:47:02,371] A3C_AGENT_WORKER-Thread-17 INFO:Local step 24500, global step 392860: loss 161.0727
[2017-11-02 10:47:03,811] A3C_AGENT_WORKER-Thread-2 INFO:Local step 24500, global step 393671: loss 81.3211
[2017-11-02 10:47:04,824] A3C_AGENT_WORKER-Thread-6 INFO:Local step 25000, global step 394200: loss -2.3943
[2017-11-02 10:47:05,336] A3C_AGENT_WORKER-Thread-15 INFO:Local step 24500, global step 394469: loss 33.8532
[2017-11-02 10:47:05,356] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-34.24597931]
 [-34.58935928]
 [-25.6813755 ]
 [-32.46544647]
 [-33.18928909]], R is [[-34.82800293]
 [-35.47972488]
 [-36.12492752]
 [-36.7636795 ]
 [-37.39604187]].
[2017-11-02 10:47:05,400] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.86279432e-03   4.50145677e-02   6.52183533e-01   1.77900884e-02
   2.82149047e-01   2.28861172e-38   1.00039039e-35   1.26084374e-37
   4.64884088e-36], sum to 1.0000
[2017-11-02 10:47:05,413] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.0, 56.0, 2.6, 290.0, 0.0, 0.0, 2.0, 30.68832568278067, 18.0, 19.0054951556784, 20.56, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7427100.0000, 
raw observation next is [6.916666666666666, 56.33333333333333, 2.558333333333333, 285.0, 0.0, 0.0, 2.0, 30.77032637752347, 18.0, 18.98511523055393, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5106837606837606, 0.5633333333333332, 0.23257575757575755, 0.7916666666666666, 0.0, 0.0, 0.5333333333333333, 0.3077032637752347, 0.0, 0.14073074722199003, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:05,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.72665886e-04   8.72779191e-02   6.36571646e-01   5.90876415e-02
   2.16490075e-01   1.24597695e-21   9.20066468e-20   5.51279649e-21
   7.41734794e-20], sum to 1.0000
[2017-11-02 10:47:05,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [5.333333333333333, 66.33333333333334, 3.433333333333334, 160.0, 0.0, 0.0, 0.5, 15.59633529334751, 18.0, 20.74627493269815, 22.2, 1.0, 0.0], 
actual action is [0.33333333333333304, 18], 
sim time next is 7349100.0000, 
raw observation next is [5.166666666666666, 66.66666666666666, 3.391666666666667, 160.0, 0.0, 0.0, 0.333333333333333, 15.80738645941847, 18.0, 20.71498515511003, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.46581196581196577, 0.6666666666666665, 0.30833333333333335, 0.4444444444444444, 0.0, 0.0, 0.5055555555555555, 0.1580738645941847, 0.0, 0.3878550221585755, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:06,033] A3C_AGENT_WORKER-Thread-14 INFO:Local step 24500, global step 394834: loss -0.5254
[2017-11-02 10:47:06,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 24500, global step 394853: loss 91.2759
[2017-11-02 10:47:06,712] A3C_AGENT_WORKER-Thread-11 INFO:Local step 24500, global step 395169: loss 20.5301
[2017-11-02 10:47:06,955] A3C_AGENT_WORKER-Thread-9 INFO:Local step 24500, global step 395301: loss 39.2570
[2017-11-02 10:47:07,814] A3C_AGENT_WORKER-Thread-12 INFO:Local step 24500, global step 395765: loss -11.7198
[2017-11-02 10:47:08,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.58855629e-01   5.18525422e-01   5.63442055e-03   6.37005956e-04
   1.63475815e-02   6.31876260e-23   3.00367739e-22   1.05339626e-23
   1.97908525e-23], sum to 1.0000
[2017-11-02 10:47:08,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 57.0, 5.1, 150.0, 99.5, 13.5, 3.75, 17.35202221094697, 18.0, 20.90182666704645, 19.4, 0.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 7373100.0000, 
raw observation next is [9.166666666666666, 56.41666666666666, 4.975, 149.1666666666667, 99.08333333333333, 11.25, 4.0, 17.21897239910939, 18.0, 20.88336761764325, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.5683760683760684, 0.5641666666666666, 0.4522727272727272, 0.41435185185185197, 0.2621252204585538, 0.01125, 0.5666666666666667, 0.1721897239910939, 0.0, 0.4119096596633212, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:08,832] A3C_AGENT_WORKER-Thread-10 INFO:Local step 25000, global step 396215: loss -22.8499
[2017-11-02 10:47:10,531] A3C_AGENT_WORKER-Thread-16 INFO:Local step 25000, global step 396810: loss -0.0477
[2017-11-02 10:47:10,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  7.09453940e-01   1.78853288e-01   5.47823943e-02   1.42158074e-02
   4.26945277e-02   2.44959913e-10   3.55947161e-10   3.84807325e-11
   2.04519370e-11], sum to 1.0000
[2017-11-02 10:47:10,847] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 59.5, 3.775, 225.8333333333333, 175.1666666666667, 5.0, 4.0, 13.12598601403285, 18.0, 21.74460457208507, 19.4, 0.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 7395000.0000, 
raw observation next is [9.0, 62.0, 3.95, 231.6666666666667, 165.3333333333333, 3.999999999999999, 4.0, 13.3130415535141, 18.0, 21.6910248296874, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5641025641025641, 0.62, 0.3590909090909091, 0.6435185185185186, 0.4373897707231039, 0.003999999999999999, 0.5666666666666667, 0.13313041553514102, 0.0, 0.5272892613839143, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:14,134] A3C_AGENT_WORKER-Thread-3 INFO:Local step 25000, global step 398381: loss -149.9581
[2017-11-02 10:47:15,808] A3C_AGENT_WORKER-Thread-8 INFO:Local step 25000, global step 398827: loss -23.8512
[2017-11-02 10:47:16,142] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.26968827e-23   5.42671796e-10   7.21805601e-11   3.57026583e-12
   1.27799146e-10   9.06699598e-01   6.52097538e-02   6.48943149e-03
   2.16012392e-02], sum to 1.0000
[2017-11-02 10:47:16,162] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 87.0, 5.191666666666666, 269.1666666666667, 0.0, 0.0, 7.0, 22.82908239569132, 18.5, 20.2721863977687, 19.4, 0.0, 18.61982264252296], 
actual action is [7.0, 19.0], 
sim time next is 7513200.0000, 
raw observation next is [2.0, 87.0, 5.1, 270.0, 0.0, 0.0, 7.0, 22.92873182488995, 19.0, 20.25018918217951, 19.4, 0.0, 10.66233997136737], 
processed observation next is [0.16666666666666666, 1.0, 0.38461538461538464, 0.87, 0.4636363636363636, 0.75, 0.0, 0.0, 0.6166666666666667, 0.2292873182488995, 0.14285714285714285, 0.32145559745421587, 0.1999999999999998, 0.0, 0.12543929378079258], 
reward next is -0.1129. 
=============================================
[2017-11-02 10:47:16,374] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.24589251e-28   3.50501335e-31   2.78041354e-32
   6.52446836e-30   9.18914914e-01   6.34014979e-02   1.34086311e-02
   4.27494477e-03], sum to 1.0000
[2017-11-02 10:47:16,449] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [6.0, 70.0, 3.1, 210.0, 201.3333333333333, 0.0, 11.0, 6.638302629620981, 25.0, 24.38177569174166, 22.2, 1.0, 35.35151078587441], 
actual action is [11.0, 25], 
sim time next is 7467900.0000, 
raw observation next is [6.0, 70.0, 3.1, 210.0, 207.1666666666667, 0.0, 11.0, 6.636479154592812, 25.0, 24.44025763673696, 22.2, 1.0, 34.59141018244124], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.48717948717948717, 0.7, 0.2818181818181818, 0.5833333333333334, 0.5480599647266315, 0.0, 0.6833333333333333, 0.06636479154592811, 1.0, 0.920036805248137, 0.5999999999999999, 1.0, 0.4069577668522498], 
reward next is -0.3729. 
=============================================
[2017-11-02 10:47:17,465] A3C_AGENT_WORKER-Thread-4 INFO:Local step 25000, global step 399299: loss 1.9157
[2017-11-02 10:47:18,387] A3C_AGENT_WORKER-Thread-7 INFO:Local step 25000, global step 399538: loss 0.2925
[2017-11-02 10:47:22,217] A3C_AGENT_WORKER-Thread-5 INFO:Local step 25000, global step 400489: loss 1.6295
[2017-11-02 10:47:22,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.29166050e-21   4.63655503e-11   1.44324093e-12   2.83671090e-13
   6.24109184e-12   2.88919300e-01   5.33646584e-01   4.85640317e-02
   1.28870085e-01], sum to 1.0000
[2017-11-02 10:47:22,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [8.0, 87.0, 4.449999999999999, 233.3333333333333, 67.33333333333333, 0.0, 13.0, 6.617090919489502, 20.0, 24.35806808832734, 22.2, 1.0, 33.51615419261191], 
actual action is [13.0, 20.5], 
sim time next is 7492500.0000, 
raw observation next is [8.0, 87.0, 4.625, 235.0, 64.0, 0.0, 13.0, 6.611362411320669, 20.5, 24.3333447849402, 22.2, 1.0, 27.47805170772794], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.5384615384615384, 0.87, 0.42045454545454547, 0.6527777777777778, 0.1693121693121693, 0.0, 0.7166666666666667, 0.06611362411320669, 0.35714285714285715, 0.9047635407057426, 0.5999999999999999, 1.0, 0.32327119656150516], 
reward next is -0.2976. 
=============================================
[2017-11-02 10:47:23,451] A3C_AGENT_WORKER-Thread-17 INFO:Local step 25000, global step 400977: loss -1.9576
[2017-11-02 10:47:23,565] A3C_AGENT_WORKER-Thread-2 INFO:Local step 25000, global step 401040: loss 14.4863
[2017-11-02 10:47:25,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 25000, global step 402260: loss -5.3570
[2017-11-02 10:47:25,815] A3C_AGENT_WORKER-Thread-9 INFO:Local step 25000, global step 402314: loss -3.4844
[2017-11-02 10:47:26,283] A3C_AGENT_WORKER-Thread-14 INFO:Local step 25000, global step 402593: loss 0.2932
[2017-11-02 10:47:26,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 25000, global step 402627: loss 5.8060
[2017-11-02 10:47:26,711] A3C_AGENT_WORKER-Thread-6 INFO:Local step 25500, global step 402841: loss 4.0379
[2017-11-02 10:47:26,856] A3C_AGENT_WORKER-Thread-12 INFO:Local step 25000, global step 402932: loss 8.0644
[2017-11-02 10:47:26,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  3.31439137e-01   6.14953816e-01   4.18802118e-03   3.31178424e-03
   4.61072885e-02   2.59107577e-24   2.72280942e-24   7.52232799e-26
   2.89480077e-25], sum to 1.0000
[2017-11-02 10:47:26,917] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 7.825, 240.0, 0.0, 0.0, -2.0, 39.07683540357812, 18.0, 18.7472430729463, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7539600.0000, 
raw observation next is [3.0, 87.0, 7.866666666666667, 240.0, 0.0, 0.0, -2.0, 39.26668372808896, 18.0, 18.74021533578814, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.41025641025641024, 0.87, 0.7151515151515152, 0.6666666666666666, 0.0, 0.0, 0.4666666666666667, 0.3926668372808896, 0.0, 0.10574504796973423, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0943. 
=============================================
[2017-11-02 10:47:26,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 25000, global step 403002: loss 7.3788
[2017-11-02 10:47:29,501] A3C_AGENT_WORKER-Thread-10 INFO:Local step 25500, global step 404385: loss 5.2155
[2017-11-02 10:47:30,301] A3C_AGENT_WORKER-Thread-16 INFO:Local step 25500, global step 404812: loss -1.4542
[2017-11-02 10:47:32,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.86172736e-01   1.14423232e-02   2.63555685e-05   3.97677613e-05
   2.31883908e-03   4.68087421e-20   1.19118816e-19   1.97663095e-20
   8.66426908e-20], sum to 1.0000
[2017-11-02 10:47:32,913] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.75, 67.0, 9.15, 260.0, 261.75, 12.0, 2.666666666666666, 17.64764763567465, 18.0, 22.21943775457174, 22.2, 1.0, 0.0], 
actual action is [2.75, 18], 
sim time next is 7559400.0000, 
raw observation next is [7.833333333333334, 66.66666666666666, 9.200000000000001, 260.0, 262.3333333333333, 12.0, 2.75, 17.73210382030184, 18.0, 22.17624778873603, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.5341880341880343, 0.6666666666666665, 0.8363636363636364, 0.7222222222222222, 0.6940035273368607, 0.012, 0.5458333333333333, 0.17732103820301842, 0.0, 0.5966068269622902, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:33,085] A3C_AGENT_WORKER-Thread-8 INFO:Local step 25500, global step 405897: loss 3.5334
[2017-11-02 10:47:33,530] A3C_AGENT_WORKER-Thread-3 INFO:Local step 25500, global step 406090: loss 5.3241
[2017-11-02 10:47:34,647] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-13.36867237]
 [-15.3968544 ]
 [-15.86459732]
 [-16.4753952 ]
 [-17.50876427]], R is [[-14.98627949]
 [-14.84989643]
 [-14.71471405]
 [-14.58068657]
 [-14.44784832]].
[2017-11-02 10:47:34,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.55467796e-01   9.27301943e-02   6.86658360e-03   7.44496798e-03
   3.74904051e-02   2.29959454e-12   4.87017371e-12   8.07825107e-13
   1.01565447e-12], sum to 1.0000
[2017-11-02 10:47:34,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.83333333333333, 43.5, 5.016666666666667, 320.8333333333333, 82.16666666666666, 561.5833333333333, 6.0, 7.495216944191146, 18.0, 24.56462795118853, 22.2, 1.0, 0.0], 
actual action is [5.83333333333333, 18], 
sim time next is 7665000.0000, 
raw observation next is [10.66666666666667, 44.0, 4.933333333333334, 321.6666666666667, 79.33333333333333, 545.6666666666666, 5.83333333333333, 7.520566372485709, 18.0, 24.45106730257907, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.606837606837607, 0.44, 0.4484848484848485, 0.8935185185185186, 0.20987654320987653, 0.5456666666666666, 0.5972222222222221, 0.07520566372485708, 0.0, 0.9215810432255813, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0075. 
=============================================
[2017-11-02 10:47:35,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.05681729e-01   6.90587386e-02   2.17648805e-03   3.09653021e-03
   1.99865345e-02   7.83926396e-12   1.63878650e-11   2.07517055e-12
   2.48266902e-12], sum to 1.0000
[2017-11-02 10:47:35,191] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.916666666666666, 54.25, 8.075, 270.8333333333334, 147.1666666666667, 193.0, 4.833333333333334, 11.38502538514715, 18.0, 23.28573110867293, 22.2, 1.0, 0.0], 
actual action is [4.916666666666666, 18], 
sim time next is 7578000.0000, 
raw observation next is [10.0, 54.0, 8.2, 270.0, 140.0, 213.0, 4.916666666666666, 11.36488090832387, 18.0, 23.26653284731316, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.5897435897435898, 0.54, 0.7454545454545454, 0.75, 0.37037037037037035, 0.213, 0.5819444444444444, 0.11364880908323871, 0.0, 0.7523618353304516, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0114. 
=============================================
[2017-11-02 10:47:35,223] A3C_AGENT_WORKER-Thread-7 INFO:Local step 25500, global step 406964: loss -0.0107
[2017-11-02 10:47:35,425] A3C_AGENT_WORKER-Thread-4 INFO:Local step 25500, global step 407065: loss 0.3578
[2017-11-02 10:47:35,893] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.10509944e-01   5.85597306e-02   3.81010212e-03   5.22673922e-03
   2.18935292e-02   6.16147133e-10   8.98090768e-10   1.27288929e-10
   8.61595378e-11], sum to 1.0000
[2017-11-02 10:47:35,921] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.33333333333333, 49.0, 4.533333333333334, 343.3333333333334, 137.0, 845.6666666666667, 6.25, 8.70526844488137, 18.0, 24.37439412156285, 22.2, 1.0, 0.0], 
actual action is [6.33333333333333, 18], 
sim time next is 7655100.0000, 
raw observation next is [11.41666666666667, 48.75, 4.566666666666666, 344.1666666666666, 136.5, 842.3333333333333, 6.33333333333333, 8.631063946732688, 18.0, 24.43837406665928, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.6260683760683762, 0.4875, 0.4151515151515151, 0.9560185185185183, 0.3611111111111111, 0.8423333333333333, 0.6055555555555555, 0.08631063946732688, 0.0, 0.9197677238084684, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0086. 
=============================================
[2017-11-02 10:47:36,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.89736784e-01   9.70560461e-02   4.61323373e-02   1.10733293e-01
   5.56341529e-01   3.03852457e-25   1.20671713e-23   6.65378289e-25
   5.38803295e-23], sum to 1.0000
[2017-11-02 10:47:36,761] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [7.5, 63.5, 4.6, 330.0, 0.0, 0.0, 2.583333333333333, 17.4885472999993, 18.0, 21.75510618078709, 22.2, 1.0, 0.0], 
actual action is [2.5, 18.0], 
sim time next is 7587300.0000, 
raw observation next is [7.416666666666667, 63.91666666666666, 4.516666666666666, 331.6666666666666, 0.0, 0.0, 2.5, 17.71412875378697, 18.0, 21.70469278456229, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.5235042735042735, 0.6391666666666665, 0.41060606060606053, 0.9212962962962961, 0.0, 0.0, 0.5416666666666666, 0.1771412875378697, 0.0, 0.5292418263660414, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:37,471] A3C_AGENT_WORKER-Thread-5 INFO:Local step 25500, global step 408133: loss 3.5480
[2017-11-02 10:47:39,091] A3C_AGENT_WORKER-Thread-2 INFO:Local step 25500, global step 408982: loss 0.0120
[2017-11-02 10:47:39,207] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:39,209] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:39,207] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:39,209] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:39,211] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:39,212] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 59.01sec

[2017-11-02 10:47:39,423] A3C_AGENT_WORKER-Thread-17 INFO:Local step 25500, global step 409168: loss 0.0389
[2017-11-02 10:47:40,210] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:40,214] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res6/Eplus-env-sub_run2
[2017-11-02 10:47:40,375] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.87684071e-01   5.48341917e-03   1.99075649e-03   4.42857825e-04
   4.39893035e-03   2.13518747e-22   5.40996063e-22   3.87839110e-23
   1.06109542e-21], sum to 1.0000
[2017-11-02 10:47:40,409] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.166666666666666, 58.75, 3.433333333333333, 354.1666666666666, 0.0, 0.0, 0.333333333333333, 18.40379791510049, 18.0, 21.14332861556534, 22.2, 1.0, 0.0], 
actual action is [0.16666666666666607, 18], 
sim time next is 7680600.0000, 
raw observation next is [5.0, 59.5, 3.6, 355.0, 0.0, 0.0, 0.1666666666666661, 18.70984715784653, 18.0, 21.10403782348874, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.9130434782608695, 0.46153846153846156, 0.595, 0.32727272727272727, 0.9861111111111112, 0.0, 0.0, 0.5027777777777778, 0.1870984715784653, 0.0, 0.4434339747841055, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:41,113] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.86658037e-01   8.88661016e-03   1.48347078e-03   3.60161095e-04
   2.61176913e-03   1.20361776e-10   1.08747754e-10   2.10206817e-11
   4.07416115e-11], sum to 1.0000
[2017-11-02 10:47:41,215] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 63.5, 0.45, 5.0, 121.0, 696.0, -1.166666666666667, 14.52120955866973, 18.0, 22.00516039873677, 22.2, 1.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 7720500.0000, 
raw observation next is [4.166666666666667, 62.75, 0.525, 5.833333333333334, 123.1666666666667, 701.0, -1.0, 14.51468005129901, 18.0, 22.26780575872885, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.4401709401709402, 0.6275, 0.04772727272727273, 0.016203703703703706, 0.3258377425044093, 0.701, 0.48333333333333334, 0.1451468005129901, 0.0, 0.6096865369612645, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0145. 
=============================================
[2017-11-02 10:47:41,348] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99966383e-01   2.17438701e-05   6.41258566e-06   2.49235484e-07
   5.26423582e-06   4.71507645e-33   1.85175497e-33   1.05564926e-34
   6.99101021e-33], sum to 1.0000
[2017-11-02 10:47:41,358] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 2.1, 240.0, 0.0, 0.0, -4.0, 40.12779798074394, 18.0, 18.85154883035874, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 7709100.0000, 
raw observation next is [1.0, 72.0, 2.1, 240.0, 0.0, 0.0, -4.0, 40.46352902111111, 18.0, 18.82203539737491, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.358974358974359, 0.72, 0.19090909090909092, 0.6666666666666666, 0.0, 0.0, 0.43333333333333335, 0.40463529021111105, 0.0, 0.1174336281964159, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0826. 
=============================================
[2017-11-02 10:47:41,556] A3C_AGENT_WORKER-Thread-9 INFO:Local step 25500, global step 410099: loss 0.0544
[2017-11-02 10:47:42,534] A3C_AGENT_WORKER-Thread-15 INFO:Local step 25500, global step 410513: loss 0.6262
[2017-11-02 10:47:42,566] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:42,566] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 58.35sec

[2017-11-02 10:47:43,207] A3C_AGENT_WORKER-Thread-13 INFO:Local step 25500, global step 410841: loss -0.6838
[2017-11-02 10:47:43,209] A3C_AGENT_WORKER-Thread-14 INFO:Local step 25500, global step 410842: loss 0.1133
[2017-11-02 10:47:43,485] A3C_AGENT_WORKER-Thread-12 INFO:Local step 25500, global step 410967: loss -0.0054
[2017-11-02 10:47:43,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 25500, global step 410970: loss 0.0982
[2017-11-02 10:47:43,569] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:43,597] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res10/Eplus-env-sub_run2
[2017-11-02 10:47:45,101] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 54.81sec

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:45,104] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,101] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:46,106] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res16/Eplus-env-sub_run2
[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  8.96sec

[2017-11-02 10:47:46,154] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,154] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,782] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  4.58sec

[2017-11-02 10:47:46,880] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  5.68sec

[2017-11-02 10:47:47,151] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,169] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res3/Eplus-env-sub_run2
[2017-11-02 10:47:47,777] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,782] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res8/Eplus-env-sub_run2
[2017-11-02 10:47:47,894] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,898] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res7/Eplus-env-sub_run2
[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:48,481] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 10.30sec

[2017-11-02 10:47:49,479] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:49,484] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res4/Eplus-env-sub_run2
[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 12.00sec

[2017-11-02 10:47:51,948] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.42153633e-01   2.52273586e-02   2.76173502e-02   8.27002048e-04
   4.17468930e-03   3.00099459e-16   2.23826339e-16   3.64317573e-17
   1.28207502e-16], sum to 1.0000
[2017-11-02 10:47:51,994] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.166666666666667, 67.25, 0.075, 0.8333333333333333, 114.75, 604.3333333333333, -2.0, 29.24924965891172, 18.0, 20.10304638166767, 19.4, 0.0, 0.0], 
actual action is [-1.833333333333333, 18], 
sim time next is 7719000.0000, 
raw observation next is [3.333333333333333, 66.5, 0.15, 1.666666666666667, 116.0, 622.6666666666667, -1.833333333333333, 27.98636803815777, 18.0, 20.24356715164483, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.41880341880341876, 0.665, 0.013636363636363636, 0.00462962962962963, 0.30687830687830686, 0.6226666666666667, 0.46944444444444444, 0.2798636803815777, 0.0, 0.3205095930921184, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:52,191] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:52,196] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res5/Eplus-env-sub_run2
[2017-11-02 10:47:52,997] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:52,997] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:53,033] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 16.78sec

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  2.33sec

[2017-11-02 10:47:53,957] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:53,963] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res2/Eplus-env-sub_run2
[2017-11-02 10:47:54,617] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:54,624] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res17/Eplus-env-sub_run2
[2017-11-02 10:47:54,794] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  7.20817566e-01   1.93742141e-01   5.11052087e-02   8.74613971e-03
   2.55889278e-02   1.51462078e-08   1.15797354e-08   5.61550939e-09
   3.43956041e-09], sum to 1.0000
[2017-11-02 10:47:54,825] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [13.5, 42.5, 3.85, 327.5, 134.25, 819.75, 8.33333333333333, 7.769911574493515, 18.0, 24.55181620747214, 22.2, 1.0, 0.0], 
actual action is [8.5, 18], 
sim time next is 7743000.0000, 
raw observation next is [13.66666666666667, 42.0, 3.933333333333333, 335.0, 133.3333333333333, 815.3333333333333, 8.5, 7.729952506651559, 18.0, 24.62804160640146, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.6837606837606839, 0.42, 0.35757575757575755, 0.9305555555555556, 0.35273368606701927, 0.8153333333333332, 0.6416666666666667, 0.07729952506651559, 0.0, 0.94686308662878, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0077. 
=============================================
[2017-11-02 10:47:57,843] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:57,847] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.64sec

[2017-11-02 10:47:58,843] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:58,846] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res9/Eplus-env-sub_run2
[2017-11-02 10:48:02,069] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,070] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  6.40270650e-01   1.75377116e-01   1.67637348e-01   4.11755731e-03
   1.25973346e-02   9.62091322e-17   1.18032678e-16   2.53811007e-17
   1.68847137e-16], sum to 1.0000
[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.80sec

[2017-11-02 10:48:02,106] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [9.075000000000001, 47.5, 3.475, 357.5, 0.0, 0.0, 4.166666666666668, 14.06317066033746, 18.0, 21.80856313993659, 22.2, 1.0, 0.0], 
actual action is [4.075000000000001, 18], 
sim time next is 7771800.0000, 
raw observation next is [8.983333333333334, 47.33333333333334, 3.516666666666667, 358.3333333333333, 0.0, 0.0, 4.075000000000001, 14.22739718979765, 18.0, 21.77375945549792, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.5636752136752137, 0.47333333333333344, 0.31969696969696976, 0.9953703703703703, 0.0, 0.0, 0.5679166666666667, 0.1422739718979765, 0.0, 0.5391084936425601, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:48:02,295] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,295] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 16.07sec

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.05sec

[2017-11-02 10:48:02,547] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,547] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 13.28sec

[2017-11-02 10:48:03,073] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,076] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res13/Eplus-env-sub_run2
[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 18.02sec

[2017-11-02 10:48:03,293] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,296] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res12/Eplus-env-sub_run2
[2017-11-02 10:48:03,334] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,361] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res14/Eplus-env-sub_run2
[2017-11-02 10:48:03,548] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,551] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res15/Eplus-env-sub_run2
[2017-11-02 10:48:04,238] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:04,241] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res11/Eplus-env-sub_run2
[2017-11-02 10:48:38,517] A3C_AGENT_WORKER-Thread-6 INFO:Local step 26000, global step 414823: loss 86.0878
[2017-11-02 10:48:41,129] A3C_AGENT_WORKER-Thread-10 INFO:Local step 26000, global step 414910: loss -3.0324
[2017-11-02 10:48:43,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99193847e-01   5.11294289e-04   2.71629222e-04   3.39260538e-07
   2.30438036e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:48:43,544] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 2.7, 41.84081935629116, 18.0, 18.42791951267186, 21.5, 0.0, 0.0], 
actual action is [2.7, 18], 
sim time next is 15600.0000, 
raw observation next is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 2.7, 42.0865450271405, 18.0, 18.39946014218834, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5307692307692308, 0.93, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.545, 0.42086545027140504, 0.0, 0.05706573459833412, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:48:44,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 26000, global step 415054: loss -32.6907
[2017-11-02 10:48:49,962] A3C_AGENT_WORKER-Thread-7 INFO:Local step 26000, global step 415393: loss -16.0129
[2017-11-02 10:48:50,025] A3C_AGENT_WORKER-Thread-8 INFO:Local step 26000, global step 415395: loss 34.7165
[2017-11-02 10:48:51,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99762475e-01   1.94294407e-04   3.69484442e-05   2.12489496e-07
   6.02136788e-06   0.00000000e+00   2.38139380e-38   0.00000000e+00
   3.82522500e-36], sum to 1.0000
[2017-11-02 10:48:51,300] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 4.85, 212.5, 0.0, 0.0, 12.2, 19.00058029978402, 19.0, 20.52122900664196, 21.5, 0.0, 33.17066896904028], 
actual action is [2.2, 18], 
sim time next is 6600.0000, 
raw observation next is [7.199999999999999, 96.0, 4.933333333333334, 215.0, 0.0, 0.0, 2.2, 20.07448087299838, 18.0, 20.74390187517663, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.5179487179487179, 0.96, 0.4484848484848485, 0.5972222222222222, 0.0, 0.0, 0.5366666666666667, 0.2007448087299838, 0.0, 0.3919859821680899, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:48:52,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 26000, global step 415591: loss 93.9479
[2017-11-02 10:48:53,464] A3C_AGENT_WORKER-Thread-4 INFO:Local step 26000, global step 415636: loss 24.7058
[2017-11-02 10:48:56,415] A3C_AGENT_WORKER-Thread-17 INFO:Local step 26000, global step 415801: loss -16.0502
[2017-11-02 10:48:57,068] A3C_AGENT_WORKER-Thread-5 INFO:Local step 26000, global step 415847: loss 151.5591
[2017-11-02 10:48:59,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.05447721e-01   1.79555155e-02   7.23984167e-02   5.38877386e-04
   3.65948025e-03   4.69548056e-25   6.04422218e-25   2.28329439e-24
   4.56920050e-22], sum to 1.0000
[2017-11-02 10:48:59,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.658333333333334, 93.25, 5.058333333333334, 238.3333333333333, 0.0, 0.0, 12.61666666666667, 14.33568326892011, 23.0, 20.94236837450102, 21.5, 0.0, 49.86025545458869], 
actual action is [12.658333333333335, 22.0], 
sim time next is 14400.0000, 
raw observation next is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 12.65833333333333, 13.33449833736156, 22.0, 21.14045700274188, 21.5, 0.0, 39.21959922720863], 
processed observation next is [1.0, 0.17391304347826086, 0.5307692307692308, 0.93, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.7109722222222222, 0.1333449833736156, 0.5714285714285714, 0.44863671467741134, 0.5, 0.0, 0.46140704973186625], 
reward next is -0.4666. 
=============================================
[2017-11-02 10:49:02,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 26000, global step 416205: loss -22.7740
[2017-11-02 10:49:02,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-48.73719406]
 [-50.66049576]
 [-51.27514267]
 [-56.15449142]
 [-54.11884689]], R is [[-49.7937088 ]
 [-50.29577255]
 [-50.79281616]
 [-51.28488922]
 [-51.77204132]].
[2017-11-02 10:49:02,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.30422224e-08   8.19225417e-12   4.03351635e-14
   1.86272844e-10   4.90868911e-38   1.13608444e-35   1.22711811e-33
   7.08075949e-32], sum to 1.0000
[2017-11-02 10:49:02,972] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 4.1, 290.0, 0.0, 0.0, 10.0, 0.0, 20.0, 19.65446279971044, 21.5, 0.0, 25.89083793705264], 
actual action is [-5.0, 18], 
sim time next is 300.0000, 
raw observation next is [0.6, 95.08333333333333, 4.1, 281.6666666666666, 0.0, 0.0, -5.0, 29.19992417020309, 18.0, 19.65446279971044, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3487179487179487, 0.9508333333333333, 0.3727272727272727, 0.7824074074074071, 0.0, 0.0, 0.4166666666666667, 0.2919992417020309, 0.0, 0.23635182853006295, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:06,925] A3C_AGENT_WORKER-Thread-12 INFO:Local step 26000, global step 417270: loss 7.9490
[2017-11-02 10:49:06,935] A3C_AGENT_WORKER-Thread-11 INFO:Local step 26000, global step 417271: loss 221.0453
[2017-11-02 10:49:06,936] A3C_AGENT_WORKER-Thread-14 INFO:Local step 26000, global step 417271: loss 520.7566
[2017-11-02 10:49:07,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 26000, global step 417383: loss 72.2693
[2017-11-02 10:49:09,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 26000, global step 417966: loss -22.3410
[2017-11-02 10:49:13,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 26000, global step 418865: loss 1049.3673
[2017-11-02 10:49:17,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.15387599e-09   1.34873404e-10   2.00557071e-11
   5.54601469e-11   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:49:17,493] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.866666666666666, 74.41666666666667, 6.6, 260.8333333333333, 0.0, 0.0, 0.2666666666666666, 23.12819443067566, 20.0, 20.24373912272766, 21.5, 0.0, 50.87386791623217], 
actual action is [-9.866666666666667, 18], 
sim time next is 104400.0000, 
raw observation next is [-5.0, 74.0, 6.6, 260.0, 0.0, 0.0, -9.866666666666667, 25.66155755334948, 18.0, 20.36328118283569, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.20512820512820512, 0.74, 0.6, 0.7222222222222222, 0.0, 0.0, 0.33555555555555555, 0.2566155755334948, 0.0, 0.3376115975479555, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:27,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.90761805e-08   1.96487377e-08   1.33807544e-05
   9.99986529e-01], sum to 1.0000
[2017-11-02 10:49:28,034] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.341666666666667, 88.66666666666666, 7.491666666666667, 264.1666666666667, 0.0, 0.0, -7.25, 28.29100257359498, 18.0, 20.04913450817269, 21.5, 0.0, 0.0], 
actual action is [2.658333333333333, 23.0], 
sim time next is 96000.0000, 
raw observation next is [-2.433333333333333, 88.33333333333334, 7.533333333333333, 263.3333333333333, 0.0, 0.0, 2.658333333333333, 23.6801575280695, 23.0, 19.92283391393866, 21.5, 0.0, 94.98125950314184], 
processed observation next is [0.0, 0.08695652173913043, 0.2709401709401709, 0.8833333333333334, 0.6848484848484848, 0.7314814814814814, 0.0, 0.0, 0.5443055555555555, 0.236801575280695, 0.7142857142857143, 0.27469055913409435, 0.5, 0.0, 1.117426582389904], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:42,194] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   6.72192643e-28   1.74513212e-27   2.86349310e-28
   2.71929521e-27   4.34979164e-08   1.88508636e-07   1.12999638e-04
   9.99886751e-01], sum to 1.0000
[2017-11-02 10:49:42,349] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.591666666666667, 62.75, 7.408333333333333, 264.1666666666667, 0.0, 0.0, -2.55, 19.2644479554929, 24.0, 21.97602495638325, 22.7, 1.0, 58.37676977186145], 
actual action is [-2.591666666666667, 25], 
sim time next is 153600.0000, 
raw observation next is [-7.633333333333333, 63.0, 7.366666666666667, 263.3333333333333, 0.0, 0.0, -2.591666666666667, 18.99769110547826, 25.0, 21.96946002388026, 22.7, 1.0, 66.5938152895416], 
processed observation next is [0.0, 0.782608695652174, 0.13760683760683762, 0.63, 0.6696969696969698, 0.7314814814814814, 0.0, 0.0, 0.4568055555555555, 0.1899769110547826, 1.0, 0.56706571769718, 0.6714285714285714, 1.0, 0.7834566504651952], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:42,643] A3C_AGENT_WORKER-Thread-3 INFO:Local step 26500, global step 422388: loss -51.3774
[2017-11-02 10:49:42,805] A3C_AGENT_WORKER-Thread-6 INFO:Local step 26500, global step 422411: loss 166.6928
[2017-11-02 10:49:43,816] A3C_AGENT_WORKER-Thread-10 INFO:Local step 26500, global step 422521: loss 99.4379
[2017-11-02 10:49:44,486] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   3.62364860e-11   2.69895512e-11   9.21304786e-12
   8.20576593e-12   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.69996797e-37], sum to 1.0000
[2017-11-02 10:49:44,578] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.15, 66.33333333333334, 5.391666666666667, 265.8333333333333, 0.0, 0.0, -3.1, 19.65541061869074, 23.0, 22.02325753624048, 22.7, 1.0, 73.48795612549677], 
actual action is [-13.15, 18.0], 
sim time next is 157200.0000, 
raw observation next is [-8.2, 66.66666666666666, 5.133333333333333, 266.6666666666667, 0.0, 0.0, -13.15, 21.8729341361406, 18.0, 21.97315522432627, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.1230769230769231, 0.6666666666666665, 0.4666666666666666, 0.7407407407407408, 0.0, 0.0, 0.2808333333333334, 0.218729341361406, 0.0, 0.5675936034751814, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:46,177] A3C_AGENT_WORKER-Thread-7 INFO:Local step 26500, global step 422790: loss 145.9757
[2017-11-02 10:49:49,489] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.69546998e-11   8.01002875e-11   1.03086819e-11
   1.09597768e-10   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.10207185e-38], sum to 1.0000
[2017-11-02 10:49:49,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.52294461e-07   7.23969080e-08   2.25678901e-03
   9.97743011e-01], sum to 1.0000
[2017-11-02 10:49:49,525] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 3.6, 203.3333333333333, 0.0, 0.0, -3.9, 24.11359999922345, 20.0, 20.41910519581861, 21.5, 0.0, 47.19479145166197], 
actual action is [-13.9, 18], 
sim time next is 186300.0000, 
raw observation next is [-8.9, 78.0, 3.6, 202.5, 0.0, 0.0, -13.9, 27.19312650927852, 18.0, 20.40984088227815, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.10512820512820512, 0.78, 0.32727272727272727, 0.5625, 0.0, 0.0, 0.26833333333333337, 0.2719312650927852, 0.0, 0.34426298318259285, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:49,571] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 4.6, 200.0, 0.0, 0.0, -3.9, 24.86746545177719, 25.0, 20.32392944796966, 21.5, 0.0, 43.64123758466133], 
actual action is [-3.9000000000000004, 25], 
sim time next is 191100.0000, 
raw observation next is [-8.9, 78.0, 4.516666666666666, 199.1666666666667, 0.0, 0.0, -3.9, 24.89642617276728, 25.0, 20.29438979398038, 21.5, 0.0, 47.61463899149982], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.10512820512820512, 0.78, 0.41060606060606053, 0.5532407407407409, 0.0, 0.0, 0.435, 0.2489642617276728, 1.0, 0.32776997056862556, 0.5, 0.0, 0.5601722234294096], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:50,015] A3C_AGENT_WORKER-Thread-8 INFO:Local step 26500, global step 423309: loss 191.1449
[2017-11-02 10:49:50,289] A3C_AGENT_WORKER-Thread-4 INFO:Local step 26500, global step 423347: loss 123.2746
[2017-11-02 10:49:52,329] A3C_AGENT_WORKER-Thread-16 INFO:Local step 26500, global step 423586: loss -0.6069
[2017-11-02 10:49:52,668] A3C_AGENT_WORKER-Thread-17 INFO:Local step 26500, global step 423625: loss 23.0608
[2017-11-02 10:49:54,993] A3C_AGENT_WORKER-Thread-5 INFO:Local step 26500, global step 423869: loss -72.4912
[2017-11-02 10:49:55,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.93267179e-01   2.64843926e-04   2.44857580e-03   4.39300260e-04
   3.58009501e-03   4.61870674e-20   8.85618144e-20   2.00166816e-16
   7.50087180e-14], sum to 1.0000
[2017-11-02 10:49:55,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 76.33333333333333, 3.35, 205.8333333333333, 0.0, 0.0, -3.9, 21.40572018592975, 25.0, 20.77369079496346, 21.5, 0.0, 47.42806736284741], 
actual action is [-3.9000000000000004, 20.0], 
sim time next is 182400.0000, 
raw observation next is [-8.9, 76.66666666666667, 3.4, 206.6666666666667, 0.0, 0.0, -3.9, 21.22727129143222, 20.0, 20.77331276201971, 21.5, 0.0, 47.21193398840865], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.10512820512820512, 0.7666666666666667, 0.3090909090909091, 0.5740740740740742, 0.0, 0.0, 0.435, 0.2122727129143222, 0.2857142857142857, 0.3961875374313872, 0.5, 0.0, 0.5554345175106901], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:57,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.32702216e-10   1.85410054e-09   2.75262544e-04
   9.99724686e-01], sum to 1.0000
[2017-11-02 10:49:57,976] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  8.55762810e-02   2.28128880e-02   2.97380865e-01   3.95303704e-02
   5.54699600e-01   8.92940545e-16   3.25847519e-15   2.35801656e-11
   3.16499964e-08], sum to 1.0000
[2017-11-02 10:49:57,986] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.391666666666667, 75.25, 5.141666666666667, 199.1666666666667, 97.75, 0.0, -12.48333333333333, 24.9288846800076, 18.0, 21.44826040828915, 22.7, 1.0, 0.0], 
actual action is [-2.3916666666666666, 23.0], 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 5.1, 200.0, 101.5, 0.0, -2.391666666666667, 22.88648809289679, 23.0, 21.17221925175753, 22.7, 1.0, 96.86521486525085], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.14615384615384616, 0.75, 0.4636363636363636, 0.5555555555555556, 0.26851851851851855, 0.0, 0.46013888888888893, 0.2288648809289679, 0.7142857142857143, 0.4531741788225041, 0.6714285714285714, 1.0, 1.1395907631205981], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:58,031] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 78.0, 3.85, 185.0, 0.0, 0.0, -3.9, 27.03977118614745, 25.0, 19.80446326255588, 21.5, 0.0, 47.33039370868946], 
actual action is [-3.9000000000000004, 25.0], 
sim time next is 196500.0000, 
raw observation next is [-8.9, 78.0, 3.891666666666667, 184.1666666666667, 0.0, 0.0, -3.9, 26.88690527467702, 25.0, 19.79941166538428, 21.5, 0.0, 47.73108682117344], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.10512820512820512, 0.78, 0.3537878787878788, 0.5115740740740742, 0.0, 0.0, 0.435, 0.2688690527467702, 1.0, 0.2570588093406115, 0.5, 0.0, 0.5615421978961581], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:03,125] A3C_AGENT_WORKER-Thread-2 INFO:Local step 26500, global step 424665: loss 257.4252
[2017-11-02 10:50:03,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   1.81605445e-37   7.43212689e-36   3.30515099e-37
   8.89943570e-36   7.18372339e-09   1.68995431e-08   4.71356761e-04
   9.99528646e-01], sum to 1.0000
[2017-11-02 10:50:03,413] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.15, 66.33333333333334, 5.391666666666667, 265.8333333333333, 0.0, 0.0, -3.1, 19.69485013738373, 25.0, 21.49223060917167, 22.7, 1.0, 66.72386791921596], 
actual action is [-3.1500000000000004, 25], 
sim time next is 157200.0000, 
raw observation next is [-8.2, 66.66666666666666, 5.133333333333333, 266.6666666666667, 0.0, 0.0, -3.15, 19.06262537909176, 25.0, 21.65491211408975, 22.7, 1.0, 65.44712287496725], 
processed observation next is [0.0, 0.8260869565217391, 0.1230769230769231, 0.6666666666666665, 0.4666666666666666, 0.7407407407407408, 0.0, 0.0, 0.4475, 0.1906262537909176, 1.0, 0.5221303020128215, 0.6714285714285714, 1.0, 0.769966151470203], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:06,805] A3C_AGENT_WORKER-Thread-9 INFO:Local step 26500, global step 425053: loss -6.9708
[2017-11-02 10:50:06,932] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   5.19796714e-34   2.94700677e-33   2.96913320e-34
   1.53004872e-32   1.78125816e-08   3.45237723e-08   8.31159006e-04
   9.99168754e-01], sum to 1.0000
[2017-11-02 10:50:07,130] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.733333333333334, 78.0, 5.266666666666667, 196.6666666666667, 28.33333333333334, 249.6666666666667, -3.775, 22.13398029821787, 25.0, 20.75031360731368, 22.7, 1.0, 66.9483274515794], 
actual action is [-3.7333333333333343, 25], 
sim time next is 203100.0000, 
raw observation next is [-8.691666666666666, 78.0, 5.308333333333333, 195.8333333333333, 31.16666666666666, 272.8333333333333, -3.733333333333334, 21.48646366680258, 25.0, 20.81983479567774, 22.7, 1.0, 66.981765909265], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.11047008547008548, 0.78, 0.4825757575757575, 0.5439814814814814, 0.08245149911816577, 0.2728333333333333, 0.43777777777777777, 0.21486463666802583, 1.0, 0.402833542239677, 0.6714285714285714, 1.0, 0.7880207754031175], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:07,486] A3C_AGENT_WORKER-Thread-12 INFO:Local step 26500, global step 425126: loss -3.0030
[2017-11-02 10:50:08,585] A3C_AGENT_WORKER-Thread-13 INFO:Local step 26500, global step 425252: loss 6.3849
[2017-11-02 10:50:09,010] A3C_AGENT_WORKER-Thread-11 INFO:Local step 26500, global step 425298: loss -119.0730
[2017-11-02 10:50:09,845] A3C_AGENT_WORKER-Thread-14 INFO:Local step 26500, global step 425395: loss -31.9919
[2017-11-02 10:50:14,735] A3C_AGENT_WORKER-Thread-15 INFO:Local step 26500, global step 425998: loss 33.2485
[2017-11-02 10:50:17,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.54446178e-38   2.20230219e-36   1.78800808e-37
   1.46494204e-35   2.33286140e-10   1.35002864e-09   4.43679346e-05
   9.99955654e-01], sum to 1.0000
[2017-11-02 10:50:17,565] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 4.016666666666667, 181.6666666666667, 0.0, 0.0, -3.9, 24.2639486776736, 25.0, 20.09674008238567, 21.5, 0.0, 42.8883572569722], 
actual action is [-3.9000000000000004, 25], 
sim time next is 197700.0000, 
raw observation next is [-8.9, 78.0, 4.058333333333333, 180.8333333333333, 0.0, 0.0, -3.9, 24.34268231132097, 25.0, 20.0681660901451, 21.5, 0.0, 46.79991850777193], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.10512820512820512, 0.78, 0.3689393939393939, 0.5023148148148147, 0.0, 0.0, 0.435, 0.2434268231132097, 1.0, 0.2954522985921569, 0.5, 0.0, 0.5505872765620227], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:25,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.58845944e-07   2.73462547e-07   7.72221363e-04
   9.99227285e-01], sum to 1.0000
[2017-11-02 10:50:25,216] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 65.0, 6.433333333333334, 220.0, 0.0, 0.0, 1.600000000000001, 12.97953109863169, 25.0, 23.03939933436567, 22.7, 1.0, 52.54728663007107], 
actual action is [1.6, 25], 
sim time next is 238500.0000, 
raw observation next is [-3.4, 65.0, 6.35, 220.0, 0.0, 0.0, 1.6, 12.99243579264335, 25.0, 23.0293864213539, 22.7, 1.0, 56.23606789162845], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.24615384615384614, 0.65, 0.5772727272727273, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.1299243579264335, 1.0, 0.7184837744791288, 0.6714285714285714, 1.0, 0.6616007987250406], 
reward next is -0.6084. 
=============================================
[2017-11-02 10:50:33,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.91735045e-32   9.27101963e-20   9.55565351e-19   1.01007934e-18
   7.19407974e-19   5.06273601e-09   7.32141414e-09   1.01429527e-04
   9.99898553e-01], sum to 1.0000
[2017-11-02 10:50:33,438] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.96666666666667, 68.0, 6.5, 256.6666666666667, 0.0, 0.0, -5.875, 22.33842110792085, 25.0, 20.33265316750819, 21.5, 0.0, 49.2583993117176], 
actual action is [-5.96666666666667, 25], 
sim time next is 278700.0000, 
raw observation next is [-11.05833333333333, 68.25, 6.324999999999999, 255.8333333333333, 0.0, 0.0, -5.96666666666667, 22.45563345023814, 25.0, 20.31246118997922, 21.5, 0.0, 49.18106152170523], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.04978632478632487, 0.6825, 0.575, 0.710648148148148, 0.0, 0.0, 0.4005555555555555, 0.22455633450238138, 1.0, 0.3303515985684601, 0.5, 0.0, 0.5786007237847675], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:45,059] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.49711248e-08   1.05257900e-08   1.13622031e-04
   9.99886394e-01], sum to 1.0000
[2017-11-02 10:50:45,209] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.399999999999999, 65.0, 5.683333333333334, 220.0, 0.0, 0.0, 1.6, 10.57693321161322, 25.0, 23.6921042804631, 22.7, 1.0, 61.8156038893245], 
actual action is [1.600000000000001, 25], 
sim time next is 241200.0000, 
raw observation next is [-3.4, 65.0, 5.6, 220.0, 0.0, 0.0, 1.600000000000001, 10.53790855385405, 25.0, 23.7015860605452, 22.7, 1.0, 61.73862788593065], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.24615384615384614, 0.65, 0.509090909090909, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.1053790855385405, 1.0, 0.8145122943636, 0.6714285714285714, 1.0, 0.7263367986580076], 
reward next is -0.6642. 
=============================================
[2017-11-02 10:51:01,909] A3C_AGENT_WORKER-Thread-3 INFO:Local step 27000, global step 430689: loss -4.2361
[2017-11-02 10:51:02,712] A3C_AGENT_WORKER-Thread-6 INFO:Local step 27000, global step 430774: loss -14.9536
[2017-11-02 10:51:03,285] A3C_AGENT_WORKER-Thread-7 INFO:Local step 27000, global step 430827: loss -94.5083
[2017-11-02 10:51:04,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.09045114e-02   1.95299042e-04   1.41845003e-03
   9.87481713e-01], sum to 1.0000
[2017-11-02 10:51:04,170] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-11.51666666666667, 55.66666666666666, 5.183333333333333, 271.6666666666666, 0.0, 0.0, -6.425000000000001, 13.69537130814438, 25.0, 22.70101084067651, 22.7, 1.0, 65.06468721519252], 
actual action is [-6.516666666666669, 25], 
sim time next is 323700.0000, 
raw observation next is [-11.60833333333333, 56.33333333333334, 5.141666666666667, 270.8333333333334, 0.0, 0.0, -6.516666666666669, 13.66718724893696, 25.0, 22.70523143556236, 22.7, 1.0, 64.6475721168983], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.03568376068376075, 0.5633333333333335, 0.4674242424242424, 0.7523148148148151, 0.0, 0.0, 0.39138888888888884, 0.1366718724893696, 1.0, 0.6721759193660516, 0.6714285714285714, 1.0, 0.7605596719635095], 
reward next is -0.6982. 
=============================================
[2017-11-02 10:51:04,477] A3C_AGENT_WORKER-Thread-10 INFO:Local step 27000, global step 430933: loss 0.3962
[2017-11-02 10:51:09,645] A3C_AGENT_WORKER-Thread-4 INFO:Local step 27000, global step 431359: loss 60.7586
[2017-11-02 10:51:10,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 27000, global step 431454: loss -24.5629
[2017-11-02 10:51:10,869] A3C_AGENT_WORKER-Thread-17 INFO:Local step 27000, global step 431475: loss -1.6861
[2017-11-02 10:51:13,437] A3C_AGENT_WORKER-Thread-8 INFO:Local step 27000, global step 431716: loss -4.9963
[2017-11-02 10:51:14,040] A3C_AGENT_WORKER-Thread-5 INFO:Local step 27000, global step 431772: loss 11.6073
[2017-11-02 10:51:23,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.92320760e-21   9.79803304e-12   1.56243291e-12   9.73068934e-12
   1.15791686e-12   2.30926881e-03   9.05672926e-03   3.19887022e-03
   9.85435128e-01], sum to 1.0000
[2017-11-02 10:51:23,940] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-9.958333333333332, 46.08333333333333, 7.908333333333333, 275.8333333333333, 84.0, 747.4166666666666, -5.050000000000001, 9.828924362747635, 25.0, 23.30810238216409, 22.7, 1.0, 63.47449804740609], 
actual action is [-4.958333333333332, 25], 
sim time next is 304800.0000, 
raw observation next is [-9.866666666666667, 45.66666666666667, 7.866666666666666, 276.6666666666667, 85.0, 736.8333333333334, -4.958333333333332, 9.822511617124762, 25.0, 23.31767146961392, 22.7, 1.0, 63.49464923151642], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.08034188034188033, 0.4566666666666667, 0.7151515151515151, 0.7685185185185186, 0.22486772486772486, 0.7368333333333333, 0.4173611111111111, 0.09822511617124763, 1.0, 0.7596673528019886, 0.6714285714285714, 1.0, 0.7469958733119578], 
reward next is -0.6821. 
=============================================
[2017-11-02 10:51:25,980] A3C_AGENT_WORKER-Thread-2 INFO:Local step 27000, global step 433012: loss 1.2686
[2017-11-02 10:51:28,040] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   8.13363306e-03   5.92170749e-03   9.47763212e-04
   9.84996915e-01], sum to 1.0000
[2017-11-02 10:51:28,149] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.1, 69.66666666666667, 5.516666666666667, 256.6666666666667, 0.0, 0.0, -10.05, 27.19584518187707, 25.0, 19.79302024664793, 21.5, 0.0, 49.63373202428961], 
actual action is [-10.1, 25], 
sim time next is 357300.0000, 
raw observation next is [-15.15, 70.0, 5.475, 255.0, 0.0, 0.0, -10.1, 27.39483627440861, 25.0, 19.76465203399081, 21.5, 0.0, 49.60053728502444], 
processed observation next is [0.5, 0.13043478260869565, -0.05512820512820514, 0.7, 0.4977272727272727, 0.7083333333333334, 0.0, 0.0, 0.33166666666666667, 0.2739483627440861, 1.0, 0.25209314771297286, 0.5, 0.0, 0.5835357327649934], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:28,579] A3C_AGENT_WORKER-Thread-12 INFO:Local step 27000, global step 433270: loss 0.2784
[2017-11-02 10:51:28,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 27000, global step 433280: loss 0.6589
[2017-11-02 10:51:30,930] A3C_AGENT_WORKER-Thread-11 INFO:Local step 27000, global step 433493: loss 1.8725
[2017-11-02 10:51:31,535] A3C_AGENT_WORKER-Thread-14 INFO:Local step 27000, global step 433548: loss 0.5941
[2017-11-02 10:51:32,815] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.78167892e-03   5.63685491e-04   9.74793744e-04
   9.95679855e-01], sum to 1.0000
[2017-11-02 10:51:32,918] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-16.2, 78.0, 5.475, 260.0, 0.0, 0.0, -11.2, 36.8870088735915, 25.0, 18.57541701587479, 21.5, 0.0, 50.16252839253289], 
actual action is [-11.2, 25], 
sim time next is 370200.0000, 
raw observation next is [-16.2, 78.0, 5.516666666666667, 260.0, 0.0, 0.0, -11.2, 37.13069695608661, 25.0, 18.54759149551651, 21.5, 0.0, 50.20789531327404], 
processed observation next is [0.5, 0.2608695652173913, -0.08205128205128204, 0.78, 0.5015151515151515, 0.7222222222222222, 0.0, 0.0, 0.31333333333333335, 0.3713069695608661, 1.0, 0.0782273565023586, 0.5, 0.0, 0.5906811213326357], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:33,981] A3C_AGENT_WORKER-Thread-13 INFO:Local step 27000, global step 433740: loss 0.6261
[2017-11-02 10:51:35,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00497956
  0.01331706  0.30666757  0.67503583], sum to 1.0000
[2017-11-02 10:51:36,165] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-12.675, 68.25, 5.85, 287.5, 0.0, 0.0, -7.633333333333329, 12.36054669106726, 25.0, 22.90243233823855, 22.7, 1.0, 64.45576733363862], 
actual action is [-7.675000000000001, 25], 
sim time next is 330600.0000, 
raw observation next is [-12.71666666666667, 68.83333333333333, 5.933333333333333, 288.3333333333334, 0.0, 0.0, -7.675000000000001, 12.42629222059024, 25.0, 22.88715289354367, 22.7, 1.0, 64.54539591344543], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.007264957264957171, 0.6883333333333332, 0.5393939393939393, 0.8009259259259262, 0.0, 0.0, 0.3720833333333333, 0.12426292220590239, 1.0, 0.6981646990776673, 0.6714285714285714, 1.0, 0.759357598981711], 
reward next is -0.6958. 
=============================================
[2017-11-02 10:51:36,978] A3C_AGENT_WORKER-Thread-15 INFO:Local step 27000, global step 433984: loss -0.9243
[2017-11-02 10:51:39,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0168792
  0.0055526   0.87583572  0.10173247], sum to 1.0000
[2017-11-02 10:51:39,967] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-14.775, 72.0, 4.1, 225.0, 47.0, 735.75, -9.86666666666667, 24.14799996920584, 25.0, 20.72221936348177, 22.7, 1.0, 63.38608958662753], 
actual action is [-9.775, 25], 
sim time next is 381000.0000, 
raw observation next is [-14.68333333333333, 70.0, 3.933333333333333, 223.3333333333333, 49.66666666666666, 735.0, -9.775, 23.74548394623149, 25.0, 20.79636698138441, 22.7, 1.0, 63.13067701146036], 
processed observation next is [0.5, 0.391304347826087, -0.04316239316239308, 0.7, 0.35757575757575755, 0.6203703703703702, 0.1313932980599647, 0.735, 0.33708333333333335, 0.2374548394623149, 1.0, 0.39948099734062986, 0.6714285714285714, 1.0, 0.7427138471936513], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:44,024] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-103.43919373]
 [-104.46818542]
 [-106.00250244]
 [-107.5440979 ]
 [-102.97489166]], R is [[-105.55390167]
 [-105.49836731]
 [-105.44338226]
 [-105.38894653]
 [-105.33506012]].
[2017-11-02 10:51:47,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   6.53707514e-32   1.36502377e-31   4.77284185e-31
   1.81494785e-32   4.70832980e-04   6.22020522e-03   8.67546499e-01
   1.25762433e-01], sum to 1.0000
[2017-11-02 10:51:47,411] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-11.6, 50.58333333333334, 6.583333333333333, 220.8333333333333, 56.25, 894.5, -6.699999999999999, 22.01397496462673, 25.0, 21.114063741199, 22.7, 1.0, 65.97383253856853], 
actual action is [-6.6, 25], 
sim time next is 393000.0000, 
raw observation next is [-11.5, 50.16666666666666, 6.566666666666666, 221.6666666666667, 56.0, 893.0, -6.6, 21.50989136993854, 25.0, 21.1909422994022, 22.7, 1.0, 65.63638085693593], 
processed observation next is [0.5, 0.5652173913043478, 0.038461538461538464, 0.5016666666666666, 0.5969696969696969, 0.6157407407407409, 0.14814814814814814, 0.893, 0.38999999999999996, 0.21509891369938539, 1.0, 0.4558488999145998, 0.6714285714285714, 1.0, 0.7721927159639521], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:49,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-118.1299057 ]
 [-116.3433609 ]
 [-117.6599884 ]
 [-117.08818054]
 [-118.29971313]], R is [[-117.65307617]
 [-117.47654724]
 [-117.3017807 ]
 [-117.12876129]
 [-116.95747375]].
[2017-11-02 10:52:07,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.54856014e-01   5.71106672e-02   3.97565454e-01   1.86927512e-01
   3.39622423e-03   3.01933198e-08   6.74705461e-06   4.41969814e-06
   1.32929505e-04], sum to 1.0000
[2017-11-02 10:52:07,371] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-10.41666666666667, 45.5, 6.375, 230.8333333333333, 50.91666666666666, 854.9166666666667, -5.5, 15.97220416122228, 25.0, 22.3329142591903, 22.7, 1.0, 56.29794533030373], 
actual action is [-5.41666666666667, 24.5], 
sim time next is 396600.0000, 
raw observation next is [-10.33333333333333, 45.0, 6.350000000000001, 231.6666666666667, 50.33333333333333, 850.3333333333334, -5.41666666666667, 15.77351642829887, 24.5, 22.3425139386093, 22.7, 1.0, 62.84415063287059], 
processed observation next is [0.5, 0.6086956521739131, 0.06837606837606845, 0.45, 0.5772727272727274, 0.6435185185185186, 0.13315696649029982, 0.8503333333333334, 0.40972222222222215, 0.1577351642829887, 0.9285714285714286, 0.620359134087043, 0.6714285714285714, 1.0, 0.7393429486220069], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:17,811] A3C_AGENT_WORKER-Thread-6 INFO:Local step 27500, global step 438185: loss -25.7576
[2017-11-02 10:52:18,628] A3C_AGENT_WORKER-Thread-3 INFO:Local step 27500, global step 438264: loss 127.9223
[2017-11-02 10:52:20,084] A3C_AGENT_WORKER-Thread-7 INFO:Local step 27500, global step 438384: loss 1.0497
[2017-11-02 10:52:22,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00111346
  0.01116488  0.00752968  0.98019195], sum to 1.0000
[2017-11-02 10:52:22,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.783333333333333, 32.16666666666666, 3.933333333333333, 178.3333333333333, 74.0, 0.0, 0.07500000000000018, 20.28939787861349, 25.0, 21.54221320587467, 22.7, 1.0, 63.11850308415741], 
actual action is [0.21666666666666679, 25], 
sim time next is 467700.0000, 
raw observation next is [-4.641666666666667, 32.08333333333334, 3.766666666666667, 179.1666666666667, 77.0, 0.0, 0.2166666666666668, 20.00361336393121, 25.0, 21.59958865998311, 22.7, 1.0, 62.88468980476539], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.21431623931623933, 0.3208333333333334, 0.34242424242424246, 0.49768518518518534, 0.2037037037037037, 0.0, 0.5036111111111111, 0.20003613363931208, 1.0, 0.5142269514261584, 0.6714285714285714, 1.0, 0.7398198800560634], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:23,605] A3C_AGENT_WORKER-Thread-10 INFO:Local step 27500, global step 438689: loss -16.6537
[2017-11-02 10:52:25,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.02503327e-11   1.08320915e-10   2.42139607e-11
   8.77054722e-13   0.00000000e+00   4.58322745e-38   0.00000000e+00
   8.46306966e-37], sum to 1.0000
[2017-11-02 10:52:25,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-11.15, 51.5, 3.3, 195.0, 0.0, 0.0, -6.05833333333333, 21.02802700990436, 20.0, 21.36272131817135, 21.5, 0.0, 48.24846911344121], 
actual action is [-16.15, 18], 
sim time next is 426900.0000, 
raw observation next is [-11.24166666666667, 51.91666666666667, 3.35, 194.1666666666667, 0.0, 0.0, -16.15, 23.8169492368133, 18.0, 21.35401418031176, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.04508547008546998, 0.5191666666666667, 0.30454545454545456, 0.539351851851852, 0.0, 0.0, 0.23083333333333336, 0.238169492368133, 0.0, 0.47914488290168017, 0.5, 0.0, 0.0], 
reward next is -0.0209. 
=============================================
[2017-11-02 10:52:27,111] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  6.87055290e-04   2.53232196e-04   4.83180955e-03   9.07316164e-04
   8.93443284e-05   9.33208095e-04   1.94123033e-02   2.30520521e-03
   9.70580518e-01], sum to 1.0000
[2017-11-02 10:52:27,356] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 32.0, 3.6, 180.0, 80.0, 0.0, 0.3583333333333334, 19.189688850604, 25.0, 21.72109248519095, 22.7, 1.0, 62.62247543516149], 
actual action is [0.5, 25], 
sim time next is 468300.0000, 
raw observation next is [-4.316666666666666, 31.66666666666666, 3.683333333333333, 183.3333333333333, 83.0, 0.0, 0.5, 18.91715867326695, 25.0, 21.77695799951753, 22.7, 1.0, 62.43573121462858], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.22264957264957266, 0.3166666666666666, 0.33484848484848484, 0.5092592592592591, 0.21957671957671956, 0.0, 0.5083333333333333, 0.1891715867326695, 1.0, 0.5395654285025044, 0.6714285714285714, 1.0, 0.7345380142897481], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:27,455] A3C_AGENT_WORKER-Thread-16 INFO:Local step 27500, global step 439113: loss -20.7978
[2017-11-02 10:52:30,437] A3C_AGENT_WORKER-Thread-4 INFO:Local step 27500, global step 439463: loss -30.6880
[2017-11-02 10:52:30,581] A3C_AGENT_WORKER-Thread-17 INFO:Local step 27500, global step 439480: loss 2.2636
[2017-11-02 10:52:30,751] A3C_AGENT_WORKER-Thread-8 INFO:Local step 27500, global step 439499: loss -14.3424
[2017-11-02 10:52:31,505] A3C_AGENT_WORKER-Thread-5 INFO:Local step 27500, global step 439584: loss 14.7415
[2017-11-02 10:52:42,578] A3C_AGENT_WORKER-Thread-2 INFO:Local step 27500, global step 440666: loss 0.6022
[2017-11-02 10:52:46,782] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   1.22293195e-38   0.00000000e+00
   0.00000000e+00   7.25076534e-04   6.29628589e-03   5.27778920e-03
   9.87700820e-01], sum to 1.0000
[2017-11-02 10:52:46,834] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.925, 86.5, 6.1, 275.0, 0.0, 0.0, 8.966666666666667, 6.204506645741499, 25.0, 23.9660422358322, 21.5, 0.0, 43.94006456422461], 
actual action is [8.925, 25], 
sim time next is 528600.0000, 
raw observation next is [3.883333333333333, 86.33333333333334, 6.1, 276.6666666666667, 0.0, 0.0, 8.925, 6.155671363865855, 25.0, 23.97144022542276, 21.5, 0.0, 44.4285133580196], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.43290598290598287, 0.8633333333333334, 0.5545454545454546, 0.7685185185185186, 0.0, 0.0, 0.6487499999999999, 0.06155671363865855, 1.0, 0.8530628893461086, 0.5, 0.0, 0.5226883924472894], 
reward next is -0.4704. 
=============================================
[2017-11-02 10:52:47,103] A3C_AGENT_WORKER-Thread-9 INFO:Local step 27500, global step 441142: loss 0.6605
[2017-11-02 10:52:47,489] A3C_AGENT_WORKER-Thread-14 INFO:Local step 27500, global step 441187: loss -2.1193
[2017-11-02 10:52:47,903] A3C_AGENT_WORKER-Thread-11 INFO:Local step 27500, global step 441235: loss 1.2103
[2017-11-02 10:52:47,970] A3C_AGENT_WORKER-Thread-12 INFO:Local step 27500, global step 441240: loss 1.0865
[2017-11-02 10:52:50,697] A3C_AGENT_WORKER-Thread-13 INFO:Local step 27500, global step 441580: loss 4.4363
[2017-11-02 10:52:54,526] A3C_AGENT_WORKER-Thread-15 INFO:Local step 27500, global step 442041: loss 0.7236
[2017-11-02 10:53:04,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.22925803e-10   9.21073773e-10   5.12654752e-10
   3.73069770e-11   9.00788656e-31   1.91325883e-29   3.48717565e-30
   1.80630336e-29], sum to 1.0000
[2017-11-02 10:53:04,426] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.341666666666667, 84.33333333333333, 6.1, 288.3333333333333, 0.0, 0.0, -1.566666666666666, 14.52073427000118, 18.0, 21.83758971865599, 21.5, 0.0, 0.0], 
actual action is [-1.6583333333333332, 18], 
sim time next is 531000.0000, 
raw observation next is [3.25, 84.0, 6.1, 290.0, 0.0, 0.0, -1.658333333333333, 15.96604436045766, 18.0, 21.87865704737865, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.4166666666666667, 0.84, 0.5545454545454546, 0.8055555555555556, 0.0, 0.0, 0.4723611111111111, 0.1596604436045766, 0.0, 0.5540938639112356, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:53:08,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.12273085e-01   3.11635877e-03   1.56766281e-01   2.58788336e-02
   1.96330459e-03   8.42953085e-09   8.98080089e-07   1.74468333e-08
   1.17017396e-06], sum to 1.0000
[2017-11-02 10:53:08,485] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.6, 85.0, 6.1, 280.0, 0.0, 0.0, -3.308333333333333, 20.62230990679152, 18.0, 21.00328896648827, 21.5, 0.0, 0.0], 
actual action is [-3.4, 18], 
sim time next is 536700.0000, 
raw observation next is [1.558333333333334, 85.24999999999999, 6.016666666666666, 279.9999999999999, 0.0, 0.0, -3.4, 22.53537884264912, 18.0, 20.94821557303171, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.3732905982905983, 0.8524999999999998, 0.5469696969696969, 0.7777777777777775, 0.0, 0.0, 0.44333333333333336, 0.2253537884264912, 0.0, 0.4211736532902443, 0.5, 0.0, 0.0], 
reward next is -0.0788. 
=============================================
[2017-11-02 10:53:08,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00878882
  0.43894276  0.01143623  0.54083228], sum to 1.0000
[2017-11-02 10:53:08,883] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.75, 90.33333333333334, 5.391666666666666, 285.8333333333334, 0.0, 0.0, -4.2, 27.00149231780817, 18.0, 20.59103765117712, 21.5, 0.0, 0.0], 
actual action is [5.75, 19.0], 
sim time next is 542400.0000, 
raw observation next is [0.7000000000000001, 90.66666666666666, 5.433333333333334, 286.6666666666666, 0.0, 0.0, 5.75, 23.31336416761033, 19.0, 20.30882267303637, 21.5, 0.0, 84.96132622695693], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.35128205128205126, 0.9066666666666666, 0.49393939393939396, 0.7962962962962961, 0.0, 0.0, 0.5958333333333333, 0.23313364167610331, 0.14285714285714285, 0.32983181043376725, 0.5, 0.0, 0.9995450144347874], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:53:11,360] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28000, global step 445296: loss 5.6584
[2017-11-02 10:53:11,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.99309301e-01   7.75522931e-05   3.59782018e-04   2.11530758e-04
   4.09745808e-05   2.00508321e-08   4.61987923e-07   2.37891644e-08
   3.58700220e-07], sum to 1.0000
[2017-11-02 10:53:11,777] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.4166666666666667, 91.83333333333334, 5.35, 293.3333333333334, 23.0, 71.00000000000001, 5.458333333333333, 12.41885857591736, 25.0, 21.79402646714256, 22.7, 1.0, 69.44134718093409], 
actual action is [5.416666666666667, 20.0], 
sim time next is 548100.0000, 
raw observation next is [0.375, 91.75, 5.475, 295.0, 25.75, 79.25, 5.416666666666667, 12.12224356791404, 20.0, 21.92843289406641, 22.7, 1.0, 50.05863693728469], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.34294871794871795, 0.9175, 0.4977272727272727, 0.8194444444444444, 0.06812169312169312, 0.07925, 0.5902777777777778, 0.1212224356791404, 0.2857142857142857, 0.5612046991523444, 0.6714285714285714, 1.0, 0.5889251404386434], 
reward next is -0.5422. 
=============================================
[2017-11-02 10:53:12,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02440093
  0.80799866  0.02833496  0.13926543], sum to 1.0000
[2017-11-02 10:53:12,497] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.8, 87.0, 5.558333333333333, 270.0, 0.0, 0.0, 2.2, 10.49742883123564, 25.0, 23.22134621642398, 21.5, 0.0, 45.59027526395683], 
actual action is [2.2, 25], 
sim time next is 587400.0000, 
raw observation next is [-2.8, 87.0, 5.516666666666667, 270.0, 0.0, 0.0, 2.2, 10.37343165226697, 25.0, 23.26085081777558, 21.5, 0.0, 45.57250808388185], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.2615384615384615, 0.87, 0.5015151515151515, 0.75, 0.0, 0.0, 0.5366666666666667, 0.10373431652266969, 1.0, 0.7515501168250829, 0.5, 0.0, 0.5361471539280218], 
reward next is -0.4825. 
=============================================
[2017-11-02 10:53:13,205] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28000, global step 445536: loss 51.7797
[2017-11-02 10:53:13,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   7.02214509e-10   3.68248609e-09   5.78664938e-09
   7.66960051e-10   2.53563684e-26   3.64120878e-24   8.97262042e-26
   1.03081815e-24], sum to 1.0000
[2017-11-02 10:53:13,258] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 87.0, 5.308333333333334, 270.0, 0.0, 0.0, 2.2, 10.22545128654459, 21.5, 23.35063434583619, 21.5, 0.0, 34.48886997475696], 
actual action is [-7.8, 18], 
sim time next is 589200.0000, 
raw observation next is [-2.8, 87.0, 5.266666666666666, 270.0, 0.0, 0.0, -7.8, 11.65757802021534, 18.0, 23.32753699624895, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.2615384615384615, 0.87, 0.4787878787878787, 0.75, 0.0, 0.0, 0.37, 0.1165757802021534, 0.0, 0.7610767137498498, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:53:14,703] A3C_AGENT_WORKER-Thread-7 INFO:Local step 28000, global step 445838: loss 8.7254
[2017-11-02 10:53:15,631] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28000, global step 446019: loss -269.5849
[2017-11-02 10:53:17,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   7.00539808e-31   4.84523010e-30   3.18204365e-30
   2.02615824e-31   8.87840346e-04   7.33056784e-01   1.98066365e-02
   2.46248662e-01], sum to 1.0000
[2017-11-02 10:53:17,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.7833333333333334, 81.16666666666667, 6.1, 329.1666666666667, 106.0833333333333, 243.75, 4.233333333333333, 12.68825435593955, 21.0, 22.45461467044509, 22.7, 1.0, 32.48718600017236], 
actual action is [4.216666666666667, 22.0], 
sim time next is 561600.0000, 
raw observation next is [-0.8, 81.0, 6.1, 330.0, 109.5, 265.5, 4.216666666666667, 12.82545552211372, 22.0, 22.45758485540058, 22.7, 1.0, 29.43141189194389], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.3128205128205128, 0.81, 0.5545454545454546, 0.9166666666666666, 0.2896825396825397, 0.2655, 0.5702777777777778, 0.12825455522113718, 0.5714285714285714, 0.636797836485797, 0.6714285714285714, 1.0, 0.34625190461110456], 
reward next is -0.3245. 
=============================================
[2017-11-02 10:53:21,660] A3C_AGENT_WORKER-Thread-8 INFO:Local step 28000, global step 446889: loss -22.0088
[2017-11-02 10:53:22,612] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28000, global step 447015: loss -44.5008
[2017-11-02 10:53:22,677] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28000, global step 447026: loss -72.0066
[2017-11-02 10:53:25,197] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28000, global step 447356: loss -46.0092
[2017-11-02 10:53:25,560] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28000, global step 447401: loss -45.4295
[2017-11-02 10:53:30,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99996781e-01   5.83446933e-07   3.53123312e-07   2.26736893e-06
   2.56333053e-08   1.16963656e-15   9.44942299e-14   5.52343663e-15
   1.58093590e-13], sum to 1.0000
[2017-11-02 10:53:30,174] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 54.0, 8.2, 250.0, 55.0, 26.5, 4.4, 13.05423696720178, 25.0, 22.73053306619569, 22.7, 1.0, 53.28897927127805], 
actual action is [4.4, 20.0], 
sim time next is 662700.0000, 
raw observation next is [-0.6499999999999999, 54.25, 8.2, 250.8333333333333, 50.33333333333333, 24.58333333333333, 4.4, 12.47491739109999, 20.0, 22.74035507491993, 22.7, 1.0, 67.21349502759621], 
processed observation next is [1.0, 0.6956521739130435, 0.31666666666666665, 0.5425, 0.7454545454545454, 0.6967592592592591, 0.13315696649029982, 0.02458333333333333, 0.5733333333333334, 0.12474917391099989, 0.2857142857142857, 0.6771935821314184, 0.6714285714285714, 1.0, 0.7907470003246613], 
reward next is -0.7241. 
=============================================
[2017-11-02 10:53:30,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   7.45589701e-10   7.80084664e-10   4.85414597e-09
   2.93398292e-11   3.20373580e-31   1.42624607e-29   5.02666634e-31
   9.55842943e-30], sum to 1.0000
[2017-11-02 10:53:30,810] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 83.0, 4.1, 260.0, 0.0, 0.0, 1.65, 19.55709849896449, 19.0, 20.9182036846031, 21.5, 0.0, 38.43289958269197], 
actual action is [-8.4, 18], 
sim time next is 601500.0000, 
raw observation next is [-3.399999999999999, 83.33333333333333, 4.141666666666666, 260.0, 0.0, 0.0, -8.4, 20.78241758187729, 18.0, 21.00166285781104, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.2461538461538462, 0.8333333333333333, 0.3765151515151514, 0.7222222222222222, 0.0, 0.0, 0.36000000000000004, 0.2078241758187729, 0.0, 0.42880897968729165, 0.5, 0.0, 0.0], 
reward next is -0.0712. 
=============================================
[2017-11-02 10:53:33,367] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28000, global step 448543: loss 47.6337
[2017-11-02 10:53:36,960] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28000, global step 449076: loss -26.9941
[2017-11-02 10:53:37,420] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28000, global step 449147: loss 67.9303
[2017-11-02 10:53:37,855] A3C_AGENT_WORKER-Thread-9 INFO:Local step 28000, global step 449216: loss 10.7482
[2017-11-02 10:53:38,161] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28000, global step 449270: loss -127.9715
[2017-11-02 10:53:40,490] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.01375801e-05   1.47548818e-03   9.86526429e-05
   9.98385787e-01], sum to 1.0000
[2017-11-02 10:53:40,619] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.05, 58.5, 7.825, 260.0, 106.25, 65.25, -6.1, 23.13498284975023, 18.0, 21.5083729655905, 22.7, 1.0, 0.0], 
actual action is [3.95, 23.0], 
sim time next is 656400.0000, 
raw observation next is [-1.0, 58.00000000000001, 7.866666666666667, 260.0, 97.83333333333333, 62.16666666666667, 3.95, 19.4555790479704, 23.0, 21.32287971292582, 22.7, 1.0, 106.1906964362311], 
processed observation next is [1.0, 0.6086956521739131, 0.3076923076923077, 0.5800000000000001, 0.7151515151515152, 0.7222222222222222, 0.2588183421516755, 0.06216666666666667, 0.5658333333333334, 0.194555790479704, 0.7142857142857143, 0.47469710184654546, 0.6714285714285714, 1.0, 1.2493023110144834], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:53:40,865] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28000, global step 449774: loss -30.0217
[2017-11-02 10:53:40,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-78.12877655]
 [-75.94465637]
 [-79.71445465]
 [-79.94161987]
 [-75.72901154]], R is [[-75.78372955]
 [-76.02589417]
 [-76.26563263]
 [-76.50297546]
 [-76.73794556]].
[2017-11-02 10:53:44,134] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28000, global step 450182: loss -196.8661
[2017-11-02 10:53:44,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-87.29421234]
 [-87.2723999 ]
 [-84.9753952 ]
 [-88.76815033]
 [-87.8760376 ]], R is [[-86.44460297]
 [-85.6149826 ]
 [-85.28937531]
 [-84.93650055]
 [-84.57946777]].
[2017-11-02 10:53:55,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   1.65735958e-30   3.66769856e-29   1.20528620e-31
   1.20241253e-29   1.18064654e-05   6.31526229e-04   2.83101399e-05
   9.99328375e-01], sum to 1.0000
[2017-11-02 10:53:55,190] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 76.0, 5.266666666666667, 253.3333333333333, 0.0, 0.0, 2.7, 21.17821940400679, 25.0, 20.42497770120241, 21.5, 0.0, 53.34740353725905], 
actual action is [2.7, 25], 
sim time next is 711900.0000, 
raw observation next is [-2.3, 76.0, 5.35, 252.5, 0.0, 0.0, 2.7, 20.3593345456032, 25.0, 20.52159418652937, 21.5, 0.0, 48.95452111750554], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.76, 0.48636363636363633, 0.7013888888888888, 0.0, 0.0, 0.545, 0.203593345456032, 1.0, 0.36022774093276716, 0.5, 0.0, 0.5759355425588888], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:05,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99923348e-01   6.77357548e-06   6.55294280e-05   4.58030939e-07
   3.76454409e-06   3.56312940e-26   2.51745299e-23   6.12222820e-25
   1.48462895e-21], sum to 1.0000
[2017-11-02 10:54:05,412] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.2333333333333334, 54.66666666666667, 6.633333333333334, 250.0, 123.1666666666667, 504.0, -5.325, 16.97757794277556, 18.0, 22.1659705359722, 22.7, 1.0, 0.0], 
actual action is [-5.233333333333333, 18], 
sim time next is 735900.0000, 
raw observation next is [-0.1416666666666666, 54.08333333333333, 6.766666666666666, 250.0, 127.0833333333333, 476.5, -5.233333333333333, 18.27760755880023, 18.0, 22.07665773653276, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.32970085470085475, 0.5408333333333333, 0.6151515151515151, 0.6944444444444444, 0.33619929453262776, 0.4765, 0.41277777777777774, 0.1827760755880023, 0.0, 0.582379676647537, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:06,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  5.90259792e-29   4.48973387e-17   3.69438211e-16   8.18268000e-19
   5.15222018e-17   6.14082410e-06   7.69026438e-03   8.78958672e-05
   9.92215693e-01], sum to 1.0000
[2017-11-02 10:54:06,280] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 50.0, 7.7, 250.0, 110.0, 611.0, 5.408333333333333, 14.46190517834578, 23.0, 21.93260335395149, 22.7, 1.0, 89.49883674821017], 
actual action is [5.5, 25], 
sim time next is 738300.0000, 
raw observation next is [0.5, 49.58333333333333, 7.525, 251.6666666666667, 106.5, 638.0, 5.5, 13.03966414076225, 25.0, 22.10724001181314, 22.7, 1.0, 70.26607952054682], 
processed observation next is [0.0, 0.5652173913043478, 0.34615384615384615, 0.4958333333333333, 0.6840909090909091, 0.6990740740740742, 0.28174603174603174, 0.638, 0.5916666666666667, 0.1303966414076225, 1.0, 0.5867485731161628, 0.6714285714285714, 1.0, 0.8266597590652568], 
reward next is -0.7570. 
=============================================
[2017-11-02 10:54:07,752] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28500, global step 453553: loss 263.2795
[2017-11-02 10:54:08,817] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28500, global step 453754: loss 46.4178
[2017-11-02 10:54:10,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28500, global step 454061: loss -61.6924
[2017-11-02 10:54:11,570] A3C_AGENT_WORKER-Thread-7 INFO:Local step 28500, global step 454274: loss -17.4010
[2017-11-02 10:54:17,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00125384
  0.35171038  0.00073342  0.6463024 ], sum to 1.0000
[2017-11-02 10:54:17,506] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.333333333333333, 67.33333333333334, 4.933333333333334, 260.0, 132.6666666666667, 64.83333333333334, 3.575, 10.92716608064029, 25.0, 22.99128726911747, 22.7, 1.0, 61.18570538172174], 
actual action is [3.666666666666667, 25], 
sim time next is 728700.0000, 
raw observation next is [-1.241666666666666, 67.16666666666666, 4.891666666666666, 260.0, 135.8333333333333, 66.41666666666666, 3.666666666666667, 10.73342113569212, 25.0, 23.06168200353858, 22.7, 1.0, 61.09310333495091], 
processed observation next is [0.0, 0.43478260869565216, 0.30149572649572653, 0.6716666666666665, 0.4446969696969696, 0.7222222222222222, 0.3593474426807759, 0.06641666666666665, 0.5611111111111111, 0.1073342113569212, 1.0, 0.7230974290769397, 0.6714285714285714, 1.0, 0.7187423921758931], 
reward next is -0.6576. 
=============================================
[2017-11-02 10:54:17,929] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28500, global step 455093: loss 55.4026
[2017-11-02 10:54:20,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28500, global step 455348: loss -97.5885
[2017-11-02 10:54:20,666] A3C_AGENT_WORKER-Thread-8 INFO:Local step 28500, global step 455402: loss 78.9232
[2017-11-02 10:54:20,956] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28500, global step 455440: loss -49.9780
[2017-11-02 10:54:22,275] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28500, global step 455600: loss 5.6491
[2017-11-02 10:54:28,003] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  8.59264135e-01   2.95779924e-03   1.33285031e-01   1.00156094e-03
   3.49152670e-03   1.59410828e-13   1.31535702e-11   1.64852981e-13
   2.56029850e-11], sum to 1.0000
[2017-11-02 10:54:28,100] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 71.0, 3.25, 78.33333333333334, 0.0, 0.0, -2.3, 16.4482516255424, 24.0, 21.15666304457362, 21.5, 0.0, 46.08666069980757], 
actual action is [-2.3000000000000007, 19.0], 
sim time next is 798000.0000, 
raw observation next is [-7.3, 71.0, 3.2, 76.66666666666667, 0.0, 0.0, -2.300000000000001, 16.38414270970074, 19.0, 21.15572164823856, 21.5, 0.0, 46.00202700357101], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.14615384615384616, 0.71, 0.29090909090909095, 0.21296296296296297, 0.0, 0.0, 0.46166666666666667, 0.16384142709700739, 0.14285714285714285, 0.45081737831979446, 0.5, 0.0, 0.5412003176890707], 
reward next is -0.5363. 
=============================================
[2017-11-02 10:54:28,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02338059
  0.5622918   0.00890357  0.40542403], sum to 1.0000
[2017-11-02 10:54:28,279] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-7.25, 70.66666666666666, 2.958333333333333, 70.83333333333333, 0.0, 0.0, -2.3, 16.89762853655667, 20.0, 21.06681395491997, 21.5, 0.0, 45.69158292831853], 
actual action is [-2.25, 21.0], 
sim time next is 799800.0000, 
raw observation next is [-7.199999999999999, 70.33333333333334, 2.916666666666667, 71.66666666666667, 0.0, 0.0, -2.25, 17.02450936306293, 21.0, 21.07068544394284, 21.5, 0.0, 39.97391486832858], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.14871794871794874, 0.7033333333333335, 0.2651515151515152, 0.1990740740740741, 0.0, 0.0, 0.4625, 0.17024509363062929, 0.42857142857142855, 0.4386693491346913, 0.5, 0.0, 0.4702813513921009], 
reward next is -0.4846. 
=============================================
[2017-11-02 10:54:31,934] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28500, global step 456812: loss 31.8267
[2017-11-02 10:54:33,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.33809051e-03   1.70596298e-02   9.53745127e-01   8.12408049e-03
   1.92076024e-02   5.96429527e-06   4.26142098e-04   1.53634574e-06
   9.18900841e-05], sum to 1.0000
[2017-11-02 10:54:33,471] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 61.0, 5.1, 350.0, 0.0, 0.0, -0.5499999999999998, 8.650947278101217, 25.0, 23.73094246485957, 21.5, 0.0, 39.31763537973384], 
actual action is [-0.5999999999999996, 24.0], 
sim time next is 767100.0000, 
raw observation next is [-5.649999999999999, 61.25, 4.975, 350.8333333333333, 0.0, 0.0, -0.5999999999999996, 8.670191011268855, 24.0, 23.69503028843591, 21.5, 0.0, 41.59519681586229], 
processed observation next is [0.0, 0.9130434782608695, 0.18846153846153849, 0.6125, 0.4522727272727272, 0.974537037037037, 0.0, 0.0, 0.49, 0.08670191011268855, 0.8571428571428571, 0.8135757554908442, 0.5, 0.0, 0.48935525665720336], 
reward next is -0.4404. 
=============================================
[2017-11-02 10:54:35,409] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28500, global step 457247: loss 1.3591
[2017-11-02 10:54:35,856] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28500, global step 457307: loss 71.8432
[2017-11-02 10:54:36,157] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28500, global step 457346: loss 26.3134
[2017-11-02 10:54:37,194] A3C_AGENT_WORKER-Thread-9 INFO:Local step 28500, global step 457485: loss 32.9728
[2017-11-02 10:54:39,994] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28500, global step 457857: loss 1.2635
[2017-11-02 10:54:41,323] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00596023
  0.30088881  0.00133414  0.69181687], sum to 1.0000
[2017-11-02 10:54:41,462] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 71.0, 2.416666666666667, 60.0, 106.3333333333333, 0.0, 0.5, 13.27018611821652, 20.0, 22.60541471627734, 22.7, 1.0, 52.88679992050997], 
actual action is [0.5, 25.0], 
sim time next is 820500.0000, 
raw observation next is [-4.5, 71.0, 2.458333333333333, 60.0, 105.4166666666667, 0.0, 0.5, 13.21611162927438, 25.0, 22.61818845691355, 22.7, 1.0, 50.22892564751666], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.22348484848484845, 0.16666666666666666, 0.2788800705467373, 0.0, 0.5083333333333333, 0.1321611162927438, 1.0, 0.6597412081305072, 0.6714285714285714, 1.0, 0.5909285370296078], 
reward next is -0.5451. 
=============================================
[2017-11-02 10:54:43,430] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28500, global step 458287: loss 121.7998
[2017-11-02 10:54:55,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.69501970e-11   4.57683127e-05   1.86295286e-02   1.23480684e-04
   2.48147087e-04   3.58317536e-03   2.02535912e-01   1.98038784e-03
   7.72853613e-01], sum to 1.0000
[2017-11-02 10:54:55,926] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.65, 72.33333333333334, 2.958333333333333, 105.8333333333333, 0.0, 0.0, -5.7, 24.53698829652872, 18.0, 20.3135885135706, 21.5, 0.0, 0.0], 
actual action is [4.35, 23.0], 
sim time next is 882000.0000, 
raw observation next is [-0.6, 72.0, 3.0, 110.0, 0.0, 0.0, 4.35, 23.01371163868098, 23.0, 20.30612312656278, 21.5, 0.0, 48.37949434499764], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.317948717948718, 0.72, 0.2727272727272727, 0.3055555555555556, 0.0, 0.0, 0.5725, 0.2301371163868098, 0.7142857142857143, 0.32944616093754014, 0.5, 0.0, 0.5691705217058546], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:57,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.06241349e-02   1.93768777e-02   8.97973001e-01   1.79031901e-02
   5.33577837e-02   3.58003632e-07   1.41143566e-04   1.72007503e-06
   6.21691230e-04], sum to 1.0000
[2017-11-02 10:54:57,153] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 79.0, 2.5, 80.0, 95.0, 0.0, 0.5, 14.83126693409174, 19.0, 22.23131677367121, 22.7, 1.0, 53.45768776261762], 
actual action is [-9.5, 18.0], 
sim time next is 824700.0000, 
raw observation next is [-4.45, 78.99999999999999, 2.5, 80.83333333333333, 94.33333333333333, 0.0, -9.5, 16.16216182131306, 18.0, 22.26615232075567, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.21923076923076926, 0.7899999999999998, 0.22727272727272727, 0.22453703703703703, 0.2495590828924162, 0.0, 0.3416666666666667, 0.1616216182131306, 0.0, 0.6094503315365242, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:02,368] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.10856972e-15   1.33794378e-10   1.67513303e-09   2.04904999e-11
   2.85150764e-10   2.75823497e-03   9.64594424e-01   1.89489557e-03
   3.07523981e-02], sum to 1.0000
[2017-11-02 10:55:02,435] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [3.25, 95.0, 3.6, 120.0, 104.0, 0.0, 8.158333333333333, 10.63304023310319, 24.0, 23.15791347228304, 22.7, 1.0, 32.30746746212602], 
actual action is [8.25, 25.0], 
sim time next is 909300.0000, 
raw observation next is [3.341666666666667, 94.66666666666666, 3.6, 118.3333333333333, 103.3333333333333, 0.0, 8.25, 10.78356316049828, 25.0, 23.14945417940487, 22.7, 1.0, 27.71936316175174], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.4190170940170941, 0.9466666666666665, 0.32727272727272727, 0.3287037037037036, 0.27336860670193996, 0.0, 0.6375, 0.1078356316049828, 1.0, 0.7356363113435529, 0.6714285714285714, 1.0, 0.32611015484413813], 
reward next is -0.3043. 
=============================================
[2017-11-02 10:55:03,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99872088e-01   3.07368691e-06   1.09161025e-04   2.60383194e-06
   1.30072212e-05   4.05934187e-17   2.51418628e-15   1.39169896e-17
   3.75300473e-16], sum to 1.0000
[2017-11-02 10:55:03,434] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 83.0, 3.975, 80.0, 44.0, 0.0, 1.100000000000001, 15.74407168085608, 20.0, 22.33465087620076, 22.7, 1.0, 33.03975633781224], 
actual action is [-8.9, 18], 
sim time next is 834600.0000, 
raw observation next is [-3.9, 82.66666666666667, 4.016666666666667, 80.0, 42.33333333333334, 0.0, -8.9, 17.56566034626146, 18.0, 22.28585291394512, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.23333333333333334, 0.8266666666666667, 0.36515151515151517, 0.2222222222222222, 0.11199294532627868, 0.0, 0.3516666666666667, 0.1756566034626146, 0.0, 0.6122647019921601, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:05,240] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-45.40746689]
 [-44.9893837 ]
 [-45.15505219]
 [-44.69604492]
 [-44.97864532]], R is [[-44.82010269]
 [-44.73168564]
 [-44.69838333]
 [-44.85802841]
 [-44.47412872]].
[2017-11-02 10:55:07,317] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29000, global step 461404: loss 7.4175
[2017-11-02 10:55:09,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   3.07650257e-37   8.91109522e-36   1.99594003e-37
   2.79716303e-36   1.04762517e-01   7.27862120e-01   3.05640213e-02
   1.36811331e-01], sum to 1.0000
[2017-11-02 10:55:09,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.608333333333333, 84.25, 3.6, 65.83333333333333, 0.0, 0.0, 1.35, 11.85269892970195, 25.0, 23.19195365428152, 22.7, 1.0, 60.93331626705335], 
actual action is [1.391666666666667, 25], 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 3.6, 66.66666666666667, 0.0, 0.0, 1.391666666666667, 11.76790303089591, 25.0, 23.22276900574307, 22.7, 1.0, 60.91464629558472], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.24188034188034188, 0.84, 0.32727272727272727, 0.1851851851851852, 0.0, 0.0, 0.5231944444444444, 0.1176790303089591, 1.0, 0.7461098579632959, 0.6714285714285714, 1.0, 0.7166428975951143], 
reward next is -0.6567. 
=============================================
[2017-11-02 10:55:09,934] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.06941216
  0.8551634   0.04394636  0.03147805], sum to 1.0000
[2017-11-02 10:55:10,038] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [3.433333333333334, 94.33333333333334, 3.6, 116.6666666666667, 102.6666666666667, 0.0, 8.341666666666667, 8.51363854768943, 25.0, 23.91939312522937, 22.7, 1.0, 62.275207198072], 
actual action is [8.433333333333334, 25], 
sim time next is 909900.0000, 
raw observation next is [3.524999999999999, 94.0, 3.6, 115.0, 102.0, 0.0, 8.433333333333334, 8.309281574636506, 25.0, 23.96266567561823, 22.7, 1.0, 62.35909997616904], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.42371794871794866, 0.94, 0.32727272727272727, 0.3194444444444444, 0.2698412698412698, 0.0, 0.6405555555555557, 0.08309281574636505, 1.0, 0.8518093822311756, 0.6714285714285714, 1.0, 0.733636470307871], 
reward next is -0.6686. 
=============================================
[2017-11-02 10:55:10,764] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.18754301e-36   1.17610613e-35   6.23275405e-37
   4.21303302e-36   5.57596833e-02   8.55723321e-01   3.84518988e-02
   5.00650965e-02], sum to 1.0000
[2017-11-02 10:55:10,803] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.0, 72.0, 2.916666666666667, 115.0, 9.666666666666664, 0.0, 5.0, 15.45171141768329, 22.5, 21.84110369120812, 22.7, 1.0, 29.34930081241493], 
actual action is [5.0, 23.5], 
sim time next is 892500.0000, 
raw observation next is [0.0, 72.0, 2.958333333333333, 117.5, 12.08333333333333, 0.0, 5.0, 15.92319905386214, 23.5, 21.78107771452243, 22.7, 1.0, 27.16864687729231], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.3333333333333333, 0.72, 0.2689393939393939, 0.3263888888888889, 0.031966490299823624, 0.0, 0.5833333333333334, 0.1592319905386214, 0.7857142857142857, 0.5401539592174898, 0.6714285714285714, 1.0, 0.31963113973285073], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:10,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29000, global step 461813: loss 27.6451
[2017-11-02 10:55:13,242] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29000, global step 462125: loss 1.3057
[2017-11-02 10:55:14,310] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29000, global step 462284: loss 23.4551
[2017-11-02 10:55:21,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29000, global step 463348: loss 5.4169
[2017-11-02 10:55:21,591] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29000, global step 463413: loss 19.1555
[2017-11-02 10:55:23,843] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29000, global step 463685: loss 10.4881
[2017-11-02 10:55:25,402] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29000, global step 463877: loss 21.7880
[2017-11-02 10:55:26,032] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29000, global step 463939: loss 0.0678
[2017-11-02 10:55:32,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.97166574e-01   4.30048131e-05   2.15699896e-03   5.77051018e-04
   5.63135327e-05   2.55002391e-11   3.20694964e-11   4.07531344e-12
   4.53430072e-13], sum to 1.0000
[2017-11-02 10:55:32,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.324999999999999, 83.75, 5.1, 152.5, 0.0, 0.0, 11.23333333333333, 13.82408343787382, 19.5, 21.69439149228581, 21.5, 0.0, 15.82423531957514], 
actual action is [1.3249999999999993, 18], 
sim time next is 957000.0000, 
raw observation next is [6.416666666666666, 83.16666666666667, 5.1, 151.6666666666667, 0.0, 0.0, 1.324999999999999, 14.39670307077042, 18.0, 21.72198914383656, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.4978632478632478, 0.8316666666666667, 0.4636363636363636, 0.42129629629629645, 0.0, 0.0, 0.5220833333333333, 0.1439670307077042, 0.0, 0.5317127348337942, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:34,030] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29000, global step 465147: loss 11.2152
[2017-11-02 10:55:35,209] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29000, global step 465369: loss 111.2722
[2017-11-02 10:55:35,431] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99946833e-01   1.21405606e-06   4.18030104e-05   9.01408839e-06
   1.02386764e-06   2.86344329e-23   5.94139678e-23   4.19679760e-24
   1.36933710e-24], sum to 1.0000
[2017-11-02 10:55:35,516] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.708333333333334, 83.0, 5.1, 178.3333333333333, 0.0, 0.0, 3.616666666666667, 20.60523279664202, 18.0, 20.92067428167926, 21.5, 0.0, 0.0], 
actual action is [3.708333333333334, 18], 
sim time next is 968400.0000, 
raw observation next is [8.8, 83.0, 5.1, 180.0, 0.0, 0.0, 3.708333333333334, 20.85801750153198, 18.0, 20.89276481197653, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.558974358974359, 0.83, 0.4636363636363636, 0.5, 0.0, 0.0, 0.5618055555555556, 0.20858017501531978, 0.0, 0.4132521159966472, 0.5, 0.0, 0.0], 
reward next is -0.0867. 
=============================================
[2017-11-02 10:55:36,611] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29000, global step 465665: loss 29.3918
[2017-11-02 10:55:37,067] A3C_AGENT_WORKER-Thread-9 INFO:Local step 29000, global step 465774: loss -188.7698
[2017-11-02 10:55:38,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99999523e-01   1.08389941e-09   4.40463850e-07   1.87549229e-08
   2.33687536e-09   4.02116159e-37   1.32805449e-35   5.57295682e-37
   8.56828623e-36], sum to 1.0000
[2017-11-02 10:55:38,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.33333333333334, 4.183333333333333, 120.0, 0.0, 0.0, 0.0, 22.73569619742262, 18.0, 20.96579806829638, 21.5, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 943200.0000, 
raw observation next is [5.0, 96.0, 4.1, 120.0, 0.0, 0.0, 0.0, 23.0278402629798, 18.0, 20.92608977211334, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.46153846153846156, 0.96, 0.3727272727272727, 0.3333333333333333, 0.0, 0.0, 0.5, 0.230278402629798, 0.0, 0.41801282458761996, 0.5, 0.0, 0.0], 
reward next is -0.0820. 
=============================================
[2017-11-02 10:55:39,256] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29000, global step 466265: loss 116.3443
[2017-11-02 10:55:40,227] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29000, global step 466430: loss -130.8849
[2017-11-02 10:55:43,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.49506249e-07   2.41689634e-07   1.67740257e-06   2.00673048e-06
   3.51838821e-07   1.71374977e-01   6.79064155e-01   1.19529538e-01
   3.00269052e-02], sum to 1.0000
[2017-11-02 10:55:43,810] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [11.7, 86.0, 6.433333333333334, 193.3333333333333, 112.0, 0.0, 6.65, 12.12618615587462, 18.0, 22.7498260794826, 22.7, 1.0, 0.0], 
actual action is [16.7, 19.0], 
sim time next is 990900.0000, 
raw observation next is [11.75, 86.0, 6.35, 195.0, 114.0, 0.0, 16.7, 11.87926601144798, 19.0, 22.73857695829786, 22.7, 1.0, 24.82544984532384], 
processed observation next is [0.5, 0.4782608695652174, 0.6346153846153846, 0.86, 0.5772727272727273, 0.5416666666666666, 0.30158730158730157, 0.0, 0.7783333333333334, 0.1187926601144798, 0.14285714285714285, 0.6769395654711227, 0.6714285714285714, 1.0, 0.29206411582733927], 
reward next is -0.2747. 
=============================================
[2017-11-02 10:55:43,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99757826e-01   8.53431629e-06   1.29107837e-04   9.63850034e-05
   8.18411081e-06   5.13046626e-19   1.88198044e-18   2.44941027e-19
   2.27829865e-19], sum to 1.0000
[2017-11-02 10:55:43,982] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29000, global step 467195: loss 5.7364
[2017-11-02 10:55:43,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.74828933e-13   6.26327046e-11   1.24191004e-08   7.42121742e-09
   2.23452576e-10   2.56565392e-01   6.17010474e-01   8.33352655e-02
   4.30888757e-02], sum to 1.0000
[2017-11-02 10:55:43,998] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.1, 180.8333333333333, 0.0, 0.0, 9.4, 11.08477991259621, 18.0, 22.6191233357144, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1033800.0000, 
raw observation next is [14.4, 75.0, 4.1, 181.6666666666667, 0.0, 0.0, 9.4, 11.12000425407401, 18.0, 22.61192722119225, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5046296296296298, 0.0, 0.0, 0.6566666666666666, 0.11120004254074009, 0.0, 0.6588467458846071, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:44,092] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [5.0, 97.0, 4.35, 120.0, 0.0, 0.0, 0.0, 22.87980321091535, 18.0, 20.93565817832779, 21.5, 0.0, 0.0], 
actual action is [10.0, 19.0], 
sim time next is 942600.0000, 
raw observation next is [5.0, 96.66666666666666, 4.266666666666667, 120.0, 0.0, 0.0, 10.0, 21.19575147820858, 19.0, 20.85854108698798, 21.5, 0.0, 44.68898808800684], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.46153846153846156, 0.9666666666666666, 0.3878787878787879, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.21195751478208583, 0.14285714285714285, 0.4083630124268543, 0.5, 0.0, 0.5257528010353746], 
reward next is -0.5648. 
=============================================
[2017-11-02 10:55:47,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-13.63201427]
 [-14.08394527]
 [-13.43881035]
 [-15.98387432]
 [-15.59074783]], R is [[-16.90137482]
 [-17.73236084]
 [-18.55503654]
 [-18.46552849]
 [-18.37391472]].
[2017-11-02 10:55:49,369] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29500, global step 468640: loss 2.2609
[2017-11-02 10:55:49,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999285e-01   2.18066045e-08   3.75153860e-07   3.55307776e-07
   2.14142144e-08   1.22933372e-25   2.98478219e-25   2.35670146e-26
   2.92054734e-26], sum to 1.0000
[2017-11-02 10:55:49,574] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.791666666666667, 83.0, 5.1, 161.6666666666667, 0.0, 0.0, 2.7, 24.84309257456859, 18.0, 20.69837191821015, 21.5, 0.0, 0.0], 
actual action is [2.791666666666667, 18], 
sim time next is 965400.0000, 
raw observation next is [7.883333333333334, 83.0, 5.1, 163.3333333333333, 0.0, 0.0, 2.791666666666667, 25.58929569960825, 18.0, 20.688302879629, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.17391304347826086, 0.5354700854700855, 0.83, 0.4636363636363636, 0.45370370370370355, 0.0, 0.0, 0.5465277777777777, 0.2558929569960825, 0.0, 0.38404326851842846, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:50,419] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-23.26151276]
 [-20.69069862]
 [-20.80579758]
 [-22.27168274]
 [-21.04619789]], R is [[-20.47130585]
 [-20.28153038]
 [-20.09362984]
 [-19.90758514]
 [-19.72337532]].
[2017-11-02 10:55:50,968] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29500, global step 469067: loss 10.7695
[2017-11-02 10:55:52,045] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29500, global step 469325: loss 2.4135
[2017-11-02 10:55:52,489] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29500, global step 469435: loss 6.2237
[2017-11-02 10:55:54,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99971390e-01   6.61963156e-07   1.15175208e-05   1.48679810e-05
   1.50235621e-06   1.34348611e-21   8.17553006e-21   6.28508228e-22
   2.15508305e-20], sum to 1.0000
[2017-11-02 10:55:54,088] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.13333333333333, 79.0, 6.100000000000001, 193.3333333333333, 0.0, 0.0, 10.225, 15.91943310656556, 18.0, 21.75670674581773, 22.7, 1.0, 0.0], 
actual action is [10.13333333333333, 18], 
sim time next is 1013100.0000, 
raw observation next is [15.04166666666667, 79.25, 6.1, 194.1666666666667, 0.0, 0.0, 10.13333333333333, 15.98207420583891, 18.0, 21.74331334121989, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.7190170940170941, 0.7925, 0.5545454545454546, 0.539351851851852, 0.0, 0.0, 0.6688888888888888, 0.1598207420583891, 0.0, 0.5347590487456984, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:55,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.62915301e-01   1.14814853e-02   1.07107423e-02   9.59885027e-03
   5.29355183e-03   3.24663052e-09   6.27382013e-09   2.29769626e-09
   3.16852033e-09], sum to 1.0000
[2017-11-02 10:55:55,314] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [18.95, 52.75, 3.525, 172.5, 147.75, 0.0, 13.9, 9.4950927638586, 18.0, 23.28388888572746, 21.5, 0.0, 0.0], 
actual action is [13.95, 18], 
sim time next is 1088400.0000, 
raw observation next is [19.0, 52.33333333333334, 3.7, 173.3333333333333, 145.1666666666667, 0.0, 13.95, 9.47259074401071, 18.0, 23.29160698668127, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.8205128205128205, 0.5233333333333334, 0.33636363636363636, 0.48148148148148134, 0.3840388007054675, 0.0, 0.7325, 0.09472590744010709, 0.0, 0.7559438552401814, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:57,555] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29500, global step 470751: loss 56.1543
[2017-11-02 10:55:59,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29500, global step 471163: loss 41.2171
[2017-11-02 10:55:59,416] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29500, global step 471229: loss 15.8228
[2017-11-02 10:56:00,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29500, global step 471413: loss 27.3806
[2017-11-02 10:56:00,115] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29500, global step 471427: loss 39.3550
[2017-11-02 10:56:03,091] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.97942281e-01   1.76410511e-01   2.60994494e-01   1.38339490e-01
   1.26268402e-01   1.37555662e-05   1.92411117e-05   7.95934920e-06
   3.84460509e-06], sum to 1.0000
[2017-11-02 10:56:03,152] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [19.4, 49.0, 3.35, 171.6666666666667, 73.0, 0.0, 14.4, 10.61319242186473, 18.0, 22.97146217451743, 21.5, 0.0, 0.0], 
actual action is [14.399999999999999, 18], 
sim time next is 1094100.0000, 
raw observation next is [19.4, 49.0, 3.175, 170.8333333333333, 68.25, 0.0, 14.4, 10.59569458669045, 18.0, 22.97436289252872, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.8307692307692307, 0.49, 0.28863636363636364, 0.4745370370370369, 0.18055555555555555, 0.0, 0.74, 0.1059569458669045, 0.0, 0.7106232703612457, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:56:05,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.40034246e-01   1.96898039e-02   7.76504353e-02   3.04970946e-02
   3.21283974e-02   3.74719202e-15   8.20976096e-15   2.36819761e-15
   7.10170380e-15], sum to 1.0000
[2017-11-02 10:56:05,325] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.6, 78.0, 5.683333333333334, 108.3333333333333, 0.0, 0.0, 6.6, 19.64120016427876, 18.0, 20.8886229825848, 21.5, 0.0, 0.0], 
actual action is [6.6, 18], 
sim time next is 1142100.0000, 
raw observation next is [11.6, 78.5, 5.725, 107.5, 0.0, 0.0, 6.6, 19.674298483464, 18.0, 20.88570412418712, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.6307692307692309, 0.785, 0.5204545454545454, 0.2986111111111111, 0.0, 0.0, 0.61, 0.19674298483464, 0.0, 0.4122434463124459, 0.5, 0.0, 0.0], 
reward next is -0.0878. 
=============================================
[2017-11-02 10:56:05,393] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29500, global step 473064: loss -14.7589
[2017-11-02 10:56:05,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.24028777e-03   1.61530264e-02   5.82650304e-01   2.98561990e-01
   9.93941724e-02   6.01475481e-10   8.24576389e-08   1.03592823e-08
   1.79544301e-07], sum to 1.0000
[2017-11-02 10:56:05,886] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.71666666666667, 60.33333333333333, 4.516666666666667, 158.3333333333333, 0.0, 0.0, 8.75833333333333, 12.89148617774649, 18.0, 22.18912745613947, 22.7, 1.0, 0.0], 
actual action is [8.71666666666667, 18], 
sim time next is 1109700.0000, 
raw observation next is [13.675, 60.5, 4.475, 157.5, 0.0, 0.0, 8.71666666666667, 12.97429674217101, 18.0, 22.16780145562853, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.683974358974359, 0.605, 0.4068181818181818, 0.4375, 0.0, 0.0, 0.6452777777777778, 0.1297429674217101, 0.0, 0.595400207946933, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 10:56:06,540] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-18.83419418]
 [-15.74446011]
 [-17.36258888]
 [-15.58142185]
 [-20.43033791]], R is [[-17.55289841]
 [-17.46186829]
 [-17.36932945]
 [-17.27531433]
 [-17.17984962]].
[2017-11-02 10:56:07,169] A3C_AGENT_WORKER-Thread-9 INFO:Local step 29500, global step 473611: loss 46.5989
[2017-11-02 10:56:07,883] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29500, global step 473835: loss 22.6060
[2017-11-02 10:56:08,094] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29500, global step 473895: loss 7.3134
[2017-11-02 10:56:08,106] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  7.18288481e-01   4.65507507e-02   8.54320154e-02   9.62724313e-02
   5.34562729e-02   2.25720983e-12   2.75006341e-12   9.71999608e-13
   2.08452201e-12], sum to 1.0000
[2017-11-02 10:56:08,125] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.825, 77.5, 5.35, 120.0, 0.0, 0.0, 5.733333333333331, 22.2493542579693, 18.0, 20.34913074312558, 21.5, 0.0, 0.0], 
actual action is [5.824999999999999, 18], 
sim time next is 1133400.0000, 
raw observation next is [10.91666666666667, 77.33333333333334, 5.433333333333334, 120.0, 0.0, 0.0, 5.824999999999999, 22.298519127678, 18.0, 20.34163911921345, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.6132478632478634, 0.7733333333333334, 0.49393939393939396, 0.3333333333333333, 0.0, 0.0, 0.5970833333333334, 0.22298519127678, 0.0, 0.33451987417335005, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:56:10,307] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29500, global step 474609: loss 16.0810
[2017-11-02 10:56:10,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29500, global step 474760: loss 12.9180
[2017-11-02 10:56:13,259] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.20449628  0.18204173  0.25686887  0.18758404  0.15345979  0.00546287
  0.00508336  0.00329736  0.00170574], sum to 1.0000
[2017-11-02 10:56:13,267] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [18.3, 65.0, 9.2, 140.0, 145.0, 0.0, 13.20833333333333, 18.55184417191404, 18.0, 21.06265302229817, 21.5, 0.0, 0.0], 
actual action is [13.3, 18], 
sim time next is 1163100.0000, 
raw observation next is [18.34166666666667, 64.83333333333333, 9.241666666666665, 141.6666666666667, 147.5, 0.0, 13.3, 18.41347748094165, 18.0, 21.08833532178769, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.8036324786324787, 0.6483333333333333, 0.840151515151515, 0.39351851851851866, 0.39021164021164023, 0.0, 0.7216666666666666, 0.1841347748094165, 0.0, 0.4411907602553841, 0.5, 0.0, 0.0], 
reward next is -0.0588. 
=============================================
[2017-11-02 10:56:15,000] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29500, global step 475963: loss -1.2000
[2017-11-02 10:56:16,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30000, global step 476377: loss -1.2903
[2017-11-02 10:56:17,212] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30000, global step 476538: loss -1.2288
[2017-11-02 10:56:18,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.29320017e-02   1.45227388e-01   2.47693092e-01   3.44628483e-01
   2.09506705e-01   2.49369600e-06   5.17294029e-06   2.24775044e-06
   2.40751342e-06], sum to 1.0000
[2017-11-02 10:56:18,837] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [10.5, 77.0, 4.6, 140.0, 0.0, 0.0, 5.59166666666667, 17.67825816657993, 18.0, 21.47792984789867, 22.7, 1.0, 0.0], 
actual action is [5.5, 18], 
sim time next is 1127100.0000, 
raw observation next is [10.45833333333333, 77.16666666666666, 4.6, 138.3333333333333, 0.0, 0.0, 5.5, 17.78302016931792, 18.0, 21.45668452807584, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.6014957264957264, 0.7716666666666666, 0.41818181818181815, 0.38425925925925913, 0.0, 0.0, 0.5916666666666667, 0.17783020169317917, 0.0, 0.4938120754394057, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:56:20,127] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30000, global step 477271: loss -0.1618
[2017-11-02 10:56:21,441] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30000, global step 477619: loss 0.3031
[2017-11-02 10:56:24,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-16.74765015]
 [-15.43551731]
 [-15.46630096]
 [-15.17015266]
 [-13.75564957]], R is [[-17.57540512]
 [-17.41018486]
 [-17.24660683]
 [-17.08465195]
 [-16.92430305]].
[2017-11-02 10:56:24,397] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30000, global step 478478: loss 19.8735
[2017-11-02 10:56:26,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30000, global step 479146: loss 3.5705
[2017-11-02 10:56:27,247] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30000, global step 479211: loss -1.1349
[2017-11-02 10:56:27,472] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30000, global step 479278: loss 0.8608
[2017-11-02 10:56:28,514] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30000, global step 479595: loss -1.4952
[2017-11-02 10:56:33,571] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30000, global step 481101: loss 22.9031
[2017-11-02 10:56:36,101] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30000, global step 481737: loss -9.4140
[2017-11-02 10:56:36,455] A3C_AGENT_WORKER-Thread-9 INFO:Local step 30000, global step 481808: loss 2.7701
[2017-11-02 10:56:37,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30000, global step 481974: loss 1.6655
[2017-11-02 10:56:39,298] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30000, global step 482499: loss -1.7253
[2017-11-02 10:56:41,005] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30000, global step 482896: loss 0.0329
[2017-11-02 10:56:43,670] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30000, global step 483560: loss -10.8501
[2017-11-02 10:56:49,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.88203416e-30   8.30770576e-20   5.05722757e-21   6.82895999e-21
   8.41230598e-20   1.74539426e-04   5.32638398e-04   4.30410117e-04
   9.98862386e-01], sum to 1.0000
[2017-11-02 10:56:49,541] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 92.0, 6.141666666666666, 259.1666666666666, 7.499999999999999, 0.0, 6.1, 15.01116072841872, 25.0, 21.02450330685676, 22.7, 1.0, 61.59010346300193], 
actual action is [6.1, 25], 
sim time next is 1324800.0000, 
raw observation next is [1.1, 92.0, 6.1, 260.0, 9.0, 0.0, 6.1, 13.64639091135211, 25.0, 21.13453339687123, 22.7, 1.0, 72.21686873390469], 
processed observation next is [0.0, 0.34782608695652173, 0.36153846153846153, 0.92, 0.5545454545454546, 0.7222222222222222, 0.023809523809523808, 0.0, 0.6016666666666667, 0.1364639091135211, 1.0, 0.4477904852673186, 0.6714285714285714, 1.0, 0.8496102203988787], 
reward next is -0.7783. 
=============================================
[2017-11-02 10:56:56,071] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30500, global step 485641: loss 9.3201
[2017-11-02 10:56:56,563] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30500, global step 485719: loss 3.4317
[2017-11-02 10:57:00,689] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30500, global step 486375: loss 25.1121
[2017-11-02 10:57:01,091] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-26.57824898]
 [-25.07042313]
 [-28.33364487]
 [-26.30947495]
 [-25.70636368]], R is [[-26.87946129]
 [-26.62017632]
 [-26.36319733]
 [-26.1084938 ]
 [-25.85603714]].
[2017-11-02 10:57:02,447] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.89214872e-04   3.89477878e-04   2.66511088e-05   8.74256293e-05
   6.88621891e-04   7.96529785e-05   1.85702404e-04   8.67082272e-05
   9.98266518e-01], sum to 1.0000
[2017-11-02 10:57:02,515] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 96.0, 5.183333333333334, 280.0, 5.999999999999998, 0.0, -4.5, 10.75851658641164, 18.0, 22.42551198671069, 22.7, 1.0, 0.0], 
actual action is [5.5, 23.0], 
sim time next is 1358100.0000, 
raw observation next is [0.5, 96.0, 5.225, 280.0, 0.0, 0.0, 5.5, 9.963339324520755, 23.0, 22.41325879877046, 22.7, 1.0, 55.76166705121513], 
processed observation next is [0.0, 0.7391304347826086, 0.34615384615384615, 0.96, 0.475, 0.7777777777777778, 0.0, 0.0, 0.5916666666666667, 0.09963339324520755, 0.7142857142857143, 0.6304655426814944, 0.6714285714285714, 1.0, 0.6560196123672368], 
reward next is -0.6004. 
=============================================
[2017-11-02 10:57:02,590] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30500, global step 486701: loss 50.4163
[2017-11-02 10:57:04,655] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30500, global step 487022: loss 5.4575
[2017-11-02 10:57:05,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30500, global step 487222: loss 2.6050
[2017-11-02 10:57:05,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.45478439e-01   2.64311340e-02   2.77750171e-03   6.00473350e-03
   1.93026438e-02   5.80624544e-08   1.18871306e-07   3.91422148e-08
   5.32076319e-06], sum to 1.0000
[2017-11-02 10:57:05,969] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 5.766666666666666, 274.1666666666666, 114.1666666666667, 0.0, 6.1, 9.286165261301615, 20.0, 22.4029345505784, 22.7, 1.0, 51.33628244997269], 
actual action is [-3.9, 18], 
sim time next is 1341000.0000, 
raw observation next is [1.1, 92.0, 5.6, 275.0, 113.0, 0.0, -3.9, 9.710856554133908, 18.0, 22.47329779034098, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.36153846153846153, 0.92, 0.509090909090909, 0.7638888888888888, 0.29894179894179895, 0.0, 0.435, 0.09710856554133908, 0.0, 0.6390425414772827, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0097. 
=============================================
[2017-11-02 10:57:07,280] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30500, global step 487468: loss 4.4156
[2017-11-02 10:57:07,366] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30500, global step 487487: loss -28.0824
[2017-11-02 10:57:07,453] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.61017549e-01   1.05152382e-02   2.22989102e-03   4.45773406e-03
   2.17796247e-02   8.80432359e-12   1.34118853e-11   5.40782306e-12
   9.07484576e-09], sum to 1.0000
[2017-11-02 10:57:07,468] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 5.85, 280.0, 0.0, 0.0, 5.5, 15.39315546264628, 23.0, 21.08725000622811, 21.5, 0.0, 88.48180146881194], 
actual action is [-4.5, 18.0], 
sim time next is 1374600.0000, 
raw observation next is [0.5, 96.0, 5.933333333333333, 280.0, 0.0, 0.0, -4.5, 16.0878491716677, 18.0, 21.2057394738396, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.34615384615384615, 0.96, 0.5393939393939393, 0.7777777777777778, 0.0, 0.0, 0.425, 0.16087849171667698, 0.0, 0.4579627819770857, 0.5, 0.0, 0.0], 
reward next is -0.0420. 
=============================================
[2017-11-02 10:57:08,783] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30500, global step 487780: loss -0.0288
[2017-11-02 10:57:10,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99321222e-01   3.60753824e-04   2.79989090e-05   5.96274731e-05
   2.30368212e-04   1.22848487e-12   4.61622060e-13   2.21076765e-13
   2.81545516e-11], sum to 1.0000
[2017-11-02 10:57:10,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 4.975, 272.5, 97.25, 0.0, -3.9, 12.63074382314563, 18.0, 22.33422142489987, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1345800.0000, 
raw observation next is [1.1, 92.0, 5.016666666666667, 271.6666666666666, 94.33333333333333, 0.0, -3.9, 12.95345489020957, 18.0, 22.2806039005661, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.36153846153846153, 0.92, 0.45606060606060606, 0.7546296296296293, 0.2495590828924162, 0.0, 0.435, 0.1295345489020957, 0.0, 0.6115148429380142, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 10:57:15,605] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30500, global step 488943: loss 2.1207
[2017-11-02 10:57:16,138] A3C_AGENT_WORKER-Thread-9 INFO:Local step 30500, global step 489042: loss 0.5291
[2017-11-02 10:57:16,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30500, global step 489058: loss 22.6040
[2017-11-02 10:57:17,938] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30500, global step 489350: loss 9.9361
[2017-11-02 10:57:18,156] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30500, global step 489382: loss 0.4571
[2017-11-02 10:57:19,328] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30500, global step 489602: loss -23.0091
[2017-11-02 10:57:22,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99984264e-01   7.66235917e-06   3.07854833e-07   7.32556998e-07
   6.98198255e-06   5.77355791e-21   5.79191138e-21   3.33618057e-21
   3.65375636e-17], sum to 1.0000
[2017-11-02 10:57:22,286] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 3.183333333333333, 318.3333333333334, 0.0, 0.0, 5.0, 16.00648159028368, 23.0, 21.06618806023646, 21.5, 0.0, 84.37645170497112], 
actual action is [-5.0, 18.0], 
sim time next is 1383300.0000, 
raw observation next is [0.0, 95.0, 3.275, 317.5, 0.0, 0.0, -5.0, 16.85907643833718, 18.0, 21.26128913227848, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.3333333333333333, 0.95, 0.29772727272727273, 0.8819444444444444, 0.0, 0.0, 0.4166666666666667, 0.1685907643833718, 0.0, 0.46589844746835446, 0.5, 0.0, 0.0], 
reward next is -0.0341. 
=============================================
[2017-11-02 10:57:24,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.97710347e-01   7.65866309e-04   1.85304656e-04   2.43950315e-04
   1.09454466e-03   1.18265762e-13   8.27848329e-14   8.21857231e-14
   5.41568623e-10], sum to 1.0000
[2017-11-02 10:57:24,053] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 2.5, 50.0, 0.0, 0.0, -3.858333333333333, 19.96814855593551, 18.0, 21.43143470627172, 21.5, 0.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1461900.0000, 
raw observation next is [1.141666666666667, 92.0, 2.291666666666667, 45.83333333333333, 0.0, 0.0, -3.9, 21.14357657663186, 18.0, 21.3043953855979, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.36260683760683765, 0.92, 0.20833333333333337, 0.1273148148148148, 0.0, 0.0, 0.435, 0.21143576576631862, 0.0, 0.47205648365684283, 0.5, 0.0, 0.0], 
reward next is -0.0279. 
=============================================
[2017-11-02 10:57:24,781] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99995232e-01   2.40360146e-06   1.06646496e-07   3.71313888e-07
   1.95566531e-06   1.29135731e-16   1.46732417e-16   7.07778216e-17
   2.95412329e-14], sum to 1.0000
[2017-11-02 10:57:24,791] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 92.0, 3.0, 240.0, 91.0, 0.0, -4.35, 14.59487085491982, 18.0, 22.02466922249814, 22.7, 1.0, 0.0], 
actual action is [-4.3, 18], 
sim time next is 1430700.0000, 
raw observation next is [0.75, 92.0, 3.0, 215.0, 90.5, 0.0, -4.3, 14.84643356664425, 18.0, 21.97243018604327, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.3525641025641026, 0.92, 0.2727272727272727, 0.5972222222222222, 0.23941798941798942, 0.0, 0.42833333333333334, 0.14846433566644252, 0.0, 0.5674900265776098, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0148. 
=============================================
[2017-11-02 10:57:27,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30500, global step 490962: loss 1.1290
[2017-11-02 10:57:27,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.85014975e-01   3.85892997e-03   4.65917954e-04   1.01353624e-03
   3.23825935e-03   2.05335746e-05   2.33102310e-05   1.17143254e-05
   6.35279343e-03], sum to 1.0000
[2017-11-02 10:57:27,445] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5999999999999999, 100.0, 2.291666666666667, 218.3333333333333, 16.5, 0.0, -5.6, 14.8958443581833, 18.0, 21.7009522986098, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1413000.0000, 
raw observation next is [-0.6, 100.0, 2.25, 190.0, 18.0, 0.0, -5.6, 15.92791550843665, 18.0, 21.69749030818885, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 1.0, 0.20454545454545456, 0.5277777777777778, 0.047619047619047616, 0.0, 0.4066666666666666, 0.1592791550843665, 0.0, 0.5282129011698358, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:31,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99961376e-01   2.27275395e-05   1.62565800e-06   2.59565445e-06
   1.17170002e-05   1.26566794e-13   1.11072765e-13   3.63861502e-14
   3.91772075e-12], sum to 1.0000
[2017-11-02 10:57:31,985] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 1.541666666666667, 10.83333333333333, 82.5, 0.0, 5.0, 10.14219552772796, 25.0, 22.60354382294326, 22.7, 1.0, 69.46772599138359], 
actual action is [5.0, 20.0], 
sim time next is 1422600.0000, 
raw observation next is [0.0, 95.0, 1.583333333333333, 11.66666666666667, 84.0, 0.0, 5.0, 9.188074660783691, 20.0, 22.7912788441696, 22.7, 1.0, 49.0083060986646], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.3333333333333333, 0.95, 0.14393939393939392, 0.03240740740740741, 0.2222222222222222, 0.0, 0.5833333333333334, 0.0918807466078369, 0.2857142857142857, 0.6844684063099429, 0.6714285714285714, 1.0, 0.5765683070431129], 
reward next is -0.5281. 
=============================================
[2017-11-02 10:57:33,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.36343290e-35   6.27868594e-24   2.26872896e-25   1.56747907e-25
   3.59938929e-24   3.22682783e-02   6.24843175e-03   5.95120620e-03
   9.55532014e-01], sum to 1.0000
[2017-11-02 10:57:33,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.65, 92.0, 3.0, 265.0, 91.5, 0.0, -4.4, 13.8596288119105, 18.0, 22.2426216439714, 22.7, 1.0, 0.0], 
actual action is [5.65, 23.0], 
sim time next is 1430400.0000, 
raw observation next is [0.7000000000000001, 92.0, 3.0, 240.0, 91.0, 0.0, 5.65, 11.12635609115217, 23.0, 22.16944493751163, 22.7, 1.0, 92.73289020117288], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.35128205128205126, 0.92, 0.2727272727272727, 0.6666666666666666, 0.24074074074074073, 0.0, 0.5941666666666666, 0.1112635609115217, 0.7142857142857143, 0.5956349910730901, 0.6714285714285714, 1.0, 1.090975178837328], 
reward next is -0.9930. 
=============================================
[2017-11-02 10:57:34,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99994159e-01   3.93514620e-06   1.63242817e-07   2.48983952e-07
   1.56811393e-06   1.32335200e-16   1.38259282e-16   1.00626164e-16
   8.74249471e-15], sum to 1.0000
[2017-11-02 10:57:34,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 3.0, 45.0, 78.0, 0.0, -3.9, 14.01920053229263, 18.0, 22.31826473366699, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1433700.0000, 
raw observation next is [1.1, 92.0, 3.0, 47.5, 76.5, 0.0, -3.9, 14.17948088111989, 18.0, 22.33319586580512, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.36153846153846153, 0.92, 0.2727272727272727, 0.13194444444444445, 0.20238095238095238, 0.0, 0.435, 0.1417948088111989, 0.0, 0.6190279808293029, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:57:37,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99965787e-01   2.09466307e-05   2.41942644e-06   2.87884518e-06
   7.94753305e-06   2.18635399e-13   2.13401318e-13   1.22669548e-13
   3.61051141e-12], sum to 1.0000
[2017-11-02 10:57:37,064] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 3.6, 90.0, 9.0, 0.0, 6.1, 11.89823822285314, 25.0, 22.27697563022705, 22.7, 1.0, 23.98149246006061], 
actual action is [6.1, 20.0], 
sim time next is 1443900.0000, 
raw observation next is [1.1, 91.66666666666666, 3.425, 102.5, 7.499999999999999, 0.0, 6.1, 11.33223229135289, 20.0, 22.32764913919205, 22.7, 1.0, 47.94318730914927], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.36153846153846153, 0.9166666666666665, 0.31136363636363634, 0.2847222222222222, 0.01984126984126984, 0.0, 0.6016666666666667, 0.1133223229135289, 0.2857142857142857, 0.6182355913131501, 0.6714285714285714, 1.0, 0.5640374977546974], 
reward next is -0.5190. 
=============================================
[2017-11-02 10:57:40,441] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31000, global step 493420: loss 0.6016
[2017-11-02 10:57:41,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99999046e-01   4.20999385e-07   1.41962744e-07   1.22697401e-07
   2.67897633e-07   7.40084633e-21   2.35809305e-20   2.33069156e-20
   2.87133354e-18], sum to 1.0000
[2017-11-02 10:57:41,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.108333333333333, 96.33333333333333, 3.466666666666666, 144.1666666666667, 0.0, 0.0, 7.2, 18.00769241265751, 23.0, 20.49596616201097, 21.5, 0.0, 102.1057063759147], 
actual action is [-2.891666666666667, 18.0], 
sim time next is 1491000.0000, 
raw observation next is [2.016666666666667, 96.66666666666666, 3.333333333333333, 148.3333333333333, 0.0, 0.0, -2.891666666666667, 19.07718061040917, 18.0, 20.69539470666098, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.38504273504273506, 0.9666666666666666, 0.303030303030303, 0.4120370370370369, 0.0, 0.0, 0.45180555555555557, 0.1907718061040917, 0.0, 0.3850563866658544, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:41,248] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31000, global step 493598: loss 1.3241
[2017-11-02 10:57:46,070] A3C_AGENT_WORKER-Thread-7 INFO:Local step 31000, global step 494588: loss 1.5198
[2017-11-02 10:57:46,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99992371e-01   4.55982899e-06   6.65054870e-07   7.17035903e-07
   1.67148858e-06   2.80733248e-14   4.85744969e-14   4.58031237e-14
   2.76034349e-13], sum to 1.0000
[2017-11-02 10:57:46,137] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 91.0, 3.075, 127.5, 0.0, 0.0, -3.9, 15.16872766271613, 18.0, 21.97864046895217, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1444800.0000, 
raw observation next is [1.1, 90.66666666666667, 2.9, 140.0, 0.0, 0.0, -3.9, 15.99971635024307, 18.0, 21.92784322389408, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.36153846153846153, 0.9066666666666667, 0.2636363636363636, 0.3888888888888889, 0.0, 0.0, 0.435, 0.1599971635024307, 0.0, 0.561120460556297, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:46,638] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31000, global step 494711: loss 1.0453
[2017-11-02 10:57:48,249] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.95971382e-01   2.24756286e-03   4.75447741e-04   4.89530619e-04
   8.15542531e-04   8.67781154e-08   1.42606496e-07   1.46646940e-07
   1.69667544e-07], sum to 1.0000
[2017-11-02 10:57:48,273] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.533333333333333, 64.66666666666666, 0.0, 0.0, 81.66666666666666, 688.3333333333333, 4.300000000000001, 9.682999594590422, 18.0, 23.02929150833421, 22.7, 1.0, 0.0], 
actual action is [4.533333333333333, 18], 
sim time next is 1518900.0000, 
raw observation next is [9.766666666666666, 63.83333333333334, 0.0, 0.0, 80.83333333333333, 685.1666666666667, 4.533333333333333, 9.560534107974032, 18.0, 23.06775522197395, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.5837606837606837, 0.6383333333333334, 0.0, 0.0, 0.21384479717813049, 0.6851666666666667, 0.5755555555555555, 0.09560534107974032, 0.0, 0.7239650317105644, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0096. 
=============================================
[2017-11-02 10:57:49,245] A3C_AGENT_WORKER-Thread-8 INFO:Local step 31000, global step 495359: loss 0.0466
[2017-11-02 10:57:49,277] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31000, global step 495364: loss 0.1926
[2017-11-02 10:57:49,572] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31000, global step 495430: loss 0.2476
[2017-11-02 10:57:50,747] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31000, global step 495741: loss 0.0447
[2017-11-02 10:57:51,499] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31000, global step 495884: loss 0.1727
[2017-11-02 10:57:53,263] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.92467821e-01   3.13968235e-03   1.86805078e-03   4.25870443e-04
   2.09844788e-03   6.18688503e-11   1.86986218e-10   4.46099380e-10
   1.65224748e-07], sum to 1.0000
[2017-11-02 10:57:53,287] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.85, 80.75, 3.45, 97.5, 0.0, 0.0, 9.9, 13.92691535992169, 23.0, 21.12063643262534, 21.5, 0.0, 101.9824930744197], 
actual action is [-0.15000000000000036, 18.0], 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 3.4, 96.66666666666667, 0.0, 0.0, -0.1500000000000004, 14.78348298306067, 18.0, 21.33770856716995, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.08695652173913043, 0.45641025641025645, 0.8133333333333335, 0.3090909090909091, 0.26851851851851855, 0.0, 0.0, 0.49749999999999994, 0.1478348298306067, 0.0, 0.4768155095957073, 0.5, 0.0, 0.0], 
reward next is -0.0232. 
=============================================
[2017-11-02 10:57:56,413] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31000, global step 496986: loss 0.2888
[2017-11-02 10:57:57,219] A3C_AGENT_WORKER-Thread-9 INFO:Local step 31000, global step 497195: loss 0.2531
[2017-11-02 10:57:57,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-2.78498697]
 [-1.16457641]
 [-0.66412628]
 [-1.25901735]
 [-2.71473885]], R is [[-6.22731876]
 [-6.17446041]
 [-6.12188959]
 [-6.06961918]
 [-6.01741219]].
[2017-11-02 10:57:58,522] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31000, global step 497532: loss 0.0663
[2017-11-02 10:57:58,879] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31000, global step 497634: loss 0.0808
[2017-11-02 10:57:58,966] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31000, global step 497647: loss 0.0039
[2017-11-02 10:58:00,436] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31000, global step 498030: loss 0.0158
[2017-11-02 10:58:02,246] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99997139e-01   1.79741801e-06   4.43592370e-07   2.34421123e-07
   3.81433154e-07   2.35462111e-18   7.71014553e-18   4.57369006e-18
   5.68161709e-17], sum to 1.0000
[2017-11-02 10:58:02,263] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.125, 81.25, 2.625, 92.5, 0.0, 0.0, 10.08333333333333, 12.81915638846572, 23.0, 21.45924218073952, 21.5, 0.0, 63.90784339443122], 
actual action is [0.125, 18.0], 
sim time next is 1578000.0000, 
raw observation next is [5.166666666666667, 81.0, 2.666666666666667, 93.33333333333334, 0.0, 0.0, 0.125, 13.67523944935795, 18.0, 21.48991822913825, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.2608695652173913, 0.4658119658119658, 0.81, 0.24242424242424246, 0.2592592592592593, 0.0, 0.0, 0.5020833333333333, 0.13675239449357948, 0.0, 0.49855974701975014, 0.5, 0.0, 0.0], 
reward next is -0.0014. 
=============================================
[2017-11-02 10:58:04,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31000, global step 499135: loss 0.1261
[2017-11-02 10:58:07,556] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:25

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=00hr 32min 41.87sec

[2017-11-02 10:58:07,576] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:58:07,576] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:58:08,558] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:58:08,561] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run3
[2017-11-02 10:58:49,498] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99563277e-01   2.41290763e-04   8.18648768e-05   3.88239496e-05
   7.47278682e-05   2.53773183e-11   5.06818199e-11   3.80540391e-11
   7.24343474e-10]
[2017-11-02 10:58:54,083] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.39233384e-06   8.23826198e-08   9.25009829e-08
   1.46921181e-07   1.09587920e-11   1.52138458e-11   8.00515470e-12
   1.08486501e-11]
[2017-11-02 10:58:54,390] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99989033e-01   8.95824905e-06   4.82953283e-07   5.37820483e-07
   9.61141609e-07   1.74137043e-08   2.29808741e-08   1.27572575e-08
   1.98767598e-08]
[2017-11-02 10:59:13,187] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.08914350e-10   1.06983566e-09   6.30251754e-11   4.61299055e-11
   1.56613666e-10   1.82280511e-01   2.58425325e-01   1.64797366e-01
   3.94496769e-01]
[2017-11-02 10:59:13,424] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964356e-01   2.82832389e-05   1.66091627e-06   1.44421858e-06
   3.41016357e-06   1.07414039e-07   1.94359288e-07   1.06263109e-07
   3.07257380e-07]
[2017-11-02 10:59:17,474] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.65930748e-07   5.14594376e-07   4.63241783e-08   2.87229884e-08
   9.37460527e-08   1.22890197e-01   1.99306160e-01   1.27046779e-01
   5.50755620e-01]
[2017-11-02 10:59:18,304] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.19495961e-06   2.36344840e-06   2.09294797e-07   1.32133579e-07
   4.24493663e-07   1.20527096e-01   2.00714663e-01   1.25251874e-01
   5.53497970e-01]
[2017-11-02 10:59:23,379] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.10750428e-12   4.27924673e-09   1.11022680e-09   4.72126838e-10
   1.80824600e-09   5.38974069e-02   8.24877694e-02   6.97590709e-02
   7.93855667e-01]
[2017-11-02 10:59:28,149] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.94685920e-09   5.81989346e-09   2.95344138e-10   2.60179350e-10
   7.87108323e-10   2.27438763e-01   2.94022381e-01   1.71391860e-01
   3.07147026e-01]
[2017-11-02 10:59:52,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994040e-01   5.05174830e-06   1.52001206e-07   1.75460286e-07
   4.60811407e-07   2.00089278e-08   3.63056465e-08   2.11646203e-08
   2.95505309e-08]
[2017-11-02 11:00:17,957] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   2.14142014e-37   0.00000000e+00   0.00000000e+00
   4.20488415e-38   2.14338824e-01   2.28776053e-01   2.44528770e-01
   3.12356442e-01]
[2017-11-02 11:00:19,867] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.45809531e-05   1.22425217e-06   3.11321493e-08   2.89917974e-08
   1.10238403e-07   1.81100994e-01   3.37536782e-01   2.17584565e-01
   2.63741761e-01]
[2017-11-02 11:00:22,944] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.82845455e-04   4.40168424e-06   1.04488905e-07   1.02115159e-07
   3.80760923e-07   1.82008564e-01   3.36701423e-01   2.25554496e-01
   2.55547732e-01]
[2017-11-02 11:00:25,810] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.54513144e-09   3.18345683e-09   7.51791129e-11   6.88410093e-11
   2.91339036e-10   1.86331615e-01   3.22808087e-01   2.31872201e-01
   2.58988082e-01]
[2017-11-02 11:00:38,607] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.06354453
  0.04386582  0.0791259   0.81346381]
[2017-11-02 11:00:49,675] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99405384e-01   1.89928556e-04   8.12177223e-06   8.89148396e-06
   2.05625802e-05   8.15029853e-05   1.15521376e-04   6.55975018e-05
   1.04415834e-04]
[2017-11-02 11:00:55,623] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.69931839e-03   1.10242225e-03   1.47620522e-04   7.99762711e-05
   2.46344251e-04   6.89894706e-02   1.19943887e-01   8.91510472e-02
   7.11639941e-01]
[2017-11-02 11:00:55,855] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996543e-01   2.37342783e-06   3.99506547e-07   2.40581414e-07
   4.67583902e-07   2.18470147e-15   4.64765157e-15   3.04726032e-15
   2.90717395e-14]
[2017-11-02 11:00:57,575] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99951363e-01   2.82535402e-05   8.30471163e-06   4.20464312e-06
   7.83495761e-06   4.69360641e-14   9.64830497e-14   7.02747051e-14
   1.14870179e-12]
[2017-11-02 11:01:12,399] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.96722389e-08   3.05973481e-06   8.85988129e-07   3.76297606e-07
   1.22035124e-06   5.14376387e-02   7.82370046e-02   6.91789016e-02
   8.01140845e-01]
[2017-11-02 11:01:16,590] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.58373845e-01   1.00388681e-03   5.36393381e-05   5.58442152e-05
   1.20609126e-04   9.81047656e-03   1.24353338e-02   6.88212924e-03
   1.12642543e-02]
[2017-11-02 11:01:41,884] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.84708362e-10   7.79273979e-09   7.67639952e-10   4.52803517e-10
   1.51498514e-09   1.22276574e-01   1.87105000e-01   1.27077684e-01
   5.63540697e-01]
[2017-11-02 11:02:04,006] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.52666539e-01   2.27342104e-03   2.02889045e-04   1.47948362e-04
   4.03345330e-04   1.15168430e-01   1.84933811e-01   1.05658695e-01
   4.38544959e-01]
[2017-11-02 11:02:06,328] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99372423e-01   4.02962178e-04   7.65180594e-05   4.36772498e-05
   1.04288192e-04   9.74164482e-09   1.91035081e-08   1.28886590e-08
   1.89559358e-07]
[2017-11-02 11:02:13,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.32418906e-03   6.95830167e-05   4.08160986e-06   4.13136149e-06
   9.37631739e-06   2.56243974e-01   3.01422834e-01   1.66050524e-01
   2.73871303e-01]
[2017-11-02 11:02:17,184] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993682e-01   5.00005854e-06   3.83158493e-07   3.64754271e-07
   6.47235481e-07   4.24083157e-10   6.34548858e-10   3.30578814e-10
   8.97236285e-10]
[2017-11-02 11:02:17,234] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.31389242e-01   2.57234625e-03   2.06555793e-04   1.66677783e-04
   3.92596528e-04   1.00479022e-01   1.40376776e-01   8.17786679e-02
   2.42638171e-01]
[2017-11-02 11:02:21,195] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   2.77033109e-06   6.87971408e-07   3.74306182e-07
   6.15753265e-07   1.38517564e-17   3.09838399e-17   2.11756202e-17
   3.43471940e-16]
[2017-11-02 11:02:21,954] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99903560e-01   5.65284427e-05   1.54719492e-05   8.60591899e-06
   1.58287094e-05   1.57514919e-12   3.09285193e-12   2.09311149e-12
   4.31092349e-11]
[2017-11-02 11:02:23,203] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995828e-01   3.36262929e-06   1.95328710e-07   2.25309620e-07
   3.67044152e-07   7.21415774e-11   9.68256031e-11   6.13791656e-11
   7.20425733e-11]
[2017-11-02 11:02:23,705] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.20400864e-06   1.33190738e-07   9.80439907e-08
   1.93921537e-07   9.11357137e-15   1.83046005e-14   1.14156418e-14
   4.95056368e-14]
[2017-11-02 11:02:24,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.42221573e-07   6.89278963e-08   5.42674812e-08
   1.07074101e-07   1.10088154e-13   2.02106506e-13   1.27883896e-13
   5.66925521e-13]
[2017-11-02 11:02:25,233] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.88428792e-07   7.13920585e-08   5.73896450e-08
   1.12281199e-07   3.73823992e-13   6.54421775e-13   4.04076783e-13
   1.68809075e-12]
[2017-11-02 11:02:25,924] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96836185e-01   2.07212847e-03   2.92057433e-04   3.00428481e-04
   4.98872658e-04   7.49958531e-08   9.52357055e-08   6.91801461e-08
   3.77592251e-08]
[2017-11-02 11:02:27,463] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964118e-01   2.21936662e-05   4.58327759e-06   3.30806870e-06
   5.82643088e-06   3.31872320e-14   6.93668349e-14   3.96200373e-14
   1.36162267e-13]
[2017-11-02 11:02:28,169] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   8.31578575e-07   7.79697871e-08   6.20511074e-08
   1.23042369e-07   3.99478844e-13   7.08117159e-13   4.34982101e-13
   1.93623264e-12]
[2017-11-02 11:02:29,647] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99823511e-01   1.14136164e-04   1.87663209e-05   1.78278842e-05
   2.58532764e-05   4.08779304e-12   5.68869084e-12   3.30010737e-12
   3.54482264e-12]
[2017-11-02 11:02:29,726] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99865055e-01   8.08096811e-05   1.81713876e-05   1.38608148e-05
   2.22175568e-05   6.34262675e-14   1.24986718e-13   7.13980741e-14
   1.57817295e-13]
[2017-11-02 11:02:29,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99896646e-01   6.12698714e-05   1.45395525e-05   1.04575956e-05
   1.71020038e-05   2.70542340e-14   5.70061441e-14   3.23091028e-14
   8.43486657e-14]
[2017-11-02 11:02:30,814] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99958515e-01   2.65026792e-05   4.80709241e-06   3.90486048e-06
   6.31263629e-06   3.55041348e-14   6.97996416e-14   4.03002725e-14
   1.09165376e-13]
[2017-11-02 11:02:31,295] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99954700e-01   2.99192943e-05   4.68948929e-06   4.27471741e-06
   6.47820707e-06   1.78426704e-13   3.03166888e-13   1.63711059e-13
   2.94467819e-13]
[2017-11-02 11:02:31,452] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99858618e-01   9.59178724e-05   1.24921598e-05   1.39858603e-05
   1.89430521e-05   4.76681229e-11   6.16664289e-11   3.37337484e-11
   2.64771139e-11]
[2017-11-02 11:02:31,501] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99784291e-01   1.45301077e-04   1.93683609e-05   2.15605305e-05
   2.94275105e-05   1.02786259e-10   1.30080807e-10   7.31493199e-11
   5.29809252e-11]
[2017-11-02 11:02:31,648] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99592841e-01   2.69795855e-04   3.79691446e-05   4.15992617e-05
   5.77821811e-05   3.03285480e-10   3.71309733e-10   2.15183066e-10
   1.40638973e-10]
[2017-11-02 11:02:33,457] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999404e-01   4.52314879e-07   4.71282888e-08   3.25006759e-08
   6.67786964e-08   2.03823012e-14   4.15875864e-14   2.70013368e-14
   1.66492078e-13]
[2017-11-02 11:02:35,508] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.55055177e-01   2.40953900e-02   7.95406476e-03   3.76733812e-03
   7.97618553e-03   3.94382769e-05   7.06396822e-05   5.49035394e-05
   9.86916479e-04]
[2017-11-02 11:02:38,332] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   1.03695484e-05   9.42980648e-07   9.88204988e-07
   1.36014717e-06   1.19803993e-11   1.86806057e-11   1.00714350e-11
   1.38606574e-11]
[2017-11-02 11:02:38,750] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99884963e-01   8.40637949e-05   7.84424628e-06   7.82822372e-06
   1.23988666e-05   6.75434819e-07   8.64421679e-07   5.12262318e-07
   8.79965739e-07]
[2017-11-02 11:02:41,571] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993443e-01   4.30322143e-06   8.52542200e-07   5.18182958e-07
   9.06225637e-07   2.08948408e-14   4.28067514e-14   2.81883908e-14
   2.70398450e-13]
[2017-11-02 11:02:43,662] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99947309e-01   3.03920860e-05   8.75757996e-06   4.82622136e-06
   8.78380979e-06   7.09792129e-14   1.40557216e-13   9.88279689e-14
   1.51140905e-12]
[2017-11-02 11:02:43,715] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.12150621e-04   8.82294495e-04   2.80205364e-04   1.26148225e-04
   3.47414694e-04   3.82583924e-02   6.17668480e-02   5.10084406e-02
   8.47218096e-01]
[2017-11-02 11:02:46,770] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   9.99087843e-06   1.04397543e-06   1.09147572e-06
   1.48378842e-06   3.43084838e-10   4.74744299e-10   2.15037974e-10
   3.45585810e-10]
[2017-11-02 11:02:51,087] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994278e-01   3.74395859e-06   6.67149891e-07   4.29785786e-07
   8.29344515e-07   1.00840370e-13   1.95433635e-13   1.20450945e-13
   1.14061169e-12]
[2017-11-02 11:02:53,751] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99991059e-01   5.26147460e-06   1.45044089e-06   8.04635533e-07
   1.38056123e-06   2.00191711e-16   4.19060127e-16   2.87155445e-16
   4.94903352e-15]
[2017-11-02 11:02:58,009] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99956250e-01   2.62342528e-05   5.51126232e-06   4.15479008e-06
   7.91043567e-06   2.32601828e-12   4.74812811e-12   2.64216665e-12
   1.10680649e-11]
[2017-11-02 11:02:58,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21695434  0.13112445  0.04369258  0.0198531   0.05064408  0.01636913
  0.03005787  0.02371034  0.46759415]
[2017-11-02 11:03:01,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984860e-01   1.10737365e-05   1.14738612e-06   1.23055247e-06
   1.65301140e-06   4.80994029e-11   6.70377087e-11   3.05095289e-11
   3.92432163e-11]
[2017-11-02 11:03:01,794] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94098425e-01   3.64579749e-03   6.26326015e-04   6.30439376e-04
   9.98334261e-04   2.16416652e-07   2.69711165e-07   1.86491661e-07
   1.04554893e-07]
[2017-11-02 11:03:02,842] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99892712e-01   6.12471922e-05   1.51940749e-05   1.10935171e-05
   1.98249782e-05   4.26107148e-13   9.26778077e-13   5.07027200e-13
   1.73034016e-12]
[2017-11-02 11:03:04,042] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   3.02899275e-06   8.51815287e-07   4.50233330e-07
   7.57527744e-07   3.41810253e-17   7.77674316e-17   5.31607903e-17
   1.07410332e-15]
[2017-11-02 11:03:04,471] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   2.99342992e-06   8.25204609e-07   4.41835027e-07
   6.78132267e-07   7.19606767e-18   1.62032324e-17   1.10516682e-17
   1.91679043e-16]
[2017-11-02 11:03:19,754] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.80968189e-01   1.53989403e-03   7.40296164e-05   7.71620762e-05
   1.77983893e-04   5.25135621e-02   6.68876916e-02   3.95402461e-02
   5.82213104e-02]
[2017-11-02 11:03:20,829] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997854e-01   1.63237894e-06   1.02576855e-07   1.12270804e-07
   1.83159017e-07   1.11086253e-11   1.60019741e-11   8.09926518e-12
   1.23254315e-11]
[2017-11-02 11:03:24,515] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99813139e-01   1.33022608e-04   1.12929638e-05   8.08772984e-06
   2.03723012e-05   1.55245175e-06   2.73596925e-06   1.66848815e-06
   8.07515244e-06]
[2017-11-02 11:03:49,171] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.60584881e-27   9.17079015e-19   2.27562608e-19   7.78246223e-20
   4.36994968e-19   5.76740466e-02   7.83346593e-02   7.59477243e-02
   7.88043559e-01]
[2017-11-02 11:04:10,918] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.78073747e-10   3.13737947e-09   1.91591756e-10   1.71710299e-10
   4.65206901e-10   2.56050885e-01   2.93599606e-01   1.79501235e-01
   2.70848334e-01]
[2017-11-02 11:04:11,582] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99938488e-01   4.66043639e-05   3.90347168e-06   3.85528756e-06
   6.35396736e-06   1.72083276e-07   2.38658885e-07   1.18364866e-07
   2.57351871e-07]
[2017-11-02 11:04:14,206] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.88176095e-01   2.23554811e-03   2.13572232e-04   1.48235427e-04
   3.98421398e-04   1.02945358e-01   1.63779870e-01   9.79886279e-02
   4.44114268e-01]
[2017-11-02 11:04:25,130] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28628372e-03   5.08722951e-05   3.37387382e-06   3.41760506e-06
   7.38047083e-06   2.58790135e-01   3.00807089e-01   1.57905832e-01
   2.81145602e-01]
[2017-11-02 11:04:29,312] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99341428e-01   4.12568334e-04   8.59737847e-05   4.80579656e-05
   1.11796100e-04   3.57872199e-09   6.88176627e-09   4.89048801e-09
   6.12598186e-08]
[2017-11-02 11:04:31,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93428648e-01   3.74473818e-03   1.05502771e-03   5.45789895e-04
   1.22269627e-03   1.55293463e-07   2.81019965e-07   2.09295678e-07
   2.42630881e-06]
[2017-11-02 11:04:31,679] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97797204e-04   1.59559445e-03   4.54655004e-04   2.13209612e-04
   6.15212717e-04   5.68142124e-02   9.03935209e-02   7.34154359e-02
   7.76200294e-01]
[2017-11-02 11:04:39,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.55181077e-07   6.51901473e-07   4.87464149e-08   3.74528142e-08
   1.10116908e-07   1.89265102e-01   2.50911593e-01   1.53768167e-01
   4.06053483e-01]
[2017-11-02 11:04:43,855] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.97658970e-04   2.92362267e-04   4.85894998e-05   2.54094866e-05
   7.75581793e-05   6.99753985e-02   1.14001468e-01   8.62105265e-02
   7.28871107e-01]
[2017-11-02 11:04:46,720] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.19795078e-13   4.08918188e-09   1.19661125e-09   4.90010421e-10
   1.79555903e-09   5.55392355e-02   8.03885087e-02   7.20971897e-02
   7.91975081e-01]
[2017-11-02 11:04:49,015] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.08692030e-11   3.64057655e-08   1.03054481e-08   4.36653202e-09
   1.55945017e-08   5.56858256e-02   8.30425695e-02   7.25194812e-02
   7.88752019e-01]
[2017-11-02 11:04:55,672] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47563929e-03   9.58843666e-05   8.34510956e-06   5.60041872e-06
   1.66530535e-05   1.22046851e-01   1.94952950e-01   1.22270532e-01
   5.59127569e-01]
[2017-11-02 11:05:08,254] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997616e-01   1.88684317e-06   1.04794879e-07   1.23659547e-07
   2.30723487e-07   9.51909107e-11   1.36738065e-10   7.24373200e-11
   1.11048573e-10]
[2017-11-02 11:05:08,325] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996185e-01   3.08158246e-06   1.71046025e-07   1.98513774e-07
   3.53716331e-07   2.50289678e-10   3.55711599e-10   1.86084634e-10
   2.88213509e-10]
[2017-11-02 11:05:10,239] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.89745200e-01   5.13617462e-03   8.18884699e-04   4.60573880e-04
   1.23927335e-03   1.49125437e-04   2.73372774e-04   1.91072220e-04
   1.98646635e-03]
[2017-11-02 11:05:14,023] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.64966914e-03   4.43811296e-03   1.16075797e-03   5.61562891e-04
   1.66646834e-03   5.35532907e-02   8.84616673e-02   7.15947375e-02
   7.76913762e-01]
[2017-11-02 11:05:20,292] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.18929844e-04   1.14219138e-05   3.32610824e-07   3.36121019e-07
   1.11887334e-06   1.93657339e-01   3.26439977e-01   2.29966775e-01
   2.49603704e-01]
[2017-11-02 11:05:21,138] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.88707900e-01   9.45112377e-04   3.66929853e-05   3.96455289e-05
   1.00003992e-04   2.03578710e-03   3.38938413e-03   2.46290816e-03
   2.28261901e-03]
[2017-11-02 11:05:24,371] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.55381358  0.04666441  0.00919802  0.00452592  0.01353543  0.01266579
  0.02450127  0.01881906  0.31627652]
[2017-11-02 11:05:24,875] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.93247829e-18   4.14139832e-13   7.97669290e-14   3.24745893e-14
   1.54337711e-13   4.26033586e-02   6.47683665e-02   5.84722906e-02
   8.34155977e-01]
[2017-11-02 11:05:25,209] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97882545e-01   1.38657843e-03   2.37672124e-04   1.27734122e-04
   3.50261136e-04   5.91381934e-07   1.22090307e-06   8.80135246e-07
   1.26315754e-05]
[2017-11-02 11:05:30,201] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98007357e-01   5.50417928e-04   4.49143517e-05   4.39690812e-05
   8.08961995e-05   2.69236421e-04   3.73318937e-04   1.78929185e-04
   4.51023778e-04]
[2017-11-02 11:05:31,070] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.76258925e-02   4.27888444e-04   3.23047352e-05   2.95334248e-05
   6.56388511e-05   2.15725690e-01   2.89185375e-01   1.78788304e-01
   2.98119366e-01]
[2017-11-02 11:05:32,920] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.33699604e-12   2.94141905e-10   3.27989927e-11   1.77153413e-11
   6.27584373e-11   1.06170967e-01   1.61713630e-01   1.19575411e-01
   6.12539947e-01]
[2017-11-02 11:05:37,161] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.94832240e-03   4.55507729e-03   1.18800905e-03   5.79325133e-04
   1.65044458e-03   5.63162118e-02   9.17792097e-02   7.19526336e-02
   7.70030737e-01]
[2017-11-02 11:05:37,321] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.66984552e-18   1.02426596e-12   2.97678413e-13   1.15810180e-13
   4.88860417e-13   4.92962413e-02   6.78711534e-02   6.29028678e-02
   8.19929779e-01]
[2017-11-02 11:05:41,544] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.10148806e-18   1.05876238e-14   7.16943668e-16   5.64644974e-16
   1.96509907e-15   2.45551318e-01   2.53423303e-01   1.42209649e-01
   3.58815730e-01]
[2017-11-02 11:05:44,119] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996543e-01   2.75734465e-06   1.48326507e-07   1.69456243e-07
   3.08790106e-07   2.93558476e-11   5.05940428e-11   2.73392888e-11
   3.35162245e-11]
[2017-11-02 11:05:44,814] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.50966001e-01   1.30034506e-03   4.87777070e-05   4.80478629e-05
   1.31066801e-04   8.70772451e-03   1.44590586e-02   1.18893413e-02
   1.24496603e-02]
[2017-11-02 11:05:48,396] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99394536e-01   3.72710114e-04   8.57242121e-05   4.56808812e-05
   1.01276346e-04   1.12852849e-09   2.20181073e-09   1.59220903e-09
   2.54441197e-08]
[2017-11-02 11:05:50,272] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.80332735e-10   8.27229414e-08   2.35901148e-08   1.03019842e-08
   3.54540468e-08   5.43759242e-02   8.31135139e-02   6.91478774e-02
   7.93362558e-01]
[2017-11-02 11:05:58,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99985933e-01   1.18593880e-05   4.08464842e-07   4.56761427e-07
   1.14577767e-06   1.83314022e-08   3.66113220e-08   2.51334047e-08
   2.60629243e-08]
[2017-11-02 11:05:59,075] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984860e-01   1.29102118e-05   3.78737440e-07   4.20659489e-07
   1.12214173e-06   7.57199032e-08   1.55751678e-07   1.03065020e-07
   1.09114467e-07]
[2017-11-02 11:06:03,834] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994397e-01   3.94741573e-06   5.20132232e-07   3.97960321e-07
   8.50541937e-07   4.64220893e-12   8.52765254e-12   4.55436600e-12
   2.37933614e-11]
[2017-11-02 11:06:20,381] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990106e-01   6.05905643e-06   1.50119274e-06   8.38451456e-07
   1.43884472e-06   2.32056951e-17   5.29726729e-17   3.46598437e-17
   4.05770154e-16]
[2017-11-02 11:06:21,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990106e-01   7.92133324e-06   5.15531326e-07   5.73416798e-07
   9.33478191e-07   3.26356497e-09   4.41552750e-09   2.24595853e-09
   3.48849549e-09]
[2017-11-02 11:06:24,232] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993920e-01   4.77560570e-06   3.13259818e-07   3.57557496e-07
   5.66617416e-07   9.51553947e-10   1.20478716e-09   6.51622090e-10
   9.04742892e-10]
[2017-11-02 11:06:26,738] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993205e-01   4.23030360e-06   1.02054594e-06   5.76647551e-07
   9.62936497e-07   7.96311969e-18   1.87416313e-17   1.15460310e-17
   1.27553130e-16]
[2017-11-02 11:06:28,978] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.96403053e-18   2.02732406e-12   6.23776096e-13   2.23748564e-13
   9.39576216e-13   4.25375886e-02   5.93756475e-02   5.84301427e-02
   8.39656651e-01]
[2017-11-02 11:06:37,865] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.66040908e-03   1.29058360e-04   8.75764090e-06   7.54633356e-06
   1.92021416e-05   2.13729322e-01   2.81903774e-01   1.77231088e-01
   3.24310869e-01]
[2017-11-02 11:06:43,476] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.31220689e-07   2.98530285e-05   7.70371389e-06   3.63553590e-06
   1.17331465e-05   5.65814190e-02   8.81715342e-02   7.46113062e-02
   7.80582011e-01]
[2017-11-02 11:06:43,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.22976017e-06   1.23245438e-04   3.07597729e-05   1.48862619e-05
   4.70105297e-05   5.61624691e-02   8.91441107e-02   7.33995959e-02
   7.81069756e-01]
[2017-11-02 11:06:44,223] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99290586e-01   4.35457652e-04   9.04422777e-05   6.15803583e-05
   1.21881785e-04   5.53190516e-09   8.94525343e-09   5.53545121e-09
   4.74990287e-08]
[2017-11-02 11:06:45,974] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.73324299e-01   8.81375745e-04   3.10158757e-05   3.23016429e-05
   8.93729666e-05   4.75610141e-03   8.48462060e-03   6.25998620e-03
   6.14096830e-03]
[2017-11-02 11:06:46,191] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86206472e-01   7.08115578e-04   2.30932910e-05   2.44748881e-05
   6.77776698e-05   2.43547698e-03   4.31700051e-03   3.19746858e-03
   3.02001275e-03]
[2017-11-02 11:06:50,512] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995947e-01   2.57987040e-06   5.90990908e-07   3.28534668e-07
   5.48448611e-07   1.22009895e-16   2.75432218e-16   1.85340166e-16
   2.85591537e-15]
[2017-11-02 11:06:51,642] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94981468e-01   3.27681960e-03   4.99672198e-04   4.77482216e-04
   7.64366123e-04   7.38590131e-08   1.01407196e-07   7.40338990e-08
   5.15847205e-08]
[2017-11-02 11:06:51,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93558466e-01   4.15084278e-03   6.63244165e-04   6.24535605e-04
   1.00253825e-03   1.08512545e-07   1.48235344e-07   1.08894028e-07
   7.63259749e-08]
[2017-11-02 11:06:52,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99664307e-01   1.83706186e-04   2.24259493e-05   1.49758771e-05
   3.26076624e-05   7.56858844e-06   1.31658453e-05   8.71431621e-06
   5.24307070e-05]
[2017-11-02 11:06:52,896] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997377e-01   1.85855390e-06   2.50432635e-07   1.85041046e-07
   3.40062257e-07   1.04777406e-12   2.05720965e-12   1.18081543e-12
   6.57461325e-12]
[2017-11-02 11:07:00,206] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99753296e-01   1.48665029e-04   3.58933867e-05   1.98046764e-05
   4.23405290e-05   4.50542763e-11   8.83925433e-11   6.26070515e-11
   9.37433797e-10]
[2017-11-02 11:07:00,944] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.90237742e-27   1.40496275e-18   4.36833926e-19   1.49594515e-19
   7.89147572e-19   5.86179085e-02   6.98871985e-02   7.16537833e-02
   7.99841106e-01]
[2017-11-02 11:07:01,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.90179896e-01   5.52873733e-03   1.57870108e-03   8.31409416e-04
   1.87212415e-03   4.91607523e-07   8.68875361e-07   6.40336225e-07
   7.14714997e-06]
[2017-11-02 11:07:02,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.68345866e-17   6.14513171e-12   1.58820158e-12   6.57229588e-13
   2.79777785e-12   6.23941161e-02   8.67632329e-02   7.70346969e-02
   7.73808002e-01]
[2017-11-02 11:07:05,162] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997139e-01   2.34012941e-06   1.13739823e-07   1.32513506e-07
   2.61667338e-07   4.96032160e-10   8.18517920e-10   4.24343560e-10
   6.28173513e-10]
[2017-11-02 11:07:07,955] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   3.05126127e-06   3.81304545e-07   3.02669463e-07
   6.75427088e-07   5.35652599e-11   1.07061734e-10   5.69712229e-11
   3.18935489e-10]
[2017-11-02 11:07:08,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99795616e-01   1.30336004e-04   2.52028676e-05   1.49271928e-05
   3.39452308e-05   2.39028047e-10   4.64352223e-10   3.11551590e-10
   3.93440391e-09]
[2017-11-02 11:07:08,830] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91684675e-01   5.08876797e-03   1.02386146e-03   5.74264152e-04
   1.45511178e-03   8.60448654e-06   1.56302413e-05   1.09103357e-05
   1.38201387e-04]
[2017-11-02 11:07:09,012] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99953032e-01   3.01318269e-05   5.80329743e-06   3.45485319e-06
   7.55646306e-06   4.30983504e-12   8.62149935e-12   5.77232533e-12
   7.43761858e-11]
[2017-11-02 11:07:16,208] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97193515e-01   1.64732465e-03   4.40969539e-04   2.21990689e-04
   4.95780259e-04   1.71166867e-08   3.27285292e-08   2.48423877e-08
   3.88790113e-07]
[2017-11-02 11:07:18,659] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99256074e-01   5.21880749e-04   5.80808883e-05   6.15960817e-05
   1.02204569e-04   3.25057670e-08   4.52035280e-08   3.31039232e-08
   1.93453253e-08]
[2017-11-02 11:07:19,375] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95496035e-01   2.49195588e-03   6.62057952e-04   5.92352124e-04
   7.57595233e-04   1.23998785e-08   1.63306986e-08   9.27390964e-09
   7.70725261e-09]
[2017-11-02 11:07:21,134] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99151587e-01   4.98287205e-04   1.33630107e-04   6.99298471e-05
   1.46562554e-04   1.19149213e-09   2.25251462e-09   1.65402103e-09
   2.24352021e-08]
[2017-11-02 11:07:24,228] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996066e-01   3.24102211e-06   1.53934138e-07   1.86281625e-07
   3.70567051e-07   3.90315225e-10   6.28537111e-10   3.54076157e-10
   4.44857068e-10]
[2017-11-02 11:07:24,531] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99961257e-01   3.05981812e-05   9.18082378e-07   1.05339006e-06
   2.70358714e-06   6.52529593e-07   1.18547928e-06   7.61558510e-07
   8.37532241e-07]
[2017-11-02 11:07:27,099] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.57104705e-03   3.16718477e-04   4.22747034e-05   2.59994213e-05
   7.42102638e-05   1.06008679e-01   1.67126611e-01   1.15116991e-01
   6.08717442e-01]
[2017-11-02 11:07:27,511] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98100817e-01   1.22518942e-03   2.26768709e-04   1.28152562e-04
   3.17383965e-04   9.28991994e-08   1.78991399e-07   1.24393026e-07
   1.41062878e-06]
[2017-11-02 11:07:29,387] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99977469e-01   1.41902437e-05   2.53143048e-06   2.58407772e-06
   3.19295577e-06   1.59971676e-14   2.40986515e-14   1.00282001e-14
   2.83362879e-14]
[2017-11-02 11:07:31,739] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99975681e-01   1.51617542e-05   3.50356027e-06   1.84692283e-06
   3.76209960e-06   1.87227621e-13   3.99725636e-13   2.86824140e-13
   4.88275045e-12]
[2017-11-02 11:07:35,517] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99981761e-01   1.52002985e-05   7.21285971e-07   7.77756952e-07
   1.56031365e-06   1.15155836e-11   2.34721270e-11   1.87507700e-11
   1.76801525e-11]
[2017-11-02 11:07:36,249] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99892712e-01   7.91618586e-05   7.57389944e-06   7.89413843e-06
   1.26263503e-05   5.52573889e-11   9.09706754e-11   6.31830005e-11
   6.53131021e-11]
[2017-11-02 11:07:39,235] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.01965998  0.02830032  0.00790032  0.00385878  0.01053576  0.04927156
  0.08101226  0.06345737  0.73600364]
[2017-11-02 11:07:41,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99983907e-01   1.32175664e-05   6.70838290e-07   7.69589406e-07
   1.48532513e-06   1.27771474e-10   2.36172415e-10   1.69991854e-10
   1.39558642e-10]
[2017-11-02 11:07:42,184] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99900818e-01   7.72320054e-05   5.37730239e-06   5.79441166e-06
   1.07350797e-05   1.01949682e-09   1.72188241e-09   1.32780931e-09
   8.91068219e-10]
[2017-11-02 11:07:47,074] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99896407e-01   7.45249927e-05   4.90391903e-06   5.25872929e-06
   9.76243427e-06   2.00539102e-06   2.88022716e-06   1.38135772e-06
   2.83661166e-06]
[2017-11-02 11:07:47,467] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99948978e-01   4.13135604e-05   2.10475901e-06   2.29692864e-06
   5.02737521e-06   4.95309216e-08   8.64717364e-08   6.57942678e-08
   6.13251316e-08]
[2017-11-02 11:07:47,525] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99978662e-01   1.73807002e-05   9.09176208e-07   1.03284447e-06
   2.08417578e-06   1.07996423e-09   1.94544358e-09   1.46038637e-09
   1.28529076e-09]
[2017-11-02 11:07:47,853] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99795258e-01   1.58221112e-04   8.31203488e-06   8.94531331e-06
   2.02343854e-05   1.70693033e-06   2.93449762e-06   2.30085470e-06
   2.11112524e-06]
[2017-11-02 11:07:48,111] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.78968164e-03   1.19673365e-04   7.19045420e-06   7.38324388e-06
   1.71959182e-05   2.50157654e-01   3.09516847e-01   1.83533818e-01
   2.51850516e-01]
[2017-11-02 11:07:57,726] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.48348791e-05   1.84591518e-05   1.71754505e-06   1.14200384e-06
   3.48737012e-06   1.29644960e-01   1.95775792e-01   1.34755954e-01
   5.39713621e-01]
[2017-11-02 11:07:59,484] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97890413e-01   1.32446643e-03   2.56477593e-04   1.53542875e-04
   3.70573864e-04   2.79172269e-07   5.10944119e-07   3.36653585e-07
   3.42486601e-06]
[2017-11-02 11:08:06,106] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.74386305  0.07797547  0.01995621  0.00974906  0.02537371  0.00559824
  0.00991044  0.0077686   0.09980522]
[2017-11-02 11:08:08,363] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994278e-01   3.93190612e-06   5.10211976e-07   5.03929357e-07
   7.96162340e-07   2.14196174e-12   2.89758235e-12   1.29398217e-12
   5.52792100e-12]
[2017-11-02 11:08:09,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99961615e-01   3.13658966e-05   1.58195382e-06   1.73701210e-06
   3.57108547e-06   1.76012929e-08   2.92954656e-08   2.33378579e-08
   1.93897307e-08]
[2017-11-02 11:08:12,735] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992728e-01   4.57851593e-06   1.10900930e-06   5.97444682e-07
   1.10566384e-06   5.27983323e-16   1.11866201e-15   7.94340298e-16
   1.13825295e-14]
[2017-11-02 11:08:12,874] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99956489e-01   2.64214650e-05   6.69018573e-06   3.51141398e-06
   6.96476445e-06   8.68708520e-14   1.81353034e-13   1.31716483e-13
   2.09987648e-12]
[2017-11-02 11:08:14,306] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99893069e-01   7.54930079e-05   4.10474831e-06   4.49732806e-06
   8.76860304e-06   3.34856213e-06   4.49184154e-06   2.54240354e-06
   3.59029082e-06]
[2017-11-02 11:08:15,025] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99583423e-01   3.10179748e-04   2.67952109e-05   2.87045459e-05
   5.08475969e-05   1.46932440e-08   2.08514681e-08   1.72806729e-08
   1.02169233e-08]
[2017-11-02 11:08:15,043] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99585569e-01   3.08387098e-04   2.66993557e-05   2.86503491e-05
   5.06247488e-05   1.45336205e-08   2.05595878e-08   1.70663572e-08
   1.01221334e-08]
[2017-11-02 11:08:15,103] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99281824e-01   5.16522734e-04   5.17131703e-05   5.51358135e-05
   9.48527522e-05   2.43474361e-08   3.30311067e-08   2.64071236e-08
   1.53379371e-08]
[2017-11-02 11:08:15,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98154104e-01   1.23950862e-03   1.62461685e-04   1.70006562e-04
   2.73696030e-04   7.35470849e-08   9.49825889e-08   6.89973234e-08
   3.92715229e-08]
[2017-11-02 11:08:15,512] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   8.03316993e-07   8.83459563e-08   6.04197794e-08
   1.27955516e-07   5.03914258e-15   1.05890477e-14   6.56125909e-15
   3.40673094e-14]
[2017-11-02 11:08:15,894] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.09632936e-06   2.67897434e-07   1.39680708e-07
   2.23154643e-07   2.60681705e-19   6.83292648e-19   4.57803937e-19
   1.03387998e-17]
[2017-11-02 11:08:19,750] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964714e-01   2.17451616e-05   4.41887642e-06   3.32020750e-06
   5.87966315e-06   3.65352497e-13   8.20512766e-13   4.97977581e-13
   2.22681444e-12]
[2017-11-02 11:08:21,630] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   1.03165203e-05   8.72966552e-07   9.62136937e-07
   1.39815052e-06   7.83799206e-11   1.12870102e-10   5.89183285e-11
   6.86024432e-11]
[2017-11-02 11:08:22,980] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99704897e-01   1.87989950e-04   1.86544694e-05   1.26156983e-05
   3.14892241e-05   4.51242749e-06   7.90169179e-06   5.01006843e-06
   2.69777593e-05]
[2017-11-02 11:08:24,085] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99679327e-01   1.87715705e-04   5.31824626e-05   2.61000350e-05
   5.37781671e-05   4.68398480e-11   9.42387071e-11   6.95318178e-11
   1.26912281e-09]
[2017-11-02 11:08:24,779] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93494213e-01   3.65923764e-03   1.10742101e-03   5.44046576e-04
   1.19328545e-03   6.18283593e-08   1.14741148e-07   8.76775914e-08
   1.47699211e-06]
[2017-11-02 11:08:27,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99915719e-01   6.39816571e-05   5.07995173e-06   5.73206080e-06
   9.37001732e-06   5.17357768e-10   7.77903242e-10   5.68926461e-10
   4.14189072e-10]
[2017-11-02 11:08:30,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86517966e-01   7.61234388e-03   2.10659462e-03   1.12661568e-03
   2.61092023e-03   1.28460806e-06   2.32435082e-06   1.71559554e-06
   2.02331048e-05]
[2017-11-02 11:08:31,853] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994397e-01   3.94898188e-06   4.18729456e-07   4.24674994e-07
   7.40928272e-07   8.33570366e-12   1.26523800e-11   5.53214115e-12
   1.93580377e-11]
[2017-11-02 11:08:32,375] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990940e-01   6.76473701e-06   5.98995371e-07   6.21717220e-07
   1.01678211e-06   3.36101563e-10   4.65237349e-10   2.27890123e-10
   5.15946119e-10]
[2017-11-02 11:08:33,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95045662e-01   2.90812110e-03   6.03007036e-04   6.01004460e-04
   8.41688190e-04   1.34207951e-07   1.74936034e-07   1.05431084e-07
   6.76045815e-08]
[2017-11-02 11:08:41,455] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.90499234e-01   5.78753874e-02   1.60925202e-02   7.91548379e-03
   1.95045117e-02   4.25799546e-04   7.28321320e-04   5.79606101e-04
   6.37912564e-03]
[2017-11-02 11:08:44,226] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99542475e-01   3.36441793e-04   2.42504575e-05   2.72006964e-05
   5.12615079e-05   4.12188365e-06   5.82850816e-06   4.57736223e-06
   3.98891461e-06]
[2017-11-02 11:08:48,694] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.30915480e-08   1.16258957e-06   2.05378399e-07   1.26283084e-07
   3.60670384e-07   9.84404981e-02   1.33244604e-01   8.56258199e-02
   6.82687163e-01]
[2017-11-02 11:08:50,429] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.26763892e-02   7.44191348e-04   2.90799744e-05   2.86369959e-05
   8.20110436e-05   1.82548329e-01   2.93891668e-01   2.64425457e-01
   2.15574220e-01]
[2017-11-02 11:08:51,585] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99937773e-01   4.62487078e-05   4.79490564e-06   3.20483628e-06
   7.99938243e-06   6.64820021e-09   1.31780205e-08   8.23427193e-09
   5.94993921e-08]
[2017-11-02 11:08:54,413] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.26446561e-10   1.06958929e-07   2.39957565e-08   1.13521015e-08
   3.75587206e-08   5.80166876e-02   9.18346569e-02   6.87599853e-02
   7.81388521e-01]
[2017-11-02 11:08:54,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.10205345e-04   9.05409921e-04   2.12243613e-04   1.05918116e-04
   2.94734025e-04   4.83018383e-02   8.35345387e-02   5.90327419e-02
   8.07002366e-01]
[2017-11-02 11:08:56,836] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.84636188e-01   8.80697463e-03   2.07179575e-03   1.89893972e-03
   2.58465461e-03   3.69170550e-07   4.90173477e-07   3.13672132e-07
   2.41361022e-07]
[2017-11-02 11:08:57,091] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997139e-01   2.00436943e-06   2.79753124e-07   2.04060555e-07
   3.93433027e-07   5.71281867e-12   1.14228323e-11   6.98754032e-12
   5.04229748e-11]
[2017-11-02 11:08:57,819] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99449432e-01   3.18278675e-04   8.69913056e-05   4.92480140e-05
   9.59913305e-05   2.77791096e-10   5.20345933e-10   3.51418117e-10
   4.95758856e-09]
[2017-11-02 11:08:58,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94877160e-01   2.96973065e-03   7.54863315e-04   4.33891808e-04
   9.62513499e-04   1.04226466e-07   1.86002339e-07   1.27451770e-07
   1.39785823e-06]
[2017-11-02 11:08:59,780] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99547541e-01   3.26844398e-04   3.24178254e-05   3.41221748e-05
   5.90100390e-05   1.59816782e-08   2.44820804e-08   1.82867748e-08
   1.17312258e-08]
[2017-11-02 11:09:00,226] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91987586e-01   5.05302195e-03   8.40151974e-04   7.96168461e-04
   1.31980993e-03   8.42567488e-07   1.11775455e-06   8.10981874e-07
   4.50993895e-07]
[2017-11-02 11:09:01,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997020e-01   2.13181738e-06   2.59243052e-07   2.05604522e-07
   3.90991261e-07   1.00523832e-12   1.80630662e-12   9.22177157e-13
   3.83072567e-12]
[2017-11-02 11:09:01,356] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99968052e-01   1.72097734e-05   5.95116944e-06   3.39511939e-06
   5.31541855e-06   2.59346980e-17   6.11365816e-17   3.60292942e-17
   6.56959389e-16]
[2017-11-02 11:09:01,850] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98348832e-01   8.55075836e-04   2.76393665e-04   2.64817383e-04
   2.54905666e-04   5.28159572e-10   6.24492902e-10   2.57333738e-10
   2.75981932e-10]
[2017-11-02 11:09:01,932] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96069431e-01   2.00536172e-03   6.59403740e-04   6.34287600e-04
   6.31573726e-04   4.63598804e-09   5.06513498e-09   2.27434271e-09
   1.90076288e-09]
[2017-11-02 11:09:04,110] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.16612422e-05   4.44698613e-04   1.47773651e-04   6.40492726e-05
   1.85078359e-04   3.19219120e-02   5.24251498e-02   4.43232432e-02
   8.70456457e-01]
[2017-11-02 11:09:04,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09000510e-04   1.01897412e-03   3.13637342e-04   1.41604905e-04
   4.06794512e-04   3.68100666e-02   6.00795858e-02   4.97181229e-02
   8.51402223e-01]
[2017-11-02 11:09:10,642] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.26268271e-08   8.91131003e-06   2.55968644e-06   1.14019520e-06
   3.64849961e-06   4.46963012e-02   6.99682385e-02   5.96355200e-02
   8.25683534e-01]
[2017-11-02 11:09:12,140] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993324e-01   5.17785975e-06   3.21246716e-07   3.79110702e-07
   6.76807986e-07   9.70620459e-11   1.51794022e-10   8.27079863e-11
   9.23942242e-11]
[2017-11-02 11:09:12,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99981403e-01   1.46803432e-05   9.12514281e-07   1.06910250e-06
   1.87170087e-06   1.93190672e-10   3.13900184e-10   2.07649550e-10
   1.81228491e-10]
[2017-11-02 11:09:12,931] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.83232200e-01   9.83696431e-03   1.98524888e-03   1.89624645e-03
   3.04370117e-03   1.54997895e-06   1.97249597e-06   1.34858828e-06
   7.10059965e-07]
[2017-11-02 11:09:13,403] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995947e-01   2.95377663e-06   3.27733574e-07   2.32596577e-07
   4.97482063e-07   2.69581614e-11   4.93828034e-11   3.07402437e-11
   1.94539454e-10]
[2017-11-02 11:09:16,937] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99527216e-01   3.45146284e-04   3.31055053e-05   3.49279871e-05
   5.95960992e-05   3.75264193e-08   5.44267671e-08   4.40304291e-08
   2.75245444e-08]
[2017-11-02 11:09:17,301] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.87234771e-01   7.68758683e-03   1.43497554e-03   1.39917014e-03
   2.23943545e-03   1.14096179e-06   1.44767967e-06   1.00592013e-06
   5.22824848e-07]
[2017-11-02 11:09:19,146] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992847e-01   4.42939654e-06   1.06711002e-06   5.95769677e-07
   1.07462643e-06   2.28354550e-16   4.88140905e-16   3.38879433e-16
   5.00157666e-15]
[2017-11-02 11:09:19,913] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.59738851e-01   2.16395818e-02   5.69311716e-03   5.34786237e-03
   7.54186744e-03   1.12565103e-05   1.36010640e-05   8.99476254e-06
   4.75795014e-06]
[2017-11-02 11:09:21,316] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.87985909e-01   6.33975631e-03   2.25052889e-03   1.10037392e-03
   2.30600894e-03   5.86053091e-07   1.05777781e-06   7.86913802e-07
   1.50441010e-05]
[2017-11-02 11:09:24,717] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99983311e-01   9.41594226e-06   2.94258325e-06   1.70928456e-06
   2.66864413e-06   3.14693545e-16   6.31329072e-16   3.98989205e-16
   6.05586799e-15]
[2017-11-02 11:09:25,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.21517789e-01   3.89750190e-02   1.29162958e-02   1.12811029e-02
   1.51127819e-02   5.82453504e-05   6.73742979e-05   4.60379124e-05
   2.52293885e-05]
[2017-11-02 11:09:27,216] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.62785125e-01   1.62327122e-02   8.09243880e-03   5.58693847e-03
   7.30288122e-03   8.66279097e-12   1.28359302e-11   5.85416351e-12
   7.86754689e-12]
[2017-11-02 11:09:27,369] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.64976013e-01   1.54705737e-02   7.42813153e-03   5.16179064e-03
   6.96351146e-03   7.39606206e-12   1.15969977e-11   5.51157167e-12
   8.08520698e-12]
[2017-11-02 11:09:29,553] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.03008819e-01   4.15085033e-02   2.09689885e-02   1.52932098e-02
   1.92205105e-02   6.21376395e-10   8.24950386e-10   3.82737120e-10
   3.42484430e-10]
[2017-11-02 11:09:29,738] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.60059023e-01   5.27155064e-02   2.98349503e-02   2.80333292e-02
   2.93549299e-02   7.80713037e-07   8.04301123e-07   3.93457697e-07
   2.59785025e-07]
[2017-11-02 11:09:30,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.72371519e-01   1.51991174e-02   3.77447926e-03   3.44069023e-03
   5.17585687e-03   1.09016964e-05   1.28721194e-05   9.36785545e-06
   5.20564981e-06]
[2017-11-02 11:09:32,056] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.11477089e-01   3.87931727e-02   1.63693912e-02   1.54847531e-02
   1.78440679e-02   1.02025442e-05   1.14656041e-05   6.19665980e-06
   3.55185148e-06]
[2017-11-02 11:09:32,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99756873e-01   1.14140748e-04   5.20338581e-05   3.05867907e-05
   4.63809629e-05   7.46618409e-16   1.82350163e-15   9.45846964e-16
   1.07449966e-14]
[2017-11-02 11:09:36,225] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   3.89381648e-06   3.14102579e-07   3.36993168e-07
   5.12897486e-07   1.99694931e-11   2.87774700e-11   1.36092864e-11
   2.05964794e-11]
[2017-11-02 11:09:38,012] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.02616835e-01   1.46292255e-03   7.30104366e-05   7.57290909e-05
   1.71865453e-04   1.71329603e-01   2.14954495e-01   1.34211659e-01
   1.75103784e-01]
[2017-11-02 11:09:40,026] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.65395689e-01   1.95684284e-02   5.57335420e-03   2.66321143e-03
   6.29561720e-03   2.17432771e-05   3.93035552e-05   3.09922034e-05
   4.11682762e-04]
[2017-11-02 11:09:47,416] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99908447e-01   5.60682747e-05   1.32707264e-05   7.41699159e-06
   1.48267200e-05   4.18074733e-12   8.60193080e-12   5.75237297e-12
   7.26234212e-11]
[2017-11-02 11:09:49,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98119771e-01   1.30622380e-03   1.60538912e-04   1.53948858e-04
   2.59513006e-04   1.19073000e-08   1.74217796e-08   1.33707925e-08
   1.02472066e-08]
[2017-11-02 11:09:50,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995470e-01   3.17746026e-06   4.31876828e-07   3.29458203e-07
   6.22270477e-07   9.00126490e-13   1.81730694e-12   9.76899117e-13
   4.49993732e-12]
[2017-11-02 11:09:51,904] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86851513e-01   7.58731365e-03   2.00896594e-03   1.07093365e-03
   2.43959995e-03   1.70646172e-06   3.10010955e-06   2.22096423e-06
   3.46210654e-05]
[2017-11-02 11:09:51,915] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.30117378  0.10792232  0.03004495  0.01493018  0.03881348  0.020472
  0.03509504  0.02666958  0.42487866]
[2017-11-02 11:09:54,939] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99845266e-01   8.74877660e-05   2.30352653e-05   2.11728893e-05
   2.29896177e-05   5.92757790e-14   9.25917329e-14   3.31392628e-14
   7.18414382e-14]
[2017-11-02 11:09:55,762] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.74295020e-01   1.46232080e-02   3.31398356e-03   3.04523786e-03
   4.70947335e-03   3.63271602e-06   4.51261440e-06   3.24426901e-06
   1.79287247e-06]
[2017-11-02 11:09:55,908] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.64586794e-01   1.95542704e-02   4.83011641e-03   4.37808596e-03
   6.62135705e-03   8.10970414e-06   9.85287716e-06   7.28175883e-06
   4.10653820e-06]
[2017-11-02 11:09:56,368] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95400846e-01   2.21651746e-03   8.31772981e-04   5.95903432e-04
   9.54928342e-04   7.40443679e-11   1.52354018e-10   7.90293733e-11
   1.31696598e-10]
[2017-11-02 11:09:56,508] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96928990e-01   1.49202230e-03   5.48474083e-04   3.92293878e-04
   6.38361031e-04   3.13038553e-11   6.73005124e-11   3.49715673e-11
   6.38015474e-11]
[2017-11-02 11:09:56,608] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98310089e-01   8.39580083e-04   2.93575809e-04   2.11674240e-04
   3.45099659e-04   8.91273427e-12   1.96106048e-11   1.02680477e-11
   2.05391988e-11]
[2017-11-02 11:09:57,009] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99756634e-01   1.54514579e-04   2.61463010e-05   2.83560003e-05
   3.44800210e-05   7.36108396e-11   9.76227293e-11   4.77258476e-11
   4.19313126e-11]
[2017-11-02 11:09:57,456] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94485199e-01   3.23342439e-03   6.50605536e-04   6.57672179e-04
   9.72866896e-04   5.50784769e-08   6.70100135e-08   4.00391578e-08
   2.28926069e-08]
[2017-11-02 11:09:57,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95038807e-01   2.91218632e-03   5.92007767e-04   5.99269581e-04
   8.57589243e-04   4.35533600e-08   5.33545510e-08   3.13750981e-08
   1.86158129e-08]
[2017-11-02 11:09:57,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99911070e-01   5.10041609e-05   1.24067601e-05   9.21865558e-06
   1.63447494e-05   5.63641310e-13   1.19835587e-12   6.47372672e-13
   2.26538688e-12]
[2017-11-02 11:10:00,891] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.93279924e-07   8.21466841e-08   6.01163066e-08
   1.34962505e-07   9.17267022e-13   1.73255843e-12   1.00416713e-12
   6.11570560e-12]
[2017-11-02 11:10:02,181] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.34120262  0.06013218  0.01500101  0.00756557  0.02028177  0.02443464
  0.04216905  0.03224149  0.45697162]
[2017-11-02 11:10:04,238] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.43320061e-06   1.06047279e-04   2.72626366e-05   1.35844111e-05
   4.17472729e-05   5.97777180e-02   9.25516337e-02   7.34000579e-02
   7.74074495e-01]
[2017-11-02 11:10:06,546] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.81933796e-01   6.16527302e-03   3.50538176e-04   3.46909219e-04
   8.44575057e-04   8.21588039e-02   1.26491189e-01   1.10647894e-01
   9.10609290e-02]
[2017-11-02 11:10:06,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99855280e-01   1.11410714e-04   8.33285321e-06   8.97223435e-06
   1.59304345e-05   6.89876600e-09   1.08999174e-08   9.18607679e-09
   6.40460351e-09]
[2017-11-02 11:10:06,862] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99812901e-01   1.42851815e-04   1.11678673e-05   1.19186479e-05
   2.10748640e-05   8.61994298e-09   1.33156322e-08   1.12452705e-08
   7.57787788e-09]
[2017-11-02 11:10:07,644] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.82579470e-01   9.62053146e-03   3.00872209e-03   1.36602309e-03
   3.36077693e-03   1.05746142e-06   2.28628505e-06   1.71800139e-06
   5.93812074e-05]
[2017-11-02 11:10:12,126] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999046e-01   6.80602227e-07   8.72687451e-08   5.41549880e-08
   1.12786054e-07   2.72930363e-15   6.18276114e-15   4.10167361e-15
   3.92315879e-14]
[2017-11-02 11:10:12,163] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997735e-01   1.56553756e-06   2.71900205e-07   1.62592087e-07
   3.01195826e-07   2.36425583e-16   5.51487005e-16   3.52219328e-16
   4.01693729e-15]
[2017-11-02 11:10:12,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.01278957e-11   5.53682042e-08   1.86299793e-08   7.45472484e-09
   2.33173640e-08   3.56812030e-02   5.60385622e-02   4.92475256e-02
   8.59032631e-01]
[2017-11-02 11:10:14,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993563e-01   4.86860563e-06   4.51388331e-07   4.50947738e-07
   6.34832986e-07   2.96835750e-10   4.03774764e-10   2.11783188e-10
   4.12719747e-10]
[2017-11-02 11:10:14,400] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99965787e-01   2.74344347e-05   1.74232855e-06   1.88606350e-06
   3.13977353e-06   1.55639095e-11   2.57928418e-11   1.99850674e-11
   1.88986847e-11]
[2017-11-02 11:10:17,217] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99850869e-01   8.44466049e-05   2.46647742e-05   1.39761514e-05
   2.60106772e-05   2.21733894e-12   4.30466340e-12   2.87286687e-12
   4.92702754e-11]
[2017-11-02 11:10:18,838] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99769509e-01   1.46101505e-04   2.56456115e-05   2.71363933e-05
   3.15629368e-05   4.28853619e-09   5.14894349e-09   2.65936140e-09
   3.64580321e-09]
[2017-11-02 11:10:21,755] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990463e-01   5.89760566e-06   1.31854654e-06   7.89361081e-07
   1.54417387e-06   5.51178315e-15   1.22090355e-14   7.61949589e-15
   1.42276626e-13]
[2017-11-02 11:10:21,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18302889  0.03500744  0.0078284   0.00383007  0.01122325  0.02717163
  0.05162882  0.03883021  0.64145136]
[2017-11-02 11:10:21,985] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.11613898e-04   9.22110223e-04   2.54572573e-04   1.23445599e-04
   3.48331319e-04   4.30601723e-02   7.21386299e-02   5.49623035e-02
   8.27878833e-01]
[2017-11-02 11:10:23,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99911547e-01   5.39805915e-05   1.06454791e-05   1.06954640e-05
   1.30875706e-05   2.78006199e-12   4.10891590e-12   1.65062939e-12
   3.20608731e-12]
[2017-11-02 11:10:24,142] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.28176498e-01   7.51366690e-02   3.35642509e-02   2.79470123e-02
   3.45877111e-02   1.81656884e-04   2.00243798e-04   1.29809967e-04
   7.61705742e-05]
[2017-11-02 11:10:24,234] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.80919015e-01   9.18439180e-02   4.47462983e-02   3.68955843e-02
   4.48245443e-02   2.38775057e-04   2.62721733e-04   1.69141931e-04
   9.99037220e-05]
[2017-11-02 11:10:24,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99447167e-01   2.49845936e-04   1.26152925e-04   7.36989605e-05
   1.03107646e-04   1.78657165e-17   4.45084745e-17   2.02361697e-17
   1.61112403e-16]
[2017-11-02 11:10:27,748] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.90241468e-01   5.61752217e-03   1.51840912e-03   8.00902722e-04
   1.80497230e-03   6.89291312e-07   1.27404519e-06   9.18192598e-07
   1.37891266e-05]
[2017-11-02 11:10:28,723] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.58581841e-01   6.44130483e-02   2.62758099e-02   2.16559805e-02
   2.87094396e-02   1.09784742e-04   1.23532285e-04   8.29919882e-05
   4.75801753e-05]
[2017-11-02 11:10:29,535] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.33455086e-01   6.77549914e-02   3.76963727e-02   2.84644850e-02
   3.26289684e-02   1.08536851e-08   1.27427962e-08   5.57767121e-09
   3.84583609e-09]
[2017-11-02 11:10:31,465] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.71184826e-01   5.54195940e-02   2.46717893e-02   2.24365145e-02
   2.62852330e-02   6.72170984e-07   7.33664933e-07   3.86938837e-07
   2.34980504e-07]
[2017-11-02 11:10:31,488] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.85850167e-01   8.52124467e-02   4.84855846e-02   3.77116688e-02
   4.27394398e-02   2.38149866e-07   2.74358854e-07   1.32036121e-07
   8.67573817e-08]
[2017-11-02 11:10:31,568] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.40948224e-01   6.57556802e-02   3.59559022e-02   2.64556408e-02
   3.08845025e-02   1.03649693e-08   1.29485169e-08   5.49162182e-09
   3.97131172e-09]
[2017-11-02 11:10:33,106] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.66418839e-01   6.12503551e-02   2.44771726e-02   2.04715822e-02
   2.70885937e-02   8.88901050e-05   1.01169295e-04   6.62781240e-05
   3.71562564e-05]
[2017-11-02 11:10:33,732] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.48849142e-01   2.23328471e-02   1.12551348e-02   7.57186394e-03
   9.99106746e-03   5.59569925e-11   8.06552672e-11   3.51527071e-11
   3.75333722e-11]
[2017-11-02 11:10:34,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99412537e-01   2.61659443e-04   1.36540708e-04   7.76029265e-05
   1.11614856e-04   1.72966404e-16   4.27325819e-16   2.17511973e-16
   1.74817870e-15]
[2017-11-02 11:10:35,029] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99902487e-01   5.75211743e-05   1.42760482e-05   1.31160405e-05
   1.24894677e-05   3.39160991e-13   5.08643962e-13   1.79822222e-13
   4.43187072e-13]
[2017-11-02 11:10:35,104] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98860359e-01   6.51774870e-04   1.71869804e-04   1.61119562e-04
   1.54871537e-04   5.63844874e-11   7.41194051e-11   3.01445431e-11
   3.89665071e-11]
[2017-11-02 11:10:35,387] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95117545e-01   2.88077118e-03   6.50760951e-04   6.40466576e-04
   7.10361230e-04   4.92258394e-08   5.91389799e-08   3.14862127e-08
   2.43414267e-08]
[2017-11-02 11:10:35,601] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.92244661e-01   4.54223342e-03   1.02764135e-03   9.99937765e-04
   1.18504802e-03   1.27612040e-07   1.57034961e-07   8.63367404e-08
   6.07630994e-08]
[2017-11-02 11:10:39,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97074246e-01   1.97520782e-03   2.60649249e-04   2.61773210e-04
   4.27696941e-04   1.23143877e-07   1.65758777e-07   1.19544694e-07
   6.80096193e-08]
[2017-11-02 11:10:40,623] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   2.67291534e-06   6.84286135e-07   3.92976460e-07
   6.55445945e-07   2.16163470e-17   4.94259805e-17   3.16016908e-17
   6.18257130e-16]
[2017-11-02 11:10:43,172] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986887e-01   1.00483685e-05   7.89021044e-07   9.00870361e-07
   1.35749383e-06   7.17608195e-10   8.91648144e-10   5.28348532e-10
   6.08208928e-10]
[2017-11-02 11:10:46,930] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99709904e-01   1.70222193e-04   3.77644174e-05   3.72925642e-05
   4.48559331e-05   5.60618609e-12   8.19575310e-12   3.34908815e-12
   4.59004102e-12]
[2017-11-02 11:10:50,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99980330e-01   1.14898894e-05   3.11110966e-06   1.85449960e-06
   3.25504607e-06   1.80299010e-15   3.66063753e-15   2.29027905e-15
   2.94822523e-14]
[2017-11-02 11:10:51,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992609e-01   4.95705581e-06   7.45030889e-07   7.14894838e-07
   1.00807097e-06   2.91202717e-12   3.77776976e-12   1.62138076e-12
   7.97511623e-12]
[2017-11-02 11:10:54,888] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -18897.0845
[2017-11-02 11:10:54,889] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 500000, evaluation results [500000.0, -18897.08454706009]
[2017-11-02 11:10:55,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99328852e-01   3.63724743e-04   1.03282822e-04   7.95384476e-05
   1.24552447e-04   4.63268226e-12   9.42376125e-12   5.29795999e-12
   1.21742434e-11], sum to 1.0000
[2017-11-02 11:10:55,515] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.05833333333333, 54.58333333333334, 6.191666666666666, 140.8333333333333, 21.41666666666666, 15.41666666666667, 7.199999999999999, 8.322220854923621, 18.0, 23.89622098789852, 22.7, 1.0, 0.0], 
actual action is [7.05833333333333, 18], 
sim time next is 1617000.0000, 
raw observation next is [11.91666666666667, 55.16666666666666, 6.283333333333333, 141.6666666666667, 17.33333333333333, 12.33333333333333, 7.05833333333333, 8.653731313985595, 18.0, 23.82976498172837, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.6388888888888891, 0.5516666666666665, 0.5712121212121212, 0.39351851851851866, 0.04585537918871251, 0.01233333333333333, 0.6176388888888888, 0.08653731313985595, 0.0, 0.8328235688183386, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0087. 
=============================================
[2017-11-02 11:10:58,664] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-15.97127247]
 [-14.93029308]
 [-14.33503628]
 [-14.83100414]
 [-15.04319954]], R is [[-15.3426218 ]
 [-15.18919563]
 [-15.03730392]
 [-14.88693142]
 [-15.8094883 ]].
[2017-11-02 11:10:59,081] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31500, global step 500947: loss 4.6548
[2017-11-02 11:11:01,933] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31500, global step 501619: loss 57.9607
[2017-11-02 11:11:03,565] A3C_AGENT_WORKER-Thread-7 INFO:Local step 31500, global step 502072: loss 0.2948
[2017-11-02 11:11:05,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.98018384e-01   9.10116651e-04   3.82397848e-04   2.78673280e-04
   4.10422072e-04   1.67462701e-08   2.91098843e-08   2.42955114e-08
   2.19297505e-08], sum to 1.0000
[2017-11-02 11:11:05,828] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.65833333333333, 52.75, 6.558333333333334, 148.3333333333333, 45.91666666666666, 33.91666666666666, 7.75, 7.870631192301595, 18.0, 23.97015822180994, 22.7, 1.0, 0.0], 
actual action is [7.65833333333333, 18], 
sim time next is 1615200.0000, 
raw observation next is [12.56666666666667, 53.0, 6.466666666666667, 146.6666666666667, 41.83333333333334, 30.83333333333334, 7.65833333333333, 7.874738283033852, 18.0, 23.94786981687016, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.6555555555555557, 0.53, 0.5878787878787879, 0.40740740740740755, 0.11067019400352736, 0.030833333333333338, 0.6276388888888889, 0.07874738283033852, 0.0, 0.8496956881243085, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0079. 
=============================================
[2017-11-02 11:11:06,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.99965906e-01   1.35706741e-05   9.37806817e-06   4.58706381e-06
   6.59587886e-06   1.42106053e-13   2.76836930e-13   2.89335667e-13
   7.00784591e-13], sum to 1.0000
[2017-11-02 11:11:06,127] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.13333333333333, 62.66666666666667, 5.800000000000001, 156.6666666666667, 0.0, 0.0, 5.225, 10.8078372844667, 18.0, 22.77720998154225, 22.7, 1.0, 0.0], 
actual action is [5.133333333333329, 18], 
sim time next is 1621500.0000, 
raw observation next is [10.04166666666667, 63.08333333333333, 5.449999999999999, 158.3333333333333, 0.0, 0.0, 5.133333333333329, 10.99324793935213, 18.0, 22.69742941178695, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5908119658119659, 0.6308333333333332, 0.49545454545454537, 0.43981481481481466, 0.0, 0.0, 0.5855555555555554, 0.1099324793935213, 0.0, 0.6710613445409928, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0110. 
=============================================
[2017-11-02 11:11:07,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31500, global step 503013: loss -4.6662
[2017-11-02 11:11:07,877] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31500, global step 503183: loss -4.0870
[2017-11-02 11:11:07,887] A3C_AGENT_WORKER-Thread-8 INFO:Local step 31500, global step 503185: loss -5.4708
[2017-11-02 11:11:08,815] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31500, global step 503414: loss 0.2725
[2017-11-02 11:11:08,963] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999166e-01   3.66206223e-07   2.60926271e-07   1.07591653e-07
   1.62785938e-07   1.33161423e-14   3.47699944e-14   3.36478248e-14
   1.78053861e-13], sum to 1.0000
[2017-11-02 11:11:09,062] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.15, 92.0, 7.7, 250.0, 0.0, 0.0, -0.7083333333333339, 13.93925040136167, 18.0, 20.99937646030371, 22.7, 1.0, 0.0], 
actual action is [-0.8499999999999996, 18], 
sim time next is 1668900.0000, 
raw observation next is [4.008333333333333, 92.0, 7.7, 250.0, 0.0, 0.0, -0.8499999999999996, 14.69538263682374, 18.0, 21.26768390222264, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.4361111111111111, 0.92, 0.7000000000000001, 0.6944444444444444, 0.0, 0.0, 0.4858333333333333, 0.1469538263682374, 0.0, 0.4668119860318057, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 11:11:10,544] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31500, global step 503791: loss 17.1192
[2017-11-02 11:11:11,086] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31500, global step 503911: loss 0.7107
[2017-11-02 11:11:11,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99493003e-01   9.58403762e-05   2.66479561e-04   3.23236964e-05
   5.95540623e-05   7.40647181e-07   1.46224863e-06   2.54588849e-06
   4.80623239e-05], sum to 1.0000
[2017-11-02 11:11:11,586] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.4166666666666667, 92.5, 8.7, 248.3333333333333, 0.0, 0.0, -4.625, 20.0139198184736, 18.0, 20.74222436039259, 21.5, 0.0, 0.0], 
actual action is [-4.583333333333333, 18], 
sim time next is 1727700.0000, 
raw observation next is [0.4583333333333333, 92.25, 8.7, 249.1666666666667, 0.0, 0.0, -4.583333333333333, 21.53002616947216, 18.0, 20.8184853082548, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.3450854700854701, 0.9225, 0.7909090909090909, 0.6921296296296298, 0.0, 0.0, 0.4236111111111111, 0.21530026169472158, 0.0, 0.4026407583221143, 0.5, 0.0, 0.0], 
reward next is -0.0974. 
=============================================
[2017-11-02 11:11:12,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99993920e-01   2.83732152e-06   1.62229117e-06   5.98448992e-07
   9.43534587e-07   4.29378921e-16   9.38966621e-16   8.57316457e-16
   1.70014516e-15], sum to 1.0000
[2017-11-02 11:11:12,268] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.516666666666667, 238.3333333333333, 93.33333333333333, 0.0, -3.9, 14.37653125511362, 18.0, 21.93457325964161, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1691700.0000, 
raw observation next is [1.1, 88.0, 6.558333333333334, 239.1666666666667, 91.66666666666666, 0.0, -3.9, 14.71743422724062, 18.0, 21.89178963790858, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.36153846153846153, 0.88, 0.5962121212121212, 0.664351851851852, 0.24250440917107582, 0.0, 0.435, 0.1471743422724062, 0.0, 0.5559699482726543, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 11:11:12,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   2.76343766e-08   2.51138239e-08   4.87641749e-09
   7.28982785e-09   4.37746338e-18   1.27612818e-17   1.77362181e-17
   1.11550348e-16], sum to 1.0000
[2017-11-02 11:11:12,387] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.491666666666666, 74.83333333333333, 7.408333333333333, 120.0, 0.0, 0.0, 2.533333333333333, 14.76682178824176, 18.0, 21.20962209130304, 21.5, 0.0, 0.0], 
actual action is [2.4916666666666663, 18], 
sim time next is 1629000.0000, 
raw observation next is [7.45, 75.0, 7.45, 120.0, 0.0, 0.0, 2.491666666666666, 15.17573305257682, 18.0, 21.16396587568249, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.5243589743589744, 0.75, 0.6772727272727272, 0.3333333333333333, 0.0, 0.0, 0.5415277777777778, 0.1517573305257682, 0.0, 0.45199512509749845, 0.5, 0.0, 0.0], 
reward next is -0.0480. 
=============================================
[2017-11-02 11:11:12,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999762e-01   5.86234883e-08   6.27519512e-08   1.14297229e-08
   1.51895936e-08   2.51846560e-20   6.31290026e-20   9.03674334e-20
   8.17745429e-19], sum to 1.0000
[2017-11-02 11:11:12,612] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.6, 97.0, 3.366666666666667, 166.6666666666667, 0.0, 0.0, 1.6, 16.76494674501678, 18.0, 21.39187752876706, 21.5, 0.0, 0.0], 
actual action is [1.5999999999999996, 18], 
sim time next is 1658700.0000, 
raw observation next is [6.6, 97.0, 3.15, 170.0, 0.0, 0.0, 1.6, 17.25771459978721, 18.0, 21.32185096724448, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.5025641025641026, 0.97, 0.2863636363636364, 0.4722222222222222, 0.0, 0.0, 0.5266666666666667, 0.1725771459978721, 0.0, 0.4745501381777828, 0.5, 0.0, 0.0], 
reward next is -0.0254. 
=============================================
[2017-11-02 11:11:15,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99999762e-01   1.03318492e-07   6.26084855e-08   1.25645938e-08
   1.86840889e-08   3.44708790e-22   6.09002436e-22   1.80531825e-21
   6.81590362e-21], sum to 1.0000
[2017-11-02 11:11:15,796] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.09999999999999999, 90.33333333333334, 9.2, 241.6666666666667, 0.0, 0.0, 4.95, 16.04627664087014, 25.0, 21.00018160739887, 21.5, 0.0, 58.28008277264994], 
actual action is [4.9, 20.0], 
sim time next is 1739700.0000, 
raw observation next is [-0.15, 90.0, 9.2, 242.5, 0.0, 0.0, 4.9, 15.24581568918282, 20.0, 21.10912679539893, 21.5, 0.0, 41.84361488032917], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.3294871794871795, 0.9, 0.8363636363636363, 0.6736111111111112, 0.0, 0.0, 0.5816666666666667, 0.1524581568918282, 0.2857142857142857, 0.44416097077127553, 0.5, 0.0, 0.49227782212151966], 
reward next is -0.4989. 
=============================================
[2017-11-02 11:11:16,372] A3C_AGENT_WORKER-Thread-9 INFO:Local step 31500, global step 505004: loss -7.3659
[2017-11-02 11:11:17,330] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31500, global step 505172: loss 44.8857
[2017-11-02 11:11:17,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31500, global step 505196: loss 21.2693
[2017-11-02 11:11:17,663] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31500, global step 505250: loss -6.1426
[2017-11-02 11:11:18,063] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31500, global step 505344: loss -43.1001
[2017-11-02 11:11:19,095] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.58920614e-38   5.35566109e-24   7.87900388e-24   8.83217840e-25
   3.38303433e-24   2.08770391e-02   1.32556828e-02   4.32901531e-01
   5.32965720e-01], sum to 1.0000
[2017-11-02 11:11:19,214] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.2, 91.0, 9.0, 240.0, 0.0, 0.0, -4.775, 16.39106154434277, 18.0, 21.31383582525559, 21.5, 0.0, 0.0], 
actual action is [5.2, 23.0], 
sim time next is 1735500.0000, 
raw observation next is [0.1833333333333333, 90.99999999999999, 9.016666666666666, 240.0, 0.0, 0.0, 5.2, 14.82898402843525, 23.0, 21.34199806337767, 21.5, 0.0, 67.45521401088232], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.33803418803418805, 0.9099999999999998, 0.8196969696969696, 0.6666666666666666, 0.0, 0.0, 0.5866666666666667, 0.14828984028435252, 0.7142857142857143, 0.4774282947682385, 0.5, 0.0, 0.7935907530692037], 
reward next is -0.7368. 
=============================================
[2017-11-02 11:11:19,591] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31500, global step 505655: loss 86.9913
[2017-11-02 11:11:20,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999285e-01   5.85785585e-07   9.98436747e-08   3.91590476e-08
   3.80458651e-08   2.42708896e-20   4.42125711e-20   6.54355131e-19
   1.62365731e-19], sum to 1.0000
[2017-11-02 11:11:20,134] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.749999999999999, 235.0, 85.0, 0.0, -3.9, 12.62348862318748, 18.0, 22.13049890240072, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1693200.0000, 
raw observation next is [1.1, 88.0, 6.800000000000001, 233.3333333333334, 83.33333333333334, 0.0, -3.9, 12.93094408181867, 18.0, 22.26750851676432, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.36153846153846153, 0.88, 0.6181818181818183, 0.6481481481481484, 0.22045855379188714, 0.0, 0.435, 0.12930944081818668, 0.0, 0.6096440738234742, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0129. 
=============================================
[2017-11-02 11:11:24,631] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31500, global step 506568: loss 7.2824
[2017-11-02 11:11:25,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.17347747e-06   8.69362091e-04   2.20352458e-03   1.02620490e-03
   5.09980950e-04   4.25570831e-03   1.14334412e-02   6.06112629e-02
   9.19089317e-01], sum to 1.0000
[2017-11-02 11:11:25,879] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.2, 91.0, 9.0, 240.0, 0.0, 0.0, -4.775, 14.48118387876521, 18.0, 21.86005953555101, 21.5, 0.0, 0.0], 
actual action is [5.2, 23.0], 
sim time next is 1735500.0000, 
raw observation next is [0.1833333333333333, 90.99999999999999, 9.016666666666666, 240.0, 0.0, 0.0, 5.2, 13.83524457304403, 23.0, 21.76565273380562, 21.5, 0.0, 53.48151272260165], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.33803418803418805, 0.9099999999999998, 0.8196969696969696, 0.6666666666666666, 0.0, 0.0, 0.5866666666666667, 0.13835244573044028, 0.7142857142857143, 0.53795039054366, 0.5, 0.0, 0.6291942673247253], 
reward next is -0.5663. 
=============================================
[2017-11-02 11:11:27,304] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.92716651e-09   3.84815735e-09   1.95766447e-09
   7.53619112e-10   1.58683568e-31   8.39704233e-31   2.79271898e-30
   1.06109002e-28], sum to 1.0000
[2017-11-02 11:11:27,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.82230632e-19   1.20901932e-13   1.22678492e-13   5.25287957e-14
   5.98161047e-14   7.68049434e-03   1.12912646e-02   1.04054585e-01
   8.76973629e-01], sum to 1.0000
[2017-11-02 11:11:27,323] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 8.7, 246.6666666666667, 0.0, 0.0, 5.5, 12.4910600336449, 20.0, 21.89592894054031, 21.5, 0.0, 43.3418513386171], 
actual action is [-4.5, 18], 
sim time next is 1729500.0000, 
raw observation next is [0.5, 92.0, 8.7, 245.8333333333333, 0.0, 0.0, -4.5, 14.09234794276747, 18.0, 21.95607711092794, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.0, 0.34615384615384615, 0.92, 0.7909090909090909, 0.6828703703703702, 0.0, 0.0, 0.425, 0.1409234794276747, 0.0, 0.5651538729897057, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:11:27,394] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 88.0, 7.200000000000001, 216.6666666666667, 0.0, 0.0, 6.1, 11.79146624026761, 20.0, 22.34050391230963, 22.7, 1.0, 71.88196719269284], 
actual action is [6.1, 25.0], 
sim time next is 1707900.0000, 
raw observation next is [1.1, 88.0, 7.199999999999999, 218.3333333333333, 0.0, 0.0, 6.1, 11.62493309932733, 25.0, 22.30651822580879, 22.7, 1.0, 38.95968381621063], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.36153846153846153, 0.88, 0.6545454545454544, 0.6064814814814814, 0.0, 0.0, 0.6016666666666667, 0.11624933099327331, 1.0, 0.6152168894012559, 0.6714285714285714, 1.0, 0.45834922136718387], 
reward next is -0.4241. 
=============================================
[2017-11-02 11:11:52,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-74.40496826]
 [-73.51778412]
 [-75.65777588]
 [-75.17462921]
 [-74.2240448 ]], R is [[-75.66401672]
 [-75.90737915]
 [-76.1483078 ]
 [-76.38682556]
 [-76.62295532]].
[2017-11-02 11:11:52,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 32000, global step 509928: loss -261.8994
[2017-11-02 11:11:55,033] A3C_AGENT_WORKER-Thread-6 INFO:Local step 32000, global step 510189: loss -140.7551
[2017-11-02 11:11:58,173] A3C_AGENT_WORKER-Thread-7 INFO:Local step 32000, global step 510565: loss 172.4965
[2017-11-02 11:12:01,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.28190415e-22   6.17785598e-15   2.08502960e-13   6.44892028e-16
   2.65673832e-15   2.80546847e-05   2.62256770e-04   2.78837886e-03
   9.96921301e-01], sum to 1.0000
[2017-11-02 11:12:01,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 85.0, 9.7, 250.0, 99.0, 0.0, -7.8, 18.72676151401176, 18.0, 22.04211858381231, 22.7, 1.0, 0.0], 
actual action is [2.2, 23.0], 
sim time next is 1780500.0000, 
raw observation next is [-2.8, 85.33333333333333, 9.616666666666665, 250.0, 96.25, 0.0, 2.2, 16.34305649234489, 23.0, 21.83476100588938, 22.7, 1.0, 99.76895133038518], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.2615384615384615, 0.8533333333333333, 0.8742424242424242, 0.6944444444444444, 0.25462962962962965, 0.0, 0.5366666666666667, 0.1634305649234489, 0.7142857142857143, 0.54782300084134, 0.6714285714285714, 1.0, 1.1737523685927669], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:02,005] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99987125e-01   2.76019023e-07   1.24494254e-05   8.42941503e-08
   1.61020125e-07   2.67867755e-23   6.12444722e-23   3.79682919e-22
   1.12778865e-19], sum to 1.0000
[2017-11-02 11:12:02,012] A3C_AGENT_WORKER-Thread-8 INFO:Local step 32000, global step 511027: loss -158.1974
[2017-11-02 11:12:02,049] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 79.0, 8.7, 245.0, 0.0, 0.0, -1.199999999999999, 21.71969082045766, 20.0, 20.12677350979494, 21.5, 0.0, 49.87907352401349], 
actual action is [-11.2, 18], 
sim time next is 1834500.0000, 
raw observation next is [-6.2, 79.0, 8.616666666666665, 245.8333333333333, 0.0, 0.0, -11.2, 24.56378177899338, 18.0, 20.18059319110866, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.17435897435897435, 0.79, 0.7833333333333332, 0.6828703703703702, 0.0, 0.0, 0.31333333333333335, 0.2456378177899338, 0.0, 0.3115133130155228, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:02,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 32000, global step 511052: loss 36.4577
[2017-11-02 11:12:03,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 32000, global step 511179: loss 101.5985
[2017-11-02 11:12:05,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 32000, global step 511420: loss -29.4161
[2017-11-02 11:12:07,128] A3C_AGENT_WORKER-Thread-5 INFO:Local step 32000, global step 511577: loss 132.0305
[2017-11-02 11:12:08,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.09147041e-32   3.01724404e-20   5.00990665e-18   3.26312654e-21
   1.50517516e-20   5.83264511e-04   1.05101115e-03   5.87604009e-03
   9.92489636e-01], sum to 1.0000
[2017-11-02 11:12:09,129] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.541666666666667, 83.25, 9.616666666666665, 249.1666666666667, 0.0, 0.0, 0.5, 21.72408992234881, 23.0, 20.90952650040602, 21.5, 0.0, 94.08405833228082], 
actual action is [0.45833333333333304, 25], 
sim time next is 1800600.0000, 
raw observation next is [-4.583333333333333, 83.5, 9.533333333333333, 248.3333333333333, 0.0, 0.0, 0.458333333333333, 19.46619876594933, 25.0, 20.95262079016296, 21.5, 0.0, 63.15033568019498], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.21581196581196585, 0.835, 0.8666666666666667, 0.6898148148148147, 0.0, 0.0, 0.5076388888888889, 0.1946619876594933, 1.0, 0.42180297002328004, 0.5, 0.0, 0.7429451256493527], 
reward next is -0.7468. 
=============================================
[2017-11-02 11:12:12,054] A3C_AGENT_WORKER-Thread-4 INFO:Local step 32000, global step 512156: loss -9.9427
[2017-11-02 11:12:16,692] A3C_AGENT_WORKER-Thread-14 INFO:Local step 32000, global step 512639: loss 37.4683
[2017-11-02 11:12:16,958] A3C_AGENT_WORKER-Thread-12 INFO:Local step 32000, global step 512669: loss 19.1070
[2017-11-02 11:12:17,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 32000, global step 512674: loss -46.0654
[2017-11-02 11:12:19,239] A3C_AGENT_WORKER-Thread-2 INFO:Local step 32000, global step 512898: loss -17.8577
[2017-11-02 11:12:19,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   4.93468120e-33   1.84264363e-30   3.41544292e-33
   2.37368294e-32   4.36905073e-03   1.76099967e-02   9.06595588e-03
   9.68955040e-01], sum to 1.0000
[2017-11-02 11:12:19,933] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 80.66666666666666, 8.991666666666665, 244.1666666666667, 0.0, 0.0, -1.2, 16.15604753145966, 20.0, 21.05064592119252, 21.5, 0.0, 49.4335098002306], 
actual action is [-1.2000000000000002, 25.0], 
sim time next is 1831200.0000, 
raw observation next is [-6.199999999999999, 80.33333333333334, 9.033333333333333, 243.3333333333333, 0.0, 0.0, -1.2, 16.2732342876522, 25.0, 21.05795252007183, 21.5, 0.0, 43.24016676272986], 
processed observation next is [1.0, 0.17391304347826086, 0.17435897435897438, 0.8033333333333335, 0.8212121212121212, 0.6759259259259258, 0.0, 0.0, 0.48000000000000004, 0.16273234287652202, 1.0, 0.43685036001026134, 0.5, 0.0, 0.5087078442674101], 
reward next is -0.5210. 
=============================================
[2017-11-02 11:12:21,487] A3C_AGENT_WORKER-Thread-13 INFO:Local step 32000, global step 513149: loss -72.5619
[2017-11-02 11:12:21,771] A3C_AGENT_WORKER-Thread-11 INFO:Local step 32000, global step 513177: loss -128.2923
[2017-11-02 11:12:24,803] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99999523e-01   3.45178131e-09   5.22298137e-07   6.41640630e-10
   1.77141046e-09   4.32720482e-33   1.44769380e-30   1.94316304e-31
   2.91442384e-28], sum to 1.0000
[2017-11-02 11:12:25,013] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.958333333333333, 71.0, 7.741666666666667, 240.0, 146.6666666666667, 33.75, 0.0, 15.32738161543833, 24.0, 21.72510083766306, 22.7, 1.0, 55.36117504438526], 
actual action is [0.04166666666666696, 19.0], 
sim time next is 1858200.0000, 
raw observation next is [-4.916666666666667, 71.0, 7.783333333333333, 240.0, 141.3333333333333, 26.99999999999999, 0.04166666666666696, 15.11282245241295, 19.0, 21.84852896824841, 22.7, 1.0, 57.1807339729309], 
processed observation next is [1.0, 0.5217391304347826, 0.20726495726495722, 0.71, 0.7075757575757575, 0.6666666666666666, 0.37389770723104043, 0.02699999999999999, 0.5006944444444444, 0.1511282245241295, 0.14285714285714285, 0.5497898526069156, 0.6714285714285714, 1.0, 0.6727145173285989], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:28,712] A3C_AGENT_WORKER-Thread-15 INFO:Local step 32000, global step 513860: loss 111.7255
[2017-11-02 11:12:34,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.55046911e-13   4.94011587e-09   2.70718124e-06   5.93097793e-09
   4.36496173e-09   8.34606035e-05   3.27573181e-03   6.20016304e-04
   9.96018112e-01], sum to 1.0000
[2017-11-02 11:12:34,790] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666667, 84.0, 4.433333333333334, 250.0, 0.0, 0.0, 0.291666666666667, 13.35861964669761, 24.0, 22.68582601464154, 22.7, 1.0, 62.82043011667013], 
actual action is [0.33333333333333304, 25], 
sim time next is 1881900.0000, 
raw observation next is [-4.625, 83.75, 4.475, 252.5, 0.0, 0.0, 0.333333333333333, 13.14943530791192, 25.0, 22.74332482475086, 22.7, 1.0, 63.05729968321976], 
processed observation next is [1.0, 0.782608695652174, 0.21474358974358973, 0.8375, 0.4068181818181818, 0.7013888888888888, 0.0, 0.0, 0.5055555555555555, 0.1314943530791192, 1.0, 0.6776178321072658, 0.6714285714285714, 1.0, 0.7418505845084677], 
reward next is -0.6808. 
=============================================
[2017-11-02 11:12:43,707] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   1.07531170e-34   1.52263649e-32   8.33577942e-35
   1.29154365e-34   8.23125988e-03   3.10671896e-01   9.57235228e-03
   6.71524405e-01], sum to 1.0000
[2017-11-02 11:12:43,805] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.9, 82.0, 3.275, 222.5, 0.0, 0.0, -3.9, 16.54548636215656, 25.0, 20.82667691506166, 21.5, 0.0, 46.12684784264881], 
actual action is [-3.9000000000000004, 25], 
sim time next is 1921800.0000, 
raw observation next is [-8.9, 82.0, 3.183333333333333, 221.6666666666667, 0.0, 0.0, -3.9, 16.58669090625938, 25.0, 20.81529180013327, 21.5, 0.0, 46.05329927872049], 
processed observation next is [0.0, 0.21739130434782608, 0.10512820512820512, 0.82, 0.28939393939393937, 0.6157407407407409, 0.0, 0.0, 0.435, 0.16586690906259383, 1.0, 0.40218454287618144, 0.5, 0.0, 0.5418035209261234], 
reward next is -0.5854. 
=============================================
[2017-11-02 11:13:06,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 32500, global step 517836: loss 3.7471
[2017-11-02 11:13:08,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  7.34339833e-01   1.37076462e-02   2.28503719e-01   2.36493768e-03
   5.16959932e-03   1.34857937e-05   1.33971020e-03   2.18288274e-04
   1.43427113e-02], sum to 1.0000
[2017-11-02 11:13:08,838] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.083333333333333, 65.0, 4.766666666666666, 228.3333333333333, 197.0, 2.666666666666667, 0.8250000000000002, 11.65760165703091, 23.0, 22.53092890922721, 22.7, 1.0, 54.17288319573777], 
actual action is [-9.083333333333332, 18.0], 
sim time next is 1947300.0000, 
raw observation next is [-3.991666666666667, 65.0, 4.683333333333333, 229.1666666666667, 189.5, 2.333333333333333, -9.083333333333332, 12.54480397097314, 18.0, 22.54319540293011, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.23098290598290597, 0.65, 0.4257575757575757, 0.6365740740740742, 0.5013227513227513, 0.002333333333333333, 0.34861111111111115, 0.1254480397097314, 0.0, 0.6490279147043013, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:13:10,600] A3C_AGENT_WORKER-Thread-6 INFO:Local step 32500, global step 518308: loss 41.0949
[2017-11-02 11:13:11,299] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.38164943e-33   2.36240980e-32   1.32714322e-34
   8.68581133e-34   2.64786230e-03   1.89117461e-01   2.66577210e-02
   7.81576991e-01], sum to 1.0000
[2017-11-02 11:13:11,428] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.25, 62.0, 5.225, 235.0, 118.25, 0.0, -8.3, 15.20100919163793, 18.0, 22.08342828722517, 22.7, 1.0, 0.0], 
actual action is [1.75, 20.0], 
sim time next is 1952400.0000, 
raw observation next is [-3.2, 62.0, 5.266666666666667, 236.6666666666667, 116.1666666666667, 0.0, 1.75, 13.07478241464459, 20.0, 22.10645214055955, 22.7, 1.0, 67.81404137271335], 
processed observation next is [0.0, 0.6086956521739131, 0.2512820512820513, 0.62, 0.47878787878787876, 0.6574074074074076, 0.30731922398589073, 0.0, 0.5291666666666667, 0.1307478241464459, 0.2857142857142857, 0.5866360200799358, 0.6714285714285714, 1.0, 0.7978122514436864], 
reward next is -0.7311. 
=============================================
[2017-11-02 11:13:12,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.97196317e-01   1.13053829e-04   2.53761164e-03   6.43728927e-05
   8.85124828e-05   1.59571436e-11   5.70530567e-10   6.70816944e-11
   3.07345371e-09], sum to 1.0000
[2017-11-02 11:13:12,770] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.733333333333334, 80.66666666666667, 4.766666666666667, 233.3333333333333, 0.0, 0.0, -3.691666666666666, 13.49231489750756, 25.0, 21.34002194349998, 21.5, 0.0, 47.11511156155684], 
actual action is [-3.7333333333333343, 20.0], 
sim time next is 1917900.0000, 
raw observation next is [-8.775, 81.0, 4.6, 232.5, 0.0, 0.0, -3.733333333333334, 13.55170295026523, 20.0, 21.32262813233478, 21.5, 0.0, 47.00935625273269], 
processed observation next is [0.0, 0.17391304347826086, 0.10833333333333332, 0.81, 0.41818181818181815, 0.6458333333333334, 0.0, 0.0, 0.43777777777777777, 0.13551702950265232, 0.2857142857142857, 0.4746611617621116, 0.5, 0.0, 0.5530512500321493], 
reward next is -0.5231. 
=============================================
[2017-11-02 11:13:14,126] A3C_AGENT_WORKER-Thread-16 INFO:Local step 32500, global step 518775: loss 78.6777
[2017-11-02 11:13:14,429] A3C_AGENT_WORKER-Thread-7 INFO:Local step 32500, global step 518819: loss 24.0859
[2017-11-02 11:13:16,221] A3C_AGENT_WORKER-Thread-8 INFO:Local step 32500, global step 519031: loss 71.5072
[2017-11-02 11:13:17,568] A3C_AGENT_WORKER-Thread-3 INFO:Local step 32500, global step 519205: loss 33.7830
[2017-11-02 11:13:19,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 32500, global step 519429: loss 31.2195
[2017-11-02 11:13:20,813] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.54675422e-09   2.68483102e-08   8.25898951e-07   1.09715481e-08
   3.69760791e-08   1.81700557e-03   4.37755138e-02   4.34363168e-03
   9.50062931e-01], sum to 1.0000
[2017-11-02 11:13:20,911] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.166666666666667, 66.33333333333334, 4.433333333333334, 260.0, 37.33333333333333, 0.0, 1.925, 13.94209625245087, 20.0, 22.21191848380469, 22.7, 1.0, 35.32469943422323], 
actual action is [1.833333333333333, 25.0], 
sim time next is 1959900.0000, 
raw observation next is [-3.258333333333333, 67.41666666666666, 4.391666666666666, 260.0, 33.66666666666667, 0.0, 1.833333333333333, 13.94015071729297, 25.0, 22.25191075660713, 22.7, 1.0, 25.57856674498662], 
processed observation next is [0.0, 0.6956521739130435, 0.2497863247863248, 0.6741666666666666, 0.3992424242424242, 0.7222222222222222, 0.08906525573192241, 0.0, 0.5305555555555556, 0.1394015071729297, 1.0, 0.6074158223724473, 0.6714285714285714, 1.0, 0.3009243146469014], 
reward next is -0.2848. 
=============================================
[2017-11-02 11:13:21,045] A3C_AGENT_WORKER-Thread-5 INFO:Local step 32500, global step 519613: loss 17.0956
[2017-11-02 11:13:22,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-53.89064407]
 [-52.26286316]
 [-53.04340363]
 [-52.17170715]
 [-51.96595383]], R is [[-52.61081696]
 [-52.76852036]
 [-52.9285965 ]
 [-53.09786224]
 [-53.28142929]].
[2017-11-02 11:13:28,412] A3C_AGENT_WORKER-Thread-4 INFO:Local step 32500, global step 520610: loss 10.6998
[2017-11-02 11:13:28,773] A3C_AGENT_WORKER-Thread-12 INFO:Local step 32500, global step 520665: loss -51.1408
[2017-11-02 11:13:32,711] A3C_AGENT_WORKER-Thread-9 INFO:Local step 32500, global step 521138: loss 0.8371
[2017-11-02 11:13:33,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 32500, global step 521205: loss 150.3241
[2017-11-02 11:13:35,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 32500, global step 521392: loss 45.3164
[2017-11-02 11:13:35,452] A3C_AGENT_WORKER-Thread-13 INFO:Local step 32500, global step 521416: loss -3.3106
[2017-11-02 11:13:37,584] A3C_AGENT_WORKER-Thread-11 INFO:Local step 32500, global step 521681: loss -28.7263
[2017-11-02 11:13:37,708] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.29168119e-29   9.69853048e-20   2.10693511e-18   5.66608768e-20
   1.06715636e-18   8.48536380e-03   8.98362994e-01   7.71894166e-03
   8.54327902e-02], sum to 1.0000
[2017-11-02 11:13:37,736] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.4, 85.33333333333334, 5.266666666666667, 253.3333333333333, 82.0, 0.0, 0.5499999999999998, 10.60143378121585, 21.0, 23.0171582009579, 22.7, 1.0, 22.77842188326439], 
actual action is [0.5999999999999996, 22.0], 
sim time next is 2042100.0000, 
raw observation next is [-4.35, 85.0, 5.35, 255.0, 79.25, 0.0, 0.5999999999999996, 10.79101787814651, 22.0, 22.98749246420834, 22.7, 1.0, 20.83270321023534], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2217948717948718, 0.85, 0.48636363636363633, 0.7083333333333334, 0.20965608465608465, 0.0, 0.51, 0.1079101787814651, 0.5714285714285714, 0.7124989234583344, 0.6714285714285714, 1.0, 0.2450906260027687], 
reward next is -0.2314. 
=============================================
[2017-11-02 11:13:39,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   4.74464878e-25   1.47435137e-23   7.78854007e-25
   6.40177112e-24   7.59547725e-02   8.11720967e-01   1.80045404e-02
   9.43197682e-02], sum to 1.0000
[2017-11-02 11:13:39,233] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 83.0, 4.199999999999999, 257.5, 0.0, 0.0, -0.6000000000000014, 10.84194975405874, 25.0, 22.47617074872006, 21.5, 0.0, 45.53840290903693], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1984800.0000, 
raw observation next is [-5.6, 83.0, 4.066666666666666, 256.6666666666667, 0.0, 0.0, -0.5999999999999996, 10.83531802590931, 25.0, 22.46942170374908, 21.5, 0.0, 45.46159060986911], 
processed observation next is [0.0, 1.0, 0.18974358974358976, 0.83, 0.3696969696969697, 0.712962962962963, 0.0, 0.0, 0.49, 0.10835318025909309, 1.0, 0.6384888148212973, 0.5, 0.0, 0.5348422424690484], 
reward next is -0.4814. 
=============================================
[2017-11-02 11:13:43,089] A3C_AGENT_WORKER-Thread-15 INFO:Local step 32500, global step 522440: loss 8.1789
[2017-11-02 11:13:47,044] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   1.77944736e-30   8.48794521e-29   4.37871157e-30
   6.00784337e-29   7.42938695e-03   8.64980102e-01   7.48857018e-03
   1.20101988e-01], sum to 1.0000
[2017-11-02 11:13:47,142] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.066666666666666, 86.33333333333333, 4.933333333333333, 240.0, 35.66666666666666, 0.0, -1.083333333333333, 12.12027852655193, 19.0, 22.01725263777491, 22.7, 1.0, 63.92427859404962], 
actual action is [-1.0666666666666664, 20.0], 
sim time next is 2018700.0000, 
raw observation next is [-6.05, 86.25, 4.975, 240.0, 39.0, 0.0, -1.066666666666666, 12.1794804484776, 20.0, 21.99881771172628, 22.7, 1.0, 38.60976194407841], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.1782051282051282, 0.8625, 0.4522727272727272, 0.6666666666666666, 0.10317460317460317, 0.0, 0.4822222222222222, 0.121794804484776, 0.2857142857142857, 0.5712596731037541, 0.6714285714285714, 1.0, 0.454232493459746], 
reward next is -0.4210. 
=============================================
[2017-11-02 11:13:51,249] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.18915610e-25   7.56062668e-16   5.14376478e-14   5.16485921e-15
   3.17837594e-14   3.09781153e-02   2.84426451e-01   2.02905405e-02
   6.64304912e-01], sum to 1.0000
[2017-11-02 11:13:51,307] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 90.16666666666667, 5.1, 261.6666666666667, 0.0, 0.0, 0.5, 9.8327648286689, 25.0, 22.44065917983294, 21.5, 0.0, 45.79684702772398], 
actual action is [0.5, 25], 
sim time next is 2078100.0000, 
raw observation next is [-4.5, 89.75, 5.1, 262.5, 0.0, 0.0, 0.5, 9.793109271171732, 25.0, 22.44546583473726, 21.5, 0.0, 45.78987689716251], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.21794871794871795, 0.8975, 0.4636363636363636, 0.7291666666666666, 0.0, 0.0, 0.5083333333333333, 0.09793109271171732, 1.0, 0.6350665478196085, 0.5, 0.0, 0.5387044340842648], 
reward next is -0.4848. 
=============================================
[2017-11-02 11:14:07,128] A3C_AGENT_WORKER-Thread-10 INFO:Local step 33000, global step 525491: loss 14.6892
[2017-11-02 11:14:09,058] A3C_AGENT_WORKER-Thread-6 INFO:Local step 33000, global step 525679: loss 20.4266
[2017-11-02 11:14:13,598] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99999642e-01   4.60169041e-08   1.19071359e-07   2.35771296e-08
   7.68266517e-08   3.23153651e-23   8.55981735e-23   6.39147159e-23
   5.07832149e-22], sum to 1.0000
[2017-11-02 11:14:13,624] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.149999999999999, 72.25, 4.85, 252.5, 271.75, 90.75, -12.2, 11.88666893818693, 18.0, 22.56334430732191, 22.7, 1.0, 0.0], 
actual action is [-12.149999999999999, 18], 
sim time next is 2114400.0000, 
raw observation next is [-7.100000000000001, 71.33333333333334, 4.766666666666667, 253.3333333333333, 278.8333333333334, 94.16666666666667, -12.15, 12.45688525897274, 18.0, 22.54600573520039, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.15128205128205124, 0.7133333333333334, 0.43333333333333335, 0.7037037037037036, 0.7376543209876546, 0.09416666666666668, 0.29750000000000004, 0.1245688525897274, 0.0, 0.6494293907429126, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:14:14,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-42.59101868]
 [-41.422966  ]
 [-40.61299133]
 [-40.88613892]
 [-41.05667877]], R is [[-41.58870316]
 [-42.17281723]
 [-41.76583481]
 [-41.36219788]
 [-40.96178436]].
[2017-11-02 11:14:14,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 33000, global step 526282: loss -17.0299
[2017-11-02 11:14:16,682] A3C_AGENT_WORKER-Thread-7 INFO:Local step 33000, global step 526684: loss -0.4559
[2017-11-02 11:14:17,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.33862779e-22   1.34621216e-14   5.34504793e-14   1.94698671e-14
   2.54664420e-14   2.33533442e-01   3.25617313e-01   1.27973586e-01
   3.12875658e-01], sum to 1.0000
[2017-11-02 11:14:17,180] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.6, 83.0, 4.333333333333333, 260.0, 0.0, 0.0, -0.5999999999999996, 17.36425787068436, 20.0, 21.4953899531721, 21.5, 0.0, 48.50616742963331], 
actual action is [-0.5999999999999996, 22.0], 
sim time next is 2148900.0000, 
raw observation next is [-5.6, 83.0, 4.466666666666666, 260.0, 0.0, 0.0, -0.5999999999999996, 17.51170649176602, 22.0, 21.39021173767012, 21.5, 0.0, 29.83406472762032], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.18974358974358976, 0.83, 0.406060606060606, 0.7222222222222222, 0.0, 0.0, 0.49, 0.17511706491766021, 0.5714285714285714, 0.48431596252430303, 0.5, 0.0, 0.3509889967955332], 
reward next is -0.3316. 
=============================================
[2017-11-02 11:14:17,658] A3C_AGENT_WORKER-Thread-3 INFO:Local step 33000, global step 526851: loss -121.6852
[2017-11-02 11:14:17,903] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-42.7748642 ]
 [-41.29005051]
 [-41.68781281]
 [-41.73126984]
 [-42.09475327]], R is [[-42.62950134]
 [-42.83296967]
 [-42.41733932]
 [-42.55105972]
 [-42.88235474]].
[2017-11-02 11:14:19,103] A3C_AGENT_WORKER-Thread-8 INFO:Local step 33000, global step 527074: loss 80.0743
[2017-11-02 11:14:21,253] A3C_AGENT_WORKER-Thread-17 INFO:Local step 33000, global step 527355: loss -7.0701
[2017-11-02 11:14:22,757] A3C_AGENT_WORKER-Thread-5 INFO:Local step 33000, global step 527562: loss -77.6363
[2017-11-02 11:14:27,067] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  6.54393807e-05   4.59899381e-02   2.13591889e-01   2.51618981e-01
   3.76275212e-01   1.54499477e-03   3.84201705e-02   2.82352697e-03
   6.96697906e-02], sum to 1.0000
[2017-11-02 11:14:27,148] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 3.0, 252.5, 0.0, 0.0, -1.700000000000001, 14.56713221232979, 24.0, 21.32904516237883, 21.5, 0.0, 45.92293477690157], 
actual action is [-1.7000000000000002, 24.0], 
sim time next is 2172000.0000, 
raw observation next is [-6.700000000000001, 78.0, 3.0, 253.3333333333333, 0.0, 0.0, -1.7, 14.40648215059858, 24.0, 21.34841784215532, 21.5, 0.0, 45.74094782631899], 
processed observation next is [0.5, 0.13043478260869565, 0.16153846153846152, 0.78, 0.2727272727272727, 0.7037037037037036, 0.0, 0.0, 0.4716666666666667, 0.1440648215059858, 0.8571428571428571, 0.4783454060221887, 0.5, 0.0, 0.538128797956694], 
reward next is -0.5060. 
=============================================
[2017-11-02 11:14:30,582] A3C_AGENT_WORKER-Thread-12 INFO:Local step 33000, global step 528586: loss -1.3172
[2017-11-02 11:14:31,506] A3C_AGENT_WORKER-Thread-4 INFO:Local step 33000, global step 528673: loss 93.6985
[2017-11-02 11:14:34,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 33000, global step 529044: loss -40.4951
[2017-11-02 11:14:35,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-48.65523529]
 [-49.60780334]
 [-49.07776642]
 [-47.9052124 ]
 [-49.49046326]], R is [[-49.27331161]
 [-49.33863068]
 [-49.21385956]
 [-49.13039398]
 [-49.19465637]].
[2017-11-02 11:14:36,536] A3C_AGENT_WORKER-Thread-9 INFO:Local step 33000, global step 529330: loss 76.4537
[2017-11-02 11:14:37,149] A3C_AGENT_WORKER-Thread-13 INFO:Local step 33000, global step 529409: loss 10.6066
[2017-11-02 11:14:40,567] A3C_AGENT_WORKER-Thread-2 INFO:Local step 33000, global step 529828: loss -9.1652
[2017-11-02 11:14:42,900] A3C_AGENT_WORKER-Thread-11 INFO:Local step 33000, global step 530115: loss 0.3579
[2017-11-02 11:14:45,697] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99996901e-01   1.95847542e-06   2.03413890e-07   3.86471413e-07
   4.71280146e-07   4.97169960e-20   1.20306306e-18   9.64095754e-19
   9.12756666e-18], sum to 1.0000
[2017-11-02 11:14:45,742] A3C_AGENT_WORKER-Thread-15 INFO:Local step 33000, global step 530474: loss -25.5381
[2017-11-02 11:14:45,757] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 68.0, 7.2, 250.0, 138.5, 142.5, -8.9, 9.806035607646225, 18.0, 23.19050361299978, 22.7, 1.0, 0.0], 
actual action is [-8.9, 18], 
sim time next is 2214300.0000, 
raw observation next is [-3.899999999999999, 68.0, 7.149999999999999, 250.0, 141.5833333333333, 166.25, -8.9, 10.51161443880792, 18.0, 23.28542093968844, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.23333333333333336, 0.68, 0.6499999999999999, 0.6944444444444444, 0.3745590828924161, 0.16625, 0.3516666666666667, 0.1051161443880792, 0.0, 0.7550601342412057, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0105. 
=============================================
[2017-11-02 11:14:49,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.95678997e-01   5.80931343e-02   6.91667153e-03   1.84220597e-02
   1.76440217e-02   9.71050667e-06   3.30522365e-04   2.11533887e-04
   2.69327615e-03], sum to 1.0000
[2017-11-02 11:14:49,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-4.45, 70.75, 7.108333333333333, 261.6666666666666, 132.1666666666667, 0.0, -9.5, 13.67123306200142, 18.0, 22.30463990144864, 22.7, 1.0, 0.0], 
actual action is [-9.45, 18], 
sim time next is 2200200.0000, 
raw observation next is [-4.4, 70.5, 7.016666666666667, 263.3333333333334, 134.3333333333333, 0.0, -9.45, 14.56322879017609, 18.0, 22.28846390261349, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.2205128205128205, 0.705, 0.6378787878787878, 0.7314814814814817, 0.35537918871252194, 0.0, 0.3425, 0.14563228790176092, 0.0, 0.6126377003733557, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:14:50,984] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   8.18029615e-37   3.45657463e-37   1.20319082e-36
   3.87814377e-36   4.22183331e-03   9.81872156e-02   6.11558929e-02
   8.36435080e-01], sum to 1.0000
[2017-11-02 11:14:51,064] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.700000000000001, 78.0, 3.0, 251.6666666666667, 0.0, 0.0, -1.7, 13.31186146124496, 25.0, 21.62779670887647, 21.5, 0.0, 45.21027678015864], 
actual action is [-1.700000000000001, 25], 
sim time next is 2171700.0000, 
raw observation next is [-6.7, 78.0, 3.0, 252.5, 0.0, 0.0, -1.700000000000001, 13.28829204737482, 25.0, 21.62631654430332, 21.5, 0.0, 45.06848766816866], 
processed observation next is [0.5, 0.13043478260869565, 0.16153846153846155, 0.78, 0.2727272727272727, 0.7013888888888888, 0.0, 0.0, 0.4716666666666666, 0.1328829204737482, 1.0, 0.5180452206147602, 0.5, 0.0, 0.5302175019784547], 
reward next is -0.4772. 
=============================================
[2017-11-02 11:14:59,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  5.51614262e-28   5.26222428e-17   7.74676895e-18   7.06404567e-17
   1.84298527e-16   4.27469751e-03   1.22422747e-01   1.53904893e-02
   8.57912123e-01], sum to 1.0000
[2017-11-02 11:14:59,599] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.675, 85.0, 3.85, 245.0, 0.0, 0.0, -2.633333333333333, 13.5678264230063, 25.0, 21.54494085803055, 21.5, 0.0, 46.09771665036101], 
actual action is [-2.675, 25], 
sim time next is 2256600.0000, 
raw observation next is [-7.716666666666667, 85.33333333333334, 3.766666666666667, 243.3333333333333, 0.0, 0.0, -2.675, 13.60568332672334, 25.0, 21.52948899497262, 21.5, 0.0, 46.04435116607841], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.13547008547008546, 0.8533333333333334, 0.34242424242424246, 0.6759259259259258, 0.0, 0.0, 0.45541666666666664, 0.13605683326723342, 1.0, 0.5042127135675172, 0.5, 0.0, 0.5416982490126871], 
reward next is -0.4875. 
=============================================
[2017-11-02 11:15:08,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-44.6688652 ]
 [-44.19784546]
 [-44.09685898]
 [-44.32813263]
 [-44.56735992]], R is [[-44.2796936 ]
 [-44.8368988 ]
 [-45.38853073]
 [-44.94941711]
 [-44.51405334]].
[2017-11-02 11:15:08,332] A3C_AGENT_WORKER-Thread-10 INFO:Local step 33500, global step 533325: loss -30.4601
[2017-11-02 11:15:09,905] A3C_AGENT_WORKER-Thread-6 INFO:Local step 33500, global step 533521: loss -76.5478
[2017-11-02 11:15:14,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99998450e-01   6.02097202e-07   7.20376434e-08   3.11117617e-07
   4.68170185e-07   1.65828060e-23   3.90319717e-22   3.57140606e-22
   1.21569515e-20], sum to 1.0000
[2017-11-02 11:15:14,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.5, 6.016666666666666, 276.6666666666667, 0.0, 0.0, 0.5, 12.56974063345286, 25.0, 21.90142380173065, 22.7, 1.0, 65.81815148609884], 
actual action is [0.5, 20.0], 
sim time next is 2224500.0000, 
raw observation next is [-4.5, 68.25, 6.058333333333333, 278.3333333333333, 0.0, 0.0, 0.5, 11.84927661810737, 20.0, 22.07915543225088, 22.7, 1.0, 66.10306134247826], 
processed observation next is [0.5, 0.7391304347826086, 0.21794871794871795, 0.6825, 0.5507575757575757, 0.7731481481481481, 0.0, 0.0, 0.5083333333333333, 0.1184927661810737, 0.2857142857142857, 0.5827364903215541, 0.6714285714285714, 1.0, 0.7776830746173913], 
reward next is -0.7118. 
=============================================
[2017-11-02 11:15:14,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 33500, global step 534066: loss -113.1180
[2017-11-02 11:15:15,005] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.46577591e-21   5.21700088e-13   1.03578794e-13   4.61087657e-13
   1.68751525e-12   9.84646939e-03   7.66583905e-02   1.21420413e-01
   7.92074680e-01], sum to 1.0000
[2017-11-02 11:15:15,062] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.775, 90.0, 2.775, 252.5, 0.0, 0.0, -3.733333333333334, 15.06683020429963, 25.0, 21.09211027218772, 21.5, 0.0, 45.5851028334779], 
actual action is [-3.7750000000000004, 25], 
sim time next is 2263800.0000, 
raw observation next is [-8.816666666666666, 90.33333333333334, 2.683333333333334, 251.6666666666667, 0.0, 0.0, -3.775, 15.11779317650542, 25.0, 21.07798045838677, 21.5, 0.0, 45.51440368489014], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.10726495726495727, 0.9033333333333334, 0.243939393939394, 0.6990740740740742, 0.0, 0.0, 0.4370833333333334, 0.1511779317650542, 1.0, 0.43971149405525267, 0.5, 0.0, 0.5354635727634134], 
reward next is -0.5422. 
=============================================
[2017-11-02 11:15:18,335] A3C_AGENT_WORKER-Thread-7 INFO:Local step 33500, global step 534616: loss -99.1644
[2017-11-02 11:15:19,271] A3C_AGENT_WORKER-Thread-8 INFO:Local step 33500, global step 534750: loss -121.5492
[2017-11-02 11:15:19,272] A3C_AGENT_WORKER-Thread-3 INFO:Local step 33500, global step 534750: loss -1.3667
[2017-11-02 11:15:21,877] A3C_AGENT_WORKER-Thread-17 INFO:Local step 33500, global step 535063: loss -26.7690
[2017-11-02 11:15:25,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99879718e-01   3.87285363e-05   1.39497088e-05   2.26046395e-05
   4.49176696e-05   8.13818980e-21   6.96622922e-19   7.19262701e-19
   7.02705895e-18], sum to 1.0000
[2017-11-02 11:15:25,279] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.25, 81.41666666666666, 4.558333333333333, 260.8333333333333, 0.0, 0.0, -2.199999999999999, 16.35365956673979, 20.0, 21.16337830420619, 21.5, 0.0, 47.39586862190762], 
actual action is [-12.25, 18], 
sim time next is 2253600.0000, 
raw observation next is [-7.3, 82.0, 4.6, 260.0, 0.0, 0.0, -12.25, 18.77411458683407, 18.0, 21.18078837539126, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.14615384615384616, 0.82, 0.41818181818181815, 0.7222222222222222, 0.0, 0.0, 0.29583333333333334, 0.1877411458683407, 0.0, 0.45439833934160845, 0.5, 0.0, 0.0], 
reward next is -0.0456. 
=============================================
[2017-11-02 11:15:25,676] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-61.58578491]
 [-61.51700974]
 [-61.44451523]
 [-63.19597244]
 [-61.3844986 ]], R is [[-61.31842041]
 [-60.72665405]
 [-60.63731003]
 [-60.55662918]
 [-60.48739243]].
[2017-11-02 11:15:26,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.70510733e-01   8.09959024e-02   2.82402616e-02   3.42226364e-02
   8.60304460e-02   9.61764522e-12   1.47967794e-09   9.94622051e-10
   9.65990754e-09], sum to 1.0000
[2017-11-02 11:15:26,732] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.425, 83.0, 4.35, 255.0, 0.0, 0.0, -2.383333333333333, 19.815850357867, 25.0, 20.73357164908276, 21.5, 0.0, 41.78024802877477], 
actual action is [-2.425, 20.0], 
sim time next is 2254800.0000, 
raw observation next is [-7.466666666666667, 83.33333333333334, 4.266666666666667, 253.3333333333333, 0.0, 0.0, -2.425, 19.32340419665688, 20.0, 20.70677683094854, 21.5, 0.0, 49.83921433183559], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.14188034188034188, 0.8333333333333335, 0.3878787878787879, 0.7037037037037036, 0.0, 0.0, 0.45958333333333334, 0.19323404196656882, 0.2857142857142857, 0.3866824044212202, 0.5, 0.0, 0.5863436980215952], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:15:27,961] A3C_AGENT_WORKER-Thread-5 INFO:Local step 33500, global step 536004: loss 17.5039
[2017-11-02 11:15:28,558] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.44166131e-07   1.02065627e-04   1.19984884e-06   4.12094414e-06
   2.17442939e-05   2.82474281e-03   2.00498641e-01   2.76620328e-01
   5.19926965e-01], sum to 1.0000
[2017-11-02 11:15:28,594] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.55, 43.5, 3.05, 240.0, 138.0, 42.0, 5.641666666666667, 14.27105013347023, 19.0, 22.29577583522854, 22.7, 1.0, 59.91052512591175], 
actual action is [5.55, 24.0], 
sim time next is 2302500.0000, 
raw observation next is [0.4583333333333333, 43.58333333333333, 3.225, 240.0, 129.9166666666667, 38.5, 5.55, 13.58630752751804, 24.0, 22.36231396952862, 22.7, 1.0, 28.27399094148715], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.3450854700854701, 0.4358333333333333, 0.2931818181818182, 0.6666666666666666, 0.3436948853615521, 0.0385, 0.5924999999999999, 0.1358630752751804, 0.8571428571428571, 0.6231877099326601, 0.6714285714285714, 1.0, 0.33263518754690763], 
reward next is -0.3130. 
=============================================
[2017-11-02 11:15:32,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-45.35417175]
 [-46.00423813]
 [-45.49516296]
 [-45.50273514]
 [-45.37244034]], R is [[-45.44679642]
 [-45.72625732]
 [-46.06330109]
 [-46.22526169]
 [-45.97801208]].
[2017-11-02 11:15:33,332] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-54.21287537]
 [-53.97615051]
 [-55.15063858]
 [-53.60837173]
 [-54.15990829]], R is [[-54.79888535]
 [-55.25089645]
 [-55.69838715]
 [-56.1414032 ]
 [-56.57999039]].
[2017-11-02 11:15:33,593] A3C_AGENT_WORKER-Thread-12 INFO:Local step 33500, global step 536821: loss 15.4391
[2017-11-02 11:15:33,975] A3C_AGENT_WORKER-Thread-4 INFO:Local step 33500, global step 536870: loss 6.8334
[2017-11-02 11:15:34,141] A3C_AGENT_WORKER-Thread-14 INFO:Local step 33500, global step 536893: loss -18.1914
[2017-11-02 11:15:36,236] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99995470e-01   2.07500852e-06   4.64553835e-07   4.78175423e-07
   1.56171654e-06   3.55250453e-24   1.15349791e-22   1.55594761e-22
   6.09446016e-22], sum to 1.0000
[2017-11-02 11:15:36,267] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 56.0, 0.0, 0.0, 0.0, 0.0, -6.7, 22.1972623117565, 18.0, 21.09230785899088, 21.5, 0.0, 0.0], 
actual action is [-6.7, 18], 
sim time next is 2325900.0000, 
raw observation next is [-1.75, 56.24999999999999, 0.1666666666666667, 30.0, 0.0, 0.0, -6.7, 23.72501420868716, 18.0, 20.96609774034092, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.28846153846153844, 0.5624999999999999, 0.015151515151515155, 0.08333333333333333, 0.0, 0.0, 0.38833333333333336, 0.2372501420868716, 0.0, 0.42372824862013153, 0.5, 0.0, 0.0], 
reward next is -0.0763. 
=============================================
[2017-11-02 11:15:37,881] A3C_AGENT_WORKER-Thread-9 INFO:Local step 33500, global step 537410: loss -11.6099
[2017-11-02 11:15:39,753] A3C_AGENT_WORKER-Thread-13 INFO:Local step 33500, global step 537665: loss -9.5039
[2017-11-02 11:15:42,637] A3C_AGENT_WORKER-Thread-2 INFO:Local step 33500, global step 538074: loss -76.4845
[2017-11-02 11:15:44,977] A3C_AGENT_WORKER-Thread-11 INFO:Local step 33500, global step 538411: loss -82.5987
[2017-11-02 11:15:45,521] A3C_AGENT_WORKER-Thread-15 INFO:Local step 33500, global step 538483: loss -36.8111
[2017-11-02 11:15:48,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-73.05911255]
 [-74.56413269]
 [-73.37625885]
 [-72.98335266]
 [-73.34286499]], R is [[-72.98299408]
 [-72.88421631]
 [-72.15927124]
 [-71.93481445]
 [-71.72483063]].
[2017-11-02 11:15:52,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   4.01288241e-34   1.02981082e-35   1.97233158e-35
   5.77985108e-34   2.48494535e-03   1.38963368e-02   9.29570869e-02
   8.90661657e-01], sum to 1.0000
[2017-11-02 11:15:52,473] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 55.66666666666667, 1.5, 245.0, 0.0, 0.0, 3.3, 16.84466205889256, 23.0, 21.79342566594594, 21.5, 0.0, 48.58525672326319], 
actual action is [3.3, 25], 
sim time next is 2319300.0000, 
raw observation next is [-1.7, 55.5, 1.5, 247.5, 0.0, 0.0, 3.3, 16.08741156398257, 25.0, 21.74317083290424, 21.5, 0.0, 44.22823081445809], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.28974358974358977, 0.555, 0.13636363636363635, 0.6875, 0.0, 0.0, 0.5549999999999999, 0.1608741156398257, 1.0, 0.5347386904148915, 0.5, 0.0, 0.5203321272289186], 
reward next is -0.4683. 
=============================================
[2017-11-02 11:15:57,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99998212e-01   1.30881483e-06   4.21746229e-08   4.37717702e-08
   4.84315592e-07   3.69024861e-28   8.96496970e-27   1.20239905e-26
   8.74175226e-25], sum to 1.0000
[2017-11-02 11:15:57,212] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.133333333333334, 43.33333333333334, 5.266666666666666, 70.0, 0.0, 0.0, -9.041666666666666, 26.52310638895977, 18.0, 20.98607490772583, 21.5, 0.0, 0.0], 
actual action is [-9.133333333333333, 18], 
sim time next is 2411100.0000, 
raw observation next is [-4.225, 43.5, 5.225, 70.0, 0.0, 0.0, -9.133333333333333, 28.23940535695683, 18.0, 20.76122131564021, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.225, 0.435, 0.475, 0.19444444444444445, 0.0, 0.0, 0.3477777777777778, 0.2823940535695683, 0.0, 0.39446018794860144, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:01,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.04687215e-04   7.95147102e-03   3.65405213e-05   1.48354666e-04
   1.41150737e-03   1.90101448e-03   5.02180494e-02   1.97178870e-01
   7.40249515e-01], sum to 1.0000
[2017-11-02 11:16:01,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.15, 47.58333333333333, 6.1, 51.66666666666666, 216.5833333333333, 374.8333333333333, -6.2, 20.10189031090241, 18.0, 21.68607307161016, 22.7, 1.0, 0.0], 
actual action is [3.85, 20.0], 
sim time next is 2376600.0000, 
raw observation next is [-1.1, 48.16666666666667, 6.1, 53.33333333333334, 223.6666666666667, 384.6666666666666, 3.85, 17.33924885372593, 20.0, 21.57188122951064, 22.7, 1.0, 79.7099369075688], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.30512820512820515, 0.4816666666666667, 0.5545454545454546, 0.14814814814814817, 0.5917107583774252, 0.38466666666666655, 0.5641666666666667, 0.1733924885372593, 0.2857142857142857, 0.5102687470729487, 0.6714285714285714, 1.0, 0.9377639636184565], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:01,515] A3C_AGENT_WORKER-Thread-10 INFO:Local step 34000, global step 540788: loss -84.1171
[2017-11-02 11:16:01,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99975920e-01   1.20769446e-05   1.94717109e-06   2.47508888e-06
   7.63778280e-06   3.54813650e-27   2.39901599e-25   1.51609082e-25
   9.30360464e-24], sum to 1.0000
[2017-11-02 11:16:01,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 55.83333333333333, 0.1250000000000001, 22.50000000000001, 0.0, 0.0, -6.7, 20.20411598273667, 18.0, 21.38852247859424, 21.5, 0.0, 0.0], 
actual action is [-6.7, 18], 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 0.0, 0.0, -6.7, 21.8811307016955, 18.0, 21.25023310383886, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.28974358974358977, 0.56, 0.0, 0.0, 0.0, 0.0, 0.38833333333333336, 0.218811307016955, 0.0, 0.4643190148341227, 0.5, 0.0, 0.0], 
reward next is -0.0357. 
=============================================
[2017-11-02 11:16:05,086] A3C_AGENT_WORKER-Thread-6 INFO:Local step 34000, global step 541324: loss -22.9086
[2017-11-02 11:16:08,689] A3C_AGENT_WORKER-Thread-16 INFO:Local step 34000, global step 541871: loss 19.7120
[2017-11-02 11:16:10,561] A3C_AGENT_WORKER-Thread-8 INFO:Local step 34000, global step 542114: loss 0.2239
[2017-11-02 11:16:13,992] A3C_AGENT_WORKER-Thread-3 INFO:Local step 34000, global step 542551: loss 13.5106
[2017-11-02 11:16:14,109] A3C_AGENT_WORKER-Thread-7 INFO:Local step 34000, global step 542564: loss 12.4586
[2017-11-02 11:16:18,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 34000, global step 543046: loss 4.8101
[2017-11-02 11:16:21,111] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-70.28113556]
 [-72.90218353]
 [-71.90699768]
 [-73.14645386]
 [-73.90107727]], R is [[-71.84207153]
 [-72.1236496 ]
 [-72.40241241]
 [-72.6783905 ]
 [-72.95160675]].
[2017-11-02 11:16:26,194] A3C_AGENT_WORKER-Thread-5 INFO:Local step 34000, global step 544090: loss 25.5211
[2017-11-02 11:16:32,112] A3C_AGENT_WORKER-Thread-12 INFO:Local step 34000, global step 545104: loss -50.7881
[2017-11-02 11:16:32,134] A3C_AGENT_WORKER-Thread-4 INFO:Local step 34000, global step 545106: loss -16.6439
[2017-11-02 11:16:32,294] A3C_AGENT_WORKER-Thread-14 INFO:Local step 34000, global step 545135: loss -6.4753
[2017-11-02 11:16:33,521] A3C_AGENT_WORKER-Thread-9 INFO:Local step 34000, global step 545311: loss -39.4612
[2017-11-02 11:16:33,679] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-70.60302734]
 [-69.98405457]
 [-71.01931   ]
 [-70.93572998]
 [-70.09384155]], R is [[-70.68405151]
 [-69.99146271]
 [-69.99996185]
 [-69.85289001]
 [-69.54738617]].
[2017-11-02 11:16:35,950] A3C_AGENT_WORKER-Thread-13 INFO:Local step 34000, global step 545731: loss 8.9888
[2017-11-02 11:16:36,362] A3C_AGENT_WORKER-Thread-2 INFO:Local step 34000, global step 545800: loss -24.1884
[2017-11-02 11:16:38,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-79.50973511]
 [-80.67836761]
 [-80.10007477]
 [-77.88137817]
 [-79.98265839]], R is [[-77.98591614]
 [-78.20605469]
 [-78.42399597]
 [-78.63975525]
 [-78.85335541]].
[2017-11-02 11:16:41,152] A3C_AGENT_WORKER-Thread-11 INFO:Local step 34000, global step 546621: loss 133.2520
[2017-11-02 11:16:41,161] A3C_AGENT_WORKER-Thread-15 INFO:Local step 34000, global step 546623: loss -46.9446
[2017-11-02 11:16:42,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   5.35712630e-25   4.68916987e-27   1.75525958e-26
   1.03482142e-24   1.23704367e-05   6.33514894e-04   8.55795108e-03
   9.90796089e-01], sum to 1.0000
[2017-11-02 11:16:42,184] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.425, 53.5, 4.35, 80.0, 0.0, 0.0, -12.38333333333333, 27.46402715820573, 18.0, 20.47572873202412, 21.5, 0.0, 0.0], 
actual action is [-2.425, 23.0], 
sim time next is 2427600.0000, 
raw observation next is [-7.466666666666667, 53.66666666666667, 4.433333333333334, 80.0, 0.0, 0.0, -2.425, 26.46587003397979, 23.0, 20.34464749143876, 21.5, 0.0, 56.08121668064394], 
processed observation next is [1.0, 0.08695652173913043, 0.14188034188034188, 0.5366666666666667, 0.40303030303030307, 0.2222222222222222, 0.0, 0.0, 0.45958333333333334, 0.2646587003397979, 0.7142857142857143, 0.33494964163410856, 0.5, 0.0, 0.6597790197722817], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:51,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.96120834e-01   5.06741814e-02   3.65631531e-05   1.45717568e-04
   3.87621787e-03   1.17248655e-05   6.17928337e-04   1.03467386e-02
   3.38170052e-01], sum to 1.0000
[2017-11-02 11:16:51,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 34500, global step 548096: loss -98.5244
[2017-11-02 11:16:51,988] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.025, 32.25, 4.6, 65.0, 87.0, 833.0, -6.166666666666667, 15.69851988868507, 18.0, 22.24812386133678, 22.7, 1.0, 0.0], 
actual action is [-6.025, 18], 
sim time next is 2461800.0000, 
raw observation next is [-0.8833333333333332, 31.83333333333334, 4.6, 63.33333333333333, 87.33333333333334, 834.3333333333334, -6.025, 17.00689198682602, 18.0, 22.26156686121228, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3106837606837607, 0.3183333333333334, 0.41818181818181815, 0.1759259259259259, 0.23104056437389772, 0.8343333333333334, 0.39958333333333335, 0.1700689198682602, 0.0, 0.6087952658874686, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:55,892] A3C_AGENT_WORKER-Thread-6 INFO:Local step 34500, global step 548750: loss 11.6265
[2017-11-02 11:16:58,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 34500, global step 549204: loss 0.6443
[2017-11-02 11:17:00,613] A3C_AGENT_WORKER-Thread-8 INFO:Local step 34500, global step 549637: loss 13.6353
[2017-11-02 11:17:04,385] A3C_AGENT_WORKER-Thread-7 INFO:Local step 34500, global step 550417: loss -23.1790
[2017-11-02 11:17:04,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 34500, global step 550445: loss -13.7993
[2017-11-02 11:17:07,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   2.46646486e-32   3.06264092e-32   8.20606259e-32
   5.83766511e-33   2.34619225e-03   1.03263627e-03   1.03584886e-01
   8.93036306e-01], sum to 1.0000
[2017-11-02 11:17:08,135] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 54.0, 2.458333333333333, 39.16666666666666, 0.0, 0.0, 2.2, 23.24554789192361, 23.0, 20.18497056116225, 22.7, 1.0, 104.1418102152653], 
actual action is [2.2, 25], 
sim time next is 2531400.0000, 
raw observation next is [-2.8, 54.0, 2.416666666666667, 38.33333333333334, 0.0, 0.0, 2.2, 20.89587136148423, 25.0, 20.26092015724389, 22.7, 1.0, 76.5296685818242], 
processed observation next is [0.0, 0.30434782608695654, 0.2615384615384615, 0.54, 0.21969696969696972, 0.10648148148148151, 0.0, 0.0, 0.5366666666666667, 0.20895871361484228, 1.0, 0.3229885938919845, 0.6714285714285714, 1.0, 0.9003490421391082], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:09,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 34500, global step 551141: loss 23.9571
[2017-11-02 11:17:10,803] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.73956676e-06   2.63072993e-03   3.67981778e-03   3.83728044e-03
   4.85271798e-04   5.24543750e-04   1.20974053e-03   1.38942702e-02
   9.73736584e-01], sum to 1.0000
[2017-11-02 11:17:10,938] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.708333333333333, 64.5, 3.891666666666666, 270.0, 0.0, 0.0, -9.666666666666668, 24.51121733602368, 18.0, 20.83823440433104, 21.5, 0.0, 0.0], 
actual action is [0.29166666666666696, 23.0], 
sim time next is 2593800.0000, 
raw observation next is [-4.75, 65.0, 3.85, 270.0, 0.0, 0.0, 0.291666666666667, 21.10688518107541, 23.0, 20.63733026857078, 21.5, 0.0, 87.32567179423378], 
processed observation next is [0.16666666666666666, 0.0, 0.21153846153846154, 0.65, 0.35000000000000003, 0.75, 0.0, 0.0, 0.5048611111111111, 0.21106885181075408, 0.7142857142857143, 0.3767614669386826, 0.5, 0.0, 1.0273608446380444], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:16,866] A3C_AGENT_WORKER-Thread-5 INFO:Local step 34500, global step 552309: loss -58.9500
[2017-11-02 11:17:17,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99995589e-01   3.00496436e-06   4.32364828e-07   7.96989866e-07
   9.96880303e-08   7.32187191e-17   4.99445400e-17   7.66737824e-16
   5.80353984e-15], sum to 1.0000
[2017-11-02 11:17:17,797] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.233333333333333, 58.66666666666666, 8.283333333333333, 235.8333333333333, 218.0, 179.6666666666667, 1.633333333333333, 14.68548130824203, 25.0, 22.13918765301202, 22.7, 1.0, 48.81861831106453], 
actual action is [1.766666666666667, 20.0], 
sim time next is 2633400.0000, 
raw observation next is [-3.1, 58.0, 8.2, 235.0, 224.0, 171.0, 1.766666666666667, 13.40696590150689, 20.0, 22.23836128787744, 22.7, 1.0, 45.20553766876398], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.25384615384615383, 0.58, 0.7454545454545454, 0.6527777777777778, 0.5925925925925926, 0.171, 0.5294444444444444, 0.1340696590150689, 0.2857142857142857, 0.6054801839824913, 0.6714285714285714, 1.0, 0.531829854926635], 
reward next is -0.4921. 
=============================================
[2017-11-02 11:17:20,305] A3C_AGENT_WORKER-Thread-4 INFO:Local step 34500, global step 552974: loss 141.6868
[2017-11-02 11:17:21,497] A3C_AGENT_WORKER-Thread-12 INFO:Local step 34500, global step 553156: loss -43.1868
[2017-11-02 11:17:21,842] A3C_AGENT_WORKER-Thread-14 INFO:Local step 34500, global step 553201: loss 10.7330
[2017-11-02 11:17:22,254] A3C_AGENT_WORKER-Thread-9 INFO:Local step 34500, global step 553258: loss 9.9034
[2017-11-02 11:17:25,713] A3C_AGENT_WORKER-Thread-13 INFO:Local step 34500, global step 553809: loss 19.5704
[2017-11-02 11:17:25,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-109.00382996]
 [-112.72373962]
 [-106.69056702]
 [-113.29626465]
 [-111.8473053 ]], R is [[-110.18507385]
 [-110.08322144]
 [-109.98239136]
 [-109.88256836]
 [-109.78374481]].
[2017-11-02 11:17:27,465] A3C_AGENT_WORKER-Thread-2 INFO:Local step 34500, global step 554112: loss -74.1897
[2017-11-02 11:17:31,636] A3C_AGENT_WORKER-Thread-15 INFO:Local step 34500, global step 554854: loss 142.7859
[2017-11-02 11:17:33,621] A3C_AGENT_WORKER-Thread-11 INFO:Local step 34500, global step 555170: loss -26.9842
[2017-11-02 11:17:35,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   3.14596009e-35   1.44476705e-34   5.50969998e-34
   4.31790184e-35   1.30730559e-05   1.69023097e-05   1.51778746e-03
   9.98452187e-01], sum to 1.0000
[2017-11-02 11:17:35,710] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 62.0, 7.999999999999999, 240.0, 0.0, 0.0, -6.2, 16.50292173104057, 18.0, 22.34058282130578, 22.7, 1.0, 0.0], 
actual action is [3.8, 23.0], 
sim time next is 2663100.0000, 
raw observation next is [-1.2, 62.25, 8.174999999999999, 240.0, 0.0, 0.0, 3.8, 14.79787300271493, 23.0, 22.13269957719751, 22.7, 1.0, 80.58893076072609], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3025641025641026, 0.6225, 0.743181818181818, 0.6666666666666666, 0.0, 0.0, 0.5633333333333332, 0.14797873002714929, 0.7142857142857143, 0.5903856538853586, 0.6714285714285714, 1.0, 0.9481050677732481], 
reward next is -0.8681. 
=============================================
[2017-11-02 11:17:35,822] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99987245e-01   1.29213220e-06   4.62370372e-06   6.28484941e-06
   5.28770897e-07   3.87818098e-19   1.87404365e-18   6.29563591e-17
   5.95889237e-14], sum to 1.0000
[2017-11-02 11:17:36,210] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 1.5, 60.0, 0.0, 0.0, -10.08333333333333, 27.6714039839788, 25.0, 19.44902091807529, 21.5, 0.0, 45.88960262901475], 
actual action is [-10.0, 20.0], 
sim time next is 2703900.0000, 
raw observation next is [-15.0, 83.0, 1.55, 68.33333333333333, 0.0, 0.0, -10.0, 27.21144784734129, 20.0, 19.43181750449951, 22.7, 1.0, 73.91983482520617], 
processed observation next is [0.3333333333333333, 0.30434782608695654, -0.05128205128205128, 0.83, 0.1409090909090909, 0.1898148148148148, 0.0, 0.0, 0.3333333333333333, 0.2721144784734129, 0.2857142857142857, 0.2045453577856442, 0.6714285714285714, 1.0, 0.8696451155906608], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:44,648] A3C_AGENT_WORKER-Thread-10 INFO:Local step 35000, global step 556517: loss 1.3237
[2017-11-02 11:17:47,110] A3C_AGENT_WORKER-Thread-6 INFO:Local step 35000, global step 556888: loss -39.4309
[2017-11-02 11:17:48,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99817789e-01   7.58617034e-06   2.31159684e-05   6.01305073e-05
   2.91563924e-06   1.35672599e-06   1.96171996e-07   7.85734883e-05
   8.38227425e-06], sum to 1.0000
[2017-11-02 11:17:48,481] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.708333333333334, 69.16666666666667, 7.2, 228.3333333333333, 97.91666666666667, 106.3333333333333, -10.85, 14.4269624125592, 18.0, 22.87396366517746, 22.7, 1.0, 0.0], 
actual action is [-10.708333333333334, 18], 
sim time next is 2626800.0000, 
raw observation next is [-5.566666666666666, 68.33333333333333, 7.2, 226.6666666666667, 102.8333333333333, 121.6666666666667, -10.70833333333333, 15.96880520408269, 18.0, 22.65390754655226, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.19059829059829062, 0.6833333333333332, 0.6545454545454545, 0.6296296296296298, 0.27204585537918863, 0.1216666666666667, 0.32152777777777786, 0.1596880520408269, 0.0, 0.6648439352217517, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:49,521] A3C_AGENT_WORKER-Thread-16 INFO:Local step 35000, global step 557276: loss -27.1257
[2017-11-02 11:17:55,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   7.29920180e-10   8.79807172e-10   1.04696729e-09
   8.89149310e-11   2.04692129e-27   5.86468702e-27   3.56230332e-25
   8.11249468e-25], sum to 1.0000
[2017-11-02 11:17:55,750] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 8.174999999999999, 225.0, 95.0, 144.5, -4.5, 14.25515216896056, 18.0, 22.84897683057725, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 2650800.0000, 
raw observation next is [0.5, 50.0, 8.0, 226.6666666666667, 88.33333333333333, 137.6666666666667, -4.5, 14.64377743582213, 18.0, 22.69859262709048, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.34615384615384615, 0.5, 0.7272727272727273, 0.6296296296296298, 0.23368606701940034, 0.13766666666666671, 0.425, 0.1464377743582213, 0.0, 0.671227518155783, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:17:56,510] A3C_AGENT_WORKER-Thread-8 INFO:Local step 35000, global step 558245: loss 75.2227
[2017-11-02 11:17:59,975] A3C_AGENT_WORKER-Thread-7 INFO:Local step 35000, global step 558772: loss 34.2218
[2017-11-02 11:18:01,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 35000, global step 559006: loss -35.2985
[2017-11-02 11:18:02,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999881e-01   8.55733351e-09   8.31404492e-08   3.38965940e-08
   6.62511823e-09   1.56950257e-32   4.84724500e-31   1.70725339e-29
   6.51545374e-28], sum to 1.0000
[2017-11-02 11:18:02,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.366666666666666, 69.0, 6.766666666666667, 266.6666666666667, 0.0, 0.0, -9.208333333333334, 20.37147647866438, 18.0, 20.91221337158052, 21.5, 0.0, 0.0], 
actual action is [-9.366666666666667, 18], 
sim time next is 2673900.0000, 
raw observation next is [-4.525, 69.0, 6.7, 267.5, 0.0, 0.0, -9.366666666666667, 22.52274267744745, 18.0, 20.95393842025853, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.21730769230769229, 0.69, 0.6090909090909091, 0.7430555555555556, 0.0, 0.0, 0.34388888888888886, 0.2252274267744745, 0.0, 0.4219912028940759, 0.5, 0.0, 0.0], 
reward next is -0.0780. 
=============================================
[2017-11-02 11:18:04,911] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99380708e-01   2.81565299e-05   2.96403625e-04   2.60269386e-04
   3.07507398e-05   4.67987142e-11   1.72477232e-09   6.19709226e-07
   3.11846156e-06], sum to 1.0000
[2017-11-02 11:18:04,967] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.5, 61.5, 1.5, 60.0, 0.0, 0.0, -0.4166666666666661, 18.5997894549416, 25.0, 20.90782002486354, 21.5, 0.0, 49.72067686789039], 
actual action is [-0.5, 20.0], 
sim time next is 2752500.0000, 
raw observation next is [-5.583333333333333, 61.91666666666667, 1.5, 60.0, 0.0, 0.0, -0.5, 17.65308096198769, 20.0, 21.05203572567817, 21.5, 0.0, 47.23772451093294], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.1901709401709402, 0.6191666666666668, 0.13636363636363635, 0.16666666666666666, 0.0, 0.0, 0.49166666666666664, 0.1765308096198769, 0.2857142857142857, 0.43600510366831, 0.5, 0.0, 0.5557379354227405], 
reward next is -0.5642. 
=============================================
[2017-11-02 11:18:05,080] A3C_AGENT_WORKER-Thread-17 INFO:Local step 35000, global step 559617: loss -86.6719
[2017-11-02 11:18:08,505] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  8.09515419e-14   2.99659908e-10   3.90125843e-09   1.76316362e-09
   3.26550842e-10   6.05190326e-05   1.54460105e-03   1.80845678e-01
   8.17549169e-01], sum to 1.0000
[2017-11-02 11:18:08,599] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.5, 61.5, 2.85, 60.0, 0.0, 0.0, -1.416666666666666, 20.94554600333245, 20.0, 20.63733086026711, 21.5, 0.0, 41.87367806770916], 
actual action is [-1.5, 22.0], 
sim time next is 2781300.0000, 
raw observation next is [-6.583333333333334, 61.91666666666667, 2.891666666666667, 60.0, 0.0, 0.0, -1.5, 20.93493168910573, 22.0, 20.652282517368, 21.5, 0.0, 39.40940454522079], 
processed observation next is [0.5, 0.17391304347826086, 0.16452991452991453, 0.6191666666666668, 0.26287878787878793, 0.16666666666666666, 0.0, 0.0, 0.475, 0.20934931689105732, 0.5714285714285714, 0.3788975024811429, 0.5, 0.0, 0.46364005347318576], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:15,263] A3C_AGENT_WORKER-Thread-4 INFO:Local step 35000, global step 560918: loss -48.0029
[2017-11-02 11:18:15,381] A3C_AGENT_WORKER-Thread-5 INFO:Local step 35000, global step 560930: loss 34.2036
[2017-11-02 11:18:19,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 35000, global step 561538: loss 10.6904
[2017-11-02 11:18:20,005] A3C_AGENT_WORKER-Thread-12 INFO:Local step 35000, global step 561575: loss -87.6859
[2017-11-02 11:18:20,782] A3C_AGENT_WORKER-Thread-14 INFO:Local step 35000, global step 561673: loss -4.0787
[2017-11-02 11:18:23,302] A3C_AGENT_WORKER-Thread-13 INFO:Local step 35000, global step 561999: loss -71.6008
[2017-11-02 11:18:26,600] A3C_AGENT_WORKER-Thread-2 INFO:Local step 35000, global step 562543: loss -30.6885
[2017-11-02 11:18:27,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-52.93047333]
 [-53.09712219]
 [-52.94266891]
 [-52.2115593 ]
 [-53.17524338]], R is [[-53.81832504]
 [-54.28014374]
 [-54.73734283]
 [-55.18996811]
 [-55.63806915]].
[2017-11-02 11:18:27,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   3.20645836e-11   2.20597762e-10   1.96827415e-10
   1.59022101e-11   1.62489650e-28   8.86465651e-29   1.32716480e-26
   5.54258564e-27], sum to 1.0000
[2017-11-02 11:18:27,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 59.0, 1.5, 40.0, 0.0, 0.0, 0.0, 20.00992439188169, 25.0, 20.69245220825187, 22.7, 1.0, 83.52229632122788], 
actual action is [0.0, 20.0], 
sim time next is 2748300.0000, 
raw observation next is [-5.0, 59.0, 1.5, 42.5, 0.0, 0.0, 0.0, 19.45859834967811, 20.0, 20.81583366747455, 22.7, 1.0, 63.26371506241276], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.20512820512820512, 0.59, 0.13636363636363635, 0.11805555555555555, 0.0, 0.0, 0.5, 0.19458598349678108, 0.2857142857142857, 0.40226195249636426, 0.6714285714285714, 1.0, 0.7442790007342678], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:28,029] A3C_AGENT_WORKER-Thread-15 INFO:Local step 35000, global step 562760: loss 22.6006
[2017-11-02 11:18:29,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.03444805e-10   3.00005931e-09   7.97366229e-10
   2.90466262e-10   2.39251705e-28   1.91366141e-28   5.70334417e-26
   2.05693355e-26], sum to 1.0000
[2017-11-02 11:18:29,564] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 88.33333333333334, 4.600000000000001, 130.0, 0.0, 0.0, -4.0, 23.98262664249792, 18.0, 20.6235117376203, 21.5, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 2863500.0000, 
raw observation next is [1.0, 88.91666666666666, 4.475, 130.0, 0.0, 0.0, -4.0, 26.10713771749109, 18.0, 20.56878146068549, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.358974358974359, 0.8891666666666665, 0.4068181818181818, 0.3611111111111111, 0.0, 0.0, 0.43333333333333335, 0.2610713771749109, 0.0, 0.36696878009792705, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:29,725] A3C_AGENT_WORKER-Thread-11 INFO:Local step 35000, global step 563023: loss -90.2604
[2017-11-02 11:18:30,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   8.22632587e-12   9.61872335e-12   5.51245421e-12
   1.79740391e-12   2.05909615e-30   1.19477227e-30   1.47012360e-28
   1.05685993e-29], sum to 1.0000
[2017-11-02 11:18:30,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 55.66666666666667, 1.5, 36.66666666666667, 104.3333333333333, 751.3333333333334, -9.733333333333334, 14.26000030718883, 18.0, 22.38925063646795, 22.7, 1.0, 0.0], 
actual action is [-9.666666666666668, 18], 
sim time next is 2729700.0000, 
raw observation next is [-4.6, 55.5, 1.5, 35.0, 103.75, 746.75, -9.666666666666668, 14.6042559069148, 18.0, 22.46589271664525, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.2153846153846154, 0.555, 0.13636363636363635, 0.09722222222222222, 0.2744708994708995, 0.74675, 0.33888888888888885, 0.14604255906914798, 0.0, 0.6379846738064643, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:18:32,760] A3C_AGENT_WORKER-Thread-10 INFO:Local step 35500, global step 563528: loss -153.4928
[2017-11-02 11:18:34,250] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-81.55034637]
 [-77.36566925]
 [-78.87939453]
 [-77.33055115]
 [-77.95808411]], R is [[-77.36257172]
 [-77.58894348]
 [-77.81305695]
 [-78.03492737]
 [-78.25457764]].
[2017-11-02 11:18:39,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   8.68446901e-02   9.57872771e-07   9.13154006e-01
   3.66463723e-07], sum to 1.0000
[2017-11-02 11:18:39,673] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.583333333333333, 64.0, 1.85, 50.0, 0.0, 0.0, -1.666666666666667, 20.46264697256441, 25.0, 20.66267439253393, 22.7, 1.0, 79.50826485823913], 
actual action is [-1.583333333333333, 25], 
sim time next is 2791800.0000, 
raw observation next is [-6.5, 64.0, 1.8, 50.0, 0.0, 0.0, -1.583333333333333, 20.345814123751, 25.0, 20.72930771430421, 22.7, 1.0, 79.45683945897814], 
processed observation next is [0.5, 0.30434782608695654, 0.16666666666666666, 0.64, 0.16363636363636364, 0.1388888888888889, 0.0, 0.0, 0.47361111111111115, 0.20345814123751002, 1.0, 0.38990110204345846, 0.6714285714285714, 1.0, 0.9347863465762134], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:39,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  4.60478463e-24   1.40753169e-19   4.02955710e-19   5.34188121e-19
   1.87397522e-19   3.70644666e-02   5.70019416e-04   9.59880829e-01
   2.48468062e-03], sum to 1.0000
[2017-11-02 11:18:40,027] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.5, 61.5, 1.5, 60.0, 0.0, 0.0, -0.4166666666666661, 11.15511845472745, 25.0, 22.90456439556811, 21.5, 0.0, 43.42389741371376], 
actual action is [-0.5, 25], 
sim time next is 2752500.0000, 
raw observation next is [-5.583333333333333, 61.91666666666667, 1.5, 60.0, 0.0, 0.0, -0.5, 11.05902267139329, 25.0, 22.9260941679229, 21.5, 0.0, 43.29402899396401], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.1901709401709402, 0.6191666666666668, 0.13636363636363635, 0.16666666666666666, 0.0, 0.0, 0.49166666666666664, 0.1105902267139329, 1.0, 0.7037277382747001, 0.5, 0.0, 0.5093415175760472], 
reward next is -0.4584. 
=============================================
[2017-11-02 11:18:40,818] A3C_AGENT_WORKER-Thread-16 INFO:Local step 35500, global step 564564: loss 3.1624
[2017-11-02 11:18:42,237] A3C_AGENT_WORKER-Thread-6 INFO:Local step 35500, global step 564748: loss 0.2845
[2017-11-02 11:18:48,110] A3C_AGENT_WORKER-Thread-8 INFO:Local step 35500, global step 565466: loss -2.2984
[2017-11-02 11:18:50,866] A3C_AGENT_WORKER-Thread-7 INFO:Local step 35500, global step 565917: loss 1.2345
[2017-11-02 11:18:51,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99999881e-01   2.39791369e-08   4.56295588e-08   4.54613769e-08
   6.32481978e-09   1.25288099e-13   1.13649087e-14   1.88297316e-12
   2.22989961e-14], sum to 1.0000
[2017-11-02 11:18:51,568] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 64.0, 2.6, 60.0, 0.0, 0.0, -2.0, 18.62938886405003, 25.0, 20.50320017788596, 21.5, 0.0, 48.73535119762848], 
actual action is [-2.0, 20.0], 
sim time next is 2786700.0000, 
raw observation next is [-6.999999999999999, 64.0, 2.558333333333333, 59.16666666666666, 0.0, 0.0, -2.0, 18.16057027202494, 20.0, 20.5463963650359, 21.5, 0.0, 47.14367529497393], 
processed observation next is [0.5, 0.2608695652173913, 0.15384615384615388, 0.64, 0.23257575757575755, 0.16435185185185183, 0.0, 0.0, 0.4666666666666667, 0.18160570272024942, 0.2857142857142857, 0.3637709092908428, 0.5, 0.0, 0.5546314740585169], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:54,499] A3C_AGENT_WORKER-Thread-3 INFO:Local step 35500, global step 566717: loss -38.6548
[2017-11-02 11:18:57,529] A3C_AGENT_WORKER-Thread-17 INFO:Local step 35500, global step 567343: loss 34.3052
[2017-11-02 11:19:00,155] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-84.50228119]
 [-86.87058258]
 [-85.88316345]
 [-85.97992706]
 [-85.1604538 ]], R is [[-85.44127655]
 [-85.58686829]
 [-85.73100281]
 [-85.87369537]
 [-86.01496124]].
[2017-11-02 11:19:03,403] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-76.14930725]
 [-77.17481995]
 [-75.86294556]
 [-76.25743866]
 [-75.83498383]], R is [[-76.80397797]
 [-77.03594208]
 [-77.26558685]
 [-77.49293518]
 [-77.71800995]].
[2017-11-02 11:19:04,604] A3C_AGENT_WORKER-Thread-4 INFO:Local step 35500, global step 568777: loss -19.6478
[2017-11-02 11:19:04,701] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.93836462e-01   1.07205269e-04   5.39208297e-04   4.32605419e-04
   1.52081397e-04   7.86850433e-06   2.25436429e-06   4.87623271e-03
   4.61084128e-05], sum to 1.0000
[2017-11-02 11:19:04,783] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 4.6, 280.0, 0.0, 0.0, 2.083333333333333, 17.18291825226923, 24.0, 20.83095600604828, 21.5, 0.0, 42.3787868659], 
actual action is [2.0, 19.0], 
sim time next is 2948700.0000, 
raw observation next is [-3.0, 84.0, 4.774999999999999, 279.9999999999999, 0.0, 0.0, 2.0, 16.77668537333068, 19.0, 20.88885871070845, 21.5, 0.0, 46.17372477716513], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.43409090909090897, 0.7777777777777775, 0.0, 0.0, 0.5333333333333333, 0.1677668537333068, 0.14285714285714285, 0.41269410152977876, 0.5, 0.0, 0.5432202914960603], 
reward next is -0.5762. 
=============================================
[2017-11-02 11:19:05,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.47329683e-03   2.11012066e-05   9.97372985e-01
   1.32673653e-04], sum to 1.0000
[2017-11-02 11:19:05,611] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.0, 72.0, 5.966666666666667, 130.0, 0.0, 0.0, 6.0, 22.36804917423812, 19.0, 20.50921898690705, 21.5, 0.0, 41.46521106251065], 
actual action is [6.0, 21.0], 
sim time next is 2852700.0000, 
raw observation next is [1.0, 72.0, 6.183333333333333, 130.0, 0.0, 0.0, 6.0, 21.96913634685836, 21.0, 20.62719418006138, 21.5, 0.0, 28.1424847983927], 
processed observation next is [0.6666666666666666, 0.0, 0.358974358974359, 0.72, 0.562121212121212, 0.3611111111111111, 0.0, 0.0, 0.6, 0.2196913634685836, 0.42857142857142855, 0.3753134542944829, 0.5, 0.0, 0.3310880564516788], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:06,366] A3C_AGENT_WORKER-Thread-5 INFO:Local step 35500, global step 569058: loss -12.8993
[2017-11-02 11:19:06,831] A3C_AGENT_WORKER-Thread-12 INFO:Local step 35500, global step 569139: loss -0.8859
[2017-11-02 11:19:08,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.78632626e-07   5.20081356e-09   2.20181953e-08   2.59010573e-08
   8.12727929e-09   1.91130228e-02   1.87955296e-03   9.58479285e-01
   2.05278192e-02], sum to 1.0000
[2017-11-02 11:19:08,129] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 83.25, 6.95, 260.0, 0.0, 0.0, 4.0, 17.62455595864911, 20.0, 21.05488931023094, 21.5, 0.0, 39.32533711542531], 
actual action is [4.0, 22.0], 
sim time next is 2926200.0000, 
raw observation next is [-1.0, 83.83333333333334, 6.866666666666667, 260.0, 0.0, 0.0, 4.0, 17.53270692925367, 22.0, 21.03821293721098, 21.5, 0.0, 25.18828378988293], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.3076923076923077, 0.8383333333333334, 0.6242424242424243, 0.7222222222222222, 0.0, 0.0, 0.5666666666666667, 0.17532706929253672, 0.5714285714285714, 0.4340304196015684, 0.5, 0.0, 0.2963327504692109], 
reward next is -0.3327. 
=============================================
[2017-11-02 11:19:08,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.48954930e-30   1.41283351e-24   8.52724008e-24   1.67404236e-23
   3.68434725e-24   1.46560436e-02   4.93004452e-04   9.78623271e-01
   6.22776709e-03], sum to 1.0000
[2017-11-02 11:19:08,284] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 77.0, 4.475, 280.0, 0.0, 0.0, 1.0, 22.3920384695837, 25.0, 19.85295212010463, 21.5, 0.0, 60.44392572536487], 
actual action is [1.0, 25], 
sim time next is 2964000.0000, 
raw observation next is [-4.0, 77.0, 4.433333333333334, 280.0, 0.0, 0.0, 1.0, 22.01915976834376, 25.0, 19.88939456813947, 21.5, 0.0, 60.99443006522367], 
processed observation next is [0.8333333333333334, 0.30434782608695654, 0.23076923076923078, 0.77, 0.40303030303030307, 0.7777777777777778, 0.0, 0.0, 0.5166666666666667, 0.22019159768343757, 1.0, 0.26991350973420986, 0.5, 0.0, 0.717581530179102], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:08,997] A3C_AGENT_WORKER-Thread-14 INFO:Local step 35500, global step 569529: loss -27.9888
[2017-11-02 11:19:09,284] A3C_AGENT_WORKER-Thread-9 INFO:Local step 35500, global step 569578: loss -41.0580
[2017-11-02 11:19:12,326] A3C_AGENT_WORKER-Thread-13 INFO:Local step 35500, global step 570108: loss -414.1638
[2017-11-02 11:19:13,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99980927e-01   4.94083815e-06   5.34558149e-06   5.79195830e-06
   2.09259315e-06   3.06047898e-09   6.18724494e-09   8.48120010e-07
   4.63755399e-08], sum to 1.0000
[2017-11-02 11:19:13,088] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.583333333333333, 100.0, 2.308333333333334, 161.6666666666667, 174.0833333333333, 0.0, -3.5, 15.50901721369641, 18.0, 21.75035537905363, 22.7, 1.0, 0.0], 
actual action is [-3.416666666666667, 18], 
sim time next is 2896800.0000, 
raw observation next is [1.666666666666667, 100.0, 2.266666666666667, 163.3333333333333, 173.1666666666667, 0.0, -3.416666666666667, 16.02166256360356, 18.0, 21.72367544816491, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.3760683760683761, 1.0, 0.20606060606060608, 0.45370370370370355, 0.45811287477954155, 0.0, 0.44305555555555554, 0.1602166256360356, 0.0, 0.5319536354521303, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:15,729] A3C_AGENT_WORKER-Thread-2 INFO:Local step 35500, global step 570772: loss 10.4175
[2017-11-02 11:19:17,017] A3C_AGENT_WORKER-Thread-15 INFO:Local step 35500, global step 571011: loss 2.1166
[2017-11-02 11:19:17,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   4.09959400e-09   7.40033368e-09   6.36859365e-09
   1.98061989e-09   4.69966122e-20   4.11867897e-20   2.36636207e-17
   6.80318365e-19], sum to 1.0000
[2017-11-02 11:19:17,973] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 3.141666666666667, 220.8333333333333, 93.5, 716.0, 3.0, 17.73072329357101, 22.0, 21.45102540770395, 22.7, 1.0, 34.82393832513527], 
actual action is [-7.0, 18], 
sim time next is 2991600.0000, 
raw observation next is [-2.0, 60.0, 3.1, 220.0, 92.0, 709.0, -7.0, 18.30365502837751, 18.0, 21.54188862072933, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.28205128205128205, 0.6, 0.2818181818181818, 0.6111111111111112, 0.24338624338624337, 0.709, 0.38333333333333336, 0.18303655028377508, 0.0, 0.5059840886756187, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:19,200] A3C_AGENT_WORKER-Thread-11 INFO:Local step 35500, global step 571402: loss 41.2903
[2017-11-02 11:19:20,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  3.30910294e-26   2.95870772e-21   2.74111241e-20   4.12797764e-20
   1.26643775e-20   4.28303116e-04   4.71031031e-04   9.82932329e-01
   1.61683764e-02], sum to 1.0000
[2017-11-02 11:19:20,683] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.8333333333333333, 92.08333333333333, 9.708333333333334, 250.0, 0.0, 0.0, -5.666666666666667, 19.43604129864356, 18.0, 20.76064932321649, 22.7, 1.0, 0.0], 
actual action is [4.166666666666667, 20.0], 
sim time next is 2919600.0000, 
raw observation next is [-1.0, 92.0, 9.8, 250.0, 0.0, 0.0, 4.166666666666667, 18.93556152376609, 20.0, 20.71066675696997, 22.7, 1.0, 41.94001006711913], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.3076923076923077, 0.92, 0.890909090909091, 0.6944444444444444, 0.0, 0.0, 0.5694444444444444, 0.1893556152376609, 0.2857142857142857, 0.3872381081385673, 0.6714285714285714, 1.0, 0.49341188314257806], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:21,209] A3C_AGENT_WORKER-Thread-10 INFO:Local step 36000, global step 571769: loss 2.5084
[2017-11-02 11:19:26,598] A3C_AGENT_WORKER-Thread-16 INFO:Local step 36000, global step 572832: loss -12.8281
[2017-11-02 11:19:26,633] A3C_AGENT_WORKER-Thread-6 INFO:Local step 36000, global step 572835: loss -43.3771
[2017-11-02 11:19:27,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.62858263e-04   5.57735970e-04   9.96783614e-01
   1.69575808e-03], sum to 1.0000
[2017-11-02 11:19:27,523] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 70.0, 2.1, 30.0, 0.0, 0.0, -1.0, 25.14640614996517, 20.0, 19.92605785056712, 21.5, 0.0, 45.84527341002012], 
actual action is [-1.0, 22.0], 
sim time next is 3045900.0000, 
raw observation next is [-6.0, 70.58333333333333, 2.183333333333334, 29.16666666666667, 0.0, 0.0, -1.0, 24.89958788821209, 22.0, 19.9922158054553, 21.5, 0.0, 39.59177058235183], 
processed observation next is [1.0, 0.2608695652173913, 0.1794871794871795, 0.7058333333333333, 0.19848484848484854, 0.08101851851851853, 0.0, 0.0, 0.48333333333333334, 0.24899587888212088, 0.5714285714285714, 0.2846022579221855, 0.5, 0.0, 0.46578553626296265], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:29,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.08202604e-15   1.07861951e-12   1.56846723e-11   1.18944585e-11
   4.92036273e-12   7.84956268e-04   3.23810079e-03   9.78166938e-01
   1.78099982e-02], sum to 1.0000
[2017-11-02 11:19:29,195] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 84.0, 4.774999999999999, 289.1666666666666, 0.0, 0.0, 2.0, 22.60786523812263, 25.0, 19.97554123275554, 21.5, 0.0, 49.12924675567918], 
actual action is [2.0, 25], 
sim time next is 2955600.0000, 
raw observation next is [-3.0, 84.0, 4.6, 290.0, 0.0, 0.0, 2.0, 21.73307911053393, 25.0, 20.11358727091342, 21.5, 0.0, 47.89925734074156], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.2564102564102564, 0.84, 0.41818181818181815, 0.8055555555555556, 0.0, 0.0, 0.5333333333333333, 0.2173307911053393, 1.0, 0.3019410387019172, 0.5, 0.0, 0.5635206745969595], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:31,696] A3C_AGENT_WORKER-Thread-8 INFO:Local step 36000, global step 573735: loss -39.4798
[2017-11-02 11:19:32,701] A3C_AGENT_WORKER-Thread-7 INFO:Local step 36000, global step 573893: loss 135.4818
[2017-11-02 11:19:32,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.82322514e-01   1.17915115e-04   9.67840664e-04   6.51127310e-04
   2.11299790e-04   2.95238788e-05   1.40584307e-04   1.52611118e-02
   2.98089639e-04], sum to 1.0000
[2017-11-02 11:19:32,899] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 86.16666666666666, 8.925, 254.1666666666667, 0.0, 0.0, -6.0, 17.33314705204304, 18.0, 21.58868998869095, 22.7, 1.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 2921400.0000, 
raw observation next is [-1.0, 85.0, 8.75, 255.0, 0.0, 0.0, -6.0, 19.46761752444103, 18.0, 21.4175868935507, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.3076923076923077, 0.85, 0.7954545454545454, 0.7083333333333334, 0.0, 0.0, 0.4, 0.1946761752444103, 0.0, 0.48822669907867117, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:35,517] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   4.00878328e-35   1.80865363e-33   1.74638604e-33
   6.15588805e-34   4.09191055e-03   3.06524009e-01   6.81715548e-01
   7.66852824e-03], sum to 1.0000
[2017-11-02 11:19:35,576] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.916666666666667, 76.5, 3.016666666666667, 30.0, 0.0, 0.0, -0.833333333333333, 20.23826599447412, 21.0, 20.95005633674094, 21.5, 0.0, 39.40165777015336], 
actual action is [-0.916666666666667, 23.0], 
sim time next is 3034800.0000, 
raw observation next is [-6.0, 77.0, 3.1, 30.0, 0.0, 0.0, -0.916666666666667, 20.59311036573617, 23.0, 20.95054032181256, 21.5, 0.0, 33.96341742912522], 
processed observation next is [1.0, 0.13043478260869565, 0.1794871794871795, 0.77, 0.2818181818181818, 0.08333333333333333, 0.0, 0.0, 0.4847222222222222, 0.2059311036573617, 0.7142857142857143, 0.42150576025893727, 0.5, 0.0, 0.3995696168132379], 
reward next is -0.4381. 
=============================================
[2017-11-02 11:19:36,479] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[ -99.092659  ]
 [-100.76425934]
 [ -99.23209381]
 [-100.26042938]
 [ -99.28627777]], R is [[-99.03739929]
 [-98.64614105]
 [-98.65968323]
 [-98.67308807]
 [-98.68635559]].
[2017-11-02 11:19:37,888] A3C_AGENT_WORKER-Thread-3 INFO:Local step 36000, global step 574658: loss 57.3189
[2017-11-02 11:19:44,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.28019531e-03   9.76918101e-01   2.11848654e-02
   6.16836769e-04], sum to 1.0000
[2017-11-02 11:19:44,991] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.0, 76.41666666666666, 1.55, 48.33333333333333, 0.0, 0.0, -1.0, 17.34519216486456, 25.0, 21.14325587275486, 21.5, 0.0, 43.9849384000952], 
actual action is [-1.0, 25], 
sim time next is 3042600.0000, 
raw observation next is [-6.0, 75.83333333333334, 1.6, 46.66666666666667, 0.0, 0.0, -1.0, 17.35590256669067, 25.0, 21.13480707395075, 21.5, 0.0, 43.96391395364145], 
processed observation next is [1.0, 0.21739130434782608, 0.1794871794871795, 0.7583333333333334, 0.14545454545454548, 0.12962962962962965, 0.0, 0.0, 0.48333333333333334, 0.1735590256669067, 1.0, 0.44782958199296424, 0.5, 0.0, 0.5172225171016641], 
reward next is -0.5177. 
=============================================
[2017-11-02 11:19:45,358] A3C_AGENT_WORKER-Thread-17 INFO:Local step 36000, global step 575758: loss 0.3993
[2017-11-02 11:19:45,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-62.48831558]
 [-61.86151123]
 [-61.95215988]
 [-62.08018875]
 [-61.27351379]], R is [[-61.34060669]
 [-61.17630768]
 [-61.01340103]
 [-60.85195923]
 [-60.69208145]].
[2017-11-02 11:19:49,335] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  7.37354709e-12   7.54656320e-12   7.16391391e-11   4.74576316e-11
   2.09489457e-11   7.02002225e-03   9.37289715e-01   5.29299304e-02
   2.76034512e-03], sum to 1.0000
[2017-11-02 11:19:49,377] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.1666666666666667, 100.0, 3.1, 83.33333333333334, 0.0, 0.0, 5.083333333333333, 16.35217008596827, 20.0, 21.64814963425528, 21.5, 0.0, 21.3007337418587], 
actual action is [5.166666666666667, 21.0], 
sim time next is 3111300.0000, 
raw observation next is [0.25, 100.0, 3.1, 85.0, 0.0, 0.0, 5.166666666666667, 16.42633497464053, 21.0, 21.61816404341035, 21.5, 0.0, 18.35034178200483], 
processed observation next is [0.0, 0.0, 0.33974358974358976, 1.0, 0.2818181818181818, 0.2361111111111111, 0.0, 0.0, 0.586111111111111, 0.1642633497464053, 0.42857142857142855, 0.5168805776300499, 0.5, 0.0, 0.21588637390593918], 
reward next is -0.1943. 
=============================================
[2017-11-02 11:19:50,108] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.18977996e-15   5.61494312e-14   4.92815858e-13   2.59981191e-13
   9.60453708e-14   1.56874990e-03   9.45897818e-01   4.63831760e-02
   6.15023356e-03], sum to 1.0000
[2017-11-02 11:19:50,324] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.0, 60.0, 2.1, 240.0, 0.0, 0.0, -7.0, 14.9311529697994, 18.0, 22.49749894929451, 22.7, 1.0, 0.0], 
actual action is [3.0, 20.0], 
sim time next is 3004500.0000, 
raw observation next is [-2.0, 60.0, 2.1, 240.0, 0.0, 0.0, 3.0, 14.10688914401123, 20.0, 22.47894056392964, 22.7, 1.0, 68.25007193034004], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.28205128205128205, 0.6, 0.19090909090909092, 0.6666666666666666, 0.0, 0.0, 0.55, 0.1410688914401123, 0.2857142857142857, 0.6398486519899487, 0.6714285714285714, 1.0, 0.8029420227098828], 
reward next is -0.7368. 
=============================================
[2017-11-02 11:19:52,325] A3C_AGENT_WORKER-Thread-4 INFO:Local step 36000, global step 576824: loss -11.2141
[2017-11-02 11:19:53,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00123766e-03   2.28825201e-07   1.46836692e-06   8.27660415e-07
   2.28225446e-07   5.48934448e-04   9.66669381e-01   3.01064774e-02
   1.67113822e-03], sum to 1.0000
[2017-11-02 11:19:53,276] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.166666666666667, 60.83333333333333, 3.6, 235.0, 107.0, 783.6666666666666, 2.75, 21.67912235468973, 20.0, 20.77317156302672, 22.7, 1.0, 20.16685228574698], 
actual action is [2.833333333333333, 21.0], 
sim time next is 2987700.0000, 
raw observation next is [-2.083333333333333, 60.41666666666667, 3.6, 232.5, 106.25, 779.5833333333333, 2.833333333333333, 21.5837020123323, 21.0, 20.79061099213175, 22.7, 1.0, 15.37360422580268], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.2799145299145299, 0.6041666666666667, 0.32727272727272727, 0.6458333333333334, 0.2810846560846561, 0.7795833333333333, 0.5472222222222223, 0.21583702012332298, 0.42857142857142855, 0.3986587131616786, 0.6714285714285714, 1.0, 0.18086593206826682], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:19:53,365] A3C_AGENT_WORKER-Thread-12 INFO:Local step 36000, global step 576979: loss 0.6393
[2017-11-02 11:19:55,052] A3C_AGENT_WORKER-Thread-5 INFO:Local step 36000, global step 577233: loss -10.4563
[2017-11-02 11:19:57,253] A3C_AGENT_WORKER-Thread-14 INFO:Local step 36000, global step 577599: loss -2.4508
[2017-11-02 11:19:57,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 36000, global step 577601: loss -5.0481
[2017-11-02 11:20:01,101] A3C_AGENT_WORKER-Thread-13 INFO:Local step 36000, global step 578206: loss -0.4506
[2017-11-02 11:20:02,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.06788331
  0.71269071  0.20352986  0.01589602], sum to 1.0000
[2017-11-02 11:20:02,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.0, 71.0, 1.5, 20.0, 0.0, 0.0, 0.08333333333333393, 12.40734222924737, 25.0, 22.2793357435041, 21.5, 0.0, 42.93969147866543], 
actual action is [0.0, 25], 
sim time next is 3027900.0000, 
raw observation next is [-5.0, 71.0, 1.55, 20.83333333333333, 0.0, 0.0, 0.0, 12.43543464351536, 25.0, 22.26459929337742, 21.5, 0.0, 43.03917125228643], 
processed observation next is [1.0, 0.043478260869565216, 0.20512820512820512, 0.71, 0.1409090909090909, 0.05787037037037036, 0.0, 0.0, 0.5, 0.12435434643515361, 1.0, 0.6092284704824884, 0.5, 0.0, 0.5063431912033698], 
reward next is -0.4557. 
=============================================
[2017-11-02 11:20:05,764] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.02089417  0.00164341  0.01473412  0.00437645  0.00310536  0.01089181
  0.21590272  0.0943238   0.63412815], sum to 1.0000
[2017-11-02 11:20:05,881] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.916666666666667, 100.0, 0.1250000000000001, 4.166666666666669, 0.0, 0.0, 6.833333333333333, 6.03365991154338, 25.0, 23.91522729624727, 21.5, 0.0, 53.64512133085427], 
actual action is [6.916666666666667, 25], 
sim time next is 3121200.0000, 
raw observation next is [2.0, 100.0, 0.0, 0.0, 0.0, 0.0, 6.916666666666667, 6.052730802997139, 25.0, 23.87267343071276, 21.5, 0.0, 55.55297619132143], 
processed observation next is [0.0, 0.13043478260869565, 0.38461538461538464, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6152777777777777, 0.060527308029971395, 1.0, 0.8389533472446798, 0.5, 0.0, 0.6535644257802521], 
reward next is -0.5882. 
=============================================
[2017-11-02 11:20:06,649] A3C_AGENT_WORKER-Thread-2 INFO:Local step 36000, global step 578990: loss 0.8660
[2017-11-02 11:20:06,858] A3C_AGENT_WORKER-Thread-15 INFO:Local step 36000, global step 579029: loss -2.2992
[2017-11-02 11:20:07,924] A3C_AGENT_WORKER-Thread-10 INFO:Local step 36500, global step 579184: loss -63.6057
[2017-11-02 11:20:08,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 36000, global step 579224: loss -3.6024
[2017-11-02 11:20:09,028] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   4.24907530e-32   1.51338089e-30   4.08740451e-31
   4.34916124e-31   1.16820047e-02   4.98553902e-01   5.48911355e-02
   4.34872985e-01], sum to 1.0000
[2017-11-02 11:20:09,144] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.0, 100.0, 3.516666666666667, 105.0, 0.0, 0.0, 5.0, 7.774650564004342, 25.0, 23.57897201972707, 21.5, 0.0, 39.55156392556046], 
actual action is [5.0, 25], 
sim time next is 3107700.0000, 
raw observation next is [0.0, 100.0, 3.475, 102.5, 0.0, 0.0, 5.0, 7.729533113053665, 25.0, 23.56222623843723, 21.5, 0.0, 43.11774309175362], 
processed observation next is [1.0, 1.0, 0.3333333333333333, 1.0, 0.3159090909090909, 0.2847222222222222, 0.0, 0.0, 0.5833333333333334, 0.07729533113053665, 1.0, 0.7946037483481757, 0.5, 0.0, 0.5072675657853367], 
reward next is -0.4565. 
=============================================
[2017-11-02 11:20:10,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   9.80970918e-38   4.34135745e-38
   5.79576484e-38   4.06789929e-02   5.59435129e-01   1.11315064e-01
   2.88570732e-01], sum to 1.0000
[2017-11-02 11:20:10,417] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.08333333333333333, 99.99999999999999, 3.1, 81.66666666666666, 0.0, 0.0, 5.0, 7.226721972444727, 25.0, 23.5819154965916, 21.5, 0.0, 37.83469787802524], 
actual action is [5.083333333333333, 25], 
sim time next is 3111000.0000, 
raw observation next is [0.1666666666666667, 100.0, 3.1, 83.33333333333334, 0.0, 0.0, 5.083333333333333, 7.174840299141422, 25.0, 23.59041611834648, 21.5, 0.0, 39.15493684571321], 
processed observation next is [0.0, 0.0, 0.3376068376068376, 1.0, 0.2818181818181818, 0.2314814814814815, 0.0, 0.0, 0.5847222222222223, 0.07174840299141422, 1.0, 0.798630874049497, 0.5, 0.0, 0.4606463158319201], 
reward next is -0.4146. 
=============================================
[2017-11-02 11:20:12,072] A3C_AGENT_WORKER-Thread-16 INFO:Local step 36500, global step 579905: loss 47.5105
[2017-11-02 11:20:12,399] A3C_AGENT_WORKER-Thread-6 INFO:Local step 36500, global step 579989: loss 11.4411
[2017-11-02 11:20:14,051] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.54629886
  0.26033136  0.06032436  0.13304542], sum to 1.0000
[2017-11-02 11:20:14,117] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.0, 70.58333333333333, 2.05, 31.66666666666667, 0.0, 0.0, -1.0, 13.65993149010003, 25.0, 21.44780334172018, 21.5, 0.0, 43.94079936640063], 
actual action is [-1.0, 25], 
sim time next is 3045600.0000, 
raw observation next is [-6.0, 70.0, 2.1, 30.0, 0.0, 0.0, -1.0, 13.70124884016922, 25.0, 21.43565530673627, 21.5, 0.0, 43.98632166482857], 
processed observation next is [1.0, 0.2608695652173913, 0.1794871794871795, 0.7, 0.19090909090909092, 0.08333333333333333, 0.0, 0.0, 0.48333333333333334, 0.1370124884016922, 1.0, 0.49080790096232413, 0.5, 0.0, 0.5174861372332773], 
reward next is -0.4749. 
=============================================
[2017-11-02 11:20:19,318] A3C_AGENT_WORKER-Thread-8 INFO:Local step 36500, global step 581303: loss 2.7756
[2017-11-02 11:20:20,123] A3C_AGENT_WORKER-Thread-7 INFO:Local step 36500, global step 581485: loss 9.1015
[2017-11-02 11:20:25,160] A3C_AGENT_WORKER-Thread-3 INFO:Local step 36500, global step 582645: loss 64.5646
[2017-11-02 11:20:26,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.78079865e-10   1.28089339e-09   5.41471368e-10
   9.67964667e-11   3.90997290e-20   2.69187009e-19   2.73585593e-20
   3.68182123e-19], sum to 1.0000
[2017-11-02 11:20:26,779] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.733333333333333, 100.0, 3.433333333333334, 136.6666666666667, 0.0, 0.0, 7.7, 20.30973082011521, 18.5, 20.53945714914605, 21.5, 0.0, 61.59440500807885], 
actual action is [-2.266666666666667, 18], 
sim time next is 3126300.0000, 
raw observation next is [2.766666666666667, 100.0, 3.391666666666667, 138.3333333333333, 0.0, 0.0, -2.266666666666667, 21.54255455920463, 18.0, 20.57143130360409, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.4042735042735043, 1.0, 0.30833333333333335, 0.38425925925925913, 0.0, 0.0, 0.46222222222222226, 0.2154255455920463, 0.0, 0.3673473290862986, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:20:29,734] A3C_AGENT_WORKER-Thread-17 INFO:Local step 36500, global step 583662: loss 44.6727
[2017-11-02 11:20:33,733] A3C_AGENT_WORKER-Thread-4 INFO:Local step 36500, global step 584510: loss 38.1101
[2017-11-02 11:20:34,689] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99964833e-01   1.28780803e-05   1.01672122e-05   8.95557241e-06
   3.20462937e-06   3.35702603e-14   4.41892616e-14   1.27720049e-14
   1.72691553e-14], sum to 1.0000
[2017-11-02 11:20:34,731] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.833333333333334, 94.16666666666666, 4.783333333333333, 191.6666666666667, 113.6666666666667, 811.0, 2.75, 8.10684850277428, 18.0, 23.71150186322414, 22.7, 1.0, 0.0], 
actual action is [2.833333333333334, 18], 
sim time next is 3153300.0000, 
raw observation next is [7.916666666666667, 93.58333333333334, 4.691666666666666, 190.8333333333333, 113.5833333333333, 812.5, 2.833333333333334, 8.042842514942567, 18.0, 23.72634620810601, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.5363247863247863, 0.9358333333333334, 0.4265151515151515, 0.5300925925925924, 0.30048500881834206, 0.8125, 0.5472222222222223, 0.08042842514942566, 0.0, 0.8180494583008583, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0080. 
=============================================
[2017-11-02 11:20:36,401] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00730738e-07   8.05702893e-10   6.60066402e-09   3.02920622e-09
   1.43364942e-09   3.00363749e-02   6.10484779e-02   3.00244633e-02
   8.78890574e-01], sum to 1.0000
[2017-11-02 11:20:36,483] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.583333333333334, 76.83333333333333, 3.983333333333333, 320.0, 0.0, 0.0, -9.5, 22.41282633806635, 18.0, 21.19342683459073, 20.8, 0.0, 0.0], 
actual action is [0.4166666666666661, 23.0], 
sim time next is 3271200.0000, 
raw observation next is [-4.666666666666666, 77.66666666666667, 3.966666666666666, 320.0, 0.0, 0.0, 0.4166666666666661, 18.84188096055736, 23.0, 21.06675581099358, 20.8, 0.0, 87.67088268686763], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.2136752136752137, 0.7766666666666667, 0.36060606060606054, 0.8888888888888888, 0.0, 0.0, 0.5069444444444444, 0.1884188096055736, 0.7142857142857143, 0.43810797299908294, 0.4000000000000001, 0.0, 1.0314221492572662], 
reward next is -0.9283. 
=============================================
[2017-11-02 11:20:36,958] A3C_AGENT_WORKER-Thread-5 INFO:Local step 36500, global step 585262: loss 116.2814
[2017-11-02 11:20:38,571] A3C_AGENT_WORKER-Thread-12 INFO:Local step 36500, global step 585632: loss 91.6817
[2017-11-02 11:20:38,764] A3C_AGENT_WORKER-Thread-9 INFO:Local step 36500, global step 585664: loss 77.0989
[2017-11-02 11:20:39,772] A3C_AGENT_WORKER-Thread-14 INFO:Local step 36500, global step 585873: loss 62.0962
[2017-11-02 11:20:41,743] A3C_AGENT_WORKER-Thread-13 INFO:Local step 36500, global step 586296: loss 27.2340
[2017-11-02 11:20:46,059] A3C_AGENT_WORKER-Thread-2 INFO:Local step 36500, global step 587250: loss 67.6547
[2017-11-02 11:20:46,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   8.02715810e-11   2.16522550e-10   8.01491928e-11
   4.41142470e-11   1.80276087e-26   3.58269069e-25   5.28534884e-25
   1.95752264e-24], sum to 1.0000
[2017-11-02 11:20:46,401] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 90.0, 7.533333333333333, 270.0, 111.6666666666667, 813.8333333333334, -7.5, 15.7279015932797, 18.0, 21.94215355911741, 22.0, 1.0, 0.0], 
actual action is [-7.666666666666667, 18], 
sim time next is 3245100.0000, 
raw observation next is [-2.833333333333333, 91.25, 7.366666666666665, 275.0, 111.3333333333333, 812.9166666666666, -7.666666666666667, 15.98096237612805, 18.0, 21.89583525269288, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.2606837606837607, 0.9125, 0.6696969696969696, 0.7638888888888888, 0.2945326278659611, 0.8129166666666666, 0.3722222222222222, 0.1598096237612805, 0.0, 0.55654789324184, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:20:46,974] A3C_AGENT_WORKER-Thread-15 INFO:Local step 36500, global step 587409: loss 91.9525
[2017-11-02 11:20:47,258] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99997377e-01   2.31273290e-07   1.50294557e-06   4.92122183e-07
   3.12563799e-07   2.70359127e-14   3.59776851e-13   1.06547637e-12
   2.20329506e-12], sum to 1.0000
[2017-11-02 11:20:47,344] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 94.66666666666666, 5.1, 270.0, 0.0, 0.0, 2.0, 16.37375927628432, 25.0, 20.38716665490338, 20.8, 0.0, 53.79497395916855], 
actual action is [2.0, 20.0], 
sim time next is 3221100.0000, 
raw observation next is [-3.0, 94.0, 5.1, 270.0, 0.0, 0.0, 2.0, 15.27657141658775, 20.0, 20.62723220178956, 20.8, 0.0, 41.21340336724914], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.2564102564102564, 0.94, 0.4636363636363636, 0.75, 0.0, 0.0, 0.5333333333333333, 0.1527657141658775, 0.2857142857142857, 0.3753188859699372, 0.4000000000000001, 0.0, 0.4848635690264605], 
reward next is -0.4611. 
=============================================
[2017-11-02 11:20:47,667] A3C_AGENT_WORKER-Thread-10 INFO:Local step 37000, global step 587556: loss 25.9878
[2017-11-02 11:20:50,402] A3C_AGENT_WORKER-Thread-11 INFO:Local step 36500, global step 588124: loss 159.2551
[2017-11-02 11:20:50,924] A3C_AGENT_WORKER-Thread-16 INFO:Local step 37000, global step 588243: loss -79.3443
[2017-11-02 11:20:53,407] A3C_AGENT_WORKER-Thread-6 INFO:Local step 37000, global step 588707: loss 4.2736
[2017-11-02 11:21:00,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.26084534e-03   1.16222654e-05   1.27652995e-04   1.00585072e-04
   4.39463838e-05   1.66560933e-02   6.72061741e-02   2.85002470e-01
   6.29590631e-01], sum to 1.0000
[2017-11-02 11:21:00,527] A3C_AGENT_WORKER-Thread-8 INFO:Local step 37000, global step 590099: loss 32.9388
[2017-11-02 11:21:00,595] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 65.0, 3.1, 170.0, 0.0, 0.0, -8.916666666666668, 17.3935198286294, 18.0, 21.72765701069666, 20.8, 0.0, 0.0], 
actual action is [1.0, 23.0], 
sim time next is 3359100.0000, 
raw observation next is [-4.0, 65.0, 3.1, 170.0, 0.0, 0.0, 1.0, 16.18561290443094, 23.0, 21.6660070340286, 20.8, 0.0, 59.86122616733002], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.23076923076923078, 0.65, 0.2818181818181818, 0.4722222222222222, 0.0, 0.0, 0.5166666666666667, 0.1618561290443094, 0.7142857142857143, 0.5237152905755141, 0.4000000000000001, 0.0, 0.7042497196156473], 
reward next is -0.6338. 
=============================================
[2017-11-02 11:21:00,725] A3C_AGENT_WORKER-Thread-7 INFO:Local step 37000, global step 590138: loss 92.3893
[2017-11-02 11:21:07,527] A3C_AGENT_WORKER-Thread-3 INFO:Local step 37000, global step 591427: loss 8.3663
[2017-11-02 11:21:09,669] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  4.09553306e-29   1.63493505e-23   1.32667148e-21   2.51512262e-21
   6.80955740e-22   1.10055245e-02   2.67186090e-02   1.72239438e-01
   7.90036380e-01], sum to 1.0000
[2017-11-02 11:21:09,758] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.41666666666667, 76.0, 3.308333333333333, 299.1666666666666, 0.0, 0.0, -5.33333333333333, 29.05082117504321, 20.0, 18.93509739762171, 20.8, 0.0, 54.16350168551787], 
actual action is [-5.41666666666667, 25.0], 
sim time next is 3303000.0000, 
raw observation next is [-10.5, 76.0, 3.35, 295.0, 0.0, 0.0, -5.41666666666667, 27.76998171596296, 25.0, 19.10334983615806, 20.8, 0.0, 49.79860728192637], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.0641025641025641, 0.76, 0.30454545454545456, 0.8194444444444444, 0.0, 0.0, 0.40972222222222215, 0.2776998171596296, 1.0, 0.15762140516543713, 0.4000000000000001, 0.0, 0.5858659680226632], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:21:10,281] A3C_AGENT_WORKER-Thread-17 INFO:Local step 37000, global step 591916: loss -62.5087
[2017-11-02 11:21:11,684] A3C_AGENT_WORKER-Thread-4 INFO:Local step 37000, global step 592187: loss 33.6081
[2017-11-02 11:21:15,683] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-66.80651855]
 [-66.68784332]
 [-66.11753845]
 [-65.86934662]
 [-64.68435669]], R is [[-65.1421814 ]
 [-64.95908356]
 [-64.86077118]
 [-64.79006958]
 [-64.7627182 ]].
[2017-11-02 11:21:18,428] A3C_AGENT_WORKER-Thread-5 INFO:Local step 37000, global step 593268: loss 2.5015
[2017-11-02 11:21:20,695] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-61.8357048 ]
 [-60.71939087]
 [-59.23262405]
 [-60.45018005]
 [-60.71590042]], R is [[-62.4228096 ]
 [-61.81315994]
 [-62.06368256]
 [-62.44304657]
 [-62.81861496]].
[2017-11-02 11:21:20,757] A3C_AGENT_WORKER-Thread-9 INFO:Local step 37000, global step 593588: loss 0.7503
[2017-11-02 11:21:21,948] A3C_AGENT_WORKER-Thread-12 INFO:Local step 37000, global step 593795: loss -8.5055
[2017-11-02 11:21:22,449] A3C_AGENT_WORKER-Thread-14 INFO:Local step 37000, global step 593894: loss -35.2255
[2017-11-02 11:21:22,605] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.08646799e-14   7.58404908e-14   8.69250215e-14
   1.20488802e-14   7.00391375e-36   7.17895981e-35   2.07362737e-34
   1.11324987e-32], sum to 1.0000
[2017-11-02 11:21:22,622] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 48.66666666666667, 5.1, 233.3333333333334, 90.16666666666666, 687.0, -7.75, 16.81093621315342, 18.0, 22.20756692754992, 22.0, 1.0, 0.0], 
actual action is [-7.666666666666667, 18], 
sim time next is 3338700.0000, 
raw observation next is [-2.583333333333333, 48.33333333333333, 5.1, 231.6666666666666, 88.58333333333334, 680.5, -7.666666666666667, 16.77306417030577, 18.0, 22.21624780409702, 22.0, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.26709401709401714, 0.4833333333333333, 0.4636363636363636, 0.6435185185185184, 0.23434744268077604, 0.6805, 0.3722222222222222, 0.16773064170305768, 0.0, 0.6023211148710027, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:21:23,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.44804602e-26   3.48604929e-21   6.00882932e-20   1.49776624e-19
   4.30087422e-20   9.89125576e-04   3.04820924e-03   1.20551661e-02
   9.83907461e-01], sum to 1.0000
[2017-11-02 11:21:23,829] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.333333333333334, 73.0, 3.1, 163.3333333333333, 0.0, 0.0, -10.25, 28.4873603702563, 18.0, 20.76441159732176, 20.8, 0.0, 0.0], 
actual action is [-0.3333333333333339, 23.0], 
sim time next is 3367500.0000, 
raw observation next is [-5.416666666666666, 73.5, 3.1, 164.1666666666667, 0.0, 0.0, -0.3333333333333339, 24.66103289941226, 23.0, 20.49792787888587, 20.8, 0.0, 91.72093754090805], 
processed observation next is [0.3333333333333333, 1.0, 0.19444444444444445, 0.735, 0.2818181818181818, 0.45601851851851866, 0.0, 0.0, 0.4944444444444444, 0.24661032899412258, 0.7142857142857143, 0.35684683984083876, 0.4000000000000001, 0.0, 1.0790698534224477], 
reward next is -1.0143. 
=============================================
[2017-11-02 11:21:24,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-66.29690552]
 [-66.87262726]
 [-65.84433746]
 [-65.16557312]
 [-66.34971619]], R is [[-65.60559845]
 [-65.54261017]
 [-65.43948364]
 [-65.3279953 ]
 [-65.67471313]].
[2017-11-02 11:21:24,765] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99989748e-01   2.21991243e-07   3.54793951e-06   4.90332877e-06
   9.38619678e-07   8.63624339e-10   2.75012590e-09   8.41892511e-09
   6.31507021e-07], sum to 1.0000
[2017-11-02 11:21:24,824] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 79.0, 6.45, 210.0, 0.0, 0.0, -4.0, 18.75208222899698, 18.0, 21.70980274064377, 22.0, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 3440100.0000, 
raw observation next is [1.0, 79.0, 6.491666666666667, 210.0, 0.0, 0.0, -4.0, 20.37030583168493, 18.0, 21.580744805124, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.8260869565217391, 0.358974358974359, 0.79, 0.5901515151515152, 0.5833333333333334, 0.0, 0.0, 0.43333333333333335, 0.20370305831684932, 0.0, 0.5115349721605712, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:21:26,633] A3C_AGENT_WORKER-Thread-13 INFO:Local step 37000, global step 594587: loss 44.8684
[2017-11-02 11:21:29,653] A3C_AGENT_WORKER-Thread-10 INFO:Local step 37500, global step 595085: loss -20.3566
[2017-11-02 11:21:30,502] A3C_AGENT_WORKER-Thread-2 INFO:Local step 37000, global step 595222: loss 1.7281
[2017-11-02 11:21:31,659] A3C_AGENT_WORKER-Thread-15 INFO:Local step 37000, global step 595445: loss -1.3698
[2017-11-02 11:21:33,179] A3C_AGENT_WORKER-Thread-16 INFO:Local step 37500, global step 595740: loss -36.2627
[2017-11-02 11:21:34,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.81909695e-12   3.07610153e-11   1.91057795e-11
   3.11798092e-12   1.12345815e-33   7.65192162e-32   7.52731452e-32
   6.07830374e-30], sum to 1.0000
[2017-11-02 11:21:34,180] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.166666666666667, 46.66666666666667, 5.1, 223.3333333333333, 78.0, 616.3333333333334, -7.25, 16.16360155650337, 18.0, 22.43512285894528, 22.0, 1.0, 0.0], 
actual action is [-7.166666666666667, 18], 
sim time next is 3340500.0000, 
raw observation next is [-2.083333333333333, 46.33333333333334, 5.1, 221.6666666666667, 75.75, 601.9166666666666, -7.166666666666667, 16.16679280570748, 18.0, 22.44332131597418, 22.0, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.2799145299145299, 0.46333333333333343, 0.4636363636363636, 0.6157407407407409, 0.2003968253968254, 0.6019166666666667, 0.38055555555555554, 0.1616679280570748, 0.0, 0.6347601879963116, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:21:34,535] A3C_AGENT_WORKER-Thread-6 INFO:Local step 37500, global step 596003: loss 4.9128
[2017-11-02 11:21:35,403] A3C_AGENT_WORKER-Thread-11 INFO:Local step 37000, global step 596179: loss 42.4107
[2017-11-02 11:21:39,253] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   5.93787129e-12   8.52478144e-10   1.81082593e-10
   3.79500251e-11   8.33034227e-28   3.44840838e-27   9.66362929e-27
   7.51497593e-25], sum to 1.0000
[2017-11-02 11:21:39,364] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 78.99999999999999, 6.566666666666666, 210.0, 0.0, 0.0, -4.0, 19.25696361708756, 18.0, 21.10894188716105, 22.0, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 3442200.0000, 
raw observation next is [1.0, 79.00000000000001, 6.433333333333334, 210.0, 0.0, 0.0, -4.0, 20.16621662740723, 18.0, 21.26416934250409, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.358974358974359, 0.7900000000000001, 0.5848484848484848, 0.5833333333333334, 0.0, 0.0, 0.43333333333333335, 0.2016621662740723, 0.0, 0.46630990607201284, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:21:41,963] A3C_AGENT_WORKER-Thread-8 INFO:Local step 37500, global step 597391: loss 14.5314
[2017-11-02 11:21:43,639] A3C_AGENT_WORKER-Thread-7 INFO:Local step 37500, global step 597715: loss 35.1704
[2017-11-02 11:21:43,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-48.01850128]
 [-47.59783936]
 [-48.85643005]
 [-47.61339951]
 [-47.48932648]], R is [[-48.25269318]
 [-48.7701683 ]
 [-49.28246689]
 [-49.78964233]
 [-50.29174805]].
[2017-11-02 11:21:47,385] A3C_AGENT_WORKER-Thread-3 INFO:Local step 37500, global step 598407: loss 97.8787
[2017-11-02 11:21:47,403] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-79.82633209]
 [-79.94816589]
 [-79.608078  ]
 [-79.91384888]
 [-79.42539215]], R is [[-80.53562164]
 [-80.73026276]
 [-80.92295837]
 [-81.11373138]
 [-81.30259705]].
[2017-11-02 11:21:52,757] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.60264965e-12   2.71174305e-10   3.37431506e-11
   1.59235784e-11   6.04205488e-30   3.18586224e-28   2.44581812e-28
   3.78189471e-26], sum to 1.0000
[2017-11-02 11:21:52,787] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.416666666666667, 48.41666666666666, 8.7, 218.3333333333333, 108.1666666666667, 755.1666666666666, -2.666666666666667, 12.26635352618594, 18.0, 23.32848148288254, 22.0, 1.0, 0.0], 
actual action is [-2.583333333333333, 18], 
sim time next is 3407400.0000, 
raw observation next is [2.5, 48.5, 9.0, 220.0, 109.0, 764.0, -2.583333333333333, 12.66339502094352, 18.0, 23.33477386590278, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.3974358974358974, 0.485, 0.8181818181818182, 0.6111111111111112, 0.28835978835978837, 0.764, 0.4569444444444445, 0.12663395020943521, 0.0, 0.7621105522718256, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0127. 
=============================================
[2017-11-02 11:21:54,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-66.93590546]
 [-67.17045593]
 [-67.33015442]
 [-67.92874146]
 [-67.60700226]], R is [[-67.77500916]
 [-68.09725952]
 [-68.41629028]
 [-68.73212433]
 [-69.04480743]].
[2017-11-02 11:21:54,727] A3C_AGENT_WORKER-Thread-4 INFO:Local step 37500, global step 599850: loss 20.0847
[2017-11-02 11:21:55,469] A3C_AGENT_WORKER-Thread-17 INFO:Local step 37500, global step 599994: loss 123.4589
[2017-11-02 11:21:56,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   6.61367055e-12   8.07356404e-10   1.29027428e-10
   8.38982772e-11   2.30956745e-35   1.60364172e-33   4.36675351e-34
   9.12916170e-33], sum to 1.0000
[2017-11-02 11:21:56,473] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 6.2, 220.0, 0.0, 0.0, -4.0, 27.54386059745074, 18.0, 20.63567391397461, 20.8, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 3449100.0000, 
raw observation next is [1.0, 86.0, 6.108333333333333, 220.0, 0.0, 0.0, -4.0, 28.57691878320625, 18.0, 20.56628976703919, 20.8, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.358974358974359, 0.86, 0.5553030303030303, 0.6111111111111112, 0.0, 0.0, 0.43333333333333335, 0.2857691878320625, 0.0, 0.3666128238627415, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0334. 
=============================================
[2017-11-02 11:21:59,487] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.79009354e-33   3.13377953e-25   1.46889271e-22   5.79030973e-23
   3.56295433e-23   5.52478665e-03   2.03244194e-01   7.33455718e-02
   7.17885494e-01], sum to 1.0000
[2017-11-02 11:21:59,548] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.0, 77.25, 5.825, 242.5, 0.0, 0.0, -4.0, 22.19211946374869, 18.0, 21.37669128869556, 20.8, 0.0, 0.0], 
actual action is [6.0, 23.0], 
sim time next is 3464400.0000, 
raw observation next is [1.0, 76.66666666666667, 5.866666666666667, 243.3333333333334, 0.0, 0.0, 6.0, 20.36344097954642, 23.0, 21.18081336990899, 20.8, 0.0, 63.72866406629763], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.358974358974359, 0.7666666666666667, 0.5333333333333333, 0.6759259259259262, 0.0, 0.0, 0.6, 0.2036344097954642, 0.7142857142857143, 0.4544019099869985, 0.4000000000000001, 0.0, 0.7497489890152662], 
reward next is -0.6748. 
=============================================
[2017-11-02 11:22:01,863] A3C_AGENT_WORKER-Thread-5 INFO:Local step 37500, global step 601192: loss 115.6360
[2017-11-02 11:22:02,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   5.50606522e-12   6.93482938e-10   1.58271146e-10
   5.10174923e-11   7.45649986e-16   1.58321554e-14   3.91910710e-15
   6.60828890e-15], sum to 1.0000
[2017-11-02 11:22:02,701] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 2.016666666666667, 261.6666666666667, 106.0, 796.0, -6.0, 19.0667956027932, 18.0, 21.8567844270883, 22.7, 1.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 3593700.0000, 
raw observation next is [-1.0, 42.0, 2.275, 262.5, 105.0, 794.0, -6.0, 19.61101957071475, 18.0, 21.80992632148022, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.3076923076923077, 0.42, 0.20681818181818182, 0.7291666666666666, 0.2777777777777778, 0.794, 0.4, 0.1961101957071475, 0.0, 0.5442751887828885, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:03,067] A3C_AGENT_WORKER-Thread-9 INFO:Local step 37500, global step 601430: loss 17.8815
[2017-11-02 11:22:05,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.00356150e-21   6.52683954e-20   7.66514028e-18   2.88742303e-18
   2.16337198e-18   1.96270812e-02   1.00339875e-01   2.06488103e-01
   6.73545003e-01], sum to 1.0000
[2017-11-02 11:22:05,323] A3C_AGENT_WORKER-Thread-12 INFO:Local step 37500, global step 601888: loss -64.5026
[2017-11-02 11:22:05,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.25, 39.75, 1.95, 270.0, 26.25, 235.25, 4.833333333333333, 16.26387762104832, 20.0, 22.17628322574628, 22.7, 1.0, 38.9333099133999], 
actual action is [4.75, 22.0], 
sim time next is 3604800.0000, 
raw observation next is [-0.3333333333333333, 40.0, 1.9, 273.3333333333334, 22.16666666666666, 204.1666666666667, 4.75, 16.22726609944715, 22.0, 22.18061284264188, 22.7, 1.0, 23.82720679226949], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.3247863247863248, 0.4, 0.17272727272727273, 0.7592592592592595, 0.05864197530864196, 0.20416666666666672, 0.5791666666666667, 0.1622726609944715, 0.5714285714285714, 0.5972304060916974, 0.6714285714285714, 1.0, 0.28032007990905283], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:05,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.23648677e-24   2.12359041e-20   2.11290334e-17   6.62545490e-18
   2.31979928e-18   9.34492238e-03   7.27758631e-02   6.59806728e-02
   8.51898491e-01], sum to 1.0000
[2017-11-02 11:22:05,986] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.08333333333333333, 71.91666666666667, 5.191666666666666, 229.1666666666667, 0.0, 0.0, 5.0, 28.16663068525259, 23.5, 19.50441613693139, 22.0, 1.0, 95.6843044746193], 
actual action is [4.916666666666667, 24.5], 
sim time next is 3481800.0000, 
raw observation next is [-0.1666666666666667, 71.83333333333333, 5.283333333333333, 228.3333333333333, 0.0, 0.0, 4.916666666666667, 24.99861507628734, 24.5, 19.6742773402685, 22.0, 1.0, 87.03529871456281], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.32905982905982906, 0.7183333333333333, 0.4803030303030303, 0.6342592592592591, 0.0, 0.0, 0.5819444444444444, 0.2499861507628734, 0.9285714285714286, 0.23918247718121424, 0.5714285714285714, 1.0, 1.0239446907595624], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:08,111] A3C_AGENT_WORKER-Thread-14 INFO:Local step 37500, global step 602405: loss 79.4884
[2017-11-02 11:22:09,404] A3C_AGENT_WORKER-Thread-13 INFO:Local step 37500, global step 602636: loss -17.6856
[2017-11-02 11:22:09,585] A3C_AGENT_WORKER-Thread-2 INFO:Local step 37500, global step 602666: loss 35.2425
[2017-11-02 11:22:10,410] A3C_AGENT_WORKER-Thread-10 INFO:Local step 38000, global step 602839: loss 213.1017
[2017-11-02 11:22:11,308] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   5.47400584e-18   4.14131084e-16   6.86612848e-17
   2.61293700e-17   0.00000000e+00   3.69601242e-38   7.84885206e-38
   5.00228127e-37], sum to 1.0000
[2017-11-02 11:22:11,439] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.416666666666666, 58.58333333333334, 4.475, 265.8333333333333, 111.25, 762.8333333333333, 0.5, 17.745563092076, 23.0, 21.58788629805086, 22.7, 1.0, 103.8884581073703], 
actual action is [-9.416666666666666, 18.0], 
sim time next is 3580800.0000, 
raw observation next is [-4.333333333333334, 57.66666666666667, 4.300000000000001, 266.6666666666667, 111.5, 767.6666666666667, -9.416666666666666, 18.74844041890872, 18.0, 21.70052481064505, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.2222222222222222, 0.5766666666666667, 0.390909090909091, 0.7407407407407408, 0.294973544973545, 0.7676666666666667, 0.3430555555555556, 0.1874844041890872, 0.0, 0.5286464015207214, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:11,835] A3C_AGENT_WORKER-Thread-16 INFO:Local step 38000, global step 603130: loss 5.6489
[2017-11-02 11:22:12,751] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   6.99462406e-13   1.28038954e-10   2.75790450e-11
   6.73095434e-12   8.97048961e-28   7.05368375e-27   1.05585011e-26
   1.34768997e-25], sum to 1.0000
[2017-11-02 11:22:12,776] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.8, 25.5, 3.225, 172.5, 0.0, 0.0, 3.866666666666667, 27.90500988047341, 18.0, 21.17940334532187, 21.5, 0.0, 0.0], 
actual action is [3.8000000000000007, 18], 
sim time next is 3637200.0000, 
raw observation next is [8.733333333333334, 25.66666666666667, 3.266666666666667, 173.3333333333333, 0.0, 0.0, 3.800000000000001, 28.72003870781614, 18.0, 21.08680297044683, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5572649572649573, 0.2566666666666667, 0.296969696969697, 0.48148148148148134, 0.0, 0.0, 0.5633333333333334, 0.2872003870781614, 0.0, 0.44097185292097557, 0.5, 0.0, 0.0], 
reward next is -0.0590. 
=============================================
[2017-11-02 11:22:15,537] A3C_AGENT_WORKER-Thread-15 INFO:Local step 37500, global step 603892: loss -36.9697
[2017-11-02 11:22:15,890] A3C_AGENT_WORKER-Thread-6 INFO:Local step 38000, global step 603970: loss 1.3261
[2017-11-02 11:22:17,194] A3C_AGENT_WORKER-Thread-11 INFO:Local step 37500, global step 604269: loss -101.1573
[2017-11-02 11:22:18,931] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   2.13616429e-12   4.90733620e-10   8.23257712e-11
   2.69516909e-11   2.80182555e-27   5.15474410e-26   2.30379694e-26
   6.68822071e-24], sum to 1.0000
[2017-11-02 11:22:18,995] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 60.0, 5.524999999999999, 290.0, 0.0, 0.0, 3.0, 25.03871300771358, 23.0, 20.07931418327709, 21.5, 0.0, 103.7648762185828], 
actual action is [-7.0, 18.0], 
sim time next is 3543000.0000, 
raw observation next is [-2.0, 60.0, 5.35, 290.0, 0.0, 0.0, -7.0, 26.49901279865876, 18.0, 20.290675127986, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.0, 0.28205128205128205, 0.6, 0.48636363636363633, 0.8055555555555556, 0.0, 0.0, 0.38333333333333336, 0.2649901279865876, 0.0, 0.32723930399799983, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:22,170] A3C_AGENT_WORKER-Thread-8 INFO:Local step 38000, global step 605205: loss 38.6738
[2017-11-02 11:22:22,671] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  6.52391076e-01   4.88227201e-08   5.20904280e-07   2.25305848e-06
   9.80929826e-07   3.36193526e-03   1.63842086e-02   1.53156342e-02
   3.12543392e-01], sum to 1.0000
[2017-11-02 11:22:22,757] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.916666666666667, 69.58333333333333, 5.149999999999999, 287.5, 95.0, 571.4166666666667, -1.0, 15.61367367439461, 20.0, 21.96532743224772, 22.7, 1.0, 55.07421979924288], 
actual action is [-10.916666666666668, 18], 
sim time next is 3575400.0000, 
raw observation next is [-5.833333333333333, 69.16666666666667, 5.2, 285.0, 96.0, 592.3333333333334, -10.91666666666667, 17.44784499273011, 18.0, 22.03872248713957, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.18376068376068377, 0.6916666666666668, 0.4727272727272727, 0.7916666666666666, 0.25396825396825395, 0.5923333333333334, 0.3180555555555555, 0.1744784499273011, 0.0, 0.5769603553056528, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:22,885] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   2.88375850e-13   1.49428972e-12   4.35565603e-12
   1.71970706e-12   5.74979257e-24   4.57587288e-23   3.24299772e-23
   5.30824983e-22], sum to 1.0000
[2017-11-02 11:22:22,927] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.333333333333334, 44.0, 4.8, 213.3333333333334, 116.8333333333333, 826.8333333333334, -0.75, 17.83593214920392, 18.0, 22.56868161720911, 22.7, 1.0, 0.0], 
actual action is [-0.6666666666666661, 18], 
sim time next is 3673500.0000, 
raw observation next is [4.416666666666666, 43.75, 4.975, 214.1666666666667, 116.9166666666667, 827.9166666666666, -0.6666666666666661, 18.11935758559348, 18.0, 22.50076868029988, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.4465811965811965, 0.4375, 0.4522727272727272, 0.5949074074074076, 0.3093033509700177, 0.8279166666666666, 0.48888888888888893, 0.1811935758559348, 0.0, 0.6429669543285544, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:23,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-47.6313324 ]
 [-47.69967651]
 [-48.16799927]
 [-47.19328308]
 [-47.47582245]], R is [[-49.29915619]
 [-49.80616379]
 [-50.30810165]
 [-50.80501938]
 [-50.39519119]].
[2017-11-02 11:22:25,748] A3C_AGENT_WORKER-Thread-7 INFO:Local step 38000, global step 605951: loss 11.7913
[2017-11-02 11:22:29,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 38000, global step 606730: loss 30.8851
[2017-11-02 11:22:29,565] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   7.90013400e-14   5.03295105e-12   3.53831461e-12
   1.17438568e-12   7.36472035e-36   1.01666830e-34   3.33771146e-35
   1.65959819e-32], sum to 1.0000
[2017-11-02 11:22:29,581] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.016666666666666, 28.83333333333333, 3.141666666666667, 180.0, 0.0, 0.0, 3.033333333333333, 28.73453099598275, 18.0, 20.93742257815225, 21.5, 0.0, 0.0], 
actual action is [3.0166666666666657, 18], 
sim time next is 3643200.0000, 
raw observation next is [8.0, 29.0, 3.1, 180.0, 0.0, 0.0, 3.016666666666666, 29.44513477739471, 18.0, 20.86374250380245, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5384615384615384, 0.29, 0.2818181818181818, 0.5, 0.0, 0.0, 0.5502777777777778, 0.2944513477739471, 0.0, 0.4091060719717784, 0.5, 0.0, 0.0], 
reward next is -0.0909. 
=============================================
[2017-11-02 11:22:29,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   1.37716408e-15   3.03149263e-14   3.72902697e-14
   2.01731501e-14   7.14326699e-32   1.34012478e-30   5.05898444e-31
   9.85369135e-29], sum to 1.0000
[2017-11-02 11:22:29,734] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.75, 70.0, 4.35, 290.0, 66.75, 349.0, -11.83333333333333, 21.88687346539292, 18.0, 20.73045775740077, 22.7, 1.0, 0.0], 
actual action is [-11.75, 18], 
sim time next is 3572400.0000, 
raw observation next is [-6.666666666666667, 70.0, 4.433333333333334, 290.0, 73.83333333333334, 374.3333333333334, -11.75, 23.99326411654184, 18.0, 20.82206985879087, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.1623931623931624, 0.7, 0.40303030303030307, 0.8055555555555556, 0.19532627865961202, 0.3743333333333334, 0.30416666666666664, 0.2399326411654184, 0.0, 0.4031528369701241, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:31,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   6.19912247e-11   3.73203912e-09   1.12230305e-08
   7.85648702e-09   6.40544366e-28   1.00069656e-26   3.72168359e-27
   2.66575427e-24], sum to 1.0000
[2017-11-02 11:22:31,787] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 66.16666666666667, 4.516666666666666, 306.6666666666667, 0.0, 0.0, 2.75, 20.55169157653846, 25.0, 20.69585590807986, 21.5, 0.0, 62.31456731482625], 
actual action is [2.5, 20.0], 
sim time next is 3711300.0000, 
raw observation next is [-2.75, 65.58333333333333, 4.558333333333333, 308.3333333333333, 0.0, 0.0, 2.5, 19.38618666165855, 20.0, 20.91486422845092, 21.5, 0.0, 42.91113426960052], 
processed observation next is [1.0, 0.9565217391304348, 0.26282051282051283, 0.6558333333333333, 0.4143939393939393, 0.8564814814814814, 0.0, 0.0, 0.5416666666666666, 0.1938618666165855, 0.2857142857142857, 0.41640917549298856, 0.5, 0.0, 0.5048368737600061], 
reward next is -0.5379. 
=============================================
[2017-11-02 11:22:35,141] A3C_AGENT_WORKER-Thread-4 INFO:Local step 38000, global step 607876: loss 1.4992
[2017-11-02 11:22:38,510] A3C_AGENT_WORKER-Thread-17 INFO:Local step 38000, global step 608471: loss 19.5119
[2017-11-02 11:22:43,022] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-35.73845291]
 [-34.4477005 ]
 [-35.65996552]
 [-36.69999313]
 [-36.43414688]], R is [[-35.21586227]
 [-35.49155426]
 [-36.12695694]
 [-35.79320908]
 [-35.46115875]].
[2017-11-02 11:22:43,821] A3C_AGENT_WORKER-Thread-5 INFO:Local step 38000, global step 609468: loss 57.9807
[2017-11-02 11:22:44,921] A3C_AGENT_WORKER-Thread-9 INFO:Local step 38000, global step 609682: loss 44.6723
[2017-11-02 11:22:46,740] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.10374057e-12   1.60416125e-11   3.67116532e-10
   2.10611514e-10   5.44084500e-17   5.04439619e-16   1.80650720e-17
   6.32185835e-15], sum to 1.0000
[2017-11-02 11:22:46,765] A3C_AGENT_WORKER-Thread-10 INFO:Local step 38500, global step 610069: loss 7.4628
[2017-11-02 11:22:46,772] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 2.791666666666667, 264.1666666666666, 103.0, 790.0, -6.0, 14.78451302643784, 18.0, 22.56892419892002, 22.7, 1.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 3594600.0000, 
raw observation next is [-1.0, 42.0, 3.05, 265.0, 102.0, 788.0, -6.0, 15.23105430626511, 18.0, 22.58177460963396, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.3076923076923077, 0.42, 0.2772727272727273, 0.7361111111111112, 0.2698412698412698, 0.788, 0.4, 0.1523105430626511, 0.0, 0.6545392299477086, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:47,482] A3C_AGENT_WORKER-Thread-12 INFO:Local step 38000, global step 610224: loss 2.2862
[2017-11-02 11:22:48,270] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.98446405e-01   5.52802067e-06   7.86695236e-05   8.13078077e-04
   6.47056440e-04   3.04934495e-08   1.91271411e-07   1.33004772e-08
   9.00908162e-06], sum to 1.0000
[2017-11-02 11:22:48,301] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 4.6, 280.0, 0.0, 0.0, -8.0, 17.91584475987624, 18.0, 21.3163544258666, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 3722700.0000, 
raw observation next is [-3.0, 65.0, 4.641666666666666, 278.3333333333333, 0.0, 0.0, -8.0, 19.57565482667301, 18.0, 21.3709398409961, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.65, 0.4219696969696969, 0.7731481481481481, 0.0, 0.0, 0.36666666666666664, 0.19575654826673008, 0.0, 0.48156283442801445, 0.5, 0.0, 0.0], 
reward next is -0.0184. 
=============================================
[2017-11-02 11:22:49,005] A3C_AGENT_WORKER-Thread-16 INFO:Local step 38500, global step 610555: loss 2.9774
[2017-11-02 11:22:49,613] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  7.49574482e-01   7.54567327e-06   1.72684726e-04   2.59158434e-03
   1.10278430e-03   4.43948526e-03   2.11421438e-02   7.03372352e-04
   2.20265865e-01], sum to 1.0000
[2017-11-02 11:22:49,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 3.475, 170.0, 0.0, 0.0, 4.0, 23.7411235016688, 18.0, 21.71953736151903, 21.5, 0.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 3633600.0000, 
raw observation next is [9.0, 25.0, 3.433333333333334, 170.0, 0.0, 0.0, 4.0, 24.43274454415172, 18.0, 21.64476108723263, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.5641025641025641, 0.25, 0.3121212121212122, 0.4722222222222222, 0.0, 0.0, 0.5666666666666667, 0.24432744544151722, 0.0, 0.5206801553189473, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:22:50,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   8.88531273e-13   8.49471275e-12   8.80105433e-11
   3.89140595e-11   1.21138320e-34   5.59691762e-33   8.54241445e-35
   2.78924532e-32], sum to 1.0000
[2017-11-02 11:22:50,853] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.6, 26.0, 3.35, 175.0, 0.0, 0.0, 3.666666666666666, 21.52023586122016, 18.0, 21.79342895358296, 21.5, 0.0, 0.0], 
actual action is [3.5999999999999996, 18], 
sim time next is 3638100.0000, 
raw observation next is [8.533333333333333, 26.16666666666667, 3.391666666666667, 175.8333333333333, 0.0, 0.0, 3.6, 22.43218580824904, 18.0, 21.74077096726288, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5521367521367521, 0.2616666666666667, 0.30833333333333335, 0.4884259259259258, 0.0, 0.0, 0.56, 0.22432185808249042, 0.0, 0.5343958524661255, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:22:50,892] A3C_AGENT_WORKER-Thread-14 INFO:Local step 38000, global step 610983: loss 41.9935
[2017-11-02 11:22:51,897] A3C_AGENT_WORKER-Thread-2 INFO:Local step 38000, global step 611209: loss 2.7197
[2017-11-02 11:22:52,208] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-28.62741852]
 [-31.13775826]
 [-28.91075325]
 [-30.48465729]
 [-30.62799644]], R is [[-29.76539612]
 [-29.48060989]
 [-29.19872093]
 [-28.91968918]
 [-28.64348221]].
[2017-11-02 11:22:53,178] A3C_AGENT_WORKER-Thread-6 INFO:Local step 38500, global step 611497: loss 2.0594
[2017-11-02 11:22:53,344] A3C_AGENT_WORKER-Thread-13 INFO:Local step 38000, global step 611537: loss 0.5330
[2017-11-02 11:22:55,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   9.15506169e-13   9.11015968e-12   5.24477545e-11
   3.39995011e-11   1.45242457e-29   2.04860860e-27   6.30442575e-29
   7.65737666e-26], sum to 1.0000
[2017-11-02 11:22:55,095] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666667, 39.5, 2.0, 266.6666666666667, 30.33333333333333, 266.3333333333333, -5.083333333333333, 17.89178015255874, 18.0, 22.32903562441168, 22.7, 1.0, 0.0], 
actual action is [-5.166666666666667, 18], 
sim time next is 3604500.0000, 
raw observation next is [-0.25, 39.75, 1.95, 270.0, 26.25, 235.25, -5.166666666666667, 18.56889050425544, 18.0, 22.25013785107446, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.3269230769230769, 0.3975, 0.17727272727272728, 0.75, 0.06944444444444445, 0.23525, 0.41388888888888886, 0.1856889050425544, 0.0, 0.6071625501534942, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:22:57,361] A3C_AGENT_WORKER-Thread-15 INFO:Local step 38000, global step 612454: loss 22.4808
[2017-11-02 11:22:58,255] A3C_AGENT_WORKER-Thread-8 INFO:Local step 38500, global step 612655: loss 3.9191
[2017-11-02 11:23:00,382] A3C_AGENT_WORKER-Thread-11 INFO:Local step 38000, global step 613085: loss 24.0316
[2017-11-02 11:23:02,103] A3C_AGENT_WORKER-Thread-7 INFO:Local step 38500, global step 613434: loss 1.0649
[2017-11-02 11:23:03,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.20726441e-11   6.71859623e-10   1.24045787e-08
   6.93290225e-09   5.60415569e-27   2.00395051e-25   1.06367663e-26
   6.46839373e-23], sum to 1.0000
[2017-11-02 11:23:03,503] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.5, 71.0, 6.45, 265.0, 0.0, 0.0, 1.583333333333333, 21.94514906553704, 23.0, 20.21440040814181, 21.5, 0.0, 53.29602465560943], 
actual action is [-8.5, 18.0], 
sim time next is 3738900.0000, 
raw observation next is [-3.583333333333333, 72.0, 6.408333333333333, 264.1666666666667, 0.0, 0.0, -8.5, 23.62769821630227, 18.0, 20.27830502047869, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.24145299145299148, 0.72, 0.5825757575757575, 0.7337962962962964, 0.0, 0.0, 0.35833333333333334, 0.2362769821630227, 0.0, 0.32547214578267003, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:23:03,964] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.43485332e-12   9.69949034e-12   1.81060486e-10
   1.76866230e-10   5.29479971e-30   2.56288264e-28   1.74672668e-29
   2.68504062e-26], sum to 1.0000
[2017-11-02 11:23:04,012] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 44.33333333333334, 5.800000000000001, 240.0, 105.5, 783.0, 11.0, 11.1166065840594, 20.0, 22.74593109263993, 22.7, 1.0, 41.08062201396879], 
actual action is [1.0, 18], 
sim time next is 3680700.0000, 
raw observation next is [6.0, 44.66666666666666, 5.975, 240.0, 104.75, 779.5, 1.0, 11.20956391810474, 18.0, 23.05878206609077, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.48717948717948717, 0.44666666666666655, 0.5431818181818181, 0.6666666666666666, 0.2771164021164021, 0.7795, 0.5166666666666667, 0.1120956391810474, 0.0, 0.7226831522986815, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0112. 
=============================================
[2017-11-02 11:23:05,703] A3C_AGENT_WORKER-Thread-3 INFO:Local step 38500, global step 614189: loss 2.6712
[2017-11-02 11:23:09,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.32224674e-11   6.25079363e-11   7.08781145e-10
   2.22728599e-10   6.83933234e-25   5.11662520e-24   1.24477493e-25
   1.05301137e-24], sum to 1.0000
[2017-11-02 11:23:09,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 63.33333333333334, 6.533333333333334, 246.6666666666667, 118.3333333333333, 827.8333333333334, -6.75, 16.28928060083151, 18.0, 22.13706586947255, 22.7, 1.0, 0.0], 
actual action is [-6.666666666666667, 18], 
sim time next is 3759900.0000, 
raw observation next is [-1.583333333333333, 62.91666666666666, 6.491666666666666, 245.8333333333333, 118.6666666666667, 828.4166666666666, -6.666666666666667, 16.49516990721846, 18.0, 22.05930017178217, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.29273504273504275, 0.6291666666666665, 0.5901515151515151, 0.6828703703703702, 0.31393298059964736, 0.8284166666666666, 0.3888888888888889, 0.1649516990721846, 0.0, 0.5799000245403099, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:23:11,433] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   9.40801866e-14   2.15667382e-13   4.24153377e-12
   1.18641728e-12   5.72205523e-29   1.03451558e-27   1.86426723e-29
   1.37642494e-28], sum to 1.0000
[2017-11-02 11:23:11,443] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333334, 60.0, 6.4, 233.3333333333333, 113.5, 811.0, -5.416666666666667, 13.6538704785288, 18.0, 22.34581214319441, 22.7, 1.0, 0.0], 
actual action is [-5.333333333333333, 18], 
sim time next is 3764700.0000, 
raw observation next is [-0.25, 60.0, 6.425, 232.5, 112.75, 807.5, -5.333333333333333, 13.75414823972672, 18.0, 22.32792967413051, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.3269230769230769, 0.6, 0.5840909090909091, 0.6458333333333334, 0.29828042328042326, 0.8075, 0.41111111111111115, 0.13754148239726718, 0.0, 0.6182756677329299, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0138. 
=============================================
[2017-11-02 11:23:12,507] A3C_AGENT_WORKER-Thread-17 INFO:Local step 38500, global step 615702: loss 1.2480
[2017-11-02 11:23:12,624] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-66.86968231]
 [-66.11954498]
 [-66.87421417]
 [-68.30789948]
 [-69.42169952]], R is [[-66.93849945]
 [-67.26911163]
 [-67.59642029]
 [-67.92045593]
 [-68.24124908]].
[2017-11-02 11:23:13,235] A3C_AGENT_WORKER-Thread-4 INFO:Local step 38500, global step 615863: loss 1.4176
[2017-11-02 11:23:18,530] A3C_AGENT_WORKER-Thread-9 INFO:Local step 38500, global step 616978: loss 2.1466
[2017-11-02 11:23:18,689] A3C_AGENT_WORKER-Thread-5 INFO:Local step 38500, global step 617016: loss 7.5783
[2017-11-02 11:23:20,696] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.88983039e-13   7.64234054e-13   6.63752994e-12
   5.54755634e-12   6.07628358e-31   1.43843675e-28   1.57078611e-30
   1.18038050e-29], sum to 1.0000
[2017-11-02 11:23:20,705] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 48.0, 6.241666666666667, 249.1666666666667, 98.08333333333334, 754.9166666666667, -3.0, 11.3512190987294, 18.0, 23.04983974159115, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 3855600.0000, 
raw observation next is [2.0, 48.0, 6.2, 250.0, 96.5, 749.5, -3.0, 11.27881083216043, 18.0, 23.07555896604803, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.38461538461538464, 0.48, 0.5636363636363636, 0.6944444444444444, 0.2552910052910053, 0.7495, 0.45, 0.1127881083216043, 0.0, 0.7250798522925754, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0113. 
=============================================
[2017-11-02 11:23:24,582] A3C_AGENT_WORKER-Thread-12 INFO:Local step 38500, global step 618228: loss 3.9634
[2017-11-02 11:23:24,584] A3C_AGENT_WORKER-Thread-2 INFO:Local step 38500, global step 618228: loss 1.8519
[2017-11-02 11:23:26,179] A3C_AGENT_WORKER-Thread-10 INFO:Local step 39000, global step 618552: loss -205.4692
[2017-11-02 11:23:28,395] A3C_AGENT_WORKER-Thread-14 INFO:Local step 38500, global step 618892: loss -60.0753
[2017-11-02 11:23:30,491] A3C_AGENT_WORKER-Thread-13 INFO:Local step 38500, global step 619248: loss 18.7584
[2017-11-02 11:23:31,039] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   5.98773071e-12   4.80742890e-10   1.93379446e-09
   6.64861410e-09   1.09462365e-33   3.40557499e-31   3.61760179e-32
   3.38214514e-29], sum to 1.0000
[2017-11-02 11:23:31,063] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 56.66666666666667, 2.266666666666667, 313.3333333333334, 0.0, 0.0, -6.0, 27.32849271105274, 18.0, 20.50143461565062, 21.5, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 3882300.0000, 
raw observation next is [-1.0, 57.08333333333333, 2.308333333333334, 311.6666666666666, 0.0, 0.0, -6.0, 28.03156468605594, 18.0, 20.42659611986829, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.3076923076923077, 0.5708333333333333, 0.20984848484848492, 0.8657407407407405, 0.0, 0.0, 0.4, 0.28031564686055943, 0.0, 0.3466565885526128, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:23:31,303] A3C_AGENT_WORKER-Thread-16 INFO:Local step 39000, global step 619419: loss 7.3884
[2017-11-02 11:23:34,428] A3C_AGENT_WORKER-Thread-15 INFO:Local step 38500, global step 620047: loss 11.6406
[2017-11-02 11:23:36,043] A3C_AGENT_WORKER-Thread-6 INFO:Local step 39000, global step 620368: loss 63.2274
[2017-11-02 11:23:36,050] A3C_AGENT_WORKER-Thread-11 INFO:Local step 38500, global step 620370: loss 2.9628
[2017-11-02 11:23:38,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   5.37694184e-37   9.41317968e-35   1.13405347e-32
   2.34976193e-32   1.49651302e-03   6.69790665e-03   3.67047377e-02
   9.55100894e-01], sum to 1.0000
[2017-11-02 11:23:38,396] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.666666666666666, 47.66666666666666, 3.766666666666667, 350.0, 0.0, 0.0, -12.58333333333333, 27.61633493708306, 18.0, 20.45020467593422, 21.5, 0.0, 0.0], 
actual action is [-2.666666666666666, 23.0], 
sim time next is 3966300.0000, 
raw observation next is [-7.75, 48.0, 3.725, 350.0, 0.0, 0.0, -2.666666666666666, 22.71654955560902, 23.0, 20.3168170217032, 21.5, 0.0, 101.2092834791209], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.1346153846153846, 0.48, 0.3386363636363636, 0.9722222222222222, 0.0, 0.0, 0.4555555555555556, 0.2271654955560902, 0.7142857142857143, 0.3309738602433145, 0.5, 0.0, 1.19069745269554], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:23:40,300] A3C_AGENT_WORKER-Thread-8 INFO:Local step 39000, global step 621165: loss 41.7275
[2017-11-02 11:23:43,135] A3C_AGENT_WORKER-Thread-7 INFO:Local step 39000, global step 621704: loss 52.1558
[2017-11-02 11:23:47,754] A3C_AGENT_WORKER-Thread-3 INFO:Local step 39000, global step 622486: loss 11.0851
[2017-11-02 11:23:49,542] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.91337535e-20   4.83678263e-23   6.72382058e-23   3.69072738e-20
   2.15522171e-21   4.69494648e-02   5.10690324e-02   9.01360989e-01
   6.20580453e-04], sum to 1.0000
[2017-11-02 11:23:49,608] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.083333333333333, 38.24999999999999, 3.933333333333333, 10.0, 38.58333333333333, 321.9166666666666, 0.0, 9.731504378814353, 22.0, 23.48821321886691, 22.7, 1.0, 20.44042984800312], 
actual action is [-0.08333333333333304, 24.0], 
sim time next is 3949800.0000, 
raw observation next is [-5.166666666666667, 38.5, 3.766666666666667, 10.0, 34.66666666666666, 291.3333333333333, -0.08333333333333304, 10.06071387380515, 24.0, 23.4355635950414, 22.7, 1.0, 22.37572818457313], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.20085470085470084, 0.385, 0.34242424242424246, 0.027777777777777776, 0.09171075837742503, 0.29133333333333333, 0.4986111111111111, 0.10060713873805151, 0.8571428571428571, 0.7765090850059144, 0.6714285714285714, 1.0, 0.263243860994978], 
reward next is -0.2470. 
=============================================
[2017-11-02 11:23:54,489] A3C_AGENT_WORKER-Thread-4 INFO:Local step 39000, global step 623679: loss -84.2280
[2017-11-02 11:23:57,430] A3C_AGENT_WORKER-Thread-17 INFO:Local step 39000, global step 624200: loss 23.1553
[2017-11-02 11:23:58,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   9.75681992e-13   3.19688304e-11   4.77830620e-09
   1.10811493e-09   1.92305366e-32   8.29640140e-30   1.12014936e-27
   1.02581071e-28], sum to 1.0000
[2017-11-02 11:23:58,585] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 2.433333333333334, 346.6666666666666, 0.0, 0.0, 3.0, 19.43692502841299, 20.0, 20.90959001705125, 21.5, 0.0, 62.19988547474341], 
actual action is [-7.0, 18], 
sim time next is 3894300.0000, 
raw observation next is [-2.0, 65.0, 2.35, 347.5, 0.0, 0.0, -7.0, 20.7381904429325, 18.0, 20.93593336185509, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.28205128205128205, 0.65, 0.21363636363636365, 0.9652777777777778, 0.0, 0.0, 0.38333333333333336, 0.207381904429325, 0.0, 0.41941905169358407, 0.5, 0.0, 0.0], 
reward next is -0.0806. 
=============================================
[2017-11-02 11:24:01,528] A3C_AGENT_WORKER-Thread-9 INFO:Local step 39000, global step 625015: loss -18.5124
[2017-11-02 11:24:01,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   9.88871636e-13   6.23920945e-13   6.12951842e-11
   5.95165930e-12   2.55117933e-19   4.49882597e-19   4.95895356e-18
   3.70551711e-21], sum to 1.0000
[2017-11-02 11:24:01,726] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 37.0, 3.475, 97.5, 92.25, 740.0, -9.0, 9.947430856614362, 18.0, 23.36453976848014, 22.7, 1.0, 0.0], 
actual action is [-9.0, 18], 
sim time next is 3943200.0000, 
raw observation next is [-4.0, 36.66666666666667, 3.6, 126.6666666666667, 90.83333333333334, 734.6666666666667, -9.0, 10.11915310545, 18.0, 23.38206368834241, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.23076923076923078, 0.3666666666666667, 0.32727272727272727, 0.35185185185185197, 0.240299823633157, 0.7346666666666667, 0.35, 0.1011915310545, 0.0, 0.7688662411917727, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0101. 
=============================================
[2017-11-02 11:24:01,956] A3C_AGENT_WORKER-Thread-5 INFO:Local step 39000, global step 625097: loss -8.6452
[2017-11-02 11:24:07,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-73.61717987]
 [-74.19021606]
 [-73.13519287]
 [-71.70545959]
 [-72.78479004]], R is [[-73.578125  ]
 [-72.93000793]
 [-72.7275238 ]
 [-72.60826111]
 [-72.49007416]].
[2017-11-02 11:24:09,774] A3C_AGENT_WORKER-Thread-12 INFO:Local step 39000, global step 626363: loss -24.1140
[2017-11-02 11:24:09,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   5.67149236e-12   5.50572912e-12   4.40481845e-10
   1.42081319e-10   2.28976511e-15   2.04970860e-14   3.00771777e-14
   6.36021555e-17], sum to 1.0000
[2017-11-02 11:24:10,013] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.583333333333333, 49.0, 3.391666666666667, 151.6666666666667, 111.9166666666667, 768.0833333333334, -1.666666666666667, 11.80119735839127, 22.0, 22.79215061873573, 22.7, 1.0, 23.41142223699477], 
actual action is [-11.583333333333332, 18], 
sim time next is 3925800.0000, 
raw observation next is [-6.5, 49.0, 3.35, 180.0, 113.0, 775.0, -11.58333333333333, 12.09574471622733, 18.0, 22.85763483221089, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.43478260869565216, 0.16666666666666666, 0.49, 0.30454545454545456, 0.5, 0.29894179894179895, 0.775, 0.3069444444444445, 0.1209574471622733, 0.0, 0.6939478331729845, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0121. 
=============================================
[2017-11-02 11:24:11,654] A3C_AGENT_WORKER-Thread-10 INFO:Local step 39500, global step 626711: loss -47.6447
[2017-11-02 11:24:12,765] A3C_AGENT_WORKER-Thread-14 INFO:Local step 39000, global step 626903: loss -93.2473
[2017-11-02 11:24:13,176] A3C_AGENT_WORKER-Thread-2 INFO:Local step 39000, global step 626981: loss 2.7249
[2017-11-02 11:24:15,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 39500, global step 627422: loss 148.4461
[2017-11-02 11:24:16,174] A3C_AGENT_WORKER-Thread-15 INFO:Local step 39000, global step 627503: loss 0.9596
[2017-11-02 11:24:16,480] A3C_AGENT_WORKER-Thread-13 INFO:Local step 39000, global step 627553: loss 4.9163
[2017-11-02 11:24:19,276] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.25908777e-02   9.70154166e-01   1.64115801e-02
   8.43330345e-04], sum to 1.0000
[2017-11-02 11:24:19,457] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-12.5, 60.5, 1.575, 270.0, 69.75, 333.0, -7.66666666666667, 16.50172446627871, 25.0, 21.22704524545276, 22.7, 1.0, 61.47742956756971], 
actual action is [-7.5, 25], 
sim time next is 4004400.0000, 
raw observation next is [-12.33333333333333, 59.66666666666667, 1.4, 240.0, 77.5, 370.0, -7.5, 15.49387070856157, 25.0, 21.44692434929175, 22.7, 1.0, 61.03216482270999], 
processed observation next is [0.5, 0.34782608695652173, 0.01709401709401717, 0.5966666666666667, 0.12727272727272726, 0.6666666666666666, 0.20502645502645503, 0.37, 0.375, 0.1549387070856157, 1.0, 0.4924177641845355, 0.6714285714285714, 1.0, 0.7180254685024704], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:24:19,981] A3C_AGENT_WORKER-Thread-11 INFO:Local step 39000, global step 628129: loss -182.5445
[2017-11-02 11:24:22,942] A3C_AGENT_WORKER-Thread-6 INFO:Local step 39500, global step 628679: loss 150.2749
[2017-11-02 11:24:23,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.45180023
  0.42903709  0.11375986  0.00540276], sum to 1.0000
[2017-11-02 11:24:23,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-12.5, 60.5, 1.575, 270.0, 69.75, 333.0, -7.66666666666667, 16.0005346232574, 25.0, 21.330203186544, 22.7, 1.0, 61.37373935262138], 
actual action is [-7.5, 25], 
sim time next is 4004400.0000, 
raw observation next is [-12.33333333333333, 59.66666666666667, 1.4, 240.0, 77.5, 370.0, -7.5, 15.0247318088589, 25.0, 21.54699869881555, 22.7, 1.0, 60.96023604902015], 
processed observation next is [0.5, 0.34782608695652173, 0.01709401709401717, 0.5966666666666667, 0.12727272727272726, 0.6666666666666666, 0.20502645502645503, 0.37, 0.375, 0.15024731808858902, 1.0, 0.5067140998307929, 0.6714285714285714, 1.0, 0.7171792476355312], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:24:23,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.46773738e-09   3.91686961e-10   4.67101247e-09   1.30379163e-07
   1.90123657e-07   3.44159850e-03   2.71993607e-01   7.05306381e-02
   6.54033780e-01], sum to 1.0000
[2017-11-02 11:24:23,461] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.0, 41.0, 2.6, 126.6666666666667, 0.0, 0.0, -1.0, 15.94784058092331, 25.0, 21.24620471596112, 22.7, 1.0, 76.05912915741432], 
actual action is [-1.0, 25], 
sim time next is 3954300.0000, 
raw observation next is [-6.0, 41.0, 2.725, 155.8333333333333, 0.0, 0.0, -1.0, 14.57967148753454, 25.0, 21.36369127477041, 22.7, 1.0, 70.96189633221475], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.1794871794871795, 0.41, 0.24772727272727274, 0.43287037037037024, 0.0, 0.0, 0.48333333333333334, 0.1457967148753454, 1.0, 0.48052732496720146, 0.6714285714285714, 1.0, 0.8348458392025264], 
reward next is -0.7659. 
=============================================
[2017-11-02 11:24:25,824] A3C_AGENT_WORKER-Thread-8 INFO:Local step 39500, global step 629192: loss 13.5221
[2017-11-02 11:24:26,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-23.05630493]
 [-22.21089935]
 [-21.96632767]
 [-21.68234634]
 [-22.0096283 ]], R is [[-23.58425331]
 [-24.34841156]
 [-25.10492706]
 [-25.85387802]
 [-26.59533882]].
[2017-11-02 11:24:27,293] A3C_AGENT_WORKER-Thread-7 INFO:Local step 39500, global step 629494: loss -21.3681
[2017-11-02 11:24:33,340] A3C_AGENT_WORKER-Thread-3 INFO:Local step 39500, global step 630565: loss 60.5621
[2017-11-02 11:24:33,714] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99999881e-01   2.98536473e-10   9.78027326e-10   1.67559264e-07
   1.65683502e-08   3.41218992e-18   7.57489653e-18   7.69770638e-18
   2.27494405e-17], sum to 1.0000
[2017-11-02 11:24:33,800] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.833333333333333, 34.66666666666667, 0.5166666666666666, 21.66666666666666, 61.33333333333334, 312.6666666666667, -8.916666666666668, 14.58594396725922, 18.0, 22.12022673891438, 22.7, 1.0, 0.0], 
actual action is [-8.833333333333332, 18], 
sim time next is 4090500.0000, 
raw observation next is [-3.75, 35.0, 0.775, 32.5, 69.0, 351.75, -8.833333333333332, 15.3277317709911, 18.0, 22.25079298970393, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.23717948717948717, 0.35, 0.07045454545454545, 0.09027777777777778, 0.18253968253968253, 0.35175, 0.3527777777777778, 0.15327731770991102, 0.0, 0.6072561413862755, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:24:35,222] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-32.21747971]
 [-32.28684235]
 [-32.84406662]
 [-34.13018417]
 [-34.55997086]], R is [[-33.63106537]
 [-33.89576721]
 [-34.55680847]
 [-35.21123886]
 [-35.85912704]].
[2017-11-02 11:24:38,008] A3C_AGENT_WORKER-Thread-4 INFO:Local step 39500, global step 631356: loss 69.1062
[2017-11-02 11:24:41,682] A3C_AGENT_WORKER-Thread-17 INFO:Local step 39500, global step 631944: loss -88.0936
[2017-11-02 11:24:44,581] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99933481e-01   5.93486185e-08   1.04261836e-07   5.59653963e-05
   2.38053190e-06   2.78516268e-06   3.02345006e-06   1.30330966e-06
   9.18056912e-07], sum to 1.0000
[2017-11-02 11:24:44,597] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 38.0, 3.1, 130.0, 98.0, 574.0, 1.916666666666667, 15.03951450131497, 21.5, 22.21115667811815, 22.7, 1.0, 19.68687323819789], 
actual action is [-8.0, 18], 
sim time next is 4093500.0000, 
raw observation next is [-2.916666666666667, 37.74999999999999, 2.966666666666667, 129.1666666666667, 99.0, 591.5, -8.0, 15.4600939873856, 18.0, 22.22545985012519, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.2585470085470085, 0.37749999999999995, 0.2696969696969697, 0.35879629629629645, 0.2619047619047619, 0.5915, 0.36666666666666664, 0.154600939873856, 0.0, 0.6036371214464558, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:24:45,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   6.37252404e-11   4.47980091e-11   6.05289330e-09
   4.66563843e-10   1.34954305e-16   3.46928813e-16   1.38648825e-16
   5.32731148e-17], sum to 1.0000
[2017-11-02 11:24:45,083] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 35.0, 3.475, 182.5, 93.58333333333334, 587.5, -1.0, 9.733598125601533, 18.0, 23.44334560004483, 22.7, 1.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 4118400.0000, 
raw observation next is [4.0, 35.0, 3.6, 180.0, 93.5, 566.0, -1.0, 9.715382387007631, 18.0, 23.45456766513334, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.4358974358974359, 0.35, 0.32727272727272727, 0.5, 0.24735449735449735, 0.566, 0.48333333333333334, 0.09715382387007632, 0.0, 0.7792239521619057, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0097. 
=============================================
[2017-11-02 11:24:46,562] A3C_AGENT_WORKER-Thread-5 INFO:Local step 39500, global step 632816: loss -42.2223
[2017-11-02 11:24:47,883] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-70.66229248]
 [-70.13134766]
 [-70.55016327]
 [-71.72719574]
 [-70.7635498 ]], R is [[-70.35081482]
 [-69.67837524]
 [-69.01794434]
 [-68.94337463]
 [-69.02825165]].
[2017-11-02 11:24:49,215] A3C_AGENT_WORKER-Thread-9 INFO:Local step 39500, global step 633362: loss 200.4255
[2017-11-02 11:24:52,741] A3C_AGENT_WORKER-Thread-10 INFO:Local step 40000, global step 634050: loss 44.3781
[2017-11-02 11:24:54,404] A3C_AGENT_WORKER-Thread-16 INFO:Local step 40000, global step 634362: loss 3.4362
[2017-11-02 11:24:56,182] A3C_AGENT_WORKER-Thread-12 INFO:Local step 39500, global step 634741: loss -16.8928
[2017-11-02 11:24:58,057] A3C_AGENT_WORKER-Thread-2 INFO:Local step 39500, global step 635165: loss -40.7520
[2017-11-02 11:24:59,403] A3C_AGENT_WORKER-Thread-14 INFO:Local step 39500, global step 635441: loss -35.8345
[2017-11-02 11:25:01,562] A3C_AGENT_WORKER-Thread-13 INFO:Local step 39500, global step 635852: loss 4.1511
[2017-11-02 11:25:02,550] A3C_AGENT_WORKER-Thread-15 INFO:Local step 39500, global step 636022: loss 10.1776
[2017-11-02 11:25:03,831] A3C_AGENT_WORKER-Thread-6 INFO:Local step 40000, global step 636254: loss -15.5838
[2017-11-02 11:25:06,329] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-42.97519684]
 [-41.97407532]
 [-42.3480835 ]
 [-43.22048187]
 [-42.69080353]], R is [[-42.1275177 ]
 [-41.71789169]
 [-41.31214523]
 [-40.91027069]
 [-40.94323349]].
[2017-11-02 11:25:06,696] A3C_AGENT_WORKER-Thread-8 INFO:Local step 40000, global step 636774: loss 48.3630
[2017-11-02 11:25:07,045] A3C_AGENT_WORKER-Thread-11 INFO:Local step 39500, global step 636844: loss -4.2268
[2017-11-02 11:25:07,673] A3C_AGENT_WORKER-Thread-7 INFO:Local step 40000, global step 636978: loss -18.8605
[2017-11-02 11:25:09,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.03663988e-05   2.45641396e-10   2.27700969e-09   1.08579982e-07
   9.93228610e-08   7.69953072e-01   8.34886730e-02   1.39569953e-01
   6.97767874e-03], sum to 1.0000
[2017-11-02 11:25:09,799] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-4.583333333333333, 50.25, 2.308333333333334, 350.0, 84.33333333333333, 447.3333333333333, 0.333333333333333, 14.67847245045457, 20.5, 21.49831970269075, 22.7, 1.0, 42.40460142764604], 
actual action is [0.41666666666666696, 21.0], 
sim time next is 4177800.0000, 
raw observation next is [-4.5, 49.5, 2.35, 350.0, 92.0, 488.0, 0.416666666666667, 14.60959481035953, 21.0, 21.64003418634569, 22.7, 1.0, 39.50984257697936], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.21794871794871795, 0.495, 0.21363636363636365, 0.9722222222222222, 0.24338624338624337, 0.488, 0.5069444444444444, 0.1460959481035953, 0.42857142857142855, 0.5200048837636702, 0.6714285714285714, 1.0, 0.46482167737622776], 
reward next is -0.4329. 
=============================================
[2017-11-02 11:25:11,640] A3C_AGENT_WORKER-Thread-3 INFO:Local step 40000, global step 637958: loss 13.7272
[2017-11-02 11:25:15,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-76.79276276]
 [-76.67803192]
 [-77.43650818]
 [-80.03949738]
 [-78.55818939]], R is [[-79.31843567]
 [-79.5252533 ]
 [-79.73000336]
 [-79.93270111]
 [-80.13337708]].
[2017-11-02 11:25:16,242] A3C_AGENT_WORKER-Thread-4 INFO:Local step 40000, global step 639058: loss 0.3014
[2017-11-02 11:25:16,991] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  4.75044377e-33   6.36210773e-26   4.18586281e-24   5.00612140e-22
   1.17495018e-21   1.08668245e-02   2.55811233e-02   8.32725286e-01
   1.30826727e-01], sum to 1.0000
[2017-11-02 11:25:17,056] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [4.166666666666667, 71.33333333333333, 5.633333333333333, 216.6666666666667, 0.0, 0.0, -0.791666666666667, 27.42781521442248, 18.0, 20.42189762117283, 21.5, 0.0, 0.0], 
actual action is [9.166666666666668, 20.0], 
sim time next is 4329900.0000, 
raw observation next is [4.125, 71.25, 5.624999999999999, 217.5, 0.0, 0.0, 9.166666666666668, 24.66717001396957, 20.0, 20.32443557845458, 21.5, 0.0, 62.59655644778972], 
processed observation next is [0.0, 0.08695652173913043, 0.4391025641025641, 0.7125, 0.5113636363636362, 0.6041666666666666, 0.0, 0.0, 0.6527777777777779, 0.24667170013969572, 0.2857142857142857, 0.3320622254935114, 0.5, 0.0, 0.7364300758563497], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:17,559] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   6.57248905e-15   1.87598824e-14   9.37560034e-13
   1.52730020e-12   6.71876916e-27   3.45524404e-26   9.05373294e-25
   1.97331013e-26], sum to 1.0000
[2017-11-02 11:25:17,576] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.95, 57.75, 6.850000000000001, 250.0, 218.75, 468.0, 1.966666666666667, 19.23780588177076, 18.0, 21.91975707627028, 22.7, 1.0, 0.0], 
actual action is [1.9500000000000002, 18], 
sim time next is 4285200.0000, 
raw observation next is [6.933333333333334, 58.00000000000001, 6.9, 250.0, 222.1666666666667, 440.3333333333334, 1.95, 19.26508905531729, 18.0, 21.91713409685557, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.5111111111111111, 0.5800000000000001, 0.6272727272727273, 0.6944444444444444, 0.5877425044091712, 0.4403333333333334, 0.5325, 0.1926508905531729, 0.0, 0.5595905852650814, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:19,215] A3C_AGENT_WORKER-Thread-17 INFO:Local step 40000, global step 639770: loss -109.3921
[2017-11-02 11:25:19,518] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99999642e-01   1.98601260e-10   9.73500835e-10   1.30192930e-07
   2.28579395e-07   1.61772939e-11   4.69679538e-11   4.93798114e-10
   5.67268316e-11], sum to 1.0000
[2017-11-02 11:25:19,582] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 43.33333333333334, 4.85, 251.6666666666667, 178.0, 238.6666666666666, 7.0, 16.67095939791403, 24.0, 21.8452829329906, 22.7, 1.0, 21.00268238293125], 
actual action is [7.0, 19.0], 
sim time next is 4200900.0000, 
raw observation next is [2.0, 43.66666666666666, 4.975, 250.8333333333333, 175.75, 276.0833333333333, 7.0, 15.62709845688676, 19.0, 21.92151157851592, 22.7, 1.0, 46.49818437837671], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.38461538461538464, 0.4366666666666666, 0.4522727272727272, 0.6967592592592591, 0.46494708994708994, 0.2760833333333333, 0.6166666666666667, 0.1562709845688676, 0.14285714285714285, 0.5602159397879883, 0.6714285714285714, 1.0, 0.5470374632750201], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:19,685] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99950767e-01   6.29310577e-08   4.13176878e-07   1.86254911e-05
   3.00243628e-05   2.40858489e-09   7.59768071e-09   6.46045564e-08
   2.35199256e-08], sum to 1.0000
[2017-11-02 11:25:19,704] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.466666666666667, 61.33333333333334, 6.600000000000001, 253.3333333333333, 31.66666666666666, 282.6666666666666, 1.499999999999999, 18.56153887252624, 18.0, 22.00011221096173, 22.7, 1.0, 0.0], 
actual action is [1.4666666666666668, 18], 
sim time next is 4296300.0000, 
raw observation next is [6.433333333333333, 61.66666666666666, 6.549999999999999, 251.6666666666667, 27.83333333333334, 255.3333333333334, 1.466666666666667, 18.83647901741525, 18.0, 21.96022649565423, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4982905982905983, 0.6166666666666666, 0.5954545454545453, 0.6990740740740742, 0.07363315696649031, 0.2553333333333334, 0.5244444444444445, 0.1883647901741525, 0.0, 0.5657466422363184, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:20,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0925611
  0.04847059  0.75843906  0.10052933], sum to 1.0000
[2017-11-02 11:25:20,134] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.083333333333333, 50.33333333333333, 2.558333333333333, 341.6666666666666, 0.0, 0.0, 2.0, 21.92711881548535, 20.0, 20.6833055806115, 21.5, 0.0, 54.86188071159822], 
actual action is [1.916666666666667, 22.0], 
sim time next is 4162200.0000, 
raw observation next is [-3.166666666666667, 50.66666666666667, 2.516666666666667, 343.3333333333334, 0.0, 0.0, 1.916666666666667, 21.5904983160689, 22.0, 20.6873617949324, 21.5, 0.0, 34.87294701369201], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.25213675213675213, 0.5066666666666667, 0.22878787878787882, 0.9537037037037039, 0.0, 0.0, 0.5319444444444444, 0.21590498316068898, 0.5714285714285714, 0.3839088278474857, 0.5, 0.0, 0.4102699648669649], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:23,448] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999762e-01   1.16076282e-09   6.63057875e-09   1.22794887e-07
   1.66880511e-07   2.71174026e-19   4.86929122e-19   9.20254975e-18
   6.75374203e-19], sum to 1.0000
[2017-11-02 11:25:23,464] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 5.7, 240.0, 0.0, 0.0, 8.0, 15.00051286010063, 22.0, 21.57914016106168, 21.5, 0.0, 39.77841545222763], 
actual action is [-2.0, 18], 
sim time next is 4251900.0000, 
raw observation next is [3.0, 45.33333333333334, 5.566666666666666, 239.1666666666667, 0.0, 0.0, -2.0, 16.34044106867035, 18.0, 21.68320238317547, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.41025641025641024, 0.4533333333333334, 0.506060606060606, 0.664351851851852, 0.0, 0.0, 0.4666666666666667, 0.16340441068670353, 0.0, 0.5261717690250671, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:25:24,570] A3C_AGENT_WORKER-Thread-5 INFO:Local step 40000, global step 640851: loss -4.6249
[2017-11-02 11:25:26,844] A3C_AGENT_WORKER-Thread-10 INFO:Local step 40500, global step 641258: loss 2.1383
[2017-11-02 11:25:27,022] A3C_AGENT_WORKER-Thread-9 INFO:Local step 40000, global step 641291: loss 16.4406
[2017-11-02 11:25:27,727] A3C_AGENT_WORKER-Thread-16 INFO:Local step 40500, global step 641429: loss 3.1768
[2017-11-02 11:25:29,821] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99999762e-01   3.55940916e-10   2.27599495e-09   1.00682101e-07
   6.85419863e-08   3.70209152e-09   1.09443632e-09   1.01561932e-08
   1.05132479e-10], sum to 1.0000
[2017-11-02 11:25:29,885] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.65, 71.33333333333333, 5.175000000000001, 224.1666666666667, 0.0, 0.0, 0.7000000000000002, 16.42929115923236, 18.0, 22.22876381973957, 21.5, 0.0, 0.0], 
actual action is [0.6500000000000004, 18], 
sim time next is 4304400.0000, 
raw observation next is [5.6, 71.66666666666667, 5.1, 223.3333333333333, 0.0, 0.0, 0.6500000000000004, 16.90149976047874, 18.0, 22.1425431691463, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.47692307692307695, 0.7166666666666667, 0.4636363636363636, 0.6203703703703702, 0.0, 0.0, 0.5108333333333334, 0.1690149976047874, 0.0, 0.5917918813066143, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:25:37,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 40000, global step 643526: loss 13.4319
[2017-11-02 11:25:37,440] A3C_AGENT_WORKER-Thread-2 INFO:Local step 40000, global step 643552: loss 52.2763
[2017-11-02 11:25:37,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.73491540e-14   4.83481609e-17   9.93494142e-17   1.43479199e-14
   2.74076416e-14   1.28056198e-01   3.97256874e-02   8.30913186e-01
   1.30487129e-03], sum to 1.0000
[2017-11-02 11:25:37,652] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [0.3333333333333333, 31.66666666666667, 2.1, 316.6666666666667, 118.8333333333333, 826.1666666666666, 5.166666666666667, 12.67151313829721, 20.0, 22.55315292006374, 22.7, 1.0, 26.64159810772389], 
actual action is [5.333333333333333, 22.0], 
sim time next is 4189500.0000, 
raw observation next is [0.5, 31.25, 2.1, 315.0, 118.75, 828.25, 5.333333333333333, 12.65213884775864, 22.0, 22.54191065566209, 22.7, 1.0, 18.2196419440742], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.34615384615384615, 0.3125, 0.19090909090909092, 0.875, 0.31415343915343913, 0.82825, 0.5888888888888889, 0.1265213884775864, 0.5714285714285714, 0.6488443793802985, 0.6714285714285714, 1.0, 0.21434872875381414], 
reward next is -0.2056. 
=============================================
[2017-11-02 11:25:37,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 40000, global step 643606: loss -16.6910
[2017-11-02 11:25:38,189] A3C_AGENT_WORKER-Thread-6 INFO:Local step 40500, global step 643688: loss 1.5357
[2017-11-02 11:25:39,920] A3C_AGENT_WORKER-Thread-8 INFO:Local step 40500, global step 644065: loss 0.3728
[2017-11-02 11:25:39,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   4.52667851e-12   2.00208513e-11   1.11078979e-09
   4.91903129e-10   1.04673251e-15   5.16118509e-16   2.32256095e-15
   1.16309866e-17], sum to 1.0000
[2017-11-02 11:25:40,004] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.350000000000001, 73.0, 4.783333333333333, 220.0, 0.0, 0.0, 0.375, 13.55407666539364, 18.0, 22.53355218933211, 21.5, 0.0, 0.0], 
actual action is [0.3500000000000014, 18], 
sim time next is 4306500.0000, 
raw observation next is [5.325000000000001, 73.0, 4.774999999999999, 220.0, 0.0, 0.0, 0.3500000000000014, 14.39498509433761, 18.0, 22.40701240644617, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.4698717948717949, 0.73, 0.43409090909090897, 0.6111111111111112, 0.0, 0.0, 0.5058333333333334, 0.1439498509433761, 0.0, 0.6295732009208815, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:25:41,157] A3C_AGENT_WORKER-Thread-15 INFO:Local step 40000, global step 644337: loss 65.6259
[2017-11-02 11:25:42,101] A3C_AGENT_WORKER-Thread-13 INFO:Local step 40000, global step 644525: loss -21.8162
[2017-11-02 11:25:42,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   4.53978903e-35   5.64174243e-34   1.91182871e-31
   1.54324576e-31   7.32627273e-01   4.09053601e-02   2.26196736e-01
   2.70683435e-04], sum to 1.0000
[2017-11-02 11:25:42,365] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.0, 47.0, 4.266666666666667, 230.0, 0.0, 0.0, 6.0, 21.85663267278134, 20.0, 21.20874478178963, 21.5, 0.0, 19.2916670122565], 
actual action is [6.0, 21.0], 
sim time next is 4227900.0000, 
raw observation next is [1.0, 47.0, 4.308333333333333, 230.0, 0.0, 0.0, 6.0, 22.13762552141763, 21.0, 21.15392070257932, 21.5, 0.0, 13.242272725081], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.358974358974359, 0.47, 0.3916666666666666, 0.6388888888888888, 0.0, 0.0, 0.6, 0.22137625521417628, 0.42857142857142855, 0.4505601003684743, 0.5, 0.0, 0.15579144382448235], 
reward next is -0.1897. 
=============================================
[2017-11-02 11:25:45,287] A3C_AGENT_WORKER-Thread-7 INFO:Local step 40500, global step 645318: loss 15.0324
[2017-11-02 11:25:46,216] A3C_AGENT_WORKER-Thread-11 INFO:Local step 40000, global step 645603: loss -218.2557
[2017-11-02 11:25:47,665] A3C_AGENT_WORKER-Thread-3 INFO:Local step 40500, global step 646025: loss 1.0544
[2017-11-02 11:25:52,650] A3C_AGENT_WORKER-Thread-4 INFO:Local step 40500, global step 647215: loss 1.2469
[2017-11-02 11:25:53,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 40500, global step 647474: loss 0.7971
[2017-11-02 11:25:56,347] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.58421116e-07   4.91308438e-10   7.56043583e-09   2.41143539e-07
   2.92039800e-07   6.08263202e-02   5.12396581e-02   1.39279589e-01
   7.48653710e-01], sum to 1.0000
[2017-11-02 11:25:56,485] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.916666666666666, 67.83333333333334, 7.25, 268.3333333333333, 0.0, 0.0, -1.025, 19.04222153336796, 18.0, 20.77655873721328, 21.5, 0.0, 0.0], 
actual action is [8.916666666666666, 23.0], 
sim time next is 4424100.0000, 
raw observation next is [3.858333333333333, 67.91666666666666, 7.275, 269.1666666666667, 0.0, 0.0, 8.916666666666666, 14.0180117321433, 23.0, 20.70918710581718, 21.5, 0.0, 106.0961169628199], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.4322649572649573, 0.6791666666666666, 0.6613636363636364, 0.7476851851851852, 0.0, 0.0, 0.648611111111111, 0.140180117321433, 0.7142857142857143, 0.38702672940245414, 0.5, 0.0, 1.248189611327293], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:58,390] A3C_AGENT_WORKER-Thread-5 INFO:Local step 40500, global step 648771: loss 2.1407
[2017-11-02 11:25:58,500] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.20660540e-13   4.00356658e-12   1.35956121e-10
   2.05619716e-10   2.35483393e-26   1.38568811e-26   7.32458028e-26
   2.54088745e-24], sum to 1.0000
[2017-11-02 11:25:58,536] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.45, 75.83333333333334, 6.033333333333333, 201.6666666666667, 0.0, 0.0, -0.5250000000000004, 27.10735835295966, 18.0, 20.85449319904105, 21.5, 0.0, 0.0], 
actual action is [-0.5499999999999998, 18], 
sim time next is 4320900.0000, 
raw observation next is [4.425, 75.75, 6.05, 202.5, 0.0, 0.0, -0.5499999999999998, 27.49587025791846, 18.0, 20.79716945031872, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.4467948717948718, 0.7575, 0.5499999999999999, 0.5625, 0.0, 0.0, 0.49083333333333334, 0.27495870257918464, 0.0, 0.39959563575981705, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:25:59,869] A3C_AGENT_WORKER-Thread-9 INFO:Local step 40500, global step 649120: loss 0.2744
[2017-11-02 11:26:01,131] A3C_AGENT_WORKER-Thread-10 INFO:Local step 41000, global step 649408: loss 5.7337
[2017-11-02 11:26:04,574] A3C_AGENT_WORKER-Thread-16 INFO:Local step 41000, global step 650237: loss -285.6514
[2017-11-02 11:26:06,095] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99999285e-01   6.98705982e-09   4.67572470e-08   3.25223937e-07
   3.75497478e-07   1.46771749e-22   1.93777522e-22   4.81510448e-22
   1.99817562e-20], sum to 1.0000
[2017-11-02 11:26:06,152] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.683333333333334, 65.16666666666667, 5.966666666666667, 260.0, 0.0, 0.0, 1.741666666666665, 15.53731445986725, 18.0, 21.51777000577038, 21.5, 0.0, 0.0], 
actual action is [1.6833333333333336, 18], 
sim time next is 4410900.0000, 
raw observation next is [6.625, 65.25, 6.000000000000001, 260.0, 0.0, 0.0, 1.683333333333334, 15.68232174909186, 18.0, 21.49408188494261, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.5032051282051282, 0.6525, 0.5454545454545455, 0.7222222222222222, 0.0, 0.0, 0.5280555555555556, 0.1568232174909186, 0.0, 0.49915455499180134, 0.5, 0.0, 0.0], 
reward next is -0.0008. 
=============================================
[2017-11-02 11:26:09,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 40500, global step 651361: loss 1.1794
[2017-11-02 11:26:10,532] A3C_AGENT_WORKER-Thread-12 INFO:Local step 40500, global step 651639: loss 1.1515
[2017-11-02 11:26:11,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 40500, global step 651777: loss 0.2372
[2017-11-02 11:26:11,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   4.42291223e-13   1.69614832e-12   4.78680325e-11
   5.47220880e-11   5.34110898e-24   4.47534754e-24   1.74626573e-23
   1.47886403e-21], sum to 1.0000
[2017-11-02 11:26:11,362] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 7.516666666666667, 301.6666666666667, 0.0, 0.0, 5.0, 12.56372873766619, 25.0, 22.15573371443242, 21.5, 0.0, 36.03129048072955], 
actual action is [5.0, 20.0], 
sim time next is 4479300.0000, 
raw observation next is [0.0, 72.0, 7.174999999999999, 302.5, 0.0, 0.0, 5.0, 12.05468616670123, 20.0, 22.27951335089811, 21.5, 0.0, 42.60985537529995], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.3333333333333333, 0.72, 0.6522727272727272, 0.8402777777777778, 0.0, 0.0, 0.5833333333333334, 0.12054686166701231, 0.2857142857142857, 0.6113590501283015, 0.5, 0.0, 0.5012924161799994], 
reward next is -0.4512. 
=============================================
[2017-11-02 11:26:11,983] A3C_AGENT_WORKER-Thread-6 INFO:Local step 41000, global step 651934: loss 18.3414
[2017-11-02 11:26:13,307] A3C_AGENT_WORKER-Thread-13 INFO:Local step 40500, global step 652224: loss 0.1011
[2017-11-02 11:26:13,308] A3C_AGENT_WORKER-Thread-8 INFO:Local step 41000, global step 652224: loss -43.3075
[2017-11-02 11:26:15,719] A3C_AGENT_WORKER-Thread-15 INFO:Local step 40500, global step 652856: loss 3.5842
[2017-11-02 11:26:17,897] A3C_AGENT_WORKER-Thread-7 INFO:Local step 41000, global step 653449: loss -340.8875
[2017-11-02 11:26:21,098] A3C_AGENT_WORKER-Thread-11 INFO:Local step 40500, global step 654268: loss 7.6583
[2017-11-02 11:26:23,126] A3C_AGENT_WORKER-Thread-3 INFO:Local step 41000, global step 654747: loss 187.2400
[2017-11-02 11:26:26,404] A3C_AGENT_WORKER-Thread-17 INFO:Local step 41000, global step 655446: loss 108.2190
[2017-11-02 11:26:28,554] A3C_AGENT_WORKER-Thread-4 INFO:Local step 41000, global step 655937: loss 4.2924
[2017-11-02 11:26:33,311] A3C_AGENT_WORKER-Thread-5 INFO:Local step 41000, global step 656965: loss 8.3460
[2017-11-02 11:26:33,800] A3C_AGENT_WORKER-Thread-9 INFO:Local step 41000, global step 657067: loss -9.6604
[2017-11-02 11:26:33,923] A3C_AGENT_WORKER-Thread-10 INFO:Local step 41500, global step 657090: loss -39.9951
[2017-11-02 11:26:40,049] A3C_AGENT_WORKER-Thread-16 INFO:Local step 41500, global step 658499: loss 13.0245
[2017-11-02 11:26:43,625] A3C_AGENT_WORKER-Thread-2 INFO:Local step 41000, global step 659217: loss 17.9638
[2017-11-02 11:26:44,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999762e-01   2.16555537e-10   2.07731898e-09   5.94359300e-08
   8.69498038e-08   1.14537701e-16   4.08446599e-17   3.08837980e-16
   4.20123836e-14], sum to 1.0000
[2017-11-02 11:26:44,496] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.8666666666666667, 71.0, 4.566666666666666, 300.0, 0.0, 0.0, -5.85, 20.56559035038117, 18.0, 20.73274614824464, 21.5, 0.0, 0.0], 
actual action is [-5.866666666666667, 18], 
sim time next is 4512300.0000, 
raw observation next is [-0.8833333333333333, 71.0, 4.508333333333333, 300.0, 0.0, 0.0, -5.866666666666667, 21.97333537679783, 18.0, 20.70007789325171, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.3106837606837607, 0.71, 0.4098484848484848, 0.8333333333333334, 0.0, 0.0, 0.4022222222222222, 0.2197333537679783, 0.0, 0.38572541332167276, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:26:44,537] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.27813588e-15   3.10793160e-14   1.25325943e-12
   1.24555737e-12   1.00964624e-33   6.28033433e-34   3.71880568e-33
   7.16616950e-31], sum to 1.0000
[2017-11-02 11:26:44,569] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.9, 71.0, 4.449999999999999, 300.0, 0.0, 0.0, -5.883333333333333, 23.47161641810892, 18.0, 20.59406919929314, 21.5, 0.0, 0.0], 
actual action is [-5.9, 18], 
sim time next is 4512900.0000, 
raw observation next is [-0.9166666666666667, 71.0, 4.391666666666667, 300.0, 0.0, 0.0, -5.9, 24.90629583499497, 18.0, 20.46246837385914, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.30982905982905984, 0.71, 0.39924242424242423, 0.8333333333333334, 0.0, 0.0, 0.40166666666666667, 0.2490629583499497, 0.0, 0.35178119626559123, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:26:44,625] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99933243e-01   1.16401225e-07   9.00767077e-07   2.32800594e-05
   4.24387108e-05   1.08963505e-10   4.11689918e-11   3.84251547e-10
   2.93599705e-08], sum to 1.0000
[2017-11-02 11:26:44,669] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.625, 69.5, 0.0, 0.0, 0.0, 0.0, 3.416666666666667, 19.18962613957101, 23.0, 20.73554763514176, 21.5, 0.0, 73.20249505193853], 
actual action is [-6.625, 18.0], 
sim time next is 4594800.0000, 
raw observation next is [-1.666666666666667, 69.66666666666667, 0.0, 0.0, 0.0, 0.0, -6.625, 20.38506449078996, 18.0, 20.88005566302317, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.17391304347826086, 0.29059829059829057, 0.6966666666666668, 0.0, 0.0, 0.0, 0.0, 0.38958333333333334, 0.20385064490789961, 0.0, 0.4114365232890244, 0.5, 0.0, 0.0], 
reward next is -0.0886. 
=============================================
[2017-11-02 11:26:45,245] A3C_AGENT_WORKER-Thread-12 INFO:Local step 41000, global step 659575: loss 37.0473
[2017-11-02 11:26:46,286] A3C_AGENT_WORKER-Thread-6 INFO:Local step 41500, global step 659786: loss 29.7496
[2017-11-02 11:26:46,688] A3C_AGENT_WORKER-Thread-8 INFO:Local step 41500, global step 659872: loss 7.4297
[2017-11-02 11:26:47,754] A3C_AGENT_WORKER-Thread-14 INFO:Local step 41000, global step 660102: loss 1.2138
[2017-11-02 11:26:48,699] A3C_AGENT_WORKER-Thread-13 INFO:Local step 41000, global step 660329: loss -3.5625
[2017-11-02 11:26:49,600] A3C_AGENT_WORKER-Thread-15 INFO:Local step 41000, global step 660519: loss 30.4906
[2017-11-02 11:26:51,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   4.62909387e-13   1.27264154e-11   2.47163345e-10
   4.44668802e-10   7.76030902e-31   1.18558310e-30   1.34331417e-29
   1.19778660e-26], sum to 1.0000
[2017-11-02 11:26:51,572] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 2.325, 255.0, 0.0, 0.0, -3.0, 19.51472970179435, 18.0, 21.81641205470936, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4562400.0000, 
raw observation next is [2.0, 52.0, 2.066666666666667, 226.6666666666667, 0.0, 0.0, -3.0, 20.51911424932671, 18.0, 21.65949208922056, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.38461538461538464, 0.52, 0.1878787878787879, 0.6296296296296298, 0.0, 0.0, 0.45, 0.2051911424932671, 0.0, 0.5227845841743657, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:26:51,871] A3C_AGENT_WORKER-Thread-7 INFO:Local step 41500, global step 660977: loss 28.1843
[2017-11-02 11:26:52,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.78676902e-17   1.07611367e-16   8.18259069e-15
   2.05823348e-14   6.52301027e-37   8.92678779e-37   2.38128179e-35
   2.30173431e-32], sum to 1.0000
[2017-11-02 11:26:52,534] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 5.699999999999999, 339.9999999999999, 167.4166666666667, 2.5, -4.0, 15.06132628287813, 18.0, 22.74881998194607, 22.7, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 4720200.0000, 
raw observation next is [1.0, 72.0, 5.7, 340.0000000000001, 163.3333333333333, 2.0, -4.0, 15.31577957962437, 18.0, 22.71046844879226, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.358974358974359, 0.72, 0.5181818181818182, 0.9444444444444448, 0.43209876543209863, 0.002, 0.43333333333333335, 0.1531577957962437, 0.0, 0.6729240641131798, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:26:53,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99997377e-01   3.09954729e-10   1.36270550e-08   8.48289289e-07
   1.83976226e-06   2.83759823e-16   1.08600821e-16   2.87708928e-15
   1.96281689e-11], sum to 1.0000
[2017-11-02 11:26:53,161] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 78.75, 3.6, 332.5, 0.0, 0.0, -8.0, 24.700845525837, 18.0, 20.69974306964951, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 4747800.0000, 
raw observation next is [-3.0, 78.16666666666667, 3.6, 331.6666666666666, 0.0, 0.0, -8.0, 26.53799712890181, 18.0, 20.60175993476829, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2564102564102564, 0.7816666666666667, 0.32727272727272727, 0.9212962962962961, 0.0, 0.0, 0.36666666666666664, 0.26537997128901814, 0.0, 0.3716799906811841, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:26:54,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.10172295e-13   1.19696375e-12   4.51452313e-11
   3.64683492e-11   3.28015637e-26   1.18383200e-26   8.72633743e-26
   2.51526533e-23], sum to 1.0000
[2017-11-02 11:26:54,783] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 57.0, 1.65, 360.0, 0.0, 0.0, -3.0, 20.86319344187839, 18.0, 21.0747835673898, 21.5, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4659600.0000, 
raw observation next is [2.0, 57.00000000000001, 1.7, 360.0, 0.0, 0.0, -3.0, 21.58590389133201, 18.0, 20.99824499306627, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.38461538461538464, 0.5700000000000001, 0.15454545454545454, 1.0, 0.0, 0.0, 0.45, 0.2158590389133201, 0.0, 0.4283207132951813, 0.5, 0.0, 0.0], 
reward next is -0.0717. 
=============================================
[2017-11-02 11:26:55,102] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   5.97353452e-14   6.04153121e-13   2.20040427e-11
   2.11546232e-11   3.04955148e-29   2.10946370e-29   1.56484288e-28
   2.09647905e-26], sum to 1.0000
[2017-11-02 11:26:55,119] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 100.0, 0.75, 160.0, 0.0, 0.0, 4.0, 14.62584618882078, 20.0, 21.59861589776022, 21.5, 0.0, 39.17496497801065], 
actual action is [-6.0, 18], 
sim time next is 4685700.0000, 
raw observation next is [-1.0, 100.0, 0.625, 133.3333333333333, 0.0, 0.0, -6.0, 15.86797747758295, 18.0, 21.68686730082878, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.3076923076923077, 1.0, 0.056818181818181816, 0.37037037037037024, 0.0, 0.0, 0.4, 0.1586797747758295, 0.0, 0.5266953286898257, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:26:55,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-32.19936371]
 [-32.46855545]
 [-31.8689785 ]
 [-31.77407646]
 [-31.43183517]], R is [[-31.93056679]
 [-31.67758179]
 [-31.42533112]
 [-31.1848278 ]
 [-31.87298012]].
[2017-11-02 11:26:55,629] A3C_AGENT_WORKER-Thread-11 INFO:Local step 41000, global step 661801: loss 1.2601
[2017-11-02 11:26:55,644] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   6.39130531e-15   1.24510955e-14   8.49137167e-13
   6.41118885e-13   1.72961777e-24   7.78981408e-25   5.00527275e-24
   2.31695879e-23], sum to 1.0000
[2017-11-02 11:26:55,702] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.2666666666666667, 72.33333333333334, 3.266666666666667, 283.3333333333333, 113.0, 55.0, 4.666666666666667, 10.79087072230278, 23.0, 23.10288037052056, 22.7, 1.0, 55.71129283903807], 
actual action is [-5.266666666666667, 18.0], 
sim time next is 4524300.0000, 
raw observation next is [-0.2, 72.25, 3.225, 282.5, 114.0, 49.5, -5.266666666666667, 11.65503265187169, 18.0, 23.11743481686343, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.3282051282051282, 0.7225, 0.2931818181818182, 0.7847222222222222, 0.30158730158730157, 0.0495, 0.4122222222222222, 0.1165503265187169, 0.0, 0.7310621166947756, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0117. 
=============================================
[2017-11-02 11:26:58,053] A3C_AGENT_WORKER-Thread-3 INFO:Local step 41500, global step 662408: loss -49.0063
[2017-11-02 11:26:58,952] A3C_AGENT_WORKER-Thread-17 INFO:Local step 41500, global step 662651: loss 59.6477
[2017-11-02 11:27:02,054] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   3.88976937e-13   1.32366097e-11   4.30593367e-10
   1.27636701e-09   1.14907149e-30   3.39787035e-29   1.47218879e-28
   4.10309206e-27], sum to 1.0000
[2017-11-02 11:27:02,070] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 71.0, 0.0, 0.0, 0.0, 0.0, -6.958333333333333, 19.8045655793537, 18.0, 21.23560192377789, 21.5, 0.0, 0.0], 
actual action is [-7.0, 18], 
sim time next is 4597500.0000, 
raw observation next is [-2.05, 71.25, 0.0, 0.0, 0.0, 0.0, -7.0, 21.77672094996674, 18.0, 21.12345929207398, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.28076923076923077, 0.7125, 0.0, 0.0, 0.0, 0.0, 0.38333333333333336, 0.2177672094996674, 0.0, 0.4462084702962831, 0.5, 0.0, 0.0], 
reward next is -0.0538. 
=============================================
[2017-11-02 11:27:04,079] A3C_AGENT_WORKER-Thread-4 INFO:Local step 41500, global step 663757: loss 1.0576
[2017-11-02 11:27:05,684] A3C_AGENT_WORKER-Thread-9 INFO:Local step 41500, global step 664100: loss -45.3071
[2017-11-02 11:27:06,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-35.56070709]
 [-37.00822449]
 [-36.36207581]
 [-35.60714722]
 [-40.55536652]], R is [[-37.30522919]
 [-36.94630432]
 [-36.59053802]
 [-36.23791122]
 [-36.38759995]].
[2017-11-02 11:27:07,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-33.01812744]
 [-35.08102417]
 [-33.90384293]
 [-33.27258301]
 [-34.06329346]], R is [[-35.48386383]
 [-36.12902451]
 [-35.99055862]
 [-36.02262115]
 [-36.66239548]].
[2017-11-02 11:27:07,681] A3C_AGENT_WORKER-Thread-5 INFO:Local step 41500, global step 664512: loss 3.6684
[2017-11-02 11:27:09,906] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   8.75367227e-12   1.50627538e-10   9.84402249e-09
   1.37877230e-08   3.67674404e-17   1.20221464e-16   8.00502886e-16
   2.92561707e-15], sum to 1.0000
[2017-11-02 11:27:09,968] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 80.33333333333334, 3.933333333333334, 336.6666666666667, 0.0, 0.0, -6.25, 16.25414966712595, 18.0, 21.73057113095025, 21.5, 0.0, 0.0], 
actual action is [-6.333333333333333, 18], 
sim time next is 4739100.0000, 
raw observation next is [-1.416666666666667, 80.91666666666666, 4.016666666666666, 338.3333333333333, 0.0, 0.0, -6.333333333333333, 17.64501370933717, 18.0, 21.68897628033599, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.29700854700854695, 0.8091666666666666, 0.36515151515151506, 0.9398148148148148, 0.0, 0.0, 0.3944444444444445, 0.1764501370933717, 0.0, 0.52699661147657, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:27:12,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   1.39737749e-10   2.16152832e-10   4.87924590e-09
   5.34622568e-09   9.61463873e-22   8.91817628e-22   4.06115389e-21
   9.03708047e-22], sum to 1.0000
[2017-11-02 11:27:12,356] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 50.0, 0.0, 0.0, 199.0, 364.0, -0.02500000000000036, 9.27368047505708, 18.0, 23.8864818135712, 22.7, 1.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 4633500.0000, 
raw observation next is [5.083333333333333, 49.41666666666666, 0.0, 0.0, 198.3333333333333, 324.8333333333333, 0.0, 9.23136795003506, 18.0, 23.92174439823791, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.46367521367521364, 0.4941666666666666, 0.0, 0.0, 0.5246913580246912, 0.3248333333333333, 0.5, 0.09231367950035059, 0.0, 0.8459634854625584, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0092. 
=============================================
[2017-11-02 11:27:12,622] A3C_AGENT_WORKER-Thread-10 INFO:Local step 42000, global step 665433: loss -25.6681
[2017-11-02 11:27:18,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 41500, global step 666644: loss 9.1754
[2017-11-02 11:27:18,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.62640880e-14   3.98468693e-13   6.33954902e-11
   5.86455606e-11   1.40968677e-32   2.48831260e-32   2.37087318e-30
   7.44229510e-30], sum to 1.0000
[2017-11-02 11:27:18,801] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 83.41666666666667, 3.6, 339.1666666666666, 0.0, 0.0, 2.0, 18.9230033895301, 25.0, 20.83190676405485, 21.5, 0.0, 42.15018152046367], 
actual action is [2.0, 20.0], 
sim time next is 4745400.0000, 
raw observation next is [-3.0, 82.83333333333333, 3.6, 338.3333333333334, 0.0, 0.0, 2.0, 17.61032318655374, 20.0, 20.90423235165099, 21.5, 0.0, 53.34840909676949], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2564102564102564, 0.8283333333333333, 0.32727272727272727, 0.9398148148148151, 0.0, 0.0, 0.5333333333333333, 0.1761032318655374, 0.2857142857142857, 0.41489033595014135, 0.5, 0.0, 0.6276283423149351], 
reward next is -0.6500. 
=============================================
[2017-11-02 11:27:18,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.30166011e-13   3.84291470e-12   1.97682218e-10
   2.82200485e-10   7.23850613e-32   1.29810523e-31   4.11077822e-30
   1.43545953e-29], sum to 1.0000
[2017-11-02 11:27:18,962] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 54.91666666666666, 2.1, 335.0, 0.0, 0.0, -3.0, 17.96489265620259, 18.0, 21.63314598750934, 21.5, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4663800.0000, 
raw observation next is [2.0, 54.5, 2.1, 330.0, 0.0, 0.0, -3.0, 19.02438631461357, 18.0, 21.51836767200673, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.38461538461538464, 0.545, 0.19090909090909092, 0.9166666666666666, 0.0, 0.0, 0.45, 0.1902438631461357, 0.0, 0.5026239531438185, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:27:19,205] A3C_AGENT_WORKER-Thread-16 INFO:Local step 42000, global step 666846: loss 57.2612
[2017-11-02 11:27:21,222] A3C_AGENT_WORKER-Thread-12 INFO:Local step 41500, global step 667349: loss 37.1199
[2017-11-02 11:27:22,485] A3C_AGENT_WORKER-Thread-14 INFO:Local step 41500, global step 667630: loss 47.1122
[2017-11-02 11:27:23,323] A3C_AGENT_WORKER-Thread-13 INFO:Local step 41500, global step 667788: loss -22.0968
[2017-11-02 11:27:24,997] A3C_AGENT_WORKER-Thread-6 INFO:Local step 42000, global step 668073: loss -67.9954
[2017-11-02 11:27:25,144] A3C_AGENT_WORKER-Thread-15 INFO:Local step 41500, global step 668098: loss 77.5517
[2017-11-02 11:27:26,169] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   5.48058343e-12   8.42677872e-11   6.65104949e-09
   2.64616116e-08   1.30609340e-22   1.84966021e-22   1.49907955e-20
   4.20786648e-20], sum to 1.0000
[2017-11-02 11:27:26,236] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 71.0, 2.6, 316.6666666666667, 0.0, 0.0, 1.0, 14.97022801010873, 19.0, 21.48740559295257, 21.5, 0.0, 40.72981696563536], 
actual action is [-9.0, 18], 
sim time next is 4758300.0000, 
raw observation next is [-4.0, 71.0, 2.6, 315.0, 0.0, 0.0, -9.0, 17.0164083551405, 18.0, 21.49951280744622, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.23076923076923078, 0.71, 0.23636363636363636, 0.875, 0.0, 0.0, 0.35, 0.170164083551405, 0.0, 0.49993040106374564, 0.5, 0.0, 0.0], 
reward next is -0.0001. 
=============================================
[2017-11-02 11:27:27,444] A3C_AGENT_WORKER-Thread-8 INFO:Local step 42000, global step 668517: loss 1.9778
[2017-11-02 11:27:28,078] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.27165373e-13   6.91585461e-12   8.95136021e-10
   7.86416354e-09   1.93880779e-26   6.92419948e-26   2.45430957e-24
   2.57883653e-22], sum to 1.0000
[2017-11-02 11:27:28,147] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 3.35, 332.5, 0.0, 0.0, -1.0, 22.90945991919567, 23.0, 20.17287121589098, 21.5, 0.0, 64.44194484527198], 
actual action is [-11.0, 18.0], 
sim time next is 4765800.0000, 
raw observation next is [-6.0, 92.0, 3.433333333333333, 335.0, 0.0, 0.0, -11.0, 24.90077976107856, 18.0, 20.13266994991386, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.3121212121212121, 0.9305555555555556, 0.0, 0.0, 0.31666666666666665, 0.2490077976107856, 0.0, 0.3046671357019802, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:27:29,843] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.33794523e-26   3.06125895e-24   8.46273176e-24   2.22024788e-21
   2.67477236e-20   7.13127805e-03   1.18099926e-02   5.12609780e-01
   4.68448877e-01], sum to 1.0000
[2017-11-02 11:27:29,911] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.0, 92.0, 0.75, 175.0, 63.0, 0.0, -5.0, 12.5183666730063, 18.0, 22.32954432049564, 22.7, 1.0, 0.0], 
actual action is [5.0, 23.0], 
sim time next is 4696500.0000, 
raw observation next is [0.0, 92.0, 0.875, 204.1666666666667, 67.33333333333334, 0.0, 5.0, 11.92252178180943, 23.0, 22.32951554202384, 22.7, 1.0, 45.09964287271275], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.3333333333333333, 0.92, 0.07954545454545454, 0.5671296296296298, 0.17813051146384482, 0.0, 0.5833333333333334, 0.1192252178180943, 0.7142857142857143, 0.6185022202891203, 0.6714285714285714, 1.0, 0.5305840337966206], 
reward next is -0.4894. 
=============================================
[2017-11-02 11:27:29,980] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-30.79000854]
 [-32.21559143]
 [-31.7238884 ]
 [-32.89136124]
 [-33.37431335]], R is [[-32.65776825]
 [-33.33119202]
 [-33.99787903]
 [-34.65790176]
 [-35.31132126]].
[2017-11-02 11:27:30,585] A3C_AGENT_WORKER-Thread-11 INFO:Local step 41500, global step 669100: loss 92.9650
[2017-11-02 11:27:31,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.80250620e-20   5.08096196e-22   2.54653065e-21   2.69547970e-18
   4.28074834e-17   4.25242679e-03   5.14020137e-02   6.78578079e-01
   2.65767425e-01], sum to 1.0000
[2017-11-02 11:27:31,532] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 65.0, 3.6, 360.0, 163.5, 575.5, 1.833333333333333, 18.83754936382734, 22.0, 21.24963307024581, 22.7, 1.0, 32.90012234793521], 
actual action is [2.0, 24.0], 
sim time next is 4788300.0000, 
raw observation next is [-2.916666666666667, 63.41666666666666, 3.558333333333333, 360.0, 161.75, 601.25, 2.0, 18.48300565204643, 24.0, 21.32257034741088, 22.7, 1.0, 25.61395319550241], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.2585470085470085, 0.6341666666666665, 0.3234848484848485, 1.0, 0.4279100529100529, 0.60125, 0.5333333333333333, 0.1848300565204643, 0.8571428571428571, 0.47465290677298305, 0.6714285714285714, 1.0, 0.30134062582944016], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:27:33,162] A3C_AGENT_WORKER-Thread-7 INFO:Local step 42000, global step 669598: loss 19.7783
[2017-11-02 11:27:38,683] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.20276521e-16   4.29263619e-16   1.25720913e-13
   5.31149452e-13   5.37227550e-30   8.92546233e-29   7.02599273e-28
   1.69411134e-27], sum to 1.0000
[2017-11-02 11:27:38,826] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.416666666666667, 41.75, 2.433333333333333, 360.0, 166.0, 791.3333333333334, 6.333333333333333, 13.77052574823264, 24.0, 22.33114609659005, 22.7, 1.0, 23.50285487215581], 
actual action is [6.416666666666667, 19.0], 
sim time next is 4797000.0000, 
raw observation next is [1.5, 41.5, 2.3, 360.0, 170.0, 787.0, 6.416666666666667, 12.96801399113449, 19.0, 22.38156422512666, 22.7, 1.0, 45.16317881314119], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.3717948717948718, 0.415, 0.20909090909090908, 1.0, 0.4497354497354497, 0.787, 0.6069444444444444, 0.1296801399113449, 0.14285714285714285, 0.6259377464466657, 0.6714285714285714, 1.0, 0.5313315154487198], 
reward next is -0.4912. 
=============================================
[2017-11-02 11:27:38,960] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.96072574e-14   4.82585109e-13   6.79097334e-11
   2.18280699e-10   1.35272591e-27   1.52876991e-26   4.74413769e-26
   2.29578087e-24], sum to 1.0000
[2017-11-02 11:27:39,004] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.083333333333333, 60.0, 2.6, 69.99999999999999, 0.0, 0.0, -7.0, 27.31896895314295, 18.0, 20.66731518359267, 21.0, 0.0, 0.0], 
actual action is [-7.083333333333333, 18], 
sim time next is 4846200.0000, 
raw observation next is [-2.166666666666667, 60.0, 2.600000000000001, 70.0, 0.0, 0.0, -7.083333333333333, 29.08635510591516, 18.0, 20.43810087805879, 21.0, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.27777777777777773, 0.6, 0.23636363636363644, 0.19444444444444445, 0.0, 0.0, 0.3819444444444445, 0.2908635510591516, 0.0, 0.3483001254369701, 0.42857142857142855, 0.0, 0.0], 
reward next is -0.0803. 
=============================================
[2017-11-02 11:27:39,057] A3C_AGENT_WORKER-Thread-3 INFO:Local step 42000, global step 670638: loss -23.7470
[2017-11-02 11:27:40,436] A3C_AGENT_WORKER-Thread-17 INFO:Local step 42000, global step 670937: loss 2.6709
[2017-11-02 11:27:41,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   2.71300278e-12   3.08691614e-11   1.37869272e-09
   6.04458616e-09   2.63190191e-26   3.42175863e-25   4.64569407e-25
   8.31372462e-24], sum to 1.0000
[2017-11-02 11:27:41,477] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 4.975, 339.1666666666666, 0.0, 0.0, 4.0, 12.69816347400606, 23.0, 21.66908036884207, 22.7, 1.0, 89.1398937035394], 
actual action is [-6.0, 18.0], 
sim time next is 4734600.0000, 
raw observation next is [-1.0, 78.0, 4.85, 338.3333333333334, 0.0, 0.0, -6.0, 13.76600093484824, 18.0, 21.81601368162464, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.3076923076923077, 0.78, 0.44090909090909086, 0.9398148148148151, 0.0, 0.0, 0.4, 0.1376600093484824, 0.0, 0.5451448116606628, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0138. 
=============================================
[2017-11-02 11:27:44,126] A3C_AGENT_WORKER-Thread-4 INFO:Local step 42000, global step 671715: loss 0.6131
[2017-11-02 11:27:44,231] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.01062760e-13   2.11592137e-12   3.26241312e-10
   1.38810718e-09   1.17914072e-25   2.37966952e-24   3.98349435e-24
   2.07937499e-22], sum to 1.0000
[2017-11-02 11:27:44,244] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 84.66666666666667, 4.266666666666667, 346.6666666666667, 0.0, 0.0, -7.25, 25.53123086622404, 18.0, 20.50154388198466, 21.5, 0.0, 0.0], 
actual action is [-7.333333333333333, 18], 
sim time next is 4742700.0000, 
raw observation next is [-2.416666666666667, 84.58333333333333, 4.183333333333333, 345.8333333333333, 0.0, 0.0, -7.333333333333333, 26.21003310962726, 18.0, 20.40408686292073, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.27136752136752135, 0.8458333333333333, 0.38030303030303025, 0.9606481481481481, 0.0, 0.0, 0.3777777777777778, 0.2621003310962726, 0.0, 0.3434409804172474, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:27:44,643] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   7.46560758e-16   2.87902920e-15   5.55248664e-13
   2.69378009e-12   1.53777409e-30   4.41222606e-29   7.36477416e-29
   2.70149664e-28], sum to 1.0000
[2017-11-02 11:27:44,658] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.65, 44.58333333333333, 3.483333333333333, 58.33333333333333, 272.75, 388.1666666666666, -3.4, 13.18094204585793, 18.0, 22.63831278240315, 22.2, 1.0, 0.0], 
actual action is [-3.35, 18], 
sim time next is 4887000.0000, 
raw observation next is [1.7, 44.5, 3.5, 60.0, 272.0, 388.0, -3.35, 13.84338809400432, 18.0, 22.67060440266392, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.3769230769230769, 0.445, 0.3181818181818182, 0.16666666666666666, 0.7195767195767195, 0.388, 0.44416666666666665, 0.1384338809400432, 0.0, 0.6672292003805599, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0138. 
=============================================
[2017-11-02 11:27:47,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  5.22563701e-18   3.52334811e-18   4.48925808e-17   1.74012009e-14
   1.33684120e-13   1.07194902e-02   5.74279055e-02   5.86193800e-01
   3.45658809e-01], sum to 1.0000
[2017-11-02 11:27:47,193] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.25, 78.0, 4.725, 340.0, 0.0, 0.0, -5.166666666666667, 12.44499476807361, 18.0, 22.46474665699646, 22.7, 1.0, 0.0], 
actual action is [4.75, 23.0], 
sim time next is 4731600.0000, 
raw observation next is [-0.3333333333333333, 78.0, 4.766666666666667, 340.0, 0.0, 0.0, 4.75, 12.23439893365718, 23.0, 22.40597387062357, 22.7, 1.0, 37.76893791724032], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3247863247863248, 0.78, 0.43333333333333335, 0.9444444444444444, 0.0, 0.0, 0.5791666666666667, 0.12234398933657181, 0.7142857142857143, 0.6294248386605099, 0.6714285714285714, 1.0, 0.44434044608518025], 
reward next is -0.4121. 
=============================================
[2017-11-02 11:27:47,709] A3C_AGENT_WORKER-Thread-5 INFO:Local step 42000, global step 672441: loss 2.4506
[2017-11-02 11:27:48,296] A3C_AGENT_WORKER-Thread-9 INFO:Local step 42000, global step 672553: loss 16.0114
[2017-11-02 11:27:50,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  6.97497382e-32   1.08087724e-25   6.48417829e-24   3.75718682e-21
   4.15220447e-19   3.27568152e-03   2.20408607e-02   3.73886645e-01
   6.00796878e-01], sum to 1.0000
[2017-11-02 11:27:50,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 92.0, 3.183333333333334, 327.5, 0.0, 0.0, -1.0, 23.52041853998451, 20.0, 19.984033005137, 21.5, 0.0, 41.00122878056904], 
actual action is [-1.0, 25.0], 
sim time next is 4765200.0000, 
raw observation next is [-6.0, 92.0, 3.266666666666667, 330.0, 0.0, 0.0, -1.0, 23.07316663679079, 25.0, 20.13154739015391, 21.5, 0.0, 32.20600177297916], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.296969696969697, 0.9166666666666666, 0.0, 0.0, 0.48333333333333334, 0.2307316663679079, 1.0, 0.30450677002198695, 0.5, 0.0, 0.37889413850563713], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:27:53,732] A3C_AGENT_WORKER-Thread-10 INFO:Local step 42500, global step 673589: loss 3.0017
[2017-11-02 11:27:58,897] A3C_AGENT_WORKER-Thread-2 INFO:Local step 42000, global step 674597: loss -27.6671
[2017-11-02 11:28:00,056] A3C_AGENT_WORKER-Thread-16 INFO:Local step 42500, global step 674812: loss 2.0816
[2017-11-02 11:28:01,456] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.73786560e-17   1.92387669e-17   7.29661908e-17   1.49027099e-13
   6.11601915e-12   1.88008984e-04   9.53268111e-02   6.85292184e-01
   2.19193012e-01], sum to 1.0000
[2017-11-02 11:28:01,493] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.3, 45.5, 3.325, 45.0, 278.75, 389.5, -3.733333333333333, 17.34258674336863, 18.0, 22.08291179501653, 22.2, 1.0, 0.0], 
actual action is [6.3, 23.0], 
sim time next is 4884600.0000, 
raw observation next is [1.333333333333333, 45.33333333333333, 3.35, 46.66666666666667, 278.0, 389.3333333333334, 6.3, 16.41277209401517, 23.0, 22.02565082685947, 22.2, 1.0, 39.82694029427199], 
processed observation next is [1.0, 0.5217391304347826, 0.3675213675213675, 0.4533333333333333, 0.30454545454545456, 0.12962962962962965, 0.7354497354497355, 0.3893333333333334, 0.605, 0.1641277209401517, 0.7142857142857143, 0.5750929752656384, 0.5999999999999999, 1.0, 0.4685522387561411], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:28:01,518] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999642e-01   5.83796683e-12   2.51355325e-11   1.92278300e-08
   4.00288826e-07   1.69713579e-22   1.38274070e-19   6.32193980e-19
   4.94310364e-19], sum to 1.0000
[2017-11-02 11:28:01,557] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.833333333333333, 37.5, 3.25, 360.0, 196.0, 626.0, 7.75, 14.42572076755805, 22.0, 22.29662114421086, 22.7, 1.0, 27.00756850549373], 
actual action is [-2.166666666666667, 18], 
sim time next is 4802100.0000, 
raw observation next is [2.916666666666667, 37.25, 3.425, 360.0, 190.0, 640.5, -2.166666666666667, 14.70645093843008, 18.0, 22.40039907191118, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.40811965811965817, 0.3725, 0.31136363636363634, 1.0, 0.5026455026455027, 0.6405, 0.46388888888888885, 0.1470645093843008, 0.0, 0.6286284388444544, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 11:28:02,477] A3C_AGENT_WORKER-Thread-12 INFO:Local step 42000, global step 675355: loss 6.2593
[2017-11-02 11:28:03,326] A3C_AGENT_WORKER-Thread-6 INFO:Local step 42500, global step 675587: loss 4.1091
[2017-11-02 11:28:03,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99785960e-01   2.72583800e-09   2.01475174e-08   3.18300522e-06
   2.10793718e-04   3.01628239e-25   9.15812430e-22   2.07201897e-21
   5.93349707e-20], sum to 1.0000
[2017-11-02 11:28:03,629] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 5.7, 340.0, 122.5, 734.5, -2.0, 13.24940879374358, 18.0, 22.8131516149267, 22.7, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4806300.0000, 
raw observation next is [3.0, 37.0, 5.483333333333333, 313.3333333333333, 118.25, 733.25, -2.0, 13.62397937945382, 18.0, 22.86996314382804, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.41025641025641024, 0.37, 0.4984848484848485, 0.8703703703703703, 0.31283068783068785, 0.73325, 0.4666666666666667, 0.1362397937945382, 0.0, 0.695709020546863, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0136. 
=============================================
[2017-11-02 11:28:04,827] A3C_AGENT_WORKER-Thread-8 INFO:Local step 42500, global step 675919: loss 0.6846
[2017-11-02 11:28:06,221] A3C_AGENT_WORKER-Thread-13 INFO:Local step 42000, global step 676233: loss -2.9048
[2017-11-02 11:28:07,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 42000, global step 676596: loss -9.6110
[2017-11-02 11:28:08,270] A3C_AGENT_WORKER-Thread-14 INFO:Local step 42000, global step 676690: loss 1.7486
[2017-11-02 11:28:08,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.97150958e-01   7.93414188e-07   4.48663695e-06   2.59934517e-04
   2.58383481e-03   3.23975430e-11   3.25093508e-10   2.90603763e-10
   1.36715017e-09], sum to 1.0000
[2017-11-02 11:28:08,803] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.666666666666667, 50.0, 2.1, 40.0, 0.0, 0.0, 3.416666666666667, 18.34893556596784, 20.0, 20.94454954051406, 21.0, 0.0, 40.46967296774415], 
actual action is [-6.666666666666667, 18], 
sim time next is 4938300.0000, 
raw observation next is [-1.75, 50.0, 2.1, 37.5, 0.0, 0.0, -6.666666666666667, 19.8248564843354, 18.0, 21.00500727775758, 21.0, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.28846153846153844, 0.5, 0.19090909090909092, 0.10416666666666667, 0.0, 0.0, 0.3888888888888889, 0.19824856484335399, 0.0, 0.42928675396536875, 0.42857142857142855, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:28:12,003] A3C_AGENT_WORKER-Thread-7 INFO:Local step 42500, global step 677573: loss 0.7009
[2017-11-02 11:28:12,708] A3C_AGENT_WORKER-Thread-11 INFO:Local step 42000, global step 677718: loss 41.5599
[2017-11-02 11:28:15,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-15.26586723]
 [-13.42950249]
 [-14.97786522]
 [-13.9751997 ]
 [-14.16438675]], R is [[-14.54975986]
 [-15.40426254]
 [-16.25022125]
 [-17.08771896]
 [-17.91684151]].
[2017-11-02 11:28:16,795] A3C_AGENT_WORKER-Thread-3 INFO:Local step 42500, global step 678607: loss 10.1244
[2017-11-02 11:28:18,109] A3C_AGENT_WORKER-Thread-17 INFO:Local step 42500, global step 678873: loss 5.3600
[2017-11-02 11:28:22,458] A3C_AGENT_WORKER-Thread-4 INFO:Local step 42500, global step 679841: loss 1.2883
[2017-11-02 11:28:23,623] A3C_AGENT_WORKER-Thread-5 INFO:Local step 42500, global step 680161: loss 0.8013
[2017-11-02 11:28:24,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99952078e-01   1.52110351e-06   1.35434323e-06   1.07382511e-05
   3.43245410e-05   1.85244997e-17   2.52820727e-16   4.98342736e-17
   4.66801545e-17], sum to 1.0000
[2017-11-02 11:28:24,136] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.083333333333333, 24.16666666666667, 3.016666666666667, 29.16666666666667, 119.5, 862.0833333333333, 2.0, 13.84600615667969, 18.0, 22.79567556608485, 22.2, 1.0, 0.0], 
actual action is [2.083333333333333, 18], 
sim time next is 4972200.0000, 
raw observation next is [7.166666666666667, 24.33333333333333, 2.933333333333334, 28.33333333333333, 119.0, 861.6666666666666, 2.083333333333333, 13.59216266603937, 18.0, 22.80826198382739, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.5170940170940171, 0.2433333333333333, 0.2666666666666667, 0.07870370370370369, 0.3148148148148148, 0.8616666666666666, 0.5347222222222222, 0.1359216266603937, 0.0, 0.6868945691181985, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0136. 
=============================================
[2017-11-02 11:28:24,497] A3C_AGENT_WORKER-Thread-9 INFO:Local step 42500, global step 680404: loss 0.6584
[2017-11-02 11:28:25,323] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43000, global step 680631: loss 2.3535
[2017-11-02 11:28:29,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99990582e-01   1.97215062e-08   1.43964547e-08   5.98702741e-07
   8.87662191e-06   3.64065762e-18   8.13746723e-16   9.90627200e-17
   3.54200141e-16], sum to 1.0000
[2017-11-02 11:28:29,424] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.16666666666667, 75.66666666666666, 6.566666666666666, 191.6666666666667, 235.3333333333333, 285.8333333333334, 6.0, 11.63433910051288, 18.0, 22.642253643602, 22.2, 1.0, 0.0], 
actual action is [6.16666666666667, 18], 
sim time next is 5145000.0000, 
raw observation next is [11.33333333333333, 75.33333333333334, 6.433333333333334, 193.3333333333333, 252.6666666666667, 326.6666666666667, 6.16666666666667, 11.4413313867974, 18.0, 22.66236645122837, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.6239316239316238, 0.7533333333333334, 0.5848484848484848, 0.5370370370370369, 0.6684303350970019, 0.32666666666666666, 0.6027777777777779, 0.11441331386797399, 0.0, 0.6660523501754813, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0114. 
=============================================
[2017-11-02 11:28:29,932] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99867320e-01   1.15519117e-06   2.42376996e-06   3.11093754e-05
   9.80122204e-05   1.07108944e-16   3.56693409e-15   3.23419123e-16
   4.57641684e-16], sum to 1.0000
[2017-11-02 11:28:29,953] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.975, 19.0, 3.108333333333333, 268.3333333333333, 0.0, 0.0, 4.0, 10.8839688791727, 18.0, 22.70145856815343, 21.0, 0.0, 0.0], 
actual action is [3.9749999999999996, 18], 
sim time next is 5087400.0000, 
raw observation next is [8.95, 19.0, 3.116666666666667, 266.6666666666667, 0.0, 0.0, 3.975, 11.18122242653092, 18.0, 22.64841525843419, 21.0, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.5628205128205128, 0.19, 0.2833333333333334, 0.7407407407407408, 0.0, 0.0, 0.56625, 0.1118122242653092, 0.0, 0.6640593226334559, 0.42857142857142855, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:28:30,131] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43000, global step 681810: loss -268.8929
[2017-11-02 11:28:31,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-21.89018631]
 [-22.62241364]
 [-26.5815506 ]
 [-24.7508049 ]
 [-26.04285431]], R is [[-23.01455307]
 [-23.17696953]
 [-23.39428711]
 [-23.5457859 ]
 [-23.32575417]].
[2017-11-02 11:28:34,374] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43000, global step 682862: loss -153.9983
[2017-11-02 11:28:36,241] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-25.85703468]
 [-25.16424179]
 [-26.26809311]
 [-26.55186844]
 [-24.50987816]], R is [[-28.81363678]
 [-29.52550125]
 [-30.23024559]
 [-30.92794418]
 [-31.6186657 ]].
[2017-11-02 11:28:36,543] A3C_AGENT_WORKER-Thread-2 INFO:Local step 42500, global step 683405: loss 0.1738
[2017-11-02 11:28:36,819] A3C_AGENT_WORKER-Thread-8 INFO:Local step 43000, global step 683470: loss 0.3472
[2017-11-02 11:28:39,999] A3C_AGENT_WORKER-Thread-12 INFO:Local step 42500, global step 684353: loss 0.5938
[2017-11-02 11:28:40,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.96611297e-01   4.96785331e-04   5.52565965e-04   9.63691215e-04
   1.37565064e-03   1.63819240e-12   7.77826067e-12   1.29878725e-12
   4.92257493e-13], sum to 1.0000
[2017-11-02 11:28:40,858] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.916666666666666, 25.08333333333333, 3.141666666666667, 350.0, 80.33333333333333, 696.4166666666666, 4.0, 8.046926095153307, 18.0, 24.46837288629559, 22.2, 1.0, 0.0], 
actual action is [3.916666666666666, 18], 
sim time next is 4983000.0000, 
raw observation next is [8.833333333333334, 25.16666666666667, 3.183333333333334, 350.0, 78.66666666666667, 685.3333333333333, 3.916666666666666, 8.057433179765498, 18.0, 24.45622015195929, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.5598290598290598, 0.2516666666666667, 0.2893939393939395, 0.9722222222222222, 0.20811287477954146, 0.6853333333333332, 0.5652777777777778, 0.08057433179765498, 0.0, 0.9223171645656129, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0081. 
=============================================
[2017-11-02 11:28:41,099] A3C_AGENT_WORKER-Thread-13 INFO:Local step 42500, global step 684705: loss 0.2289
[2017-11-02 11:28:41,291] A3C_AGENT_WORKER-Thread-7 INFO:Local step 43000, global step 684758: loss 4.1460
[2017-11-02 11:28:42,000] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99394298e-01   7.04137346e-05   7.30234387e-05   1.94581778e-04
   2.67741125e-04   3.76222491e-12   2.26853120e-11   3.01768679e-12
   6.62543859e-13], sum to 1.0000
[2017-11-02 11:28:42,009] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.416666666666666, 25.58333333333333, 2.808333333333334, 355.8333333333333, 93.41666666666667, 777.75, 3.333333333333334, 8.956574044695799, 18.0, 24.17850283341983, 22.2, 1.0, 0.0], 
actual action is [3.416666666666666, 18], 
sim time next is 4980600.0000, 
raw observation next is [8.5, 25.5, 2.85, 355.0, 92.0, 774.0, 3.416666666666666, 8.865054291406613, 18.0, 24.22560129006491, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5512820512820513, 0.255, 0.2590909090909091, 0.9861111111111112, 0.24338624338624337, 0.774, 0.5569444444444444, 0.08865054291406613, 0.0, 0.8893716128664154, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0089. 
=============================================
[2017-11-02 11:28:43,948] A3C_AGENT_WORKER-Thread-15 INFO:Local step 42500, global step 685574: loss 0.7740
[2017-11-02 11:28:44,647] A3C_AGENT_WORKER-Thread-14 INFO:Local step 42500, global step 685800: loss 0.4499
[2017-11-02 11:28:44,857] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43000, global step 685856: loss 10.1629
[2017-11-02 11:28:46,785] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43000, global step 686427: loss 17.6567
[2017-11-02 11:28:48,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99997020e-01   2.79327459e-08   1.26944016e-07   1.52596584e-07
   2.63372863e-06   2.17997234e-24   6.65111222e-22   1.99958733e-22
   1.19845401e-20], sum to 1.0000
[2017-11-02 11:28:48,635] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.666666666666666, 27.0, 2.566666666666666, 330.0, 0.0, 0.0, -0.1666666666666661, 15.78334973632133, 18.0, 22.18631878472652, 21.0, 0.0, 0.0], 
actual action is [-0.3333333333333339, 18], 
sim time next is 4999500.0000, 
raw observation next is [4.5, 27.5, 2.7, 332.5, 0.0, 0.0, -0.3333333333333339, 16.43088448670689, 18.0, 22.08994019699094, 21.0, 0.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.44871794871794873, 0.275, 0.24545454545454548, 0.9236111111111112, 0.0, 0.0, 0.4944444444444444, 0.1643088448670689, 0.0, 0.5842771709987059, 0.42857142857142855, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:28:48,906] A3C_AGENT_WORKER-Thread-11 INFO:Local step 42500, global step 686925: loss 7.9391
[2017-11-02 11:28:50,973] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43000, global step 687468: loss 1.7193
[2017-11-02 11:28:51,106] A3C_AGENT_WORKER-Thread-9 INFO:Local step 43000, global step 687513: loss -17.7724
[2017-11-02 11:28:51,617] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.97727692e-01   6.23197469e-04   4.94934444e-04   3.26907117e-04
   8.27380747e-04   2.28433781e-13   2.02031794e-12   1.90840277e-13
   1.16237206e-13], sum to 1.0000
[2017-11-02 11:28:51,643] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 25.5, 3.1, 355.0, 34.0, 304.0, 2.166666666666666, 10.24668033322564, 18.0, 23.50899746234288, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 4988100.0000, 
raw observation next is [6.833333333333333, 25.41666666666666, 3.016666666666667, 355.8333333333333, 31.16666666666666, 278.6666666666666, 2.0, 10.37801157310867, 18.0, 23.44212262719964, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5085470085470085, 0.2541666666666666, 0.2742424242424243, 0.9884259259259258, 0.08245149911816577, 0.27866666666666656, 0.5333333333333333, 0.10378011573108671, 0.0, 0.7774460895999488, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0104. 
=============================================
[2017-11-02 11:28:52,105] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43000, global step 687749: loss 1.1844
[2017-11-02 11:28:54,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99997139e-01   5.47128593e-07   2.77609956e-07   2.42379684e-07
   1.84335863e-06   1.44978967e-16   6.32415593e-15   9.14367831e-16
   6.59258025e-16], sum to 1.0000
[2017-11-02 11:28:54,629] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.333333333333333, 40.16666666666667, 1.25, 108.3333333333333, 114.6666666666667, 772.0, -1.833333333333333, 11.8035882784156, 18.0, 23.3828626954703, 22.2, 1.0, 0.0], 
actual action is [-1.666666666666667, 18], 
sim time next is 5048100.0000, 
raw observation next is [3.5, 39.75, 1.125, 97.5, 115.0, 781.25, -1.666666666666667, 11.67565811697263, 18.0, 23.42319067101315, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.4230769230769231, 0.3975, 0.10227272727272728, 0.2708333333333333, 0.30423280423280424, 0.78125, 0.4722222222222222, 0.11675658116972629, 0.0, 0.7747415244304499, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0117. 
=============================================
[2017-11-02 11:28:56,363] A3C_AGENT_WORKER-Thread-10 INFO:Local step 43500, global step 688877: loss 94.5294
[2017-11-02 11:28:57,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99997854e-01   8.29524652e-07   2.90533677e-07   2.88272730e-07
   8.42150712e-07   1.20195140e-15   2.49119827e-14   4.08804740e-15
   7.08188259e-16], sum to 1.0000
[2017-11-02 11:28:57,319] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.5, 19.5, 2.05, 255.0, 111.0, 819.0, 6.41666666666667, 7.570811411647696, 18.0, 24.45536084995868, 22.2, 1.0, 0.0], 
actual action is [6.5, 18], 
sim time next is 5063700.0000, 
raw observation next is [11.58333333333333, 19.41666666666666, 2.141666666666667, 257.5, 109.75, 812.8333333333334, 6.5, 7.518215332094148, 18.0, 24.52246176781458, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.6303418803418802, 0.1941666666666666, 0.19469696969696973, 0.7152777777777778, 0.29034391534391535, 0.8128333333333334, 0.6083333333333333, 0.07518215332094148, 0.0, 0.93178025254494, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0075. 
=============================================
[2017-11-02 11:29:01,264] A3C_AGENT_WORKER-Thread-16 INFO:Local step 43500, global step 690173: loss 1.1358
[2017-11-02 11:29:04,943] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43000, global step 691065: loss 8.9983
[2017-11-02 11:29:05,257] A3C_AGENT_WORKER-Thread-6 INFO:Local step 43500, global step 691144: loss 1.0267
[2017-11-02 11:29:07,643] A3C_AGENT_WORKER-Thread-8 INFO:Local step 43500, global step 691764: loss 81.2200
[2017-11-02 11:29:07,813] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43000, global step 691806: loss 61.5551
[2017-11-02 11:29:09,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999762e-01   1.51984043e-08   3.72247158e-08   4.62379219e-08
   8.86079405e-08   9.46746562e-27   1.14831598e-25   3.63158936e-27
   5.77728717e-27], sum to 1.0000
[2017-11-02 11:29:09,722] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.666666666666667, 44.66666666666666, 3.766666666666667, 170.0, 0.0, 0.0, 2.5, 27.03862760810302, 18.0, 20.26650907269564, 21.0, 0.0, 0.0], 
actual action is [2.666666666666667, 18], 
sim time next is 5113500.0000, 
raw observation next is [7.833333333333333, 43.83333333333333, 3.808333333333333, 170.0, 0.0, 0.0, 2.666666666666667, 27.1352886605036, 18.0, 20.25624714831497, 21.0, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.5341880341880342, 0.4383333333333333, 0.3462121212121212, 0.4722222222222222, 0.0, 0.0, 0.5444444444444444, 0.27135288660503604, 0.0, 0.3223210211878528, 0.42857142857142855, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:10,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-15.62021732]
 [-20.89508438]
 [-20.34389114]
 [-20.06076431]
 [-21.71645737]], R is [[-18.78271294]
 [-18.60833359]
 [-19.05354309]
 [-18.87675476]
 [-19.40511703]].
[2017-11-02 11:29:11,821] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43000, global step 692776: loss 20.7164
[2017-11-02 11:29:13,660] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43000, global step 693279: loss 28.5124
[2017-11-02 11:29:13,669] A3C_AGENT_WORKER-Thread-7 INFO:Local step 43500, global step 693282: loss -42.5997
[2017-11-02 11:29:14,764] A3C_AGENT_WORKER-Thread-3 INFO:Local step 43500, global step 693598: loss -14.7439
[2017-11-02 11:29:14,946] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43000, global step 693647: loss 67.3796
[2017-11-02 11:29:15,079] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   8.39312952e-10   1.65512784e-10   2.28742247e-10
   1.13183429e-09   4.25091652e-25   1.16549844e-22   2.06976552e-24
   1.31137397e-24], sum to 1.0000
[2017-11-02 11:29:15,116] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.3333333333333333, 70.33333333333334, 3.433333333333334, 230.0, 202.1666666666667, 594.0000000000001, 5.25, 12.99700055305794, 19.0, 23.01781261444807, 22.2, 1.0, 30.95826234842757], 
actual action is [-4.666666666666667, 18], 
sim time next is 5307900.0000, 
raw observation next is [0.4166666666666667, 69.91666666666666, 3.391666666666667, 202.5, 200.5833333333333, 624.9999999999999, -4.666666666666667, 13.28797865788759, 18.0, 23.07450229377005, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.344017094017094, 0.6991666666666666, 0.30833333333333335, 0.5625, 0.5306437389770722, 0.6249999999999999, 0.4222222222222222, 0.1328797865788759, 0.0, 0.724928899110007, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 11:29:16,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.44690711e-28   1.09796869e-20   3.14889209e-20   1.89925683e-19
   7.57524354e-19   3.01950774e-03   9.91805911e-01   2.16652313e-03
   3.00810300e-03], sum to 1.0000
[2017-11-02 11:29:16,532] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.25, 73.5, 4.725, 322.5, 0.0, 0.0, -5.166666666666667, 34.27323183303752, 18.0, 19.65421010916473, 19.4, 0.0, 0.0], 
actual action is [4.75, 19.0], 
sim time next is 5264400.0000, 
raw observation next is [-0.3333333333333333, 74.0, 4.600000000000001, 323.3333333333334, 0.0, 0.0, 4.75, 31.74501966823668, 19.0, 19.58547618570478, 19.4, 0.0, 55.96377798024281], 
processed observation next is [0.5, 0.9565217391304348, 0.3247863247863248, 0.74, 0.4181818181818183, 0.8981481481481484, 0.0, 0.0, 0.5791666666666667, 0.3174501966823668, 0.14285714285714285, 0.2264965979578259, 0.1999999999999998, 0.0, 0.6583973880028566], 
reward next is -0.5926. 
=============================================
[2017-11-02 11:29:17,268] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43000, global step 694254: loss -23.4462
[2017-11-02 11:29:18,272] A3C_AGENT_WORKER-Thread-17 INFO:Local step 43500, global step 694519: loss 11.4751
[2017-11-02 11:29:21,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   1.14758991e-09   2.23292740e-09   3.16782378e-09
   5.51997470e-09   1.66184581e-26   3.18261317e-24   1.02583518e-26
   1.63927992e-26], sum to 1.0000
[2017-11-02 11:29:21,569] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 54.41666666666667, 4.6, 290.0, 0.0, 0.0, 9.0, 32.98613327566503, 19.0, 18.88113580124675, 19.4, 0.0, 42.27593803732327], 
actual action is [-1.0, 18], 
sim time next is 5194800.0000, 
raw observation next is [4.0, 54.0, 4.6, 290.0, 0.0, 0.0, -1.0, 33.53974232420551, 18.0, 18.9372323246123, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.13043478260869565, 0.4358974358974359, 0.54, 0.41818181818181815, 0.8055555555555556, 0.0, 0.0, 0.48333333333333334, 0.3353974232420551, 0.0, 0.13389033208747136, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0661. 
=============================================
[2017-11-02 11:29:21,658] A3C_AGENT_WORKER-Thread-9 INFO:Local step 43500, global step 695404: loss 58.5779
[2017-11-02 11:29:21,889] A3C_AGENT_WORKER-Thread-5 INFO:Local step 43500, global step 695459: loss -97.6571
[2017-11-02 11:29:21,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   8.32781344e-10   1.64279346e-09   3.57442009e-09
   6.09069328e-09   5.79375137e-20   1.56054174e-17   3.97809639e-20
   4.67676965e-20], sum to 1.0000
[2017-11-02 11:29:22,010] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 68.08333333333333, 5.35, 325.8333333333333, 0.0, 0.0, -6.0, 39.56300544523064, 18.0, 18.91188629201042, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 5276400.0000, 
raw observation next is [-1.0, 67.66666666666667, 5.3, 326.6666666666667, 0.0, 0.0, -6.0, 40.72165733932999, 18.0, 18.87116137958799, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.3076923076923077, 0.6766666666666667, 0.4818181818181818, 0.9074074074074074, 0.0, 0.0, 0.4, 0.40721657339329986, 0.0, 0.12445162565542692, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0755. 
=============================================
[2017-11-02 11:29:22,910] A3C_AGENT_WORKER-Thread-4 INFO:Local step 43500, global step 695734: loss -4.8971
[2017-11-02 11:29:23,570] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.51007979e-08   4.13717283e-09   7.61802266e-09
   3.39525030e-08   1.59427525e-15   1.98016259e-13   3.87474841e-15
   4.99994973e-16], sum to 1.0000
[2017-11-02 11:29:23,631] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 58.0, 3.2, 180.0, 144.0, 815.0, -3.166666666666667, 15.75314145667584, 18.0, 22.65970260775762, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5312100.0000, 
raw observation next is [2.166666666666667, 56.5, 3.216666666666667, 208.3333333333333, 144.0, 816.1666666666666, -3.0, 15.79225069765745, 18.0, 22.64934320708309, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.3888888888888889, 0.565, 0.2924242424242424, 0.5787037037037036, 0.38095238095238093, 0.8161666666666666, 0.45, 0.1579225069765745, 0.0, 0.6641918867261555, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:25,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   2.79372775e-10   4.39273701e-10   6.66549815e-10
   1.38632916e-09   6.67788552e-27   1.84178669e-24   6.57094479e-27
   1.80496290e-26], sum to 1.0000
[2017-11-02 11:29:25,828] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.333333333333333, 62.33333333333333, 4.466666666666667, 310.0, 0.0, 0.0, -2.583333333333333, 33.79745784904565, 18.0, 18.9666608509669, 19.4, 0.0, 0.0], 
actual action is [-2.666666666666667, 18], 
sim time next is 5204700.0000, 
raw observation next is [2.25, 63.5, 4.25, 310.0, 0.0, 0.0, -2.666666666666667, 34.85467714884638, 18.0, 19.02601270784519, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.391025641025641, 0.635, 0.38636363636363635, 0.8611111111111112, 0.0, 0.0, 0.45555555555555555, 0.3485467714884638, 0.0, 0.14657324397788432, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0534. 
=============================================
[2017-11-02 11:29:28,554] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44000, global step 697097: loss 2.0552
[2017-11-02 11:29:29,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.83321125e-09   6.34469588e-10   1.23095173e-10   6.27001229e-10
   8.14846413e-09   6.13774348e-04   9.81727242e-01   3.84475943e-03
   1.38142779e-02], sum to 1.0000
[2017-11-02 11:29:29,177] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.833333333333333, 81.0, 5.016666666666667, 296.6666666666667, 95.33333333333333, 0.0, 6.916666666666667, 20.79486192624404, 19.0, 20.9034021701652, 22.2, 1.0, 36.47670565897079], 
actual action is [6.833333333333333, 20.0], 
sim time next is 5217300.0000, 
raw observation next is [1.75, 81.5, 4.975, 295.0, 95.0, 0.0, 6.833333333333333, 20.27623596775256, 20.0, 20.99480105208097, 22.2, 1.0, 24.2064836862477], 
processed observation next is [0.5, 0.391304347826087, 0.3782051282051282, 0.815, 0.4522727272727272, 0.8194444444444444, 0.25132275132275134, 0.0, 0.6138888888888889, 0.2027623596775256, 0.2857142857142857, 0.4278287217258528, 0.5999999999999999, 1.0, 0.28478216101467885], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:32,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.31724937e-10   5.01713913e-11   9.93280874e-11
   1.45605639e-09   1.19016332e-24   1.12781048e-21   1.70550118e-23
   8.99772880e-22], sum to 1.0000
[2017-11-02 11:29:32,322] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.416666666666667, 83.5, 5.1, 294.1666666666666, 94.66666666666666, 0.7500000000000003, 6.333333333333333, 19.90461886906577, 24.0, 20.04215627777923, 22.2, 1.0, 70.14354538791596], 
actual action is [6.416666666666667, 19.0], 
sim time next is 5214600.0000, 
raw observation next is [1.5, 83.0, 5.1, 295.0, 98.0, 0.0, 6.416666666666667, 18.38187135084114, 19.0, 20.50613821915054, 22.2, 1.0, 50.83306943756203], 
processed observation next is [0.5, 0.34782608695652173, 0.3717948717948718, 0.83, 0.4636363636363636, 0.8194444444444444, 0.25925925925925924, 0.0, 0.6069444444444444, 0.18381871350841142, 0.14285714285714285, 0.3580197455929342, 0.5999999999999999, 1.0, 0.5980361110301415], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:33,218] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   6.04870581e-12   9.18777814e-12   1.40199536e-11
   4.77338238e-11   3.77461522e-34   5.19591073e-32   5.40556679e-34
   3.86905796e-32], sum to 1.0000
[2017-11-02 11:29:33,229] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5, 53.0, 0.6000000000000001, 255.0, 0.0, 0.0, 4.666666666666667, 38.71554313690127, 23.0, 18.78524635056473, 19.4, 0.0, 80.11189748491624], 
actual action is [-5.5, 18.0], 
sim time next is 5367000.0000, 
raw observation next is [-0.6666666666666667, 53.66666666666666, 0.6666666666666667, 283.3333333333334, 0.0, 0.0, -5.5, 39.73546087542486, 18.0, 18.89790790243496, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.3162393162393163, 0.5366666666666666, 0.060606060606060615, 0.7870370370370373, 0.0, 0.0, 0.4083333333333333, 0.3973546087542486, 0.0, 0.1282725574907084, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0717. 
=============================================
[2017-11-02 11:29:33,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44000, global step 698396: loss 0.9791
[2017-11-02 11:29:34,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.97189581e-01   3.41336330e-04   4.89046157e-04   6.06495538e-04
   1.37357449e-03   6.36479064e-15   7.30591043e-13   3.95487069e-14
   2.36753477e-12], sum to 1.0000
[2017-11-02 11:29:34,839] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.583333333333333, 37.25, 3.391666666666667, 298.3333333333334, 0.0, 0.0, 0.6666666666666661, 16.20470637022679, 18.0, 22.00604403535378, 22.2, 1.0, 0.0], 
actual action is [0.583333333333333, 18], 
sim time next is 5337000.0000, 
raw observation next is [5.5, 37.5, 3.35, 300.0, 0.0, 0.0, 0.583333333333333, 16.68915216618352, 18.0, 21.88555149355807, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.47435897435897434, 0.375, 0.30454545454545456, 0.8333333333333334, 0.0, 0.0, 0.5097222222222222, 0.16689152166183518, 0.0, 0.5550787847940098, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:35,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.71491514e-08   2.87588922e-08   2.53664698e-08
   3.74320521e-08   6.53279831e-29   1.96928609e-27   6.21483450e-29
   1.14678295e-27], sum to 1.0000
[2017-11-02 11:29:35,596] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.166666666666667, 43.5, 4.1, 260.0, 0.0, 0.0, 2.25, 25.16742454282738, 18.0, 20.9791090328901, 19.4, 0.0, 0.0], 
actual action is [2.166666666666667, 18], 
sim time next is 5435700.0000, 
raw observation next is [7.083333333333333, 43.75, 4.1, 260.0, 0.0, 0.0, 2.166666666666667, 25.46363600445969, 18.0, 20.94482414493389, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.5149572649572649, 0.4375, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5361111111111111, 0.2546363600445969, 0.0, 0.4206891635619842, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:29:37,426] A3C_AGENT_WORKER-Thread-2 INFO:Local step 43500, global step 699267: loss 2.9857
[2017-11-02 11:29:37,986] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44000, global step 699379: loss 1.4615
[2017-11-02 11:29:38,322] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99998927e-01   5.69725849e-08   2.73799060e-07   3.31021482e-07
   5.31316687e-07   6.04926865e-22   6.20270688e-20   3.05105024e-21
   4.27254710e-19], sum to 1.0000
[2017-11-02 11:29:38,384] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.666666666666668, 32.66666666666667, 3.600000000000001, 270.0, 0.0, 0.0, 3.75, 22.075121509814, 18.0, 21.66997905628035, 20.56, 1.0, 0.0], 
actual action is [3.666666666666668, 18], 
sim time next is 5426700.0000, 
raw observation next is [8.583333333333332, 32.83333333333333, 3.6, 270.0, 0.0, 0.0, 3.666666666666668, 22.30811399673245, 18.0, 21.62762994092947, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.5534188034188033, 0.3283333333333333, 0.32727272727272727, 0.75, 0.0, 0.0, 0.5611111111111112, 0.2230811399673245, 0.0, 0.51823284870421, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:40,689] A3C_AGENT_WORKER-Thread-12 INFO:Local step 43500, global step 700000: loss 36.8874
[2017-11-02 11:29:41,923] A3C_AGENT_WORKER-Thread-8 INFO:Local step 44000, global step 700293: loss 17.7375
[2017-11-02 11:29:42,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-51.43864441]
 [-44.90409088]
 [-49.2684288 ]
 [-49.58103943]
 [-48.11231995]], R is [[-47.21350479]
 [-46.75563812]
 [-46.30254745]
 [-45.85419083]
 [-45.41051865]].
[2017-11-02 11:29:43,399] A3C_AGENT_WORKER-Thread-13 INFO:Local step 43500, global step 700602: loss 37.7053
[2017-11-02 11:29:44,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  8.29441984e-13   7.62461448e-12   6.97669613e-12   1.55922619e-11
   1.54119661e-10   4.74426042e-06   2.00166646e-03   2.18443063e-04
   9.97775137e-01], sum to 1.0000
[2017-11-02 11:29:44,231] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [2.0, 80.0, 4.433333333333333, 320.0, 108.3333333333333, 0.0, -3.0, 18.3450679707674, 18.0, 22.24609048432905, 22.2, 1.0, 0.0], 
actual action is [7.0, 23.0], 
sim time next is 5241300.0000, 
raw observation next is [2.0, 80.0, 4.516666666666666, 320.0, 105.4166666666667, 0.0, 7.0, 14.53189834379814, 23.0, 22.20665874420328, 22.2, 1.0, 92.75037879153582], 
processed observation next is [0.5, 0.6521739130434783, 0.38461538461538464, 0.8, 0.41060606060606053, 0.8888888888888888, 0.2788800705467373, 0.0, 0.6166666666666667, 0.1453189834379814, 0.7142857142857143, 0.6009512491718974, 0.5999999999999999, 1.0, 1.091180926959245], 
reward next is -0.9966. 
=============================================
[2017-11-02 11:29:46,199] A3C_AGENT_WORKER-Thread-7 INFO:Local step 44000, global step 701163: loss 3.3350
[2017-11-02 11:29:47,273] A3C_AGENT_WORKER-Thread-15 INFO:Local step 43500, global step 701383: loss 4.0197
[2017-11-02 11:29:48,870] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44000, global step 701684: loss 0.4164
[2017-11-02 11:29:49,220] A3C_AGENT_WORKER-Thread-14 INFO:Local step 43500, global step 701754: loss 1.3833
[2017-11-02 11:29:51,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99762833e-01   3.72952331e-06   2.84567377e-05   6.39718710e-05
   9.23344633e-05   2.35089701e-07   1.55949601e-06   4.95141457e-08
   4.68742910e-05], sum to 1.0000
[2017-11-02 11:29:51,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.15011041e-08   4.23657553e-09   4.61887240e-09
   2.27751631e-08   8.26989266e-22   1.34229070e-20   6.95545198e-22
   1.27035119e-20], sum to 1.0000
[2017-11-02 11:29:51,993] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.666666666666667, 65.33333333333333, 2.033333333333333, 276.6666666666667, 0.0, 0.0, -1.416666666666667, 34.72432091610105, 18.0, 19.79641024882674, 19.4, 0.0, 0.0], 
actual action is [-1.333333333333333, 18], 
sim time next is 5539500.0000, 
raw observation next is [3.75, 65.0, 1.9, 267.5, 0.0, 0.0, -1.333333333333333, 34.90044640607029, 18.0, 19.77772793577381, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.42948717948717946, 0.65, 0.17272727272727273, 0.7430555555555556, 0.0, 0.0, 0.4777777777777778, 0.34900446406070285, 0.0, 0.253961133681973, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:29:52,011] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 25.66666666666667, 5.35, 275.0, 138.0, 698.0, 7.0, 12.59446297314114, 18.0, 23.63502490587507, 20.56, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5411700.0000, 
raw observation next is [12.0, 25.5, 5.175000000000001, 277.5, 139.25, 686.5, 7.0, 12.50442885669582, 18.0, 23.66690680577645, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.6410256410256411, 0.255, 0.4704545454545455, 0.7708333333333334, 0.3683862433862434, 0.6865, 0.6166666666666667, 0.1250442885669582, 0.0, 0.8095581151109214, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:29:52,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99999881e-01   3.23029248e-08   1.00737765e-08   1.66296434e-08
   8.88245424e-08   1.81638440e-14   3.94536075e-13   2.71119949e-14
   5.61468027e-13], sum to 1.0000
[2017-11-02 11:29:52,409] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 24.33333333333333, 3.95, 295.0, 137.0, 558.3333333333334, 7.0, 12.08340648116213, 18.0, 23.8848326825387, 20.56, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5414100.0000, 
raw observation next is [12.0, 24.16666666666667, 3.775, 297.5, 135.5, 534.9166666666667, 7.0, 12.05660925297255, 18.0, 23.90749990375466, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.6410256410256411, 0.24166666666666672, 0.3431818181818182, 0.8263888888888888, 0.3584656084656085, 0.5349166666666667, 0.6166666666666667, 0.1205660925297255, 0.0, 0.8439285576792369, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0121. 
=============================================
[2017-11-02 11:29:52,864] A3C_AGENT_WORKER-Thread-11 INFO:Local step 43500, global step 702590: loss -28.0754
[2017-11-02 11:29:53,684] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   3.31118227e-12   7.44230632e-12   1.36859898e-11
   2.19597673e-11   4.96382774e-29   4.19157275e-28   6.71986072e-30
   2.13060584e-27], sum to 1.0000
[2017-11-02 11:29:53,707] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.416666666666667, 71.91666666666667, 3.891666666666667, 264.1666666666667, 0.0, 0.0, -1.5, 46.48947057293433, 18.0, 18.7231930146428, 19.4, 0.0, 0.0], 
actual action is [-1.583333333333333, 18], 
sim time next is 5463600.0000, 
raw observation next is [3.333333333333333, 72.33333333333333, 3.933333333333333, 263.3333333333333, 0.0, 0.0, -1.583333333333333, 46.7987439288401, 18.0, 18.69363761396729, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.41880341880341876, 0.7233333333333333, 0.35757575757575755, 0.7314814814814814, 0.0, 0.0, 0.47361111111111115, 0.46798743928840103, 0.0, 0.09909108770961288, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:29:54,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44000, global step 703010: loss 3.0051
[2017-11-02 11:29:55,265] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44000, global step 703163: loss 5.6299
[2017-11-02 11:29:56,550] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99999285e-01   9.80560486e-08   1.90124510e-07   1.67099572e-07
   2.75567885e-07   4.78322457e-25   1.69911567e-24   1.00706476e-25
   3.03177567e-24], sum to 1.0000
[2017-11-02 11:29:56,568] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.25, 53.25, 2.85, 340.0, 0.0, 0.0, 1.333333333333334, 24.23733206493598, 18.0, 21.0321974363073, 19.4, 0.0, 0.0], 
actual action is [1.25, 18], 
sim time next is 5529000.0000, 
raw observation next is [6.166666666666666, 53.83333333333334, 2.933333333333334, 343.3333333333334, 0.0, 0.0, 1.25, 24.50497908474438, 18.0, 20.9935653485261, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 1.0, 0.4914529914529914, 0.5383333333333334, 0.2666666666666667, 0.9537037037037039, 0.0, 0.0, 0.5208333333333334, 0.2450497908474438, 0.0, 0.4276521926465858, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:29:56,995] A3C_AGENT_WORKER-Thread-9 INFO:Local step 44000, global step 703550: loss 4.3972
[2017-11-02 11:29:57,963] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44000, global step 703763: loss 10.6934
[2017-11-02 11:29:59,995] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-15.69579697]
 [-16.77445412]
 [-16.10971832]
 [-15.8498354 ]
 [-16.1031189 ]], R is [[-16.70014954]
 [-16.54752922]
 [-16.3964119 ]
 [-16.24677086]
 [-16.0985775 ]].
[2017-11-02 11:30:00,043] A3C_AGENT_WORKER-Thread-10 INFO:Local step 44500, global step 704264: loss 0.8911
[2017-11-02 11:30:02,504] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   2.32301872e-10   7.52653773e-10   1.65744751e-09
   1.41345646e-09   2.35786386e-18   5.34883274e-18   2.03938498e-19
   6.80565289e-18], sum to 1.0000
[2017-11-02 11:30:02,523] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.833333333333333, 69.83333333333333, 3.683333333333333, 268.3333333333333, 0.0, 0.0, -1.083333333333333, 33.03656769648253, 18.0, 19.73880403970518, 19.4, 0.0, 0.0], 
actual action is [-1.166666666666667, 18], 
sim time next is 5462100.0000, 
raw observation next is [3.75, 70.25, 3.725, 267.5, 0.0, 0.0, -1.166666666666667, 33.87996175546662, 18.0, 19.85573205239023, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.42948717948717946, 0.7025, 0.3386363636363636, 0.7430555555555556, 0.0, 0.0, 0.4805555555555555, 0.33879961755466614, 0.0, 0.2651045789128901, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:06,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 44500, global step 705920: loss 0.4561
[2017-11-02 11:30:07,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-19.86004639]
 [-18.84348297]
 [-18.91784668]
 [-18.83308792]
 [-19.23007584]], R is [[-19.01233292]
 [-18.82221031]
 [-19.39729691]
 [-19.22082901]
 [-19.84485817]].
[2017-11-02 11:30:08,593] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   2.11293913e-10   6.62071648e-11   6.92279983e-11
   6.20875740e-10   1.06480287e-23   1.12902325e-23   6.84622304e-25
   4.30376832e-24], sum to 1.0000
[2017-11-02 11:30:08,622] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.41666666666667, 41.5, 4.683333333333333, 314.1666666666666, 143.0833333333333, 833.75, 7.33333333333333, 16.32540672495498, 18.0, 22.8452988515329, 20.56, 1.0, 0.0], 
actual action is [7.41666666666667, 18], 
sim time next is 5488200.0000, 
raw observation next is [12.5, 41.0, 4.6, 315.0, 143.0, 835.0, 7.41666666666667, 16.30057286139259, 18.0, 22.84188733966385, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6538461538461539, 0.41, 0.41818181818181815, 0.875, 0.3783068783068783, 0.835, 0.6236111111111112, 0.16300572861392593, 0.0, 0.6916981913805499, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:30:10,084] A3C_AGENT_WORKER-Thread-6 INFO:Local step 44500, global step 706918: loss 1.6648
[2017-11-02 11:30:12,272] A3C_AGENT_WORKER-Thread-8 INFO:Local step 44500, global step 707464: loss 0.2832
[2017-11-02 11:30:14,337] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44000, global step 707993: loss 24.1374
[2017-11-02 11:30:15,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.09220904e-22   1.93550192e-18   4.66990088e-19   1.32368926e-18
   5.37484095e-18   6.04868047e-02   3.49077463e-01   8.36887956e-03
   5.82066894e-01], sum to 1.0000
[2017-11-02 11:30:15,096] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [6.083333333333333, 38.83333333333334, 2.05, 26.66666666666666, 138.6666666666667, 800.0, 1.0, 12.84051188748401, 18.0, 23.55141028293264, 20.56, 1.0, 0.0], 
actual action is [11.083333333333332, 19.0], 
sim time next is 5397000.0000, 
raw observation next is [6.166666666666666, 38.66666666666666, 2.0, 43.33333333333334, 139.3333333333333, 804.0, 11.08333333333333, 12.33285719065412, 19.0, 23.54635397099242, 20.56, 1.0, 40.22720671733446], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.4914529914529914, 0.38666666666666655, 0.18181818181818182, 0.12037037037037039, 0.36860670194003514, 0.804, 0.6847222222222221, 0.1233285719065412, 0.14285714285714285, 0.7923362815703457, 0.36571428571428555, 1.0, 0.4732612554980525], 
reward next is -0.4383. 
=============================================
[2017-11-02 11:30:16,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   3.04191428e-09   8.78945539e-09   1.30352431e-08
   4.24304503e-09   2.32944472e-24   1.81245783e-24   5.35354660e-26
   2.21918677e-25], sum to 1.0000
[2017-11-02 11:30:16,111] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 48.0, 1.65, 325.0, 0.0, 0.0, 2.0, 26.90012341244882, 18.0, 20.39480209003467, 19.4, 0.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 5523600.0000, 
raw observation next is [7.0, 48.0, 1.7, 323.3333333333334, 0.0, 0.0, 2.0, 27.15903146492406, 18.0, 20.3614665328551, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5128205128205128, 0.48, 0.15454545454545454, 0.8981481481481484, 0.0, 0.0, 0.5333333333333333, 0.2715903146492406, 0.0, 0.33735236183644296, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:17,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99995112e-01   5.35988647e-07   1.45523518e-06   2.30511000e-06
   6.53987115e-07   5.92601207e-18   3.08763196e-18   2.75165870e-19
   4.55781170e-19], sum to 1.0000
[2017-11-02 11:30:17,147] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.75, 44.75, 4.1, 260.0, 0.0, 0.0, 1.833333333333334, 25.35862603603411, 18.0, 21.07246291512689, 19.4, 0.0, 0.0], 
actual action is [1.75, 18], 
sim time next is 5437200.0000, 
raw observation next is [6.666666666666667, 45.0, 4.1, 260.0, 0.0, 0.0, 1.75, 25.57375967064516, 18.0, 21.04034291694547, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.5042735042735043, 0.45, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5291666666666667, 0.2557375967064516, 0.0, 0.43433470242078137, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:17,739] A3C_AGENT_WORKER-Thread-7 INFO:Local step 44500, global step 708742: loss 1.1328
[2017-11-02 11:30:17,899] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44000, global step 708783: loss 9.0971
[2017-11-02 11:30:19,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99998212e-01   4.57338899e-07   2.03252796e-07   4.55333520e-07
   5.63326694e-07   3.92674886e-14   1.40620127e-13   5.47058364e-14
   1.99416763e-13], sum to 1.0000
[2017-11-02 11:30:19,740] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 24.83333333333333, 4.475, 287.5, 141.5, 628.5833333333333, 7.0, 13.49622282012382, 18.0, 23.45752531321589, 20.56, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5413200.0000, 
raw observation next is [12.0, 24.66666666666667, 4.300000000000001, 290.0, 140.0, 605.1666666666667, 7.0, 13.4234738713965, 18.0, 23.49429848872196, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.6410256410256411, 0.2466666666666667, 0.390909090909091, 0.8055555555555556, 0.37037037037037035, 0.6051666666666667, 0.6166666666666667, 0.134234738713965, 0.0, 0.7848997841031371, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 11:30:19,936] A3C_AGENT_WORKER-Thread-3 INFO:Local step 44500, global step 709275: loss 0.2681
[2017-11-02 11:30:21,907] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44000, global step 709769: loss 3.9264
[2017-11-02 11:30:23,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99579012e-01   8.35675019e-05   1.43548110e-04   1.30935587e-04
   6.28571506e-05   4.25109871e-13   2.60273194e-13   6.30117093e-14
   2.39136273e-14], sum to 1.0000
[2017-11-02 11:30:23,313] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [18.91666666666666, 52.58333333333333, 5.058333333333334, 240.8333333333333, 0.0, 0.0, 14.0, 6.594339950047575, 18.0, 24.54068545333404, 19.4, 0.0, 0.0], 
actual action is [13.91666666666666, 18], 
sim time next is 5695800.0000, 
raw observation next is [18.83333333333334, 53.16666666666667, 5.016666666666667, 241.6666666666667, 0.0, 0.0, 13.91666666666666, 6.55581207243906, 18.0, 24.51526119373758, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.8162393162393163, 0.5316666666666667, 0.45606060606060606, 0.6712962962962964, 0.0, 0.0, 0.7319444444444443, 0.0655581207243906, 0.0, 0.9307515991053685, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:23,830] A3C_AGENT_WORKER-Thread-17 INFO:Local step 44500, global step 710321: loss 0.8276
[2017-11-02 11:30:24,410] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44000, global step 710483: loss 4.7798
[2017-11-02 11:30:24,648] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44000, global step 710549: loss 6.6882
[2017-11-02 11:30:25,712] A3C_AGENT_WORKER-Thread-5 INFO:Local step 44500, global step 710840: loss 0.7754
[2017-11-02 11:30:25,812] A3C_AGENT_WORKER-Thread-9 INFO:Local step 44500, global step 710856: loss 0.5589
[2017-11-02 11:30:28,530] A3C_AGENT_WORKER-Thread-4 INFO:Local step 44500, global step 711643: loss 0.2666
[2017-11-02 11:30:28,626] A3C_AGENT_WORKER-Thread-10 INFO:Local step 45000, global step 711668: loss 0.2190
[2017-11-02 11:30:28,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99874234e-01   1.62184424e-05   5.02161638e-05   3.86008905e-05
   2.06912246e-05   4.52464989e-16   3.32574622e-16   7.58791636e-17
   2.91785830e-16], sum to 1.0000
[2017-11-02 11:30:28,905] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.5, 58.0, 2.975, 162.5, 0.0, 0.0, 1.666666666666667, 19.44824038519713, 18.0, 20.65107490993442, 19.4, 0.0, 0.0], 
actual action is [1.5, 18], 
sim time next is 5619000.0000, 
raw observation next is [6.333333333333333, 58.66666666666666, 3.016666666666667, 161.6666666666667, 0.0, 0.0, 1.5, 19.68217871836169, 18.0, 20.62040386906411, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.4957264957264957, 0.5866666666666666, 0.2742424242424243, 0.4490740740740742, 0.0, 0.0, 0.525, 0.1968217871836169, 0.0, 0.3743434098663013, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:29,897] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44000, global step 712036: loss -1.1333
[2017-11-02 11:30:32,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99978662e-01   4.87894476e-06   5.21711991e-06   8.57013401e-06
   2.59680837e-06   1.94394149e-20   2.92381786e-20   4.28607068e-21
   3.53142855e-20], sum to 1.0000
[2017-11-02 11:30:32,156] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.333333333333334, 59.83333333333334, 3.433333333333334, 306.6666666666667, 131.3333333333333, 750.6666666666667, 3.166666666666666, 32.37697743563032, 18.0, 20.42436759056886, 19.4, 0.0, 0.0], 
actual action is [3.333333333333334, 18], 
sim time next is 5480100.0000, 
raw observation next is [8.5, 59.25, 3.45, 305.0, 131.75, 757.5, 3.333333333333334, 31.98677867227501, 18.0, 20.4710782168479, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.5512820512820513, 0.5925, 0.31363636363636366, 0.8472222222222222, 0.34854497354497355, 0.7575, 0.5555555555555556, 0.31986778672275007, 0.0, 0.3530111738354143, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:34,119] A3C_AGENT_WORKER-Thread-16 INFO:Local step 45000, global step 713350: loss 0.3668
[2017-11-02 11:30:35,173] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.97096181e-01   5.41571470e-04   9.43767431e-04   1.06044265e-03
   3.58060701e-04   7.15475368e-13   3.18416924e-13   6.95701092e-14
   5.49547692e-14], sum to 1.0000
[2017-11-02 11:30:35,220] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 50.33333333333334, 2.6, 157.5, 0.0, 0.0, 3.0, 19.54731224407971, 18.0, 20.75727468995368, 19.4, 0.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5614800.0000, 
raw observation next is [8.0, 50.66666666666666, 2.6, 160.0, 0.0, 0.0, 3.0, 19.76696543171529, 18.0, 20.72603169012066, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5384615384615384, 0.5066666666666666, 0.23636363636363636, 0.4444444444444444, 0.0, 0.0, 0.55, 0.1976696543171529, 0.0, 0.3894330985886657, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:38,290] A3C_AGENT_WORKER-Thread-6 INFO:Local step 45000, global step 714651: loss 0.0600
[2017-11-02 11:30:39,330] A3C_AGENT_WORKER-Thread-8 INFO:Local step 45000, global step 714985: loss 0.0870
[2017-11-02 11:30:40,361] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.31458354e-01   1.81028619e-02   2.21772138e-02   1.83452014e-02
   9.91644710e-03   6.12694506e-10   3.68312741e-10   1.07260374e-10
   6.29172062e-11], sum to 1.0000
[2017-11-02 11:30:40,375] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 51.0, 4.933333333333333, 236.6666666666667, 0.0, 0.0, 14.41666666666666, 5.809160058289814, 18.0, 24.03448637217749, 19.4, 0.0, 0.0], 
actual action is [14.33333333333334, 18], 
sim time next is 5694300.0000, 
raw observation next is [19.25, 51.25, 4.975, 237.5, 0.0, 0.0, 14.33333333333334, 5.793034438688374, 18.0, 24.01086312008652, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.8269230769230769, 0.5125, 0.4522727272727272, 0.6597222222222222, 0.0, 0.0, 0.738888888888889, 0.05793034438688374, 0.0, 0.8586947314409313, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:42,089] A3C_AGENT_WORKER-Thread-2 INFO:Local step 44500, global step 715796: loss 1.0822
[2017-11-02 11:30:44,009] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.84222829e-01   4.07797471e-03   5.21286530e-03   4.71245032e-03
   1.77388580e-03   4.66980517e-11   2.51143724e-11   5.68872120e-12
   4.01223759e-12], sum to 1.0000
[2017-11-02 11:30:44,094] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [16.0, 63.0, 4.891666666666667, 245.8333333333333, 0.0, 0.0, 11.0, 6.012224305387433, 18.0, 22.83795205612952, 19.4, 0.0, 0.0], 
actual action is [11.0, 18], 
sim time next is 5715600.0000, 
raw observation next is [16.0, 63.0, 4.933333333333333, 246.6666666666667, 0.0, 0.0, 11.0, 6.028901826641763, 18.0, 22.82258508558261, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.7435897435897436, 0.63, 0.44848484848484843, 0.6851851851851853, 0.0, 0.0, 0.6833333333333333, 0.06028901826641763, 0.0, 0.6889407265118014, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:44,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99993920e-01   8.20608079e-07   1.32901437e-06   3.01966770e-06
   9.81600010e-07   2.18994766e-12   4.01665029e-13   8.72940094e-14
   6.35560961e-12], sum to 1.0000
[2017-11-02 11:30:44,227] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 68.0, 2.6, 260.0, 0.0, 0.0, -2.0, 49.19968761883366, 18.0, 18.12803793203486, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 5551500.0000, 
raw observation next is [2.916666666666667, 68.41666666666666, 2.383333333333333, 238.3333333333333, 0.0, 0.0, -2.0, 49.97902944374353, 18.0, 18.08696428409225, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.40811965811965817, 0.6841666666666666, 0.21666666666666662, 0.6620370370370369, 0.0, 0.0, 0.4666666666666667, 0.4997902944374353, 0.0, 0.012423469156035745, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:30:44,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.73740160e-01   6.47972478e-03   8.24260805e-03   8.32057651e-03
   3.21683777e-03   2.88267576e-10   1.51985161e-10   4.57478638e-11
   4.01407692e-11], sum to 1.0000
[2017-11-02 11:30:44,740] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.83333333333333, 39.5, 4.183333333333333, 340.8333333333333, 0.0, 0.0, 6.0, 21.64356369673444, 18.0, 21.67931096559974, 19.4, 0.0, 0.0], 
actual action is [5.83333333333333, 18], 
sim time next is 5512200.0000, 
raw observation next is [10.66666666666667, 40.0, 4.266666666666667, 341.6666666666667, 0.0, 0.0, 5.83333333333333, 21.90590297905775, 18.0, 21.63016894042741, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.606837606837607, 0.4, 0.3878787878787879, 0.9490740740740742, 0.0, 0.0, 0.5972222222222221, 0.2190590297905775, 0.0, 0.5185955629182014, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:45,085] A3C_AGENT_WORKER-Thread-12 INFO:Local step 44500, global step 716709: loss -0.2686
[2017-11-02 11:30:45,362] A3C_AGENT_WORKER-Thread-7 INFO:Local step 45000, global step 716790: loss 0.1704
[2017-11-02 11:30:46,847] A3C_AGENT_WORKER-Thread-3 INFO:Local step 45000, global step 717249: loss 0.1942
[2017-11-02 11:30:46,933] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  8.54088843e-01   3.40710171e-02   4.84365039e-02   4.51219603e-02
   1.82816200e-02   4.84914473e-08   1.93376319e-08   5.48154588e-09
   2.99873926e-09], sum to 1.0000
[2017-11-02 11:30:46,954] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666666, 37.33333333333334, 3.966666666666667, 233.3333333333333, 40.83333333333334, 295.0, 18.83333333333334, 31.69960253529911, 18.0, 28.36874246770137, 19.4, 0.0, 0.0], 
actual action is [18.66666666666666, 18], 
sim time next is 5766300.0000, 
raw observation next is [23.5, 37.5, 3.75, 232.5, 36.75, 265.5, 18.66666666666666, 31.28456756443087, 18.0, 28.28627983215327, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.9358974358974359, 0.375, 0.3409090909090909, 0.6458333333333334, 0.09722222222222222, 0.2655, 0.811111111111111, 0.3128456756443087, 0.0, 1.469468547450467, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:47,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-1.78307664]
 [-1.41951668]
 [-1.70710433]
 [-1.66303742]
 [-1.82287824]], R is [[-1.48267317]
 [-1.46784639]
 [-1.45316792]
 [-1.4386363 ]
 [-1.42425001]].
[2017-11-02 11:30:47,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 44500, global step 717599: loss 1.8213
[2017-11-02 11:30:49,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.99698877e-01   4.69314109e-05   9.20303646e-05   8.38892665e-05
   7.82960778e-05   1.72963175e-16   1.04744313e-16   3.40376848e-17
   3.70500639e-15], sum to 1.0000
[2017-11-02 11:30:49,566] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.5, 66.0, 0.75, 120.0, 0.0, 0.0, -1.416666666666667, 45.57793126360045, 18.0, 18.58216063130085, 19.4, 0.0, 0.0], 
actual action is [-1.5, 18], 
sim time next is 5542500.0000, 
raw observation next is [3.416666666666667, 66.33333333333334, 0.625, 99.99999999999999, 0.0, 0.0, -1.5, 45.8139201259097, 18.0, 18.56039250262808, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.42094017094017094, 0.6633333333333334, 0.056818181818181816, 0.27777777777777773, 0.0, 0.0, 0.475, 0.458139201259097, 0.0, 0.0800560718040114, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:30:50,844] A3C_AGENT_WORKER-Thread-9 INFO:Local step 45000, global step 718406: loss -0.0474
[2017-11-02 11:30:50,912] A3C_AGENT_WORKER-Thread-17 INFO:Local step 45000, global step 718423: loss -2.1674
[2017-11-02 11:30:51,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 44500, global step 718626: loss 0.0202
[2017-11-02 11:30:51,639] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  8.08559060e-01   5.54733090e-02   6.76527694e-02   4.55938615e-02
   2.27205623e-02   2.15938044e-07   1.29495575e-07   5.63076057e-08
   2.49792969e-08], sum to 1.0000
[2017-11-02 11:30:51,705] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 49.66666666666666, 2.6, 152.5, 0.0, 0.0, 3.0, 17.78067386660605, 18.0, 21.13567482194481, 19.4, 0.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5614200.0000, 
raw observation next is [8.0, 50.0, 2.6, 155.0, 0.0, 0.0, 3.0, 17.99242667962648, 18.0, 21.10137044290945, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5384615384615384, 0.5, 0.23636363636363636, 0.4305555555555556, 0.0, 0.0, 0.55, 0.1799242667962648, 0.0, 0.44305292041563554, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:51,877] A3C_AGENT_WORKER-Thread-5 INFO:Local step 45000, global step 718742: loss 0.2725
[2017-11-02 11:30:52,913] A3C_AGENT_WORKER-Thread-15 INFO:Local step 44500, global step 719062: loss 2.7738
[2017-11-02 11:30:54,894] A3C_AGENT_WORKER-Thread-4 INFO:Local step 45000, global step 719678: loss -1.0335
[2017-11-02 11:30:55,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  5.03720939e-01   1.39669240e-01   1.96436957e-01   1.01889931e-01
   5.82823567e-02   2.12747025e-07   2.09911818e-07   9.02055248e-08
   3.67596513e-08], sum to 1.0000
[2017-11-02 11:30:55,552] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.0, 62.0, 4.558333333333333, 309.1666666666666, 0.0, 0.0, 8.0, 8.335125900697463, 18.0, 24.14746511134332, 19.4, 0.0, 0.0], 
actual action is [8.0, 18], 
sim time next is 5868000.0000, 
raw observation next is [13.0, 62.0, 4.6, 310.0, 0.0, 0.0, 8.0, 8.224575976567865, 18.0, 24.12194077112838, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.6666666666666666, 0.62, 0.41818181818181815, 0.8611111111111112, 0.0, 0.0, 0.6333333333333333, 0.08224575976567865, 0.0, 0.8745629673040541, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:55,892] A3C_AGENT_WORKER-Thread-11 INFO:Local step 44500, global step 719974: loss -1.9284
[2017-11-02 11:30:56,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.32563505  0.15143436  0.24952736  0.15989898  0.09302981  0.00884431
  0.00654384  0.00383797  0.00124831], sum to 1.0000
[2017-11-02 11:30:56,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [11.33333333333333, 48.0, 3.1, 353.3333333333333, 144.1666666666667, 834.3333333333334, 6.16666666666667, 18.28362924405912, 18.0, 21.79214438184921, 19.4, 0.0, 0.0], 
actual action is [6.33333333333333, 18.0], 
sim time next is 5575500.0000, 
raw observation next is [11.5, 47.75, 3.1, 352.5, 143.75, 834.0, 6.33333333333333, 18.15108566699036, 18.0, 21.77815671372555, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.6282051282051282, 0.4775, 0.2818181818181818, 0.9791666666666666, 0.3802910052910053, 0.834, 0.6055555555555555, 0.18151085666990363, 0.0, 0.5397366733893644, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:56,483] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.49029809e-01   1.39533192e-01   2.65173584e-01   1.63077310e-01
   8.11515152e-02   9.62264370e-04   6.25725195e-04   3.62050807e-04
   8.46229595e-05], sum to 1.0000
[2017-11-02 11:30:56,497] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [24.0, 42.25, 5.1, 245.8333333333333, 148.6666666666667, 809.75, 19.0, 14.81758802703771, 18.0, 26.58658286399495, 19.4, 0.0, 0.0], 
actual action is [19.0, 18], 
sim time next is 5751000.0000, 
raw observation next is [24.0, 42.5, 5.1, 245.0, 149.0, 807.0, 19.0, 15.13943787200784, 18.0, 26.61660149356785, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.9487179487179487, 0.425, 0.4636363636363636, 0.6805555555555556, 0.3941798941798942, 0.807, 0.8166666666666667, 0.15139437872007838, 0.0, 1.2309430705096926, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:57,062] A3C_AGENT_WORKER-Thread-10 INFO:Local step 45500, global step 720289: loss 3.1924
[2017-11-02 11:30:59,528] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  4.00082946e-01   1.28817156e-01   2.45328262e-01   1.55329823e-01
   7.03429803e-02   3.54953772e-05   3.69685331e-05   2.14991614e-05
   4.82891073e-06], sum to 1.0000
[2017-11-02 11:30:59,589] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.0, 42.0, 3.1, 130.0, 0.0, 0.0, 15.16666666666667, 7.375532940803198, 18.5, 23.46632063491817, 19.4, 0.0, 19.33759785465203], 
actual action is [5.0, 18], 
sim time next is 5609100.0000, 
raw observation next is [9.833333333333332, 42.5, 3.058333333333334, 130.8333333333333, 0.0, 0.0, 5.0, 7.837434594452167, 18.0, 23.49072336410324, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.5854700854700854, 0.425, 0.27803030303030307, 0.3634259259259258, 0.0, 0.0, 0.5833333333333334, 0.07837434594452167, 0.0, 0.7843890520147484, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:30:59,915] A3C_AGENT_WORKER-Thread-16 INFO:Local step 45500, global step 721088: loss -0.4355
[2017-11-02 11:31:04,037] A3C_AGENT_WORKER-Thread-6 INFO:Local step 45500, global step 722445: loss 0.3660
[2017-11-02 11:31:05,881] A3C_AGENT_WORKER-Thread-8 INFO:Local step 45500, global step 723043: loss 0.3205
[2017-11-02 11:31:07,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.10639042  0.16242912  0.37517634  0.21387427  0.13017239  0.00365366
  0.00372414  0.00355539  0.0010244 ], sum to 1.0000
[2017-11-02 11:31:07,377] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [17.0, 59.0, 4.266666666666667, 246.6666666666667, 0.0, 0.0, 12.0, 5.782246063211621, 18.0, 23.17195890280034, 19.4, 0.0, 0.0], 
actual action is [12.0, 18], 
sim time next is 5703900.0000, 
raw observation next is [17.0, 59.0, 4.308333333333333, 245.8333333333333, 0.0, 0.0, 12.0, 5.775863008365357, 18.0, 23.16124107044533, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.0, 0.7692307692307693, 0.59, 0.3916666666666666, 0.6828703703703702, 0.0, 0.0, 0.7, 0.05775863008365357, 0.0, 0.7373201529207617, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:31:08,792] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.18396069  0.16080262  0.31494558  0.17085254  0.14025508  0.00954411
  0.00992132  0.00760949  0.00210847], sum to 1.0000
[2017-11-02 11:31:08,814] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [19.5, 56.0, 8.45, 220.0, 232.75, 597.75, 14.33333333333334, 14.89231989437923, 18.0, 26.65788990175242, 19.4, 0.0, 0.0], 
actual action is [14.5, 18.0], 
sim time next is 5826000.0000, 
raw observation next is [19.66666666666667, 56.0, 8.366666666666667, 220.0, 232.8333333333333, 606.8333333333334, 14.5, 15.28893094182593, 18.0, 26.74037548155974, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.8376068376068377, 0.56, 0.7606060606060606, 0.6111111111111112, 0.6159611992945325, 0.6068333333333333, 0.7416666666666667, 0.1528893094182593, 0.0, 1.2486250687942488, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:31:08,856] A3C_AGENT_WORKER-Thread-2 INFO:Local step 45000, global step 724006: loss -0.2092
[2017-11-02 11:31:10,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 45000, global step 724634: loss 0.4437
[2017-11-02 11:31:10,706] A3C_AGENT_WORKER-Thread-7 INFO:Local step 45500, global step 724898: loss 3.8779
[2017-11-02 11:31:10,948] A3C_AGENT_WORKER-Thread-3 INFO:Local step 45500, global step 725005: loss -0.0223
[2017-11-02 11:31:11,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-16.06761742]
 [-16.62062454]
 [-15.74822903]
 [-20.35520172]
 [-17.18445396]], R is [[-18.65729904]
 [-19.47072601]
 [-20.27601814]
 [-21.07325745]
 [-21.86252594]].
[2017-11-02 11:31:12,131] A3C_AGENT_WORKER-Thread-13 INFO:Local step 45000, global step 725504: loss 1.5272
[2017-11-02 11:31:13,003] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  5.35539269e-01   1.42964378e-01   1.38890758e-01   6.11159280e-02
   1.21487908e-01   3.31894313e-07   7.95747951e-07   4.61620033e-07
   1.14506378e-07], sum to 1.0000
[2017-11-02 11:31:13,014] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [8.0, 57.0, 3.6, 313.3333333333334, 228.3333333333333, 248.3333333333333, 3.0, 6.797656939995536, 18.0, 23.30500289475188, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5931900.0000, 
raw observation next is [8.0, 57.0, 3.6, 317.5, 219.0, 266.5, 3.0, 6.720526525406791, 18.0, 23.35077195079413, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.5384615384615384, 0.57, 0.32727272727272727, 0.8819444444444444, 0.5793650793650794, 0.2665, 0.55, 0.06720526525406792, 0.0, 0.7643959929705899, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0067. 
=============================================
[2017-11-02 11:31:13,919] A3C_AGENT_WORKER-Thread-17 INFO:Local step 45500, global step 726324: loss 0.2954
[2017-11-02 11:31:14,020] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.1491152   0.15713337  0.29159722  0.18061534  0.2146661   0.00168734
  0.00260746  0.00195917  0.00061879], sum to 1.0000
[2017-11-02 11:31:14,042] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.75, 75.5, 3.925, 272.5, 0.0, 0.0, -2.166666666666667, 12.64812934189899, 18.0, 21.22076007755987, 22.2, 1.0, 0.0], 
actual action is [-2.25, 18], 
sim time next is 5948400.0000, 
raw observation next is [2.666666666666667, 76.0, 3.866666666666667, 243.3333333333334, 0.0, 0.0, -2.25, 13.02126719643207, 18.0, 21.15738683979351, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.4017094017094017, 0.76, 0.35151515151515156, 0.6759259259259262, 0.0, 0.0, 0.4625, 0.1302126719643207, 0.0, 0.4510552628276443, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 11:31:14,220] A3C_AGENT_WORKER-Thread-5 INFO:Local step 45500, global step 726453: loss 0.0082
[2017-11-02 11:31:14,675] A3C_AGENT_WORKER-Thread-9 INFO:Local step 45500, global step 726649: loss 0.5005
[2017-11-02 11:31:14,699] A3C_AGENT_WORKER-Thread-14 INFO:Local step 45000, global step 726660: loss -0.3892
[2017-11-02 11:31:15,889] A3C_AGENT_WORKER-Thread-15 INFO:Local step 45000, global step 727143: loss 0.2664
[2017-11-02 11:31:16,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.14610152  0.1629619   0.3098425   0.19320267  0.18446149  0.00090631
  0.00109364  0.00110823  0.00032166], sum to 1.0000
[2017-11-02 11:31:16,010] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.083333333333333, 64.66666666666666, 2.641666666666667, 290.8333333333333, 110.3333333333333, 0.0, 1.0, 8.352557692693178, 18.0, 22.22564300170407, 22.2, 1.0, 0.0], 
actual action is [1.083333333333333, 18], 
sim time next is 5915400.0000, 
raw observation next is [6.166666666666666, 64.33333333333334, 2.683333333333334, 291.6666666666667, 111.6666666666667, 0.0, 1.083333333333333, 8.435190896297964, 18.0, 22.22159302799993, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.4914529914529914, 0.6433333333333334, 0.243939393939394, 0.8101851851851852, 0.2954144620811288, 0.0, 0.5180555555555555, 0.08435190896297964, 0.0, 0.6030847182857043, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0084. 
=============================================
[2017-11-02 11:31:16,645] A3C_AGENT_WORKER-Thread-4 INFO:Local step 45500, global step 727444: loss 0.0099
[2017-11-02 11:31:17,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 45000, global step 727843: loss -2.4125
[2017-11-02 11:31:18,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-7.33740282]
 [-8.32158947]
 [-8.65197849]
 [-9.26668453]
 [-8.57116032]], R is [[-11.71988297]
 [-11.61170769]
 [-11.50467968]
 [-11.3988018 ]
 [-11.29406166]].
[2017-11-02 11:31:20,381] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.07909545e-01   1.65936068e-01   3.45139325e-01   2.06906617e-01
   1.72189832e-01   5.40396606e-04   5.77238563e-04   6.35417935e-04
   1.65474368e-04], sum to 1.0000
[2017-11-02 11:31:20,396] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 39.0, 3.266666666666667, 226.6666666666667, 0.0, 0.0, 17.75, 34.83524764231574, 18.0, 28.73462943354085, 19.4, 0.0, 0.0], 
actual action is [17.66666666666667, 18], 
sim time next is 5768700.0000, 
raw observation next is [22.58333333333333, 39.25, 3.308333333333333, 225.8333333333333, 0.0, 0.0, 17.66666666666667, 33.98965160428032, 18.0, 28.61806546930416, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.9123931623931623, 0.3925, 0.3007575757575757, 0.6273148148148147, 0.0, 0.0, 0.7944444444444445, 0.3398965160428032, 0.0, 1.5168664956148799, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:31:20,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  6.71589449e-02   2.11151868e-01   3.24837655e-01   2.04396367e-01
   1.91250905e-01   2.88450334e-04   4.09998727e-04   3.87569395e-04
   1.18290394e-04], sum to 1.0000
[2017-11-02 11:31:20,965] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [16.33333333333334, 55.0, 4.433333333333334, 193.3333333333333, 0.0, 0.0, 11.25, 6.081423561703706, 18.0, 23.83735584474147, 22.2, 1.0, 0.0], 
actual action is [11.33333333333334, 18.0], 
sim time next is 5808300.0000, 
raw observation next is [16.41666666666666, 55.0, 4.516666666666666, 194.1666666666667, 0.0, 0.0, 11.33333333333334, 6.062139286826311, 18.0, 23.82974530766084, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.7542735042735041, 0.55, 0.41060606060606053, 0.539351851851852, 0.0, 0.0, 0.688888888888889, 0.06062139286826311, 0.0, 0.8328207582372629, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0061. 
=============================================
[2017-11-02 11:31:25,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.06789897  0.15159334  0.35180283  0.26909733  0.15588781  0.00095193
  0.00102988  0.00133809  0.00039987], sum to 1.0000
[2017-11-02 11:31:25,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [17.08333333333333, 51.75, 4.141666666666667, 189.1666666666667, 0.0, 0.0, 12.16666666666667, 9.213246672379872, 18.0, 24.86767628994115, 19.4, 0.0, 0.0], 
actual action is [12.083333333333329, 18], 
sim time next is 5796000.0000, 
raw observation next is [17.0, 52.0, 4.1, 190.0, 0.0, 0.0, 12.08333333333333, 9.100146678580298, 18.0, 24.84142304102755, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.08695652173913043, 0.7692307692307693, 0.52, 0.3727272727272727, 0.5277777777777778, 0.0, 0.0, 0.7013888888888888, 0.09100146678580298, 0.0, 0.9773461487182215, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:31:25,267] A3C_AGENT_WORKER-Thread-10 INFO:Local step 46000, global step 730425: loss 34.5947
[2017-11-02 11:31:25,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.91981241e-01   1.95013449e-01   2.87530333e-01   1.17716268e-01
   2.07758680e-01   1.48900805e-11   6.57964377e-11   8.38089251e-11
   1.51429896e-10], sum to 1.0000
[2017-11-02 11:31:25,426] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [18.83333333333333, 56.25, 8.358333333333333, 217.5, 232.4166666666667, 561.4166666666666, 13.66666666666667, 13.54726044966801, 18.0, 26.49454713234216, 22.2, 1.0, 0.0], 
actual action is [13.833333333333329, 18.0], 
sim time next is 5824800.0000, 
raw observation next is [19.0, 56.0, 8.7, 220.0, 232.5, 570.5, 13.83333333333333, 13.91400758814035, 18.0, 26.57496064414407, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.8205128205128205, 0.56, 0.7909090909090909, 0.6111111111111112, 0.6150793650793651, 0.5705, 0.7305555555555555, 0.1391400758814035, 0.0, 1.2249943777348673, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 11:31:26,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.66133922e-02   2.15678185e-01   3.16111922e-01   1.19558558e-01
   2.52037942e-01   3.22453991e-14   3.43825961e-13   5.96312171e-13
   1.83334858e-11], sum to 1.0000
[2017-11-02 11:31:26,453] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [18.5, 66.16666666666667, 8.116666666666665, 268.3333333333333, 110.6666666666667, 400.0, 13.25, 24.45233265872777, 18.0, 26.86255624306971, 22.2, 1.0, 0.0], 
actual action is [13.5, 18], 
sim time next is 5849700.0000, 
raw observation next is [18.75, 65.08333333333333, 8.158333333333333, 269.1666666666667, 103.0833333333333, 392.5, 13.5, 25.09955836750086, 18.0, 26.94483742477501, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.8141025641025641, 0.6508333333333333, 0.7416666666666667, 0.7476851851851852, 0.27270723104056427, 0.3925, 0.725, 0.25099558367500857, 0.0, 1.2778339178250013, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:31:27,348] A3C_AGENT_WORKER-Thread-16 INFO:Local step 46000, global step 731032: loss -33.8608
[2017-11-02 11:31:28,789] A3C_AGENT_WORKER-Thread-2 INFO:Local step 45500, global step 731458: loss 2.2099
[2017-11-02 11:31:29,835] A3C_AGENT_WORKER-Thread-6 INFO:Local step 46000, global step 731765: loss -8.1728
[2017-11-02 11:31:30,414] A3C_AGENT_WORKER-Thread-12 INFO:Local step 45500, global step 731920: loss 14.5402
[2017-11-02 11:31:32,496] A3C_AGENT_WORKER-Thread-13 INFO:Local step 45500, global step 732416: loss 1.2098
[2017-11-02 11:31:33,906] A3C_AGENT_WORKER-Thread-8 INFO:Local step 46000, global step 732756: loss -37.0693
[2017-11-02 11:31:36,948] A3C_AGENT_WORKER-Thread-14 INFO:Local step 45500, global step 733523: loss -0.4522
[2017-11-02 11:31:37,791] A3C_AGENT_WORKER-Thread-15 INFO:Local step 45500, global step 733734: loss 14.6413
[2017-11-02 11:31:38,657] A3C_AGENT_WORKER-Thread-7 INFO:Local step 46000, global step 733939: loss 411.0335
[2017-11-02 11:31:39,355] A3C_AGENT_WORKER-Thread-3 INFO:Local step 46000, global step 734134: loss 1.3882
[2017-11-02 11:31:39,434] A3C_AGENT_WORKER-Thread-11 INFO:Local step 45500, global step 734149: loss 0.7977
[2017-11-02 11:31:41,456] A3C_AGENT_WORKER-Thread-9 INFO:Local step 46000, global step 734692: loss 41.5286
[2017-11-02 11:31:42,012] A3C_AGENT_WORKER-Thread-17 INFO:Local step 46000, global step 734868: loss 67.2495
[2017-11-02 11:31:43,005] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.14020472e-02   2.73511648e-01   4.69624102e-01   6.61874264e-02
   1.79274812e-01   9.81278521e-15   1.13649053e-12   8.81514534e-13
   1.81072657e-10], sum to 1.0000
[2017-11-02 11:31:43,016] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [4.583333333333334, 95.91666666666666, 3.225, 354.1666666666667, 173.75, 0.0, -0.5, 17.19440917504789, 18.0, 22.13880436111787, 20.56, 1.0, 0.0], 
actual action is [-0.4166666666666661, 18], 
sim time next is 6014400.0000, 
raw observation next is [4.666666666666666, 95.33333333333334, 3.1, 353.3333333333333, 169.5, 0.0, -0.4166666666666661, 17.59765994441808, 18.0, 22.06547140772575, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.45299145299145294, 0.9533333333333335, 0.2818181818181818, 0.9814814814814814, 0.44841269841269843, 0.0, 0.4930555555555556, 0.1759765994441808, 0.0, 0.5807816296751069, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:31:43,305] A3C_AGENT_WORKER-Thread-5 INFO:Local step 46000, global step 735240: loss 5.1883
[2017-11-02 11:31:43,699] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.69141290e-02   1.75603956e-01   4.38219965e-01   1.91245586e-01
   1.68015629e-01   4.69546464e-08   2.21519969e-07   1.69052768e-07
   3.59946654e-07], sum to 1.0000
[2017-11-02 11:31:43,728] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [3.0, 78.08333333333333, 4.1, 360.0, 0.0, 0.0, -2.0, 12.14208982110548, 18.0, 21.69018123654013, 22.2, 1.0, 0.0], 
actual action is [-2.0, 18.0], 
sim time next is 5945400.0000, 
raw observation next is [3.0, 77.5, 4.1, 360.0, 0.0, 0.0, -2.0, 12.39578621807422, 18.0, 21.62735188770349, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.41025641025641024, 0.775, 0.3727272727272727, 1.0, 0.0, 0.0, 0.4666666666666667, 0.12395786218074219, 0.0, 0.5181931268147844, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0124. 
=============================================
[2017-11-02 11:31:44,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.47125290e-02   1.54358938e-01   5.40915549e-01   1.29810810e-01
   1.50202245e-01   1.76118357e-13   2.22040030e-12   1.70397323e-12
   1.79796438e-11], sum to 1.0000
[2017-11-02 11:31:44,282] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.833333333333333, 100.0, 4.266666666666667, 286.6666666666667, 0.0, 0.0, -1.083333333333333, 26.55928942391761, 18.0, 20.50867035686719, 19.4, 0.0, 0.0], 
actual action is [-1.166666666666667, 18], 
sim time next is 6041700.0000, 
raw observation next is [3.75, 100.0, 4.35, 285.0, 0.0, 0.0, -1.166666666666667, 26.77516267009811, 18.0, 20.48630451676183, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.42948717948717946, 1.0, 0.39545454545454545, 0.7916666666666666, 0.0, 0.0, 0.4805555555555555, 0.26775162670098107, 0.0, 0.35518635953740435, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:31:44,605] A3C_AGENT_WORKER-Thread-4 INFO:Local step 46000, global step 735598: loss -6.1623
[2017-11-02 11:31:51,147] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.16246544e-01   2.69779544e-02   8.03691566e-01   3.01733334e-02
   2.29105707e-02   1.95868517e-20   1.76713274e-17   5.70526404e-18
   1.26816524e-17], sum to 1.0000
[2017-11-02 11:31:51,205] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.916666666666667, 64.58333333333333, 3.558333333333333, 249.1666666666667, 0.0, 0.0, 2.166666666666667, 22.21056398199854, 21.0, 20.60757792787786, 19.4, 0.0, 40.12869759118633], 
actual action is [2.083333333333333, 20.0], 
sim time next is 6138000.0000, 
raw observation next is [-3.0, 65.0, 3.6, 250.0, 0.0, 0.0, 2.083333333333333, 21.72320790367462, 20.0, 20.82407947001315, 19.4, 0.0, 33.73064517902856], 
processed observation next is [0.0, 0.043478260869565216, 0.2564102564102564, 0.65, 0.32727272727272727, 0.6944444444444444, 0.0, 0.0, 0.5347222222222222, 0.2172320790367462, 0.2857142857142857, 0.4034399242875928, 0.1999999999999998, 0.0, 0.39683111975327723], 
reward next is -0.3571. 
=============================================
[2017-11-02 11:31:52,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   7.17507963e-24   2.30612113e-22   4.82122250e-23
   4.34432800e-23   1.17225526e-03   1.47829145e-01   7.28754029e-02
   7.78123140e-01], sum to 1.0000
[2017-11-02 11:31:52,120] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.0, 70.5, 4.058333333333333, 259.1666666666666, 0.0, 0.0, 2.0, 24.50461794717358, 19.0, 20.65025727879103, 19.4, 0.0, 27.21317565349646], 
actual action is [2.0, 20.0], 
sim time next is 6141600.0000, 
raw observation next is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 24.73731336936322, 20.0, 20.6635242545591, 19.4, 0.0, 25.92967834509388], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.71, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5333333333333333, 0.2473731336936322, 0.2857142857142857, 0.38050346493701426, 0.1999999999999998, 0.0, 0.30505503935404565], 
reward next is -0.2745. 
=============================================
[2017-11-02 11:31:55,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-54.12322235]
 [-57.75716019]
 [-60.4928894 ]
 [-59.81458282]
 [-61.00733948]], R is [[-55.47900009]
 [-55.7088089 ]
 [-55.99330902]
 [-56.24441147]
 [-56.34196472]].
[2017-11-02 11:31:59,110] A3C_AGENT_WORKER-Thread-2 INFO:Local step 46000, global step 738748: loss 32.6121
[2017-11-02 11:32:00,544] A3C_AGENT_WORKER-Thread-10 INFO:Local step 46500, global step 739066: loss 0.0999
[2017-11-02 11:32:00,801] A3C_AGENT_WORKER-Thread-16 INFO:Local step 46500, global step 739126: loss 32.6122
[2017-11-02 11:32:01,281] A3C_AGENT_WORKER-Thread-12 INFO:Local step 46000, global step 739248: loss 44.6781
[2017-11-02 11:32:02,931] A3C_AGENT_WORKER-Thread-13 INFO:Local step 46000, global step 739702: loss 88.9176
[2017-11-02 11:32:03,255] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  7.15565309e-02   4.67091590e-01   2.37166047e-01   3.41983028e-02
   1.89987585e-01   1.44834476e-18   8.18037527e-16   2.67269044e-16
   2.08047730e-16], sum to 1.0000
[2017-11-02 11:32:03,298] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-1.25, 61.25, 2.725, 282.5, 0.0, 0.0, -6.166666666666667, 27.33940655055464, 18.0, 20.54613852589599, 19.4, 0.0, 0.0], 
actual action is [-6.25, 18], 
sim time next is 6128400.0000, 
raw observation next is [-1.333333333333333, 61.66666666666667, 2.766666666666667, 280.0, 0.0, 0.0, -6.25, 28.4340260260529, 18.0, 20.58325418382065, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2991452991452992, 0.6166666666666667, 0.2515151515151515, 0.7777777777777778, 0.0, 0.0, 0.3958333333333333, 0.284340260260529, 0.0, 0.36903631197437853, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:32:04,492] A3C_AGENT_WORKER-Thread-6 INFO:Local step 46500, global step 740103: loss 5.1443
[2017-11-02 11:32:04,755] A3C_AGENT_WORKER-Thread-8 INFO:Local step 46500, global step 740170: loss -3.0968
[2017-11-02 11:32:05,459] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.02909078e-04   4.29085761e-01   3.13447207e-01   1.29936971e-02
   2.43770465e-01   6.65574543e-19   8.25864376e-16   6.61074011e-16
   5.18184942e-15], sum to 1.0000
[2017-11-02 11:32:05,498] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [5.0, 89.16666666666667, 2.600000000000001, 348.3333333333334, 144.0, 0.0, 10.0, 8.426522069966405, 25.0, 23.6385001165282, 20.56, 1.0, 24.66232973731645], 
actual action is [10.0, 23.0], 
sim time next is 6016500.0000, 
raw observation next is [5.0, 87.25, 2.6, 347.5, 139.75, 0.0, 10.0, 8.249790367486586, 23.0, 23.61212938050107, 20.56, 1.0, 45.45854439885042], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.46153846153846156, 0.8725, 0.23636363636363636, 0.9652777777777778, 0.3697089947089947, 0.0, 0.6666666666666666, 0.08249790367486586, 0.7142857142857143, 0.80173276864301, 0.36571428571428555, 1.0, 0.5348064046923579], 
reward next is -0.4896. 
=============================================
[2017-11-02 11:32:05,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.64828216e-18   1.74742970e-10   9.48204071e-10   1.70695041e-10
   4.00051686e-10   9.83369164e-03   2.30495974e-01   3.40879768e-01
   4.18790519e-01], sum to 1.0000
[2017-11-02 11:32:05,734] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.22760802e-09   5.72276767e-05   2.90457654e-04   2.58567979e-05
   7.10538370e-05   7.51779694e-03   4.26782519e-01   4.72866744e-01
   9.23883766e-02], sum to 1.0000
[2017-11-02 11:32:05,765] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [4.5, 52.25, 2.975, 175.0, 0.0, 0.0, 9.666666666666666, 14.16030083139087, 24.0, 22.22324598252349, 22.2, 1.0, 14.48908743096653], 
actual action is [9.5, 25], 
sim time next is 6205800.0000, 
raw observation next is [4.333333333333333, 52.83333333333333, 3.016666666666667, 173.3333333333333, 0.0, 0.0, 9.5, 13.44681922739435, 25.0, 22.20407517888, 22.2, 1.0, 43.59704255553446], 
processed observation next is [0.0, 0.8260869565217391, 0.4444444444444444, 0.5283333333333333, 0.2742424242424243, 0.48148148148148134, 0.0, 0.0, 0.6583333333333333, 0.1344681922739435, 1.0, 0.6005821684114286, 0.5999999999999999, 1.0, 0.5129063830062878], 
reward next is -0.4751. 
=============================================
[2017-11-02 11:32:05,780] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.5833333333333334, 60.0, 3.141666666666667, 314.1666666666666, 0.0, 0.0, -5.5, 18.56660964187095, 18.0, 22.03834450969679, 19.4, 0.0, 0.0], 
actual action is [4.416666666666667, 19.0], 
sim time next is 6122400.0000, 
raw observation next is [-0.6666666666666666, 60.0, 3.033333333333333, 313.3333333333334, 0.0, 0.0, 4.416666666666667, 17.13547977475362, 19.0, 21.92050169436069, 19.4, 0.0, 55.12015059251235], 
processed observation next is [1.0, 0.8695652173913043, 0.3162393162393163, 0.6, 0.27575757575757576, 0.8703703703703707, 0.0, 0.0, 0.5736111111111111, 0.1713547977475362, 0.14285714285714285, 0.5600716706229559, 0.1999999999999998, 0.0, 0.64847235991191], 
reward next is -0.5836. 
=============================================
[2017-11-02 11:32:07,003] A3C_AGENT_WORKER-Thread-14 INFO:Local step 46000, global step 740820: loss 10.0428
[2017-11-02 11:32:07,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.79658998e-02   1.89438865e-01   5.21320462e-01   1.39730815e-02
   2.57301688e-01   8.32227914e-19   7.34882145e-17   8.03988056e-17
   1.10450244e-16], sum to 1.0000
[2017-11-02 11:32:07,877] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 94.66666666666666, 4.933333333333333, 286.6666666666666, 0.0, 0.0, 4.0, 15.81432153990279, 19.0, 21.36545076645709, 19.4, 0.0, 30.23154209090241], 
actual action is [-6.0, 18.0], 
sim time next is 6065100.0000, 
raw observation next is [-1.0, 94.0, 4.975, 287.5, 0.0, 0.0, -6.0, 17.88314198656825, 18.0, 21.34312265626039, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.3076923076923077, 0.94, 0.4522727272727272, 0.7986111111111112, 0.0, 0.0, 0.4, 0.17883141986568252, 0.0, 0.47758895089434156, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:32:07,894] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.05912536e-02   1.86706036e-01   4.64066237e-01   2.60962714e-02
   3.12540203e-01   1.25807355e-17   3.65704675e-16   4.92004381e-16
   7.98699341e-16], sum to 1.0000
[2017-11-02 11:32:07,961] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.333333333333333, 60.66666666666666, 3.1, 186.6666666666667, 0.0, 0.0, 7.416666666666667, 12.98577648710258, 19.5, 21.3877936518725, 19.4, 0.0, 33.5304587623088], 
actual action is [7.333333333333333, 19.0], 
sim time next is 6219900.0000, 
raw observation next is [2.25, 61.0, 3.1, 185.0, 0.0, 0.0, 7.333333333333333, 12.53547361076031, 19.0, 21.65327232992218, 19.4, 0.0, 31.06953799877354], 
processed observation next is [0.0, 1.0, 0.391025641025641, 0.61, 0.2818181818181818, 0.5138888888888888, 0.0, 0.0, 0.6222222222222222, 0.1253547361076031, 0.14285714285714285, 0.5218960471317402, 0.1999999999999998, 0.0, 0.3655239764561593], 
reward next is -0.3290. 
=============================================
[2017-11-02 11:32:10,640] A3C_AGENT_WORKER-Thread-11 INFO:Local step 46000, global step 741942: loss -107.6494
[2017-11-02 11:32:10,761] A3C_AGENT_WORKER-Thread-15 INFO:Local step 46000, global step 741983: loss 23.7382
[2017-11-02 11:32:11,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-28.92433357]
 [-28.97432327]
 [-31.13712692]
 [-31.42792892]
 [-31.61016083]], R is [[-30.99523163]
 [-31.68527985]
 [-32.36842728]
 [-33.04474258]
 [-33.71429443]].
[2017-11-02 11:32:12,510] A3C_AGENT_WORKER-Thread-3 INFO:Local step 46500, global step 742420: loss -1.7871
[2017-11-02 11:32:12,831] A3C_AGENT_WORKER-Thread-7 INFO:Local step 46500, global step 742502: loss -8.7543
[2017-11-02 11:32:13,454] A3C_AGENT_WORKER-Thread-9 INFO:Local step 46500, global step 742695: loss 28.1115
[2017-11-02 11:32:14,468] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.93390383e-03   1.24315709e-01   6.83732510e-01   2.04975139e-02
   1.68519944e-01   1.58957363e-08   1.22010405e-07   2.53795349e-07
   6.24882119e-08], sum to 1.0000
[2017-11-02 11:32:14,480] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 65.0, 3.6, 240.0, 0.0, 0.0, -8.0, 28.61596517433116, 18.0, 20.40418301704842, 19.4, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 6156300.0000, 
raw observation next is [-3.0, 65.0, 3.558333333333333, 239.1666666666667, 0.0, 0.0, -8.0, 31.67668591282249, 18.0, 20.22572531576719, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.2564102564102564, 0.65, 0.3234848484848485, 0.664351851851852, 0.0, 0.0, 0.36666666666666664, 0.3167668591282249, 0.0, 0.3179607593953127, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:32:14,576] A3C_AGENT_WORKER-Thread-17 INFO:Local step 46500, global step 743117: loss -10.1175
[2017-11-02 11:32:15,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.05000884e-03   4.76840585e-01   2.44000137e-01   1.77098662e-02
   2.52399415e-01   3.41696234e-17   1.45799294e-15   1.40055564e-15
   9.62028999e-16], sum to 1.0000
[2017-11-02 11:32:15,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [12.0, 47.0, 7.033333333333334, 236.6666666666667, 143.1666666666667, 855.6666666666666, 7.0, 9.879001693279395, 18.0, 23.12957070985824, 22.2, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 6265500.0000, 
raw observation next is [12.0, 47.0, 6.991666666666666, 240.8333333333333, 143.0833333333333, 856.8333333333334, 7.0, 9.766246169737663, 18.0, 23.15559487058074, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.6410256410256411, 0.47, 0.6356060606060606, 0.6689814814814814, 0.3785273368606701, 0.8568333333333333, 0.6166666666666667, 0.09766246169737663, 0.0, 0.7365135529401056, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0098. 
=============================================
[2017-11-02 11:32:15,956] A3C_AGENT_WORKER-Thread-5 INFO:Local step 46500, global step 743577: loss 1.0707
[2017-11-02 11:32:17,997] A3C_AGENT_WORKER-Thread-4 INFO:Local step 46500, global step 744309: loss -4.6198
[2017-11-02 11:32:18,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-17.53067207]
 [-16.83995438]
 [-18.12867546]
 [-17.60713959]
 [-16.77987289]], R is [[-17.63435555]
 [-17.45801163]
 [-17.28343201]
 [-17.11059761]
 [-16.93949127]].
[2017-11-02 11:32:21,506] A3C_AGENT_WORKER-Thread-10 INFO:Local step 47000, global step 745710: loss 5.2218
[2017-11-02 11:32:22,065] A3C_AGENT_WORKER-Thread-16 INFO:Local step 47000, global step 745954: loss 10.6381
[2017-11-02 11:32:23,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.85783801e-03   6.97422922e-01   1.35933891e-01   1.57961119e-02
   1.48989215e-01   1.34708514e-22   1.09891478e-20   3.92271568e-20
   4.01206540e-20], sum to 1.0000
[2017-11-02 11:32:23,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-1.0, 78.0, 6.575, 322.5, 156.0, 4.5, 4.0, 14.70563900780014, 23.0, 22.25519152596834, 20.56, 1.0, 63.04135014715988], 
actual action is [4.0, 21.0], 
sim time next is 6094200.0000, 
raw observation next is [-1.0, 78.0, 6.616666666666667, 321.6666666666667, 166.0, 5.999999999999998, 4.0, 14.442908443622, 21.0, 22.40337956337774, 20.56, 1.0, 53.41613086748315], 
processed observation next is [1.0, 0.5217391304347826, 0.3076923076923077, 0.78, 0.6015151515151516, 0.8935185185185186, 0.43915343915343913, 0.005999999999999998, 0.5666666666666667, 0.14442908443622002, 0.42857142857142855, 0.6290542233396772, 0.36571428571428555, 1.0, 0.6284250690292135], 
reward next is -0.5800. 
=============================================
[2017-11-02 11:32:24,754] A3C_AGENT_WORKER-Thread-6 INFO:Local step 47000, global step 747026: loss 7.1282
[2017-11-02 11:32:24,877] A3C_AGENT_WORKER-Thread-8 INFO:Local step 47000, global step 747083: loss 9.7446
[2017-11-02 11:32:26,293] A3C_AGENT_WORKER-Thread-2 INFO:Local step 46500, global step 747721: loss 17.0845
[2017-11-02 11:32:27,075] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.23698390e-01   3.83988738e-01   4.60952371e-02   2.21917834e-02
   2.40258127e-02   4.39116025e-18   2.53079697e-17   8.00001708e-17
   6.97392997e-18], sum to 1.0000
[2017-11-02 11:32:27,094] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 31.50534453032151, 23.0, 20.0328621865822, 19.4, 0.0, 42.34246602674953], 
actual action is [-8.0, 18.0], 
sim time next is 6144300.0000, 
raw observation next is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, -8.0, 33.630821730504, 18.0, 20.09535427068699, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.71, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.36666666666666664, 0.33630821730504, 0.0, 0.29933632438385566, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:32:27,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.90581161e-02   5.35828590e-01   1.26226068e-01   1.12824209e-01
   1.36062905e-01   2.70619768e-12   1.43834285e-11   3.76003846e-11
   3.69170389e-11], sum to 1.0000
[2017-11-02 11:32:27,524] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [8.0, 52.0, 1.591666666666667, 196.6666666666667, 0.0, 0.0, 3.0, 23.97602136512159, 18.0, 20.59667812809628, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 6303600.0000, 
raw observation next is [8.0, 52.0, 1.5, 190.0, 0.0, 0.0, 3.0, 24.14564321733978, 18.0, 20.57827239851991, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 1.0, 0.5384615384615384, 0.52, 0.13636363636363635, 0.5277777777777778, 0.0, 0.0, 0.55, 0.24145643217339782, 0.0, 0.3683246283599872, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:32:27,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 46500, global step 748283: loss 8.7292
[2017-11-02 11:32:28,140] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.63220733e-01   1.96616083e-01   2.31663287e-01   2.31748149e-01
   1.75490111e-01   3.50353163e-04   4.52564680e-04   3.78660246e-04
   7.99921836e-05], sum to 1.0000
[2017-11-02 11:32:28,156] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [19.0, 30.0, 10.3, 220.0, 138.5, 826.0, 14.0, 6.37306611716067, 18.0, 24.3776234933033, 19.4, 0.0, 0.0], 
actual action is [14.0, 18], 
sim time next is 6357900.0000, 
raw observation next is [19.08333333333333, 30.0, 10.08333333333333, 220.8333333333333, 138.0833333333333, 822.1666666666666, 14.0, 6.354493044651224, 18.0, 24.41437910700554, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.8226495726495725, 0.3, 0.9166666666666664, 0.6134259259259258, 0.36529982363315683, 0.8221666666666666, 0.7333333333333333, 0.06354493044651224, 0.0, 0.916339872429363, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:32:29,187] A3C_AGENT_WORKER-Thread-9 INFO:Local step 47000, global step 749034: loss 5.6941
[2017-11-02 11:32:29,818] A3C_AGENT_WORKER-Thread-13 INFO:Local step 46500, global step 749355: loss 3.7036
[2017-11-02 11:32:30,478] A3C_AGENT_WORKER-Thread-3 INFO:Local step 47000, global step 749672: loss -0.2675
[2017-11-02 11:32:30,708] A3C_AGENT_WORKER-Thread-7 INFO:Local step 47000, global step 749787: loss 4.1710
[2017-11-02 11:32:31,121] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2017-11-02 11:32:31,129] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:32:31,129] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:EnergyPlus Starting

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:58

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Processing Data Dictionary

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Processing Input File

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Initializing Simulation

[2017-11-02 11:32:31,133] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Reporting Surfaces

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Beginning Primary Simulation

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Initializing New Environment Parameters

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {1}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:ExternalInterface initializes.

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {2}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {3}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {4}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {5}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Warming up {6}

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:32:31,134] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:32:31,135] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:32:31,135] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:32:31,135] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_2 INFO:EnergyPlus Run Time=00hr 34min 22.46sec

[2017-11-02 11:32:32,130] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:32:32,135] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run4
[2017-11-02 11:32:56,920] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.24242705e-01   2.97741473e-01   1.28927529e-01   9.44478139e-02
   5.46405166e-02   4.98264251e-14   1.54152136e-13   3.21128703e-13
   6.47453960e-14]
[2017-11-02 11:32:57,328] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.15779796e-01   2.87754565e-01   2.38795459e-01   1.55303016e-01
   1.02366701e-01   6.79964174e-08   1.10012628e-07   2.34208187e-07
   8.11009002e-08]
[2017-11-02 11:32:57,387] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.19631106e-01   2.95144856e-01   2.38762259e-01   1.48898095e-01
   9.75633711e-02   5.23525969e-08   8.41200318e-08   1.90586888e-07
   6.98508416e-08]
[2017-11-02 11:32:57,670] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.86929858e-01   2.62563378e-01   6.49218410e-02   6.52694926e-02
   2.03154162e-02   7.03303735e-12   1.53105514e-11   7.82532997e-11
   2.29481174e-11]
[2017-11-02 11:33:02,137] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.73454001e-11   4.70839354e-04   7.45931538e-05   1.35719456e-04
   1.03369726e-04   3.58838812e-02   6.88647032e-02   6.69150174e-01
   2.25316823e-01]
[2017-11-02 11:33:02,267] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.67157621e-20   6.62748356e-10   8.13979023e-11   2.02596176e-10
   1.81633750e-10   3.38510461e-02   5.74561805e-02   6.83306992e-01
   2.25385755e-01]
[2017-11-02 11:33:22,507] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.92995433e-08   1.77563876e-01   9.12295748e-03   1.32673457e-02
   2.15337109e-02   6.10228861e-03   2.15995293e-02   5.65365553e-01
   1.85444742e-01]
[2017-11-02 11:33:39,023] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.09250732e-01   7.36702621e-01   4.87869382e-02   3.45993452e-02
   7.06603825e-02   4.11419325e-13   2.24682924e-12   3.42630785e-11
   1.53355592e-11]
[2017-11-02 11:33:39,292] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.58681790e-12   5.35055937e-04   2.61515415e-05   3.89847155e-05
   8.23721202e-05   1.11964988e-02   3.96514498e-02   7.27054894e-01
   2.21414641e-01]
[2017-11-02 11:33:47,243] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.25525425e-23   2.09160082e-13   1.97191201e-14   7.96624594e-14
   3.03983726e-14   6.27278835e-02   7.29902536e-02   8.35788190e-01
   2.84936894e-02]
[2017-11-02 11:33:48,361] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.          0.          0.          0.          0.          0.08591972
  0.03511319  0.87131429  0.00765285]
[2017-11-02 11:33:56,948] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.47764055e-07   4.73931700e-01   2.06642114e-02   2.84774490e-02
   5.75207621e-02   2.64453469e-03   1.22144045e-02   3.06628972e-01
   9.79178026e-02]
[2017-11-02 11:34:00,733] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.31878859e-16   1.82407744e-09   2.53511823e-10   7.67944375e-10
   4.84484286e-10   4.74753082e-02   7.77355582e-02   6.21161044e-01
   2.53628075e-01]
[2017-11-02 11:34:15,134] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.26998257e-06   8.28399122e-01   3.74462605e-02   4.37537394e-02
   8.91271457e-02   5.65929304e-06   3.78164259e-05   6.42472529e-04
   5.79505228e-04]
[2017-11-02 11:34:15,281] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04657638e-05   7.98101962e-01   4.16916758e-02   5.05930148e-02
   9.71107483e-02   5.55474544e-05   4.53239132e-04   5.91530325e-03
   6.06797496e-03]
[2017-11-02 11:34:16,067] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.04610005  0.42208219  0.12601472  0.18567021  0.14300708  0.00191993
  0.00522719  0.03273676  0.03724192]
[2017-11-02 11:34:16,418] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.46422154e-02   4.16189730e-01   1.61822513e-01   1.87036917e-01
   1.80305824e-01   8.76280666e-08   3.35789736e-07   1.34785660e-06
   9.63563707e-07]
[2017-11-02 11:34:18,234] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.91560441e-01   3.29822183e-01   2.11734191e-01   1.08652681e-01
   5.82304001e-02   1.00098513e-10   1.49867230e-10   5.73221359e-10
   2.34164438e-10]
[2017-11-02 11:34:24,517] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.96109009e-01   3.00382346e-01   6.80715293e-02   8.35940987e-02
   5.18430173e-02   1.51493518e-09   3.99583211e-09   1.63308851e-08
   2.22116658e-09]
[2017-11-02 11:34:25,682] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.55391002e-01   1.73757657e-01   2.61391830e-02   3.20929252e-02
   1.26192700e-02   2.42819070e-10   5.79071902e-10   3.90815202e-09
   3.69284381e-10]
[2017-11-02 11:34:28,283] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.39698093e-05   6.34274006e-01   9.59014371e-02   1.24287598e-01
   1.41495436e-01   8.43370508e-05   2.16654240e-04   1.97838014e-03
   1.73820567e-03]
[2017-11-02 11:34:29,032] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.14708893e-35   8.42742827e-19   3.89266931e-20   1.40377332e-19
   2.72914750e-19   1.13928160e-02   2.66090017e-02   6.19299173e-01
   3.42699021e-01]
[2017-11-02 11:34:38,610] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.87897808e-06   5.42676598e-02   8.04944616e-03   1.48808444e-02
   6.76653301e-03   6.50967285e-02   1.01261653e-01   6.63257539e-01
   8.64156708e-02]
[2017-11-02 11:34:38,791] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.00065781  0.61007959  0.0977082   0.15867835  0.06987579  0.00431585
  0.00712825  0.04499146  0.00656465]
[2017-11-02 11:34:40,601] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.42042910e-23   1.98842852e-12   2.01377841e-13   5.54886324e-13
   5.97927957e-13   2.93448735e-02   5.58280200e-02   6.23013616e-01
   2.91813523e-01]
[2017-11-02 11:34:43,209] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.58778208e-01   4.85596359e-01   5.91220409e-02   3.55325304e-02
   6.09708652e-02   5.82415043e-14   2.32993827e-13   1.81560409e-12
   7.44758693e-13]
[2017-11-02 11:34:44,269] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.64186235e-06   6.06766641e-01   4.99998517e-02   5.70493676e-02
   1.01138182e-01   2.83997413e-03   1.03951693e-02   1.04059272e-01
   6.77498654e-02]
[2017-11-02 11:34:44,365] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.09914824e-01   6.70234799e-01   7.24676922e-02   5.04749380e-02
   9.69077647e-02   9.37546395e-12   4.83077502e-11   4.31298719e-10
   3.58203550e-10]
[2017-11-02 11:34:45,814] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.10481736e-02   4.37132508e-01   1.48445711e-01   1.83524281e-01
   1.39733002e-01   3.99675628e-06   1.10084884e-05   5.64009679e-05
   4.49173967e-05]
[2017-11-02 11:34:52,669] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   4.54617637e-22   2.19029171e-23   1.03806446e-22
   1.56084183e-22   1.80866607e-02   2.88002659e-02   7.60916829e-01
   1.92196235e-01]
[2017-11-02 11:34:53,714] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.68601475e-19   2.50449368e-08   1.23295130e-09   2.68308709e-09
   4.27580105e-09   9.91649181e-03   2.74313278e-02   7.30477691e-01
   2.32174426e-01]
[2017-11-02 11:35:02,535] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.34903252e-01   2.36696392e-01   4.64336611e-02   5.53183146e-02
   2.66483370e-02   4.25823110e-09   8.63263150e-09   4.31183089e-08
   8.05460498e-09]
[2017-11-02 11:35:10,096] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.69344538e-01   2.99390882e-01   1.97345540e-01   1.41774416e-01
   9.21446458e-02   3.59174539e-12   7.63080658e-12   1.53808199e-11
   6.04125690e-12]
[2017-11-02 11:35:10,624] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.28885403e-01   2.17158064e-01   2.57913053e-01   2.26301894e-01
   1.69677302e-01   1.29382179e-05   2.11138195e-05   2.46264335e-05
   5.59787168e-06]
[2017-11-02 11:35:11,018] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.03022107e-01   2.90412217e-01   2.18521670e-01   1.66650146e-01
   1.21393859e-01   1.22571966e-10   3.80599385e-10   3.84038329e-10
   5.89566729e-11]
[2017-11-02 11:35:11,465] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.49701804e-01   1.98269710e-01   2.66797006e-01   2.30166301e-01
   1.54865667e-01   4.87995821e-05   6.89082808e-05   6.99347147e-05
   1.18579137e-05]
[2017-11-02 11:35:11,556] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.14747947  0.19891843  0.26218748  0.23335722  0.15408915  0.00108478
  0.00128156  0.00131645  0.00028544]
[2017-11-02 11:35:11,960] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.37678966e-01   2.03253657e-01   2.48245299e-01   2.35217810e-01
   1.74090326e-01   3.89909925e-04   5.21691516e-04   4.91711078e-04
   1.10503555e-04]
[2017-11-02 11:35:12,198] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.41619724e-02   2.26040572e-01   2.83349723e-01   2.20924824e-01
   1.75512865e-01   1.81837595e-06   4.15943123e-06   3.46789238e-06
   6.03994067e-07]
[2017-11-02 11:35:12,243] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.02483787e-01   2.56490976e-01   2.70146877e-01   2.06045985e-01
   1.64831594e-01   1.11032776e-07   3.13401216e-07   2.56091312e-07
   4.10550705e-08]
[2017-11-02 11:35:12,670] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.02045113e-01   2.80139714e-01   2.25277260e-01   1.66353807e-01
   1.26184121e-01   2.41771853e-10   6.81525336e-10   6.60325239e-10
   1.03133072e-10]
[2017-11-02 11:35:13,157] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.39395803e-01   2.03148767e-01   2.58773834e-01   2.32581824e-01
   1.65221810e-01   2.25957760e-04   2.96702172e-04   2.97021528e-04
   5.82236644e-05]
[2017-11-02 11:35:13,536] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34339347e-01   2.00644374e-01   2.53590852e-01   2.38525733e-01
   1.71434402e-01   3.80031415e-04   4.98534879e-04   4.82933072e-04
   1.03818755e-04]
[2017-11-02 11:35:13,727] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.32067558e-02   2.52908379e-01   2.76986748e-01   2.08610520e-01
   1.68287039e-01   8.27447408e-08   2.58300417e-07   2.02459461e-07
   3.06853885e-08]
[2017-11-02 11:35:14,020] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.11939549e-01   2.63433665e-01   2.64961541e-01   2.00617820e-01
   1.59047216e-01   2.64803983e-08   7.97056927e-08   6.54836398e-08
   9.62567714e-09]
[2017-11-02 11:35:14,149] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.11149535e-01   2.63443083e-01   2.65458643e-01   2.00122029e-01
   1.59826532e-01   2.49979237e-08   7.87084176e-08   6.41023661e-08
   9.25803079e-09]
[2017-11-02 11:35:14,183] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.13806382e-01   2.64527023e-01   2.63976634e-01   1.99042737e-01
   1.58647135e-01   1.83185040e-08   5.78225681e-08   4.73423398e-08
   6.78807366e-09]
[2017-11-02 11:35:15,678] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.39637117e-02   5.35947323e-01   1.67205855e-01   1.82396978e-01
   7.04857409e-02   3.36332846e-08   5.76960737e-08   2.28307343e-07
   1.43237799e-07]
[2017-11-02 11:35:18,592] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.37357617e-05   7.78730512e-01   4.93529774e-02   5.65713793e-02
   1.01901241e-01   1.31706416e-04   6.75486051e-04   7.03829667e-03
   5.57472184e-03]
[2017-11-02 11:35:18,851] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.96271907e-02   6.34070098e-01   9.82969776e-02   8.69561657e-02
   1.41049057e-01   4.60255567e-09   2.91583717e-08   1.91370589e-07
   2.25262696e-07]
[2017-11-02 11:35:19,670] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.05570135  0.42163661  0.15025201  0.20430747  0.14662817  0.00060968
  0.00152493  0.00850099  0.01083881]
[2017-11-02 11:35:28,305] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.17764471e-17   2.26284751e-08   2.04188733e-09   4.41452919e-09
   5.76924020e-09   2.19579544e-02   4.72141355e-02   6.62884057e-01
   2.67943829e-01]
[2017-11-02 11:35:28,390] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.67361081e-11   3.63029889e-04   3.39188628e-05   5.75835911e-05
   7.62998316e-05   1.85393654e-02   4.74518575e-02   6.44365907e-01
   2.89112002e-01]
[2017-11-02 11:35:29,693] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.63899773e-01   5.08214653e-01   7.48144016e-02   4.96208742e-02
   1.03450350e-01   1.63408133e-12   8.21702602e-12   3.39361976e-11
   9.07351711e-12]
[2017-11-02 11:35:30,028] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.46242270e-01   4.26430434e-01   1.18762881e-01   7.95501247e-02
   1.29014283e-01   3.28350180e-10   1.08579157e-09   2.12603890e-09
   2.44833376e-10]
[2017-11-02 11:35:30,440] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.93649773e-02   3.70985836e-01   1.70327246e-01   2.31721684e-01
   2.04915345e-01   6.97249488e-05   3.02155880e-04   1.04016415e-03
   1.27291994e-03]
[2017-11-02 11:35:32,153] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.37451351e-01   2.75675207e-01   2.46268600e-01   1.89246133e-01
   1.51358649e-01   7.26642613e-09   2.04319726e-08   1.83004332e-08
   2.87823743e-09]
[2017-11-02 11:35:32,644] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.38088751e-01   3.18867505e-01   1.51884794e-01   1.16010718e-01
   7.51482770e-02   3.45238031e-12   8.88971709e-12   1.65547923e-11
   4.45471004e-12]
[2017-11-02 11:35:32,770] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.19037104e-01   3.01135659e-01   1.27069905e-01   9.52872187e-02
   5.74701168e-02   3.27541732e-13   9.01052074e-13   1.94604055e-12
   5.02514480e-13]
[2017-11-02 11:35:32,965] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.68556374e-01   2.93277711e-01   1.08851589e-01   8.62625614e-02
   4.30517793e-02   2.94765406e-13   7.85518026e-13   2.10446612e-12
   5.77801153e-13]
[2017-11-02 11:35:32,980] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.70115215e-01   2.93182284e-01   1.08360514e-01   8.60741064e-02
   4.22678590e-02   2.55085232e-13   6.82997766e-13   1.85646702e-12
   5.06130077e-13]
[2017-11-02 11:35:33,081] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.54617214e-01   3.10761541e-01   2.04518899e-01   1.43508911e-01
   8.65934640e-02   1.13929508e-11   2.10461700e-11   4.91890868e-11
   2.21617898e-11]
[2017-11-02 11:35:33,180] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.71975538e-01   2.43631512e-01   2.63800561e-01   2.05423012e-01
   1.15162432e-01   1.18424100e-06   1.99536453e-06   3.04705100e-06
   7.54318876e-07]
[2017-11-02 11:35:33,615] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.03611016e-01   3.10341835e-01   2.22336859e-01   1.63885891e-01
   9.98243615e-02   2.72453260e-09   4.39497372e-09   9.42950340e-09
   4.43746018e-09]
[2017-11-02 11:35:33,940] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.19483108e-04   5.87703228e-01   1.28758952e-01   1.93727076e-01
   8.74262974e-02   9.36126380e-05   1.73684050e-04   1.16104912e-03
   6.36610202e-04]
[2017-11-02 11:35:34,871] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.10316098e-01   2.51323134e-01   5.81215546e-02   6.27543107e-02
   1.74848400e-02   2.98910098e-11   6.00452257e-11   3.44168305e-10
   1.08274230e-10]
[2017-11-02 11:35:36,608] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.53763616e-01   1.77614182e-01   2.66338587e-02   3.11210360e-02
   1.08673181e-02   1.92881267e-11   4.94572959e-11   3.33176320e-10
   3.80976951e-11]
[2017-11-02 11:35:37,228] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.63188660e-01   1.69259369e-01   2.55918037e-02   3.09007112e-02
   1.10594230e-02   4.15535106e-11   1.04099541e-10   7.15833837e-10
   6.76562209e-11]
[2017-11-02 11:35:48,921] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.59447737e-13   5.97542282e-07   7.72689930e-08   2.11673324e-07
   7.23133340e-08   7.38597438e-02   9.72291231e-02   7.75435865e-01
   5.34742624e-02]
[2017-11-02 11:35:49,629] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.57803977e-01   1.73765630e-01   2.53686234e-02   3.05985324e-02
   1.24633117e-02   4.45844715e-11   1.19146859e-10   7.64586450e-10
   6.21359908e-11]
[2017-11-02 11:36:23,389] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.17149711e-01   2.47977495e-01   4.81489748e-02   5.88818416e-02
   2.78418381e-02   1.65656893e-08   3.19438698e-08   1.64763932e-07
   2.77761938e-08]
[2017-11-02 11:36:25,082] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.07148821e-15   2.71453704e-08   3.98244060e-09   1.05221556e-08
   4.51655424e-09   9.14494321e-02   1.07202731e-01   7.17398286e-01
   8.39494616e-02]
[2017-11-02 11:36:37,292] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.00627392  0.54838741  0.11122482  0.14647469  0.14268915  0.00058122
  0.00265898  0.01800631  0.02370354]
[2017-11-02 11:36:41,286] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.10355276e-15   9.77602568e-08   1.84174418e-08   4.70076245e-08
   1.67769496e-08   1.00431494e-01   1.14203893e-01   6.38652086e-01
   1.46712318e-01]
[2017-11-02 11:36:52,138] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.95716671e-03   8.03040087e-01   5.50324880e-02   4.67610843e-02
   9.32086185e-02   6.10787687e-09   2.70968332e-08   3.23643150e-07
   1.55034712e-07]
[2017-11-02 11:37:11,635] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.82268466e-02   7.04514623e-01   7.53050521e-02   5.23888171e-02
   1.29564688e-01   6.01689976e-13   5.86012619e-12   4.86918283e-11
   3.99673350e-11]
[2017-11-02 11:37:44,288] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.57402948e-02   4.23569947e-01   1.56022534e-01   1.89056799e-01
   1.65594205e-01   5.38895733e-07   1.84905934e-06   8.08334153e-06
   5.70942575e-06]
[2017-11-02 11:37:44,497] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.20161504e-01   4.32269454e-01   1.39687881e-01   1.68830305e-01
   1.39032930e-01   6.43385135e-07   1.80612608e-06   9.27302426e-06
   6.30149907e-06]
[2017-11-02 11:37:46,280] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.87407672e-01   2.07534119e-01   3.59672979e-02   4.94307540e-02
   1.96597949e-02   2.45205687e-08   4.96312644e-08   2.65283461e-07
   3.86080679e-08]
[2017-11-02 11:38:01,595] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.12627656e-12   8.56692532e-06   1.31065701e-06   2.98788018e-06
   1.38767120e-06   9.13185552e-02   1.15550265e-01   6.92384481e-01
   1.00732453e-01]
[2017-11-02 11:38:08,036] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.98760027e-01   4.67390776e-01   8.89570639e-02   5.53891473e-02
   8.95030424e-02   8.58494116e-14   3.52490823e-13   1.45914010e-12
   5.22300790e-13]
[2017-11-02 11:38:08,158] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.98031867e-01   4.55645561e-01   9.35198143e-02   5.90029098e-02
   9.37999263e-02   1.89610060e-13   7.60663288e-13   2.77662268e-12
   8.86284644e-13]
[2017-11-02 11:38:16,005] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.60046077e-31   8.28560416e-17   6.07727197e-18   2.15773835e-17
   2.85496425e-17   2.35139690e-02   4.21722382e-02   6.37985051e-01
   2.96328634e-01]
[2017-11-02 11:38:20,731] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.64193586e-01   6.13563299e-01   8.06836411e-02   5.06587699e-02
   9.09007341e-02   3.49434544e-12   1.48384464e-11   9.81476705e-11
   5.71783142e-11]
[2017-11-02 11:38:21,632] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.0456248   0.4129146   0.1485244   0.19984315  0.15139371  0.00132807
  0.00381275  0.01775279  0.0188057 ]
[2017-11-02 11:38:35,408] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.73199350e-01   5.58110595e-01   5.80486841e-02   3.86121571e-02
   7.20292106e-02   2.75134570e-13   1.37348900e-12   1.38088152e-11
   6.67282072e-12]
[2017-11-02 11:38:35,760] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.87916924e-03   7.86435425e-01   5.92548586e-02   5.17650843e-02
   9.86624956e-02   4.91339733e-08   2.02168494e-07   1.98596672e-06
   6.71723058e-07]
[2017-11-02 11:38:36,708] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.34273649e-08   2.29906160e-02   1.91497419e-03   2.43966584e-03
   4.16892488e-03   1.92839745e-02   7.06196949e-02   5.97385705e-01
   2.81196415e-01]
[2017-11-02 11:38:43,980] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.19632260e-06   3.81485187e-02   5.14082937e-03   1.02181453e-02
   4.83526103e-03   7.08220080e-02   1.10798150e-01   6.87203646e-01
   7.28252530e-02]
[2017-11-02 11:38:49,871] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.73194826e-01   6.03679717e-01   7.16627240e-02   4.86569330e-02
   1.02805734e-01   3.71850380e-12   2.01536374e-11   1.16082408e-10
   3.89029156e-11]
[2017-11-02 11:38:50,545] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.88201566e-02   7.23784268e-01   6.34949654e-02   4.94197607e-02
   1.14480861e-01   1.17600443e-10   8.74356310e-10   8.67840466e-09
   7.33677519e-09]
[2017-11-02 11:38:51,000] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.76526208e-02   4.86368299e-01   1.36839420e-01   1.70138374e-01
   1.56308919e-01   5.73824509e-05   2.07242105e-04   1.16159697e-03
   1.26602966e-03]
[2017-11-02 11:38:52,457] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.08076756e-02   5.40843129e-01   1.14549287e-01   1.75270185e-01
   1.20303348e-01   3.15252779e-04   6.47113367e-04   4.62300191e-03
   2.64102942e-03]
[2017-11-02 11:38:53,125] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.32089716e-01   3.10146421e-01   1.12255625e-01   1.00785106e-01
   4.47231196e-02   2.06265543e-11   4.42546833e-11   1.28848987e-10
   4.45800029e-11]
[2017-11-02 11:38:53,203] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.60983664e-01   3.04765999e-01   1.00360170e-01   9.53022465e-02
   3.85879315e-02   3.74463620e-11   7.65564209e-11   2.63153804e-10
   1.05388531e-10]
[2017-11-02 11:38:53,329] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.59120899e-01   3.02785099e-01   9.85732973e-02   1.01009488e-01
   3.85112576e-02   4.87993534e-10   8.74881279e-10   3.39479778e-09
   1.78059933e-09]
[2017-11-02 11:38:56,462] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.08077669e-01   2.74667233e-01   2.53054619e-01   1.72324851e-01
   9.18750390e-02   8.58512621e-08   1.26245538e-07   2.57452996e-07
   8.68771721e-08]
[2017-11-02 11:39:00,629] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.47559289e-08   1.64957636e-03   2.29217549e-04   5.06558688e-04
   1.78117538e-04   6.37674332e-02   9.68487337e-02   7.74573803e-01
   6.22465611e-02]
[2017-11-02 11:39:00,776] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.00082289  0.60712588  0.08725683  0.15612279  0.05784775  0.00517044
  0.00920579  0.07049257  0.00595496]
[2017-11-02 11:39:11,316] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.99103621e-05   8.16327095e-01   4.25410457e-02   4.34397049e-02
   9.71133038e-02   5.06645392e-06   2.66363986e-05   3.43397551e-04
   1.33935784e-04]
[2017-11-02 11:39:21,518] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.49646648e-16   3.23011432e-06   1.93097492e-07   3.18441664e-07
   6.50872380e-07   9.25628748e-03   3.65111418e-02   5.83978891e-01
   3.70249242e-01]
[2017-11-02 11:39:22,830] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.63097047e-03   8.10368896e-01   5.33095263e-02   4.19274904e-02
   8.87632072e-02   4.70224901e-11   2.61447308e-10   4.18555901e-09
   2.33659203e-09]
[2017-11-02 11:39:26,655] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.36427402e-01   2.25331098e-01   5.07204570e-02   5.76248430e-02
   2.98962891e-02   6.85356424e-11   1.86828678e-10   6.06282857e-10
   3.82869500e-11]
[2017-11-02 11:39:27,400] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.97932329e-03   5.61153412e-01   1.53167561e-01   2.07042485e-01
   7.25236535e-02   1.07397254e-05   1.68944134e-05   7.26595099e-05
   3.32365198e-05]
[2017-11-02 11:39:28,509] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.08896709e-05   1.90473124e-01   2.90774796e-02   4.97622378e-02
   2.71454081e-02   5.34474067e-02   8.51640552e-02   4.84508693e-01
   8.04007351e-02]
[2017-11-02 11:39:29,428] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.40147364e-01   2.88776159e-01   7.04788342e-02   6.91409633e-02
   3.14566642e-02   1.71512304e-10   3.63268859e-10   1.65864944e-09
   4.85412543e-10]
[2017-11-02 11:39:33,940] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.23577356e-01   2.45032489e-01   4.92344461e-02   5.56403063e-02
   2.65154466e-02   1.42259804e-09   3.02887626e-09   1.48555133e-08
   2.90467495e-09]
[2017-11-02 11:39:38,913] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.15934201e-01   4.91419286e-01   1.24534957e-01   1.41107991e-01
   1.26538575e-01   1.79641502e-05   4.58604700e-05   2.44821713e-04
   1.56279668e-04]
[2017-11-02 11:39:41,262] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.50327611e-02   4.46778864e-01   1.36759773e-01   1.86837196e-01
   1.37215436e-01   2.04533571e-04   5.33669896e-04   3.31898499e-03
   3.31888371e-03]
[2017-11-02 11:39:42,503] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.53350495e-02   6.48292959e-01   1.03936091e-01   1.65214851e-01
   6.51806444e-02   1.38753094e-04   2.49453995e-04   1.47408724e-03
   1.78102709e-04]
[2017-11-02 11:39:44,414] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.24661699e-01   5.94255984e-01   9.36155245e-02   1.29655346e-01
   5.78017160e-02   5.89517185e-07   1.18849755e-06   7.01692261e-06
   9.32805506e-07]
[2017-11-02 11:39:45,989] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.0020316   0.61806661  0.08226149  0.14811321  0.06417489  0.00515772
  0.00937425  0.06508214  0.00573807]
[2017-11-02 11:39:52,698] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.14726567e-01   5.97200930e-01   6.00290932e-02   4.15530279e-02
   8.64903778e-02   2.00753953e-12   1.08931380e-11   8.23861951e-11
   3.02305923e-11]
[2017-11-02 11:39:53,393] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.19085310e-02   7.73387253e-01   6.22803122e-02   4.90412749e-02
   9.33826119e-02   1.72160286e-09   7.79473552e-09   6.66554172e-08
   2.66394053e-08]
[2017-11-02 11:39:56,963] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.21608794e-01   2.38295078e-01   5.15600927e-02   6.19830228e-02
   2.65530143e-02   4.49205756e-10   1.06441700e-09   3.76954246e-09
   4.48945381e-10]
[2017-11-02 11:39:59,105] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.84972839e-06   2.24551372e-02   3.32647236e-03   6.62356103e-03
   2.79920525e-03   7.44863600e-02   1.11360952e-01   6.94838047e-01
   8.41084048e-02]
[2017-11-02 11:40:00,829] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.49807990e-01   2.28892028e-01   4.49918061e-02   5.11569493e-02
   2.51512323e-02   2.59408023e-10   6.04210293e-10   2.72895417e-09
   4.11495255e-10]
[2017-11-02 11:40:04,328] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.37767550e-02   6.82116449e-01   6.90011904e-02   4.83355224e-02
   1.06770076e-01   5.99311356e-12   4.09642459e-11   3.48869517e-10
   2.19666924e-10]
[2017-11-02 11:40:04,759] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.77994162e-01   5.76944232e-01   7.91074634e-02   5.09588458e-02
   1.14995338e-01   1.03072325e-12   5.92950255e-12   2.48569481e-11
   6.45539655e-12]
[2017-11-02 11:40:09,472] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.60810244e-01   3.04544449e-01   1.02285489e-01   9.37393531e-02
   3.86205353e-02   1.57516951e-11   3.29553294e-11   1.16464768e-10
   5.13695891e-11]
[2017-11-02 11:40:17,023] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.28206088e-18   2.85447499e-10   3.72533636e-11   1.16559026e-10
   4.39488064e-11   8.50685313e-02   9.66338441e-02   7.58508384e-01
   5.97892851e-02]
[2017-11-02 11:40:27,592] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.37173694e-01   3.06390941e-01   1.08856015e-01   1.02291971e-01
   4.52873223e-02   1.27391764e-10   2.52260962e-10   7.42307826e-10
   2.83568363e-10]
[2017-11-02 11:40:28,516] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.99539554e-01   2.79511690e-01   1.00371085e-01   8.32334086e-02
   3.73443216e-02   2.79847109e-13   7.29576935e-13   2.14395342e-12
   5.53907614e-13]
[2017-11-02 11:40:28,990] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.15969355  0.21651959  0.25199726  0.22042398  0.14831005  0.00076075
  0.00098829  0.00103293  0.00027358]
[2017-11-02 11:40:30,009] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.57659799e-01   2.07359299e-01   2.45534256e-01   2.21941054e-01
   1.65380538e-01   5.26817981e-04   7.22574652e-04   6.84653816e-04
   1.90950814e-04]
[2017-11-02 11:40:30,978] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.37306166e-01   2.97367185e-01   1.21912673e-01   9.61910263e-02
   4.72229384e-02   1.50771038e-13   4.35399275e-13   1.02008668e-12
   2.02646371e-13]
[2017-11-02 11:40:33,889] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.12854523e-05   1.02578402e-01   1.67388208e-02   3.02168094e-02
   1.35530289e-02   6.19063340e-02   9.42030773e-02   5.91163278e-01
   8.96289796e-02]
[2017-11-02 11:40:38,736] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.13888574e-01   4.20996964e-01   6.59298450e-02   3.98885272e-02
   5.92960455e-02   4.01067763e-14   1.50357754e-13   8.74273689e-13
   3.07545845e-13]
[2017-11-02 11:40:40,755] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.75703043e-02   4.24141765e-01   1.57252014e-01   1.95285678e-01
   1.45128429e-01   2.18999667e-05   5.77110550e-05   2.79514701e-04
   2.62740097e-04]
[2017-11-02 11:40:43,325] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.00058062  0.57949924  0.0918217   0.15445437  0.06772575  0.00743348
  0.01241156  0.07572203  0.01035127]
[2017-11-02 11:40:49,461] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.86008507e-01   5.14083803e-01   6.94082677e-02   4.42142710e-02
   8.62851292e-02   2.88223574e-13   1.33155325e-12   6.90092558e-12
   2.20620679e-12]
[2017-11-02 11:40:49,608] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.01138520e-01   5.00876427e-01   6.87802285e-02   4.36900295e-02
   8.55148211e-02   1.98520521e-13   9.15264175e-13   4.67020519e-12
   1.42572380e-12]
[2017-11-02 11:40:49,715] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.16710860e-01   5.01444221e-01   6.38624728e-02   3.98581438e-02
   7.81242475e-02   1.50240944e-13   6.82289728e-13   3.97780506e-12
   1.25092720e-12]
[2017-11-02 11:40:52,767] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.54787105e-01   3.13702732e-01   8.85325372e-02   8.93781483e-02
   5.35994619e-02   7.42770290e-11   1.99849193e-10   5.43080636e-10
   7.25143348e-11]
[2017-11-02 11:40:53,202] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.96164596e-01   3.24595720e-01   1.15009353e-01   1.15582868e-01
   4.86475155e-02   7.30215888e-10   1.29148237e-09   4.43018511e-09
   2.53022070e-09]
[2017-11-02 11:41:00,950] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04812533e-02   7.89979100e-01   5.81182018e-02   4.69651185e-02
   9.44561437e-02   3.30216654e-09   1.41876662e-08   1.43618692e-07
   4.82901008e-08]
[2017-11-02 11:41:04,524] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.02285981e-01   2.43464395e-01   5.52151054e-02   6.46101534e-02
   3.44243236e-02   2.85482332e-10   7.37260364e-10   2.40054843e-09
   1.90247679e-10]
[2017-11-02 11:41:08,845] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.51616106e-27   4.34172175e-16   3.94981919e-17   1.82314802e-16
   7.54316986e-17   7.25272894e-02   7.51018003e-02   8.21788967e-01
   3.05818580e-02]
[2017-11-02 11:41:10,095] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.          0.          0.          0.          0.          0.07854564
  0.0380077   0.87503457  0.0084121 ]
[2017-11-02 11:41:14,070] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.99339616e-34   4.04757796e-18   1.29041520e-19   5.27583291e-19
   8.94933322e-19   8.98635294e-03   2.08365880e-02   7.99745440e-01
   1.70431599e-01]
[2017-11-02 11:41:21,232] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.42831248e-01   3.62920433e-01   6.64790869e-02   8.68851990e-02
   4.08829041e-02   8.75069404e-08   1.65588361e-07   8.40850134e-07
   1.45122399e-07]
[2017-11-02 11:41:27,289] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.27120182e-01   6.27064705e-01   7.45092109e-02   5.56110144e-02
   1.15694806e-01   3.21409913e-11   1.97242264e-10   1.08784315e-09
   3.68598291e-10]
[2017-11-02 11:41:27,966] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.62398919e-01   5.91714680e-01   7.69885555e-02   5.18298373e-02
   1.17067978e-01   4.21342475e-12   2.44401097e-11   1.07216284e-10
   2.34375713e-11]
[2017-11-02 11:41:28,249] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.78254142e-01   5.54525733e-01   8.54437873e-02   5.82542643e-02
   1.23522021e-01   2.48386173e-11   1.30160938e-10   4.17302193e-10
   6.39543626e-11]
[2017-11-02 11:41:30,972] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.48322576e-20   2.52626149e-11   3.27502782e-12   1.08942022e-11
   3.86517250e-12   8.75905901e-02   9.38964561e-02   7.57059932e-01
   6.14530183e-02]
[2017-11-02 11:41:36,857] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.26744155e-03   8.16791713e-01   4.72003557e-02   4.12405580e-02
   9.34974551e-02   2.46158312e-08   1.32986671e-07   1.60892489e-06
   6.50401716e-07]
[2017-11-02 11:41:39,826] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.12663221e-01   3.08486253e-01   1.23911522e-01   1.04248486e-01
   5.06904982e-02   4.51912466e-12   1.07863657e-11   2.64003906e-11
   6.99562023e-12]
[2017-11-02 11:41:40,068] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.51139033e-01   3.05363089e-01   1.05714388e-01   9.68906283e-02
   4.08929549e-02   1.14430453e-11   2.43238225e-11   7.91159777e-11
   2.81275732e-11]
[2017-11-02 11:41:41,637] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.68521032e-01   2.52574086e-01   2.51812130e-01   2.04516545e-01
   1.22471832e-01   1.93486503e-05   2.78949192e-05   4.28924868e-05
   1.42238714e-05]
[2017-11-02 11:41:42,239] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.53322622e-01   2.27074668e-01   2.40150839e-01   2.18920231e-01
   1.60199672e-01   6.90266679e-05   1.04730032e-04   1.20472279e-04
   3.76796270e-05]
[2017-11-02 11:41:43,488] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.94485199e-01   2.85510033e-01   1.00477621e-01   8.36542547e-02
   3.58728953e-02   1.75481022e-13   4.84851471e-13   1.42621050e-12
   3.23528205e-13]
[2017-11-02 11:41:45,750] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.63883936e-01   3.53130519e-01   6.79620579e-02   7.80450106e-02
   3.69785316e-02   3.93980049e-09   8.23684854e-09   4.43165007e-08
   8.68101679e-09]
[2017-11-02 11:41:46,880] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.15816309e-34   9.58450234e-20   1.12544627e-20   4.67125565e-20
   4.54803159e-20   4.43225577e-02   5.84710836e-02   5.58751047e-01
   3.38455200e-01]
[2017-11-02 11:41:48,757] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.22341800e-01   3.82977307e-01   1.15548201e-01   7.34614804e-02
   1.05671190e-01   1.47732889e-12   4.82236690e-12   1.21117803e-11
   2.92781598e-12]
[2017-11-02 11:41:52,008] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.72414207e-01   2.78576612e-01   2.06758544e-01   1.46006525e-01
   9.62441266e-02   9.72630396e-12   2.76112241e-11   3.34480950e-11
   6.47032211e-12]
[2017-11-02 11:41:55,762] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.40896696e-02   5.55154860e-01   1.21984839e-01   1.29176319e-01
   1.59565017e-01   3.83357019e-07   2.01927992e-06   1.19901133e-05
   1.48311392e-05]
[2017-11-02 11:41:56,051] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.03031401  0.40547323  0.1461017   0.20054623  0.15606169  0.00145831
  0.00472966  0.02330008  0.03201505]
[2017-11-02 11:41:58,681] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.41935554e-04   5.43806970e-01   1.26054049e-01   2.00104252e-01
   7.18409717e-02   4.52185143e-03   7.01641571e-03   3.46479081e-02
   1.18655963e-02]
[2017-11-02 11:41:59,204] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.41892136e-03   6.63186491e-01   1.03598148e-01   1.60147741e-01
   6.64890930e-02   7.56768932e-05   1.42131466e-04   8.12263635e-04
   1.29597931e-04]
[2017-11-02 11:42:02,275] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.00054714e-09   6.67699277e-02   4.25194716e-03   5.71132777e-03
   1.06421988e-02   7.02055311e-03   2.82195844e-02   5.09074509e-01
   3.68309975e-01]
[2017-11-02 11:42:03,410] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.65306144e-11   2.84456671e-03   1.24194499e-04   1.99281581e-04
   3.71387810e-04   7.54169840e-03   2.80139688e-02   6.89741254e-01
   2.71163732e-01]
[2017-11-02 11:42:06,039] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.43952647e-02   3.77258152e-01   1.77409187e-01   2.17631772e-01
   2.03239307e-01   1.90774472e-06   8.54131304e-06   2.87234470e-05
   2.71985482e-05]
[2017-11-02 11:42:08,443] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.17410270e-02   6.53956115e-01   1.02841273e-01   1.39908269e-01
   8.14932883e-02   4.13031148e-06   8.14670148e-06   4.02269434e-05
   7.49067794e-06]
[2017-11-02 11:42:11,658] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.03333493e-02   6.71282709e-01   9.78862271e-02   6.46712035e-02
   1.25826567e-01   6.16778460e-12   3.98160047e-11   3.11813408e-10
   3.80157683e-10]
[2017-11-02 11:42:15,182] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.26942563e-01   3.20736378e-01   1.56457588e-01   1.20477498e-01
   7.53859878e-02   7.15715941e-12   1.75433314e-11   3.17566910e-11
   8.26037155e-12]
[2017-11-02 11:42:20,178] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.20339417e-02   7.11358428e-01   5.92643507e-02   3.76040936e-02
   1.19739197e-01   1.42970596e-15   1.51250980e-14   1.30417907e-13
   5.89402320e-14]
[2017-11-02 11:42:22,398] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.04614013  0.38163933  0.12132585  0.18162104  0.14025594  0.00314256
  0.00846348  0.05123013  0.06618149]
[2017-11-02 11:42:22,408] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.85046400e-05   1.83015689e-02   4.27569309e-03   7.79063022e-03
   5.71699347e-03   2.69055404e-02   6.48589581e-02   4.17241514e-01
   4.54850554e-01]
[2017-11-02 11:42:25,416] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.84690493e-10   8.02475988e-05   1.16667361e-05   2.70953606e-05
   9.80341156e-06   7.25013763e-02   1.00418873e-01   7.55527794e-01
   7.14231059e-02]
[2017-11-02 11:42:33,143] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.41469990e-06   7.73055911e-01   4.23484743e-02   4.47808057e-02
   1.06389351e-01   3.57920624e-04   1.60526414e-03   2.25667339e-02
   8.89217760e-03]
[2017-11-02 11:42:35,383] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.13531064e-04   5.30509055e-01   1.22492187e-01   1.96958348e-01
   7.01334253e-02   6.58322219e-03   9.59696528e-03   4.67331931e-02
   1.67800933e-02]
[2017-11-02 11:42:38,100] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.69677106e-09   2.01585470e-04   2.51598740e-05   5.81602435e-05
   2.49100449e-05   7.56972581e-02   1.10229649e-01   7.48196781e-01
   6.55665249e-02]
[2017-11-02 11:42:38,805] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.03692913e-01   2.00152352e-01   3.44306454e-02   4.14009467e-02
   2.03230530e-02   3.16299403e-10   7.61081864e-10   3.96085831e-09
   4.61042260e-10]
[2017-11-02 11:42:41,563] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.03196365e-07   7.59063244e-01   3.73034030e-02   4.39823307e-02
   1.00762621e-01   3.57892772e-04   1.49930816e-03   3.89840268e-02
   1.80470068e-02]
[2017-11-02 11:42:41,897] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.18875038e-12   6.72223163e-04   2.87396324e-05   4.43068129e-05
   9.75072035e-05   6.41046278e-03   2.35453025e-02   7.16729045e-01
   2.52472371e-01]
[2017-11-02 11:42:44,130] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.01784536e-08   2.15315837e-02   1.70085276e-03   2.22103973e-03
   4.03629243e-03   1.38675133e-02   5.76725230e-02   5.41103959e-01
   3.57866228e-01]
[2017-11-02 11:42:45,107] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.30610031e-01   3.00719768e-01   1.17984779e-01   1.00518160e-01
   5.01672067e-02   1.29011090e-11   2.89200122e-11   6.99089536e-11
   1.90645676e-11]
[2017-11-02 11:42:45,216] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.47564095e-01   3.01265359e-01   1.09119415e-01   9.71550494e-02
   4.48960923e-02   3.37762630e-11   7.06184833e-11   1.93966052e-10
   6.10387782e-11]
[2017-11-02 11:42:51,697] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.39098483e-01   3.72591674e-01   1.16666541e-01   7.36143589e-02
   9.80289429e-02   3.75781058e-13   1.26251331e-12   3.46491087e-12
   9.87667196e-13]
[2017-11-02 11:42:53,418] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.02904788  0.32667774  0.13149522  0.18991664  0.13576251  0.00541885
  0.01437667  0.06824485  0.0990596 ]
[2017-11-02 11:42:53,859] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.54734010e-01   3.61299485e-01   1.53201073e-01   1.32366166e-01
   9.83992070e-02   4.42451666e-11   1.24255370e-10   2.65152206e-10
   7.22886473e-11]
[2017-11-02 11:42:55,999] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.15319686e-03   6.49079204e-01   1.02846652e-01   1.52527213e-01
   8.78486782e-02   1.87997546e-04   3.32807889e-04   1.70032948e-03
   3.23880377e-04]
[2017-11-02 11:42:58,060] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.20173493e-02   6.31874323e-01   1.12037331e-01   7.10481107e-02
   1.13022923e-01   2.73538761e-11   1.15756078e-10   6.90650037e-10
   6.71938893e-10]
[2017-11-02 11:43:02,198] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.55888551e-01   2.84065157e-01   2.07541287e-01   1.46908551e-01
   1.05596513e-01   3.72856676e-11   9.88556667e-11   1.17190868e-10
   2.52801894e-11]
[2017-11-02 11:43:02,948] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.14621496  0.20501341  0.25503626  0.22738409  0.1555465   0.00292779
  0.00344339  0.00354595  0.00088767]
[2017-11-02 11:43:06,736] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.90140653e-01   3.09310257e-01   1.34985447e-01   1.05986863e-01
   5.95767461e-02   3.14350846e-12   7.39412784e-12   1.64095976e-11
   5.20821710e-12]
[2017-11-02 11:43:06,937] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.09287840e-01   3.10937703e-01   1.24688677e-01   1.04044668e-01
   5.10411188e-02   5.57371423e-12   1.24267324e-11   3.25632125e-11
   1.14567808e-11]
[2017-11-02 11:43:07,270] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.30246961e-01   2.73635805e-01   2.55134463e-01   1.67036846e-01
   7.39459172e-02   1.08146203e-08   1.55318212e-08   3.46232945e-08
   1.04831690e-08]
[2017-11-02 11:43:07,457] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.99989676e-01   2.79225945e-01   2.60281086e-01   1.69707030e-01
   9.07773525e-02   3.04699415e-06   4.50735843e-06   8.40038501e-06
   2.85385977e-06]
[2017-11-02 11:43:13,241] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.60763085e-18   1.88586102e-09   2.60734379e-10   7.81718079e-10
   2.53059712e-10   7.72566721e-02   9.10250545e-02   7.62771666e-01
   6.89466670e-02]
[2017-11-02 11:43:13,601] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.36549224e-02   6.38262808e-01   1.04021974e-01   1.53420493e-01
   6.05774224e-02   3.79077255e-06   7.28641953e-06   4.52270688e-05
   6.11297855e-06]
[2017-11-02 11:43:18,264] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.53351187e-04   8.28695297e-01   4.36839759e-02   3.97092216e-02
   8.73545110e-02   2.92481754e-08   1.72119087e-07   2.33897958e-06
   1.21663550e-06]
[2017-11-02 11:43:22,279] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.62607035e-04   4.60379034e-01   7.07178563e-02   1.29796445e-01
   4.81371656e-02   2.04942040e-02   3.36544178e-02   2.08384842e-01
   2.81734336e-02]
[2017-11-02 11:43:24,812] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.15676506  0.21435174  0.24326046  0.22153088  0.16146761  0.00062415
  0.00087332  0.0008624   0.0002643 ]
[2017-11-02 11:43:25,730] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.57164380e-01   2.47452423e-01   2.51867533e-01   1.97436854e-01
   1.46078140e-01   1.06428452e-07   2.08017809e-07   2.36818238e-07
   5.55087460e-08]
[2017-11-02 11:43:26,554] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.77075636e-01   2.95433044e-01   9.98800173e-02   8.97137448e-02
   3.78974527e-02   6.22959063e-12   1.37689591e-11   4.38753339e-11
   1.43279416e-11]
[2017-11-02 11:43:27,560] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.47147235e-04   5.11821151e-01   7.07458183e-02   1.27967373e-01
   4.91329767e-02   1.50732296e-02   2.72217225e-02   1.77930966e-01
   1.99596472e-02]
[2017-11-02 11:43:29,185] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.15900925  0.20594758  0.24786456  0.22125146  0.16302986  0.00071272
  0.00098426  0.00093437  0.00026597]
[2017-11-02 11:43:31,801] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.54655194e-01   2.78124720e-01   6.31565899e-02   6.61188960e-02
   3.79445627e-02   5.06330644e-10   1.11684895e-09   4.90586149e-09
   1.05728215e-09]
[2017-11-02 11:43:35,607] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.78612763e-01   3.77849162e-01   1.32732689e-01   8.73262733e-02
   1.23479061e-01   6.07983585e-12   1.86835443e-11   3.93628047e-11
   7.19743449e-12]
[2017-11-02 11:43:38,072] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.92378187e-01   3.26310843e-01   1.70243695e-01   1.23160109e-01
   8.79071578e-02   2.35938977e-11   5.56711933e-11   9.60665089e-11
   3.32118603e-11]
[2017-11-02 11:43:40,752] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.27092367e-02   3.44473958e-01   2.40272507e-01   1.85958818e-01
   1.76573455e-01   1.43215357e-06   4.25177677e-06   5.21817674e-06
   1.05973254e-06]
[2017-11-02 11:43:43,386] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.70894402e-01   3.95019919e-01   8.12103152e-02   5.23549691e-02
   1.00520350e-01   5.52341051e-13   2.08772843e-12   5.78493330e-12
   6.12983134e-13]
[2017-11-02 11:43:43,877] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.06978339e-01   3.96890044e-01   6.93099052e-02   4.27703708e-02
   8.40513930e-02   3.56051350e-14   1.49184430e-13   5.25806720e-13
   6.24346291e-14]
[2017-11-02 11:43:45,481] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.18633591e-02   3.34381700e-01   2.33724758e-01   1.91387415e-01
   1.78632393e-01   1.38630787e-06   3.78500090e-06   4.48647415e-06
   7.77428681e-07]
[2017-11-02 11:43:45,691] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.94349392e-02   3.28357577e-01   2.37753600e-01   1.95494696e-01
   1.78947642e-01   1.57510624e-06   4.20810147e-06   4.91024502e-06
   8.65388245e-07]
[2017-11-02 11:43:47,841] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.51679221e-02   4.01108176e-01   1.96441367e-01   1.49513140e-01
   1.67769000e-01   4.04778859e-08   1.32103622e-07   2.19178943e-07
   2.85537229e-08]
[2017-11-02 11:43:48,137] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.92042506e-02   3.67485762e-01   2.22013935e-01   1.74444303e-01
   1.76849708e-01   2.28016305e-07   7.00755322e-07   9.66561970e-07
   1.90192338e-07]
[2017-11-02 11:43:52,240] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.59428412e-01   3.43828440e-01   1.36642426e-01   1.45683900e-01
   1.14416666e-01   1.08445803e-08   2.65096816e-08   6.35206874e-08
   1.02820232e-08]
[2017-11-02 11:43:54,044] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.09095322e-03   4.79603142e-01   2.51913011e-01   1.60111010e-01
   1.05277695e-01   2.86097162e-07   4.88684236e-07   2.06303321e-06
   1.38606981e-06]
[2017-11-02 11:44:01,094] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.60551029e-02   4.44255948e-01   1.50648519e-01   1.91188753e-01
   1.77583188e-01   5.86312353e-06   2.47782609e-05   1.14182571e-04
   1.23739926e-04]
[2017-11-02 11:44:01,471] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.92671257e-01   3.28199267e-01   1.04745239e-01   1.02312580e-01
   7.20716119e-02   8.01321856e-11   2.41950793e-10   5.55939073e-10
   6.34352501e-11]
[2017-11-02 11:44:01,569] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.55177486e-01   3.01768899e-01   9.78937969e-02   8.77460763e-02
   5.74137270e-02   1.51834762e-12   5.32118880e-12   1.03579896e-11
   1.02772597e-12]
[2017-11-02 11:44:01,825] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.33842218e-01   2.98861772e-01   1.69399992e-01   1.23192817e-01
   7.47031197e-02   1.13808561e-12   3.52948855e-12   5.02629839e-12
   8.87695408e-13]
[2017-11-02 11:44:01,936] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.52996737e-01   3.09160322e-01   1.56435937e-01   1.13910876e-01
   6.74961358e-02   5.41671742e-13   1.61895996e-12   2.66494053e-12
   4.88844642e-13]
[2017-11-02 11:44:08,097] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.59921041e-17   8.90865238e-07   2.32609718e-08   4.98148260e-08
   1.03197550e-07   4.25458001e-03   1.63264032e-02   7.58317053e-01
   2.21100792e-01]
[2017-11-02 11:44:10,282] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.17188378e-07   2.23980621e-01   1.44269420e-02   1.77633222e-02
   3.60948667e-02   7.34745339e-03   3.37335579e-02   3.95456582e-01
   2.71196514e-01]
[2017-11-02 11:44:14,420] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.70883691e-01   2.73904622e-01   5.73137440e-02   6.20504171e-02
   3.58474255e-02   6.49189591e-10   1.44301782e-09   6.36164854e-09
   1.16802090e-09]
[2017-11-02 11:44:15,324] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.16270591  0.21999124  0.26061797  0.22305191  0.12622629  0.00183856
  0.00220509  0.00262936  0.00073369]
[2017-11-02 11:44:16,956] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.61656576e-01   3.84124726e-01   1.03716001e-01   6.32476509e-02
   8.72550383e-02   4.12790495e-14   1.53508418e-13   5.13019369e-13
   1.50440560e-13]
[2017-11-02 11:44:18,761] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.16580648e-02   3.54376793e-01   1.94805682e-01   2.29285151e-01
   1.99614123e-01   9.78168373e-06   3.73873336e-05   1.06280946e-04
   1.06683896e-04]
[2017-11-02 11:44:23,099] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.03026440e-02   3.67800504e-01   1.77201167e-01   2.31032789e-01
   2.02354625e-01   3.74567826e-05   1.51917004e-04   5.03434916e-04
   6.15467492e-04]
[2017-11-02 11:44:23,306] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.0395647   0.39241099  0.14925638  0.21235631  0.16154723  0.00120225
  0.00339316  0.01660412  0.02366485]
[2017-11-02 11:44:24,347] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.73031324e-01   3.27089995e-01   1.81196660e-01   1.29221037e-01
   8.94610062e-02   1.82072916e-11   3.92529169e-11   7.28356264e-11
   2.88762365e-11]
[2017-11-02 11:44:24,873] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.13662869  0.18900289  0.24314831  0.22449231  0.15455742  0.01460715
  0.01674827  0.0160106   0.00480446]
[2017-11-02 11:44:25,182] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.14281683  0.19861765  0.25081202  0.23330054  0.15929329  0.00407964
  0.00507795  0.00476811  0.00123397]
[2017-11-02 11:44:25,732] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.33447158e-01   3.94470662e-01   9.70327407e-02   6.20989390e-02
   1.12950496e-01   4.84906559e-12   1.73336692e-11   3.81472597e-11
   4.31376983e-12]
[2017-11-02 11:44:28,164] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.25639749e-02   3.66844803e-01   2.08954901e-01   1.94562420e-01
   1.87051773e-01   2.11750807e-06   6.71260750e-06   1.03487328e-05
   2.97470456e-06]
[2017-11-02 11:44:28,285] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.71224917e-02   3.71637434e-01   2.00458884e-01   1.95904925e-01
   1.94855526e-01   1.63233449e-06   5.80348751e-06   1.00299758e-05
   3.26765462e-06]
[2017-11-02 11:44:29,219] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.65320352e-01   5.29919863e-01   9.85351950e-02   6.75642565e-02
   1.38660371e-01   1.14022654e-11   6.03363332e-11   1.65873593e-10
   2.71994510e-11]
[2017-11-02 11:44:30,427] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.0320216   0.39201239  0.14453052  0.20739719  0.1718334   0.00125177
  0.00409977  0.01913673  0.02771661]
[2017-11-02 11:44:33,033] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.17211004  0.20190325  0.24707948  0.21525431  0.15642457  0.00173844
  0.00242708  0.00229405  0.00076891]
[2017-11-02 11:44:33,398] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.66241869e-01   2.41493270e-01   2.27078393e-01   1.86504066e-01
   1.78666100e-01   3.32596596e-06   5.12692986e-06   6.11276846e-06
   1.72470527e-06]
[2017-11-02 11:44:34,147] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.41207248e-01   5.95031083e-01   8.45712423e-02   5.37092015e-02
   1.25481218e-01   7.56570804e-13   4.73802464e-12   1.98134443e-11
   5.22590261e-12]
[2017-11-02 11:44:36,495] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.52695870e-01   2.66883194e-01   6.60403296e-02   7.38962367e-02
   4.04843800e-02   1.99514363e-10   5.24264576e-10   1.52573842e-09
   1.24485755e-10]
[2017-11-02 11:44:40,804] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.97288990e-01   2.06836566e-01   3.22838835e-02   4.27731127e-02
   2.08173413e-02   8.71050165e-09   1.85847586e-08   1.07091608e-07
   1.30879885e-08]
[2017-11-02 11:44:42,023] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.67027640e-02   5.84442496e-01   1.32759824e-01   7.00278655e-02
   1.26067117e-01   1.32306896e-15   7.47513691e-15   3.29969511e-14
   3.14811077e-14]
[2017-11-02 11:44:46,027] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34575218e-01   6.21851861e-01   7.60819316e-02   4.82529998e-02
   1.19237959e-01   2.15660470e-13   1.41161464e-12   7.47062568e-12
   2.73198304e-12]
[2017-11-02 11:44:46,885] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.52233899e-01   3.37627172e-01   1.72432557e-01   1.74026445e-01
   1.63679913e-01   1.32579803e-09   3.78353837e-09   9.30949628e-09
   2.03286010e-09]
[2017-11-02 11:44:54,232] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.53887928e-01   6.40051186e-01   6.28344342e-02   3.84216420e-02
   1.04804836e-01   3.25427111e-14   2.24688012e-13   1.59210481e-12
   5.98623148e-13]
[2017-11-02 11:44:55,783] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.14516206e-01   4.23045188e-01   1.30526423e-01   1.81334168e-01
   1.50400132e-01   5.97236749e-06   1.54505396e-05   8.58297426e-05
   7.06986466e-05]
[2017-11-02 11:44:58,834] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.47204274e-01   3.72078478e-01   1.40975311e-01   1.29941911e-01
   1.09800063e-01   4.06843670e-10   1.13950749e-09   2.79797630e-09
   5.75012316e-10]
[2017-11-02 11:45:02,496] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.45900238e-01   3.25047344e-01   1.41690984e-01   1.17315494e-01
   7.00458661e-02   2.04692069e-10   4.04009465e-10   8.74515849e-10
   3.54324348e-10]
[2017-11-02 11:45:02,960] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.89433560e-01   2.21964210e-01   2.78960437e-01   2.11204305e-01
   9.84276682e-02   1.93718347e-06   2.59980379e-06   4.18594072e-06
   9.64989908e-07]
[2017-11-02 11:45:04,242] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.41478646e-01   4.19308722e-01   8.50059465e-02   5.42437211e-02
   9.99630019e-02   9.69871319e-13   4.09491625e-12   1.23573825e-11
   1.97561477e-12]
[2017-11-02 11:45:06,364] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.45018056e-01   2.00170532e-01   2.46097520e-01   2.34292820e-01
   1.71348885e-01   8.00086244e-04   1.06182392e-03   9.74399329e-04
   2.35838830e-04]
[2017-11-02 11:45:07,025] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.87864257e-02   3.65764678e-01   2.01262206e-01   1.85315266e-01
   1.88863620e-01   7.75876742e-07   2.28760791e-06   3.76903881e-06
   9.40998007e-07]
[2017-11-02 11:45:07,173] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.69272956e-02   3.68650198e-01   1.91261947e-01   1.91498488e-01
   2.01649487e-01   9.53514814e-07   3.24856842e-06   6.27928921e-06
   2.02006981e-06]
[2017-11-02 11:45:08,866] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.90723702e-01   4.40700501e-01   1.27028063e-01   9.66496468e-02
   1.44898042e-01   2.77022161e-09   8.83078854e-09   1.89967153e-08
   1.44105883e-09]
[2017-11-02 11:45:10,439] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.82803321e-01   4.23763454e-01   6.31706566e-02   3.99471521e-02
   9.03153494e-02   1.41043969e-13   7.14730033e-13   2.16835144e-12
   1.58940935e-13]
[2017-11-02 11:45:10,813] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.11006391e-01   4.13068593e-01   5.66783510e-02   3.56142893e-02
   8.36323500e-02   4.28461757e-14   2.27515381e-13   7.38305033e-13
   5.18719657e-14]
[2017-11-02 11:45:11,737] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.21608421e-02   3.71932149e-01   2.16812074e-01   1.72960550e-01
   1.76132530e-01   2.05395111e-07   6.06816002e-07   8.73618376e-07
   1.59330938e-07]
[2017-11-02 11:45:13,082] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.32879364e-01   4.42226648e-01   7.41067529e-02   4.81949635e-02
   1.02592312e-01   2.35648740e-12   1.07557114e-11   2.86654329e-11
   2.22662210e-12]
[2017-11-02 11:45:13,190] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.31983179e-01   4.37730789e-01   7.62742534e-02   4.98892404e-02
   1.04122587e-01   3.91263627e-12   1.72913055e-11   4.43162139e-11
   3.40870648e-12]
[2017-11-02 11:45:13,479] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.70714188e-02   3.79113704e-01   1.99815482e-01   1.64063036e-01
   1.69932172e-01   4.92103879e-07   1.33863659e-06   2.05195056e-06
   2.28980525e-07]
[2017-11-02 11:45:13,718] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.15365729e-02   3.73180002e-01   2.02118874e-01   1.80667460e-01
   1.82493329e-01   4.09903691e-07   1.17544766e-06   1.90322942e-06
   3.81769240e-07]
[2017-11-02 11:45:15,260] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.23967014e-01   5.54954648e-01   1.06032997e-01   7.50430897e-02
   1.40002266e-01   5.67709178e-11   2.94837432e-10   8.57983684e-10
   2.23364660e-10]
[2017-11-02 11:45:15,543] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.96008366e-02   3.57375056e-01   1.85582042e-01   2.30309546e-01
   2.06048474e-01   3.87849213e-05   1.50100197e-04   4.28706291e-04
   4.66465339e-04]
[2017-11-02 11:45:16,380] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.85517359e-01   3.22460979e-01   1.23572730e-01   1.13208264e-01
   5.52406944e-02   2.52554505e-10   4.79512929e-10   1.40984002e-09
   7.93035859e-10]
[2017-11-02 11:45:16,401] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.29025984e-01   3.31459850e-01   1.41689494e-01   1.31165370e-01
   6.66592866e-02   8.44902037e-10   1.46886447e-09   4.25594671e-09
   3.04469872e-09]
[2017-11-02 11:45:17,788] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.52653649e-02   6.19957983e-01   9.42186788e-02   7.22995177e-02
   1.48258463e-01   8.29259023e-11   5.61017233e-10   2.50347076e-09
   1.23521116e-09]
[2017-11-02 11:45:18,778] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.18097764e-01   3.16122085e-01   1.17890313e-01   1.00358009e-01
   4.75317948e-02   8.62861518e-12   1.86965391e-11   5.46636590e-11
   2.23290761e-11]
[2017-11-02 11:45:18,836] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.25261408e-01   3.15868348e-01   1.14206336e-01   9.95411202e-02
   4.51227911e-02   1.01783833e-11   2.17378563e-11   6.73230499e-11
   2.83783413e-11]
[2017-11-02 11:45:20,344] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.19895655e-01   3.16757858e-01   1.64459750e-01   1.23090111e-01
   7.57965967e-02   4.22014333e-12   1.11021531e-11   1.81863136e-11
   4.27073611e-12]
[2017-11-02 11:45:22,887] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.79194380e-02   3.50475192e-01   1.91549972e-01   2.20351577e-01
   2.19505906e-01   9.50513459e-06   4.07824991e-05   9.27175206e-05
   5.49668475e-05]
[2017-11-02 11:45:24,240] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.15456493  0.20268254  0.24098639  0.22318056  0.164251    0.00385648
  0.00473306  0.00439891  0.00134623]
[2017-11-02 11:45:25,504] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.50557077e-02   3.72427702e-01   2.06202015e-01   1.82997346e-01
   1.83307558e-01   1.01667933e-06   2.93513358e-06   4.57926762e-06
   1.07527853e-06]
[2017-11-02 11:45:25,546] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.27377389e-02   3.71916711e-01   2.04900458e-01   1.85078248e-01
   1.85355216e-01   1.18881849e-06   3.49605193e-06   5.56604073e-06
   1.37728716e-06]
[2017-11-02 11:45:25,760] A3C_AGENT_WORKER-Thread-17 INFO:Evaluation: average reward by now is -21495.0035
[2017-11-02 11:45:25,888] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 750000, evaluation results [750000.0, -21495.003462081168]
[2017-11-02 11:45:26,084] A3C_AGENT_WORKER-Thread-17 INFO:Local step 47000, global step 750055: loss 0.0329
[2017-11-02 11:45:27,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 46500, global step 750781: loss -4.4257
[2017-11-02 11:45:27,703] A3C_AGENT_WORKER-Thread-5 INFO:Local step 47000, global step 750864: loss -0.1852
[2017-11-02 11:45:30,338] A3C_AGENT_WORKER-Thread-15 INFO:Local step 46500, global step 752106: loss 18.5311
[2017-11-02 11:45:30,564] A3C_AGENT_WORKER-Thread-4 INFO:Local step 47000, global step 752212: loss 4.8815
[2017-11-02 11:45:30,960] A3C_AGENT_WORKER-Thread-16 INFO:Local step 47500, global step 752389: loss -0.9995
[2017-11-02 11:45:31,724] A3C_AGENT_WORKER-Thread-10 INFO:Local step 47500, global step 752727: loss -23.2147
[2017-11-02 11:45:32,497] A3C_AGENT_WORKER-Thread-11 INFO:Local step 46500, global step 753097: loss -8.9092
[2017-11-02 11:45:32,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.25535488e-01   2.23337501e-01   2.54216313e-01   3.09062570e-01
   8.78480971e-02   1.36469225e-10   1.51602605e-10   8.66165362e-10
   4.99640884e-10], sum to 1.0000
[2017-11-02 11:45:32,867] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.416666666666667, 60.33333333333334, 3.1, 188.3333333333333, 0.0, 0.0, -2.5, 32.55013211758552, 18.0, 20.10429081013706, 19.4, 0.0, 0.0], 
actual action is [-2.583333333333333, 18], 
sim time next is 6219600.0000, 
raw observation next is [2.333333333333333, 60.66666666666666, 3.1, 186.6666666666667, 0.0, 0.0, -2.583333333333333, 32.81329919697743, 18.0, 20.07870788223379, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.39316239316239315, 0.6066666666666666, 0.2818181818181818, 0.5185185185185186, 0.0, 0.0, 0.4569444444444445, 0.3281329919697743, 0.0, 0.2969582688905414, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:33,477] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.39097159e-02   2.37355188e-01   2.01293260e-01   2.85162717e-01
   2.52278060e-01   1.31921340e-07   1.72073598e-07   5.43770113e-07
   1.83012148e-07], sum to 1.0000
[2017-11-02 11:45:33,493] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.0, 100.0, 4.6, 340.0, 0.0, 0.0, 1.083333333333334, 19.28455063127898, 18.0, 19.58598869168502, 22.2, 1.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6469500.0000, 
raw observation next is [5.916666666666667, 99.99999999999999, 4.641666666666666, 339.9999999999999, 0.0, 0.0, 1.0, 19.63670713271005, 18.0, 19.5634239318126, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.9130434782608695, 0.4850427350427351, 0.9999999999999999, 0.4219696969696969, 0.9444444444444441, 0.0, 0.0, 0.5166666666666667, 0.19636707132710052, 0.0, 0.22334627597322868, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:45:34,289] A3C_AGENT_WORKER-Thread-8 INFO:Local step 47500, global step 753940: loss -2.3847
[2017-11-02 11:45:34,384] A3C_AGENT_WORKER-Thread-6 INFO:Local step 47500, global step 753980: loss 298.3545
[2017-11-02 11:45:37,092] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.06888907e-02   1.69586837e-01   3.08858395e-01   1.14332229e-01
   3.96533638e-01   7.18552277e-18   3.96312654e-17   1.44920918e-16
   8.24674083e-16], sum to 1.0000
[2017-11-02 11:45:37,107] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 98.66666666666667, 6.366666666666667, 333.3333333333333, 0.0, 0.0, -6.0, 22.93825388579513, 18.0, 20.03385039164321, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18.0], 
sim time next is 6495300.0000, 
raw observation next is [-1.0, 98.0, 6.45, 335.0, 0.0, 0.0, -6.0, 25.66129623128398, 18.0, 19.77802107999472, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.3076923076923077, 0.98, 0.5863636363636364, 0.9305555555555556, 0.0, 0.0, 0.4, 0.2566129623128398, 0.0, 0.254003011427817, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:37,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.31504685e-01   1.56481728e-01   2.56707728e-01   2.44214207e-01
   2.10836038e-01   6.53689422e-05   8.31939251e-05   8.75457481e-05
   1.95171160e-05], sum to 1.0000
[2017-11-02 11:45:38,023] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 52.25, 7.45, 347.5, 264.5, 614.25, -4.0, 28.63871450338317, 18.0, 19.55586628156047, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 6528000.0000, 
raw observation next is [1.0, 52.66666666666667, 7.366666666666667, 346.6666666666667, 250.6666666666667, 656.5, -4.0, 28.1600326620457, 18.0, 19.66922016755197, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.358974358974359, 0.5266666666666667, 0.6696969696969698, 0.962962962962963, 0.6631393298059965, 0.6565, 0.43333333333333335, 0.28160032662045703, 0.0, 0.2384600239359957, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:38,873] A3C_AGENT_WORKER-Thread-2 INFO:Local step 47000, global step 755997: loss -9.2314
[2017-11-02 11:45:39,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  4.26555097e-01   1.41878709e-01   1.85902223e-01   1.28108293e-01
   1.17555186e-01   1.01969896e-07   1.44189514e-07   2.09225462e-07
   6.14529805e-09], sum to 1.0000
[2017-11-02 11:45:39,333] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 100.0, 4.891666666666666, 180.0, 124.1666666666667, 0.0, 6.0, 7.392807400519785, 18.0, 22.4071023989506, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6442200.0000, 
raw observation next is [11.0, 100.0, 4.85, 180.0, 124.0, 0.0, 6.0, 7.373910091572731, 18.0, 22.40898546379839, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.6153846153846154, 1.0, 0.44090909090909086, 0.5, 0.328042328042328, 0.0, 0.6, 0.07373910091572732, 0.0, 0.629855066256913, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0074. 
=============================================
[2017-11-02 11:45:39,644] A3C_AGENT_WORKER-Thread-9 INFO:Local step 47500, global step 756373: loss 0.1266
[2017-11-02 11:45:39,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 47000, global step 756405: loss 7.0529
[2017-11-02 11:45:39,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.34843269e-01   1.87273383e-01   2.52905279e-01   1.53079152e-01
   1.71898916e-01   1.11551574e-10   2.26751090e-10   4.43239584e-10
   1.70104191e-11], sum to 1.0000
[2017-11-02 11:45:39,998] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [12.66666666666667, 41.0, 7.699999999999999, 243.3333333333333, 236.5, 639.1666666666666, 7.58333333333333, 10.18498406479651, 18.0, 23.55034720334583, 22.2, 1.0, 0.0], 
actual action is [7.66666666666667, 18], 
sim time next is 6270300.0000, 
raw observation next is [12.75, 40.25, 7.824999999999999, 240.0, 243.25, 594.25, 7.66666666666667, 10.08929865786789, 18.0, 23.58476424917618, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.6602564102564102, 0.4025, 0.7113636363636363, 0.6666666666666666, 0.6435185185185185, 0.59425, 0.6277777777777779, 0.1008929865786789, 0.0, 0.797823464168026, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0101. 
=============================================
[2017-11-02 11:45:40,509] A3C_AGENT_WORKER-Thread-3 INFO:Local step 47500, global step 756758: loss 6.3627
[2017-11-02 11:45:40,838] A3C_AGENT_WORKER-Thread-7 INFO:Local step 47500, global step 756896: loss -73.8861
[2017-11-02 11:45:42,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.18334718e-01   1.86394036e-01   2.53256887e-01   2.09746793e-01
   2.31536165e-01   1.67701030e-04   2.43143164e-04   2.64443370e-04
   5.60589287e-05], sum to 1.0000
[2017-11-02 11:45:42,269] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [19.0, 31.66666666666666, 9.216666666666667, 232.5, 140.5833333333333, 845.1666666666667, 14.0, 6.745213940113445, 18.0, 24.08198418400228, 19.4, 0.0, 0.0], 
actual action is [14.0, 18], 
sim time next is 6356400.0000, 
raw observation next is [19.0, 31.33333333333334, 9.433333333333334, 230.0, 140.1666666666667, 841.3333333333333, 14.0, 6.69257873550504, 18.0, 24.11431954193786, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.8205128205128205, 0.3133333333333334, 0.8575757575757575, 0.6388888888888888, 0.3708112874779543, 0.8413333333333333, 0.7333333333333333, 0.0669257873550504, 0.0, 0.8734742202768372, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:43,225] A3C_AGENT_WORKER-Thread-17 INFO:Local step 47500, global step 757761: loss 4.4462
[2017-11-02 11:45:43,891] A3C_AGENT_WORKER-Thread-5 INFO:Local step 47500, global step 758024: loss 2.8148
[2017-11-02 11:45:44,024] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.69032949e-01   6.88500404e-02   4.17276740e-01   5.24775460e-02
   9.23627242e-02   7.01602932e-18   2.80606100e-17   6.88765701e-17
   2.06962125e-16], sum to 1.0000
[2017-11-02 11:45:44,051] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 96.66666666666666, 6.616666666666666, 338.3333333333333, 0.0, 0.0, -6.0, 32.90797602799655, 18.0, 18.77678233964252, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 6496200.0000, 
raw observation next is [-1.0, 96.0, 6.7, 340.0, 0.0, 0.0, -6.0, 34.03036015613212, 18.0, 18.64368378824744, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.3076923076923077, 0.96, 0.6090909090909091, 0.9444444444444444, 0.0, 0.0, 0.4, 0.34030360156132117, 0.0, 0.09195482689249143, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:45:44,361] A3C_AGENT_WORKER-Thread-13 INFO:Local step 47000, global step 758214: loss 10.6876
[2017-11-02 11:45:45,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  8.50400403e-02   2.12447599e-01   3.41876358e-01   8.87994915e-02
   2.71836579e-01   8.02174716e-11   3.48400975e-10   4.45516402e-10
   1.08122442e-10], sum to 1.0000
[2017-11-02 11:45:45,158] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.5, 35.0, 4.9, 220.0, 0.0, 0.0, 12.58333333333333, 6.361828840929653, 18.0, 24.21781097510751, 22.2, 1.0, 0.0], 
actual action is [12.5, 18], 
sim time next is 6374100.0000, 
raw observation next is [17.41666666666667, 35.16666666666666, 4.766666666666667, 220.0, 0.0, 0.0, 12.5, 6.376394401506416, 18.0, 24.1437586276314, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.77991452991453, 0.35166666666666657, 0.43333333333333335, 0.6111111111111112, 0.0, 0.0, 0.7083333333333334, 0.06376394401506416, 0.0, 0.8776798039473428, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0064. 
=============================================
[2017-11-02 11:45:45,173] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  7.24943578e-02   1.29555032e-01   4.01243448e-01   8.09399709e-02
   3.15767229e-01   5.84702642e-13   3.93316889e-12   8.27484262e-12
   6.66385176e-12], sum to 1.0000
[2017-11-02 11:45:45,201] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [8.583333333333332, 97.08333333333333, 4.766666666666666, 350.0, 0.0, 0.0, 3.666666666666668, 13.13310567199255, 18.0, 20.60816600443222, 22.2, 1.0, 0.0], 
actual action is [3.583333333333332, 18.0], 
sim time next is 6460200.0000, 
raw observation next is [8.5, 96.5, 4.9, 350.0, 0.0, 0.0, 3.583333333333332, 13.42275695364829, 18.0, 20.54585621270761, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5512820512820513, 0.965, 0.4454545454545455, 0.9722222222222222, 0.0, 0.0, 0.5597222222222221, 0.1342275695364829, 0.0, 0.36369374467251553, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 11:45:46,465] A3C_AGENT_WORKER-Thread-14 INFO:Local step 47000, global step 758967: loss 1.2167
[2017-11-02 11:45:46,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.23761374e-01   2.14114055e-01   1.62081107e-01   9.01924595e-02
   2.09850997e-01   3.73753979e-12   1.63679608e-11   2.15491184e-11
   1.62637015e-12], sum to 1.0000
[2017-11-02 11:45:46,693] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [12.33333333333333, 39.33333333333333, 7.866666666666666, 256.6666666666667, 291.8333333333333, 205.5, 7.41666666666667, 8.692650737768584, 18.0, 24.11929408419127, 22.2, 1.0, 0.0], 
actual action is [7.33333333333333, 18], 
sim time next is 6273900.0000, 
raw observation next is [12.25, 39.5, 7.825, 260.0, 285.75, 213.25, 7.33333333333333, 8.667972336863642, 18.0, 24.13323709950808, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.6474358974358975, 0.395, 0.7113636363636364, 0.7222222222222222, 0.7559523809523809, 0.21325, 0.6222222222222221, 0.08667972336863641, 0.0, 0.8761767285011542, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0087. 
=============================================
[2017-11-02 11:45:47,125] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.16947745  0.15074328  0.23865213  0.204035    0.23489885  0.00046557
  0.00075708  0.00070894  0.0002617 ], sum to 1.0000
[2017-11-02 11:45:47,144] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.583333333333333, 53.66666666666667, 6.116666666666667, 340.0, 134.6666666666667, 797.9166666666666, -3.5, 23.85229003496613, 18.0, 20.01872323859705, 19.4, 0.0, 0.0], 
actual action is [-3.416666666666667, 18], 
sim time next is 6532800.0000, 
raw observation next is [1.666666666666667, 53.33333333333333, 6.033333333333333, 340.0, 133.3333333333333, 792.8333333333334, -3.416666666666667, 23.53352845924428, 18.0, 20.05302115055595, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3760683760683761, 0.5333333333333333, 0.5484848484848485, 0.9444444444444444, 0.35273368606701927, 0.7928333333333334, 0.44305555555555554, 0.2353352845924428, 0.0, 0.293288735793707, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:47,554] A3C_AGENT_WORKER-Thread-4 INFO:Local step 47500, global step 759404: loss -3.1130
[2017-11-02 11:45:48,156] A3C_AGENT_WORKER-Thread-15 INFO:Local step 47000, global step 759664: loss 21.2757
[2017-11-02 11:45:48,169] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.34650314e-01   8.09224024e-02   1.81938976e-01   2.11040020e-01
   2.91448325e-01   8.66146563e-16   6.58987694e-15   1.58063632e-14
   3.46012722e-14], sum to 1.0000
[2017-11-02 11:45:48,179] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.416666666666666, 56.08333333333333, 2.183333333333333, 28.33333333333333, 0.0, 0.0, -9.333333333333334, 37.71065916644633, 18.0, 19.49614178934874, 19.4, 0.0, 0.0], 
actual action is [-9.416666666666666, 18], 
sim time next is 6568200.0000, 
raw observation next is [-4.5, 56.5, 2.2, 30.0, 0.0, 0.0, -9.416666666666666, 39.18003148251635, 18.0, 19.40288256829886, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.0, 0.21794871794871795, 0.565, 0.2, 0.08333333333333333, 0.0, 0.0, 0.3430555555555556, 0.3918003148251635, 0.0, 0.20041179547126578, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:48,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.69152170e-01   7.88866431e-02   3.06940675e-01   1.69720963e-01
   2.75299430e-01   5.04407376e-18   2.85870907e-17   7.98156235e-17
   1.35320065e-16], sum to 1.0000
[2017-11-02 11:45:48,422] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.583333333333334, 57.66666666666667, 3.975, 175.8333333333333, 0.0, 0.0, 1.5, 34.20495503387875, 18.0, 19.68674757846234, 19.4, 0.0, 0.0], 
actual action is [1.583333333333334, 18], 
sim time next is 6327600.0000, 
raw observation next is [6.666666666666666, 57.33333333333333, 4.1, 176.6666666666667, 0.0, 0.0, 1.583333333333334, 34.2986458481009, 18.0, 19.6834923770164, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.5042735042735043, 0.5733333333333333, 0.3727272727272727, 0.49074074074074087, 0.0, 0.0, 0.5263888888888889, 0.34298645848100895, 0.0, 0.2404989110023428, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:45:49,961] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-36.09009933]
 [-34.68321228]
 [-35.10531235]
 [-35.8563385 ]
 [-33.31209946]], R is [[-38.17262268]
 [-38.26635361]
 [-38.68590927]
 [-38.29904938]
 [-37.91605759]].
[2017-11-02 11:45:50,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  3.14078510e-01   1.64776981e-01   2.42330998e-01   1.58546701e-01
   1.20266795e-01   3.93968285e-16   2.02175774e-15   6.72680659e-15
   7.39325169e-15], sum to 1.0000
[2017-11-02 11:45:50,975] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.5, 55.5, 8.5, 350.0, 389.0, 234.0, -4.583333333333333, 19.0273445025163, 18.0, 21.11445951690337, 22.2, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 6525300.0000, 
raw observation next is [0.5833333333333334, 54.75, 8.366666666666667, 350.0, 375.1666666666666, 276.25, -4.5, 18.91762419574722, 18.0, 21.12832258533625, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.34829059829059833, 0.5475, 0.7606060606060606, 0.9722222222222222, 0.9925044091710756, 0.27625, 0.425, 0.18917624195747218, 0.0, 0.4469032264766071, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:45:52,800] A3C_AGENT_WORKER-Thread-11 INFO:Local step 47000, global step 761142: loss -2.7137
[2017-11-02 11:45:54,298] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.13644034e-01   2.59167075e-01   2.06321985e-01   2.08002061e-01
   2.12864846e-01   5.58068924e-09   1.18223431e-08   1.52017456e-08
   2.78367174e-09], sum to 1.0000
[2017-11-02 11:45:54,316] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.0, 43.99999999999999, 3.225, 200.0, 0.0, 0.0, 9.0, 7.828808397139533, 18.0, 22.85413482011057, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 6387000.0000, 
raw observation next is [14.0, 44.00000000000001, 3.35, 200.0, 0.0, 0.0, 9.0, 7.894617825902206, 18.0, 22.8240227071779, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.6923076923076923, 0.44000000000000006, 0.30454545454545456, 0.5555555555555556, 0.0, 0.0, 0.65, 0.07894617825902206, 0.0, 0.6891461010254142, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0079. 
=============================================
[2017-11-02 11:45:54,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.20624328e-01   2.17738107e-01   1.74672067e-01   2.06886113e-01
   1.80079311e-01   1.60846749e-08   2.89742097e-08   3.41542936e-08
   4.33613945e-09], sum to 1.0000
[2017-11-02 11:45:54,835] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [14.0, 43.99999999999999, 4.6, 199.1666666666667, 0.0, 0.0, 9.0, 8.476957620298894, 18.0, 22.56489368088991, 22.2, 1.0, 0.0], 
actual action is [9.0, 18.0], 
sim time next is 6390600.0000, 
raw observation next is [14.0, 44.00000000000001, 4.6, 198.3333333333333, 0.0, 0.0, 9.0, 8.428830450974852, 18.0, 22.56197278772951, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 1.0, 0.6923076923076923, 0.44000000000000006, 0.41818181818181815, 0.5509259259259258, 0.0, 0.0, 0.65, 0.08428830450974852, 0.0, 0.6517103982470728, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0084. 
=============================================
[2017-11-02 11:45:56,137] A3C_AGENT_WORKER-Thread-16 INFO:Local step 48000, global step 762352: loss -3.5229
[2017-11-02 11:45:56,358] A3C_AGENT_WORKER-Thread-10 INFO:Local step 48000, global step 762412: loss -5.5382
[2017-11-02 11:45:56,761] A3C_AGENT_WORKER-Thread-2 INFO:Local step 47500, global step 762537: loss 72.2764
[2017-11-02 11:45:57,314] A3C_AGENT_WORKER-Thread-12 INFO:Local step 47500, global step 762738: loss 103.5156
[2017-11-02 11:45:57,320] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-11.41209221]
 [-12.08009243]
 [-11.50155544]
 [-11.49004555]
 [-13.18543148]], R is [[-10.91134453]
 [-10.80878925]
 [-10.70721817]
 [-10.60663033]
 [-10.50702477]].
[2017-11-02 11:45:59,670] A3C_AGENT_WORKER-Thread-6 INFO:Local step 48000, global step 763584: loss 7.0008
[2017-11-02 11:46:01,278] A3C_AGENT_WORKER-Thread-8 INFO:Local step 48000, global step 764035: loss -10.0031
[2017-11-02 11:46:02,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.69099402e-02   9.19402540e-02   9.58159566e-02   6.39558807e-02
   7.31378019e-01   6.21113524e-21   1.06545044e-19   3.85667377e-19
   1.52594929e-18], sum to 1.0000
[2017-11-02 11:46:02,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.916666666666667, 71.0, 9.625, 350.0, 116.4166666666667, 430.4166666666666, -7.0, 24.90408226423356, 18.0, 20.01391402084927, 22.2, 1.0, 0.0], 
actual action is [-6.916666666666667, 18], 
sim time next is 6509400.0000, 
raw observation next is [-1.833333333333333, 71.0, 9.450000000000001, 350.0, 120.3333333333333, 446.3333333333334, -6.916666666666667, 24.71239408470997, 18.0, 20.02977099004425, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.28632478632478636, 0.71, 0.8590909090909092, 0.9722222222222222, 0.3183421516754849, 0.4463333333333334, 0.3847222222222222, 0.2471239408470997, 0.0, 0.2899672842920355, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:03,011] A3C_AGENT_WORKER-Thread-13 INFO:Local step 47500, global step 764510: loss 32.9714
[2017-11-02 11:46:05,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.55729908e-02   2.49836177e-01   1.58912197e-01   1.70938537e-01
   3.84740114e-01   5.97441259e-13   2.91604371e-12   3.72893730e-12
   1.64782717e-12], sum to 1.0000
[2017-11-02 11:46:05,916] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [11.0, 92.25, 4.975, 202.5, 65.75, 0.0, 6.0, 9.364542970347735, 18.0, 21.79621153110008, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6425400.0000, 
raw observation next is [11.0, 92.83333333333334, 5.016666666666667, 201.6666666666667, 68.66666666666667, 0.0, 6.0, 9.282757516323576, 18.0, 21.81761969263264, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.34782608695652173, 0.6153846153846154, 0.9283333333333335, 0.45606060606060606, 0.5601851851851853, 0.181657848324515, 0.0, 0.6, 0.09282757516323575, 0.0, 0.5453742418046629, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0093. 
=============================================
[2017-11-02 11:46:06,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 47500, global step 765411: loss 52.1434
[2017-11-02 11:46:06,741] A3C_AGENT_WORKER-Thread-3 INFO:Local step 48000, global step 765550: loss 7.0124
[2017-11-02 11:46:06,935] A3C_AGENT_WORKER-Thread-7 INFO:Local step 48000, global step 765594: loss 21.9794
[2017-11-02 11:46:06,957] A3C_AGENT_WORKER-Thread-9 INFO:Local step 48000, global step 765595: loss 22.7407
[2017-11-02 11:46:08,248] A3C_AGENT_WORKER-Thread-15 INFO:Local step 47500, global step 765904: loss 26.7827
[2017-11-02 11:46:10,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  4.55158412e-01   1.90260097e-01   2.68785972e-02   1.67775899e-01
   1.59926862e-01   8.67664757e-25   1.53384789e-23   1.91199452e-23
   1.58349829e-22], sum to 1.0000
[2017-11-02 11:46:10,109] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 92.66666666666667, 7.116666666666666, 348.3333333333333, 0.0, 0.0, -6.0, 28.65058226530772, 18.0, 19.06524784469234, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 6498000.0000, 
raw observation next is [-1.0, 92.0, 7.2, 350.0, 0.0, 0.0, -6.0, 30.0634887260829, 18.0, 18.88814032904958, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.3076923076923077, 0.92, 0.6545454545454545, 0.9722222222222222, 0.0, 0.0, 0.4, 0.300634887260829, 0.0, 0.12687718986422578, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0731. 
=============================================
[2017-11-02 11:46:11,852] A3C_AGENT_WORKER-Thread-17 INFO:Local step 48000, global step 766922: loss 77.2579
[2017-11-02 11:46:13,346] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.83659532e-03   3.02076638e-01   3.14178132e-02   3.04335393e-02
   6.30235374e-01   8.95081334e-26   3.14805673e-24   5.89284224e-24
   2.02157547e-22], sum to 1.0000
[2017-11-02 11:46:13,484] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.333333333333333, 55.33333333333334, 5.1, 123.3333333333333, 213.8333333333333, 5.0, 11.25, 21.9194390244154, 23.0, 21.02431501881367, 20.56, 1.0, 111.3119427318253], 
actual action is [11.333333333333332, 21.0], 
sim time next is 6690300.0000, 
raw observation next is [6.416666666666666, 55.41666666666666, 5.1, 124.1666666666667, 221.4166666666667, 5.5, 11.33333333333333, 18.99909787651762, 21.0, 21.21819404705193, 20.56, 1.0, 58.26982531869072], 
processed observation next is [1.0, 0.43478260869565216, 0.4978632478632478, 0.5541666666666666, 0.4636363636363636, 0.3449074074074075, 0.5857583774250442, 0.0055, 0.6888888888888888, 0.1899909787651762, 0.42857142857142855, 0.4597420067217044, 0.36571428571428555, 1.0, 0.685527356690479], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:13,812] A3C_AGENT_WORKER-Thread-5 INFO:Local step 48000, global step 767426: loss 51.2461
[2017-11-02 11:46:13,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 47500, global step 767448: loss 1.4774
[2017-11-02 11:46:15,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-10.24158573]
 [-12.07138443]
 [-10.4917984 ]
 [-11.14246368]
 [ -8.94602966]], R is [[-10.59806347]
 [-10.4920826 ]
 [-10.38716221]
 [-10.28329086]
 [-10.18045807]].
[2017-11-02 11:46:16,707] A3C_AGENT_WORKER-Thread-4 INFO:Local step 48000, global step 768417: loss -5.1013
[2017-11-02 11:46:17,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.23106621e-01   4.55363154e-01   9.39841475e-03   1.15966044e-01
   2.96165794e-01   5.27175548e-24   1.00889264e-22   1.64174218e-21
   2.31515716e-21], sum to 1.0000
[2017-11-02 11:46:17,667] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.083333333333333, 50.75, 5.1, 349.1666666666667, 79.5, 545.8333333333334, -3.833333333333333, 12.85731797530578, 18.0, 22.38052462560452, 22.2, 1.0, 0.0], 
actual action is [-3.916666666666667, 18], 
sim time next is 6541200.0000, 
raw observation next is [1.0, 51.0, 5.1, 350.0, 76.0, 527.0, -3.916666666666667, 13.01003047817448, 18.0, 22.35225922083316, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.358974358974359, 0.51, 0.4636363636363636, 0.9722222222222222, 0.20105820105820105, 0.527, 0.4347222222222222, 0.1301003047817448, 0.0, 0.6217513172618803, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 11:46:21,455] A3C_AGENT_WORKER-Thread-16 INFO:Local step 48500, global step 770015: loss 1.1969
[2017-11-02 11:46:21,459] A3C_AGENT_WORKER-Thread-10 INFO:Local step 48500, global step 770017: loss 35.6916
[2017-11-02 11:46:23,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.04770081e-02   4.42060262e-01   1.85462907e-01   2.83713460e-01
   6.82863221e-02   4.31380007e-25   2.08804177e-23   1.08623395e-21
   2.97211746e-20], sum to 1.0000
[2017-11-02 11:46:23,201] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.5, 34.83333333333334, 5.016666666666667, 98.33333333333334, 141.6666666666667, 820.6666666666666, -3.75, 21.20864743585146, 18.0, 21.78572959326849, 20.56, 1.0, 0.0], 
actual action is [-3.5, 18], 
sim time next is 6605700.0000, 
raw observation next is [1.75, 34.41666666666666, 5.058333333333334, 99.16666666666666, 142.3333333333333, 824.3333333333333, -3.5, 21.9668252791994, 18.0, 21.71529740227489, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.3782051282051282, 0.34416666666666657, 0.4598484848484849, 0.2754629629629629, 0.3765432098765431, 0.8243333333333333, 0.44166666666666665, 0.219668252791994, 0.0, 0.5307567717535555, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:23,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.34848280e-16   1.32401709e-07   4.71171688e-08   1.60914806e-06
   9.67194680e-08   1.59582514e-02   1.55952396e-02   8.45102906e-01
   1.23341739e-01], sum to 1.0000
[2017-11-02 11:46:23,674] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 64.0, 2.766666666666667, 80.0, 0.0, 0.0, -2.0, 31.15712193908178, 20.0, 19.48167032928885, 19.4, 0.0, 46.14789012792658], 
actual action is [-2.0, 20.5], 
sim time next is 6589500.0000, 
raw observation next is [-7.0, 64.0, 2.808333333333334, 77.5, 0.0, 0.0, -2.0, 30.97543181320159, 20.5, 19.53319571333848, 19.4, 0.0, 40.29745206219585], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.15384615384615385, 0.64, 0.25530303030303036, 0.2152777777777778, 0.0, 0.0, 0.4666666666666667, 0.30975431813201587, 0.35714285714285715, 0.21902795904835415, 0.1999999999999998, 0.0, 0.4740876713199512], 
reward next is -0.4267. 
=============================================
[2017-11-02 11:46:23,788] A3C_AGENT_WORKER-Thread-6 INFO:Local step 48500, global step 770888: loss 1.3516
[2017-11-02 11:46:25,674] A3C_AGENT_WORKER-Thread-2 INFO:Local step 48000, global step 771346: loss 3.8152
[2017-11-02 11:46:25,943] A3C_AGENT_WORKER-Thread-8 INFO:Local step 48500, global step 771433: loss 43.8912
[2017-11-02 11:46:26,139] A3C_AGENT_WORKER-Thread-12 INFO:Local step 48000, global step 771518: loss 9.1676
[2017-11-02 11:46:27,011] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99668464e-02   1.86893091e-01   1.72663987e-01   2.64878839e-01
   2.75526047e-01   1.40181355e-05   2.70846467e-05   2.55327341e-05
   4.45571686e-06], sum to 1.0000
[2017-11-02 11:46:27,027] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.0, 60.0, 4.6, 90.0, 136.0, 0.0, 1.0, 20.03562120193173, 18.0, 22.07147869658833, 19.4, 0.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6793500.0000, 
raw observation next is [5.916666666666667, 60.33333333333334, 4.6, 91.66666666666667, 130.0, 0.0, 1.0, 20.06839946739759, 18.0, 22.07204797374227, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.4850427350427351, 0.6033333333333334, 0.41818181818181815, 0.25462962962962965, 0.3439153439153439, 0.0, 0.5166666666666667, 0.2006839946739759, 0.0, 0.5817211391060384, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:46:27,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  7.34202388e-08   3.23504180e-01   9.69203711e-02   1.56589240e-01
   4.22986150e-01   1.97728377e-17   1.85532127e-15   1.10958479e-14
   1.98153993e-12], sum to 1.0000
[2017-11-02 11:46:27,674] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.166666666666667, 43.08333333333333, 5.241666666666666, 90.0, 129.0, 738.1666666666667, -7.333333333333333, 24.42426999331634, 18.0, 21.58756980512308, 20.56, 1.0, 0.0], 
actual action is [-7.166666666666667, 18.0], 
sim time next is 6600600.0000, 
raw observation next is [-2.0, 42.5, 5.15, 90.0, 130.0, 747.0, -7.166666666666667, 26.24535802596227, 18.0, 21.43708665122531, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.28205128205128205, 0.425, 0.4681818181818182, 0.25, 0.3439153439153439, 0.747, 0.38055555555555554, 0.2624535802596227, 0.0, 0.49101237874647297, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:28,813] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-12.21408749]
 [-12.10824203]
 [-10.22329903]
 [ -7.16656065]
 [ -7.0376606 ]], R is [[-8.13654327]
 [-8.05517769]
 [-7.97462606]
 [-7.89487982]
 [-7.81593132]].
[2017-11-02 11:46:29,458] A3C_AGENT_WORKER-Thread-3 INFO:Local step 48500, global step 772838: loss 6.1841
[2017-11-02 11:46:29,627] A3C_AGENT_WORKER-Thread-9 INFO:Local step 48500, global step 772907: loss 5.1575
[2017-11-02 11:46:30,235] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.73975769e-02   4.87970203e-01   1.76042095e-01   1.26960993e-01
   1.91629142e-01   4.67372854e-27   5.03745916e-25   1.20779283e-23
   3.69930705e-22], sum to 1.0000
[2017-11-02 11:46:30,314] A3C_AGENT_WORKER-Thread-7 INFO:Local step 48500, global step 773191: loss 5.0692
[2017-11-02 11:46:30,393] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.166666666666666, 50.66666666666666, 4.475, 101.6666666666667, 115.6666666666667, 616.2499999999999, 0.6666666666666661, 25.43972948654097, 23.0, 20.59012369767265, 20.56, 1.0, 86.49926044120181], 
actual action is [0.8333333333333339, 23.0], 
sim time next is 6597000.0000, 
raw observation next is [-4.0, 50.0, 4.65, 100.0, 118.0, 641.0, 0.8333333333333339, 23.37439222887572, 23.0, 20.69872265916238, 20.56, 1.0, 71.25222551350676], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.23076923076923078, 0.5, 0.4227272727272728, 0.2777777777777778, 0.31216931216931215, 0.641, 0.513888888888889, 0.2337439222887572, 0.7142857142857143, 0.3855318084517688, 0.36571428571428555, 1.0, 0.8382614766294912], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:31,668] A3C_AGENT_WORKER-Thread-13 INFO:Local step 48000, global step 773761: loss -5.7377
[2017-11-02 11:46:33,192] A3C_AGENT_WORKER-Thread-14 INFO:Local step 48000, global step 774394: loss 23.8375
[2017-11-02 11:46:33,870] A3C_AGENT_WORKER-Thread-17 INFO:Local step 48500, global step 774631: loss 24.3145
[2017-11-02 11:46:34,906] A3C_AGENT_WORKER-Thread-5 INFO:Local step 48500, global step 774979: loss 1.6008
[2017-11-02 11:46:34,974] A3C_AGENT_WORKER-Thread-15 INFO:Local step 48000, global step 774995: loss 17.7351
[2017-11-02 11:46:35,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.98550117e-01   3.57430166e-04   6.88775501e-04   3.01473599e-04
   1.02255559e-04   9.34797194e-30   3.64910671e-29   1.88096795e-27
   2.05197360e-30], sum to 1.0000
[2017-11-02 11:46:35,461] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 45.0, 4.6, 127.5, 0.0, 0.0, -3.0, 39.32866270173324, 18.0, 19.92327265772145, 19.4, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 6643200.0000, 
raw observation next is [2.0, 45.33333333333334, 4.6, 126.6666666666667, 0.0, 0.0, -3.0, 39.66596364103737, 18.0, 19.88214780358936, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.38461538461538464, 0.4533333333333334, 0.41818181818181815, 0.35185185185185197, 0.0, 0.0, 0.45, 0.3966596364103737, 0.0, 0.2688782576556226, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:46:37,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[ -9.65739441]
 [-14.61344147]
 [ -6.87354946]
 [ -3.28935814]
 [ -2.01322341]], R is [[-13.7510767 ]
 [-13.69607162]
 [-13.63415051]
 [-13.56492901]
 [-13.48795128]].
[2017-11-02 11:46:37,643] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.15628414e-01   1.60010800e-01   2.21027046e-01   3.21261406e-01
   1.82071477e-01   1.29415795e-07   2.12650633e-07   4.50531843e-07
   3.97269844e-08], sum to 1.0000
[2017-11-02 11:46:37,666] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.0, 83.0, 4.266666666666667, 86.66666666666667, 99.83333333333333, 2.833333333333333, 1.0, 35.14972951943442, 18.0, 19.41060238609151, 19.4, 0.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6882300.0000, 
raw observation next is [6.0, 84.0, 4.35, 87.5, 105.25, 4.25, 1.0, 35.10944558928027, 18.0, 19.39437624003074, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.48717948717948717, 0.84, 0.39545454545454545, 0.24305555555555555, 0.27843915343915343, 0.00425, 0.5166666666666667, 0.3510944558928027, 0.0, 0.19919660571867734, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0008. 
=============================================
[2017-11-02 11:46:38,006] A3C_AGENT_WORKER-Thread-4 INFO:Local step 48500, global step 776432: loss 5.4270
[2017-11-02 11:46:38,678] A3C_AGENT_WORKER-Thread-11 INFO:Local step 48000, global step 776749: loss 1.8103
[2017-11-02 11:46:40,224] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.90397635e-08   8.58405232e-02   3.06717992e-01   3.64792824e-01
   2.42648706e-01   1.15666938e-12   4.44996253e-12   2.82569301e-09
   9.47066536e-10], sum to 1.0000
[2017-11-02 11:46:40,251] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.0, 80.5, 1.55, 20.0, 0.0, 0.0, -1.0, 49.87810208061099, 18.0, 17.75757538321824, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18.0], 
sim time next is 6905400.0000, 
raw observation next is [4.0, 80.0, 1.6, 20.0, 0.0, 0.0, -1.0, 50.95450316447438, 18.0, 17.67630785454276, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.4358974358974359, 0.8, 0.14545454545454548, 0.05555555555555555, 0.0, 0.0, 0.48333333333333334, 0.5095450316447439, 0.0, -0.04624173506532005, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:40,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-56.53585052]
 [-54.22218323]
 [-56.03247452]
 [-54.26822281]
 [-49.72953796]], R is [[-54.87134933]
 [-54.32263565]
 [-53.77941132]
 [-53.24161911]
 [-52.70920181]].
[2017-11-02 11:46:42,683] A3C_AGENT_WORKER-Thread-10 INFO:Local step 49000, global step 778156: loss -64.1113
[2017-11-02 11:46:43,594] A3C_AGENT_WORKER-Thread-16 INFO:Local step 49000, global step 778495: loss 109.4341
[2017-11-02 11:46:43,961] A3C_AGENT_WORKER-Thread-2 INFO:Local step 48500, global step 778654: loss -1.3496
[2017-11-02 11:46:44,084] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.97963667e-01   1.62492652e-04   1.07214064e-03   3.76035314e-04
   4.25661972e-04   7.53545649e-34   9.05098985e-33   2.97167342e-30
   4.29433154e-32], sum to 1.0000
[2017-11-02 11:46:44,099] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 2.433333333333334, 350.0, 0.0, 0.0, 8.0, 43.79341781590395, 20.0, 17.86203278558952, 19.4, 0.0, 114.4177388133804], 
actual action is [-2.0, 18], 
sim time next is 6927900.0000, 
raw observation next is [3.0, 87.0, 2.391666666666667, 350.0, 0.0, 0.0, -2.0, 44.69608060591288, 18.0, 18.15661988256502, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.41025641025641024, 0.87, 0.21742424242424246, 0.9722222222222222, 0.0, 0.0, 0.4666666666666667, 0.4469608060591288, 0.0, 0.02237426893786016, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:44,139] A3C_AGENT_WORKER-Thread-6 INFO:Local step 49000, global step 778730: loss 22.9315
[2017-11-02 11:46:45,854] A3C_AGENT_WORKER-Thread-12 INFO:Local step 48500, global step 779273: loss 6.8864
[2017-11-02 11:46:46,800] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.35398293e-03   2.29349315e-01   2.68414885e-01   4.29333150e-02
   4.55948561e-01   1.70117060e-31   2.54510649e-29   1.10398927e-27
   2.09392400e-28], sum to 1.0000
[2017-11-02 11:46:46,810] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [12.91666666666667, 51.25, 5.233333333333333, 110.8333333333333, 197.0, 87.16666666666667, 8.0, 23.90100595818502, 18.0, 22.0447044801966, 20.56, 1.0, 0.0], 
actual action is [7.91666666666667, 18.0], 
sim time next is 6711000.0000, 
raw observation next is [12.83333333333333, 51.5, 5.366666666666667, 111.6666666666667, 188.0, 74.33333333333331, 7.91666666666667, 24.00388895352177, 18.0, 22.03696052203504, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.6623931623931623, 0.515, 0.4878787878787879, 0.3101851851851853, 0.4973544973544973, 0.07433333333333332, 0.6319444444444445, 0.2400388895352177, 0.0, 0.5767086460050059, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:47,111] A3C_AGENT_WORKER-Thread-8 INFO:Local step 49000, global step 779685: loss 137.8738
[2017-11-02 11:46:49,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.79587200e-03   2.58642048e-01   1.42157316e-01   6.40166849e-02
   5.28388083e-01   2.13618101e-19   9.63022198e-18   9.25617686e-17
   2.37631255e-17], sum to 1.0000
[2017-11-02 11:46:49,037] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.0, 87.0, 4.516666666666666, 89.16666666666667, 126.9166666666667, 9.916666666666668, 1.0, 20.52089132465823, 18.0, 21.57669480373594, 22.2, 1.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6883800.0000, 
raw observation next is [6.0, 87.0, 4.433333333333333, 88.33333333333333, 132.3333333333333, 11.33333333333333, 1.0, 21.55282511747526, 18.0, 21.52032175990931, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.48717948717948717, 0.87, 0.40303030303030296, 0.24537037037037035, 0.35008818342151665, 0.01133333333333333, 0.5166666666666667, 0.21552825117475258, 0.0, 0.5029031085584731, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:49,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.07577097e-01   9.08469781e-03   2.64823926e-03   5.77211892e-03
   7.49179646e-02   6.37390608e-28   1.93663565e-26   2.33766110e-25
   7.65702175e-28], sum to 1.0000
[2017-11-02 11:46:49,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 75.0, 5.4, 120.0, 0.0, 0.0, 1.0, 39.56980955467817, 18.0, 19.63433263814161, 19.4, 0.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6741300.0000, 
raw observation next is [6.0, 75.0, 5.183333333333334, 118.3333333333333, 0.0, 0.0, 1.0, 39.60177338867735, 18.0, 19.62850556293358, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.48717948717948717, 0.75, 0.47121212121212125, 0.3287037037037036, 0.0, 0.0, 0.5166666666666667, 0.3960177338867735, 0.0, 0.2326436518476542, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:46:49,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.73444008e-03   1.39493823e-01   1.12103529e-01   3.60223055e-02
   7.08645880e-01   8.58127946e-26   2.09765656e-23   1.14945213e-22
   2.34897692e-23], sum to 1.0000
[2017-11-02 11:46:49,621] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [7.833333333333334, 75.0, 0.0, 0.0, 282.0, 22.0, 2.75, 17.52739746576825, 18.0, 22.17169045333904, 22.2, 1.0, 0.0], 
actual action is [2.833333333333334, 18.0], 
sim time next is 6958500.0000, 
raw observation next is [7.916666666666667, 75.5, 0.0, 0.0, 268.25, 20.0, 2.833333333333334, 17.45969434426367, 18.0, 22.18250854452273, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.5363247863247863, 0.755, 0.0, 0.0, 0.7096560846560847, 0.02, 0.5472222222222223, 0.1745969434426367, 0.0, 0.5975012206461042, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:46:49,754] A3C_AGENT_WORKER-Thread-7 INFO:Local step 49000, global step 780588: loss -89.7539
[2017-11-02 11:46:50,147] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.72626148e-02   2.37622231e-01   2.48949975e-01   1.90219462e-01
   2.85945654e-01   9.11560974e-13   7.46596188e-12   9.71029680e-12
   2.31620213e-12], sum to 1.0000
[2017-11-02 11:46:50,154] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [5.5, 72.75, 3.45, 97.5, 176.5, 42.0, 0.3333333333333339, 33.26428542822929, 18.0, 19.76832915238555, 19.4, 0.0, 0.0], 
actual action is [0.5, 18], 
sim time next is 6943800.0000, 
raw observation next is [5.666666666666666, 71.83333333333333, 3.666666666666667, 68.33333333333331, 175.0, 37.33333333333334, 0.5, 33.19806751798588, 18.0, 19.78398095520077, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.4786324786324786, 0.7183333333333333, 0.33333333333333337, 0.18981481481481477, 0.46296296296296297, 0.03733333333333334, 0.5083333333333333, 0.33198067517985885, 0.0, 0.2548544221715388, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:46:51,436] A3C_AGENT_WORKER-Thread-9 INFO:Local step 49000, global step 781028: loss -16.7121
[2017-11-02 11:46:51,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 48500, global step 781111: loss 38.1056
[2017-11-02 11:46:52,444] A3C_AGENT_WORKER-Thread-3 INFO:Local step 49000, global step 781366: loss -22.7593
[2017-11-02 11:46:53,622] A3C_AGENT_WORKER-Thread-14 INFO:Local step 48500, global step 781888: loss 4.0989
[2017-11-02 11:46:53,708] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.83636558e-01   6.93813385e-03   2.27077981e-04   2.03370629e-03
   7.16449320e-03   2.36192158e-27   1.01277858e-25   2.66603727e-25
   7.91531014e-28], sum to 1.0000
[2017-11-02 11:46:53,720] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 81.0, 0.375, 5.0, 0.0, 0.0, -1.0, 34.10534910042312, 18.0, 19.74021486607246, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 6902400.0000, 
raw observation next is [4.0, 81.0, 0.5, 6.666666666666666, 0.0, 0.0, -1.0, 35.04872333893125, 18.0, 19.65459990055862, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.4358974358974359, 0.81, 0.045454545454545456, 0.018518518518518517, 0.0, 0.0, 0.48333333333333334, 0.3504872333893125, 0.0, 0.23637141436551698, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:46:55,210] A3C_AGENT_WORKER-Thread-15 INFO:Local step 48500, global step 782579: loss 11.8802
[2017-11-02 11:46:55,784] A3C_AGENT_WORKER-Thread-17 INFO:Local step 49000, global step 782819: loss 60.1126
[2017-11-02 11:46:56,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.61400929e-02   9.67190638e-02   1.65719483e-02   6.72819614e-01
   1.47749245e-01   3.18428867e-10   5.69691294e-10   3.20152482e-09
   2.07649418e-11], sum to 1.0000
[2017-11-02 11:46:56,773] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [3.0, 87.0, 2.433333333333334, 343.3333333333334, 0.0, 0.0, -2.0, 45.05033623225929, 18.0, 18.93325416458227, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18.0], 
sim time next is 6932700.0000, 
raw observation next is [3.0, 87.0, 2.475, 342.5, 0.0, 0.0, -2.0, 45.6439853449131, 18.0, 18.86585283270634, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.87, 0.225, 0.9513888888888888, 0.0, 0.0, 0.4666666666666667, 0.45643985344913096, 0.0, 0.12369326181519165, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0763. 
=============================================
[2017-11-02 11:46:57,259] A3C_AGENT_WORKER-Thread-5 INFO:Local step 49000, global step 783557: loss 10.5680
[2017-11-02 11:46:58,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.60825807e-02   5.33052742e-01   5.67260422e-02   1.45546287e-01
   2.28592440e-01   8.63918054e-22   4.66828620e-20   1.47716311e-19
   8.38511533e-21], sum to 1.0000
[2017-11-02 11:46:58,345] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [11.0, 71.0, 0.0, 0.0, 89.5, 424.5833333333334, 6.0, 9.860850760422718, 18.0, 23.53154511783737, 22.2, 1.0, 0.0], 
actual action is [6.0, 18.0], 
sim time next is 6973800.0000, 
raw observation next is [11.0, 71.0, 0.0, 0.0, 86.0, 397.6666666666666, 6.0, 10.03079568017503, 18.0, 23.44042630044941, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.6153846153846154, 0.71, 0.0, 0.0, 0.2275132275132275, 0.39766666666666656, 0.6, 0.10030795680175031, 0.0, 0.7772037572070586, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0100. 
=============================================
[2017-11-02 11:46:59,937] A3C_AGENT_WORKER-Thread-4 INFO:Local step 49000, global step 784888: loss 0.6932
[2017-11-02 11:47:00,631] A3C_AGENT_WORKER-Thread-10 INFO:Local step 49500, global step 785224: loss 12.0089
[2017-11-02 11:47:00,793] A3C_AGENT_WORKER-Thread-11 INFO:Local step 48500, global step 785308: loss -0.7003
[2017-11-02 11:47:01,796] A3C_AGENT_WORKER-Thread-16 INFO:Local step 49500, global step 785866: loss -3.2404
[2017-11-02 11:47:02,376] A3C_AGENT_WORKER-Thread-6 INFO:Local step 49500, global step 786179: loss -7.4519
[2017-11-02 11:47:03,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  4.16454859e-02   2.25952446e-01   1.66429028e-01   2.60665625e-01
   3.05307508e-01   2.20906622e-19   1.59930398e-18   2.04116908e-17
   9.44983043e-18], sum to 1.0000
[2017-11-02 11:47:03,676] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [2.7, 87.75, 1.875, 55.0, 60.5, 33.25, 7.666666666666667, 30.65196522325166, 20.0, 19.25143928244423, 22.2, 1.0, 85.70937161936752], 
actual action is [7.7, 20.0], 
sim time next is 6852000.0000, 
raw observation next is [2.733333333333333, 87.66666666666667, 1.9, 56.66666666666667, 67.0, 35.83333333333334, 7.7, 27.90421844953518, 20.0, 19.47257205333582, 22.2, 1.0, 53.83298019109007], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.4034188034188034, 0.8766666666666667, 0.17272727272727273, 0.1574074074074074, 0.17724867724867724, 0.03583333333333334, 0.6283333333333334, 0.2790421844953518, 0.2857142857142857, 0.2103674361908315, 0.5999999999999999, 1.0, 0.6333291787187068], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:04,120] A3C_AGENT_WORKER-Thread-8 INFO:Local step 49500, global step 787016: loss 14.5270
[2017-11-02 11:47:04,817] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.11649552e-01   1.14439741e-01   1.12007305e-01   3.79711658e-01
   1.82191819e-01   5.87019156e-10   1.11259491e-09   1.67592118e-09
   8.60011992e-11], sum to 1.0000
[2017-11-02 11:47:04,823] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [3.0, 91.0, 3.433333333333333, 70.0, 109.0, 0.0, -2.0, 38.03938072357292, 18.0, 19.61302747011876, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6857100.0000, 
raw observation next is [3.0, 91.5, 3.6, 70.0, 110.5, 0.0, -2.0, 38.0135666273916, 18.0, 19.62196787601831, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.41025641025641024, 0.915, 0.32727272727272727, 0.19444444444444445, 0.2923280423280423, 0.0, 0.4666666666666667, 0.380135666273916, 0.0, 0.2317096965740443, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:05,420] A3C_AGENT_WORKER-Thread-2 INFO:Local step 49000, global step 787525: loss 89.6603
[2017-11-02 11:47:06,720] A3C_AGENT_WORKER-Thread-9 INFO:Local step 49500, global step 788078: loss -1.9307
[2017-11-02 11:47:07,323] A3C_AGENT_WORKER-Thread-7 INFO:Local step 49500, global step 788334: loss 68.0412
[2017-11-02 11:47:07,379] A3C_AGENT_WORKER-Thread-12 INFO:Local step 49000, global step 788359: loss 50.4730
[2017-11-02 11:47:08,198] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.71925232e-01   1.40007958e-01   1.60643652e-01   3.30847621e-01
   1.95597216e-01   1.87743120e-04   3.09210358e-04   3.91697977e-04
   8.96765923e-05], sum to 1.0000
[2017-11-02 11:47:08,231] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.91666666666667, 67.0, 2.558333333333334, 148.3333333333333, 141.5, 841.3333333333333, 8.83333333333333, 7.875979041676449, 18.0, 23.50937261850272, 19.4, 0.0, 0.0], 
actual action is [8.91666666666667, 18], 
sim time next is 7124400.0000, 
raw observation next is [14.0, 67.0, 2.6, 150.0, 142.0, 845.0, 8.91666666666667, 7.751127976889914, 18.0, 23.54177640606393, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.6923076923076923, 0.67, 0.23636363636363636, 0.4166666666666667, 0.37566137566137564, 0.845, 0.6486111111111111, 0.07751127976889914, 0.0, 0.7916823437234187, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:08,325] A3C_AGENT_WORKER-Thread-3 INFO:Local step 49500, global step 788775: loss -2.1766
[2017-11-02 11:47:08,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  5.76993465e-01   7.12624639e-02   5.27819023e-02   1.11759752e-01
   1.87202334e-01   3.79703144e-15   1.74233203e-14   3.91442873e-13
   1.63034392e-15], sum to 1.0000
[2017-11-02 11:47:08,605] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [11.0, 71.0, 0.0, 0.0, 0.0, 0.0, 6.0, 13.79895237560148, 18.0, 21.01925863939918, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 7077300.0000, 
raw observation next is [11.0, 71.0, 0.0, 0.0, 0.0, 0.0, 6.0, 13.94815705625428, 18.0, 20.99672435521541, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.9130434782608695, 0.6153846153846154, 0.71, 0.0, 0.0, 0.0, 0.0, 0.6, 0.1394815705625428, 0.0, 0.42810347931648707, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 11:47:11,784] A3C_AGENT_WORKER-Thread-17 INFO:Local step 49500, global step 790132: loss 12.6966
[2017-11-02 11:47:11,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.25023022e-01   1.84939876e-01   1.74926654e-01   3.31646144e-01
   1.83464274e-01   8.64820493e-10   2.55451438e-09   3.72409170e-09
   4.32151953e-10], sum to 1.0000
[2017-11-02 11:47:11,982] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [14.58333333333333, 64.66666666666666, 3.6, 160.0, 0.0, 0.0, 9.66666666666667, 5.694280690988454, 18.0, 23.34321126765427, 19.4, 0.0, 0.0], 
actual action is [9.58333333333333, 18], 
sim time next is 7165800.0000, 
raw observation next is [14.5, 65.0, 3.6, 160.0, 0.0, 0.0, 9.58333333333333, 5.693004377507686, 18.0, 23.3023069746484, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.7051282051282052, 0.65, 0.32727272727272727, 0.4444444444444444, 0.0, 0.0, 0.6597222222222221, 0.056930043775076856, 0.0, 0.7574724249497713, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:12,509] A3C_AGENT_WORKER-Thread-13 INFO:Local step 49000, global step 790468: loss -15.7717
[2017-11-02 11:47:13,558] A3C_AGENT_WORKER-Thread-5 INFO:Local step 49500, global step 790931: loss 24.1990
[2017-11-02 11:47:14,060] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.03963149e-01   3.40582244e-02   1.48381256e-02   2.52212528e-02
   2.19192933e-02   2.09102594e-18   7.48105703e-18   2.33803778e-16
   9.09940136e-19], sum to 1.0000
[2017-11-02 11:47:14,071] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.25, 67.75, 0.0, 0.0, 103.5, 532.25, 6.33333333333333, 10.96121896299938, 18.0, 23.24999406766451, 22.2, 1.0, 0.0], 
actual action is [6.25, 18], 
sim time next is 6972600.0000, 
raw observation next is [11.16666666666667, 68.83333333333334, 0.0, 0.0, 100.0, 505.3333333333333, 6.25, 10.92430563897937, 18.0, 23.24452344811444, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.6196581196581198, 0.6883333333333335, 0.0, 0.0, 0.26455026455026454, 0.5053333333333333, 0.6041666666666666, 0.10924305638979369, 0.0, 0.7492176354449198, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0109. 
=============================================
[2017-11-02 11:47:14,514] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-3.51416779]
 [-3.46307063]
 [-3.51191473]
 [-3.47352958]
 [-3.29762268]], R is [[-3.67592216]
 [-3.63916302]
 [-3.60277152]
 [-3.56674385]
 [-3.53107643]].
[2017-11-02 11:47:14,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.85766831e-01   9.36677679e-02   1.54987976e-01   4.38653976e-01
   1.26922876e-01   1.06325572e-07   1.76182141e-07   2.55447389e-07
   3.09108898e-08], sum to 1.0000
[2017-11-02 11:47:14,575] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [3.916666666666667, 81.5, 1.591666666666667, 331.6666666666667, 141.9166666666667, 139.4166666666667, -1.166666666666667, 38.81789275437561, 18.0, 19.23988175500622, 19.4, 0.0, 0.0], 
actual action is [-1.083333333333333, 18.0], 
sim time next is 6940800.0000, 
raw observation next is [4.0, 81.0, 1.5, 360.0, 147.5, 127.5, -1.083333333333333, 38.71737205399778, 18.0, 19.25249066200703, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.4358974358974359, 0.81, 0.13636363636363635, 1.0, 0.39021164021164023, 0.1275, 0.48194444444444445, 0.3871737205399778, 0.0, 0.17892723742957578, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0211. 
=============================================
[2017-11-02 11:47:14,634] A3C_AGENT_WORKER-Thread-14 INFO:Local step 49000, global step 791503: loss 23.6244
[2017-11-02 11:47:14,946] A3C_AGENT_WORKER-Thread-15 INFO:Local step 49000, global step 791634: loss -43.1886
[2017-11-02 11:47:15,047] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  5.35844922e-01   3.65940221e-02   7.72499815e-02   2.30400741e-01
   1.19910300e-01   3.05407955e-19   1.55193652e-18   8.07589535e-17
   4.44650835e-19], sum to 1.0000
[2017-11-02 11:47:15,072] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 84.5, 2.1, 70.0, 0.0, 0.0, 3.0, 20.82467098595621, 18.0, 20.11109176233218, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 7090200.0000, 
raw observation next is [8.0, 84.0, 2.1, 70.0, 0.0, 0.0, 3.0, 21.01889902835413, 18.0, 20.08691880108999, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.5384615384615384, 0.84, 0.19090909090909092, 0.19444444444444445, 0.0, 0.0, 0.55, 0.21018899028354132, 0.0, 0.29813125729857, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:15,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.44073769e-01   1.33204266e-01   1.53425992e-01   4.23916966e-01
   1.45373344e-01   9.88947704e-07   1.74259014e-06   2.56204498e-06
   4.24614854e-07], sum to 1.0000
[2017-11-02 11:47:15,181] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [14.0, 67.0, 4.308333333333333, 190.0, 15.41666666666667, 32.41666666666666, 9.0, 9.454965235906293, 18.0, 21.48464172663591, 19.4, 0.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7195200.0000, 
raw observation next is [14.0, 67.0, 4.266666666666667, 190.0, 23.83333333333333, 36.83333333333333, 9.0, 9.46835436579175, 18.0, 21.48117630831151, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.6923076923076923, 0.67, 0.3878787878787879, 0.5277777777777778, 0.0630511463844797, 0.03683333333333333, 0.65, 0.09468354365791751, 0.0, 0.4973109011873587, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:16,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.09307158e-01   1.44703276e-02   2.68360283e-02   1.28744528e-01
   2.06419360e-02   3.31708648e-15   3.10581359e-15   8.33810966e-14
   8.56081218e-16], sum to 1.0000
[2017-11-02 11:47:16,049] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [3.0, 87.0, 2.516666666666667, 341.6666666666667, 0.0, 0.0, -2.0, 30.51224733398233, 18.0, 19.79130422695547, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6933300.0000, 
raw observation next is [3.0, 87.0, 2.558333333333334, 340.8333333333333, 0.0, 0.0, -2.0, 32.43058175138059, 18.0, 19.82232925126582, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.87, 0.23257575757575763, 0.9467592592592592, 0.0, 0.0, 0.4666666666666667, 0.32430581751380594, 0.0, 0.2603327501808315, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:16,120] A3C_AGENT_WORKER-Thread-4 INFO:Local step 49500, global step 792182: loss -1.4279
[2017-11-02 11:47:17,053] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00840509e-01   8.45232308e-02   1.49588510e-01   5.37420452e-01
   1.27627119e-01   3.03641201e-08   6.59753852e-08   9.49451291e-08
   1.03613003e-08], sum to 1.0000
[2017-11-02 11:47:17,064] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [16.5, 57.5, 2.55, 145.0, 0.0, 0.0, 11.75, 5.831052150210521, 18.0, 23.72837397704626, 19.4, 0.0, 0.0], 
actual action is [11.5, 18], 
sim time next is 7162500.0000, 
raw observation next is [16.25, 58.41666666666666, 2.725, 147.5, 0.0, 0.0, 11.5, 5.806448090201433, 18.0, 23.69156494502947, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.75, 0.5841666666666666, 0.24772727272727274, 0.4097222222222222, 0.0, 0.0, 0.6916666666666667, 0.058064480902014326, 0.0, 0.8130807064327813, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:17,214] A3C_AGENT_WORKER-Thread-10 INFO:Local step 50000, global step 792748: loss -2.5136
[2017-11-02 11:47:17,254] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-0.12916577]
 [-0.24873793]
 [-0.00505018]
 [-0.0715338 ]
 [-0.16823304]], R is [[-0.00119032]
 [-0.00117842]
 [-0.00116663]
 [-0.00115497]
 [-0.00114342]].
[2017-11-02 11:47:18,352] A3C_AGENT_WORKER-Thread-16 INFO:Local step 50000, global step 793331: loss -1.3827
[2017-11-02 11:47:18,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.80361047e-01   1.25991106e-01   1.52747288e-01   3.74082267e-01
   1.66818157e-01   3.03191996e-08   5.17214787e-08   7.08252514e-08
   1.00981392e-08], sum to 1.0000
[2017-11-02 11:47:18,990] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [8.916666666666668, 66.83333333333334, 0.0, 0.0, 219.0833333333333, 33.08333333333333, 3.833333333333332, 18.34726135130226, 18.0, 21.55007910071584, 22.2, 1.0, 0.0], 
actual action is [3.916666666666668, 18.0], 
sim time next is 6962400.0000, 
raw observation next is [9.0, 66.0, 0.0, 0.0, 228.5, 38.5, 3.916666666666668, 18.3573688142531, 18.0, 21.69040062425461, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.5641025641025641, 0.66, 0.0, 0.0, 0.6044973544973545, 0.0385, 0.5652777777777779, 0.183573688142531, 0.0, 0.5272000891792301, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:19,572] A3C_AGENT_WORKER-Thread-6 INFO:Local step 50000, global step 793926: loss 0.5605
[2017-11-02 11:47:20,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.40971744e-01   3.45232338e-02   4.35190983e-02   1.20009840e-01
   6.09759912e-02   4.60603832e-13   1.27818795e-12   9.85475850e-12
   3.19163980e-14], sum to 1.0000
[2017-11-02 11:47:20,162] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.33333333333333, 66.66666666666666, 0.0, 0.0, 107.0, 559.1666666666667, 6.41666666666667, 11.15603682044706, 18.0, 22.99066674833519, 22.2, 1.0, 0.0], 
actual action is [6.33333333333333, 18], 
sim time next is 6972300.0000, 
raw observation next is [11.25, 67.75, 0.0, 0.0, 103.5, 532.25, 6.33333333333333, 11.07768920838388, 18.0, 22.99025596632716, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.6217948717948718, 0.6775, 0.0, 0.0, 0.27380952380952384, 0.53225, 0.6055555555555555, 0.1107768920838388, 0.0, 0.7128937094753088, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0111. 
=============================================
[2017-11-02 11:47:21,054] A3C_AGENT_WORKER-Thread-8 INFO:Local step 50000, global step 794689: loss -1.9044
[2017-11-02 11:47:21,741] A3C_AGENT_WORKER-Thread-2 INFO:Local step 49500, global step 795053: loss 9.9671
[2017-11-02 11:47:21,759] A3C_AGENT_WORKER-Thread-11 INFO:Local step 49000, global step 795060: loss 5.0429
[2017-11-02 11:47:22,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.94655713e-02   4.60782796e-02   5.07817388e-01   1.44056231e-01
   2.82582551e-01   8.93406054e-22   2.30954530e-20   6.45752142e-19
   2.38424019e-20], sum to 1.0000
[2017-11-02 11:47:22,657] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [8.0, 87.0, 1.516666666666667, 157.5, 0.0, 0.0, 13.0, 23.19674891446712, 20.0, 20.12151166618823, 19.4, 0.0, 60.41585436012681], 
actual action is [13.0, 20.0], 
sim time next is 7011000.0000, 
raw observation next is [8.0, 87.0, 1.3, 135.0, 0.0, 0.0, 13.0, 21.58647019652139, 20.0, 20.24600554847891, 19.4, 0.0, 27.36462287802429], 
processed observation next is [0.5, 0.13043478260869565, 0.5384615384615384, 0.87, 0.11818181818181818, 0.375, 0.0, 0.0, 0.7166666666666667, 0.2158647019652139, 0.2857142857142857, 0.320857935496987, 0.1999999999999998, 0.0, 0.3219367397414622], 
reward next is -0.2897. 
=============================================
[2017-11-02 11:47:23,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.71919659e-01   1.33615136e-01   1.98749810e-01   3.62962604e-01
   1.32344931e-01   8.00387497e-05   1.40956021e-04   1.53482746e-04
   3.34045944e-05], sum to 1.0000
[2017-11-02 11:47:23,168] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [22.33333333333334, 52.0, 8.366666666666667, 276.6666666666667, 254.0, 615.5, 17.25, 6.196269153771786, 18.0, 24.30845925537809, 19.4, 0.0, 0.0], 
actual action is [17.33333333333334, 18], 
sim time next is 7223100.0000, 
raw observation next is [22.41666666666666, 51.75, 8.283333333333333, 275.8333333333333, 249.5, 623.25, 17.33333333333334, 6.307495356177856, 18.0, 24.36102494832544, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.9081196581196579, 0.5175, 0.753030303030303, 0.7662037037037036, 0.66005291005291, 0.62325, 0.7888888888888891, 0.06307495356177856, 0.0, 0.9087178497607772, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:23,233] A3C_AGENT_WORKER-Thread-7 INFO:Local step 50000, global step 795849: loss -0.0064
[2017-11-02 11:47:23,234] A3C_AGENT_WORKER-Thread-9 INFO:Local step 50000, global step 795849: loss 0.6586
[2017-11-02 11:47:24,076] A3C_AGENT_WORKER-Thread-3 INFO:Local step 50000, global step 796317: loss -0.6554
[2017-11-02 11:47:24,258] A3C_AGENT_WORKER-Thread-12 INFO:Local step 49500, global step 796412: loss 16.2334
[2017-11-02 11:47:26,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 50000, global step 797639: loss 0.5917
[2017-11-02 11:47:28,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.17231122  0.18646039  0.18588868  0.29335064  0.14422812  0.00366391
  0.0061284   0.0057419   0.00222673], sum to 1.0000
[2017-11-02 11:47:28,252] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.0, 67.0, 2.1, 100.8333333333333, 264.0833333333334, 445.75, 8.0, 7.640390138913807, 18.0, 23.4786692827394, 19.4, 0.0, 0.0], 
actual action is [8.0, 18], 
sim time next is 7052400.0000, 
raw observation next is [13.0, 67.0, 2.1, 80.0, 252.5, 476.5, 8.0, 7.504661663739169, 18.0, 23.52992587568071, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.6666666666666666, 0.67, 0.19090909090909092, 0.2222222222222222, 0.667989417989418, 0.4765, 0.6333333333333333, 0.07504661663739169, 0.0, 0.7899894108115301, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:28,780] A3C_AGENT_WORKER-Thread-5 INFO:Local step 50000, global step 798842: loss -0.0714
[2017-11-02 11:47:28,998] A3C_AGENT_WORKER-Thread-13 INFO:Local step 49500, global step 798962: loss 0.7587
[2017-11-02 11:47:30,303] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[ 0.10702598]
 [ 0.07852495]
 [ 0.19025004]
 [-0.68886173]
 [-0.16024053]], R is [[-0.05285745]
 [-0.06158321]
 [-0.07025483]
 [-0.07887559]
 [-0.08744945]].
[2017-11-02 11:47:30,409] A3C_AGENT_WORKER-Thread-14 INFO:Local step 49500, global step 799717: loss -1.8300
[2017-11-02 11:47:30,576] A3C_AGENT_WORKER-Thread-15 INFO:Local step 49500, global step 799808: loss -1.7089
[2017-11-02 11:47:30,749] A3C_AGENT_WORKER-Thread-4 INFO:Local step 50000, global step 799905: loss 0.0377
[2017-11-02 11:47:32,627] A3C_AGENT_WORKER-Thread-10 INFO:Local step 50500, global step 800959: loss 1.7182
[2017-11-02 11:47:33,250] A3C_AGENT_WORKER-Thread-16 INFO:Local step 50500, global step 801283: loss -1.0489
[2017-11-02 11:47:34,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[ 0.91831005]
 [ 0.86492455]
 [ 0.98816288]
 [ 0.92154181]
 [ 0.89157546]], R is [[ 0.78355265]
 [ 0.77571714]
 [ 0.76795995]
 [ 0.76028037]
 [ 0.75267756]].
[2017-11-02 11:47:34,526] A3C_AGENT_WORKER-Thread-6 INFO:Local step 50500, global step 801912: loss 23.3909
[2017-11-02 11:47:34,942] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.09137309e-01   3.53038311e-02   1.52781140e-02   3.14948857e-02
   8.78580753e-03   3.34661965e-10   6.12324413e-10   2.93298297e-09
   6.53383641e-12], sum to 1.0000
[2017-11-02 11:47:34,962] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.83333333333333, 67.0, 2.516666666666667, 146.6666666666667, 141.0, 837.6666666666667, 8.75, 8.465364177299186, 18.0, 23.27467829934759, 22.2, 1.0, 0.0], 
actual action is [8.83333333333333, 18], 
sim time next is 7124100.0000, 
raw observation next is [13.91666666666667, 67.0, 2.558333333333334, 148.3333333333333, 141.5, 841.3333333333333, 8.83333333333333, 8.320457509261631, 18.0, 23.30802021418913, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.6901709401709403, 0.67, 0.23257575757575763, 0.4120370370370369, 0.37433862433862436, 0.8413333333333333, 0.6472222222222221, 0.0832045750926163, 0.0, 0.7582886020270188, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0083. 
=============================================
[2017-11-02 11:47:35,676] A3C_AGENT_WORKER-Thread-8 INFO:Local step 50500, global step 802537: loss 0.4499
[2017-11-02 11:47:35,794] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  5.61103597e-02   1.19469099e-01   3.25569332e-01   3.94224554e-01
   1.04626603e-01   9.64474269e-13   3.42019317e-12   2.11306944e-11
   5.86663747e-13], sum to 1.0000
[2017-11-02 11:47:35,809] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 76.0, 1.7, 10.0, 0.0, 0.0, 6.0, 9.338127818811152, 18.0, 22.74166279744696, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 7069500.0000, 
raw observation next is [11.0, 76.0, 1.65, 10.0, 0.0, 0.0, 6.0, 9.419689160902966, 18.0, 22.69558442122701, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.8260869565217391, 0.6153846153846154, 0.76, 0.15, 0.027777777777777776, 0.0, 0.0, 0.6, 0.09419689160902965, 0.0, 0.6707977744610015, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0094. 
=============================================
[2017-11-02 11:47:36,057] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.10882235e-02   1.05687298e-01   3.85339528e-01   3.77517551e-01
   9.03674141e-02   2.88400749e-12   1.59841636e-11   1.08214972e-10
   2.70840642e-12], sum to 1.0000
[2017-11-02 11:47:36,063] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.0, 67.0, 4.6, 188.3333333333333, 0.0, 0.0, 9.0, 9.57852563280506, 18.0, 21.47270807640664, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7192500.0000, 
raw observation next is [14.0, 67.0, 4.6, 189.1666666666667, 0.0, 0.0, 9.0, 9.636983647159434, 18.0, 21.46093052224404, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.6923076923076923, 0.67, 0.41818181818181815, 0.5254629629629631, 0.0, 0.0, 0.65, 0.09636983647159435, 0.0, 0.494418646034863, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0096. 
=============================================
[2017-11-02 11:47:36,286] A3C_AGENT_WORKER-Thread-11 INFO:Local step 49500, global step 802868: loss 4.8549
[2017-11-02 11:47:36,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-28.55152702]
 [-29.93252373]
 [-30.46138954]
 [-29.47636604]
 [-25.165411  ]], R is [[-32.34814453]
 [-33.02466202]
 [-33.69441605]
 [-34.35747147]
 [-35.01389694]].
[2017-11-02 11:47:36,701] A3C_AGENT_WORKER-Thread-2 INFO:Local step 50000, global step 803085: loss -0.6050
[2017-11-02 11:47:37,151] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.82659382e-01   6.79247379e-02   2.29562119e-01   3.62897515e-01
   5.69562465e-02   7.22280236e-10   2.21238960e-09   1.04546650e-07
   1.57179025e-09], sum to 1.0000
[2017-11-02 11:47:37,159] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [9.0, 92.0, 3.116666666666667, 315.0, 116.6666666666667, 9.666666666666664, 4.0, 13.34795872820113, 18.0, 22.01239293705568, 22.2, 1.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 7401300.0000, 
raw observation next is [9.0, 92.5, 2.858333333333333, 317.5, 123.5833333333333, 12.08333333333333, 4.0, 13.22961539684785, 18.0, 22.01775988488527, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.5641025641025641, 0.925, 0.25984848484848483, 0.8819444444444444, 0.3269400352733685, 0.01208333333333333, 0.5666666666666667, 0.1322961539684785, 0.0, 0.5739656978407527, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0132. 
=============================================
[2017-11-02 11:47:37,479] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  6.22943223e-01   5.42431325e-02   9.04349238e-02   2.05114797e-01
   2.72639245e-02   3.38475585e-14   3.28658033e-14   3.74314214e-13
   3.58845915e-14], sum to 1.0000
[2017-11-02 11:47:37,490] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [5.25, 63.0, 3.1, 150.0, 0.0, 0.0, 0.166666666666667, 30.34006456076019, 18.0, 19.02950296836739, 19.4, 0.0, 0.0], 
actual action is [0.25, 18], 
sim time next is 7366800.0000, 
raw observation next is [5.333333333333334, 62.66666666666667, 3.1, 150.0, 0.0, 0.0, 0.25, 30.49518192101368, 18.0, 19.02143286333667, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.47008547008547014, 0.6266666666666667, 0.2818181818181818, 0.4166666666666667, 0.0, 0.0, 0.5041666666666667, 0.3049518192101368, 0.0, 0.1459189804766672, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0541. 
=============================================
[2017-11-02 11:47:38,211] A3C_AGENT_WORKER-Thread-7 INFO:Local step 50500, global step 803841: loss -0.0583
[2017-11-02 11:47:38,268] A3C_AGENT_WORKER-Thread-9 INFO:Local step 50500, global step 803862: loss 1.6687
[2017-11-02 11:47:38,358] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.1285879   0.18818049  0.19814575  0.26676041  0.20236778  0.00418737
  0.00467329  0.00472444  0.00237254], sum to 1.0000
[2017-11-02 11:47:38,380] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [10.66666666666667, 51.16666666666667, 3.85, 141.6666666666667, 112.3333333333333, 0.0, 5.5, 19.87957034325561, 18.0, 20.61770579244715, 19.4, 0.0, 0.0], 
actual action is [5.66666666666667, 18], 
sim time next is 7376100.0000, 
raw observation next is [10.83333333333333, 50.58333333333333, 3.725, 140.8333333333333, 116.1666666666667, 0.0, 5.66666666666667, 19.59182995952462, 18.0, 20.6758357762485, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.6111111111111109, 0.5058333333333332, 0.3386363636363636, 0.39120370370370355, 0.30731922398589073, 0.0, 0.5944444444444446, 0.1959182995952462, 0.0, 0.3822622537497859, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:38,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.05103858e-01   2.05530748e-01   1.71966642e-01   3.02261353e-01
   2.15126678e-01   2.16580270e-06   3.80417737e-06   3.55081033e-06
   1.23969448e-06], sum to 1.0000
[2017-11-02 11:47:38,761] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [16.0, 45.0, 3.6, 290.0, 0.0, 0.0, 11.08333333333333, 5.460586817536338, 18.0, 23.32531998435674, 19.4, 0.0, 0.0], 
actual action is [11.0, 18], 
sim time next is 7247100.0000, 
raw observation next is [15.91666666666667, 44.66666666666666, 3.941666666666666, 290.0, 0.0, 0.0, 11.0, 5.453843333759014, 18.0, 23.29331595237203, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.7414529914529916, 0.44666666666666655, 0.3583333333333333, 0.8055555555555556, 0.0, 0.0, 0.6833333333333333, 0.05453843333759014, 0.0, 0.7561879931960043, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:39,498] A3C_AGENT_WORKER-Thread-12 INFO:Local step 50000, global step 804538: loss 0.2030
[2017-11-02 11:47:39,723] A3C_AGENT_WORKER-Thread-3 INFO:Local step 50500, global step 804644: loss 79.3378
[2017-11-02 11:47:40,590] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  7.99550861e-02   1.81180984e-01   1.73785329e-01   3.44714105e-01
   2.20364258e-01   7.68859536e-08   1.12713550e-07   1.10773655e-07
   2.77762275e-08], sum to 1.0000
[2017-11-02 11:47:40,614] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.5, 44.5, 2.6, 200.0, 0.0, 0.0, 5.58333333333333, 11.95979706233979, 18.0, 21.47215956789648, 19.4, 0.0, 0.0], 
actual action is [5.5, 18], 
sim time next is 7335300.0000, 
raw observation next is [10.41666666666667, 44.75, 2.6, 201.6666666666667, 0.0, 0.0, 5.5, 12.10957680778864, 18.0, 21.44156158452773, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.6004273504273505, 0.4475, 0.23636363636363636, 0.5601851851851853, 0.0, 0.0, 0.5916666666666667, 0.1210957680778864, 0.0, 0.49165165493253277, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:41,226] A3C_AGENT_WORKER-Thread-17 INFO:Local step 50500, global step 805407: loss -9.1105
[2017-11-02 11:47:41,283] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.84245557e-01   2.38471478e-01   2.07428008e-01   2.01181158e-01
   1.68673813e-01   4.13625297e-12   1.11047135e-11   3.31171583e-11
   7.02733553e-13], sum to 1.0000
[2017-11-02 11:47:41,291] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.0, 67.0, 4.308333333333333, 190.0, 15.41666666666667, 32.41666666666666, 9.0, 9.654452943808183, 18.0, 21.42719260483228, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7195200.0000, 
raw observation next is [14.0, 67.0, 4.266666666666667, 190.0, 23.83333333333333, 36.83333333333333, 9.0, 9.668660966891897, 18.0, 21.42364799892771, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.6923076923076923, 0.67, 0.3878787878787879, 0.5277777777777778, 0.0630511463844797, 0.03683333333333333, 0.65, 0.09668660966891897, 0.0, 0.489092571275387, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0097. 
=============================================
[2017-11-02 11:47:44,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 50000, global step 806906: loss -0.0019
[2017-11-02 11:47:44,569] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.68015790e-01   6.96113426e-03   5.80897229e-03   1.35314316e-02
   5.68272592e-03   2.09966325e-16   2.06906750e-16   4.01520764e-15
   1.14129219e-17], sum to 1.0000
[2017-11-02 11:47:44,579] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 64.0, 3.6, 160.0, 0.0, 0.0, 9.916666666666666, 26.6651426181072, 22.0, 19.20534087661053, 19.4, 0.0, 11.63186975623868], 
actual action is [0.0, 18], 
sim time next is 7362300.0000, 
raw observation next is [5.0, 64.0, 3.558333333333333, 159.1666666666667, 0.0, 0.0, 0.0, 27.18866549186571, 18.0, 19.20978348802762, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.46153846153846156, 0.64, 0.3234848484848485, 0.44212962962962976, 0.0, 0.0, 0.5, 0.2718866549186571, 0.0, 0.17282621257537453, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0272. 
=============================================
[2017-11-02 11:47:44,741] A3C_AGENT_WORKER-Thread-5 INFO:Local step 50500, global step 807042: loss 1.9859
[2017-11-02 11:47:45,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.02169091e-01   1.44417614e-01   2.79274166e-01   2.01546893e-01
   1.72592223e-01   9.68293262e-13   3.49969749e-12   3.23273214e-11
   3.45624571e-13], sum to 1.0000
[2017-11-02 11:47:45,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.666666666666667, 61.0, 4.766666666666667, 290.0, 0.0, 0.0, 2.75, 16.21483679032712, 18.0, 20.33441047479882, 22.2, 1.0, 0.0], 
actual action is [2.666666666666667, 18], 
sim time next is 7280700.0000, 
raw observation next is [7.583333333333333, 61.0, 4.808333333333333, 287.5, 0.0, 0.0, 2.666666666666667, 16.40851275131979, 18.0, 20.30779272475277, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.5277777777777778, 0.61, 0.4371212121212121, 0.7986111111111112, 0.0, 0.0, 0.5444444444444444, 0.1640851275131979, 0.0, 0.3296846749646813, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:45,375] A3C_AGENT_WORKER-Thread-14 INFO:Local step 50000, global step 807344: loss 0.0199
[2017-11-02 11:47:45,743] A3C_AGENT_WORKER-Thread-15 INFO:Local step 50000, global step 807500: loss 0.3936
[2017-11-02 11:47:46,003] A3C_AGENT_WORKER-Thread-4 INFO:Local step 50500, global step 807628: loss -1.8805
[2017-11-02 11:47:46,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.46913365e-01   1.48339242e-01   1.47626832e-01   2.84738421e-01
   2.72382140e-01   5.45028026e-14   1.01871263e-13   1.99665886e-13
   1.78242719e-14], sum to 1.0000
[2017-11-02 11:47:46,519] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.666666666666667, 87.0, 5.7, 250.0, 0.0, 0.0, -0.166666666666667, 27.79452192592674, 18.0, 19.74564602253831, 19.4, 0.0, 0.0], 
actual action is [-0.33333333333333304, 18.0], 
sim time next is 7499700.0000, 
raw observation next is [4.5, 87.0, 5.7, 250.0, 0.0, 0.0, -0.333333333333333, 28.17857746030693, 18.0, 19.69010870964687, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.44871794871794873, 0.87, 0.5181818181818182, 0.6944444444444444, 0.0, 0.0, 0.49444444444444446, 0.2817857746030693, 0.0, 0.2414441013781245, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:46,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.95236027e-01   1.35383636e-01   4.91780639e-02   4.38080095e-02
   7.63942823e-02   4.38321905e-12   9.53024985e-12   5.93091617e-11
   2.57543363e-13], sum to 1.0000
[2017-11-02 11:47:46,621] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.666666666666666, 76.0, 3.933333333333333, 246.6666666666667, 312.1666666666667, 449.3333333333334, 2.583333333333334, 10.35036930269078, 18.0, 23.31050431029488, 22.2, 1.0, 0.0], 
actual action is [2.666666666666666, 18], 
sim time next is 7483500.0000, 
raw observation next is [7.75, 76.0, 3.975, 247.5, 307.25, 415.0, 2.666666666666666, 10.24020738829877, 18.0, 23.35817108717378, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.532051282051282, 0.76, 0.3613636363636364, 0.6875, 0.8128306878306878, 0.415, 0.5444444444444444, 0.10240207388298771, 0.0, 0.7654530124533971, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0102. 
=============================================
[2017-11-02 11:47:49,579] A3C_AGENT_WORKER-Thread-10 INFO:Local step 51000, global step 809370: loss 55.7225
[2017-11-02 11:47:50,852] A3C_AGENT_WORKER-Thread-16 INFO:Local step 51000, global step 809974: loss 7.5465
[2017-11-02 11:47:51,315] A3C_AGENT_WORKER-Thread-11 INFO:Local step 50000, global step 810186: loss -1.5143
[2017-11-02 11:47:51,434] A3C_AGENT_WORKER-Thread-6 INFO:Local step 51000, global step 810240: loss 8.0619
[2017-11-02 11:47:51,631] A3C_AGENT_WORKER-Thread-2 INFO:Local step 50500, global step 810330: loss -0.0878
[2017-11-02 11:47:53,421] A3C_AGENT_WORKER-Thread-8 INFO:Local step 51000, global step 811134: loss -2.2147
[2017-11-02 11:47:53,495] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  4.45503384e-01   2.80106455e-01   9.55693796e-02   7.73790851e-02
   1.01441652e-01   5.58070257e-10   8.34203651e-10   3.39457973e-09
   2.47472997e-11], sum to 1.0000
[2017-11-02 11:47:53,510] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.0, 41.0, 5.7, 330.0, 147.5, 868.5, 7.91666666666667, 10.31697661079774, 18.0, 21.83050758417743, 22.2, 1.0, 0.0], 
actual action is [8.0, 18], 
sim time next is 7304700.0000, 
raw observation next is [13.0, 41.24999999999999, 5.783333333333333, 325.8333333333333, 147.25, 867.25, 8.0, 10.2310276584121, 18.0, 21.84006390221533, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.4124999999999999, 0.5257575757575758, 0.9050925925925926, 0.38955026455026454, 0.86725, 0.6333333333333333, 0.102310276584121, 0.0, 0.548580557459333, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0102. 
=============================================
[2017-11-02 11:47:54,806] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.78848708e-01   3.78723532e-01   1.61984771e-01   8.22767317e-02
   9.81663018e-02   6.68120849e-21   1.91635453e-20   7.80788059e-20
   2.29414363e-21], sum to 1.0000
[2017-11-02 11:47:54,821] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.25, 87.0, 6.45, 257.5, 0.0, 0.0, -2.666666666666667, 30.3724150214277, 18.0, 19.75899328818269, 19.4, 0.0, 0.0], 
actual action is [-2.75, 18], 
sim time next is 7509000.0000, 
raw observation next is [2.166666666666667, 87.0, 6.366666666666667, 258.3333333333334, 0.0, 0.0, -2.75, 30.76812265840729, 18.0, 19.71706719881568, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.3888888888888889, 0.87, 0.5787878787878789, 0.7175925925925929, 0.0, 0.0, 0.45416666666666666, 0.3076812265840729, 0.0, 0.24529531411652578, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:47:55,237] A3C_AGENT_WORKER-Thread-12 INFO:Local step 50500, global step 811905: loss -1.6724
[2017-11-02 11:47:55,476] A3C_AGENT_WORKER-Thread-7 INFO:Local step 51000, global step 812044: loss 42.5757
[2017-11-02 11:47:55,489] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.49150014e-01   7.14928687e-01   6.51707500e-02   2.21198369e-02
   4.86307293e-02   3.09144810e-12   1.20212000e-11   1.24695076e-09
   9.51942431e-12], sum to 1.0000
[2017-11-02 11:47:55,500] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.69876629e-01   5.07344663e-01   9.49237198e-02   4.49826978e-02
   8.28723088e-02   3.10696361e-14   1.13037502e-13   6.90033859e-13
   4.04287005e-15], sum to 1.0000
[2017-11-02 11:47:55,506] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.75, 71.25, 2.975, 197.5, 160.5, 0.0, 0.666666666666667, 23.62701810662285, 18.0, 20.74846884386963, 22.2, 1.0, 0.0], 
actual action is [0.75, 18], 
sim time next is 7465800.0000, 
raw observation next is [5.833333333333333, 70.83333333333333, 3.016666666666667, 201.6666666666667, 166.3333333333333, 0.0, 0.75, 23.53633166084564, 18.0, 20.76166543741299, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.48290598290598286, 0.7083333333333333, 0.2742424242424243, 0.5601851851851853, 0.4400352733686066, 0.0, 0.5125, 0.2353633166084564, 0.0, 0.3945236339161414, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:55,514] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [8.0, 87.0, 4.274999999999999, 231.6666666666667, 70.66666666666667, 0.0, 3.0, 13.4831582503187, 18.0, 22.5286781503282, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 7492200.0000, 
raw observation next is [8.0, 87.0, 4.449999999999999, 233.3333333333333, 67.33333333333333, 0.0, 3.0, 13.84689726462515, 18.0, 22.41264159579544, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.5384615384615384, 0.87, 0.4045454545454545, 0.648148148148148, 0.1781305114638448, 0.0, 0.55, 0.1384689726462515, 0.0, 0.6303773708279198, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0138. 
=============================================
[2017-11-02 11:47:55,835] A3C_AGENT_WORKER-Thread-3 INFO:Local step 51000, global step 812239: loss -0.6140
[2017-11-02 11:47:56,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  6.99358165e-01   1.59826487e-01   5.42340390e-02   4.07162234e-02
   4.58651818e-02   8.21715794e-17   1.27357240e-16   1.71474112e-15
   9.14092149e-17], sum to 1.0000
[2017-11-02 11:47:56,122] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.0, 87.0, 6.2, 270.0, 0.0, 0.0, -2.0, 40.54248377285015, 18.0, 18.85357273015026, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7522500.0000, 
raw observation next is [3.0, 88.0, 6.116666666666667, 270.0, 0.0, 0.0, -2.0, 40.7601660757433, 18.0, 18.83656997858279, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.41025641025641024, 0.88, 0.5560606060606061, 0.75, 0.0, 0.0, 0.4666666666666667, 0.407601660757433, 0.0, 0.11950999694039867, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0805. 
=============================================
[2017-11-02 11:47:56,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 51000, global step 812457: loss -1.6102
[2017-11-02 11:47:57,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.50904320e-02   7.86468089e-01   8.87767822e-02   2.94762850e-02
   8.01884532e-02   4.80974490e-17   9.47406669e-16   1.60393363e-14
   2.60775239e-16], sum to 1.0000
[2017-11-02 11:47:57,286] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.0, 60.0, 3.6, 170.0, 0.0, 0.0, 1.25, 17.59952399861957, 18.0, 20.4857422256151, 22.2, 1.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 7344300.0000, 
raw observation next is [6.0, 60.41666666666666, 3.6, 169.1666666666667, 0.0, 0.0, 1.0, 17.77181694059018, 18.0, 20.43627786613482, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.0, 0.48717948717948717, 0.6041666666666665, 0.32727272727272727, 0.46990740740740755, 0.0, 0.0, 0.5166666666666667, 0.17771816940590182, 0.0, 0.3480396951621171, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:57,463] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.79513466e-01   1.99347362e-02   1.58266674e-04   6.67775166e-05
   3.26869893e-04   3.15476597e-36   1.89249138e-35   5.05774040e-33
   5.52261186e-36], sum to 1.0000
[2017-11-02 11:47:57,483] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 7.949999999999999, 240.0, 0.0, 0.0, 8.0, 36.81350191184717, 20.0, 18.11964973813518, 19.4, 0.0, 102.3216001591916], 
actual action is [-2.0, 18], 
sim time next is 7540500.0000, 
raw observation next is [3.0, 87.0, 7.991666666666666, 240.0, 8.16666666666667, 0.0, -2.0, 38.68789436367517, 18.0, 18.37392608462765, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.41025641025641024, 0.87, 0.7265151515151514, 0.6666666666666666, 0.021604938271604947, 0.0, 0.4666666666666667, 0.3868789436367517, 0.0, 0.053418012089664506, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:47:58,968] A3C_AGENT_WORKER-Thread-17 INFO:Local step 51000, global step 813888: loss 1.4404
[2017-11-02 11:48:00,085] A3C_AGENT_WORKER-Thread-13 INFO:Local step 50500, global step 814419: loss 46.6253
[2017-11-02 11:48:00,429] A3C_AGENT_WORKER-Thread-14 INFO:Local step 50500, global step 814573: loss -0.7545
[2017-11-02 11:48:01,532] A3C_AGENT_WORKER-Thread-5 INFO:Local step 51000, global step 815082: loss 28.8468
[2017-11-02 11:48:02,069] A3C_AGENT_WORKER-Thread-15 INFO:Local step 50500, global step 815385: loss 0.4494
[2017-11-02 11:48:02,722] A3C_AGENT_WORKER-Thread-4 INFO:Local step 51000, global step 815688: loss 10.8014
[2017-11-02 11:48:03,486] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  8.86302173e-01   1.50941014e-02   8.02403083e-04   2.96676764e-03
   9.48345363e-02   1.80013350e-28   1.92636944e-27   2.90152754e-25
   1.13203947e-27], sum to 1.0000
[2017-11-02 11:48:03,499] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 93.0, 5.7, 265.0, 0.0, 0.0, -2.0, 31.37256742519735, 18.0, 20.00459291703428, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7529700.0000, 
raw observation next is [3.0, 93.0, 5.7, 262.5, 0.0, 0.0, -2.0, 32.73775649034069, 18.0, 19.94847720144399, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.41025641025641024, 0.93, 0.5181818181818182, 0.7291666666666666, 0.0, 0.0, 0.4666666666666667, 0.3273775649034069, 0.0, 0.27835388592056987, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:03,947] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-25.40052605]
 [-24.71932983]
 [-30.12491608]
 [-30.24059296]
 [-33.90416336]], R is [[-19.9852581 ]
 [-20.78540611]
 [-21.5775528 ]
 [-22.36177826]
 [-23.13816071]].
[2017-11-02 11:48:05,382] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.12227427  0.19241838  0.16606051  0.21646151  0.2925882   0.00229128
  0.00377338  0.00267309  0.00145932], sum to 1.0000
[2017-11-02 11:48:05,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [7.083333333333333, 60.25, 3.558333333333333, 315.8333333333333, 217.0, 697.8333333333334, 2.0, 17.3436680897986, 18.0, 22.1498491734392, 19.4, 0.0, 0.0], 
actual action is [2.083333333333333, 18], 
sim time next is 7643400.0000, 
raw observation next is [7.166666666666667, 59.5, 3.516666666666667, 311.6666666666667, 212.0, 713.6666666666667, 2.083333333333333, 17.67992631032867, 18.0, 22.06172164600383, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.5170940170940171, 0.595, 0.31969696969696976, 0.8657407407407408, 0.5608465608465608, 0.7136666666666668, 0.5347222222222222, 0.17679926310328672, 0.0, 0.5802459494291183, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:06,755] A3C_AGENT_WORKER-Thread-11 INFO:Local step 50500, global step 817353: loss 1.7091
[2017-11-02 11:48:07,018] A3C_AGENT_WORKER-Thread-10 INFO:Local step 51500, global step 817453: loss 143.4420
[2017-11-02 11:48:09,388] A3C_AGENT_WORKER-Thread-6 INFO:Local step 51500, global step 818415: loss -8.6990
[2017-11-02 11:48:09,445] A3C_AGENT_WORKER-Thread-16 INFO:Local step 51500, global step 818445: loss 62.1640
[2017-11-02 11:48:10,159] A3C_AGENT_WORKER-Thread-2 INFO:Local step 51000, global step 818733: loss -2.6979
[2017-11-02 11:48:11,437] A3C_AGENT_WORKER-Thread-8 INFO:Local step 51500, global step 819251: loss 81.3776
[2017-11-02 11:48:12,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[ -6.83427668]
 [ -6.71552134]
 [ -8.61939049]
 [-10.37686539]
 [ -9.50361443]], R is [[-6.39503384]
 [-6.33108377]
 [-6.26777315]
 [-6.20509529]
 [-6.36691332]].
[2017-11-02 11:48:13,293] A3C_AGENT_WORKER-Thread-3 INFO:Local step 51500, global step 820023: loss -46.4480
[2017-11-02 11:48:13,559] A3C_AGENT_WORKER-Thread-7 INFO:Local step 51500, global step 820148: loss 7.6831
[2017-11-02 11:48:14,015] A3C_AGENT_WORKER-Thread-9 INFO:Local step 51500, global step 820361: loss 1.3149
[2017-11-02 11:48:14,296] A3C_AGENT_WORKER-Thread-12 INFO:Local step 51000, global step 820501: loss 4.2601
[2017-11-02 11:48:16,228] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.11797918  0.18054129  0.19081768  0.20264567  0.2980935   0.00221697
  0.00344976  0.00200183  0.00225416], sum to 1.0000
[2017-11-02 11:48:16,257] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [5.333333333333334, 71.66666666666667, 3.333333333333333, 310.0, 203.0, 597.5000000000001, 0.25, 21.74718258052414, 18.0, 21.45547950688186, 19.4, 0.0, 0.0], 
actual action is [0.3333333333333339, 18], 
sim time next is 7637100.0000, 
raw observation next is [5.416666666666666, 70.83333333333333, 3.341666666666666, 310.0, 202.5, 634.2499999999999, 0.3333333333333339, 21.06193172574346, 18.0, 21.59247353509604, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.391304347826087, 0.47222222222222215, 0.7083333333333333, 0.3037878787878787, 0.8611111111111112, 0.5357142857142857, 0.6342499999999999, 0.5055555555555556, 0.2106193172574346, 0.0, 0.51321050501372, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:16,792] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  5.99596381e-01   8.38144422e-02   1.23998307e-01   3.69244032e-02
   1.55666426e-01   2.57192021e-20   8.50303413e-20   6.54859297e-19
   1.03354835e-19], sum to 1.0000
[2017-11-02 11:48:16,809] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 3.683333333333333, 268.3333333333333, 0.0, 0.0, 7.0, 34.15148815316344, 20.0, 19.34781904221209, 19.4, 0.0, 59.76564728123965], 
actual action is [-3.0, 18], 
sim time next is 7626600.0000, 
raw observation next is [2.0, 80.0, 3.6, 270.0, 0.0, 0.0, -3.0, 35.04641865231459, 18.0, 19.39421289983965, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.2608695652173913, 0.38461538461538464, 0.8, 0.32727272727272727, 0.75, 0.0, 0.0, 0.45, 0.3504641865231459, 0.0, 0.19917327140566446, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0008. 
=============================================
[2017-11-02 11:48:16,963] A3C_AGENT_WORKER-Thread-17 INFO:Local step 51500, global step 821637: loss -12.7763
[2017-11-02 11:48:18,761] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:18,761] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:18,782] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:18,782] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:18,782] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:18,783] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 35.11sec

[2017-11-02 11:48:18,938] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.20249279e-01   1.96407259e-01   1.97674543e-01   2.03263581e-01
   2.81368315e-01   2.32610837e-04   3.74595693e-04   2.18339352e-04
   2.11476086e-04], sum to 1.0000
[2017-11-02 11:48:18,948] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.33333333333333, 43.0, 3.766666666666667, 320.0, 135.1666666666667, 824.1666666666667, 8.16666666666667, 7.512985996507009, 18.0, 24.03328163465771, 19.4, 0.0, 0.0], 
actual action is [8.33333333333333, 18], 
sim time next is 7742700.0000, 
raw observation next is [13.5, 42.5, 3.85, 327.5, 134.25, 819.75, 8.33333333333333, 7.404162125757273, 18.0, 24.10459362265973, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.6794871794871795, 0.425, 0.35000000000000003, 0.9097222222222222, 0.3551587301587302, 0.81975, 0.6388888888888888, 0.07404162125757273, 0.0, 0.8720848032371045, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:19,229] A3C_AGENT_WORKER-Thread-13 INFO:Local step 51000, global step 822635: loss 5.5309
[2017-11-02 11:48:19,757] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:19,766] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res10/Eplus-env-sub_run3
[2017-11-02 11:48:20,119] A3C_AGENT_WORKER-Thread-14 INFO:Local step 51000, global step 823021: loss -0.4025
[2017-11-02 11:48:20,587] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:20,587] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:20,588] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:20,588] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:20,588] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:20,588] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:20,588] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:20,589] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:20,590] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:20,591] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 34.40sec

[2017-11-02 11:48:20,591] A3C_AGENT_WORKER-Thread-5 INFO:Local step 51500, global step 823235: loss -28.9050
[2017-11-02 11:48:20,735] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  8.76503825e-01   2.53479462e-02   3.64647172e-02   3.26847658e-02
   2.89986618e-02   2.90839130e-13   4.81462851e-13   3.25256445e-12
   3.97117696e-13], sum to 1.0000
[2017-11-02 11:48:20,753] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 88.5, 7.7, 245.0, 0.0, 0.0, -2.0, 37.46288976909221, 18.0, 19.44196118543165, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7537800.0000, 
raw observation next is [3.0, 88.0, 7.7, 243.3333333333333, 0.0, 0.0, -2.0, 37.7522065060932, 18.0, 19.40872403442777, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.88, 0.7000000000000001, 0.6759259259259258, 0.0, 0.0, 0.4666666666666667, 0.377522065060932, 0.0, 0.2012462906325386, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:21,374] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:21,374] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:21,391] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:21,392] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:21,393] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:21,393] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:21,393] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:21,394] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:21,394] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 41.10sec

[2017-11-02 11:48:21,579] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:21,586] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res16/Eplus-env-sub_run3
[2017-11-02 11:48:21,716] A3C_AGENT_WORKER-Thread-15 INFO:Local step 51000, global step 823686: loss 3.5750
[2017-11-02 11:48:21,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.71617377e-01   4.04105932e-02   3.35742272e-02   1.42967105e-02
   4.01010141e-02   1.75169145e-15   2.94231760e-15   1.01994227e-14
   2.97473037e-15], sum to 1.0000
[2017-11-02 11:48:21,783] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 88.5, 7.7, 245.0, 0.0, 0.0, -2.0, 28.30952764873367, 18.0, 19.62083878014916, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7537800.0000, 
raw observation next is [3.0, 88.0, 7.7, 243.3333333333333, 0.0, 0.0, -2.0, 29.48679825903109, 18.0, 19.68889990982948, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.88, 0.7000000000000001, 0.6759259259259258, 0.0, 0.0, 0.4666666666666667, 0.2948679825903109, 0.0, 0.24127141568992577, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:21,879] A3C_AGENT_WORKER-Thread-4 INFO:Local step 51500, global step 823747: loss 8.1649
[2017-11-02 11:48:22,377] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:22,393] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res6/Eplus-env-sub_run3
[2017-11-02 11:48:22,561] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:22,561] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:22,692] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:22,693] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 34.71sec

[2017-11-02 11:48:23,545] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:23,549] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res8/Eplus-env-sub_run3
[2017-11-02 11:48:24,603] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:24,604] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:24,642] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:24,643] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 37.38sec

[2017-11-02 11:48:24,978] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.55527398e-01   2.25427717e-01   1.83172196e-01   1.61436900e-01
   2.74358988e-01   1.87345431e-05   2.67292307e-05   1.44772102e-05
   1.68428105e-05], sum to 1.0000
[2017-11-02 11:48:25,023] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.0, 70.0, 0.75, 145.0, 106.0, 476.0, -3.166666666666667, 33.93100450630997, 18.0, 19.26636702784174, 19.4, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 7716900.0000, 
raw observation next is [2.166666666666667, 69.66666666666667, 0.625, 120.8333333333333, 107.25, 494.3333333333334, -3.0, 33.03958282097173, 18.0, 19.37853841304835, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.3888888888888889, 0.6966666666666668, 0.056818181818181816, 0.33564814814814803, 0.2837301587301587, 0.4943333333333334, 0.45, 0.3303958282097173, 0.0, 0.19693405900690714, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0031. 
=============================================
[2017-11-02 11:48:25,494] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:25,496] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:25,496] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:25,496] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:25,497] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:25,498] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 37.54sec

[2017-11-02 11:48:25,610] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:25,614] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res3/Eplus-env-sub_run3
[2017-11-02 11:48:25,819] A3C_AGENT_WORKER-Thread-11 INFO:Local step 51000, global step 825103: loss 3.8010
[2017-11-02 11:48:26,502] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:26,506] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res7/Eplus-env-sub_run3
[2017-11-02 11:48:26,674] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:26,675] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:26,677] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:26,678] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 27.69sec

[2017-11-02 11:48:27,667] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:27,670] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res9/Eplus-env-sub_run3
[2017-11-02 11:48:28,295] A3C_AGENT_WORKER-Thread-2 INFO:Local step 51500, global step 825570: loss 10.4756
[2017-11-02 11:48:30,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.84706208e-02   4.59658563e-01   1.54422775e-01   3.90680283e-02
   2.48379961e-01   8.96684430e-17   8.21677016e-17   2.24369472e-16
   2.60985012e-16], sum to 1.0000
[2017-11-02 11:48:30,272] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.583333333333333, 72.08333333333333, 3.016666666666667, 287.5, 0.0, 0.0, -0.333333333333333, 23.41651169351199, 18.0, 20.64145943107182, 19.4, 0.0, 0.0], 
actual action is [-0.41666666666666696, 18.0], 
sim time next is 7597800.0000, 
raw observation next is [4.5, 72.5, 3.1, 285.0, 0.0, 0.0, -0.416666666666667, 23.80523022570784, 18.0, 20.58608570124985, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.44871794871794873, 0.725, 0.2818181818181818, 0.7916666666666666, 0.0, 0.0, 0.4930555555555555, 0.2380523022570784, 0.0, 0.3694408144642643, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:31,657] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:31,658] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 36.91sec

[2017-11-02 11:48:31,681] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:31,682] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:32,653] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:32,656] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res17/Eplus-env-sub_run3
[2017-11-02 11:48:34,371] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:34,371] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:34,401] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:34,402] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 42.10sec

[2017-11-02 11:48:35,371] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:35,374] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res5/Eplus-env-sub_run3
[2017-11-02 11:48:36,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 51500, global step 826719: loss -0.8279
[2017-11-02 11:48:37,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.64663300e-01   5.69493592e-01   3.73222157e-02   4.42605559e-03
   2.24094823e-01   4.25484317e-24   2.53502917e-24   2.99876669e-23
   1.70053073e-23], sum to 1.0000
[2017-11-02 11:48:37,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 81.16666666666667, 4.016666666666667, 256.6666666666667, 0.0, 0.0, -3.0, 36.63134474581798, 18.0, 18.89556025150995, 19.4, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 7624500.0000, 
raw observation next is [2.0, 80.58333333333333, 4.058333333333333, 258.3333333333333, 0.0, 0.0, -3.0, 37.9179603759746, 18.0, 18.81203272198125, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.38461538461538464, 0.8058333333333333, 0.3689393939393939, 0.7175925925925926, 0.0, 0.0, 0.45, 0.379179603759746, 0.0, 0.11600467456875004, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0840. 
=============================================
[2017-11-02 11:48:39,171] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:39,171] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:39,945] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:39,946] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 49.60sec

[2017-11-02 11:48:40,172] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:40,197] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res4/Eplus-env-sub_run3
[2017-11-02 11:48:43,842] A3C_AGENT_WORKER-Thread-13 INFO:Local step 51500, global step 827407: loss -13.1225
[2017-11-02 11:48:48,112] A3C_AGENT_WORKER-Thread-14 INFO:Local step 51500, global step 827731: loss 64.4425
[2017-11-02 11:48:49,388] A3C_AGENT_WORKER-Thread-15 INFO:Local step 51500, global step 827843: loss -8.1746
[2017-11-02 11:48:51,353] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:51,353] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:47

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:51,367] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:51,368] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 57.32sec

[2017-11-02 11:48:52,357] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:48:52,360] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res2/Eplus-env-sub_run3
[2017-11-02 11:48:53,524] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.15732014e-01   6.85666323e-01   1.58714522e-02   4.24510241e-03
   1.78485066e-01   7.06320574e-24   2.86995052e-24   5.75041222e-24
   3.09312392e-23], sum to 1.0000
[2017-11-02 11:48:53,547] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.0, 66.58333333333333, 3.3, 320.8333333333333, 0.0, 0.0, -3.0, 22.3772309748053, 18.0, 19.74416894861614, 19.4, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 7690200.0000, 
raw observation next is [2.0, 66.16666666666667, 3.0, 291.6666666666667, 0.0, 0.0, -3.0, 24.13971650811181, 18.0, 19.73144334271901, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.0, 0.38461538461538464, 0.6616666666666667, 0.2727272727272727, 0.8101851851851852, 0.0, 0.0, 0.45, 0.2413971650811181, 0.0, 0.2473490489598587, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:48:59,114] A3C_AGENT_WORKER-Thread-11 INFO:Local step 51500, global step 828550: loss -4.9708
[2017-11-02 11:48:59,705] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:59,705] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:48:59,716] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:48:59,716] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:48

[2017-11-02 11:48:59,716] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:48:59,716] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:48:59,716] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:48:59,717] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:48:59,718] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:48:59,718] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:48:59,718] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:48:59,718] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 00min 56.26sec

[2017-11-02 11:49:00,710] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:49:00,721] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res12/Eplus-env-sub_run3
[2017-11-02 11:49:03,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-0.41763663]
 [-0.3748908 ]
 [-0.38276374]
 [-0.40436339]
 [-0.33511305]], R is [[-0.42093441]
 [-0.41672507]
 [-0.41255781]
 [-0.40843225]
 [-0.40434793]].
[2017-11-02 11:49:07,513] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:07,513] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:48

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:49:07,565] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:49:07,566] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 01min  4.31sec

[2017-11-02 11:49:08,517] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:49:08,520] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res13/Eplus-env-sub_run3
[2017-11-02 11:49:09,014] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.93284345e-01   7.75161665e-04   1.05009917e-06   2.45358734e-07
   9.03053267e-04   7.79981347e-05   4.86302406e-06   3.04661063e-03
   1.90663652e-03], sum to 1.0000
[2017-11-02 11:49:09,031] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.6, 95.08333333333333, 4.1, 281.6666666666666, 0.0, 0.0, -5.0, 29.19992417020309, 18.0, 19.65446279971044, 21.5, 0.0, 0.0], 
actual action is [-4.4, 18], 
sim time next is 600.0000, 
raw observation next is [1.2, 95.16666666666667, 4.1, 273.3333333333334, 0.0, 0.0, -4.4, 30.82727976173015, 18.0, 19.59203125880981, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3641025641025641, 0.9516666666666667, 0.3727272727272727, 0.7592592592592595, 0.0, 0.0, 0.4266666666666667, 0.3082727976173015, 0.0, 0.22743303697283018, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:49:09,504] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:09,504] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:09,517] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:48

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:49:09,518] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:49:09,519] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 01min  5.99sec

[2017-11-02 11:49:10,509] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:49:10,512] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res14/Eplus-env-sub_run3
[2017-11-02 11:49:11,157] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:11,157] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:48

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:49:11,169] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:49:11,170] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 01min  7.44sec

[2017-11-02 11:49:12,157] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:49:12,160] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res15/Eplus-env-sub_run3
[2017-11-02 11:49:20,041] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:20,042] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:48

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 11:49:20,062] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 11:49:20,063] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=01hr 01min 15.69sec

[2017-11-02 11:49:21,045] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 11:49:21,060] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res11/Eplus-env-sub_run3
[2017-11-02 11:49:21,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  7.22501338e-01   1.92980647e-01   3.15705948e-02   4.29405272e-03
   4.86533754e-02   2.33630865e-35   1.96101501e-35   6.50293634e-35
   1.35589850e-32], sum to 1.0000
[2017-11-02 11:49:21,206] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 4.808333333333333, 220.0, 0.0, 0.0, 2.2, 30.88966632157845, 18.0, 19.79636600674161, 21.5, 0.0, 0.0], 
actual action is [2.2, 18], 
sim time next is 9600.0000, 
raw observation next is [7.2, 96.0, 4.766666666666667, 220.0, 0.0, 0.0, 2.2, 31.69113644261098, 18.0, 19.6846949696022, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5179487179487179, 0.96, 0.43333333333333335, 0.6111111111111112, 0.0, 0.0, 0.5366666666666667, 0.3169113644261098, 0.0, 0.24067070994317166, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:49:22,896] A3C_AGENT_WORKER-Thread-10 INFO:Local step 52000, global step 830118: loss -128.6343
[2017-11-02 11:49:24,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.34209466e-01   4.21775967e-01   7.38144368e-02   7.59280706e-03
   6.26072809e-02   2.21314436e-31   4.59979732e-31   2.62880711e-30
   3.91700447e-28], sum to 1.0000
[2017-11-02 11:49:24,422] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 6.191666666666666, 250.0, 12.25, 0.0, 12.7, 22.58022309195093, 23.0, 19.6797613855458, 22.7, 1.0, 117.2142874129199], 
actual action is [12.7, 22.0], 
sim time next is 29400.0000, 
raw observation next is [7.7, 93.0, 6.283333333333333, 250.0, 14.0, 0.0, 12.7, 18.71012883157534, 22.0, 19.87335960182907, 22.7, 1.0, 84.79531906233203], 
processed observation next is [1.0, 0.34782608695652173, 0.5307692307692308, 0.93, 0.5712121212121212, 0.6944444444444444, 0.037037037037037035, 0.0, 0.7116666666666667, 0.1871012883157534, 0.5714285714285714, 0.2676228002612956, 0.6714285714285714, 1.0, 0.9975919889686121], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:49:28,124] A3C_AGENT_WORKER-Thread-8 INFO:Local step 52000, global step 830442: loss -2.4169
[2017-11-02 11:49:28,505] A3C_AGENT_WORKER-Thread-6 INFO:Local step 52000, global step 830467: loss 123.8293
[2017-11-02 11:49:30,789] A3C_AGENT_WORKER-Thread-16 INFO:Local step 52000, global step 830583: loss 81.6023
[2017-11-02 11:49:34,260] A3C_AGENT_WORKER-Thread-3 INFO:Local step 52000, global step 830830: loss 50.2071
[2017-11-02 11:49:35,714] A3C_AGENT_WORKER-Thread-9 INFO:Local step 52000, global step 830981: loss -16.0872
[2017-11-02 11:49:36,889] A3C_AGENT_WORKER-Thread-7 INFO:Local step 52000, global step 831104: loss 12.7215
[2017-11-02 11:49:42,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.39937569e-07   8.30729723e-01   1.55775413e-01   4.26166691e-03
   9.23308078e-03   3.69484623e-15   5.68975815e-14   2.36988272e-13
   1.46776623e-12], sum to 1.0000
[2017-11-02 11:49:42,789] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [7.800000000000001, 91.83333333333333, 6.016666666666667, 251.6666666666667, 89.0, 0.0, 2.75, 12.70547550742915, 18.0, 22.14094224648744, 22.7, 1.0, 0.0], 
actual action is [2.8000000000000007, 18], 
sim time next is 44100.0000, 
raw observation next is [7.850000000000001, 91.25, 5.975, 252.5, 90.75, 0.0, 2.800000000000001, 13.8202113042461, 18.0, 22.17779151156004, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5346153846153846, 0.9125, 0.5431818181818181, 0.7013888888888888, 0.2400793650793651, 0.0, 0.5466666666666667, 0.138202113042461, 0.0, 0.5968273587942916, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0138. 
=============================================
[2017-11-02 11:49:42,790] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.0781484   0.44968554  0.46071494  0.00122721  0.01022397  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-02 11:49:42,866] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 5.975, 240.0, 0.0, 0.0, 12.7, 21.18474623245545, 23.0, 20.30646464300765, 21.5, 0.0, 44.86667386997757], 
actual action is [2.7, 18.0], 
sim time next is 24600.0000, 
raw observation next is [7.7, 93.0, 6.016666666666666, 240.0, 0.0, 0.0, 2.7, 22.24463743096799, 18.0, 20.28791007721216, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.5307692307692308, 0.93, 0.5469696969696969, 0.6666666666666666, 0.0, 0.0, 0.545, 0.22244637430967992, 0.0, 0.3268442967445943, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:49:44,160] A3C_AGENT_WORKER-Thread-17 INFO:Local step 52000, global step 831845: loss -23.3731
[2017-11-02 11:49:47,542] A3C_AGENT_WORKER-Thread-5 INFO:Local step 52000, global step 832164: loss 42.5938
[2017-11-02 11:49:50,649] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.49278228e-26   2.03742426e-10   3.49350236e-11   4.67897943e-11
   7.87780258e-12   6.98915590e-03   1.73978563e-02   3.82774249e-02
   9.37335610e-01], sum to 1.0000
[2017-11-02 11:49:50,740] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [6.233333333333333, 83.33333333333334, 7.533333333333333, 273.3333333333334, 23.33333333333333, 0.0, 11.325, 15.02652553696827, 23.0, 21.8732363716933, 22.7, 1.0, 41.41981581270384], 
actual action is [11.233333333333334, 25], 
sim time next is 59100.0000, 
raw observation next is [6.141666666666666, 83.66666666666666, 7.491666666666666, 274.1666666666666, 20.66666666666667, 0.0, 11.23333333333333, 14.01608182661129, 25.0, 21.84095100081423, 22.7, 1.0, 52.74361329427835], 
processed observation next is [1.0, 0.6956521739130435, 0.4908119658119658, 0.8366666666666666, 0.681060606060606, 0.7615740740740738, 0.05467372134038802, 0.0, 0.6872222222222223, 0.1401608182661129, 1.0, 0.5487072858306041, 0.6714285714285714, 1.0, 0.6205130975797453], 
reward next is -0.5725. 
=============================================
[2017-11-02 11:49:53,136] A3C_AGENT_WORKER-Thread-4 INFO:Local step 52000, global step 832693: loss 95.8589
[2017-11-02 11:50:00,405] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.41105340e-06   6.07230425e-01   3.06810439e-01   7.84858465e-02
   7.46888295e-03   5.70720277e-11   8.90474014e-11   3.65560138e-10
   4.59381955e-09], sum to 1.0000
[2017-11-02 11:50:00,560] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-8.3, 65.16666666666667, 8.1, 261.6666666666667, 166.0, 209.6666666666666, -3.25, 13.51463482516894, 25.0, 22.19037260985204, 22.7, 1.0, 64.95240950175484], 
actual action is [-3.3000000000000007, 23.0], 
sim time next is 129300.0000, 
raw observation next is [-8.35, 63.08333333333334, 8.399999999999999, 260.8333333333333, 161.5, 258.8333333333333, -3.300000000000001, 13.12754963115001, 23.0, 22.2922162942755, 22.7, 1.0, 64.55395781134872], 
processed observation next is [0.0, 0.4782608695652174, 0.11923076923076924, 0.6308333333333335, 0.7636363636363636, 0.724537037037037, 0.42724867724867727, 0.2588333333333333, 0.445, 0.1312754963115001, 0.7142857142857143, 0.6131737563250717, 0.6714285714285714, 1.0, 0.759458327192338], 
reward next is -0.6966. 
=============================================
[2017-11-02 11:50:03,216] A3C_AGENT_WORKER-Thread-2 INFO:Local step 52000, global step 833621: loss 82.6512
[2017-11-02 11:50:06,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.91155200e-04   5.42452574e-01   4.30610806e-01   2.15582550e-02
   4.78715869e-03   1.00308479e-15   9.31275880e-16   4.94187863e-15
   1.80269997e-13], sum to 1.0000
[2017-11-02 11:50:06,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.05, 84.0, 7.45, 275.0, 18.0, 0.0, 1.141666666666666, 16.75511468447442, 18.0, 21.58979512930534, 22.7, 1.0, 0.0], 
actual action is [1.0499999999999998, 18], 
sim time next is 59700.0000, 
raw observation next is [5.958333333333333, 84.33333333333334, 7.408333333333333, 275.8333333333333, 16.5, 0.0, 1.05, 17.47927818942629, 18.0, 21.56412649855436, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.4861111111111111, 0.8433333333333334, 0.6734848484848485, 0.7662037037037036, 0.04365079365079365, 0.0, 0.5175, 0.1747927818942629, 0.0, 0.5091609283649083, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:50:09,468] A3C_AGENT_WORKER-Thread-12 INFO:Local step 52000, global step 834364: loss 6.9664
[2017-11-02 11:50:11,751] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.51306736
  0.01057131  0.10231972  0.37404162], sum to 1.0000
[2017-11-02 11:50:11,862] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.1, 68.66666666666666, 7.2, 266.6666666666667, 22.5, 2.5, -2.050000000000001, 17.59451583071699, 24.0, 21.97814945651598, 22.7, 1.0, 56.73969886597917], 
actual action is [-2.0999999999999996, 25], 
sim time next is 146700.0000, 
raw observation next is [-7.149999999999999, 69.25, 7.2, 267.5, 20.25, 2.25, -2.1, 16.94062655740449, 25.0, 21.96793854520541, 22.7, 1.0, 68.40429182524967], 
processed observation next is [0.0, 0.6956521739130435, 0.15000000000000005, 0.6925, 0.6545454545454545, 0.7430555555555556, 0.05357142857142857, 0.00225, 0.46499999999999997, 0.1694062655740449, 1.0, 0.5668483636007728, 0.6714285714285714, 1.0, 0.804756374414702], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:50:13,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-64.75540924]
 [-64.62220001]
 [-59.80328751]
 [-65.29733276]
 [-61.44499969]], R is [[-65.19651794]
 [-65.54455566]
 [-65.88911438]
 [-66.23022461]
 [-66.5679245 ]].
[2017-11-02 11:50:16,285] A3C_AGENT_WORKER-Thread-13 INFO:Local step 52000, global step 835155: loss 30.1371
[2017-11-02 11:50:16,325] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  4.61573094e-01   2.59980023e-01   2.64235348e-01   9.15659498e-03
   5.05490089e-03   5.78495676e-26   8.16828342e-25   2.33282894e-24
   4.93451492e-23], sum to 1.0000
[2017-11-02 11:50:16,364] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.7, 93.0, 6.1, 254.1666666666667, 76.75, 0.0, 12.7, 11.99850993801731, 23.0, 22.10877779228925, 22.7, 1.0, 46.52439853033284], 
actual action is [12.7, 22.0], 
sim time next is 42000.0000, 
raw observation next is [7.699999999999999, 93.0, 6.1, 253.3333333333333, 78.5, 0.0, 12.7, 11.82754030087573, 22.0, 22.10685945172907, 22.7, 1.0, 28.65298908958448], 
processed observation next is [1.0, 0.4782608695652174, 0.5307692307692308, 0.93, 0.5545454545454546, 0.7037037037037036, 0.20767195767195767, 0.0, 0.7116666666666667, 0.1182754030087573, 0.5714285714285714, 0.5866942073898669, 0.6714285714285714, 1.0, 0.3370939892892292], 
reward next is -0.3152. 
=============================================
[2017-11-02 11:50:17,501] A3C_AGENT_WORKER-Thread-15 INFO:Local step 52000, global step 835309: loss 2.7488
[2017-11-02 11:50:17,772] A3C_AGENT_WORKER-Thread-14 INFO:Local step 52000, global step 835350: loss -94.9805
[2017-11-02 11:50:26,077] A3C_AGENT_WORKER-Thread-11 INFO:Local step 52000, global step 836579: loss -1.0714
[2017-11-02 11:50:30,034] A3C_AGENT_WORKER-Thread-8 INFO:Local step 52500, global step 837209: loss -38.0661
[2017-11-02 11:50:30,569] A3C_AGENT_WORKER-Thread-10 INFO:Local step 52500, global step 837277: loss -89.2248
[2017-11-02 11:50:32,018] A3C_AGENT_WORKER-Thread-16 INFO:Local step 52500, global step 837465: loss 48.2293
[2017-11-02 11:50:32,683] A3C_AGENT_WORKER-Thread-6 INFO:Local step 52500, global step 837548: loss 1.4422
[2017-11-02 11:50:33,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.56666811e-05   7.16407895e-01   3.10626160e-02   2.50640035e-01
   1.87378540e-03   8.39514813e-21   2.27112286e-19   2.53022064e-19
   2.56895101e-17], sum to 1.0000
[2017-11-02 11:50:33,260] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.666666666666667, 78.16666666666667, 6.6, 268.3333333333333, 0.0, 0.0, 1.466666666666667, 17.93199519561654, 23.0, 20.96660277020777, 21.5, 0.0, 47.5655566418713], 
actual action is [1.333333333333333, 22.5], 
sim time next is 101700.0000, 
raw observation next is [-3.8, 77.75, 6.6, 267.5, 0.0, 0.0, 1.333333333333333, 17.7266614328194, 22.5, 20.87596463288937, 21.5, 0.0, 46.06093248558604], 
processed observation next is [0.0, 0.17391304347826086, 0.2358974358974359, 0.7775, 0.6, 0.7430555555555556, 0.0, 0.0, 0.5222222222222223, 0.17726661432819402, 0.6428571428571429, 0.41085209041276727, 0.5, 0.0, 0.5418933233598358], 
reward next is -0.5769. 
=============================================
[2017-11-02 11:50:38,355] A3C_AGENT_WORKER-Thread-3 INFO:Local step 52500, global step 838207: loss -47.1263
[2017-11-02 11:50:38,821] A3C_AGENT_WORKER-Thread-9 INFO:Local step 52500, global step 838259: loss -92.7599
[2017-11-02 11:50:39,055] A3C_AGENT_WORKER-Thread-7 INFO:Local step 52500, global step 838280: loss -63.3307
[2017-11-02 11:50:45,449] A3C_AGENT_WORKER-Thread-17 INFO:Local step 52500, global step 838898: loss 273.2459
[2017-11-02 11:50:47,559] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  7.39555084e-10   2.65894711e-01   4.87564981e-01   2.46092558e-01
   4.47760685e-04   3.99159863e-23   1.84512119e-20   7.21370076e-21
   9.03360121e-19], sum to 1.0000
[2017-11-02 11:50:47,624] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-8.9, 78.0, 3.933333333333334, 193.3333333333333, 0.0, 0.0, -3.9, 23.23879419964755, 23.5, 20.38579199092635, 21.5, 0.0, 34.4181180288552], 
actual action is [-3.9000000000000004, 21.5], 
sim time next is 193500.0000, 
raw observation next is [-8.9, 78.0, 3.85, 192.5, 0.0, 0.0, -3.9, 23.58322012745809, 21.5, 20.31974924284852, 21.5, 0.0, 42.38455340403587], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.10512820512820512, 0.78, 0.35000000000000003, 0.5347222222222222, 0.0, 0.0, 0.435, 0.2358322012745809, 0.5, 0.33139274897835996, 0.5, 0.0, 0.49864180475336317], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:50:49,669] A3C_AGENT_WORKER-Thread-5 INFO:Local step 52500, global step 839234: loss 76.2129
[2017-11-02 11:50:53,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.83202133e-01   3.06375444e-01   4.61808652e-01   4.83308733e-02
   2.82878580e-04   0.00000000e+00   3.15301263e-38   0.00000000e+00
   6.43172265e-36], sum to 1.0000
[2017-11-02 11:50:53,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.4, 70.0, 4.766666666666667, 260.0, 0.0, 0.0, -3.4, 27.15615075843858, 23.0, 20.50102730546588, 21.5, 0.0, 68.80919164033085], 
actual action is [-3.4000000000000004, 22.0], 
sim time next is 164700.0000, 
raw observation next is [-8.4, 70.25, 4.725, 260.0, 0.0, 0.0, -3.4, 25.22446550602674, 22.0, 20.45532786009646, 21.5, 0.0, 58.25742438711303], 
processed observation next is [0.0, 0.9130434782608695, 0.11794871794871795, 0.7025, 0.4295454545454545, 0.7222222222222222, 0.0, 0.0, 0.44333333333333336, 0.2522446550602674, 0.5714285714285714, 0.3507611228709229, 0.5, 0.0, 0.6853814633778004], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:50:54,705] A3C_AGENT_WORKER-Thread-4 INFO:Local step 52500, global step 839718: loss -133.8008
[2017-11-02 11:50:54,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   9.94696836e-16   1.36354133e-16   1.60149896e-15
   1.56007732e-18   7.58915558e-04   1.18016824e-01   8.91653672e-02
   7.92058885e-01], sum to 1.0000
[2017-11-02 11:50:55,117] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.199999999999999, 69.83333333333334, 7.199999999999999, 268.3333333333333, 18.0, 2.0, -12.15, 17.37766028748881, 18.0, 22.45178419398079, 22.7, 1.0, 0.0], 
actual action is [-2.1999999999999993, 23.0], 
sim time next is 147300.0000, 
raw observation next is [-7.25, 70.41666666666666, 7.2, 269.1666666666667, 15.75, 1.75, -2.199999999999999, 17.47992566356783, 23.0, 22.27908209021344, 22.7, 1.0, 53.92306788590921], 
processed observation next is [0.0, 0.6956521739130435, 0.14743589743589744, 0.7041666666666666, 0.6545454545454545, 0.7476851851851852, 0.041666666666666664, 0.00175, 0.4633333333333333, 0.1747992566356783, 0.7142857142857143, 0.6112974414590627, 0.6714285714285714, 1.0, 0.6343890339518731], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:00,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.12802833e-08   4.87537414e-01   3.65037233e-01   1.46743089e-01
   6.82173471e-04   4.39009519e-14   6.79739251e-12   1.56093769e-12
   9.09925260e-11], sum to 1.0000
[2017-11-02 11:51:01,012] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.299999999999999, 66.83333333333333, 7.408333333333333, 270.0, 0.0, 0.0, -2.300000000000001, 14.33076777570516, 20.5, 22.71983231988505, 22.7, 1.0, 41.44557486684923], 
actual action is [-2.299999999999999, 20.0], 
sim time next is 149400.0000, 
raw observation next is [-7.3, 66.0, 7.45, 270.0, 0.0, 0.0, -2.299999999999999, 14.91665973473629, 20.0, 22.64564003076757, 22.7, 1.0, 38.77608420347956], 
processed observation next is [0.0, 0.7391304347826086, 0.14615384615384616, 0.66, 0.6772727272727272, 0.75, 0.0, 0.0, 0.4616666666666667, 0.1491665973473629, 0.2857142857142857, 0.6636628615382243, 0.6714285714285714, 1.0, 0.456189225923289], 
reward next is -0.4255. 
=============================================
[2017-11-02 11:51:05,346] A3C_AGENT_WORKER-Thread-2 INFO:Local step 52500, global step 840870: loss -86.1573
[2017-11-02 11:51:10,272] A3C_AGENT_WORKER-Thread-12 INFO:Local step 52500, global step 841509: loss 1.0067
[2017-11-02 11:51:11,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.78836364e-16   4.71968472e-01   4.29024577e-01   8.32159147e-02
   1.33369677e-03   8.10740232e-07   2.31761776e-04   3.32989002e-05
   1.41914506e-02], sum to 1.0000
[2017-11-02 11:51:11,511] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.9, 78.0, 3.6, 202.5, 0.0, 0.0, -3.9, 20.57902789012254, 25.0, 20.82322216181264, 21.5, 0.0, 46.52703216961231], 
actual action is [-3.9000000000000004, 24.0], 
sim time next is 186600.0000, 
raw observation next is [-8.9, 78.0, 3.6, 201.6666666666667, 0.0, 0.0, -3.9, 20.62202608369479, 24.0, 20.81087127336911, 21.5, 0.0, 46.54272317770074], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.10512820512820512, 0.78, 0.32727272727272727, 0.5601851851851853, 0.0, 0.0, 0.435, 0.20622026083694792, 0.8571428571428571, 0.4015530390527299, 0.5, 0.0, 0.5475614491494205], 
reward next is -0.5913. 
=============================================
[2017-11-02 11:51:12,873] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00119515
  0.08200584  0.02915988  0.88763916], sum to 1.0000
[2017-11-02 11:51:13,053] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.399999999999999, 62.24999999999999, 6.233333333333333, 229.1666666666667, 33.83333333333333, 0.0, 1.6, 14.24687517127946, 25.0, 22.61724315332972, 22.7, 1.0, 66.43982130195221], 
actual action is [1.600000000000001, 25], 
sim time next is 231000.0000, 
raw observation next is [-3.4, 62.5, 6.366666666666666, 228.3333333333333, 30.66666666666666, 0.0, 1.600000000000001, 13.80394690696201, 25.0, 22.63082835030669, 22.7, 1.0, 67.28624781455693], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.24615384615384614, 0.625, 0.5787878787878787, 0.6342592592592591, 0.08112874779541444, 0.0, 0.5266666666666667, 0.13803946906962009, 1.0, 0.66154690718667, 0.6714285714285714, 1.0, 0.7916029154653756], 
reward next is -0.7262. 
=============================================
[2017-11-02 11:51:13,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-65.1164856 ]
 [-65.43719482]
 [-64.02720642]
 [-64.01075745]
 [-63.60458755]], R is [[-65.47367096]
 [-65.36846924]
 [-65.26407623]
 [-65.16196442]
 [-65.059021  ]].
[2017-11-02 11:51:14,739] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  7.65995210e-05   1.48761077e-02   9.82044697e-01   2.72489456e-03
   2.77754531e-04   2.54339287e-24   7.04113263e-21   1.50409284e-21
   3.11893775e-19], sum to 1.0000
[2017-11-02 11:51:14,808] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.9, 59.5, 7.433333333333334, 230.0, 76.33333333333333, 0.0, 2.15, 17.55259187616571, 25.0, 22.22115902484999, 22.7, 1.0, 38.88854511421093], 
actual action is [2.1, 24.0], 
sim time next is 227700.0000, 
raw observation next is [-2.95, 59.75, 7.300000000000001, 230.0, 71.25, 0.0, 2.1, 17.16318523533434, 24.0, 22.18133712821012, 22.7, 1.0, 52.7137272622352], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2576923076923077, 0.5975, 0.6636363636363637, 0.6388888888888888, 0.1884920634920635, 0.0, 0.535, 0.17163185235334338, 0.8571428571428571, 0.5973338754585887, 0.6714285714285714, 1.0, 0.6201614972027671], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:15,733] A3C_AGENT_WORKER-Thread-13 INFO:Local step 52500, global step 842157: loss 32.5983
[2017-11-02 11:51:16,379] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.23870565e-15   2.40272775e-01   7.11783171e-01   4.54500392e-02
   2.33351416e-03   2.24093917e-08   3.77489619e-06   1.41981798e-06
   1.55393907e-04], sum to 1.0000
[2017-11-02 11:51:16,456] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-7.0, 69.0, 6.9, 285.0, 0.0, 0.0, -1.949999999999999, 17.11475208164767, 25.0, 21.3549850972251, 21.5, 0.0, 49.0805597700905], 
actual action is [-2.0, 24.0], 
sim time next is 264900.0000, 
raw observation next is [-7.050000000000001, 69.33333333333334, 6.766666666666667, 284.1666666666667, 0.0, 0.0, -2.0, 16.89466734226378, 24.0, 21.37953568970287, 21.5, 0.0, 48.84279389213952], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.15256410256410255, 0.6933333333333335, 0.6151515151515151, 0.7893518518518519, 0.0, 0.0, 0.4666666666666667, 0.1689466734226378, 0.8571428571428571, 0.48279081281469566, 0.5, 0.0, 0.5746211046134061], 
reward next is -0.5344. 
=============================================
[2017-11-02 11:51:17,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 52500, global step 842345: loss -96.3572
[2017-11-02 11:51:19,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 52500, global step 842571: loss -14.8178
[2017-11-02 11:51:25,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.10501293
  0.19240709  0.0370118   0.66556823], sum to 1.0000
[2017-11-02 11:51:25,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.50833333333333, 67.25, 7.241666666666666, 263.3333333333333, 0.0, 0.0, -5.41666666666667, 24.57124157100174, 19.0, 20.28405050337471, 21.5, 0.0, 56.09030065668956], 
actual action is [-5.508333333333329, 24.0], 
sim time next is 277200.0000, 
raw observation next is [-10.6, 67.0, 7.2, 260.0, 0.0, 0.0, -5.508333333333329, 25.15971261710643, 24.0, 20.14708225365075, 21.5, 0.0, 39.48946438155416], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.06153846153846155, 0.67, 0.6545454545454545, 0.7222222222222222, 0.0, 0.0, 0.4081944444444445, 0.2515971261710643, 0.8571428571428571, 0.3067260362358216, 0.5, 0.0, 0.4645819339006371], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:29,540] A3C_AGENT_WORKER-Thread-11 INFO:Local step 52500, global step 843572: loss 215.1039
[2017-11-02 11:51:30,790] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.16750038e-06   4.42843558e-03   9.86390352e-01   2.39407062e-03
   6.78395294e-03   6.30226370e-27   2.82195204e-23   3.45405903e-24
   1.65872644e-21], sum to 1.0000
[2017-11-02 11:51:31,009] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.9, 78.0, 4.516666666666666, 188.3333333333333, 0.0, 0.0, -3.900000000000002, 20.15237775961458, 23.0, 20.74607308967605, 22.7, 1.0, 65.10591442288533], 
actual action is [-3.9000000000000004, 22.0], 
sim time next is 199800.0000, 
raw observation next is [-8.9, 78.0, 4.6, 190.0, 0.0, 0.0, -3.9, 20.05669500626322, 22.0, 20.81729137055054, 22.7, 1.0, 65.21850793225137], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.10512820512820512, 0.78, 0.41818181818181815, 0.5277777777777778, 0.0, 0.0, 0.435, 0.2005669500626322, 0.5714285714285714, 0.4024701957929341, 0.6714285714285714, 1.0, 0.7672765639088397], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:39,398] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0153735
  0.40857461  0.06726213  0.50878978], sum to 1.0000
[2017-11-02 11:51:39,504] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-10.96666666666667, 51.66666666666667, 5.433333333333334, 276.6666666666667, 0.0, 0.0, -15.875, 22.56030953513486, 18.0, 22.15278630635509, 22.7, 1.0, 0.0], 
actual action is [-5.96666666666667, 19.0], 
sim time next is 321900.0000, 
raw observation next is [-11.05833333333333, 52.33333333333333, 5.391666666666666, 275.8333333333333, 0.0, 0.0, -5.96666666666667, 21.66969110975113, 19.0, 21.84634181064618, 22.7, 1.0, 66.61574713705988], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.04978632478632487, 0.5233333333333333, 0.49015151515151506, 0.7662037037037036, 0.0, 0.0, 0.4005555555555555, 0.21669691109751132, 0.14285714285714285, 0.5494774015208829, 0.6714285714285714, 1.0, 0.7837146722007046], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:42,436] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.10641937e-04   3.23332213e-02   9.13498461e-01   3.59955393e-02
   1.80621725e-02   2.47615392e-24   2.62122691e-21   6.98339154e-22
   3.58123840e-19], sum to 1.0000
[2017-11-02 11:51:42,645] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-11.85, 64.0, 5.6, 255.0, 93.0, 415.25, -6.9, 16.58020041117765, 24.0, 21.72413672385242, 22.7, 1.0, 63.61692093247703], 
actual action is [-6.85, 22.0], 
sim time next is 294600.0000, 
raw observation next is [-11.8, 63.66666666666666, 5.6, 256.6666666666667, 92.33333333333334, 426.0, -6.85, 16.38596402174578, 22.0, 21.77471507155897, 22.7, 1.0, 63.54400775490641], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.03076923076923075, 0.6366666666666666, 0.509090909090909, 0.712962962962963, 0.24426807760141095, 0.426, 0.3858333333333333, 0.1638596402174578, 0.5714285714285714, 0.5392450102227099, 0.6714285714285714, 1.0, 0.7475765618224284], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:48,629] A3C_AGENT_WORKER-Thread-8 INFO:Local step 53000, global step 845408: loss -56.4748
[2017-11-02 11:51:49,626] A3C_AGENT_WORKER-Thread-16 INFO:Local step 53000, global step 845544: loss -90.6679
[2017-11-02 11:51:50,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   1.80164435e-19   2.21775911e-20   1.06717135e-17
   2.17433277e-20   5.60278189e-04   7.04846457e-02   9.80528723e-03
   9.19149816e-01], sum to 1.0000
[2017-11-02 11:51:50,380] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-12.46666666666667, 68.0, 5.766666666666667, 263.3333333333334, 0.0, 0.0, -7.425000000000001, 23.7964183193946, 24.5, 20.10658300262535, 22.7, 1.0, 67.2459163681704], 
actual action is [-7.46666666666667, 25], 
sim time next is 285900.0000, 
raw observation next is [-12.50833333333333, 68.25, 5.683333333333333, 261.6666666666666, 0.0, 0.0, -7.46666666666667, 23.671592786524, 25.0, 20.16223319512552, 22.7, 1.0, 66.98132819483267], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.01260683760683771, 0.6825, 0.5166666666666666, 0.7268518518518516, 0.0, 0.0, 0.37555555555555553, 0.23671592786523998, 1.0, 0.3088904564465028, 0.6714285714285714, 1.0, 0.7880156258215608], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:51,336] A3C_AGENT_WORKER-Thread-6 INFO:Local step 53000, global step 845754: loss -43.1959
[2017-11-02 11:51:52,046] A3C_AGENT_WORKER-Thread-10 INFO:Local step 53000, global step 845841: loss -1.4351
[2017-11-02 11:51:53,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.75895470e-05   2.97589898e-01   4.23089623e-01   2.70859450e-01
   8.42344668e-03   3.77801214e-30   5.66554856e-28   1.63434102e-28
   7.78506551e-26], sum to 1.0000
[2017-11-02 11:51:53,500] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.333333333333334, 69.0, 7.433333333333334, 288.3333333333334, 0.0, 0.0, -1.15, 24.91089974870023, 23.0, 20.43638511029427, 21.5, 0.0, 85.65537941962026], 
actual action is [-1.333333333333334, 23.0], 
sim time next is 262500.0000, 
raw observation next is [-6.516666666666667, 68.0, 7.566666666666667, 289.1666666666666, 0.0, 0.0, -1.333333333333334, 23.2025237397693, 23.0, 20.38137225916955, 21.5, 0.0, 61.08300884773018], 
processed observation next is [0.3333333333333333, 0.0, 0.16623931623931623, 0.68, 0.687878787878788, 0.8032407407407405, 0.0, 0.0, 0.47777777777777775, 0.232025237397693, 0.7142857142857143, 0.34019603702422124, 0.5, 0.0, 0.718623633502708], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:51:58,095] A3C_AGENT_WORKER-Thread-3 INFO:Local step 53000, global step 846597: loss 233.1008
[2017-11-02 11:51:59,848] A3C_AGENT_WORKER-Thread-7 INFO:Local step 53000, global step 846784: loss 21.9728
[2017-11-02 11:52:00,474] A3C_AGENT_WORKER-Thread-9 INFO:Local step 53000, global step 846837: loss -27.4877
[2017-11-02 11:52:07,373] A3C_AGENT_WORKER-Thread-17 INFO:Local step 53000, global step 847492: loss -48.5566
[2017-11-02 11:52:12,279] A3C_AGENT_WORKER-Thread-5 INFO:Local step 53000, global step 847942: loss -5.3771
[2017-11-02 11:52:12,560] A3C_AGENT_WORKER-Thread-4 INFO:Local step 53000, global step 847971: loss 167.5766
[2017-11-02 11:52:23,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.16113779e-06   1.59976305e-03   1.17535109e-03
   9.97223735e-01], sum to 1.0000
[2017-11-02 11:52:23,859] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 37.66666666666667, 5.766666666666667, 210.0, 26.33333333333333, 504.3333333333333, -13.9, 19.76772330702778, 18.0, 22.31018329912361, 22.7, 1.0, 0.0], 
actual action is [-3.9000000000000004, 23.0], 
sim time next is 404100.0000, 
raw observation next is [-8.9, 37.5, 5.6, 210.0, 25.0, 479.0, -3.9, 19.70147507373644, 23.0, 22.14614135188236, 22.7, 1.0, 55.33450434097584], 
processed observation next is [0.5, 0.6956521739130435, 0.10512820512820512, 0.375, 0.509090909090909, 0.5833333333333334, 0.06613756613756613, 0.479, 0.435, 0.1970147507373644, 0.7142857142857143, 0.5923059074117657, 0.6714285714285714, 1.0, 0.6509941687173628], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:52:26,422] A3C_AGENT_WORKER-Thread-2 INFO:Local step 53000, global step 849054: loss 100.8564
[2017-11-02 11:52:27,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.14305967e-05   2.70959758e-03   2.45899870e-03
   9.94820058e-01], sum to 1.0000
[2017-11-02 11:52:27,427] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-14.5, 66.0, 3.6, 220.0, 55.0, 733.5, -9.59166666666667, 25.5329577997045, 25.0, 20.73940131397353, 22.7, 1.0, 62.84110930920973], 
actual action is [-9.5, 25], 
sim time next is 381900.0000, 
raw observation next is [-14.40833333333333, 65.5, 3.766666666666667, 220.8333333333333, 57.66666666666667, 732.75, -9.5, 25.15267564295554, 25.0, 20.8080390992742, 22.7, 1.0, 62.68571202368607], 
processed observation next is [0.5, 0.43478260869565216, -0.03611111111111102, 0.655, 0.34242424242424246, 0.6134259259259258, 0.1525573192239859, 0.73275, 0.3416666666666667, 0.2515267564295554, 1.0, 0.4011484427534572, 0.6714285714285714, 1.0, 0.737478964984542], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:52:35,005] A3C_AGENT_WORKER-Thread-12 INFO:Local step 53000, global step 849663: loss 3.2373
[2017-11-02 11:52:39,265] A3C_AGENT_WORKER-Thread-15 INFO:Local step 53000, global step 850046: loss -5.8574
[2017-11-02 11:52:41,491] A3C_AGENT_WORKER-Thread-14 INFO:Local step 53000, global step 850273: loss -11.9577
[2017-11-02 11:52:43,750] A3C_AGENT_WORKER-Thread-13 INFO:Local step 53000, global step 850496: loss -25.3478
[2017-11-02 11:52:53,354] A3C_AGENT_WORKER-Thread-11 INFO:Local step 53000, global step 851440: loss 155.0240
[2017-11-02 11:53:06,970] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.19429233e-20   4.40346688e-01   5.21140337e-01   2.32125092e-02
   1.52584817e-02   8.38020060e-06   3.50836764e-08   5.87915736e-07
   3.29185350e-05], sum to 1.0000
[2017-11-02 11:53:07,561] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-8.4, 43.0, 4.1, 180.0, 0.0, 0.0, -3.491666666666667, 32.13372366859397, 25.0, 19.49057393892975, 21.5, 0.0, 47.37429930555645], 
actual action is [-3.4000000000000004, 23.0], 
sim time next is 457500.0000, 
raw observation next is [-8.35, 42.75, 4.183333333333333, 180.8333333333333, 0.0, 0.0, -3.4, 31.29581041278748, 23.0, 19.49924718695067, 22.7, 1.0, 75.55922553910159], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.11923076923076924, 0.4275, 0.38030303030303025, 0.5023148148148147, 0.0, 0.0, 0.44333333333333336, 0.3129581041278748, 0.7142857142857143, 0.21417816956438124, 0.6714285714285714, 1.0, 0.8889320651659011], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:53:12,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-105.59594727]
 [-104.05246735]
 [-102.11351776]
 [-102.50891113]
 [-104.24410248]], R is [[-105.57657623]
 [-105.52081299]
 [-105.46560669]
 [-105.41094971]
 [-105.35684204]].
[2017-11-02 11:53:15,982] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.47651572e-05   5.19914776e-02   9.11167979e-01   5.12152817e-03
   3.17042544e-02   3.46212851e-22   6.04716163e-21   2.79293850e-20
   2.39562755e-18], sum to 1.0000
[2017-11-02 11:53:16,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-10.16666666666667, 44.0, 6.300000000000001, 233.3333333333333, 49.16666666666666, 841.1666666666667, -5.25, 17.21019844196618, 22.0, 22.27308991244712, 22.7, 1.0, 61.58990991247096], 
actual action is [-5.16666666666667, 21.0], 
sim time next is 397500.0000, 
raw observation next is [-10.08333333333333, 43.5, 6.274999999999999, 234.1666666666667, 48.58333333333334, 836.5833333333334, -5.16666666666667, 17.2591405254378, 21.0, 22.31307976519937, 22.7, 1.0, 51.4435308860384], 
processed observation next is [0.5, 0.6086956521739131, 0.07478632478632487, 0.435, 0.5704545454545453, 0.6504629629629631, 0.12852733686067022, 0.8365833333333333, 0.4138888888888888, 0.172591405254378, 0.42857142857142855, 0.6161542521713385, 0.6714285714285714, 1.0, 0.6052180104239812], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:53:17,924] A3C_AGENT_WORKER-Thread-8 INFO:Local step 53500, global step 853434: loss -11.4532
[2017-11-02 11:53:18,917] A3C_AGENT_WORKER-Thread-10 INFO:Local step 53500, global step 853512: loss 0.1940
[2017-11-02 11:53:19,365] A3C_AGENT_WORKER-Thread-16 INFO:Local step 53500, global step 853550: loss -0.1213
[2017-11-02 11:53:23,071] A3C_AGENT_WORKER-Thread-6 INFO:Local step 53500, global step 853851: loss -9.1551
[2017-11-02 11:53:26,226] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.98087490e-06   1.02879472e-01   6.14863276e-01   2.79016960e-02
   2.54349530e-01   1.83828083e-19   6.52841855e-19   4.98826429e-18
   3.56841084e-16], sum to 1.0000
[2017-11-02 11:53:26,471] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.1, 96.0, 4.766666666666666, 123.3333333333333, 0.0, 0.0, 6.1, 14.21576901812347, 22.0, 22.77761248062509, 22.7, 1.0, 42.1340731847862], 
actual action is [6.1, 21.0], 
sim time next is 503700.0000, 
raw observation next is [1.1, 96.0, 4.683333333333333, 121.6666666666667, 0.0, 0.0, 6.1, 14.344366881172, 21.0, 22.83698929821424, 22.7, 1.0, 38.89039136460279], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.96, 0.4257575757575757, 0.3379629629629631, 0.0, 0.0, 0.6016666666666667, 0.14344366881172, 0.42857142857142855, 0.6909984711734631, 0.6714285714285714, 1.0, 0.4575340160541505], 
reward next is -0.4261. 
=============================================
[2017-11-02 11:53:29,936] A3C_AGENT_WORKER-Thread-7 INFO:Local step 53500, global step 854566: loss -45.5704
[2017-11-02 11:53:30,352] A3C_AGENT_WORKER-Thread-3 INFO:Local step 53500, global step 854609: loss -47.5392
[2017-11-02 11:53:31,777] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.40853441e-13   4.00809824e-01   2.91917294e-01   5.12567051e-02
   2.56001621e-01   4.25408544e-08   1.69629448e-08   1.30524199e-07
   1.43465622e-05], sum to 1.0000
[2017-11-02 11:53:31,997] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.1, 96.0, 4.766666666666666, 123.3333333333333, 0.0, 0.0, 6.1, 16.15802233435013, 24.5, 22.39778349270529, 22.7, 1.0, 50.40378316203747], 
actual action is [6.1, 23.5], 
sim time next is 503700.0000, 
raw observation next is [1.1, 96.0, 4.683333333333333, 121.6666666666667, 0.0, 0.0, 6.1, 15.33804358385234, 23.5, 22.40991183519277, 22.7, 1.0, 65.99501110694501], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.96, 0.4257575757575757, 0.3379629629629631, 0.0, 0.0, 0.6016666666666667, 0.1533804358385234, 0.7857142857142857, 0.6299874050275385, 0.6714285714285714, 1.0, 0.7764118953758237], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:53:34,187] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   7.44161093e-22   1.00652543e-21   2.38479705e-21
   1.81315102e-21   9.80540738e-03   1.27050676e-03   1.39993802e-02
   9.74924684e-01], sum to 1.0000
[2017-11-02 11:53:34,356] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.899999999999999, 40.5, 4.933333333333334, 188.3333333333333, 7.666666666666665, 0.0, -2.949999999999999, 27.17319991823554, 25.0, 20.41845733638405, 22.7, 1.0, 65.64863852317899], 
actual action is [-2.8999999999999986, 25], 
sim time next is 460500.0000, 
raw observation next is [-7.85, 40.25, 5.016666666666667, 189.1666666666667, 9.583333333333332, 0.0, -2.899999999999999, 27.0110785145605, 25.0, 20.45882024726804, 22.7, 1.0, 65.69130585658587], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.13205128205128205, 0.4025, 0.45606060606060606, 0.5254629629629631, 0.025352733686067018, 0.0, 0.4516666666666667, 0.270110785145605, 1.0, 0.35126003532400574, 0.6714285714285714, 1.0, 0.772838892430422], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:53:36,227] A3C_AGENT_WORKER-Thread-9 INFO:Local step 53500, global step 855334: loss 1.4468
[2017-11-02 11:53:40,860] A3C_AGENT_WORKER-Thread-17 INFO:Local step 53500, global step 855916: loss 3.3007
[2017-11-02 11:53:41,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.20957133e-09   3.01832501e-02   8.88568223e-01   1.36021664e-02
   6.76463991e-02   1.33067171e-15   5.06482673e-14   1.45726083e-13
   1.06117788e-10], sum to 1.0000
[2017-11-02 11:53:42,082] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 83.66666666666667, 6.183333333333333, 321.6666666666667, 81.0, 139.0, 4.4, 12.44481141114207, 21.0, 22.60560463373266, 22.7, 1.0, 43.07108068050645], 
actual action is [4.4, 20.0], 
sim time next is 557700.0000, 
raw observation next is [-0.6, 83.33333333333333, 6.141666666666666, 320.8333333333333, 82.0, 138.5, 4.4, 12.72504236868432, 20.0, 22.59626892577196, 22.7, 1.0, 37.33432645187451], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.317948717948718, 0.8333333333333333, 0.5583333333333332, 0.8912037037037036, 0.21693121693121692, 0.1385, 0.5733333333333334, 0.1272504236868432, 0.2857142857142857, 0.6566098465388512, 0.6714285714285714, 1.0, 0.4392273700220531], 
reward next is -0.4080. 
=============================================
[2017-11-02 11:53:43,261] A3C_AGENT_WORKER-Thread-5 INFO:Local step 53500, global step 856190: loss -32.9020
[2017-11-02 11:53:43,769] A3C_AGENT_WORKER-Thread-4 INFO:Local step 53500, global step 856251: loss -21.6410
[2017-11-02 11:53:57,953] A3C_AGENT_WORKER-Thread-2 INFO:Local step 53500, global step 857770: loss 10.6909
[2017-11-02 11:53:59,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  8.28109317e-11   4.34746891e-01   2.03575298e-01   2.59282529e-01
   1.02395333e-01   5.04410532e-12   7.34385914e-13   8.16421366e-13
   3.35238348e-09], sum to 1.0000
[2017-11-02 11:54:00,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  6.95693734e-06   7.14683652e-01   1.35934338e-01   1.05549634e-01
   4.38254215e-02   2.97669551e-19   2.86878179e-19   2.16996875e-19
   5.05838282e-16], sum to 1.0000
[2017-11-02 11:54:00,230] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-1.2, 80.0, 5.999999999999999, 315.0, 135.25, 563.0, 3.8, 10.27848372694428, 20.5, 23.61094404456168, 22.7, 1.0, 28.1741070613698], 
actual action is [3.8, 18.5], 
sim time next is 568200.0000, 
raw observation next is [-1.2, 80.0, 5.866666666666667, 313.3333333333334, 134.3333333333333, 552.3333333333333, 3.8, 10.55116238237915, 18.5, 23.53644781166984, 22.7, 1.0, 26.12122188302896], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.3025641025641026, 0.8, 0.5333333333333333, 0.8703703703703707, 0.35537918871252194, 0.5523333333333332, 0.5633333333333332, 0.1055116238237915, 0.07142857142857142, 0.7909211159528345, 0.6714285714285714, 1.0, 0.30730849274151717], 
reward next is -0.2871. 
=============================================
[2017-11-02 11:54:00,416] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 84.0, 5.85, 277.5, 0.0, 0.0, 2.2, 17.5840944784559, 21.5, 21.72019302101245, 21.5, 0.0, 27.78332758866556], 
actual action is [2.2, 20.5], 
sim time next is 593400.0000, 
raw observation next is [-2.8, 83.66666666666667, 5.933333333333333, 278.3333333333333, 0.0, 0.0, 2.2, 17.59115290680358, 20.5, 21.73321171223726, 21.5, 0.0, 24.3178049132806], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.2615384615384615, 0.8366666666666667, 0.5393939393939393, 0.7731481481481481, 0.0, 0.0, 0.5366666666666667, 0.17591152906803578, 0.35714285714285715, 0.5333159588910371, 0.5, 0.0, 0.2860918225091835], 
reward next is -0.2575. 
=============================================
[2017-11-02 11:54:02,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.55974643e-27   2.16449862e-08   2.59460942e-09   3.27449290e-09
   2.80099299e-09   1.15294545e-03   2.38548993e-04   7.35859736e-04
   9.97872591e-01], sum to 1.0000
[2017-11-02 11:54:02,425] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.283333333333333, 27.5, 2.766666666666667, 190.0, 125.6666666666667, 0.0, 3.675, 14.25446469294686, 25.0, 22.9616929584468, 22.7, 1.0, 60.96982390140514], 
actual action is [3.716666666666667, 25], 
sim time next is 478500.0000, 
raw observation next is [-1.241666666666667, 27.75, 2.633333333333333, 185.0, 124.8333333333333, 0.0, 3.716666666666667, 14.0263610269133, 25.0, 23.01462400591276, 22.7, 1.0, 60.49378392752914], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.3014957264957265, 0.2775, 0.23939393939393935, 0.5138888888888888, 0.3302469135802468, 0.0, 0.5619444444444445, 0.140263610269133, 1.0, 0.7163748579875373, 0.6714285714285714, 1.0, 0.7116915756179898], 
reward next is -0.6545. 
=============================================
[2017-11-02 11:54:07,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.35617491e-04   7.86417902e-01   8.38853717e-02   2.91942060e-02
   1.00367010e-01   4.91789812e-24   6.23542639e-24   1.35547382e-23
   8.34104373e-20], sum to 1.0000
[2017-11-02 11:54:08,017] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.383333333333333, 87.0, 5.183333333333334, 286.6666666666667, 0.0, 0.0, 2.658333333333334, 10.93741512548656, 22.0, 23.37007284814786, 22.7, 1.0, 37.28264458263632], 
actual action is [2.616666666666667, 20.0], 
sim time next is 584100.0000, 
raw observation next is [-2.425, 87.0, 5.225, 285.0, 0.0, 0.0, 2.616666666666667, 11.25069175168819, 20.0, 23.29958223994712, 22.7, 1.0, 32.04425032622954], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.27115384615384613, 0.87, 0.475, 0.7916666666666666, 0.0, 0.0, 0.5436111111111112, 0.11250691751688191, 0.2857142857142857, 0.7570831771353029, 0.6714285714285714, 1.0, 0.3769911803085828], 
reward next is -0.3505. 
=============================================
[2017-11-02 11:54:09,054] A3C_AGENT_WORKER-Thread-12 INFO:Local step 53500, global step 858990: loss -26.1730
[2017-11-02 11:54:11,764] A3C_AGENT_WORKER-Thread-14 INFO:Local step 53500, global step 859376: loss -82.5414
[2017-11-02 11:54:12,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.34000642e-04   9.17369366e-01   3.70844305e-02   9.20010917e-03
   3.62121053e-02   8.78562985e-35   7.10267149e-35   1.22610845e-34
   3.17868907e-30], sum to 1.0000
[2017-11-02 11:54:12,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.4, 83.0, 4.1, 260.0, 0.0, 0.0, -8.35, 25.23948230791926, 18.0, 21.13600129513573, 21.5, 0.0, 0.0], 
actual action is [-8.4, 18], 
sim time next is 601500.0000, 
raw observation next is [-3.399999999999999, 83.33333333333333, 4.141666666666666, 260.0, 0.0, 0.0, -8.4, 27.32186702185714, 18.0, 20.90148065313996, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.2461538461538462, 0.8333333333333333, 0.3765151515151514, 0.7222222222222222, 0.0, 0.0, 0.36000000000000004, 0.27321867021857144, 0.0, 0.41449723616285133, 0.5, 0.0, 0.0], 
reward next is -0.0855. 
=============================================
[2017-11-02 11:54:13,133] A3C_AGENT_WORKER-Thread-15 INFO:Local step 53500, global step 859577: loss -19.4121
[2017-11-02 11:54:14,365] A3C_AGENT_WORKER-Thread-13 INFO:Local step 53500, global step 859776: loss -1.1343
[2017-11-02 11:54:15,998] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-80.24382019]
 [-82.56263733]
 [-79.4355011 ]
 [-82.990448  ]
 [-82.54457092]], R is [[-81.39926147]
 [-81.58526611]
 [-81.76941681]
 [-81.95172119]
 [-82.13220215]].
[2017-11-02 11:54:19,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-68.59809875]
 [-67.49845886]
 [-69.08216858]
 [-68.71539307]
 [-71.05210876]], R is [[-68.13085175]
 [-67.44954681]
 [-67.12820435]
 [-66.90864563]
 [-66.92550659]].
[2017-11-02 11:54:21,481] A3C_AGENT_WORKER-Thread-16 INFO:Local step 54000, global step 860770: loss 24.2385
[2017-11-02 11:54:21,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-79.49925995]
 [-80.47171783]
 [-80.2647171 ]
 [-79.08085632]
 [-80.10734558]], R is [[-80.98865509]
 [-80.87635803]
 [-80.64555359]
 [-80.27832031]
 [-80.47554016]].
[2017-11-02 11:54:22,758] A3C_AGENT_WORKER-Thread-8 INFO:Local step 54000, global step 860925: loss 39.0657
[2017-11-02 11:54:24,419] A3C_AGENT_WORKER-Thread-11 INFO:Local step 53500, global step 861148: loss -148.3657
[2017-11-02 11:54:25,752] A3C_AGENT_WORKER-Thread-10 INFO:Local step 54000, global step 861293: loss 41.5807
[2017-11-02 11:54:28,929] A3C_AGENT_WORKER-Thread-6 INFO:Local step 54000, global step 861692: loss -13.9504
[2017-11-02 11:54:31,120] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  6.42778832e-06   9.97272074e-01   1.11700513e-03   5.80450404e-04
   1.02408347e-03   5.36300050e-29   1.42660612e-27   1.76565421e-26
   3.14452579e-24], sum to 1.0000
[2017-11-02 11:54:31,199] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.208333333333333, 59.08333333333333, 5.774999999999999, 250.8333333333333, 152.8333333333333, 95.91666666666666, 2.7, 15.72855207714477, 23.0, 22.21438999618163, 22.7, 1.0, 56.90075032402822], 
actual action is [2.791666666666667, 21.0], 
sim time next is 652200.0000, 
raw observation next is [-2.116666666666667, 59.16666666666667, 5.95, 251.6666666666667, 158.6666666666667, 95.33333333333334, 2.791666666666667, 15.12920925910236, 21.0, 22.24235566696186, 22.7, 1.0, 59.2377459373447], 
processed observation next is [1.0, 0.5652173913043478, 0.27905982905982907, 0.5916666666666667, 0.5409090909090909, 0.6990740740740742, 0.41975308641975323, 0.09533333333333334, 0.5465277777777777, 0.1512920925910236, 0.42857142857142855, 0.60605080956598, 0.6714285714285714, 1.0, 0.6969146580864082], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:54:32,169] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   7.92080886e-04   4.64249781e-04   2.28406396e-02
   9.75903034e-01], sum to 1.0000
[2017-11-02 11:54:32,232] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.6, 54.0, 8.2, 250.0, 55.0, 26.5, -5.6, 21.46210635344353, 18.0, 21.98801101439792, 22.7, 1.0, 0.0], 
actual action is [4.4, 23.0], 
sim time next is 662700.0000, 
raw observation next is [-0.6499999999999999, 54.25, 8.2, 250.8333333333333, 50.33333333333333, 24.58333333333333, 4.4, 19.62032516089579, 23.0, 21.74631717030707, 22.7, 1.0, 76.02022201073915], 
processed observation next is [1.0, 0.6956521739130435, 0.31666666666666665, 0.5425, 0.7454545454545454, 0.6967592592592591, 0.13315696649029982, 0.02458333333333333, 0.5733333333333334, 0.19620325160895788, 0.7142857142857143, 0.5351881671867241, 0.6714285714285714, 1.0, 0.8943555530675193], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:54:35,061] A3C_AGENT_WORKER-Thread-3 INFO:Local step 54000, global step 862378: loss 14.2164
[2017-11-02 11:54:35,363] A3C_AGENT_WORKER-Thread-7 INFO:Local step 54000, global step 862404: loss -37.8138
[2017-11-02 11:54:37,301] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-71.00920868]
 [-71.12686157]
 [-70.06728363]
 [-70.57093048]
 [-69.78595734]], R is [[-70.52380371]
 [-70.81856537]
 [-71.11038208]
 [-71.39927673]
 [-71.68528748]].
[2017-11-02 11:54:40,965] A3C_AGENT_WORKER-Thread-9 INFO:Local step 54000, global step 863110: loss 29.7771
[2017-11-02 11:54:42,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.67371543e-05   9.85481560e-01   2.16932711e-03   8.48536147e-04
   1.14738038e-02   1.53456924e-38   4.41783623e-37   1.60310822e-36
   2.20384216e-33], sum to 1.0000
[2017-11-02 11:54:42,351] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.899999999999999, 71.0, 2.958333333333333, 230.8333333333333, 0.0, 0.0, 1.1, 25.26882145871176, 21.0, 20.5942483883199, 21.5, 0.0, 26.74253271841939], 
actual action is [1.100000000000001, 19.0], 
sim time next is 688200.0000, 
raw observation next is [-3.9, 71.0, 2.916666666666667, 231.6666666666667, 0.0, 0.0, 1.100000000000001, 25.42113519703947, 19.0, 20.61089404974134, 21.5, 0.0, 24.97312359094953], 
processed observation next is [1.0, 1.0, 0.23333333333333334, 0.71, 0.2651515151515152, 0.6435185185185186, 0.0, 0.0, 0.5183333333333333, 0.2542113519703947, 0.14285714285714285, 0.37298486424876287, 0.5, 0.0, 0.29380145401117097], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:54:42,430] A3C_AGENT_WORKER-Thread-17 INFO:Local step 54000, global step 863312: loss 19.2340
[2017-11-02 11:54:43,342] A3C_AGENT_WORKER-Thread-4 INFO:Local step 54000, global step 863428: loss -31.6103
[2017-11-02 11:54:45,921] A3C_AGENT_WORKER-Thread-5 INFO:Local step 54000, global step 863729: loss -15.0134
[2017-11-02 11:54:46,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.03827858e-06   9.65638757e-01   5.53745450e-03   1.42126821e-03
   2.74014249e-02   1.23416270e-36   4.58544045e-34   9.28605364e-34
   1.20812748e-30], sum to 1.0000
[2017-11-02 11:54:46,534] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.2, 75.0, 4.766666666666667, 230.0, 0.0, 0.0, 1.75, 21.1696981876592, 23.0, 20.58794275913182, 21.5, 0.0, 48.21760867560731], 
actual action is [1.7999999999999998, 21.0], 
sim time next is 703500.0000, 
raw observation next is [-3.149999999999999, 75.0, 4.683333333333333, 232.5, 0.0, 0.0, 1.8, 20.38977212893803, 21.0, 20.70461183793895, 21.5, 0.0, 47.92420244616567], 
processed observation next is [0.0, 0.13043478260869565, 0.2525641025641026, 0.75, 0.4257575757575757, 0.6458333333333334, 0.0, 0.0, 0.53, 0.2038977212893803, 0.42857142857142855, 0.38637311970556404, 0.5, 0.0, 0.5638141464254784], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:54:58,561] A3C_AGENT_WORKER-Thread-2 INFO:Local step 54000, global step 865414: loss -22.4685
[2017-11-02 11:55:05,153] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-100.12517548]
 [-101.65462494]
 [ -99.43579102]
 [ -99.24916077]
 [-101.79357147]], R is [[-100.54748535]
 [-100.54201508]
 [-100.53659821]
 [-100.53123474]
 [-100.52592468]].
[2017-11-02 11:55:07,338] A3C_AGENT_WORKER-Thread-12 INFO:Local step 54000, global step 866464: loss -95.2145
[2017-11-02 11:55:10,245] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.09796942e-23   2.00036585e-01   5.45373245e-04   9.45540518e-02
   6.09167479e-03   4.39734977e-05   4.65515361e-04   6.20293955e-04
   6.97642505e-01], sum to 1.0000
[2017-11-02 11:55:10,354] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.35, 75.0, 8.325, 265.0, 0.0, 0.0, 0.7000000000000002, 24.16456589232233, 23.0, 20.24913767041413, 21.5, 0.0, 55.00680325413449], 
actual action is [0.6500000000000004, 25], 
sim time next is 618600.0000, 
raw observation next is [-4.399999999999999, 75.0, 8.45, 266.6666666666666, 0.0, 0.0, 0.6500000000000004, 23.78965717937047, 25.0, 20.21708531048022, 21.5, 0.0, 48.54435604932912], 
processed observation next is [1.0, 0.13043478260869565, 0.22051282051282056, 0.75, 0.7681818181818181, 0.7407407407407405, 0.0, 0.0, 0.5108333333333334, 0.2378965717937047, 1.0, 0.31672647292574546, 0.5, 0.0, 0.5711100711685778], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:55:11,308] A3C_AGENT_WORKER-Thread-14 INFO:Local step 54000, global step 866939: loss -39.2257
[2017-11-02 11:55:12,033] A3C_AGENT_WORKER-Thread-13 INFO:Local step 54000, global step 867023: loss 13.4651
[2017-11-02 11:55:12,753] A3C_AGENT_WORKER-Thread-15 INFO:Local step 54000, global step 867104: loss 40.5363
[2017-11-02 11:55:13,054] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.14900102e-07   5.37527323e-01   5.80161996e-02   3.66919935e-01
   3.75358872e-02   4.49397020e-30   1.88314868e-27   2.24244498e-27
   4.44734345e-23], sum to 1.0000
[2017-11-02 11:55:13,178] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.3, 76.0, 4.808333333333333, 255.8333333333333, 0.0, 0.0, 2.7, 20.84831436106947, 21.0, 20.2394159111087, 22.7, 1.0, 55.0881150947918], 
actual action is [2.7, 19.0], 
sim time next is 718800.0000, 
raw observation next is [-2.3, 76.0, 4.766666666666667, 256.6666666666666, 0.0, 0.0, 2.7, 20.57625935067286, 19.0, 20.4746632467559, 22.7, 1.0, 50.62287471762304], 
processed observation next is [0.0, 0.30434782608695654, 0.27435897435897433, 0.76, 0.43333333333333335, 0.7129629629629627, 0.0, 0.0, 0.545, 0.2057625935067286, 0.14285714285714285, 0.3535233209651284, 0.6714285714285714, 1.0, 0.5955632319720358], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:55:26,394] A3C_AGENT_WORKER-Thread-8 INFO:Local step 54500, global step 868661: loss -4.2310
[2017-11-02 11:55:26,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  4.47173854e-10   2.89017081e-01   3.25588067e-03   7.01916814e-01
   5.81026077e-03   2.14634770e-19   2.60459281e-18   1.84918873e-18
   3.12898164e-15], sum to 1.0000
[2017-11-02 11:55:26,698] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.299999999999999, 71.66666666666667, 3.5, 88.33333333333333, 0.0, 0.0, -2.3, 18.65500873720946, 22.0, 20.98981638891912, 21.5, 0.0, 45.90608911016172], 
actual action is [-2.299999999999999, 21.5], 
sim time next is 795300.0000, 
raw observation next is [-7.3, 71.33333333333333, 3.55, 89.16666666666667, 0.0, 0.0, -2.299999999999999, 18.62690611378654, 21.5, 20.99077592175345, 21.5, 0.0, 45.83471382177479], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.14615384615384616, 0.7133333333333333, 0.3227272727272727, 0.2476851851851852, 0.0, 0.0, 0.4616666666666667, 0.1862690611378654, 0.5, 0.42725370310763566, 0.5, 0.0, 0.5392319273149976], 
reward next is -0.5581. 
=============================================
[2017-11-02 11:55:27,656] A3C_AGENT_WORKER-Thread-10 INFO:Local step 54500, global step 868826: loss -36.0327
[2017-11-02 11:55:27,763] A3C_AGENT_WORKER-Thread-16 INFO:Local step 54500, global step 868842: loss -50.2853
[2017-11-02 11:55:28,581] A3C_AGENT_WORKER-Thread-11 INFO:Local step 54000, global step 868948: loss 4.6105
[2017-11-02 11:55:32,089] A3C_AGENT_WORKER-Thread-6 INFO:Local step 54500, global step 869339: loss -18.9435
[2017-11-02 11:55:38,498] A3C_AGENT_WORKER-Thread-3 INFO:Local step 54500, global step 870013: loss -7.8858
[2017-11-02 11:55:39,499] A3C_AGENT_WORKER-Thread-7 INFO:Local step 54500, global step 870126: loss -43.7496
[2017-11-02 11:55:45,611] A3C_AGENT_WORKER-Thread-9 INFO:Local step 54500, global step 870769: loss -105.3670
[2017-11-02 11:55:46,989] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  5.61840207e-05   8.58839214e-01   1.05949678e-02   1.29760340e-01
   7.49351806e-04   3.17294795e-31   8.60597944e-29   2.06113745e-29
   5.91708541e-26], sum to 1.0000
[2017-11-02 11:55:47,155] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.47997377e-05   8.95353317e-01   1.93427652e-02   8.41289088e-02
   1.15019421e-03   2.72291690e-36   1.82377122e-33   3.50481768e-34
   5.88321522e-31], sum to 1.0000
[2017-11-02 11:55:47,213] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.9, 82.5, 3.05, 85.0, 59.0, 0.0, 1.100000000000001, 15.1763841976149, 23.0, 22.3090929316295, 22.7, 1.0, 51.80458108860349], 
actual action is [1.1, 21.0], 
sim time next is 830100.0000, 
raw observation next is [-3.899999999999999, 83.08333333333334, 3.141666666666667, 84.16666666666667, 58.16666666666666, 0.0, 1.1, 14.73912688382272, 21.0, 22.31991987512516, 22.7, 1.0, 58.24100636655596], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.23333333333333336, 0.8308333333333334, 0.28560606060606064, 0.2337962962962963, 0.1538800705467372, 0.0, 0.5183333333333333, 0.1473912688382272, 0.42857142857142855, 0.6171314107321655, 0.6714285714285714, 1.0, 0.685188310194776], 
reward next is -0.6314. 
=============================================
[2017-11-02 11:55:47,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.325, 55.25, 6.499999999999999, 250.0, 119.25, 531.5, 4.583333333333333, 18.60550890458477, 21.0, 21.34118186383395, 22.7, 1.0, 31.60310326743814], 
actual action is [4.675, 19.0], 
sim time next is 735600.0000, 
raw observation next is [-0.2333333333333334, 54.66666666666667, 6.633333333333334, 250.0, 123.1666666666667, 504.0, 4.675, 18.40613975586648, 19.0, 21.4138596207528, 22.7, 1.0, 21.93671508659226], 
processed observation next is [0.0, 0.5217391304347826, 0.32735042735042735, 0.5466666666666667, 0.603030303030303, 0.6944444444444444, 0.3258377425044093, 0.504, 0.5779166666666666, 0.1840613975586648, 0.14285714285714285, 0.48769423153611413, 0.6714285714285714, 1.0, 0.2580790010187325], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:55:48,634] A3C_AGENT_WORKER-Thread-17 INFO:Local step 54500, global step 871110: loss -58.3404
[2017-11-02 11:55:50,130] A3C_AGENT_WORKER-Thread-5 INFO:Local step 54500, global step 871267: loss -58.1230
[2017-11-02 11:55:50,158] A3C_AGENT_WORKER-Thread-4 INFO:Local step 54500, global step 871271: loss 60.7801
[2017-11-02 11:56:01,277] A3C_AGENT_WORKER-Thread-2 INFO:Local step 54500, global step 872310: loss 8.9405
[2017-11-02 11:56:06,953] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.52163351e-12   4.23427284e-01   1.56815257e-02   5.59001863e-01
   1.86490652e-03   1.05430081e-06   1.26090902e-06   1.14863144e-06
   2.09333211e-05], sum to 1.0000
[2017-11-02 11:56:07,157] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.9, 82.66666666666667, 4.016666666666667, 80.0, 42.33333333333334, 0.0, 1.1, 10.89807299010328, 25.0, 23.27863470861906, 22.7, 1.0, 61.7902789632253], 
actual action is [1.1, 24.5], 
sim time next is 834900.0000, 
raw observation next is [-3.9, 82.33333333333333, 4.058333333333333, 80.0, 40.66666666666667, 0.0, 1.1, 10.77381605525528, 24.5, 23.32858349863184, 22.7, 1.0, 61.3103723894571], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.23333333333333334, 0.8233333333333333, 0.3689393939393939, 0.2222222222222222, 0.10758377425044093, 0.0, 0.5183333333333333, 0.1077381605525528, 0.9285714285714286, 0.7612262140902628, 0.6714285714285714, 1.0, 0.7212984986994952], 
reward next is -0.6599. 
=============================================
[2017-11-02 11:56:14,166] A3C_AGENT_WORKER-Thread-12 INFO:Local step 54500, global step 873570: loss -4.0190
[2017-11-02 11:56:15,672] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-39.41435623]
 [-39.52888107]
 [-40.42245865]
 [-41.62651825]
 [-40.38542938]], R is [[-40.16931152]
 [-40.22888184]
 [-40.28918457]
 [-40.35017395]
 [-40.41877747]].
[2017-11-02 11:56:20,602] A3C_AGENT_WORKER-Thread-15 INFO:Local step 54500, global step 874188: loss -31.2751
[2017-11-02 11:56:20,880] A3C_AGENT_WORKER-Thread-14 INFO:Local step 54500, global step 874217: loss -7.3983
[2017-11-02 11:56:26,485] A3C_AGENT_WORKER-Thread-13 INFO:Local step 54500, global step 874761: loss -58.3473
[2017-11-02 11:56:34,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.69728626e-03   6.25422448e-02   6.19705720e-03   9.24903870e-01
   4.65954747e-03   2.50923998e-18   1.24607042e-17   8.82302771e-18
   5.11320438e-16], sum to 1.0000
[2017-11-02 11:56:34,258] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.3, 71.0, 2.458333333333333, 40.0, 0.0, 0.0, -2.299999999999999, 15.41301619491978, 24.0, 21.6795437611486, 21.5, 0.0, 25.50135717137703], 
actual action is [-2.3, 23.5], 
sim time next is 781200.0000, 
raw observation next is [-7.3, 71.0, 2.5, 40.0, 0.0, 0.0, -2.3, 15.38157521592699, 23.5, 21.60942539702605, 21.5, 0.0, 39.11503776599223], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.14615384615384616, 0.71, 0.22727272727272727, 0.1111111111111111, 0.0, 0.0, 0.46166666666666667, 0.1538157521592699, 0.7857142857142857, 0.5156321995751502, 0.5, 0.0, 0.4601769148940262], 
reward next is -0.4142. 
=============================================
[2017-11-02 11:56:39,862] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.88381761
  0.00889669  0.0133384   0.09394736], sum to 1.0000
[2017-11-02 11:56:39,989] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 2.375, 90.0, 0.0, 0.0, -5.0, 30.61533063004045, 18.0, 19.78263691865232, 21.5, 0.0, 0.0], 
actual action is [5.0, 18.5], 
sim time next is 888600.0000, 
raw observation next is [0.0, 72.0, 2.416666666666667, 90.0, 0.0, 0.0, 5.0, 26.96876268147788, 18.5, 19.64180972330743, 21.5, 0.0, 71.75908948428277], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.3333333333333333, 0.72, 0.21969696969696972, 0.25, 0.0, 0.0, 0.5833333333333334, 0.2696876268147788, 0.07142857142857142, 0.2345442461867755, 0.5, 0.0, 0.8442245821680325], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:56:40,105] A3C_AGENT_WORKER-Thread-11 INFO:Local step 54500, global step 876449: loss -74.9902
[2017-11-02 11:56:40,397] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.45564914e-01   2.05054030e-01   1.52602438e-02   6.31649435e-01
   2.47132755e-03   2.99041977e-26   1.69439495e-25   6.03381279e-26
   2.33262442e-24], sum to 1.0000
[2017-11-02 11:56:40,520] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 100.0, 5.1, 113.3333333333333, 0.0, 0.0, 0.0, 12.8857031762354, 18.0, 22.53350455308017, 21.5, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 937500.0000, 
raw observation next is [5.0, 100.0, 5.1, 114.1666666666667, 0.0, 0.0, 0.0, 13.71120308148595, 18.0, 22.43486973404459, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.46153846153846156, 1.0, 0.4636363636363636, 0.3171296296296297, 0.0, 0.0, 0.5, 0.1371120308148595, 0.0, 0.6335528191492271, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:56:41,090] A3C_AGENT_WORKER-Thread-10 INFO:Local step 55000, global step 876587: loss 9.5255
[2017-11-02 11:56:42,548] A3C_AGENT_WORKER-Thread-8 INFO:Local step 55000, global step 876774: loss 3.0233
[2017-11-02 11:56:42,934] A3C_AGENT_WORKER-Thread-16 INFO:Local step 55000, global step 876812: loss 29.8895
[2017-11-02 11:56:43,870] A3C_AGENT_WORKER-Thread-6 INFO:Local step 55000, global step 876925: loss -1.8231
[2017-11-02 11:56:49,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.47960761e-01   4.35423791e-01   1.28844649e-01   1.85532749e-01
   2.23810342e-03   1.28989485e-27   1.58480215e-26   2.29352172e-26
   6.07384982e-25], sum to 1.0000
[2017-11-02 11:56:49,912] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.66666666666666, 4.266666666666667, 120.0, 0.0, 0.0, 0.0, 23.42952456301008, 18.0, 20.94092882520044, 21.5, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 942900.0000, 
raw observation next is [5.0, 96.33333333333334, 4.183333333333333, 120.0, 0.0, 0.0, 0.0, 23.78609299424281, 18.0, 20.87863155105535, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.46153846153846156, 0.9633333333333334, 0.38030303030303025, 0.3333333333333333, 0.0, 0.0, 0.5, 0.2378609299424281, 0.0, 0.4112330787221928, 0.5, 0.0, 0.0], 
reward next is -0.0888. 
=============================================
[2017-11-02 11:56:51,770] A3C_AGENT_WORKER-Thread-3 INFO:Local step 55000, global step 878203: loss 9.6156
[2017-11-02 11:56:54,149] A3C_AGENT_WORKER-Thread-7 INFO:Local step 55000, global step 878639: loss 103.2900
[2017-11-02 11:56:55,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 55000, global step 878831: loss 45.9991
[2017-11-02 11:56:57,984] A3C_AGENT_WORKER-Thread-17 INFO:Local step 55000, global step 879392: loss -122.7258
[2017-11-02 11:56:59,382] A3C_AGENT_WORKER-Thread-5 INFO:Local step 55000, global step 879656: loss 4.2440
[2017-11-02 11:56:59,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.29036811e-02   4.12106663e-02   7.23598480e-01   1.38472572e-01
   3.81451775e-03   4.34963526e-28   2.83527992e-27   1.16572909e-27
   2.53887610e-25], sum to 1.0000
[2017-11-02 11:56:59,841] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-0.6, 72.0, 3.0, 110.0, 0.0, 0.0, 4.35, 18.33211543414087, 22.0, 20.7913578069764, 21.5, 0.0, 45.94124497121362], 
actual action is [4.4, 21.5], 
sim time next is 882300.0000, 
raw observation next is [-0.5499999999999999, 72.0, 2.916666666666667, 108.3333333333333, 0.0, 0.0, 4.4, 17.65127436984092, 21.5, 20.9266684985324, 21.5, 0.0, 45.11038643375812], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.3192307692307692, 0.72, 0.2651515151515152, 0.3009259259259258, 0.0, 0.0, 0.5733333333333334, 0.1765127436984092, 0.5, 0.41809549979034294, 0.5, 0.0, 0.5307104286324485], 
reward next is -0.5595. 
=============================================
[2017-11-02 11:57:00,697] A3C_AGENT_WORKER-Thread-4 INFO:Local step 55000, global step 879899: loss 2.2384
[2017-11-02 11:57:03,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-30.08452034]
 [-29.17567635]
 [-29.48196411]
 [-31.60767174]
 [-31.6320591 ]], R is [[-30.82985497]
 [-31.04728508]
 [-31.28948593]
 [-31.54828453]
 [-31.76894951]].
[2017-11-02 11:57:06,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.36648107e-01   5.07005490e-02   6.37598559e-02   4.84526791e-02
   4.38779593e-04   1.42951946e-23   2.41195320e-22   1.55641878e-22
   2.18446331e-20], sum to 1.0000
[2017-11-02 11:57:06,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.675, 79.5, 7.575, 225.0, 66.25, 0.0, 9.58333333333333, 11.01693431129496, 18.0, 22.97861725169228, 22.7, 1.0, 0.0], 
actual action is [9.675, 18], 
sim time next is 1005600.0000, 
raw observation next is [14.76666666666667, 79.0, 7.533333333333333, 223.3333333333333, 63.16666666666666, 0.0, 9.675, 11.25680456220143, 18.0, 22.99474559236454, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.711965811965812, 0.79, 0.6848484848484848, 0.6203703703703702, 0.16710758377425042, 0.0, 0.66125, 0.11256804562201429, 0.0, 0.7135350846235059, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0113. 
=============================================
[2017-11-02 11:57:10,191] A3C_AGENT_WORKER-Thread-2 INFO:Local step 55000, global step 881778: loss 17.9471
[2017-11-02 11:57:14,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.07857451e-01   2.47833654e-01   2.12939709e-01   2.32969210e-01
   1.98399886e-01   9.47123091e-09   2.01432044e-08   8.37786818e-09
   1.64754361e-08], sum to 1.0000
[2017-11-02 11:57:14,592] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [19.4, 49.0, 3.7, 173.3333333333333, 82.5, 0.0, 14.4, 9.875666490547964, 18.0, 23.53810234029901, 21.5, 0.0, 0.0], 
actual action is [14.399999999999999, 18], 
sim time next is 1093500.0000, 
raw observation next is [19.4, 49.0, 3.525, 172.5, 77.75, 0.0, 14.4, 9.861560455084868, 18.0, 23.54187886427515, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.8307692307692307, 0.49, 0.32045454545454544, 0.4791666666666667, 0.2056878306878307, 0.0, 0.74, 0.09861560455084868, 0.0, 0.7916969806107359, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:15,033] A3C_AGENT_WORKER-Thread-16 INFO:Local step 55500, global step 883098: loss 46.0075
[2017-11-02 11:57:15,599] A3C_AGENT_WORKER-Thread-10 INFO:Local step 55500, global step 883260: loss -10.7759
[2017-11-02 11:57:15,613] A3C_AGENT_WORKER-Thread-8 INFO:Local step 55500, global step 883263: loss 30.8340
[2017-11-02 11:57:16,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.88634882e-03   1.34782037e-02   8.71434927e-01   1.02821574e-01
   1.03789773e-02   6.14995449e-24   3.16019224e-21   2.06757712e-21
   3.45932557e-17], sum to 1.0000
[2017-11-02 11:57:16,414] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [4.4, 93.0, 3.808333333333333, 145.8333333333333, 51.0, 0.0, 9.4, 15.03739710702146, 18.5, 22.14164278342419, 22.7, 1.0, 28.46883339239968], 
actual action is [-0.5999999999999996, 18], 
sim time next is 920400.0000, 
raw observation next is [4.4, 93.0, 3.766666666666667, 146.6666666666667, 48.0, 0.0, -0.5999999999999996, 15.95257128614417, 18.0, 22.16521036501786, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.4461538461538461, 0.93, 0.34242424242424246, 0.40740740740740755, 0.12698412698412698, 0.0, 0.49, 0.1595257128614417, 0.0, 0.5950300521454085, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:57:17,419] A3C_AGENT_WORKER-Thread-12 INFO:Local step 55000, global step 883717: loss -4.6900
[2017-11-02 11:57:17,884] A3C_AGENT_WORKER-Thread-6 INFO:Local step 55500, global step 883836: loss 128.4513
[2017-11-02 11:57:19,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.72245282e-01   1.43010557e-01   1.95776731e-01   1.47203878e-01
   1.41763464e-01   4.58625508e-20   3.39341489e-19   1.15864571e-19
   1.14386456e-17], sum to 1.0000
[2017-11-02 11:57:19,138] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.325, 65.5, 4.475, 130.0, 0.0, 0.0, 7.366666666666671, 17.197082140371, 18.0, 21.15164992622855, 21.5, 0.0, 0.0], 
actual action is [7.324999999999999, 18], 
sim time next is 1119000.0000, 
raw observation next is [12.28333333333333, 65.66666666666666, 4.516666666666666, 130.0, 0.0, 0.0, 7.324999999999999, 17.28459664925741, 18.0, 21.1357106211816, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.6482905982905982, 0.6566666666666666, 0.41060606060606053, 0.3611111111111111, 0.0, 0.0, 0.6220833333333334, 0.17284596649257408, 0.0, 0.44795866016880026, 0.5, 0.0, 0.0], 
reward next is -0.0520. 
=============================================
[2017-11-02 11:57:19,453] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  7.43643224e-01   4.87843603e-02   5.60922213e-02   9.03188363e-02
   6.11612909e-02   8.40097585e-22   1.37447109e-20   1.99406063e-21
   4.98983521e-19], sum to 1.0000
[2017-11-02 11:57:19,460] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 5.6, 180.0, 0.0, 0.0, 9.4, 14.92710052086607, 18.0, 22.3975908134469, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1029900.0000, 
raw observation next is [14.4, 75.0, 5.475, 180.0, 0.0, 0.0, 9.4, 15.02174343268571, 18.0, 22.38397905160338, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.7025641025641025, 0.75, 0.4977272727272727, 0.5, 0.0, 0.0, 0.6566666666666666, 0.1502174343268571, 0.0, 0.6262827216576257, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:20,327] A3C_AGENT_WORKER-Thread-14 INFO:Local step 55000, global step 884404: loss 165.8182
[2017-11-02 11:57:20,662] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  4.99273747e-01   1.22180656e-01   9.59270447e-02   1.92023665e-01
   9.05949101e-02   6.01055130e-15   5.12643144e-14   6.66374203e-15
   6.19092586e-14], sum to 1.0000
[2017-11-02 11:57:20,700] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.0, 77.0, 4.266666666666667, 186.6666666666667, 0.0, 0.0, 9.05, 17.05327297774317, 18.0, 21.72714981765461, 21.5, 0.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 1043100.0000, 
raw observation next is [13.95, 77.25, 4.225, 185.0, 0.0, 0.0, 9.0, 17.11182275791042, 18.0, 21.71665250510262, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.691025641025641, 0.7725, 0.38409090909090904, 0.5138888888888888, 0.0, 0.0, 0.65, 0.17111822757910422, 0.0, 0.5309503578718028, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:22,430] A3C_AGENT_WORKER-Thread-15 INFO:Local step 55000, global step 884936: loss -36.9326
[2017-11-02 11:57:23,932] A3C_AGENT_WORKER-Thread-13 INFO:Local step 55000, global step 885329: loss -47.1452
[2017-11-02 11:57:24,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 55500, global step 885414: loss -12.8909
[2017-11-02 11:57:25,291] A3C_AGENT_WORKER-Thread-9 INFO:Local step 55500, global step 885650: loss 2.8416
[2017-11-02 11:57:25,897] A3C_AGENT_WORKER-Thread-7 INFO:Local step 55500, global step 885803: loss -5.5901
[2017-11-02 11:57:28,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.13272242e-01   2.40599081e-01   1.77866742e-01   2.58059174e-01
   2.09594235e-01   1.41641547e-04   2.33072642e-04   9.88172615e-05
   1.35025446e-04], sum to 1.0000
[2017-11-02 11:57:28,310] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [18.675, 63.5, 9.825, 155.0, 168.25, 0.0, 13.71666666666667, 13.08321920623256, 18.0, 21.69806044555395, 21.5, 0.0, 0.0], 
actual action is [13.675, 18], 
sim time next is 1167600.0000, 
raw observation next is [18.63333333333333, 63.66666666666667, 9.866666666666667, 153.3333333333333, 169.1666666666667, 0.0, 13.675, 13.0299639480952, 18.0, 21.70770458658936, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.811111111111111, 0.6366666666666667, 0.896969696969697, 0.4259259259259258, 0.44753086419753096, 0.0, 0.7279166666666667, 0.130299639480952, 0.0, 0.5296720837984802, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:28,716] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  3.16800684e-01   3.36122930e-01   9.22787040e-02   1.79589987e-01
   7.52077326e-02   9.67294367e-16   1.54643466e-14   3.37299637e-15
   3.30320657e-14], sum to 1.0000
[2017-11-02 11:57:28,725] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.7, 84.0, 5.1, 120.0, 16.0, 0.5, 7.699999999999999, 17.69618329854996, 18.0, 21.38978356965914, 21.5, 0.0, 0.0], 
actual action is [7.699999999999999, 18], 
sim time next is 1152300.0000, 
raw observation next is [12.93333333333333, 83.25, 5.183333333333334, 121.6666666666667, 18.5, 0.4166666666666666, 7.699999999999999, 17.84394516729775, 18.0, 21.37342914299057, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.6649572649572649, 0.8325, 0.47121212121212125, 0.3379629629629631, 0.04894179894179894, 0.0004166666666666666, 0.6283333333333334, 0.1784394516729775, 0.0, 0.4819184489986529, 0.5, 0.0, 0.0], 
reward next is -0.0181. 
=============================================
[2017-11-02 11:57:29,451] A3C_AGENT_WORKER-Thread-17 INFO:Local step 55500, global step 886754: loss -9.6431
[2017-11-02 11:57:31,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.17570393e-01   2.82338113e-01   4.87896085e-01   9.93492305e-02
   1.28461989e-02   1.10795441e-21   9.79850883e-20   2.81383806e-20
   3.70684448e-19], sum to 1.0000
[2017-11-02 11:57:31,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [15.225, 76.5, 7.325, 215.0, 49.0, 0.0, 10.13333333333333, 13.880090102075, 18.0, 22.35258740198406, 22.7, 1.0, 0.0], 
actual action is [10.225, 18.0], 
sim time next is 1007400.0000, 
raw observation next is [15.31666666666667, 76.0, 7.283333333333333, 213.3333333333333, 46.33333333333334, 0.0, 10.225, 13.91000835545077, 18.0, 22.34599392501974, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.7260683760683762, 0.76, 0.6621212121212121, 0.5925925925925924, 0.12257495590828926, 0.0, 0.6704166666666667, 0.1391000835545077, 0.0, 0.6208562750028201, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 11:57:31,740] A3C_AGENT_WORKER-Thread-4 INFO:Local step 55500, global step 887330: loss 4.8790
[2017-11-02 11:57:31,742] A3C_AGENT_WORKER-Thread-5 INFO:Local step 55500, global step 887330: loss -6.1101
[2017-11-02 11:57:36,954] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-2.79938817]
 [-2.32791615]
 [-2.25731134]
 [-1.14051104]
 [-1.55238819]], R is [[-2.21937561]
 [-2.23501754]
 [-2.24775314]
 [-2.25766087]
 [-2.26481867]].
[2017-11-02 11:57:37,215] A3C_AGENT_WORKER-Thread-11 INFO:Local step 55000, global step 889051: loss 1.4704
[2017-11-02 11:57:39,092] A3C_AGENT_WORKER-Thread-2 INFO:Local step 55500, global step 889549: loss 17.6102
[2017-11-02 11:57:41,902] A3C_AGENT_WORKER-Thread-10 INFO:Local step 56000, global step 890418: loss 13.6728
[2017-11-02 11:57:42,174] A3C_AGENT_WORKER-Thread-16 INFO:Local step 56000, global step 890503: loss -0.7510
[2017-11-02 11:57:44,153] A3C_AGENT_WORKER-Thread-8 INFO:Local step 56000, global step 891072: loss 0.5742
[2017-11-02 11:57:46,038] A3C_AGENT_WORKER-Thread-6 INFO:Local step 56000, global step 891673: loss -22.1854
[2017-11-02 11:57:46,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.98686776e-02   2.45576784e-01   1.67149693e-01   2.42603734e-01
   2.44326532e-01   1.03668921e-04   1.77555034e-04   8.07132601e-05
   1.12591879e-04], sum to 1.0000
[2017-11-02 11:57:46,894] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [17.7, 67.0, 9.7, 120.0, 0.0, 0.0, 12.7, 12.21814127344544, 18.0, 21.99516291820556, 21.5, 0.0, 0.0], 
actual action is [12.7, 18], 
sim time next is 1199100.0000, 
raw observation next is [17.60833333333333, 67.66666666666666, 9.616666666666665, 120.0, 0.0, 0.0, 12.7, 12.21261718609683, 18.0, 21.9947178532555, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.7848290598290598, 0.6766666666666665, 0.8742424242424242, 0.3333333333333333, 0.0, 0.0, 0.7116666666666667, 0.1221261718609683, 0.0, 0.5706739790365002, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:47,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 55500, global step 892031: loss 1.2821
[2017-11-02 11:57:47,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.04898229e-01   2.46218681e-01   1.70304954e-01   2.46518493e-01
   2.31387526e-01   1.53534114e-04   2.45733187e-04   1.16614501e-04
   1.56330745e-04], sum to 1.0000
[2017-11-02 11:57:47,888] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [16.6, 75.0, 7.575, 135.0, 0.0, 0.0, 11.6, 12.51716261255155, 18.0, 21.85534636953819, 21.5, 0.0, 0.0], 
actual action is [11.600000000000001, 18], 
sim time next is 1205400.0000, 
raw observation next is [16.6, 75.0, 7.449999999999999, 136.6666666666667, 0.0, 0.0, 11.6, 12.52354706759791, 18.0, 21.84986437909597, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.758974358974359, 0.75, 0.6772727272727272, 0.37962962962962976, 0.0, 0.0, 0.6933333333333334, 0.1252354706759791, 0.0, 0.5499806255851384, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:57:47,979] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.31834108e-01   4.22412962e-01   8.64875168e-02   1.15264744e-01
   4.40006144e-02   2.10892436e-12   1.44994503e-11   3.02407665e-12
   4.97689043e-12], sum to 1.0000
[2017-11-02 11:57:48,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [5.85, 97.66666666666666, 5.683333333333333, 202.5, 0.0, 0.0, 0.9000000000000004, 22.0706042994312, 18.0, 19.73421399544173, 22.7, 1.0, 0.0], 
actual action is [0.8499999999999996, 18], 
sim time next is 1283400.0000, 
raw observation next is [5.8, 98.0, 5.6, 175.0, 0.0, 0.0, 0.8499999999999996, 22.29360919185143, 18.0, 19.71091916633898, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.8695652173913043, 0.48205128205128206, 0.98, 0.509090909090909, 0.4861111111111111, 0.0, 0.0, 0.5141666666666667, 0.2229360919185143, 0.0, 0.24441702376271124, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:57:48,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.41460964e-01   3.95051986e-01   1.20316871e-01   1.51700750e-01
   9.14694145e-02   1.87981186e-08   6.22937790e-08   1.68249592e-08
   1.32938069e-08], sum to 1.0000
[2017-11-02 11:57:48,409] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.04166666666667, 95.75, 7.983333333333333, 176.6666666666667, 0.0, 0.0, 10.08333333333333, 12.01407682968171, 18.0, 21.77390970497984, 22.7, 1.0, 0.0], 
actual action is [10.04166666666667, 18], 
sim time next is 1227600.0000, 
raw observation next is [15.0, 96.0, 8.2, 180.0, 0.0, 0.0, 10.04166666666667, 12.03522014046042, 18.0, 21.76572549812701, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.717948717948718, 0.96, 0.7454545454545454, 0.5, 0.0, 0.0, 0.6673611111111112, 0.1203522014046042, 0.0, 0.5379607854467159, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0120. 
=============================================
[2017-11-02 11:57:49,437] A3C_AGENT_WORKER-Thread-14 INFO:Local step 55500, global step 892798: loss -0.1640
[2017-11-02 11:57:50,357] A3C_AGENT_WORKER-Thread-9 INFO:Local step 56000, global step 893100: loss 9.8792
[2017-11-02 11:57:51,340] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.73734516e-01   5.58891237e-01   1.05758689e-01   1.20340548e-01
   4.12750132e-02   1.33786157e-12   1.16572524e-11   3.57059217e-12
   4.45399230e-12], sum to 1.0000
[2017-11-02 11:57:51,485] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [6.558333333333334, 96.0, 6.308333333333334, 335.8333333333334, 0.0, 0.0, 1.65, 15.64959337506914, 18.0, 21.4600045274648, 22.7, 1.0, 0.0], 
actual action is [1.5583333333333336, 18.0], 
sim time next is 1280400.0000, 
raw observation next is [6.466666666666667, 96.0, 6.266666666666667, 336.6666666666667, 0.0, 0.0, 1.558333333333334, 15.80508777681566, 18.0, 21.43572794444774, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.4991452991452992, 0.96, 0.5696969696969697, 0.9351851851851852, 0.0, 0.0, 0.5259722222222222, 0.1580508777681566, 0.0, 0.49081827777824877, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:57:51,563] A3C_AGENT_WORKER-Thread-3 INFO:Local step 56000, global step 893472: loss 1.8811
[2017-11-02 11:57:52,092] A3C_AGENT_WORKER-Thread-15 INFO:Local step 55500, global step 893629: loss 10.0205
[2017-11-02 11:57:52,294] A3C_AGENT_WORKER-Thread-13 INFO:Local step 55500, global step 893686: loss -0.0379
[2017-11-02 11:57:53,168] A3C_AGENT_WORKER-Thread-7 INFO:Local step 56000, global step 893960: loss 2.7126
[2017-11-02 11:57:55,376] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.97876934e-02   9.12516773e-01   4.41346541e-02   1.68593246e-02
   6.70147082e-03   8.04012359e-18   1.57177445e-16   8.80744329e-17
   1.81645326e-15], sum to 1.0000
[2017-11-02 11:57:55,401] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [11.1, 77.0, 5.6, 120.0, 0.0, 0.0, 6.1, 19.53055958205956, 18.0, 21.03336142103358, 22.7, 1.0, 0.0], 
actual action is [6.1, 18], 
sim time next is 1135800.0000, 
raw observation next is [11.1, 77.0, 5.6, 120.0, 0.0, 0.0, 6.1, 19.59773908486037, 18.0, 21.02608236736021, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.617948717948718, 0.77, 0.509090909090909, 0.3333333333333333, 0.0, 0.0, 0.6016666666666667, 0.1959773908486037, 0.0, 0.43229748105145865, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:57:55,946] A3C_AGENT_WORKER-Thread-17 INFO:Local step 56000, global step 894744: loss 0.0400
[2017-11-02 11:57:56,697] A3C_AGENT_WORKER-Thread-4 INFO:Local step 56000, global step 894975: loss -1.4382
[2017-11-02 11:57:57,961] A3C_AGENT_WORKER-Thread-5 INFO:Local step 56000, global step 895339: loss 17.7998
[2017-11-02 11:57:58,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-0.99858761]
 [-0.9625572 ]
 [-1.05121422]
 [-2.01322675]
 [-1.67452049]], R is [[-0.89239937]
 [-0.97316223]
 [-1.05288279]
 [-1.13131785]
 [-1.20838487]].
[2017-11-02 11:57:59,800] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-23.25799179]
 [-24.49788284]
 [-25.14630127]
 [-23.00170517]
 [-24.70344543]], R is [[-22.85389137]
 [-22.63665771]
 [-22.42157745]
 [-22.20863533]
 [-21.99781036]].
[2017-11-02 11:58:00,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.13492832e-02   9.02521193e-01   5.57320155e-02   1.38918590e-02
   1.65055525e-02   3.67233093e-21   1.50155680e-19   3.39955464e-20
   1.40989342e-19], sum to 1.0000
[2017-11-02 11:58:00,899] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [18.50833333333333, 64.16666666666666, 8.408333333333331, 144.1666666666667, 84.0, 0.0, 13.46666666666667, 12.51291583442517, 18.0, 22.28161177154356, 22.7, 1.0, 0.0], 
actual action is [13.50833333333333, 18], 
sim time next is 1179000.0000, 
raw observation next is [18.55, 64.0, 8.45, 145.0, 80.0, 0.0, 13.50833333333333, 12.48859164826094, 18.0, 22.283526277405, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.808974358974359, 0.64, 0.7681818181818181, 0.4027777777777778, 0.21164021164021163, 0.0, 0.7251388888888888, 0.1248859164826094, 0.0, 0.6119323253435712, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:58:02,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-40.94020462]
 [-41.36444092]
 [-41.07567215]
 [-41.09715652]
 [-35.7567749 ]], R is [[-38.10385895]
 [-38.72282028]
 [-39.33559418]
 [-39.94223785]
 [-40.54281616]].
[2017-11-02 11:58:02,524] A3C_AGENT_WORKER-Thread-2 INFO:Local step 56000, global step 896485: loss -0.1744
[2017-11-02 11:58:04,653] A3C_AGENT_WORKER-Thread-11 INFO:Local step 55500, global step 897028: loss -0.5648
[2017-11-02 11:58:14,924] A3C_AGENT_WORKER-Thread-12 INFO:Local step 56000, global step 899247: loss 4.6366
[2017-11-02 11:58:15,064] A3C_AGENT_WORKER-Thread-10 INFO:Local step 56500, global step 899284: loss -21.5118
[2017-11-02 11:58:16,263] A3C_AGENT_WORKER-Thread-14 INFO:Local step 56000, global step 899560: loss 13.5580
[2017-11-02 11:58:16,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.66741868e-03   5.21089613e-01   8.36547613e-02   3.52414727e-01
   4.01735343e-02   5.53178408e-21   3.43631247e-19   1.13837475e-19
   5.59044847e-18], sum to 1.0000
[2017-11-02 11:58:16,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.5, 96.0, 5.391666666666666, 280.0, 0.0, 0.0, 5.5, 13.04099438630622, 18.5, 21.89341018605325, 22.7, 1.0, 32.37266252975432], 
actual action is [-4.5, 18.0], 
sim time next is 1359600.0000, 
raw observation next is [0.5, 96.0, 5.433333333333334, 280.0, 0.0, 0.0, -4.5, 13.74702174368858, 18.0, 21.95048659472656, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.34615384615384615, 0.96, 0.49393939393939396, 0.7777777777777778, 0.0, 0.0, 0.425, 0.13747021743688578, 0.0, 0.5643552278180799, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0137. 
=============================================
[2017-11-02 11:58:18,466] A3C_AGENT_WORKER-Thread-8 INFO:Local step 56500, global step 900022: loss -2.8820
[2017-11-02 11:58:18,761] A3C_AGENT_WORKER-Thread-16 INFO:Local step 56500, global step 900077: loss 37.7091
[2017-11-02 11:58:21,128] A3C_AGENT_WORKER-Thread-6 INFO:Local step 56500, global step 900582: loss -1.7314
[2017-11-02 11:58:21,266] A3C_AGENT_WORKER-Thread-13 INFO:Local step 56000, global step 900613: loss -0.0018
[2017-11-02 11:58:21,870] A3C_AGENT_WORKER-Thread-15 INFO:Local step 56000, global step 900742: loss 0.5662
[2017-11-02 11:58:23,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.1343042   0.25934267  0.16738258  0.21620588  0.21801718  0.00126121
  0.00171066  0.00087173  0.00090388], sum to 1.0000
[2017-11-02 11:58:23,354] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [13.95, 99.0, 3.6, 340.0, 99.5, 0.0, 9.0, 13.53692502216759, 18.0, 21.18604089796851, 21.5, 0.0, 0.0], 
actual action is [8.95, 18], 
sim time next is 1255800.0000, 
raw observation next is [13.9, 99.33333333333334, 3.6, 340.0, 99.0, 0.0, 8.95, 13.55197671553103, 18.0, 21.18321057856651, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6897435897435897, 0.9933333333333334, 0.32727272727272727, 0.9444444444444444, 0.2619047619047619, 0.0, 0.6491666666666667, 0.1355197671553103, 0.0, 0.45474436836664417, 0.5, 0.0, 0.0], 
reward next is -0.0453. 
=============================================
[2017-11-02 11:58:25,842] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.40810071e-03   7.63673425e-01   8.11317861e-02   1.40397221e-01
   1.33894840e-02   2.99075608e-18   1.76272983e-16   5.03706836e-17
   3.06810347e-15], sum to 1.0000
[2017-11-02 11:58:25,902] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.5, 96.0, 6.433333333333333, 296.6666666666666, 0.0, 0.0, -4.5, 11.80193156965993, 18.0, 22.99071744948726, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 1364100.0000, 
raw observation next is [0.5, 96.0, 6.516666666666667, 298.3333333333334, 0.0, 0.0, -4.5, 12.9746833615604, 18.0, 22.72751537526497, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.34615384615384615, 0.96, 0.5924242424242424, 0.8287037037037039, 0.0, 0.0, 0.425, 0.129746833615604, 0.0, 0.6753593393235674, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 11:58:27,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  3.49852058e-09   8.58999908e-01   2.10090522e-02   1.14094950e-01
   5.73794916e-03   5.05637672e-07   1.96480323e-05   4.44211400e-06
   1.33615918e-04], sum to 1.0000
[2017-11-02 11:58:28,008] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.1, 92.0, 6.5, 283.3333333333333, 66.5, 0.0, -3.9, 11.15421949686354, 18.0, 22.90346980606764, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1349100.0000, 
raw observation next is [1.1, 92.0, 6.675000000000001, 285.0, 64.25, 0.0, -3.9, 11.55041943538003, 18.0, 22.82491734747277, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.36153846153846153, 0.92, 0.6068181818181819, 0.7916666666666666, 0.16997354497354497, 0.0, 0.435, 0.1155041943538003, 0.0, 0.6892739067818242, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0116. 
=============================================
[2017-11-02 11:58:28,491] A3C_AGENT_WORKER-Thread-9 INFO:Local step 56500, global step 901970: loss 29.5159
[2017-11-02 11:58:28,633] A3C_AGENT_WORKER-Thread-3 INFO:Local step 56500, global step 902001: loss 18.4281
[2017-11-02 11:58:32,196] A3C_AGENT_WORKER-Thread-7 INFO:Local step 56500, global step 902701: loss 10.5957
[2017-11-02 11:58:32,482] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-15.4991188 ]
 [-18.5340023 ]
 [-16.65736198]
 [-19.42290497]
 [-16.26793098]], R is [[-13.90484428]
 [-13.84768009]
 [-13.79020596]
 [-13.73237419]
 [-13.67413807]].
[2017-11-02 11:58:32,745] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.28624274e-03   9.03402984e-01   4.70888689e-02   3.75998504e-02
   1.06220441e-02   1.28438352e-27   1.01379424e-25   1.47907861e-26
   6.12628886e-25], sum to 1.0000
[2017-11-02 11:58:32,785] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.308333333333333, 90.75, 2.291666666666667, 58.33333333333333, 0.0, 0.0, -3.65, 14.47860884211681, 18.0, 21.83964308232818, 21.5, 0.0, 0.0], 
actual action is [-3.6916666666666673, 18], 
sim time next is 1460400.0000, 
raw observation next is [1.266666666666667, 91.0, 2.333333333333333, 56.66666666666666, 0.0, 0.0, -3.691666666666667, 15.36948589473437, 18.0, 21.76142824902594, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.36581196581196584, 0.91, 0.2121212121212121, 0.15740740740740738, 0.0, 0.0, 0.4384722222222222, 0.1536948589473437, 0.0, 0.5373468927179914, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:58:32,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00101053e-03   7.97190964e-01   1.08115487e-01   7.96512663e-02
   1.40412757e-02   4.04260417e-23   2.77029229e-21   6.61848695e-22
   4.28899642e-20], sum to 1.0000
[2017-11-02 11:58:32,845] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.0, 95.0, 3.808333333333333, 292.5, 0.0, 0.0, -5.0, 14.79200688472651, 18.0, 21.62394243749547, 21.5, 0.0, 0.0], 
actual action is [-5.0, 18], 
sim time next is 1388400.0000, 
raw observation next is [0.0, 95.0, 3.766666666666667, 290.0, 0.0, 0.0, -5.0, 16.30345663018804, 18.0, 21.5158122015878, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.3333333333333333, 0.95, 0.34242424242424246, 0.8055555555555556, 0.0, 0.0, 0.4166666666666667, 0.1630345663018804, 0.0, 0.5022588859411142, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:58:35,440] A3C_AGENT_WORKER-Thread-5 INFO:Local step 56500, global step 903269: loss -127.4466
[2017-11-02 11:58:35,945] A3C_AGENT_WORKER-Thread-17 INFO:Local step 56500, global step 903372: loss -5.6722
[2017-11-02 11:58:35,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 56000, global step 903372: loss -1.2355
[2017-11-02 11:58:36,059] A3C_AGENT_WORKER-Thread-4 INFO:Local step 56500, global step 903396: loss -39.3570
[2017-11-02 11:58:41,416] A3C_AGENT_WORKER-Thread-2 INFO:Local step 56500, global step 904402: loss -18.3906
[2017-11-02 11:58:43,142] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-26.41593742]
 [-25.4184761 ]
 [-27.06999397]
 [-26.07193565]
 [-27.78664017]], R is [[-27.42747498]
 [-27.80719566]
 [-27.70301628]
 [-27.67745972]
 [-27.89147949]].
[2017-11-02 11:58:44,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-32.11935806]
 [-32.42341232]
 [-32.06103897]
 [-32.90166473]
 [-32.55591965]], R is [[-32.64981079]
 [-33.32331467]
 [-33.99008179]
 [-34.65018082]
 [-35.30368042]].
[2017-11-02 11:58:47,500] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.72254653e-03   9.42026556e-01   3.44528705e-02   1.99812129e-02
   1.81681942e-03   6.72035023e-24   1.70367664e-22   6.20713626e-23
   8.09014547e-21], sum to 1.0000
[2017-11-02 11:58:47,546] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.375, 95.75, 5.6, 287.5, 0.0, 0.0, 5.416666666666667, 15.68961069462059, 21.0, 21.09575699486903, 21.5, 0.0, 49.5223672302946], 
actual action is [5.375, 19.0], 
sim time next is 1376400.0000, 
raw observation next is [0.3333333333333334, 95.66666666666666, 5.433333333333334, 290.0, 0.0, 0.0, 5.375, 14.81605352812664, 19.0, 21.17445130877376, 21.5, 0.0, 42.7439690061539], 
processed observation next is [0.0, 0.9565217391304348, 0.3418803418803419, 0.9566666666666666, 0.49393939393939396, 0.8055555555555556, 0.0, 0.0, 0.5895833333333333, 0.14816053528126638, 0.14285714285714285, 0.45349304411053737, 0.5, 0.0, 0.5028702236018106], 
reward next is -0.4991. 
=============================================
[2017-11-02 11:58:47,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  6.42326940e-03   9.41875219e-01   3.00537534e-02   1.88848022e-02
   2.76303524e-03   8.00459060e-20   2.19869446e-18   6.05489798e-19
   3.01737951e-17], sum to 1.0000
[2017-11-02 11:58:47,911] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-0.6, 100.0, 2.125, 105.0, 25.0, 0.0, -5.6, 12.01939594432235, 18.0, 22.2965047633154, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1414200.0000, 
raw observation next is [-0.6, 100.0, 2.083333333333333, 76.66666666666666, 27.33333333333333, 0.0, -5.6, 12.8732107598297, 18.0, 22.23195298791905, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 1.0, 0.18939393939393936, 0.21296296296296294, 0.07231040564373896, 0.0, 0.4066666666666666, 0.128732107598297, 0.0, 0.6045647125598644, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0129. 
=============================================
[2017-11-02 11:58:51,370] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.20558325e-04   9.01854217e-01   8.64955112e-02   1.05335228e-02
   9.96141229e-04   1.84811624e-28   2.67955496e-26   1.14060096e-26
   5.49117872e-24], sum to 1.0000
[2017-11-02 11:58:51,404] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.141666666666667, 91.75, 4.383333333333333, 88.33333333333333, 0.0, 0.0, -3.9, 17.72933633704411, 18.0, 21.61422740478681, 22.7, 1.0, 0.0], 
actual action is [-3.858333333333333, 18], 
sim time next is 1455000.0000, 
raw observation next is [1.183333333333333, 91.5, 4.166666666666666, 86.66666666666667, 0.0, 0.0, -3.858333333333333, 19.20618207209293, 18.0, 21.43006420738624, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.36367521367521366, 0.915, 0.37878787878787873, 0.24074074074074076, 0.0, 0.0, 0.43569444444444444, 0.19206182072092928, 0.0, 0.49000917248374876, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:58:52,015] A3C_AGENT_WORKER-Thread-12 INFO:Local step 56500, global step 906458: loss -8.2474
[2017-11-02 11:58:55,334] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57000, global step 907131: loss 2.9610
[2017-11-02 11:58:57,021] A3C_AGENT_WORKER-Thread-14 INFO:Local step 56500, global step 907473: loss -23.2038
[2017-11-02 11:58:59,030] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57000, global step 907847: loss 0.5168
[2017-11-02 11:58:59,322] A3C_AGENT_WORKER-Thread-8 INFO:Local step 57000, global step 907909: loss 13.5784
[2017-11-02 11:59:00,924] A3C_AGENT_WORKER-Thread-15 INFO:Local step 56500, global step 908250: loss -0.1916
[2017-11-02 11:59:02,071] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57000, global step 908462: loss 2.2045
[2017-11-02 11:59:02,353] A3C_AGENT_WORKER-Thread-13 INFO:Local step 56500, global step 908521: loss 0.1524
[2017-11-02 11:59:02,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.11074519e-29   9.99277809e-13   1.53080619e-13   3.34992044e-13
   3.17707625e-14   1.07632754e-02   1.97568592e-02   3.69783193e-02
   9.32501554e-01], sum to 1.0000
[2017-11-02 11:59:02,713] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [4.7, 82.5, 3.3, 95.0, 0.0, 0.0, -0.25, 19.37153862058284, 18.0, 20.97690722010724, 21.5, 0.0, 0.0], 
actual action is [9.7, 23.0], 
sim time next is 1564500.0000, 
raw observation next is [4.65, 83.08333333333334, 3.25, 94.16666666666666, 0.0, 0.0, 9.7, 15.6224978358156, 23.0, 20.87754123352227, 21.5, 0.0, 91.09911641263766], 
processed observation next is [0.5, 0.08695652173913043, 0.4525641025641025, 0.8308333333333334, 0.29545454545454547, 0.26157407407407407, 0.0, 0.0, 0.6616666666666667, 0.15622497835815602, 0.7142857142857143, 0.41107731907460987, 0.5, 0.0, 1.0717543107369136], 
reward next is -1.0535. 
=============================================
[2017-11-02 11:59:06,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57000, global step 909369: loss 0.5556
[2017-11-02 11:59:09,038] A3C_AGENT_WORKER-Thread-9 INFO:Local step 57000, global step 909904: loss -4.5644
[2017-11-02 11:59:09,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-27.20159721]
 [-27.52878952]
 [-27.36389923]
 [-27.32024002]
 [-27.06533051]], R is [[-27.90195274]
 [-28.62293434]
 [-29.33670616]
 [-30.04333878]
 [-29.84033394]].
[2017-11-02 11:59:11,554] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  6.39996007e-02   9.01462495e-01   1.88278202e-02   6.29576109e-03
   9.41421185e-03   2.95574773e-15   2.96649166e-14   2.44986967e-14
   1.15825725e-13], sum to 1.0000
[2017-11-02 11:59:11,570] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [12.15, 50.16666666666666, 2.5, 130.0, 81.16666666666667, 290.5000000000001, 7.1, 7.663305598046249, 18.0, 24.07310705320359, 22.7, 1.0, 0.0], 
actual action is [7.15, 18], 
sim time next is 1526400.0000, 
raw observation next is [12.2, 50.0, 2.5, 130.0, 82.0, 253.0, 7.15, 7.656915435406187, 18.0, 24.08606551185096, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.6461538461538462, 0.5, 0.22727272727272727, 0.3611111111111111, 0.21693121693121692, 0.253, 0.6191666666666666, 0.07656915435406188, 0.0, 0.8694379302644231, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0077. 
=============================================
[2017-11-02 11:59:12,740] A3C_AGENT_WORKER-Thread-7 INFO:Local step 57000, global step 910808: loss 3.4311
[2017-11-02 11:59:14,440] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57000, global step 911202: loss 0.9915
[2017-11-02 11:59:15,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.24488806e-02   9.04329836e-01   5.35783134e-02   8.36424902e-03
   1.12787094e-02   2.02689525e-18   1.51150515e-17   3.31394758e-17
   1.84819624e-15], sum to 1.0000
[2017-11-02 11:59:15,185] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.6, 92.0, 0.0, 0.0, 0.0, 0.0, 6.6, 14.53872166955044, 21.0, 21.50117400490211, 21.5, 0.0, 40.93657939501209], 
actual action is [6.6, 19.0], 
sim time next is 1465800.0000, 
raw observation next is [1.6, 92.0, 0.0, 0.0, 0.0, 0.0, 6.6, 13.87449806779018, 19.0, 21.60015982247705, 21.5, 0.0, 37.92019829983201], 
processed observation next is [0.16666666666666666, 1.0, 0.37435897435897436, 0.92, 0.0, 0.0, 0.0, 0.0, 0.61, 0.1387449806779018, 0.14285714285714285, 0.5143085460681499, 0.5, 0.0, 0.44611997999802366], 
reward next is -0.4015. 
=============================================
[2017-11-02 11:59:15,961] A3C_AGENT_WORKER-Thread-11 INFO:Local step 56500, global step 911528: loss -20.4786
[2017-11-02 11:59:16,721] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57000, global step 911677: loss 2.4531
[2017-11-02 11:59:17,398] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57000, global step 911813: loss 2.8998
[2017-11-02 11:59:21,199] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  4.31485823e-05   8.87774706e-01   6.88160136e-02   4.04425077e-02
   2.92321504e-03   3.96430444e-09   5.12408871e-09   1.17571082e-08
   4.31238561e-07], sum to 1.0000
[2017-11-02 11:59:21,242] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [4.45, 85.75, 2.95, 90.0, 0.0, 0.0, -0.5666666666666664, 20.77227979499638, 18.0, 20.37541507327978, 21.5, 0.0, 0.0], 
actual action is [-0.5499999999999998, 18], 
sim time next is 1567200.0000, 
raw observation next is [4.466666666666667, 85.66666666666667, 2.933333333333333, 90.0, 0.0, 0.0, -0.5499999999999998, 21.41117361700231, 18.0, 20.33012007947846, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.13043478260869565, 0.44786324786324794, 0.8566666666666667, 0.26666666666666666, 0.25, 0.0, 0.0, 0.49083333333333334, 0.21411173617002308, 0.0, 0.3328742970683512, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:59:22,276] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57000, global step 912917: loss -4.9686
[2017-11-02 11:59:25,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  7.75213058e-30   2.45150838e-15   1.29968375e-15   1.61526282e-15
   1.15522589e-16   6.18430413e-02   6.79837307e-03   1.99431498e-02
   9.11415398e-01], sum to 1.0000
[2017-11-02 11:59:25,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [2.2, 94.33333333333334, 2.1, 105.0, 0.0, 0.0, 7.2, 15.37850376627612, 22.0, 21.18079960260057, 21.5, 0.0, 34.03381715520281], 
actual action is [7.2, 25], 
sim time next is 1480500.0000, 
raw observation next is [2.2, 94.5, 2.25, 112.5, 0.0, 0.0, 7.2, 15.08747924377573, 25.0, 21.26610988303856, 21.5, 0.0, 25.05504268246668], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.38974358974358975, 0.945, 0.20454545454545456, 0.3125, 0.0, 0.0, 0.62, 0.1508747924377573, 1.0, 0.46658712614836567, 0.5, 0.0, 0.2947652080290198], 
reward next is -0.2987. 
=============================================
[2017-11-02 11:59:28,042] A3C_AGENT_WORKER-Thread-10 INFO:Local step 57500, global step 914217: loss 8.1755
[2017-11-02 11:59:28,673] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-13.32141876]
 [-11.97981262]
 [-12.93141937]
 [-11.8198452 ]
 [-11.73517799]], R is [[-12.34652901]
 [-12.23511219]
 [-12.12466431]
 [-12.01516628]
 [-11.90660191]].
[2017-11-02 11:59:28,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.95047794e-04   8.10553253e-01   1.58403993e-01   2.70840190e-02
   3.66363418e-03   1.01927022e-09   5.75048564e-10   7.70795705e-10
   3.83179319e-08], sum to 1.0000
[2017-11-02 11:59:28,919] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.6, 97.0, 4.891666666666667, 135.8333333333333, 0.0, 0.0, 1.6, 16.66924009211101, 18.0, 21.241629139426, 21.5, 0.0, 0.0], 
actual action is [1.5999999999999996, 18], 
sim time next is 1654800.0000, 
raw observation next is [6.6, 97.0, 4.933333333333333, 136.6666666666667, 0.0, 0.0, 1.6, 17.13683738010358, 18.0, 21.15722891532484, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5025641025641026, 0.97, 0.44848484848484843, 0.37962962962962976, 0.0, 0.0, 0.5266666666666667, 0.17136837380103578, 0.0, 0.45103270218926284, 0.5, 0.0, 0.0], 
reward next is -0.0490. 
=============================================
[2017-11-02 11:59:31,165] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57000, global step 914939: loss 0.1790
[2017-11-02 11:59:33,485] A3C_AGENT_WORKER-Thread-8 INFO:Local step 57500, global step 915493: loss 16.4351
[2017-11-02 11:59:34,155] A3C_AGENT_WORKER-Thread-16 INFO:Local step 57500, global step 915679: loss -3.4719
[2017-11-02 11:59:34,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.28577912e-01   7.58359015e-01   7.60148140e-03   4.35744459e-03
   1.10412412e-03   1.42675504e-13   6.62913572e-13   1.45041775e-13
   1.29266433e-12], sum to 1.0000
[2017-11-02 11:59:34,488] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [13.61666666666667, 49.66666666666666, 7.024999999999999, 136.6666666666667, 160.25, 72.33333333333334, 8.43333333333334, 9.018495857912313, 18.0, 23.3125973037587, 22.7, 1.0, 0.0], 
actual action is [8.61666666666667, 18], 
sim time next is 1602000.0000, 
raw observation next is [13.8, 49.0, 7.2, 140.0, 162.5, 62.0, 8.61666666666667, 9.008592720408933, 18.0, 23.30930284036263, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.6871794871794872, 0.49, 0.6545454545454545, 0.3888888888888889, 0.4298941798941799, 0.062, 0.6436111111111112, 0.09008592720408932, 0.0, 0.7584718343375185, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0090. 
=============================================
[2017-11-02 11:59:35,875] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57000, global step 916101: loss 0.1990
[2017-11-02 11:59:38,152] A3C_AGENT_WORKER-Thread-6 INFO:Local step 57500, global step 916596: loss 7.7493
[2017-11-02 11:59:38,224] A3C_AGENT_WORKER-Thread-3 INFO:Local step 57500, global step 916619: loss 34.4508
[2017-11-02 11:59:38,788] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.75331510e-13   3.48635425e-04   8.85349436e-07   4.39993664e-06
   1.03120378e-07   1.76522359e-02   5.16726524e-02   1.38702067e-02
   9.16450918e-01], sum to 1.0000
[2017-11-02 11:59:38,834] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.308333333333333, 85.08333333333334, 6.949999999999999, 210.0, 27.58333333333333, 0.0, -3.65, 13.77093906316028, 18.0, 22.06136606867943, 22.7, 1.0, 0.0], 
actual action is [6.308333333333333, 23.0], 
sim time next is 1701600.0000, 
raw observation next is [1.266666666666667, 85.66666666666667, 7.0, 210.0, 25.16666666666667, 0.0, 6.308333333333333, 13.21853366233379, 23.0, 22.01248149080873, 22.7, 1.0, 27.7254126559104], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.36581196581196584, 0.8566666666666667, 0.6363636363636364, 0.5833333333333334, 0.06657848324514992, 0.0, 0.6051388888888888, 0.1321853366233379, 0.7142857142857143, 0.5732116415441045, 0.6714285714285714, 1.0, 0.32618132536365174], 
reward next is -0.3068. 
=============================================
[2017-11-02 11:59:38,911] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57000, global step 916766: loss 0.7658
[2017-11-02 11:59:42,326] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57000, global step 917440: loss 0.1429
[2017-11-02 11:59:43,848] A3C_AGENT_WORKER-Thread-9 INFO:Local step 57500, global step 917725: loss 0.0167
[2017-11-02 11:59:46,712] A3C_AGENT_WORKER-Thread-7 INFO:Local step 57500, global step 918312: loss -1.3552
[2017-11-02 11:59:48,595] A3C_AGENT_WORKER-Thread-4 INFO:Local step 57500, global step 918665: loss 1.6711
[2017-11-02 11:59:52,275] A3C_AGENT_WORKER-Thread-5 INFO:Local step 57500, global step 919366: loss 38.6574
[2017-11-02 11:59:52,322] A3C_AGENT_WORKER-Thread-17 INFO:Local step 57500, global step 919369: loss -20.4288
[2017-11-02 11:59:54,557] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57000, global step 919788: loss -9.4859
[2017-11-02 11:59:55,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-38.08405685]
 [-38.17882156]
 [-37.90222931]
 [-37.79669189]
 [-36.51998901]], R is [[-37.04013824]
 [-37.17855453]
 [-37.4962883 ]
 [-37.97935486]
 [-37.64538956]].
[2017-11-02 11:59:55,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.20749706e-01   3.84882361e-01   3.74866724e-01   1.92406867e-02
   2.60466739e-04   3.54048077e-26   1.09926229e-24   2.91213279e-25
   4.40869697e-22], sum to 1.0000
[2017-11-02 11:59:55,804] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.1, 88.00000000000001, 7.283333333333333, 231.6666666666667, 0.0, 0.0, -3.9, 15.17172579140416, 18.0, 21.91475484774375, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1710900.0000, 
raw observation next is [1.1, 88.0, 7.325, 232.5, 0.0, 0.0, -3.9, 16.86368221239166, 18.0, 21.72722393225341, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.88, 0.6659090909090909, 0.6458333333333334, 0.0, 0.0, 0.435, 0.1686368221239166, 0.0, 0.5324605617504871, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:59:56,894] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-35.45404053]
 [-35.77593994]
 [-36.99293137]
 [-36.0748024 ]
 [-34.997509  ]], R is [[-34.93125916]
 [-35.34434128]
 [-35.99089813]
 [-36.63098907]
 [-37.26467896]].
[2017-11-02 11:59:57,235] A3C_AGENT_WORKER-Thread-2 INFO:Local step 57500, global step 920235: loss 40.6507
[2017-11-02 12:00:06,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-36.85613251]
 [-32.55333328]
 [-37.05544662]
 [-35.3562851 ]
 [-35.2183876 ]], R is [[-35.77648926]
 [-35.41872406]
 [-35.06453705]
 [-34.99487686]
 [-34.9443779 ]].
[2017-11-02 12:00:06,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  6.91464618e-02   1.80758938e-01   6.97204590e-01   4.95753475e-02
   3.31465830e-03   1.81483951e-21   6.46603207e-20   5.70993003e-21
   2.25631607e-19], sum to 1.0000
[2017-11-02 12:00:06,795] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.691666666666666, 75.33333333333333, 5.1, 129.1666666666667, 82.50000000000001, 93.91666666666667, 11.6, 10.81795013291648, 23.0, 21.69486317246051, 22.7, 1.0, 102.1804017122389], 
actual action is [11.691666666666666, 22.0], 
sim time next is 1588200.0000, 
raw observation next is [6.783333333333333, 74.66666666666667, 5.1, 128.3333333333333, 89.0, 102.3333333333333, 11.69166666666667, 8.88191452839418, 22.0, 21.97989563825987, 22.7, 1.0, 57.84723013922764], 
processed observation next is [0.5, 0.391304347826087, 0.5072649572649572, 0.7466666666666667, 0.4636363636363636, 0.35648148148148134, 0.23544973544973544, 0.1023333333333333, 0.6948611111111112, 0.0888191452839418, 0.5714285714285714, 0.5685565197514099, 0.6714285714285714, 1.0, 0.6805556486967957], 
reward next is -0.6214. 
=============================================
[2017-11-02 12:00:08,111] A3C_AGENT_WORKER-Thread-12 INFO:Local step 57500, global step 921900: loss 155.3301
[2017-11-02 12:00:12,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-32.04131317]
 [-34.59429932]
 [-32.5446434 ]
 [-31.8571434 ]
 [-32.53137207]], R is [[-31.43984222]
 [-31.13328934]
 [-30.82980919]
 [-30.52937317]
 [-30.23194885]].
[2017-11-02 12:00:14,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.24702418e-07   3.59188057e-02   9.27093506e-01   3.69573459e-02
   3.01262862e-05   2.18837042e-19   4.65769918e-17   1.44047289e-18
   1.64631092e-15], sum to 1.0000
[2017-11-02 12:00:14,219] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 82.0, 8.7, 245.0, 0.0, 0.0, 1.100000000000001, 12.63756307462329, 20.0, 22.68614535699337, 22.7, 1.0, 45.27393643394398], 
actual action is [1.1, 19.0], 
sim time next is 1791300.0000, 
raw observation next is [-3.899999999999999, 82.0, 8.7, 244.1666666666667, 0.0, 0.0, 1.1, 12.92688305354714, 19.0, 22.69528575018896, 22.7, 1.0, 42.29347532424133], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.23333333333333336, 0.82, 0.7909090909090909, 0.6782407407407409, 0.0, 0.0, 0.5183333333333333, 0.1292688305354714, 0.14285714285714285, 0.6707551071698516, 0.6714285714285714, 1.0, 0.49757029793225094], 
reward next is -0.4607. 
=============================================
[2017-11-02 12:00:14,352] A3C_AGENT_WORKER-Thread-14 INFO:Local step 57500, global step 922757: loss 0.2072
[2017-11-02 12:00:17,924] A3C_AGENT_WORKER-Thread-15 INFO:Local step 57500, global step 923267: loss -39.3978
[2017-11-02 12:00:18,187] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00578061e-13   1.68713368e-02   8.72121394e-01   1.10871024e-01
   1.36183735e-04   1.73158048e-12   9.04019012e-11   1.27935744e-11
   3.33634063e-08], sum to 1.0000
[2017-11-02 12:00:18,272] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.6, 78.0, 9.2, 250.0, 0.0, 0.0, -0.5499999999999998, 16.32088137856925, 23.0, 21.34900540714033, 21.5, 0.0, 49.44517291494043], 
actual action is [-0.5999999999999996, 22.5], 
sim time next is 1818300.0000, 
raw observation next is [-5.633333333333333, 78.41666666666667, 9.2, 250.0, 0.0, 0.0, -0.5999999999999996, 16.0933204196308, 22.5, 21.36052748558014, 21.5, 0.0, 49.81534531286606], 
processed observation next is [1.0, 0.043478260869565216, 0.1888888888888889, 0.7841666666666667, 0.8363636363636363, 0.6944444444444444, 0.0, 0.0, 0.49, 0.160933204196308, 0.6428571428571429, 0.480075355082877, 0.5, 0.0, 0.5860628860337184], 
reward next is -0.5474. 
=============================================
[2017-11-02 12:00:22,688] A3C_AGENT_WORKER-Thread-13 INFO:Local step 57500, global step 923938: loss -0.4358
[2017-11-02 12:00:25,370] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58000, global step 924241: loss -520.4502
[2017-11-02 12:00:28,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.11890214e-05   4.22158715e-04   7.35619469e-05
   9.99463141e-01], sum to 1.0000
[2017-11-02 12:00:28,610] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.3, 92.0, 7.7, 250.0, 15.5, 0.0, -1.558333333333333, 19.67246679792149, 18.0, 21.08267002531644, 22.7, 1.0, 0.0], 
actual action is [8.3, 23.0], 
sim time next is 1670700.0000, 
raw observation next is [3.208333333333333, 92.0, 7.658333333333333, 248.3333333333333, 17.91666666666667, 0.0, 8.3, 15.02142584456596, 23.0, 20.97956964758275, 22.7, 1.0, 110.3812454731868], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.41559829059829057, 0.92, 0.6962121212121212, 0.6898148148148147, 0.04739858906525574, 0.0, 0.6383333333333333, 0.15021425844565958, 0.7142857142857143, 0.4256528067975357, 0.6714285714285714, 1.0, 1.2986028879198446], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:00:29,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.39624215e-17   4.01791139e-03   8.96864057e-01   9.91136879e-02
   4.04909360e-06   1.81096390e-13   4.14202214e-11   4.78304722e-12
   3.07204289e-07], sum to 1.0000
[2017-11-02 12:00:29,495] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 75.0, 8.2, 250.0, 152.0, 66.0, -0.5999999999999996, 18.39853163745618, 23.0, 21.56863007479547, 22.7, 1.0, 86.26743829728424], 
actual action is [-0.5999999999999996, 22.0], 
sim time next is 1854300.0000, 
raw observation next is [-5.55, 74.66666666666667, 8.158333333333331, 249.1666666666667, 157.3333333333333, 68.5, -0.5999999999999996, 17.3486687453524, 22.0, 21.43643835788442, 22.7, 1.0, 70.63348563400434], 
processed observation next is [1.0, 0.4782608695652174, 0.19102564102564104, 0.7466666666666667, 0.7416666666666665, 0.6921296296296298, 0.41622574955908276, 0.0685, 0.49, 0.173486687453524, 0.5714285714285714, 0.49091976541205995, 0.6714285714285714, 1.0, 0.8309821839294629], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:00:31,542] A3C_AGENT_WORKER-Thread-8 INFO:Local step 58000, global step 924978: loss -48.7480
[2017-11-02 12:00:32,395] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.23023176e-06   2.72212434e-03   9.80746925e-01   1.65260918e-02
   3.64910829e-06   3.59501268e-30   5.46833671e-28   5.96216753e-29
   3.47838710e-24], sum to 1.0000
[2017-11-02 12:00:32,399] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58000, global step 925096: loss 12.4843
[2017-11-02 12:00:32,487] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.7, 78.0, 8.575, 240.0, 0.0, 0.0, -1.7, 19.68767095227404, 25.0, 20.37284896548798, 21.5, 0.0, 49.4137109701398], 
actual action is [-1.7000000000000002, 24.0], 
sim time next is 1840200.0000, 
raw observation next is [-6.700000000000001, 78.0, 8.45, 240.0, 0.0, 0.0, -1.7, 19.565160604777, 24.0, 20.3906377435188, 21.5, 0.0, 49.27403726231471], 
processed observation next is [1.0, 0.30434782608695654, 0.16153846153846152, 0.78, 0.7681818181818181, 0.6666666666666666, 0.0, 0.0, 0.4716666666666667, 0.19565160604777, 0.8571428571428571, 0.34151967764554264, 0.5, 0.0, 0.5796945560272319], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:00:36,077] A3C_AGENT_WORKER-Thread-11 INFO:Local step 57500, global step 925527: loss 1.0482
[2017-11-02 12:00:36,901] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58000, global step 925628: loss 49.3093
[2017-11-02 12:00:37,613] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58000, global step 925714: loss 72.7548
[2017-11-02 12:00:40,379] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  8.34848324e-04   6.46636356e-03   9.78920400e-01   1.37562975e-02
   2.20721231e-05   2.52891908e-37   6.91931045e-35   6.07154240e-36
   7.66778962e-32], sum to 1.0000
[2017-11-02 12:00:40,417] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.633333333333333, 78.41666666666667, 9.2, 250.0, 0.0, 0.0, -0.5999999999999996, 17.57226103977535, 19.0, 21.32497131229053, 21.5, 0.0, 35.46708257613286], 
actual action is [-10.633333333333333, 18.0], 
sim time next is 1818600.0000, 
raw observation next is [-5.666666666666667, 78.83333333333333, 9.2, 250.0, 0.0, 0.0, -10.63333333333333, 20.183678837342, 18.0, 21.28721729409365, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.18803418803418803, 0.7883333333333333, 0.8363636363636363, 0.6944444444444444, 0.0, 0.0, 0.32277777777777783, 0.20183678837342, 0.0, 0.46960247058480725, 0.5, 0.0, 0.0], 
reward next is -0.0304. 
=============================================
[2017-11-02 12:00:40,885] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  5.60752667e-10   5.93761168e-03   9.44487989e-01   4.95181717e-02
   5.62371424e-05   2.04851899e-18   1.19886396e-16   2.26542138e-17
   1.41229124e-13], sum to 1.0000
[2017-11-02 12:00:40,997] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.766666666666666, 80.08333333333333, 9.2, 250.0, 0.0, 0.0, -0.7333333333333334, 19.31423733946643, 24.0, 20.95539765070655, 21.5, 0.0, 52.81675658315995], 
actual action is [-0.7666666666666657, 23.5], 
sim time next is 1819800.0000, 
raw observation next is [-5.8, 80.5, 9.2, 250.0, 0.0, 0.0, -0.7666666666666657, 18.76364022004352, 23.5, 20.96655556871104, 21.5, 0.0, 52.0379696509255], 
processed observation next is [1.0, 0.043478260869565216, 0.18461538461538463, 0.805, 0.8363636363636363, 0.6944444444444444, 0.0, 0.0, 0.4872222222222222, 0.1876364022004352, 0.7857142857142857, 0.4237936526730058, 0.5, 0.0, 0.612211407657947], 
reward next is -0.6272. 
=============================================
[2017-11-02 12:00:43,097] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.20895757e-30   3.08484168e-13   1.94788310e-10   5.58725392e-11
   1.28442806e-14   5.75028480e-06   2.84414738e-04   5.29626195e-05
   9.99656916e-01], sum to 1.0000
[2017-11-02 12:00:43,229] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 88.0, 7.616666666666667, 238.3333333333333, 0.0, 0.0, 6.1, 13.03891519110305, 21.0, 21.81583499623192, 22.7, 1.0, 51.72738296903265], 
actual action is [6.1, 25], 
sim time next is 1713300.0000, 
raw observation next is [1.1, 88.0, 7.658333333333334, 239.1666666666667, 0.0, 0.0, 6.1, 12.73682627193031, 25.0, 21.89708985529216, 22.7, 1.0, 41.57364405441712], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.88, 0.6962121212121213, 0.664351851851852, 0.0, 0.0, 0.6016666666666667, 0.1273682627193031, 1.0, 0.5567271221845941, 0.6714285714285714, 1.0, 0.4891016947578485], 
reward next is -0.4529. 
=============================================
[2017-11-02 12:00:47,458] A3C_AGENT_WORKER-Thread-9 INFO:Local step 58000, global step 926718: loss -37.6038
[2017-11-02 12:00:48,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.13802054e-03   2.27603037e-02   9.48552668e-01   2.75111962e-02
   3.78420191e-05   3.87020287e-36   2.16838300e-33   3.49556020e-34
   1.69088208e-29], sum to 1.0000
[2017-11-02 12:00:48,321] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.466666666666667, 83.0, 9.366666666666667, 250.0, 124.8333333333333, 0.0, 2.575, 10.70141034345807, 23.0, 22.98460739659416, 22.7, 1.0, 57.83621108388944], 
actual action is [2.533333333333333, 22.0], 
sim time next is 1772700.0000, 
raw observation next is [-2.508333333333333, 83.0, 9.408333333333331, 250.0, 125.4166666666667, 0.0, 2.533333333333333, 10.76028154463507, 22.0, 22.98150376821635, 22.7, 1.0, 52.76889355965289], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.269017094017094, 0.83, 0.8553030303030301, 0.6944444444444444, 0.3317901234567902, 0.0, 0.5422222222222222, 0.1076028154463507, 0.5714285714285714, 0.7116433954594784, 0.6714285714285714, 1.0, 0.6208105124665045], 
reward next is -0.5695. 
=============================================
[2017-11-02 12:00:48,752] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58000, global step 926840: loss 23.8769
[2017-11-02 12:00:52,686] A3C_AGENT_WORKER-Thread-7 INFO:Local step 58000, global step 927215: loss 1.2896
[2017-11-02 12:00:55,051] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58000, global step 927450: loss 50.7484
[2017-11-02 12:00:57,619] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58000, global step 927708: loss -3.6464
[2017-11-02 12:00:58,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   8.80868286e-36   6.74369281e-33   2.48236407e-31
   2.65251620e-35   2.27094752e-05   3.15240701e-04   6.84591214e-05
   9.99593556e-01], sum to 1.0000
[2017-11-02 12:00:58,146] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.4, 78.0, 4.725, 249.1666666666667, 0.0, 0.0, -3.4, 17.46652110655572, 24.0, 21.08599856089925, 21.5, 0.0, 43.11106055685944], 
actual action is [-3.4000000000000004, 25], 
sim time next is 1912200.0000, 
raw observation next is [-8.4, 78.0, 4.85, 248.3333333333333, 0.0, 0.0, -3.4, 17.42652028671564, 25.0, 21.05825551486886, 21.5, 0.0, 47.24764477997027], 
processed observation next is [0.0, 0.13043478260869565, 0.11794871794871795, 0.78, 0.44090909090909086, 0.6898148148148147, 0.0, 0.0, 0.44333333333333336, 0.1742652028671564, 1.0, 0.43689364498126587, 0.5, 0.0, 0.5558546444702385], 
reward next is -0.5634. 
=============================================
[2017-11-02 12:01:03,676] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58000, global step 928328: loss 21.4660
[2017-11-02 12:01:19,275] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58000, global step 930129: loss 5.9196
[2017-11-02 12:01:23,544] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58000, global step 930549: loss -30.3940
[2017-11-02 12:01:25,202] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58000, global step 930729: loss 24.3159
[2017-11-02 12:01:25,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   1.78835102e-28   1.10088998e-26   7.45394768e-25
   6.16392739e-26   2.97122006e-06   3.64461506e-04   2.79152533e-04
   9.99353468e-01], sum to 1.0000
[2017-11-02 12:01:25,729] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 84.33333333333333, 7.783333333333332, 250.0, 0.0, 0.0, 0.0, 17.13624636024062, 25.0, 21.37150853448095, 21.5, 0.0, 35.06716590615857], 
actual action is [0.0, 25], 
sim time next is 1809000.0000, 
raw observation next is [-5.0, 84.0, 7.699999999999999, 250.0, 0.0, 0.0, 0.0, 16.82804418871413, 25.0, 21.41826939178217, 21.5, 0.0, 43.52886561554354], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.20512820512820512, 0.84, 0.7, 0.6944444444444444, 0.0, 0.0, 0.5, 0.1682804418871413, 1.0, 0.4883241988260245, 0.5, 0.0, 0.5121043013593357], 
reward next is -0.4726. 
=============================================
[2017-11-02 12:01:29,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.85140496e-04   6.38264045e-03   6.98561408e-03
   9.86446619e-01], sum to 1.0000
[2017-11-02 12:01:29,733] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-9.2, 88.5, 3.85, 220.0, 33.0, 21.0, -4.25, 13.38640562265289, 25.0, 21.86489996226076, 22.7, 1.0, 63.58906470848337], 
actual action is [-4.199999999999999, 25], 
sim time next is 1931700.0000, 
raw observation next is [-9.15, 88.08333333333334, 3.808333333333333, 220.0, 37.33333333333334, 65.00000000000003, -4.199999999999999, 13.03555254042289, 25.0, 21.93632640390681, 22.7, 1.0, 63.44730874438318], 
processed observation next is [0.0, 0.34782608695652173, 0.09871794871794871, 0.8808333333333335, 0.3462121212121212, 0.6111111111111112, 0.09876543209876545, 0.06500000000000003, 0.43, 0.1303555254042289, 1.0, 0.5623323434152587, 0.6714285714285714, 1.0, 0.7464389264045079], 
reward next is -0.6848. 
=============================================
[2017-11-02 12:01:32,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58000, global step 931539: loss 30.5241
[2017-11-02 12:01:35,984] A3C_AGENT_WORKER-Thread-10 INFO:Local step 58500, global step 931908: loss 21.7016
[2017-11-02 12:01:40,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.12355322
  0.03602633  0.02166515  0.81875527], sum to 1.0000
[2017-11-02 12:01:40,290] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.35, 89.75, 3.975, 220.0, 25.25, 16.0, -4.4, 14.48277882661824, 25.0, 21.56367930030554, 22.7, 1.0, 63.8971767747], 
actual action is [-4.35, 25], 
sim time next is 1930800.0000, 
raw observation next is [-9.3, 89.33333333333334, 3.933333333333334, 220.0, 27.83333333333333, 17.66666666666667, -4.35, 14.06382554508469, 25.0, 21.68108756086334, 22.7, 1.0, 63.82888695091015], 
processed observation next is [0.0, 0.34782608695652173, 0.09487179487179485, 0.8933333333333334, 0.35757575757575766, 0.6111111111111112, 0.07363315696649028, 0.01766666666666667, 0.4275, 0.1406382554508469, 1.0, 0.5258696515519057, 0.6714285714285714, 1.0, 0.7509280817754136], 
reward next is -0.6899. 
=============================================
[2017-11-02 12:01:42,615] A3C_AGENT_WORKER-Thread-8 INFO:Local step 58500, global step 932581: loss 8.2530
[2017-11-02 12:01:44,664] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58000, global step 932843: loss -2.7214
[2017-11-02 12:01:45,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.01593607e-05   3.49566758e-01   1.99773714e-01   2.55592465e-01
   1.95026875e-01   9.20678259e-20   9.50393611e-19   8.12071590e-19
   4.19191146e-17], sum to 1.0000
[2017-11-02 12:01:45,411] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 81.0, 6.1, 240.0, 100.5, 21.0, 0.5, 13.16377696453513, 18.5, 22.63500590853669, 22.7, 1.0, 37.59750037445563], 
actual action is [-9.5, 18], 
sim time next is 1869600.0000, 
raw observation next is [-4.5, 80.33333333333334, 6.100000000000001, 240.0, 91.0, 14.0, -9.5, 14.95884002399103, 18.0, 22.60110597944164, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.21794871794871795, 0.8033333333333335, 0.5545454545454547, 0.6666666666666666, 0.24074074074074073, 0.014, 0.3416666666666667, 0.1495884002399103, 0.0, 0.6573008542059487, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0150. 
=============================================
[2017-11-02 12:01:47,613] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-61.91314316]
 [-62.34181213]
 [-62.85248566]
 [-63.19924164]
 [-62.34034348]], R is [[-62.97676086]
 [-62.81351852]
 [-62.69231796]
 [-62.56087875]
 [-61.94260025]].
[2017-11-02 12:01:48,366] A3C_AGENT_WORKER-Thread-16 INFO:Local step 58500, global step 933284: loss 20.2030
[2017-11-02 12:01:49,507] A3C_AGENT_WORKER-Thread-3 INFO:Local step 58500, global step 933412: loss -5.3497
[2017-11-02 12:01:49,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.35583410e-01   6.09157741e-01   1.90682951e-02   6.14293553e-02
   7.47611895e-02   9.08619329e-31   3.63523129e-29   9.98711887e-30
   2.61603398e-28], sum to 1.0000
[2017-11-02 12:01:49,962] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.291666666666667, 75.33333333333333, 6.516666666666667, 259.1666666666666, 0.0, 0.0, -1.2, 14.75407859813372, 22.5, 21.93628819512007, 21.5, 0.0, 47.64457736504306], 
actual action is [-1.291666666666667, 22.5], 
sim time next is 1894200.0000, 
raw observation next is [-6.383333333333334, 75.66666666666667, 6.433333333333334, 258.3333333333334, 0.0, 0.0, -1.291666666666667, 14.79218156086004, 22.5, 21.96412337774153, 21.5, 0.0, 41.81804117682179], 
processed observation next is [1.0, 0.9565217391304348, 0.16965811965811964, 0.7566666666666667, 0.5848484848484848, 0.7175925925925929, 0.0, 0.0, 0.4784722222222222, 0.1479218156086004, 0.6428571428571429, 0.5663033396773614, 0.5, 0.0, 0.4919769550214328], 
reward next is -0.4428. 
=============================================
[2017-11-02 12:01:50,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.33171621e-15   1.21560565e-03   1.19053431e-04   3.22643435e-03
   8.47387302e-04   1.45377498e-02   3.40901971e-01   9.41924527e-02
   5.44959307e-01], sum to 1.0000
[2017-11-02 12:01:50,993] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.7, 78.83333333333333, 4.516666666666667, 253.3333333333333, 0.0, 0.0, -0.6499999999999986, 14.55909099739427, 18.5, 21.60681588323028, 21.5, 0.0, 49.53652169181574], 
actual action is [-0.7000000000000002, 19.5], 
sim time next is 1977300.0000, 
raw observation next is [-5.749999999999999, 79.25, 4.475, 255.0, 0.0, 0.0, -0.7000000000000002, 14.23470139930268, 19.5, 21.66299137136928, 21.5, 0.0, 40.94718100173868], 
processed observation next is [0.0, 0.9130434782608695, 0.18589743589743593, 0.7925, 0.4068181818181818, 0.7083333333333334, 0.0, 0.0, 0.48833333333333334, 0.1423470139930268, 0.21428571428571427, 0.5232844816241828, 0.5, 0.0, 0.48173154119692563], 
reward next is -0.4336. 
=============================================
[2017-11-02 12:01:52,006] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.20170692e-01   3.58705312e-01   7.40139857e-02   2.61283666e-01
   8.58262926e-02   2.55778802e-31   5.04915276e-29   1.23685719e-29
   2.68993600e-28], sum to 1.0000
[2017-11-02 12:01:52,065] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.6, 83.0, 2.958333333333333, 260.0, 0.0, 0.0, -10.6, 15.13052147909147, 18.0, 21.66180733255639, 21.5, 0.0, 0.0], 
actual action is [-10.6, 18], 
sim time next is 1996800.0000, 
raw observation next is [-5.6, 83.0, 2.866666666666667, 260.0, 0.0, 0.0, -10.6, 17.38909530102828, 18.0, 21.521537140054, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.18974358974358976, 0.83, 0.2606060606060607, 0.7222222222222222, 0.0, 0.0, 0.3233333333333333, 0.17389095301028282, 0.0, 0.5030767342934287, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 12:01:52,655] A3C_AGENT_WORKER-Thread-6 INFO:Local step 58500, global step 933831: loss 61.4503
[2017-11-02 12:01:57,041] A3C_AGENT_WORKER-Thread-9 INFO:Local step 58500, global step 934407: loss 11.8118
[2017-11-02 12:02:01,382] A3C_AGENT_WORKER-Thread-4 INFO:Local step 58500, global step 934947: loss 51.7604
[2017-11-02 12:02:05,164] A3C_AGENT_WORKER-Thread-5 INFO:Local step 58500, global step 935412: loss 22.7885
[2017-11-02 12:02:05,706] A3C_AGENT_WORKER-Thread-7 INFO:Local step 58500, global step 935480: loss -7.1429
[2017-11-02 12:02:06,991] A3C_AGENT_WORKER-Thread-17 INFO:Local step 58500, global step 935638: loss -33.6770
[2017-11-02 12:02:09,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.26558555e-13   8.61640722e-02   3.10365502e-02   2.45751701e-02
   3.40849012e-02   1.66665495e-03   4.83130142e-02   1.02685235e-01
   6.71474397e-01], sum to 1.0000
[2017-11-02 12:02:09,027] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.25, 84.33333333333333, 5.516666666666666, 258.3333333333333, 73.75, 0.0, -9.3, 13.66792009889633, 18.0, 22.42827089326135, 22.7, 1.0, 0.0], 
actual action is [-9.25, 18], 
sim time next is 2043000.0000, 
raw observation next is [-4.2, 84.0, 5.6, 260.0, 71.0, 0.0, -9.25, 14.60600847626661, 18.0, 22.38060876395716, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.22564102564102567, 0.84, 0.509090909090909, 0.7222222222222222, 0.18783068783068782, 0.0, 0.3458333333333333, 0.1460600847626661, 0.0, 0.6258012519938799, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 12:02:13,200] A3C_AGENT_WORKER-Thread-2 INFO:Local step 58500, global step 936441: loss 16.7248
[2017-11-02 12:02:13,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  7.07937684e-03   3.00050586e-01   5.95121443e-01   1.39634917e-02
   8.37851018e-02   2.30216809e-36   9.43415583e-34   4.77837214e-34
   3.53690146e-32], sum to 1.0000
[2017-11-02 12:02:13,445] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-5.6, 91.0, 5.1, 240.0, 0.0, 0.0, -0.5499999999999998, 15.30531976179945, 22.0, 21.17444601486452, 21.5, 0.0, 48.71094685029531], 
actual action is [-0.5999999999999996, 20.0], 
sim time next is 2088300.0000, 
raw observation next is [-5.649999999999999, 90.66666666666666, 5.058333333333334, 240.0, 0.0, 0.0, -0.5999999999999996, 15.24349693843207, 20.0, 21.19828011970052, 21.5, 0.0, 40.92586786851028], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.18846153846153849, 0.9066666666666666, 0.4598484848484849, 0.6666666666666666, 0.0, 0.0, 0.49, 0.1524349693843207, 0.2857142857142857, 0.4568971599572172, 0.5, 0.0, 0.48148079845306213], 
reward next is -0.4764. 
=============================================
[2017-11-02 12:02:16,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.40382863e-13   1.87645763e-01   3.03929210e-01   5.11088558e-02
   3.68627965e-01   3.51902236e-05   1.19439214e-02   7.02189794e-03
   6.96871877e-02], sum to 1.0000
[2017-11-02 12:02:16,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 78.0, 5.475, 244.1666666666667, 0.0, 0.0, -3.4, 17.81588492722027, 21.0, 20.92652748882297, 21.5, 0.0, 47.75733460579108], 
actual action is [-3.4000000000000004, 21.0], 
sim time next is 1914000.0000, 
raw observation next is [-8.4, 78.0, 5.6, 243.3333333333333, 0.0, 0.0, -3.4, 18.02001193151498, 21.0, 20.91016349763473, 21.5, 0.0, 41.49571297042911], 
processed observation next is [0.0, 0.13043478260869565, 0.11794871794871795, 0.78, 0.509090909090909, 0.6759259259259258, 0.0, 0.0, 0.44333333333333336, 0.1802001193151498, 0.42857142857142855, 0.4157376425192472, 0.5, 0.0, 0.4881848584756366], 
reward next is -0.5236. 
=============================================
[2017-11-02 12:02:18,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   3.04637941e-29   2.82812250e-29   6.01974622e-29
   7.34275838e-29   3.92252859e-03   5.70616305e-01   2.74068922e-01
   1.51392192e-01], sum to 1.0000
[2017-11-02 12:02:18,896] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.6, 82.58333333333333, 4.141666666666666, 259.1666666666666, 0.0, 0.0, -10.6, 15.7899064209925, 18.0, 22.47986183185674, 22.7, 1.0, 0.0], 
actual action is [-0.5999999999999996, 23.0], 
sim time next is 1973400.0000, 
raw observation next is [-5.600000000000001, 82.16666666666667, 4.183333333333334, 258.3333333333334, 0.0, 0.0, -0.5999999999999996, 14.96183291077737, 23.0, 22.21003390759489, 21.5, 0.0, 60.26042756322556], 
processed observation next is [0.0, 0.8695652173913043, 0.1897435897435897, 0.8216666666666668, 0.3803030303030303, 0.7175925925925929, 0.0, 0.0, 0.49, 0.1496183291077737, 0.7142857142857143, 0.6014334153706987, 0.5, 0.0, 0.7089462066261831], 
reward next is -0.6381. 
=============================================
[2017-11-02 12:02:20,969] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   5.40223920e-37   4.25686223e-37   2.54366495e-36
   4.26165741e-36   4.06866474e-03   3.02447796e-01   5.59453249e-01
   1.34030297e-01], sum to 1.0000
[2017-11-02 12:02:21,061] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 78.0, 4.6, 262.5, 154.0, 0.0, -9.5, 16.4451871536839, 18.0, 22.05510619432937, 22.7, 1.0, 0.0], 
actual action is [0.5, 20.0], 
sim time next is 2033400.0000, 
raw observation next is [-4.5, 78.33333333333334, 4.6, 261.6666666666667, 153.3333333333333, 0.0, 0.5, 15.55436958264366, 20.0, 21.90366799595051, 22.7, 1.0, 49.70344509211168], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.21794871794871795, 0.7833333333333334, 0.41818181818181815, 0.7268518518518519, 0.4056437389770722, 0.0, 0.5083333333333333, 0.1555436958264366, 0.2857142857142857, 0.5576668565643585, 0.6714285714285714, 1.0, 0.5847464128483727], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:02:24,548] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00108302
  0.27308488  0.51425391  0.21157819], sum to 1.0000
[2017-11-02 12:02:24,604] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.35, 85.0, 5.35, 255.0, 79.25, 0.0, 0.5999999999999996, 14.70964812977064, 19.0, 22.24749366466613, 22.7, 1.0, 43.3573347955445], 
actual action is [0.6500000000000004, 21.0], 
sim time next is 2042400.0000, 
raw observation next is [-4.300000000000001, 84.66666666666667, 5.433333333333334, 256.6666666666667, 76.5, 0.0, 0.6500000000000004, 14.54946326451493, 21.0, 22.21870315232181, 22.7, 1.0, 22.87170215231553], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.22307692307692306, 0.8466666666666667, 0.49393939393939396, 0.712962962962963, 0.20238095238095238, 0.0, 0.5108333333333334, 0.1454946326451493, 0.42857142857142855, 0.6026718789031159, 0.6714285714285714, 1.0, 0.26907884885077094], 
reward next is -0.2567. 
=============================================
[2017-11-02 12:02:26,892] A3C_AGENT_WORKER-Thread-12 INFO:Local step 58500, global step 938142: loss -89.1931
[2017-11-02 12:02:29,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.90524656e-01   2.99480468e-01   2.97458380e-01   4.43932042e-03
   8.09716899e-03   7.42671147e-29   1.27855642e-25   1.55262248e-25
   9.77674023e-26], sum to 1.0000
[2017-11-02 12:02:29,759] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-5.6, 75.0, 5.1, 220.0, 201.5, 123.0, -0.7416666666666663, 13.35617012119976, 24.0, 21.98764282023599, 22.7, 1.0, 79.71122000548569], 
actual action is [-0.5999999999999996, 22.0], 
sim time next is 1940700.0000, 
raw observation next is [-5.55, 74.16666666666667, 5.141666666666667, 220.0, 206.5833333333333, 104.1666666666667, -0.5999999999999996, 12.27094768395419, 22.0, 22.15554163169216, 22.7, 1.0, 47.52332020811217], 
processed observation next is [0.0, 0.4782608695652174, 0.19102564102564104, 0.7416666666666667, 0.4674242424242424, 0.6111111111111112, 0.5465167548500881, 0.1041666666666667, 0.49, 0.1227094768395419, 0.5714285714285714, 0.5936488045274514, 0.6714285714285714, 1.0, 0.5590978848013196], 
reward next is -0.5155. 
=============================================
[2017-11-02 12:02:30,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  4.81702127e-02   2.01410234e-01   7.29613006e-01   6.77882181e-03
   1.40277464e-02   9.10288092e-27   1.89140351e-23   1.76966603e-23
   4.42767494e-23], sum to 1.0000
[2017-11-02 12:02:31,009] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.9, 82.00000000000001, 5.85, 258.3333333333334, 0.0, 0.0, 1.100000000000001, 14.38969255879323, 18.5, 21.97966461627729, 22.7, 1.0, 28.83561641360775], 
actual action is [-8.9, 18], 
sim time next is 2052900.0000, 
raw observation next is [-3.9, 82.0, 5.725, 257.5, 0.0, 0.0, -8.9, 15.765668527837, 18.0, 21.88693868207674, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.23333333333333334, 0.82, 0.5204545454545454, 0.7152777777777778, 0.0, 0.0, 0.3516666666666667, 0.15765668527837, 0.0, 0.5552769545823912, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:02:32,084] A3C_AGENT_WORKER-Thread-14 INFO:Local step 58500, global step 938871: loss -34.6750
[2017-11-02 12:02:32,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  8.90014989e-18   1.32967243e-05   5.04809941e-06   1.85992781e-06
   8.55026485e-07   6.35919103e-04   6.90719366e-01   2.48018339e-01
   6.06054030e-02], sum to 1.0000
[2017-11-02 12:02:33,085] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.9, 85.0, 4.225, 265.0, 0.0, 0.0, 1.100000000000001, 21.66911885981338, 20.5, 20.67613705716893, 22.7, 1.0, 19.28397105506914], 
actual action is [1.1, 21.5], 
sim time next is 2058600.0000, 
raw observation next is [-3.9, 85.33333333333334, 4.183333333333333, 266.6666666666666, 0.0, 0.0, 1.1, 22.22789814903362, 21.5, 20.62895692174465, 22.7, 1.0, 17.90863038343456], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.23333333333333334, 0.8533333333333334, 0.38030303030303025, 0.7407407407407405, 0.0, 0.0, 0.5183333333333333, 0.2222789814903362, 0.5, 0.37556527453494987, 0.6714285714285714, 1.0, 0.21068976921687715], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:02:34,554] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.18594084e-11   1.84552550e-01   7.30365157e-01   5.31826727e-02
   3.18830647e-02   5.14611598e-09   8.71669636e-06   4.03537297e-06
   3.79504922e-06], sum to 1.0000
[2017-11-02 12:02:34,835] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.9, 78.33333333333334, 2.666666666666667, 236.6666666666667, 0.0, 0.0, -1.850000000000001, 18.86628086549675, 22.0, 20.50642015169117, 22.7, 1.0, 61.94358680668206], 
actual action is [-1.9000000000000004, 21.0], 
sim time next is 2100300.0000, 
raw observation next is [-6.949999999999999, 78.41666666666666, 2.583333333333333, 235.8333333333333, 0.0, 0.0, -1.9, 18.28218746937642, 21.0, 20.58082758506798, 22.7, 1.0, 62.02861109367073], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.15512820512820516, 0.7841666666666666, 0.23484848484848483, 0.6550925925925924, 0.0, 0.0, 0.4683333333333334, 0.1828218746937642, 0.42857142857142855, 0.3686896550097113, 0.6714285714285714, 1.0, 0.7297483658078909], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:02:36,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.46281762e-06   3.47188830e-01   6.09298170e-01   2.65056789e-02
   1.69978030e-02   1.92858366e-22   3.09172842e-19   1.48814303e-19
   2.47172010e-19], sum to 1.0000
[2017-11-02 12:02:36,330] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.05, 83.0, 4.225, 255.0, 0.0, 0.0, -9.0, 27.23447955997165, 18.0, 20.18836963984489, 21.5, 0.0, 0.0], 
actual action is [-9.05, 18], 
sim time next is 2067600.0000, 
raw observation next is [-4.1, 83.33333333333334, 4.433333333333334, 253.3333333333333, 0.0, 0.0, -9.05, 28.75472018292255, 18.0, 20.0594785826994, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.22820512820512823, 0.8333333333333335, 0.40303030303030307, 0.7037037037037036, 0.0, 0.0, 0.3491666666666667, 0.2875472018292255, 0.0, 0.29421122609991407, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:02:37,318] A3C_AGENT_WORKER-Thread-15 INFO:Local step 58500, global step 939577: loss -35.1872
[2017-11-02 12:02:40,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 58500, global step 939939: loss 10.4912
[2017-11-02 12:02:40,329] A3C_AGENT_WORKER-Thread-10 INFO:Local step 59000, global step 939975: loss 3.0757
[2017-11-02 12:02:43,561] A3C_AGENT_WORKER-Thread-8 INFO:Local step 59000, global step 940418: loss 62.1253
[2017-11-02 12:02:50,652] A3C_AGENT_WORKER-Thread-11 INFO:Local step 58500, global step 941217: loss 6.7756
[2017-11-02 12:02:51,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.02619806e-01   5.14212310e-01   1.91889256e-01   1.30733810e-02
   7.82051459e-02   1.86702322e-20   1.70226884e-18   2.05176216e-18
   6.63773812e-18], sum to 1.0000
[2017-11-02 12:02:52,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.016666666666667, 86.08333333333333, 5.058333333333334, 240.0, 45.66666666666666, 0.0, -1.033333333333333, 11.73607693174846, 23.0, 22.33107337144215, 22.7, 1.0, 56.34076596103774], 
actual action is [-1.0166666666666666, 21.0], 
sim time next is 2019600.0000, 
raw observation next is [-6.0, 86.0, 5.1, 240.0, 49.0, 0.0, -1.016666666666667, 11.63252348143692, 21.0, 22.37493040283525, 22.7, 1.0, 58.3610548313424], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.1794871794871795, 0.86, 0.4636363636363636, 0.6666666666666666, 0.12962962962962962, 0.0, 0.48305555555555557, 0.1163252348143692, 0.42857142857142855, 0.6249900575478929, 0.6714285714285714, 1.0, 0.6866006450746165], 
reward next is -0.6296. 
=============================================
[2017-11-02 12:02:52,513] A3C_AGENT_WORKER-Thread-3 INFO:Local step 59000, global step 941421: loss 3.2432
[2017-11-02 12:02:53,278] A3C_AGENT_WORKER-Thread-16 INFO:Local step 59000, global step 941521: loss 6.5267
[2017-11-02 12:02:56,412] A3C_AGENT_WORKER-Thread-6 INFO:Local step 59000, global step 941899: loss 3.3975
[2017-11-02 12:02:58,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  7.72388652e-02   4.12420392e-01   4.68318641e-01   3.69490683e-03
   3.83271389e-02   2.27063381e-25   3.63264862e-23   3.84715978e-23
   5.18290955e-22], sum to 1.0000
[2017-11-02 12:02:58,088] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 86.83333333333334, 5.933333333333333, 241.6666666666667, 0.0, 0.0, -9.5, 17.68931212774553, 18.0, 21.58155102084397, 21.5, 0.0, 0.0], 
actual action is [-9.5, 18.0], 
sim time next is 2070900.0000, 
raw observation next is [-4.5, 87.25, 5.85, 242.5, 0.0, 0.0, -9.5, 20.14012971434183, 18.0, 21.35815415208144, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 1.0, 0.21794871794871795, 0.8725, 0.5318181818181817, 0.6736111111111112, 0.0, 0.0, 0.3416666666666667, 0.20140129714341828, 0.0, 0.4797363074402057, 0.5, 0.0, 0.0], 
reward next is -0.0203. 
=============================================
[2017-11-02 12:02:59,215] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.90047203e-02   6.40585780e-01   2.55929649e-01   4.66112513e-03
   3.98187302e-02   4.10905781e-23   3.82664980e-21   2.28471789e-21
   1.00211429e-20], sum to 1.0000
[2017-11-02 12:02:59,238] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.15, 64.33333333333333, 3.133333333333333, 250.0, 149.8333333333333, 55.83333333333333, -11.2, 12.15323161603338, 18.0, 22.54947634260868, 22.7, 1.0, 0.0], 
actual action is [-11.15, 18], 
sim time next is 2121000.0000, 
raw observation next is [-6.100000000000001, 64.66666666666667, 3.266666666666667, 250.0, 149.6666666666667, 44.66666666666666, -11.15, 13.16565076385932, 18.0, 22.50389145197331, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.17692307692307688, 0.6466666666666667, 0.296969696969697, 0.6944444444444444, 0.3959435626102294, 0.04466666666666666, 0.3141666666666667, 0.1316565076385932, 0.0, 0.6434130645676157, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0132. 
=============================================
[2017-11-02 12:03:02,045] A3C_AGENT_WORKER-Thread-9 INFO:Local step 59000, global step 942571: loss 42.2289
[2017-11-02 12:03:05,173] A3C_AGENT_WORKER-Thread-4 INFO:Local step 59000, global step 942957: loss 27.6420
[2017-11-02 12:03:08,158] A3C_AGENT_WORKER-Thread-5 INFO:Local step 59000, global step 943384: loss -17.4652
[2017-11-02 12:03:10,644] A3C_AGENT_WORKER-Thread-7 INFO:Local step 59000, global step 943696: loss 7.3605
[2017-11-02 12:03:10,817] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.75774291e-27   1.21306130e-26   9.50574926e-27
   7.12904385e-27   1.07857008e-02   1.19820789e-01   1.80124983e-01
   6.89268529e-01], sum to 1.0000
[2017-11-02 12:03:10,998] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.899999999999999, 69.75, 6.85, 261.6666666666666, 122.0, 0.0, -8.9, 17.06299355929586, 18.0, 22.1669297844601, 22.7, 1.0, 0.0], 
actual action is [1.100000000000001, 20.0], 
sim time next is 2212200.0000, 
raw observation next is [-3.9, 69.5, 6.9, 260.0, 120.0, 0.0, 1.100000000000001, 15.06508146473875, 20.0, 22.06822135621801, 22.7, 1.0, 72.79166454777679], 
processed observation next is [0.5, 0.6086956521739131, 0.23333333333333334, 0.695, 0.6272727272727273, 0.7222222222222222, 0.31746031746031744, 0.0, 0.5183333333333333, 0.1506508146473875, 0.2857142857142857, 0.5811744794597159, 0.6714285714285714, 1.0, 0.8563725240914917], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:03:11,653] A3C_AGENT_WORKER-Thread-17 INFO:Local step 59000, global step 943834: loss 8.7464
[2017-11-02 12:03:14,918] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   2.86314939e-37   3.18929073e-36   1.88584134e-35
   1.64857888e-35   1.85194367e-04   4.72144550e-03   1.87238939e-02
   9.76369441e-01], sum to 1.0000
[2017-11-02 12:03:15,055] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.408333333333333, 76.25, 3.0, 265.8333333333333, 0.0, 0.0, -1.45, 19.63552468909453, 23.0, 20.55382407754747, 21.5, 0.0, 51.47844129977641], 
actual action is [-1.4083333333333332, 25], 
sim time next is 2176800.0000, 
raw observation next is [-6.366666666666667, 76.0, 3.0, 266.6666666666667, 0.0, 0.0, -1.408333333333333, 19.43264937135545, 25.0, 20.50701710134455, 21.5, 0.0, 45.36799967749518], 
processed observation next is [0.5, 0.17391304347826086, 0.17008547008547006, 0.76, 0.2727272727272727, 0.7407407407407408, 0.0, 0.0, 0.47652777777777783, 0.19432649371355448, 1.0, 0.3581453001920788, 0.5, 0.0, 0.5337411726764139], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:03:18,686] A3C_AGENT_WORKER-Thread-2 INFO:Local step 59000, global step 944723: loss 94.5193
[2017-11-02 12:03:21,184] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.19015211e-02   3.24455112e-01   1.46274611e-01   9.92681086e-03
   5.07441938e-01   2.12093069e-25   2.20473133e-23   1.52070831e-23
   1.34480375e-22], sum to 1.0000
[2017-11-02 12:03:21,375] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.608333333333333, 66.25, 5.808333333333333, 274.1666666666666, 129.3333333333333, 0.0, 1.35, 11.11839918529971, 23.0, 21.96840371430107, 22.7, 1.0, 67.85674388334911], 
actual action is [1.391666666666667, 21.0], 
sim time next is 2205600.0000, 
raw observation next is [-3.566666666666666, 66.0, 5.766666666666667, 273.3333333333334, 130.6666666666667, 0.0, 1.391666666666667, 10.46409225726144, 21.0, 22.27012410771431, 22.7, 1.0, 52.32706007707995], 
processed observation next is [0.5, 0.5217391304347826, 0.24188034188034188, 0.66, 0.5242424242424243, 0.7592592592592595, 0.34567901234567916, 0.0, 0.5231944444444444, 0.1046409225726144, 0.42857142857142855, 0.6100177296734728, 0.6714285714285714, 1.0, 0.6156124714950583], 
reward next is -0.5645. 
=============================================
[2017-11-02 12:03:22,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.96262647e-02   3.91533852e-01   2.79074699e-01   1.32019222e-02
   2.66563237e-01   5.43834976e-26   3.54223593e-24   2.35683101e-24
   1.04759079e-23], sum to 1.0000
[2017-11-02 12:03:22,377] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.85, 66.33333333333334, 3.933333333333333, 250.0, 147.0, 0.0, -0.9000000000000004, 10.07906143843629, 23.0, 22.22447190959371, 22.7, 1.0, 60.63184881737099], 
actual action is [-0.8499999999999996, 22.0], 
sim time next is 2122800.0000, 
raw observation next is [-5.8, 66.66666666666666, 4.066666666666666, 250.0, 145.0, 0.0, -0.8499999999999996, 9.650518167893274, 22.0, 22.52009106204437, 22.7, 1.0, 45.71135488249107], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.18461538461538463, 0.6666666666666665, 0.3696969696969697, 0.6944444444444444, 0.3835978835978836, 0.0, 0.4858333333333333, 0.09650518167893274, 0.5714285714285714, 0.6457272945777669, 0.6714285714285714, 1.0, 0.5377806456763655], 
reward next is -0.4937. 
=============================================
[2017-11-02 12:03:26,950] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.13447812e-02   3.08299512e-01   3.64409268e-01   1.39544150e-02
   2.21992061e-01   2.88550528e-26   1.67090896e-24   1.14535287e-24
   1.47155517e-23], sum to 1.0000
[2017-11-02 12:03:27,016] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-4.2, 69.5, 6.65, 270.0, 143.0, 0.0, 0.75, 12.98481856182382, 23.0, 22.39627346522187, 22.7, 1.0, 67.1022809276708], 
actual action is [0.7999999999999998, 21.0], 
sim time next is 2201700.0000, 
raw observation next is [-4.149999999999999, 69.25, 6.558333333333334, 271.6666666666667, 141.75, 0.0, 0.7999999999999998, 12.62363113696792, 21.0, 22.38739433302012, 22.7, 1.0, 39.51226115790281], 
processed observation next is [0.5, 0.4782608695652174, 0.22692307692307695, 0.6925, 0.5962121212121212, 0.7546296296296297, 0.375, 0.0, 0.5133333333333333, 0.1262363113696792, 0.42857142857142855, 0.6267706190028741, 0.6714285714285714, 1.0, 0.46485013126944486], 
reward next is -0.4310. 
=============================================
[2017-11-02 12:03:31,686] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.22692697e-02   3.30442518e-01   4.07967329e-01   1.89162269e-02
   2.30404630e-01   2.03561974e-30   3.14262608e-28   2.10092861e-28
   1.85365457e-26], sum to 1.0000
[2017-11-02 12:03:31,817] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.699999999999999, 70.25, 6.825, 265.0, 0.0, 0.0, -9.666666666666666, 14.24696668836715, 18.0, 22.24437010721336, 22.7, 1.0, 0.0], 
actual action is [-9.7, 18], 
sim time next is 2229600.0000, 
raw observation next is [-4.733333333333333, 70.33333333333334, 6.866666666666667, 263.3333333333334, 0.0, 0.0, -9.7, 16.36028488653903, 18.0, 22.11175824279472, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.8260869565217391, 0.21196581196581193, 0.7033333333333335, 0.6242424242424243, 0.7314814814814817, 0.0, 0.0, 0.3383333333333333, 0.1636028488653903, 0.0, 0.5873940346849602, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:03:32,603] A3C_AGENT_WORKER-Thread-12 INFO:Local step 59000, global step 946500: loss 37.6941
[2017-11-02 12:03:34,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.07059618e-18   4.84730490e-02   4.72706079e-01   2.41478860e-01
   2.36750424e-01   2.50744190e-08   1.53453686e-06   3.03915112e-06
   5.86953072e-04], sum to 1.0000
[2017-11-02 12:03:34,759] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-7.199999999999999, 80.83333333333334, 4.516666666666666, 261.6666666666667, 0.0, 0.0, -2.149999999999999, 19.73568896337233, 22.0, 20.42306814263503, 21.5, 0.0, 48.49241565331228], 
actual action is [-2.1999999999999993, 22.0], 
sim time next is 2253300.0000, 
raw observation next is [-7.25, 81.41666666666666, 4.558333333333333, 260.8333333333333, 0.0, 0.0, -2.199999999999999, 19.22155118654825, 22.0, 20.51820652342399, 21.5, 0.0, 48.01271343102925], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.14743589743589744, 0.8141666666666666, 0.4143939393939393, 0.724537037037037, 0.0, 0.0, 0.4633333333333333, 0.1922155118654825, 0.5714285714285714, 0.3597437890605702, 0.5, 0.0, 0.5648554521297559], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:03:35,484] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.16103308e-02   3.54882240e-01   4.80162054e-01   6.23048879e-02
   8.10404867e-02   8.15289780e-29   5.79094393e-27   4.36483518e-27
   1.27906117e-25], sum to 1.0000
[2017-11-02 12:03:35,566] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.566666666666667, 67.0, 5.933333333333334, 270.0, 141.3333333333333, 0.0, 1.475, 9.400396493811908, 20.0, 23.01781660001271, 22.7, 1.0, 44.25353351207077], 
actual action is [-8.566666666666666, 18.0], 
sim time next is 2208300.0000, 
raw observation next is [-3.608333333333333, 67.5, 6.016666666666666, 270.0, 142.6666666666667, 0.0, -8.566666666666666, 10.44919385123499, 18.0, 23.09252011207386, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.24081196581196584, 0.675, 0.5469696969696969, 0.75, 0.3774250440917109, 0.0, 0.3572222222222222, 0.10449193851234989, 0.0, 0.7275028731534086, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0104. 
=============================================
[2017-11-02 12:03:37,138] A3C_AGENT_WORKER-Thread-14 INFO:Local step 59000, global step 947046: loss -0.9923
[2017-11-02 12:03:40,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 59000, global step 947485: loss 88.0453
[2017-11-02 12:03:43,245] A3C_AGENT_WORKER-Thread-10 INFO:Local step 59500, global step 947846: loss 13.4984
[2017-11-02 12:03:46,959] A3C_AGENT_WORKER-Thread-8 INFO:Local step 59500, global step 948340: loss 21.7413
[2017-11-02 12:03:47,547] A3C_AGENT_WORKER-Thread-13 INFO:Local step 59000, global step 948407: loss 3.4208
[2017-11-02 12:03:54,954] A3C_AGENT_WORKER-Thread-16 INFO:Local step 59500, global step 949346: loss 10.0032
[2017-11-02 12:03:55,235] A3C_AGENT_WORKER-Thread-11 INFO:Local step 59000, global step 949380: loss 43.8115
[2017-11-02 12:03:55,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-65.64865875]
 [-65.60179901]
 [-66.09494781]
 [-65.18583679]
 [-64.89396667]], R is [[-65.89800262]
 [-66.2390213 ]
 [-66.57662964]
 [-65.92511749]
 [-65.69701385]].
[2017-11-02 12:03:55,551] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.18809163e-03   2.52446324e-01   4.48279709e-01   2.31954873e-01
   6.51310384e-02   8.54817784e-36   4.38864791e-33   1.10267009e-33
   2.06363182e-31], sum to 1.0000
[2017-11-02 12:03:55,574] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.39849123e-03   2.34000117e-01   4.91073400e-01   2.12825596e-01
   5.77023104e-02   4.76447844e-31   1.04367227e-28   4.54987618e-29
   6.00828320e-27], sum to 1.0000
[2017-11-02 12:03:55,596] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.7, 55.33333333333334, 1.5, 250.0, 0.0, 0.0, 3.3, 12.63988127623313, 18.5, 22.31643603909415, 21.5, 0.0, 30.25872534692074], 
actual action is [-6.7, 18], 
sim time next is 2319900.0000, 
raw observation next is [-1.7, 55.16666666666666, 1.5, 252.5, 0.0, 0.0, -6.7, 14.08198067210215, 18.0, 22.35214517122742, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.28974358974358977, 0.5516666666666665, 0.13636363636363635, 0.7013888888888888, 0.0, 0.0, 0.38833333333333336, 0.14081980672102148, 0.0, 0.62173502446106, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 12:03:55,602] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.816666666666666, 67.5, 6.016666666666667, 278.3333333333334, 133.0, 0.0, -8.858333333333333, 16.70486851987347, 18.0, 22.43450336581571, 22.7, 1.0, 0.0], 
actual action is [-8.816666666666666, 18], 
sim time next is 2204100.0000, 
raw observation next is [-3.775, 67.25, 5.975, 277.5, 131.75, 0.0, -8.816666666666666, 18.23947984287903, 18.0, 22.18475861734745, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.23653846153846153, 0.6725, 0.5431818181818181, 0.7708333333333334, 0.34854497354497355, 0.0, 0.35305555555555557, 0.1823947984287903, 0.0, 0.5978226596210641, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:03:57,190] A3C_AGENT_WORKER-Thread-3 INFO:Local step 59500, global step 949634: loss 9.8028
[2017-11-02 12:03:59,407] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  6.82396861e-03   1.65380105e-01   5.42724013e-01   2.31436610e-01
   5.36353774e-02   1.05870403e-33   9.21160279e-32   2.54131887e-32
   4.63072364e-30], sum to 1.0000
[2017-11-02 12:03:59,475] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.2, 77.0, 3.0, 270.0, 0.0, 0.0, -1.199999999999999, 15.8566834228923, 22.0, 21.06128269746901, 21.5, 0.0, 45.60886773019431], 
actual action is [-1.2000000000000002, 21.5], 
sim time next is 2180100.0000, 
raw observation next is [-6.2, 77.33333333333333, 3.0, 270.0, 0.0, 0.0, -1.2, 15.93819405414527, 21.5, 21.0734203513563, 21.5, 0.0, 39.84063963619722], 
processed observation next is [0.5, 0.21739130434782608, 0.17435897435897435, 0.7733333333333333, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.15938194054145272, 0.5, 0.43906005019375727, 0.5, 0.0, 0.46871340748467316], 
reward next is -0.4828. 
=============================================
[2017-11-02 12:04:01,680] A3C_AGENT_WORKER-Thread-6 INFO:Local step 59500, global step 950204: loss 45.1871
[2017-11-02 12:04:06,026] A3C_AGENT_WORKER-Thread-9 INFO:Local step 59500, global step 950783: loss -89.9543
[2017-11-02 12:04:06,874] A3C_AGENT_WORKER-Thread-4 INFO:Local step 59500, global step 950921: loss 5.5963
[2017-11-02 12:04:09,377] A3C_AGENT_WORKER-Thread-5 INFO:Local step 59500, global step 951263: loss 7.0513
[2017-11-02 12:04:10,072] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.54556540e-06   5.24609275e-02   5.09134710e-01   3.55693728e-01
   8.27091187e-02   4.16225604e-17   2.39506666e-16   7.56219051e-16
   5.52920407e-14], sum to 1.0000
[2017-11-02 12:04:10,087] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.95, 57.25, 0.8333333333333334, 150.0, 0.0, 0.0, -6.9, 24.25994495197514, 18.0, 21.07892373285401, 21.5, 0.0, 0.0], 
actual action is [-6.95, 18], 
sim time next is 2327400.0000, 
raw observation next is [-2.0, 57.5, 1.0, 180.0, 0.0, 0.0, -6.95, 25.68809895187742, 18.0, 20.81571320352302, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.28205128205128205, 0.575, 0.09090909090909091, 0.5, 0.0, 0.0, 0.38416666666666666, 0.2568809895187742, 0.0, 0.4022447433604316, 0.5, 0.0, 0.0], 
reward next is -0.0978. 
=============================================
[2017-11-02 12:04:10,759] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.96170341e-24   1.46224685e-10   1.31447053e-09   6.55711441e-09
   7.19918847e-10   1.07023139e-02   3.17955799e-02   1.01218976e-01
   8.56283188e-01], sum to 1.0000
[2017-11-02 12:04:10,800] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 51.0, 2.5, 220.0, 241.5, 71.5, 3.175, 13.38375847278567, 23.0, 22.48687072491943, 22.7, 1.0, 31.23787105134073], 
actual action is [3.3, 25], 
sim time next is 2293500.0000, 
raw observation next is [-1.608333333333333, 50.5, 2.458333333333333, 219.1666666666667, 238.0833333333333, 71.08333333333333, 3.3, 13.23265352458607, 25.0, 22.44805651081023, 22.7, 1.0, 18.79673847199316], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.2920940170940171, 0.505, 0.22348484848484845, 0.6087962962962964, 0.6298500881834214, 0.07108333333333333, 0.5549999999999999, 0.1323265352458607, 1.0, 0.6354366444014613, 0.6714285714285714, 1.0, 0.22113809967050774], 
reward next is -0.2123. 
=============================================
[2017-11-02 12:04:11,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-44.99028778]
 [-45.35243225]
 [-45.82204437]
 [-46.86125946]
 [-46.4655304 ]], R is [[-42.51265335]
 [-42.7738533 ]
 [-43.0464325 ]
 [-43.6159668 ]
 [-44.17980576]].
[2017-11-02 12:04:12,469] A3C_AGENT_WORKER-Thread-7 INFO:Local step 59500, global step 951659: loss 44.7486
[2017-11-02 12:04:13,759] A3C_AGENT_WORKER-Thread-17 INFO:Local step 59500, global step 951816: loss 70.7733
[2017-11-02 12:04:14,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-40.97773361]
 [-40.57991409]
 [-40.93706512]
 [-40.67830276]
 [-40.55760956]], R is [[-40.66326523]
 [-40.61417389]
 [-40.59120941]
 [-40.59604645]
 [-40.65221024]].
[2017-11-02 12:04:16,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   2.33930385e-32   1.43067659e-30   2.03233348e-28
   4.96225818e-30   2.73740739e-02   2.09730621e-02   1.47405908e-01
   8.04246962e-01], sum to 1.0000
[2017-11-02 12:04:16,513] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.8, 56.5, 0.3333333333333333, 60.0, 0.0, 0.0, -6.75, 21.23576361388173, 18.0, 21.51871084108879, 21.5, 0.0, 0.0], 
actual action is [3.2, 23.0], 
sim time next is 2326500.0000, 
raw observation next is [-1.85, 56.75, 0.5, 90.0, 0.0, 0.0, 3.2, 18.90303338392226, 23.0, 21.2643938163286, 21.5, 0.0, 72.10547242652301], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2858974358974359, 0.5675, 0.045454545454545456, 0.25, 0.0, 0.0, 0.5533333333333333, 0.1890303338392226, 0.7142857142857143, 0.4663419737612285, 0.5, 0.0, 0.848299675606153], 
reward next is -0.7971. 
=============================================
[2017-11-02 12:04:27,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 59500, global step 953678: loss 14.7089
[2017-11-02 12:04:28,520] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.01577777e-08   1.00833187e-02   2.06851378e-01   4.47004825e-01
   3.36060435e-01   1.35024310e-19   1.96884682e-18   4.35622965e-18
   3.12704341e-16], sum to 1.0000
[2017-11-02 12:04:28,627] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.35, 68.66666666666667, 4.6, 80.83333333333333, 0.0, 0.0, 1.7, 15.86506929661839, 20.5, 21.29391313273957, 21.5, 0.0, 33.32197686570711], 
actual action is [1.65, 20.0], 
sim time next is 2350800.0000, 
raw observation next is [-3.4, 69.0, 4.6, 80.0, 0.0, 0.0, 1.65, 16.21648406767888, 20.0, 21.28607438510176, 21.5, 0.0, 31.90222755346807], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.24615384615384614, 0.69, 0.41818181818181815, 0.2222222222222222, 0.0, 0.0, 0.5275, 0.1621648406767888, 0.2857142857142857, 0.4694391978716799, 0.5, 0.0, 0.37532032415844785], 
reward next is -0.3683. 
=============================================
[2017-11-02 12:04:39,169] A3C_AGENT_WORKER-Thread-12 INFO:Local step 59500, global step 955069: loss 10.0392
[2017-11-02 12:04:40,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  5.35393774e-08   6.68843929e-03   1.69357017e-01   4.50437516e-01
   3.73517007e-01   5.38220347e-13   2.80214328e-12   3.21375196e-12
   3.79052796e-11], sum to 1.0000
[2017-11-02 12:04:40,879] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-5.425, 70.5, 2.5, 237.5, 173.75, 65.0, -0.5666666666666664, 8.249802268485034, 23.5, 23.92682979118737, 22.7, 1.0, 31.88382559594952], 
actual action is [-0.4249999999999998, 23.5], 
sim time next is 2285400.0000, 
raw observation next is [-5.283333333333333, 69.66666666666667, 2.5, 238.3333333333333, 172.3333333333333, 70.0, -0.4249999999999998, 8.429933438846856, 23.5, 23.88339185903898, 22.7, 1.0, 29.64950413374551], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.19786324786324785, 0.6966666666666668, 0.22727272727272727, 0.6620370370370369, 0.45590828924162247, 0.07, 0.49291666666666667, 0.08429933438846855, 0.7857142857142857, 0.8404845512912829, 0.6714285714285714, 1.0, 0.34881769569112364], 
reward next is -0.3224. 
=============================================
[2017-11-02 12:04:42,237] A3C_AGENT_WORKER-Thread-14 INFO:Local step 59500, global step 955501: loss 5.8992
[2017-11-02 12:04:43,411] A3C_AGENT_WORKER-Thread-10 INFO:Local step 60000, global step 955696: loss 120.8232
[2017-11-02 12:04:43,985] A3C_AGENT_WORKER-Thread-15 INFO:Local step 59500, global step 955776: loss 9.0449
[2017-11-02 12:04:44,154] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-48.65990067]
 [-48.71055984]
 [-48.13531494]
 [-47.73615646]
 [-47.03370285]], R is [[-47.5841217 ]
 [-47.74348831]
 [-47.99751282]
 [-47.51753998]
 [-47.04236603]].
[2017-11-02 12:04:44,437] A3C_AGENT_WORKER-Thread-8 INFO:Local step 60000, global step 955846: loss -62.3750
[2017-11-02 12:04:48,809] A3C_AGENT_WORKER-Thread-13 INFO:Local step 59500, global step 956532: loss 19.5920
[2017-11-02 12:04:51,281] A3C_AGENT_WORKER-Thread-16 INFO:Local step 60000, global step 956892: loss 4.1087
[2017-11-02 12:04:51,702] A3C_AGENT_WORKER-Thread-3 INFO:Local step 60000, global step 956950: loss 283.0319
[2017-11-02 12:04:51,999] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-70.71134949]
 [-69.09671021]
 [-71.29058838]
 [-71.08023071]
 [-72.58018494]], R is [[-68.90486145]
 [-68.65486145]
 [-68.4937439 ]
 [-68.38460541]
 [-68.3468399 ]].
[2017-11-02 12:04:52,544] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.39625163e-02   3.43782990e-03   5.50501227e-01   3.42022657e-01
   8.00757259e-02   0.00000000e+00   2.07623936e-37   6.16438201e-38
   8.09743560e-36], sum to 1.0000
[2017-11-02 12:04:52,599] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.649999999999999, 43.41666666666666, 4.641666666666666, 69.99999999999999, 0.0, 0.0, -0.5999999999999996, 23.55534219859632, 19.0, 20.56902611595978, 21.5, 0.0, 29.1545166040773], 
actual action is [-10.649999999999999, 18.0], 
sim time next is 2419800.0000, 
raw observation next is [-5.7, 43.83333333333334, 4.683333333333333, 70.0, 0.0, 0.0, -10.65, 25.80059423712821, 18.0, 20.57686982314033, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.18717948717948718, 0.4383333333333334, 0.4257575757575757, 0.19444444444444445, 0.0, 0.0, 0.3225, 0.2580059423712821, 0.0, 0.36812426044861873, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:04:55,393] A3C_AGENT_WORKER-Thread-6 INFO:Local step 60000, global step 957495: loss -24.7719
[2017-11-02 12:04:58,604] A3C_AGENT_WORKER-Thread-11 INFO:Local step 59500, global step 958022: loss 64.2227
[2017-11-02 12:05:00,630] A3C_AGENT_WORKER-Thread-4 INFO:Local step 60000, global step 958344: loss -60.6782
[2017-11-02 12:05:01,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-61.74293518]
 [-61.74625015]
 [-61.02859879]
 [-60.58600235]
 [-62.09343719]], R is [[-61.84793854]
 [-62.22945786]
 [-62.60716248]
 [-62.98109055]
 [-63.35128021]].
[2017-11-02 12:05:02,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 60000, global step 958631: loss 62.3145
[2017-11-02 12:05:04,687] A3C_AGENT_WORKER-Thread-5 INFO:Local step 60000, global step 958906: loss 219.0175
[2017-11-02 12:05:05,662] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.04961044
  0.01530868  0.01789002  0.91719085], sum to 1.0000
[2017-11-02 12:05:05,733] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-9.2, 60.5, 3.3, 65.0, 0.0, 0.0, -4.15, 22.16431200650972, 25.0, 20.3353558348955, 21.5, 0.0, 46.23139227565201], 
actual action is [-4.199999999999999, 25], 
sim time next is 2442900.0000, 
raw observation next is [-9.25, 60.58333333333333, 3.35, 64.16666666666666, 0.0, 0.0, -4.199999999999999, 22.25895539679476, 25.0, 20.31811862754993, 21.5, 0.0, 46.28570673980989], 
processed observation next is [1.0, 0.2608695652173913, 0.09615384615384616, 0.6058333333333333, 0.30454545454545456, 0.17824074074074073, 0.0, 0.0, 0.43, 0.2225895539679476, 1.0, 0.3311598039357041, 0.5, 0.0, 0.5445377263507046], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:05:07,346] A3C_AGENT_WORKER-Thread-7 INFO:Local step 60000, global step 959244: loss 326.0114
[2017-11-02 12:05:08,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-46.77627563]
 [-46.63769531]
 [-45.93159485]
 [-47.26584625]
 [-46.55332184]], R is [[-46.51641846]
 [-46.37291718]
 [-46.43266678]
 [-45.96834183]
 [-45.50865936]].
[2017-11-02 12:05:09,565] A3C_AGENT_WORKER-Thread-17 INFO:Local step 60000, global step 959549: loss 102.8017
[2017-11-02 12:05:19,363] A3C_AGENT_WORKER-Thread-2 INFO:Local step 60000, global step 961119: loss -10.5813
[2017-11-02 12:05:21,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.64490834e-01   4.97353047e-01   1.68669343e-01   1.16229273e-01
   5.32575026e-02   1.02860127e-28   1.74890328e-27   9.31759707e-28
   1.54146656e-26], sum to 1.0000
[2017-11-02 12:05:21,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.35, 45.83333333333333, 5.516666666666666, 74.16666666666666, 72.91666666666666, 54.5, 4.7, 14.02332479550788, 22.0, 22.51165316088838, 22.7, 1.0, 46.1923253803903], 
actual action is [4.65, 20.0], 
sim time next is 2392800.0000, 
raw observation next is [-0.4, 45.66666666666667, 5.433333333333334, 73.33333333333334, 66.83333333333334, 51.0, 4.65, 13.67753814139085, 20.0, 22.4908141437777, 22.7, 1.0, 48.6593646382327], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.3230769230769231, 0.4566666666666667, 0.49393939393939396, 0.20370370370370372, 0.1768077601410935, 0.051, 0.5775, 0.1367753814139085, 0.2857142857142857, 0.6415448776825288, 0.6714285714285714, 1.0, 0.572463113390973], 
reward next is -0.5289. 
=============================================
[2017-11-02 12:05:23,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-42.21099472]
 [-42.4616127 ]
 [-42.14499283]
 [-42.89149857]
 [-43.69580841]], R is [[-41.98797226]
 [-42.13879776]
 [-42.33511734]
 [-42.57974625]
 [-42.82530212]].
[2017-11-02 12:05:29,565] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-45.29121399]
 [-46.53578186]
 [-50.658535  ]
 [-47.81636429]
 [-46.12225723]], R is [[-48.11347198]
 [-47.63233948]
 [-47.39107132]
 [-47.16289139]
 [-46.94849014]].
[2017-11-02 12:05:29,669] A3C_AGENT_WORKER-Thread-12 INFO:Local step 60000, global step 962761: loss 109.6766
[2017-11-02 12:05:31,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-45.98691559]
 [-43.97028732]
 [-45.03437042]
 [-43.95462799]
 [-43.87893677]], R is [[-48.4562149 ]
 [-48.97165298]
 [-49.48193741]
 [-49.98711777]
 [-49.57261276]].
[2017-11-02 12:05:31,342] A3C_AGENT_WORKER-Thread-10 INFO:Local step 60500, global step 963108: loss 69.7266
[2017-11-02 12:05:33,976] A3C_AGENT_WORKER-Thread-8 INFO:Local step 60500, global step 963497: loss -76.7769
[2017-11-02 12:05:35,055] A3C_AGENT_WORKER-Thread-14 INFO:Local step 60000, global step 963649: loss 195.1190
[2017-11-02 12:05:37,514] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  6.60594702e-02   7.56656826e-01   6.94794804e-02   1.94658563e-02
   8.83383378e-02   7.73318127e-26   1.34656693e-24   4.23729042e-25
   1.78440140e-24], sum to 1.0000
[2017-11-02 12:05:37,523] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.3, 29.0, 4.199999999999999, 347.5, 103.0, 303.75, -1.7, 10.634475405978, 18.0, 23.46470876387194, 22.7, 1.0, 0.0], 
actual action is [-1.7000000000000002, 18], 
sim time next is 2562600.0000, 
raw observation next is [3.3, 29.0, 4.333333333333333, 348.3333333333334, 99.33333333333334, 288.0, -1.7, 10.74594716854319, 18.0, 23.44014431279934, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.41794871794871796, 0.29, 0.3939393939393939, 0.9675925925925929, 0.2627865961199295, 0.288, 0.4716666666666667, 0.10745947168543189, 0.0, 0.7771634732570486, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 12:05:38,351] A3C_AGENT_WORKER-Thread-15 INFO:Local step 60000, global step 964131: loss 373.1223
[2017-11-02 12:05:40,505] A3C_AGENT_WORKER-Thread-13 INFO:Local step 60000, global step 964457: loss 91.2194
[2017-11-02 12:05:42,022] A3C_AGENT_WORKER-Thread-16 INFO:Local step 60500, global step 964711: loss -84.2427
[2017-11-02 12:05:42,082] A3C_AGENT_WORKER-Thread-3 INFO:Local step 60500, global step 964720: loss -1.6087
[2017-11-02 12:05:43,156] A3C_AGENT_WORKER-Thread-6 INFO:Local step 60500, global step 964903: loss -154.7652
[2017-11-02 12:05:47,514] A3C_AGENT_WORKER-Thread-4 INFO:Local step 60500, global step 965679: loss 46.6007
[2017-11-02 12:05:52,029] A3C_AGENT_WORKER-Thread-9 INFO:Local step 60500, global step 966360: loss -1.1751
[2017-11-02 12:05:52,878] A3C_AGENT_WORKER-Thread-11 INFO:Local step 60000, global step 966508: loss 905.8512
[2017-11-02 12:05:54,221] A3C_AGENT_WORKER-Thread-5 INFO:Local step 60500, global step 966727: loss 26.7521
[2017-11-02 12:05:54,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.33157072e-04   4.83613580e-01   5.04292428e-01   2.54056067e-03
   9.32025071e-03   8.59936536e-32   1.97249701e-30   4.48830149e-30
   1.19396474e-28], sum to 1.0000
[2017-11-02 12:05:54,680] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.95, 59.24999999999999, 4.1, 279.1666666666666, 0.0, 0.0, -8.9, 20.50787219725384, 18.0, 21.23772691367367, 21.5, 0.0, 0.0], 
actual action is [-8.95, 18], 
sim time next is 2589000.0000, 
raw observation next is [-4.0, 59.5, 4.1, 278.3333333333334, 0.0, 0.0, -8.95, 22.84503253929964, 18.0, 21.09978964482322, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 1.0, 0.23076923076923078, 0.595, 0.3727272727272727, 0.7731481481481484, 0.0, 0.0, 0.35083333333333333, 0.22845032539299642, 0.0, 0.4428270921176026, 0.5, 0.0, 0.0], 
reward next is -0.0572. 
=============================================
[2017-11-02 12:05:55,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-41.48108292]
 [-42.61655045]
 [-38.74022293]
 [-41.14829636]
 [-41.01076889]], R is [[-38.91029358]
 [-38.96948624]
 [-39.39211273]
 [-39.99819183]
 [-40.59820938]].
[2017-11-02 12:05:56,993] A3C_AGENT_WORKER-Thread-17 INFO:Local step 60500, global step 967228: loss 1.0324
[2017-11-02 12:05:57,108] A3C_AGENT_WORKER-Thread-7 INFO:Local step 60500, global step 967244: loss -44.5779
[2017-11-02 12:05:59,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.54016560e-06   2.14968652e-01   7.40442216e-01   7.33699044e-03
   3.72466706e-02   7.39033492e-25   1.41033168e-23   7.11324461e-23
   5.13612477e-21], sum to 1.0000
[2017-11-02 12:05:59,461] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.1333333333333334, 35.33333333333334, 4.433333333333334, 123.3333333333333, 0.0, 0.0, 5.225, 12.7796869537427, 20.0, 22.0623461023574, 22.7, 1.0, 37.61187944215106], 
actual action is [-4.866666666666666, 18.0], 
sim time next is 2571900.0000, 
raw observation next is [0.04166666666666663, 35.41666666666666, 4.391666666666666, 151.6666666666667, 0.0, 0.0, -4.866666666666666, 13.90234292155584, 18.0, 22.13334728122474, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.3344017094017094, 0.3541666666666666, 0.3992424242424242, 0.42129629629629645, 0.0, 0.0, 0.41888888888888887, 0.1390234292155584, 0.0, 0.5904781830321058, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 12:06:07,451] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.85561719e-24   3.42364820e-06   4.97604415e-05   9.53443873e-07
   2.71892873e-06   1.50446067e-04   3.10016971e-04   1.59728173e-02
   9.83509839e-01], sum to 1.0000
[2017-11-02 12:06:07,551] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-15.25, 83.0, 0.0, 0.0, 0.0, 0.0, -10.16666666666667, 23.16001013424003, 25.0, 19.85398736515046, 21.5, 0.0, 44.93125281998495], 
actual action is [-10.25, 25], 
sim time next is 2697600.0000, 
raw observation next is [-15.33333333333334, 83.0, 0.0, 0.0, 0.0, 0.0, -10.25, 23.27474566631559, 25.0, 19.84064234979137, 21.5, 0.0, 44.92933330573897], 
processed observation next is [0.3333333333333333, 0.21739130434782608, -0.059829059829059984, 0.83, 0.0, 0.0, 0.0, 0.0, 0.32916666666666666, 0.23274745666315588, 1.0, 0.26294890711305285, 0.5, 0.0, 0.5285803918322232], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:06:08,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   3.84972557e-30   3.33042910e-29   3.29213048e-29
   1.55870325e-29   1.14343718e-01   5.89903779e-02   6.10617936e-01
   2.16047987e-01], sum to 1.0000
[2017-11-02 12:06:08,836] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.8, 55.16666666666667, 2.0, 24.16666666666666, 58.08333333333334, 19.25, 2.2, 16.71451891679228, 20.0, 21.71824465274059, 22.7, 1.0, 57.17736111211427], 
actual action is [2.2, 22.0], 
sim time next is 2536800.0000, 
raw observation next is [-2.8, 55.33333333333333, 2.0, 23.33333333333334, 65.16666666666666, 20.5, 2.2, 16.26978909036804, 22.0, 21.75189068916037, 22.7, 1.0, 36.77808260244613], 
processed observation next is [0.0, 0.34782608695652173, 0.2615384615384615, 0.5533333333333332, 0.18181818181818182, 0.06481481481481483, 0.1723985890652557, 0.0205, 0.5366666666666667, 0.1626978909036804, 0.5714285714285714, 0.535984384165767, 0.6714285714285714, 1.0, 0.43268332473466037], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:06:08,852] A3C_AGENT_WORKER-Thread-2 INFO:Local step 60500, global step 969011: loss 47.4826
[2017-11-02 12:06:12,494] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.69542340e-07   5.29599309e-01   3.78845781e-01   4.50579002e-02
   4.64967079e-02   1.92834482e-09   9.02553765e-09   4.22952482e-08
   2.78600645e-08], sum to 1.0000
[2017-11-02 12:06:12,505] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.591666666666666, 51.08333333333333, 7.908333333333333, 234.1666666666667, 243.25, 149.0, -6.733333333333333, 18.64388472423117, 18.0, 21.77121556591471, 22.7, 1.0, 0.0], 
actual action is [-6.591666666666666, 18], 
sim time next is 2637000.0000, 
raw observation next is [-1.45, 50.5, 7.949999999999999, 235.0, 245.0, 147.0, -6.591666666666666, 19.18217652899918, 18.0, 21.69032886277363, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.29615384615384616, 0.505, 0.7227272727272727, 0.6527777777777778, 0.6481481481481481, 0.147, 0.3901388888888889, 0.19182176528999179, 0.0, 0.5271898375390899, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:06:19,405] A3C_AGENT_WORKER-Thread-12 INFO:Local step 60500, global step 970657: loss 10.9049
[2017-11-02 12:06:24,185] A3C_AGENT_WORKER-Thread-14 INFO:Local step 60500, global step 971302: loss 33.2413
[2017-11-02 12:06:27,134] A3C_AGENT_WORKER-Thread-15 INFO:Local step 60500, global step 971669: loss 19.7621
[2017-11-02 12:06:29,302] A3C_AGENT_WORKER-Thread-10 INFO:Local step 61000, global step 971959: loss -5.0341
[2017-11-02 12:06:30,544] A3C_AGENT_WORKER-Thread-8 INFO:Local step 61000, global step 972132: loss -82.4830
[2017-11-02 12:06:32,116] A3C_AGENT_WORKER-Thread-13 INFO:Local step 60500, global step 972346: loss 99.0173
[2017-11-02 12:06:36,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.81439179e-03   8.13338161e-01   1.78252771e-01   3.21243214e-03
   1.38224033e-03   3.34951128e-33   1.63210657e-30   9.64692008e-31
   7.82108836e-29], sum to 1.0000
[2017-11-02 12:06:36,745] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.0, 59.0, 2.475, 70.0, 0.0, 0.0, -1.0, 16.99380000012185, 20.0, 21.3592331136552, 21.5, 0.0, 39.69535747574059], 
actual action is [-11.0, 18.0], 
sim time next is 2767800.0000, 
raw observation next is [-6.0, 59.0, 2.516666666666667, 70.0, 0.0, 0.0, -11.0, 18.9867189109807, 18.0, 21.37836749364235, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.0, 0.1794871794871795, 0.59, 0.22878787878787882, 0.19444444444444445, 0.0, 0.0, 0.31666666666666665, 0.189867189109807, 0.0, 0.482623927663193, 0.5, 0.0, 0.0], 
reward next is -0.0174. 
=============================================
[2017-11-02 12:06:38,241] A3C_AGENT_WORKER-Thread-16 INFO:Local step 61000, global step 973079: loss 7.5476
[2017-11-02 12:06:40,972] A3C_AGENT_WORKER-Thread-6 INFO:Local step 61000, global step 973377: loss -21.2293
[2017-11-02 12:06:42,530] A3C_AGENT_WORKER-Thread-3 INFO:Local step 61000, global step 973540: loss -23.7307
[2017-11-02 12:06:44,428] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.63883151e-32   1.69256677e-12   3.01853377e-13   3.74106670e-13
   4.05161880e-14   2.65029841e-03   1.94503203e-01   2.51207855e-02
   7.77725697e-01], sum to 1.0000
[2017-11-02 12:06:44,478] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.75, 62.75, 2.975, 60.0, 0.0, 0.0, -1.666666666666666, 16.96181443382966, 25.0, 21.03171603187457, 21.5, 0.0, 39.94728381784338], 
actual action is [-1.75, 25], 
sim time next is 2782200.0000, 
raw observation next is [-6.833333333333334, 63.16666666666666, 3.016666666666667, 60.0, 0.0, 0.0, -1.75, 17.08963794344387, 25.0, 21.03671509466122, 21.5, 0.0, 41.37175480882004], 
processed observation next is [0.5, 0.17391304347826086, 0.1581196581196581, 0.6316666666666666, 0.2742424242424243, 0.16666666666666666, 0.0, 0.0, 0.4708333333333333, 0.1708963794344387, 1.0, 0.4338164420944598, 0.5, 0.0, 0.48672652716258874], 
reward next is -0.5042. 
=============================================
[2017-11-02 12:06:44,887] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  6.95935935e-02   8.78106356e-01   4.80064116e-02   3.62273096e-03
   6.70956390e-04   3.67614420e-27   1.33554881e-24   1.19747446e-25
   1.68001151e-23], sum to 1.0000
[2017-11-02 12:06:44,996] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-5.0, 70.5, 3.6, 265.8333333333333, 0.0, 0.0, 0.0, 12.95283712581218, 25.0, 22.01574280458355, 21.5, 0.0, 41.35430061824712], 
actual action is [0.0, 23.0], 
sim time next is 2597400.0000, 
raw observation next is [-5.0, 71.0, 3.6, 265.0, 0.0, 0.0, 0.0, 12.78534064624378, 23.0, 22.00799532690617, 21.5, 0.0, 45.9751688645916], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.20512820512820512, 0.71, 0.32727272727272727, 0.7361111111111112, 0.0, 0.0, 0.5, 0.1278534064624378, 0.7142857142857143, 0.5725707609865955, 0.5, 0.0, 0.5408843395834306], 
reward next is -0.4868. 
=============================================
[2017-11-02 12:06:45,242] A3C_AGENT_WORKER-Thread-11 INFO:Local step 60500, global step 973867: loss 97.1396
[2017-11-02 12:06:45,568] A3C_AGENT_WORKER-Thread-4 INFO:Local step 61000, global step 973907: loss -178.3369
[2017-11-02 12:06:53,694] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.68854880e-04   9.23289955e-01   6.22770637e-02   1.01919239e-02
   4.07229504e-03   1.10526418e-17   9.30407141e-16   5.28224410e-16
   2.78566245e-15], sum to 1.0000
[2017-11-02 12:06:54,059] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-14.58333333333333, 86.33333333333333, 1.85, 139.1666666666667, 73.33333333333333, 302.5, -9.66666666666667, 16.79112799951275, 25.0, 21.1361261059515, 22.7, 1.0, 61.97442860479494], 
actual action is [-9.58333333333333, 23.0], 
sim time next is 2709000.0000, 
raw observation next is [-14.5, 87.0, 1.8, 135.0, 80.0, 330.0, -9.58333333333333, 16.23419981232684, 23.0, 21.2620305775886, 22.7, 1.0, 61.68870287059317], 
processed observation next is [0.3333333333333333, 0.34782608695652173, -0.038461538461538464, 0.87, 0.16363636363636364, 0.375, 0.21164021164021163, 0.33, 0.34027777777777785, 0.16234199812326838, 0.7142857142857143, 0.4660043682269429, 0.6714285714285714, 1.0, 0.7257494455363902], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:06:54,293] A3C_AGENT_WORKER-Thread-9 INFO:Local step 61000, global step 975079: loss -47.8472
[2017-11-02 12:06:55,042] A3C_AGENT_WORKER-Thread-5 INFO:Local step 61000, global step 975183: loss -25.1064
[2017-11-02 12:06:57,193] A3C_AGENT_WORKER-Thread-7 INFO:Local step 61000, global step 975420: loss -4.2514
[2017-11-02 12:06:58,548] A3C_AGENT_WORKER-Thread-17 INFO:Local step 61000, global step 975600: loss 84.6959
[2017-11-02 12:07:00,773] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-78.84500122]
 [-79.17220306]
 [-81.14492798]
 [-82.40753174]
 [-80.8964386 ]], R is [[-82.04690552]
 [-82.22644043]
 [-82.4041748 ]
 [-82.58013153]
 [-82.7543335 ]].
[2017-11-02 12:07:02,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.52406339e-17   1.23330187e-02   3.49114212e-04   3.52174626e-04
   6.41161969e-05   2.31060461e-04   3.89272384e-02   4.43993546e-02
   9.03343916e-01], sum to 1.0000
[2017-11-02 12:07:02,353] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 60.25, 1.95, 52.5, 0.0, 0.0, -11.0, 16.82612861086946, 18.0, 21.98345574910649, 21.5, 0.0, 0.0], 
actual action is [-1.0, 23.0], 
sim time next is 2757000.0000, 
raw observation next is [-6.0, 59.83333333333334, 2.0, 51.66666666666667, 0.0, 0.0, -1.0, 15.45237017683777, 23.0, 21.74980591550366, 21.5, 0.0, 70.53542207634807], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.1794871794871795, 0.5983333333333334, 0.18181818181818182, 0.14351851851851855, 0.0, 0.0, 0.48333333333333334, 0.1545237017683777, 0.7142857142857143, 0.5356865593576658, 0.5, 0.0, 0.8298284950158596], 
reward next is -0.7468. 
=============================================
[2017-11-02 12:07:07,263] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.30301009e-03   9.63579476e-01   2.89470106e-02   4.60109627e-03
   5.69393800e-04   3.86796366e-36   3.49331317e-33   1.27690847e-33
   7.16888278e-32], sum to 1.0000
[2017-11-02 12:07:07,279] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.0, 44.0, 4.308333333333333, 114.1666666666667, 0.0, 0.0, -3.0, 15.78919925712701, 18.0, 22.13679408205357, 21.5, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 2842200.0000, 
raw observation next is [2.0, 44.0, 4.35, 115.0, 0.0, 0.0, -3.0, 17.30923943782495, 18.0, 22.02765188125928, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.9130434782608695, 0.38461538461538464, 0.44, 0.39545454545454545, 0.3194444444444444, 0.0, 0.0, 0.45, 0.1730923943782495, 0.0, 0.5753788401798973, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 12:07:09,969] A3C_AGENT_WORKER-Thread-2 INFO:Local step 61000, global step 977207: loss -71.3581
[2017-11-02 12:07:13,529] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.74228565e-13   9.76367533e-01   1.79670360e-02   5.16905123e-03
   4.96331370e-04   5.59422910e-14   1.81212077e-11   4.20405932e-11
   2.28555286e-09], sum to 1.0000
[2017-11-02 12:07:13,557] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 84.83333333333334, 5.366666666666666, 130.0, 0.0, 0.0, -4.0, 20.12936277198874, 18.0, 21.32137962790907, 21.5, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 2861700.0000, 
raw observation next is [1.0, 85.41666666666667, 5.233333333333333, 130.0, 0.0, 0.0, -4.0, 22.11495649190299, 18.0, 21.09115841808032, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.358974358974359, 0.8541666666666667, 0.47575757575757577, 0.3611111111111111, 0.0, 0.0, 0.43333333333333335, 0.2211495649190299, 0.0, 0.4415940597257598, 0.5, 0.0, 0.0], 
reward next is -0.0584. 
=============================================
[2017-11-02 12:07:19,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.10424904e-02   9.69346225e-01   8.01466219e-03   1.43826602e-03
   1.58257477e-04   3.91094518e-23   8.09083290e-21   1.07399305e-21
   9.08733351e-21], sum to 1.0000
[2017-11-02 12:07:19,681] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-7.5, 62.75, 1.95, 65.0, 112.75, 794.5, -12.66666666666667, 17.15941025763891, 18.0, 22.13243633975186, 22.7, 1.0, 0.0], 
actual action is [-12.5, 18], 
sim time next is 2722800.0000, 
raw observation next is [-7.333333333333334, 62.33333333333334, 1.9, 63.33333333333334, 112.8333333333333, 796.0, -12.5, 18.02310736807169, 18.0, 21.92681542353909, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.14529914529914528, 0.6233333333333334, 0.17272727272727273, 0.17592592592592596, 0.2985008818342151, 0.796, 0.2916666666666667, 0.1802310736807169, 0.0, 0.5609736319341556, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:07:23,218] A3C_AGENT_WORKER-Thread-12 INFO:Local step 61000, global step 978954: loss 1.9657
[2017-11-02 12:07:25,614] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  7.55635556e-04   9.93102789e-01   5.51771093e-03   5.23381517e-04
   1.00494515e-04   7.71824129e-28   3.92716332e-25   6.59728751e-26
   3.94456682e-24], sum to 1.0000
[2017-11-02 12:07:25,694] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.583333333333334, 26.5, 4.683333333333334, 127.5, 116.0833333333333, 0.0, 11.5, 11.48648114832974, 21.0, 22.70238598747616, 22.7, 1.0, 51.24541213562477], 
actual action is [11.583333333333334, 19.0], 
sim time next is 2817600.0000, 
raw observation next is [6.666666666666666, 26.0, 4.766666666666666, 130.0, 114.1666666666667, 0.0, 11.58333333333333, 11.26099974633942, 19.0, 22.87423693383976, 22.7, 1.0, 42.77845589553367], 
processed observation next is [0.5, 0.6086956521739131, 0.5042735042735043, 0.26, 0.43333333333333324, 0.3611111111111111, 0.30202821869488544, 0.0, 0.6930555555555554, 0.1126099974633942, 0.14285714285714285, 0.6963195619771086, 0.6714285714285714, 1.0, 0.5032759517121608], 
reward next is -0.4642. 
=============================================
[2017-11-02 12:07:25,821] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.87102053e-03   9.73035693e-01   2.18623597e-02   2.68789451e-03
   5.42987953e-04   3.03700158e-25   7.78769544e-23   1.77583997e-23
   2.00908620e-21], sum to 1.0000
[2017-11-02 12:07:25,840] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 98.83333333333334, 2.683333333333334, 145.0, 116.3333333333333, 0.0, -4.0, 9.654705076075803, 18.0, 23.04688373893925, 22.7, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 2894100.0000, 
raw observation next is [1.0, 99.41666666666666, 2.641666666666667, 147.5, 123.6666666666667, 0.0, -4.0, 10.19877057549948, 18.0, 23.07185130688267, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.358974358974359, 0.9941666666666665, 0.2401515151515152, 0.4097222222222222, 0.32716049382716056, 0.0, 0.43333333333333335, 0.1019877057549948, 0.0, 0.7245501866975245, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0102. 
=============================================
[2017-11-02 12:07:27,329] A3C_AGENT_WORKER-Thread-8 INFO:Local step 61500, global step 979519: loss 26.8011
[2017-11-02 12:07:27,444] A3C_AGENT_WORKER-Thread-14 INFO:Local step 61000, global step 979535: loss -16.5475
[2017-11-02 12:07:28,258] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.23670789e-24   1.44728238e-08   2.46237725e-10   3.35316330e-10
   6.31638630e-11   2.69345776e-03   1.47268891e-01   2.70820260e-02
   8.22955608e-01], sum to 1.0000
[2017-11-02 12:07:28,322] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [6.050000000000001, 27.75, 4.141666666666667, 120.8333333333333, 43.50000000000001, 63.5, 1.1, 12.1017948080283, 18.0, 23.04020214955954, 22.7, 1.0, 0.0], 
actual action is [11.05, 23.0], 
sim time next is 2826000.0000, 
raw observation next is [6.0, 28.0, 4.1, 120.0, 38.0, 61.0, 11.05, 11.72501313319298, 23.0, 22.99685731061666, 22.7, 1.0, 25.50040867604805], 
processed observation next is [0.5, 0.7391304347826086, 0.48717948717948717, 0.28, 0.3727272727272727, 0.3333333333333333, 0.10052910052910052, 0.061, 0.6841666666666666, 0.11725013133192981, 0.7142857142857143, 0.7138367586595231, 0.6714285714285714, 1.0, 0.3000048079535065], 
reward next is -0.2817. 
=============================================
[2017-11-02 12:07:28,640] A3C_AGENT_WORKER-Thread-10 INFO:Local step 61500, global step 979708: loss 37.2452
[2017-11-02 12:07:29,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 61000, global step 979867: loss 13.7270
[2017-11-02 12:07:34,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.58136508e-14   9.92583394e-01   3.96031793e-03   2.25280551e-03
   5.09370759e-04   4.60858836e-08   1.54682803e-05   1.54207260e-06
   6.77117088e-04], sum to 1.0000
[2017-11-02 12:07:34,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.0, 59.0, 2.05, 65.0, 0.0, 0.0, -1.0, 21.77238240921512, 23.0, 20.28111472659827, 21.5, 0.0, 48.5883175660866], 
actual action is [-1.0, 21.0], 
sim time next is 2777700.0000, 
raw observation next is [-6.0, 59.0, 2.141666666666667, 64.16666666666666, 0.0, 0.0, -1.0, 20.98325383175515, 21.0, 20.36918982459049, 21.5, 0.0, 46.88793382509285], 
processed observation next is [0.5, 0.13043478260869565, 0.1794871794871795, 0.59, 0.19469696969696973, 0.17824074074074073, 0.0, 0.0, 0.48333333333333334, 0.2098325383175515, 0.42857142857142855, 0.3384556892272127, 0.5, 0.0, 0.5516227508834453], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:07:35,461] A3C_AGENT_WORKER-Thread-16 INFO:Local step 61500, global step 980648: loss -16.9249
[2017-11-02 12:07:38,061] A3C_AGENT_WORKER-Thread-13 INFO:Local step 61000, global step 981025: loss -8.4898
[2017-11-02 12:07:40,449] A3C_AGENT_WORKER-Thread-6 INFO:Local step 61500, global step 981421: loss -74.2680
[2017-11-02 12:07:41,443] A3C_AGENT_WORKER-Thread-3 INFO:Local step 61500, global step 981573: loss 65.6992
[2017-11-02 12:07:43,631] A3C_AGENT_WORKER-Thread-4 INFO:Local step 61500, global step 981860: loss 9.8080
[2017-11-02 12:07:45,517] A3C_AGENT_WORKER-Thread-11 INFO:Local step 61000, global step 982089: loss 105.7676
[2017-11-02 12:07:47,028] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.41336848e-03   8.95708859e-01   8.93664062e-02   1.08070206e-02
   7.04431441e-04   3.79637956e-29   8.03418470e-27   9.34348446e-28
   4.51363623e-26], sum to 1.0000
[2017-11-02 12:07:47,079] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.0, 93.0, 6.166666666666667, 130.0, 17.5, 48.49999999999999, 7.0, 15.48487217340981, 19.0, 21.38892497779873, 22.7, 1.0, 52.86955915614131], 
actual action is [-3.0, 18], 
sim time next is 2879100.0000, 
raw observation next is [2.0, 93.0, 6.300000000000001, 130.0, 26.25, 59.25, -3.0, 16.65459255367515, 18.0, 21.48817411072162, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.38461538461538464, 0.93, 0.5727272727272728, 0.3611111111111111, 0.06944444444444445, 0.05925, 0.45, 0.16654592553675152, 0.0, 0.4983105872459456, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:07:47,591] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.15719512e-05   9.45477366e-01   5.25452830e-02   1.87030958e-03
   5.54300314e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.62548782e-37], sum to 1.0000
[2017-11-02 12:07:47,763] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.416666666666667, 97.08333333333333, 5.1, 130.0, 0.0, 0.0, 6.333333333333333, 22.10196322239348, 25.0, 19.99877878471303, 21.5, 0.0, 67.64239321591977], 
actual action is [6.416666666666667, 23.0], 
sim time next is 2874600.0000, 
raw observation next is [1.5, 96.5, 5.1, 130.0, 0.0, 0.0, 6.416666666666667, 20.12663994163951, 23.0, 20.12522405437518, 21.5, 0.0, 62.84065958754328], 
processed observation next is [0.6666666666666666, 0.2608695652173913, 0.3717948717948718, 0.965, 0.4636363636363636, 0.3611111111111111, 0.0, 0.0, 0.6069444444444444, 0.2012663994163951, 0.7142857142857143, 0.3036034363393116, 0.5, 0.0, 0.7393018775005091], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:07:53,330] A3C_AGENT_WORKER-Thread-9 INFO:Local step 61500, global step 982960: loss 55.3820
[2017-11-02 12:07:54,641] A3C_AGENT_WORKER-Thread-17 INFO:Local step 61500, global step 983134: loss 9.3527
[2017-11-02 12:07:55,403] A3C_AGENT_WORKER-Thread-5 INFO:Local step 61500, global step 983247: loss -12.9023
[2017-11-02 12:07:56,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-48.82518005]
 [-49.85182953]
 [-49.46849823]
 [-49.6190834 ]
 [-49.18856812]], R is [[-50.57964325]
 [-51.07384872]
 [-51.56311035]
 [-52.04748154]
 [-52.52700806]].
[2017-11-02 12:07:57,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.08872289e-02   9.32792246e-01   3.66326086e-02   1.93866808e-02
   3.01177352e-04   2.47163141e-26   3.83934382e-24   1.86995422e-25
   5.53631616e-24], sum to 1.0000
[2017-11-02 12:07:58,030] A3C_AGENT_WORKER-Thread-7 INFO:Local step 61500, global step 983565: loss -7.5004
[2017-11-02 12:07:58,385] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-4.0, 71.0, 5.925000000000001, 280.0, 136.5, 111.25, 1.0, 14.2003664470995, 21.0, 21.82326674624114, 22.7, 1.0, 64.56649172665762], 
actual action is [1.0, 19.0], 
sim time next is 2971200.0000, 
raw observation next is [-4.0, 71.0, 5.833333333333334, 280.0, 142.3333333333333, 118.1666666666667, 1.0, 13.96158235417334, 19.0, 21.88820255398931, 22.7, 1.0, 53.83068409941555], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.23076923076923078, 0.71, 0.5303030303030304, 0.7777777777777778, 0.3765432098765431, 0.1181666666666667, 0.5166666666666667, 0.1396158235417334, 0.14285714285714285, 0.5554575077127585, 0.6714285714285714, 1.0, 0.633302165875477], 
reward next is -0.5839. 
=============================================
[2017-11-02 12:08:09,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.56182808e-02   8.90220761e-01   2.45432165e-02   3.86531651e-02
   9.64626088e-04   2.15294563e-20   8.43254438e-19   9.96575828e-20
   1.51440671e-18], sum to 1.0000
[2017-11-02 12:08:09,386] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.449999999999999, 25.75, 4.475, 127.5, 77.0, 57.0, 1.5, 10.35426091559799, 18.0, 23.66628388475975, 22.7, 1.0, 0.0], 
actual action is [1.4499999999999993, 18], 
sim time next is 2823600.0000, 
raw observation next is [6.4, 26.0, 4.433333333333334, 126.6666666666667, 75.0, 63.33333333333334, 1.449999999999999, 10.78748866537887, 18.0, 23.58071446201334, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.4974358974358974, 0.26, 0.40303030303030307, 0.35185185185185197, 0.1984126984126984, 0.06333333333333334, 0.5241666666666667, 0.10787488665378869, 0.0, 0.7972449231447628, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0108. 
=============================================
[2017-11-02 12:08:10,079] A3C_AGENT_WORKER-Thread-2 INFO:Local step 61500, global step 985055: loss -91.7153
[2017-11-02 12:08:25,313] A3C_AGENT_WORKER-Thread-12 INFO:Local step 61500, global step 987082: loss 23.3447
[2017-11-02 12:08:26,793] A3C_AGENT_WORKER-Thread-8 INFO:Local step 62000, global step 987270: loss -13.5548
[2017-11-02 12:08:27,875] A3C_AGENT_WORKER-Thread-10 INFO:Local step 62000, global step 987411: loss -114.1269
[2017-11-02 12:08:28,237] A3C_AGENT_WORKER-Thread-14 INFO:Local step 61500, global step 987459: loss 2.9149
[2017-11-02 12:08:30,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-56.64728546]
 [-56.93453598]
 [-56.79751205]
 [-58.1096344 ]
 [-58.34884644]], R is [[-56.55690765]
 [-56.61956024]
 [-57.0533638 ]
 [-57.48283005]
 [-57.90800095]].
[2017-11-02 12:08:33,279] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.30236866e-04   5.73933497e-03   1.22100580e-03
   9.92509365e-01], sum to 1.0000
[2017-11-02 12:08:33,328] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 77.0, 2.325, 57.5, 0.0, 0.0, -1.0, 18.55469415347854, 21.0, 21.07697500074303, 21.5, 0.0, 44.52944475992945], 
actual action is [-1.0, 25], 
sim time next is 3039600.0000, 
raw observation next is [-6.0, 77.0, 2.233333333333333, 56.66666666666667, 0.0, 0.0, -1.0, 18.60264833300873, 25.0, 21.08761257216301, 21.5, 0.0, 38.98000045819322], 
processed observation next is [1.0, 0.17391304347826086, 0.1794871794871795, 0.77, 0.203030303030303, 0.1574074074074074, 0.0, 0.0, 0.48333333333333334, 0.1860264833300873, 1.0, 0.44108751030900145, 0.5, 0.0, 0.45858824068462606], 
reward next is -0.4716. 
=============================================
[2017-11-02 12:08:33,726] A3C_AGENT_WORKER-Thread-15 INFO:Local step 61500, global step 988215: loss 8.9302
[2017-11-02 12:08:36,262] A3C_AGENT_WORKER-Thread-16 INFO:Local step 62000, global step 988694: loss -15.9068
[2017-11-02 12:08:37,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  5.13163221e-04   9.11987901e-01   1.51356813e-02   7.19882622e-02
   3.75003088e-04   2.13880715e-34   1.02692127e-31   1.21215662e-32
   1.72312019e-29], sum to 1.0000
[2017-11-02 12:08:37,434] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-1.666666666666667, 58.33333333333334, 2.766666666666667, 243.3333333333333, 0.0, 0.0, 3.416666666666667, 16.19922157603093, 25.0, 21.87477543457861, 22.7, 1.0, 57.09404484592758], 
actual action is [3.333333333333333, 23.0], 
sim time next is 3001500.0000, 
raw observation next is [-1.75, 58.75, 2.6, 242.5, 0.0, 0.0, 3.333333333333333, 14.72262218668933, 23.0, 21.90936967770731, 22.7, 1.0, 75.21810761611317], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.28846153846153844, 0.5875, 0.23636363636363636, 0.6736111111111112, 0.0, 0.0, 0.5555555555555556, 0.1472262218668933, 0.7142857142857143, 0.5584813825296158, 0.6714285714285714, 1.0, 0.8849189131307432], 
reward next is -0.8111. 
=============================================
[2017-11-02 12:08:37,658] A3C_AGENT_WORKER-Thread-13 INFO:Local step 61500, global step 988939: loss 9.4888
[2017-11-02 12:08:38,952] A3C_AGENT_WORKER-Thread-3 INFO:Local step 62000, global step 989148: loss -46.8147
[2017-11-02 12:08:39,837] A3C_AGENT_WORKER-Thread-6 INFO:Local step 62000, global step 989297: loss 28.0747
[2017-11-02 12:08:40,749] A3C_AGENT_WORKER-Thread-4 INFO:Local step 62000, global step 989465: loss -177.4362
[2017-11-02 12:08:40,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-66.47434235]
 [-67.47382355]
 [-67.34022522]
 [-65.63540649]
 [-64.03041077]], R is [[-67.71822357]
 [-67.05535126]
 [-66.38479614]
 [-65.72094727]
 [-65.06373596]].
[2017-11-02 12:08:41,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  3.25196065e-16   4.72398221e-01   1.09756179e-02   5.15513539e-01
   1.11128297e-03   3.14533252e-12   7.15282444e-10   6.03268338e-11
   1.36362337e-06], sum to 1.0000
[2017-11-02 12:08:41,962] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.958333333333333, 65.0, 0.0, 0.0, 0.0, 0.0, -8.916666666666668, 28.71864738973529, 18.0, 20.55293324093802, 21.5, 0.0, 0.0], 
actual action is [-8.958333333333332, 18], 
sim time next is 3016800.0000, 
raw observation next is [-4.0, 65.0, 0.0, 0.0, 0.0, 0.0, -8.958333333333332, 29.7443133009631, 18.0, 20.4266534859353, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.23076923076923078, 0.65, 0.0, 0.0, 0.0, 0.0, 0.3506944444444445, 0.297443133009631, 0.0, 0.346664783705043, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:08:44,346] A3C_AGENT_WORKER-Thread-11 INFO:Local step 61500, global step 990058: loss -4.6825
[2017-11-02 12:08:45,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.81282815e-02   6.81339085e-01   1.63795371e-02   2.78513849e-01
   5.63923595e-03   3.93772124e-26   5.52616076e-24   3.19547757e-25
   2.30475647e-22], sum to 1.0000
[2017-11-02 12:08:45,797] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-4.0, 54.0, 2.166666666666667, 41.66666666666667, 107.6666666666667, 774.3333333333333, -9.0, 15.22786456949572, 18.0, 22.40101768588702, 22.7, 1.0, 0.0], 
actual action is [-9.0, 18], 
sim time next is 3063300.0000, 
raw observation next is [-4.0, 54.0, 2.383333333333333, 45.83333333333333, 108.0833333333333, 778.1666666666666, -9.0, 16.30687359462323, 18.0, 22.3184886689834, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.23076923076923078, 0.54, 0.21666666666666662, 0.1273148148148148, 0.2859347442680775, 0.7781666666666667, 0.35, 0.1630687359462323, 0.0, 0.6169269527119141, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:08:50,792] A3C_AGENT_WORKER-Thread-5 INFO:Local step 62000, global step 991094: loss -76.3102
[2017-11-02 12:08:51,776] A3C_AGENT_WORKER-Thread-9 INFO:Local step 62000, global step 991239: loss -36.0853
[2017-11-02 12:08:51,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.97102896e-03   8.13432992e-01   2.91147940e-02   1.45778209e-01
   2.70297867e-03   4.20483850e-36   2.48860015e-33   1.04423548e-34
   2.13126365e-31], sum to 1.0000
[2017-11-02 12:08:52,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  6.01455342e-21   2.87136203e-07   2.32786359e-08   1.18992864e-06
   2.89212618e-08   3.22565739e-03   9.75690782e-02   1.11553641e-02
   8.88048351e-01], sum to 1.0000
[2017-11-02 12:08:52,129] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.0, 76.41666666666666, 3.016666666666667, 20.83333333333333, 0.0, 0.0, -1.0, 18.95175235932111, 25.0, 20.79885978228988, 21.5, 0.0, 45.12222396720922], 
actual action is [-1.0, 23.0], 
sim time next is 3049200.0000, 
raw observation next is [-6.0, 77.0, 3.1, 20.0, 0.0, 0.0, -1.0, 18.91879585839758, 23.0, 20.8032056379008, 21.5, 0.0, 45.18233478719799], 
processed observation next is [1.0, 0.30434782608695654, 0.1794871794871795, 0.77, 0.2818181818181818, 0.05555555555555555, 0.0, 0.0, 0.48333333333333334, 0.1891879585839758, 0.7142857142857143, 0.40045794827154274, 0.5, 0.0, 0.531556879849388], 
reward next is -0.5779. 
=============================================
[2017-11-02 12:08:52,206] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 71.0, 6.016666666666667, 280.0, 130.6666666666667, 104.3333333333333, 1.0, 12.41633802997799, 21.0, 22.08818917542647, 22.7, 1.0, 52.54025144909088], 
actual action is [1.0, 25], 
sim time next is 2970900.0000, 
raw observation next is [-4.0, 71.0, 5.925000000000001, 280.0, 136.5, 111.25, 1.0, 12.55488367694663, 25.0, 22.14175872268723, 22.7, 1.0, 44.18474304736413], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.23076923076923078, 0.71, 0.5386363636363637, 0.7777777777777778, 0.3611111111111111, 0.11125, 0.5166666666666667, 0.1255488367694663, 1.0, 0.5916798175267469, 0.6714285714285714, 1.0, 0.519820506439578], 
reward next is -0.4804. 
=============================================
[2017-11-02 12:08:53,296] A3C_AGENT_WORKER-Thread-17 INFO:Local step 62000, global step 991490: loss -50.2996
[2017-11-02 12:08:53,931] A3C_AGENT_WORKER-Thread-7 INFO:Local step 62000, global step 991584: loss -21.9173
[2017-11-02 12:08:54,883] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.36204206e-03   7.54240572e-01   9.29264948e-02   1.41152173e-01
   7.31865782e-03   2.63596356e-31   1.25489849e-29   1.16823525e-30
   2.56045790e-28], sum to 1.0000
[2017-11-02 12:08:54,924] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [5.166666666666666, 100.0, 5.533333333333333, 167.5, 0.0, 0.0, 0.0, 15.77393451316563, 18.0, 21.17827277971206, 21.5, 0.0, 0.0], 
actual action is [0.16666666666666607, 18], 
sim time next is 3134400.0000, 
raw observation next is [5.333333333333334, 100.0, 5.666666666666666, 170.0, 0.0, 0.0, 0.1666666666666661, 17.27837834758775, 18.0, 21.12059875197417, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.47008547008547014, 1.0, 0.5151515151515151, 0.4722222222222222, 0.0, 0.0, 0.5027777777777778, 0.1727837834758775, 0.0, 0.4457998217105959, 0.5, 0.0, 0.0], 
reward next is -0.0542. 
=============================================
[2017-11-02 12:09:02,954] A3C_AGENT_WORKER-Thread-2 INFO:Local step 62000, global step 993127: loss -81.0755
[2017-11-02 12:09:03,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.00075207e-02   5.75959802e-01   1.54998541e-01   2.26902261e-01
   1.21319070e-02   1.50432263e-30   2.80743530e-29   5.75839248e-30
   2.49004311e-27], sum to 1.0000
[2017-11-02 12:09:03,445] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.09999999999999999, 73.66666666666667, 7.483333333333333, 126.6666666666667, 23.66666666666666, 220.6666666666666, 4.95, 12.31041992431875, 19.0, 22.78982701799514, 22.7, 1.0, 32.68438615971247], 
actual action is [-5.1, 18], 
sim time next is 3086100.0000, 
raw observation next is [-0.15, 74.5, 7.375, 125.0, 19.5, 187.5, -5.1, 13.17225495459628, 18.0, 22.8382166118136, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.3294871794871795, 0.745, 0.6704545454545454, 0.3472222222222222, 0.051587301587301584, 0.1875, 0.415, 0.1317225495459628, 0.0, 0.6911738016876571, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0132. 
=============================================
[2017-11-02 12:09:09,469] A3C_AGENT_WORKER-Thread-8 INFO:Local step 62500, global step 994326: loss 1.3565
[2017-11-02 12:09:10,428] A3C_AGENT_WORKER-Thread-10 INFO:Local step 62500, global step 994510: loss 9.9267
[2017-11-02 12:09:13,945] A3C_AGENT_WORKER-Thread-12 INFO:Local step 62000, global step 995260: loss -24.6597
[2017-11-02 12:09:14,440] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.31500801e-02   8.62766147e-01   8.45513716e-02   3.79790924e-02
   1.55329809e-03   7.42721170e-25   8.05697011e-24   5.11226477e-24
   6.47213647e-22], sum to 1.0000
[2017-11-02 12:09:14,488] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 98.66666666666667, 5.1, 270.0, 0.0, 0.0, 2.0, 13.97259062522835, 22.5, 21.04041058861267, 20.8, 0.0, 48.03549661631165], 
actual action is [2.0, 20.5], 
sim time next is 3219300.0000, 
raw observation next is [-3.0, 98.0, 5.1, 270.0, 0.0, 0.0, 2.0, 13.21128496278087, 20.5, 21.08750222651286, 20.8, 0.0, 50.88068888929702], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.2564102564102564, 0.98, 0.4636363636363636, 0.75, 0.0, 0.0, 0.5333333333333333, 0.1321128496278087, 0.35714285714285715, 0.4410717466446944, 0.4000000000000001, 0.0, 0.5985963398740826], 
reward next is -0.5387. 
=============================================
[2017-11-02 12:09:14,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.15924941e-02   8.49525988e-01   8.16834271e-02   4.36393432e-02
   3.55870859e-03   3.13327953e-22   2.31774271e-21   1.47405645e-21
   5.93427902e-20], sum to 1.0000
[2017-11-02 12:09:14,719] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.0, 100.0, 3.1, 320.0, 0.0, 0.0, -2.916666666666667, 15.44733496121789, 18.0, 21.06741182691193, 21.5, 0.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 3189900.0000, 
raw observation next is [2.0, 99.41666666666666, 3.058333333333334, 320.0, 0.0, 0.0, -3.0, 16.21852707168181, 18.0, 20.98188644394216, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.38461538461538464, 0.9941666666666665, 0.27803030303030307, 0.8888888888888888, 0.0, 0.0, 0.45, 0.1621852707168181, 0.0, 0.4259837777060227, 0.5, 0.0, 0.0], 
reward next is -0.0740. 
=============================================
[2017-11-02 12:09:14,989] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  6.42912611e-02   6.81977034e-01   8.58728513e-02   1.25498369e-01
   4.23605666e-02   2.88232242e-17   1.71282887e-16   3.69775773e-17
   1.41779816e-16], sum to 1.0000
[2017-11-02 12:09:15,026] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [7.333333333333333, 97.66666666666666, 4.266666666666667, 196.6666666666667, 112.8333333333333, 820.1666666666667, 2.416666666666667, 8.078442986995723, 18.0, 23.37339937587989, 22.7, 1.0, 0.0], 
actual action is [2.333333333333333, 18], 
sim time next is 3156300.0000, 
raw observation next is [7.25, 98.25, 4.225, 197.5, 112.75, 818.75, 2.333333333333333, 8.09943221814909, 18.0, 23.33835845856678, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5192307692307693, 0.9825, 0.38409090909090904, 0.5486111111111112, 0.29828042328042326, 0.81875, 0.538888888888889, 0.0809943221814909, 0.0, 0.7626226369381115, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0081. 
=============================================
[2017-11-02 12:09:16,139] A3C_AGENT_WORKER-Thread-14 INFO:Local step 62000, global step 995707: loss 72.6315
[2017-11-02 12:09:17,244] A3C_AGENT_WORKER-Thread-16 INFO:Local step 62500, global step 995922: loss -23.6986
[2017-11-02 12:09:18,876] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   9.68284872e-28   3.19676974e-28   2.22292175e-26
   2.46906626e-28   1.24947550e-02   9.38330498e-03   1.02187945e-02
   9.67903078e-01], sum to 1.0000
[2017-11-02 12:09:18,985] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.416666666666667, 100.0, 2.375, 335.8333333333334, 0.0, 0.0, -1.5, 13.83149222426347, 18.0, 21.3425584042084, 22.7, 1.0, 0.0], 
actual action is [8.416666666666668, 23.0], 
sim time next is 3181200.0000, 
raw observation next is [3.333333333333333, 100.0, 2.2, 336.6666666666667, 0.0, 0.0, 8.416666666666668, 10.7567280641812, 23.0, 21.28636670118364, 22.7, 1.0, 110.3586179181324], 
processed observation next is [0.0, 0.8260869565217391, 0.41880341880341876, 1.0, 0.2, 0.9351851851851852, 0.0, 0.0, 0.6402777777777778, 0.107567280641812, 0.7142857142857143, 0.46948095731194833, 0.6714285714285714, 1.0, 1.298336681389793], 
reward next is -1.1793. 
=============================================
[2017-11-02 12:09:21,016] A3C_AGENT_WORKER-Thread-15 INFO:Local step 62000, global step 996586: loss 8.3346
[2017-11-02 12:09:22,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 62500, global step 996801: loss -1.2552
[2017-11-02 12:09:23,061] A3C_AGENT_WORKER-Thread-4 INFO:Local step 62500, global step 996991: loss -93.3283
[2017-11-02 12:09:23,899] A3C_AGENT_WORKER-Thread-6 INFO:Local step 62500, global step 997176: loss -165.7089
[2017-11-02 12:09:25,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 62000, global step 997497: loss -18.3208
[2017-11-02 12:09:30,975] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-33.18401337]
 [-34.48569107]
 [-34.49044037]
 [-33.77090073]
 [-35.89280319]], R is [[-34.28120041]
 [-33.96390152]
 [-33.63256073]
 [-33.29623413]
 [-32.96327209]].
[2017-11-02 12:09:31,798] A3C_AGENT_WORKER-Thread-5 INFO:Local step 62500, global step 998758: loss 25.1748
[2017-11-02 12:09:32,301] A3C_AGENT_WORKER-Thread-9 INFO:Local step 62500, global step 998854: loss -149.9347
[2017-11-02 12:09:32,603] A3C_AGENT_WORKER-Thread-11 INFO:Local step 62000, global step 998913: loss -127.1392
[2017-11-02 12:09:32,616] A3C_AGENT_WORKER-Thread-17 INFO:Local step 62500, global step 998917: loss 1.8590
[2017-11-02 12:09:34,029] A3C_AGENT_WORKER-Thread-7 INFO:Local step 62500, global step 999251: loss -23.4576
[2017-11-02 12:09:35,239] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.88578357e-28   1.35170851e-29   7.74890402e-28
   2.68009289e-30   7.28348643e-03   2.43772729e-03   1.54946139e-02
   9.74784195e-01], sum to 1.0000
[2017-11-02 12:09:35,287] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.225, 77.0, 4.85, 320.0, 0.0, 0.0, -3.15, 20.46959789796782, 21.0, 20.15052965866287, 20.8, 0.0, 49.23749905235533], 
actual action is [-3.2249999999999996, 25], 
sim time next is 3295200.0000, 
raw observation next is [-8.3, 77.0, 4.766666666666667, 320.0, 0.0, 0.0, -3.225, 19.94092342075238, 25.0, 20.28793415247193, 20.8, 0.0, 36.65747398205767], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.1205128205128205, 0.77, 0.43333333333333335, 0.8888888888888888, 0.0, 0.0, 0.44625, 0.1994092342075238, 1.0, 0.32684773606741857, 0.4000000000000001, 0.0, 0.43126439978891373], 
reward next is -0.4613. 
=============================================
[2017-11-02 12:09:35,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.16556048
  0.00461109  0.06689657  0.76293182], sum to 1.0000
[2017-11-02 12:09:35,806] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 60.25, 0.775, 15.0, 87.0, 428.0, -1.0, 18.54880066636492, 22.5, 21.1146159447784, 22.7, 1.0, 50.41847427526298], 
actual action is [-1.0, 25], 
sim time next is 3055800.0000, 
raw observation next is [-6.0, 59.83333333333334, 0.5166666666666666, 9.999999999999998, 88.33333333333334, 451.0, -1.0, 17.41352999464752, 25.0, 21.16922033992689, 22.7, 1.0, 64.48520680911557], 
processed observation next is [1.0, 0.34782608695652173, 0.1794871794871795, 0.5983333333333334, 0.04696969696969697, 0.027777777777777773, 0.23368606701940037, 0.451, 0.48333333333333334, 0.1741352999464752, 1.0, 0.45274576284669876, 0.6714285714285714, 1.0, 0.7586494918719479], 
reward next is -1.0000. 
=============================================
[2017-11-02 12:09:37,709] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2017-11-02 12:09:37,714] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 12:09:37,714] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 12:09:37,721] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:EnergyPlus Starting

[2017-11-02 12:09:37,721] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 11:32

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Processing Data Dictionary

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Processing Input File

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Initializing Simulation

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Reporting Surfaces

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Beginning Primary Simulation

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Initializing New Environment Parameters

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {1}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:ExternalInterface initializes.

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {2}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {3}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {4}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {5}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Warming up {6}

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:ExternalInterface starts first data exchange.

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 12:09:37,722] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 12:09:37,723] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_3 INFO:EnergyPlus Run Time=00hr 37min  5.51sec

[2017-11-02 12:09:38,711] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 12:09:38,713] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run5
[2017-11-02 12:10:20,455] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.05422182e-03   8.85332048e-01   7.59234056e-02   3.10781803e-02
   6.12098374e-04   8.45274937e-27   8.61630936e-27   5.98455582e-26
   2.28481452e-24]
[2017-11-02 12:10:24,728] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.25040957e-06   8.28359604e-01   8.55231434e-02   8.34018961e-02
   2.70907697e-03   3.23423449e-12   2.02677545e-12   1.12823882e-11
   7.05148648e-11]
[2017-11-02 12:10:25,440] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.77810248e-02   8.30834925e-01   1.05612695e-01   4.35954109e-02
   2.17599235e-03   3.74090009e-22   4.53682666e-22   1.53966756e-21
   8.66894006e-21]
[2017-11-02 12:10:32,583] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.63986350e-08   8.62815022e-01   5.83758317e-02   7.73000196e-02
   1.50899740e-03   1.87230474e-11   8.97437333e-12   7.43749506e-11
   8.94478491e-10]
[2017-11-02 12:10:39,256] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.66037579e-03   7.42640257e-01   1.13194577e-01   1.26795128e-01
   1.47096617e-02   1.91854599e-09   1.54458535e-09   2.60618593e-09
   2.90058666e-09]
[2017-11-02 12:10:39,760] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.76882782e-03   7.77302206e-01   9.84556377e-02   1.02529310e-01
   1.19440239e-02   1.22150970e-10   1.00767304e-10   1.74613130e-10
   1.80516421e-10]
[2017-11-02 12:10:50,794] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.47306994e-23   4.98092447e-08   3.94650668e-09   2.36217499e-08
   2.25229904e-10   5.35883382e-02   1.03610270e-02   1.17556006e-01
   8.18494499e-01]
[2017-11-02 12:10:53,784] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.19265273e-13   7.86697209e-01   5.04286475e-02   1.52345404e-01
   1.18981081e-03   1.11489993e-04   3.38131649e-05   4.14615031e-04
   8.77897814e-03]
[2017-11-02 12:10:54,381] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.83956267e-19   2.35597574e-04   1.76924113e-05   8.97042773e-05
   5.81338554e-07   1.56950336e-02   3.61927203e-03   4.80045043e-02
   9.32337642e-01]
[2017-11-02 12:10:54,416] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.56757406e-14   2.93555677e-01   1.98860858e-02   7.38812685e-02
   5.33727871e-04   8.14903807e-03   2.18519988e-03   2.81587914e-02
   5.73650181e-01]
[2017-11-02 12:11:09,870] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.10857794e-17   3.46311353e-05   3.70214821e-06   1.54497648e-05
   2.27721827e-07   6.02452420e-02   1.54486680e-02   1.25355110e-01
   7.98896968e-01]
[2017-11-02 12:11:10,157] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.86524304e-19   2.40707982e-06   2.56859494e-07   1.20471759e-06
   1.64330096e-08   6.06296323e-02   1.43240960e-02   1.23179927e-01
   8.01862478e-01]
[2017-11-02 12:11:13,323] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.29236033e-08   9.03129280e-01   4.07757461e-02   5.52579351e-02
   8.36950378e-04   2.23924698e-12   1.02076886e-12   9.35107634e-12
   1.17718682e-10]
[2017-11-02 12:11:16,895] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.74604114e-26   2.58858233e-08   1.95582017e-09   1.53921711e-08
   6.27623856e-11   1.22932056e-02   2.09709490e-03   3.76399234e-02
   9.47969735e-01]
[2017-11-02 12:11:39,390] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   6.24401346e-30   7.52324237e-31   4.98437741e-29
   5.88762567e-32   1.95203386e-02   1.01638958e-03   3.22957598e-02
   9.47167516e-01]
[2017-11-02 12:11:42,276] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.06358759e-01   3.16709134e-04   3.06663383e-02
   8.62658203e-01]
[2017-11-02 12:11:43,542] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.21576869e-01   1.90436869e-04   2.84190197e-02
   7.49813676e-01]
[2017-11-02 12:12:05,445] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.48951963e-13   8.21969032e-01   4.52166200e-02   1.30986437e-01
   9.03316482e-04   8.74248599e-06   2.61777041e-06   3.48686044e-05
   8.78387946e-04]
[2017-11-02 12:12:10,543] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.71016899e-02   8.08421231e-04   3.27387974e-02
   9.39351082e-01]
[2017-11-02 12:12:17,616] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.05098108e-20   1.60142906e-06   1.97841302e-07   9.26609800e-07
   1.29807329e-08   6.60209581e-02   1.64811276e-02   1.45351768e-01
   7.72143364e-01]
[2017-11-02 12:12:19,530] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.18566656e-02   8.72954845e-01   7.12248161e-02   3.26658711e-02
   1.29781733e-03   1.18332646e-19   9.19524794e-20   5.21327996e-19
   2.98961644e-18]
[2017-11-02 12:12:23,021] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.42932643e-08   8.31651032e-01   6.44085556e-02   1.02523312e-01
   1.41699007e-03   1.33047506e-09   6.37531750e-10   5.31571676e-09
   8.37196126e-08]
[2017-11-02 12:12:27,294] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.12557596e-06   9.16377068e-01   4.65718731e-02   3.65256891e-02
   5.19233232e-04   1.35804484e-19   8.65467895e-20   8.45855249e-19
   2.59754945e-17]
[2017-11-02 12:12:28,573] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.02809394e-09   8.46430600e-01   6.50212094e-02   8.74662325e-02
   1.08198437e-03   1.01587131e-12   4.70108598e-13   4.97502690e-12
   1.49951898e-10]
[2017-11-02 12:12:30,806] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.53007007e-03   8.76861513e-01   7.43299946e-02   3.86880189e-02
   1.59037707e-03   5.07780370e-18   3.89495114e-18   2.04280243e-17
   1.13709104e-16]
[2017-11-02 12:12:34,096] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.28530413e-02   9.10243630e-01   5.23093678e-02   2.41272319e-02
   4.66773898e-04   1.18890726e-24   9.23072375e-25   7.67683934e-24
   2.17979131e-22]
[2017-11-02 12:12:41,410] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.36912519e-02   8.76347423e-01   6.89557642e-02   2.97799446e-02
   1.22556929e-03   1.31833300e-20   1.07832606e-20   5.81090309e-20
   3.13282404e-19]
[2017-11-02 12:12:45,272] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.28556254e-09   8.99661720e-01   4.25607450e-02   5.71547635e-02
   6.22784428e-04   1.24595036e-13   5.34765645e-14   6.17484904e-13
   1.49634870e-11]
[2017-11-02 12:12:49,276] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.75761609e-02   7.97353208e-01   8.30308944e-02   5.52944690e-02
   6.74523832e-03   6.50959855e-15   6.83825877e-15   1.15141297e-14
   1.51590759e-14]
[2017-11-02 12:12:51,910] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.81842624e-02   8.04938912e-01   6.00678772e-02   6.51334599e-02
   1.16754696e-02   3.67359070e-14   5.24118035e-14   5.19777533e-14
   4.91777707e-14]
[2017-11-02 12:13:04,312] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.86962569e-29   1.24154376e-13   2.32327161e-14   1.69073441e-13
   4.28766426e-15   2.44411752e-01   5.05096093e-02   2.71913171e-01
   4.33165520e-01]
[2017-11-02 12:13:04,899] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.91348878e-02   8.53856742e-01   6.32716939e-02   3.12568247e-02
   2.47988128e-03   2.78935560e-17   2.47742413e-17   7.42607681e-17
   1.25794782e-16]
[2017-11-02 12:13:08,110] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.51587143e-03   8.56031835e-01   8.15588534e-02   5.31572700e-02
   1.73617597e-03   5.32215848e-17   3.89175508e-17   1.96911152e-16
   1.84619365e-15]
[2017-11-02 12:13:10,096] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.33398964e-05   8.84204745e-01   6.67781308e-02   4.81484197e-02
   8.25335388e-04   2.23145851e-19   1.62407246e-19   1.27856304e-18
   3.99622998e-17]
[2017-11-02 12:13:15,031] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.67693079e-04   8.67810011e-01   7.16025233e-02   5.87693527e-02
   1.45044259e-03   3.64867235e-15   2.35288579e-15   1.43250331e-14
   1.57737836e-13]
[2017-11-02 12:13:15,598] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.00246655e-06   8.55373383e-01   6.19346835e-02   8.10966864e-02
   1.59421563e-03   1.27147570e-10   6.58044452e-11   4.50268572e-10
   4.58629668e-09]
[2017-11-02 12:13:16,453] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.48471571e-07   8.63895297e-01   6.26759231e-02   7.22497106e-02
   1.17898011e-03   2.93830579e-14   1.58408155e-14   1.33947378e-13
   3.25427272e-12]
[2017-11-02 12:13:16,719] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.21642145e-17   4.26839618e-03   4.59683797e-04   2.02216324e-03
   1.77706479e-05   1.16030574e-02   2.96440162e-03   3.61833051e-02
   9.42481220e-01]
[2017-11-02 12:13:18,740] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.38157341e-02   8.42042863e-01   8.39454234e-02   3.76804546e-02
   2.51551205e-03   2.22928225e-19   2.39839519e-19   7.04153471e-19
   2.05596176e-18]
[2017-11-02 12:13:18,862] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.95231047e-03   7.98636615e-01   1.21377230e-01   6.78541437e-02
   2.17970391e-03   2.66207223e-20   2.87294529e-20   1.13374344e-19
   1.57764839e-18]
[2017-11-02 12:13:19,487] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.96963847e-03   7.46838510e-01   1.46496832e-01   9.75849479e-02
   3.11007793e-03   4.10884960e-19   5.14406717e-19   2.02943304e-18
   4.73153498e-17]
[2017-11-02 12:13:20,116] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.27125885e-02   7.91266799e-01   1.30880982e-01   6.00241683e-02
   5.11538843e-03   1.04891042e-22   1.93142129e-22   3.03151269e-22
   1.13164962e-21]
[2017-11-02 12:13:20,264] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.17851128e-03   6.93293333e-01   1.85869887e-01   1.11991681e-01
   5.66665456e-03   1.23715099e-22   3.63308337e-22   6.26209802e-22
   7.49335324e-21]
[2017-11-02 12:13:22,280] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.81426939e-03   6.81375206e-01   1.85562715e-01   1.24698833e-01
   5.54888323e-03   5.13000866e-22   1.48373786e-21   2.80851668e-21
   4.83079746e-20]
[2017-11-02 12:13:22,369] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.73747393e-03   6.77485466e-01   1.86262861e-01   1.27860293e-01
   5.65390754e-03   8.95560035e-22   2.60343728e-21   5.01626638e-21
   9.11630131e-20]
[2017-11-02 12:13:22,994] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.14697407e-03   7.21090913e-01   1.65837467e-01   1.05117157e-01
   3.80745204e-03   1.40865455e-21   2.72188971e-21   7.59422727e-21
   1.57472183e-19]
[2017-11-02 12:13:23,623] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.21765037e-03   8.68614972e-01   8.02213252e-02   4.87934910e-02
   1.15253159e-03   2.27840292e-20   1.61454524e-20   1.14901048e-19
   3.25399329e-18]
[2017-11-02 12:13:26,003] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.06041506e-02   7.14808822e-01   1.25223771e-01   1.31267428e-01
   1.80958845e-02   9.21775878e-10   8.14706524e-10   1.20736976e-09
   1.49575619e-09]
[2017-11-02 12:13:27,019] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.68546450e-02   8.26019168e-01   7.76473284e-02   4.64956947e-02
   2.98318430e-03   2.98577155e-16   2.27596562e-16   8.85773481e-16
   3.85232448e-15]
[2017-11-02 12:13:34,322] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.75223965e-02   8.76596689e-01   6.62480071e-02   3.84339541e-02
   1.19898212e-03   1.33099912e-20   1.06587109e-20   5.70221931e-20
   7.79731361e-19]
[2017-11-02 12:13:34,765] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.40426531e-02   8.76003087e-01   7.40151480e-02   3.48685123e-02
   1.07066217e-03   1.92463964e-23   2.02131833e-23   9.42036173e-23
   1.38621435e-21]
[2017-11-02 12:13:38,296] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.06314137e-02   8.20211887e-01   9.36600119e-02   4.99310493e-02
   5.56564145e-03   2.59148319e-19   4.00043854e-19   4.97786643e-19
   9.42804229e-19]
[2017-11-02 12:13:38,752] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.55557848e-03   8.14911604e-01   9.84625593e-02   8.17604586e-02
   2.30975938e-03   5.86663617e-15   4.04674565e-15   2.19587718e-14
   3.42174721e-13]
[2017-11-02 12:13:41,296] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.10653394e-02   8.36178780e-01   9.17637423e-02   4.60558906e-02
   4.93626902e-03   1.38382197e-21   2.22338616e-21   3.12125194e-21
   7.32499209e-21]
[2017-11-02 12:13:43,015] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.54762269e-05   7.86367834e-01   1.11977443e-01   9.94035006e-02
   2.21576681e-03   8.16434390e-15   6.33631467e-15   3.64518494e-14
   7.85679356e-13]
[2017-11-02 12:13:44,881] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.50665138e-02   7.64204741e-01   1.46261096e-01   7.05870911e-02
   3.88063514e-03   1.13543671e-19   1.34976424e-19   4.10361536e-19
   2.74822611e-18]
[2017-11-02 12:13:45,353] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.87685998e-03   7.68073440e-01   1.39301479e-01   8.24805200e-02
   2.26773508e-03   8.84993429e-20   9.63469863e-20   4.27027183e-19
   9.43243896e-18]
[2017-11-02 12:13:48,888] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.46916845e-34   1.27306341e-13   1.45482093e-14   1.83788165e-13
   7.90395930e-16   1.49682546e-02   2.01352965e-03   3.58719304e-02
   9.47146356e-01]
[2017-11-02 12:14:03,586] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.07502764e-12   5.15868127e-01   4.65168580e-02   1.20707117e-01
   2.06304621e-03   1.81092881e-02   5.36094233e-03   4.95108962e-02
   2.41863698e-01]
[2017-11-02 12:14:04,210] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.16154428e-23   1.64647851e-08   1.87335591e-09   1.04369491e-08
   1.25606650e-10   7.29133487e-02   1.42383687e-02   1.53259188e-01
   7.59589016e-01]
[2017-11-02 12:14:10,376] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.43541461e-08   9.01558876e-01   4.47300859e-02   5.30437790e-02
   6.67213346e-04   7.32750076e-15   3.40064416e-15   3.73931199e-14
   9.35537997e-13]
[2017-11-02 12:14:20,048] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.69516925e-10   8.56618762e-01   4.05863747e-02   9.91154388e-02
   1.38008595e-03   1.16962459e-04   3.71729802e-05   3.27519170e-04
   1.81769079e-03]
[2017-11-02 12:14:25,264] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.80698887e-03   8.62573802e-01   7.78583735e-02   5.13467267e-02
   3.41407908e-03   1.90714567e-14   1.50013702e-14   4.63077012e-14
   1.08172531e-13]
[2017-11-02 12:14:25,588] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.22343656e-03   8.40333402e-01   8.74451622e-02   6.62350804e-02
   4.76289494e-03   1.28121071e-12   9.58616650e-13   2.77596609e-12
   5.70200007e-12]
[2017-11-02 12:14:26,205] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.43495762e-09   6.64965689e-01   8.66117850e-02   1.68098882e-01
   8.33321549e-03   1.24206236e-02   5.60525153e-03   1.98881160e-02
   3.40764001e-02]
[2017-11-02 12:14:28,358] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.32449865e-15   5.21420327e-04   6.16056277e-05   2.18084562e-04
   4.44502666e-06   7.86522701e-02   2.46796478e-02   1.47395402e-01
   7.48467088e-01]
[2017-11-02 12:14:29,065] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.16222713e-34   2.25924095e-16   3.31135156e-17   4.01513761e-16
   4.00598483e-18   9.02990401e-02   1.33547466e-02   1.24380797e-01
   7.71965444e-01]
[2017-11-02 12:14:32,383] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.06918909e-08   8.68460000e-01   5.59286177e-02   7.46995807e-02
   9.11871030e-04   3.74550732e-13   1.80233175e-13   1.80177585e-12
   4.97196243e-11]
[2017-11-02 12:14:32,638] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.14639937e-12   7.81674027e-01   5.98162785e-02   1.56516507e-01
   1.55517657e-03   5.00691067e-06   1.76425442e-06   1.83178727e-05
   4.12949419e-04]
[2017-11-02 12:14:32,715] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.29722684e-13   7.51623809e-01   6.11627586e-02   1.77001908e-01
   1.65959622e-03   9.72211492e-05   3.11041076e-05   3.47774738e-04
   8.07586685e-03]
[2017-11-02 12:14:34,022] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.72223206e-12   7.91091144e-01   5.44656850e-02   1.52045876e-01
   1.25590514e-03   1.14226659e-05   3.73919329e-06   4.33038367e-05
   1.08288927e-03]
[2017-11-02 12:14:37,133] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.89757918e-02   8.62860560e-01   5.68475947e-02   2.93502826e-02
   1.96574628e-03   1.03737535e-16   8.64777890e-17   2.92925831e-16
   5.68016695e-16]
[2017-11-02 12:14:39,075] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.69268777e-08   7.78171420e-01   7.77817816e-02   1.41439036e-01
   2.59109959e-03   4.50160144e-07   2.12433051e-07   1.37328345e-06
   1.45397280e-05]
[2017-11-02 12:14:44,486] A3C_AGENT_WORKER-Thre