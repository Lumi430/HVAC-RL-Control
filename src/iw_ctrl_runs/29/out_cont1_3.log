Using TensorFlow backend.
[2017-11-01 09:17:07,365] A3C_AGENT_MAIN INFO:Namespace(act_func='5', action_space='iw_af5_1', agent_num=5, clip_norm=5.0, decay_steps=1000000, dropout_prob=0.5, end_e=0.0, env='IW-v5702', err_penalty_scl=0.15, eval_epi_num=1, eval_freq=250000, gamma=0.99, h_regu_frac=0.1, init_e=0.0, is_warm_start=True, job_mode='Train', learning_rate=0.0001, max_interactions=15000000, model_dir='a3c-res-v0.1/IW-v5702-run1/model_data/model.ckpt-15000000', num_threads=16, output='a3c-res-v0.1/IW-v5702-run4', p_loss_frac=1.0, reward_func='10', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=0.5, rwd_p_para=0.5, save_freq=500000, save_scope='all', state_dim=13, test_env='IW-eval-v5702', test_mode='Multiple', train_freq=5, v_loss_frac=0.5, window_len=24)
[2017-11-01 09:17:07,366] A3C_AGENT_MAIN INFO:Start compiling...
2017-11-01 09:17:16.135712: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:17:16.136060: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:17:16.136196: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:17:16.136284: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:17:16.136359: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[2017-11-01 09:17:22,618] A3C_AGENT_MAIN INFO:Start the learning...
[2017-11-01 09:17:22,622] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['IW-v5702'] ...
[2017-11-01 09:17:22,622] Making new env: IW-v5702
[2017-11-01 09:17:22,665] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:22,673] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2017-11-01 09:17:22,673] Making new env: IW-v5702
[2017-11-01 09:17:22,701] EPLUS_ENV_IW-v5702_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:22,704] EPLUS_ENV_IW-v5702_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res20/Eplus-env-sub_run1
[2017-11-01 09:17:23,695] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:23,695] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2017-11-01 09:17:23,696] Making new env: IW-v5702
[2017-11-01 09:17:23,709] EPLUS_ENV_IW-v5702_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:23,712] EPLUS_ENV_IW-v5702_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res21/Eplus-env-sub_run1
[2017-11-01 09:17:24,698] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:24,699] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2017-11-01 09:17:24,699] Making new env: IW-v5702
[2017-11-01 09:17:24,714] EPLUS_ENV_IW-v5702_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:24,726] EPLUS_ENV_IW-v5702_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res22/Eplus-env-sub_run1
[2017-11-01 09:17:25,700] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:25,701] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2017-11-01 09:17:25,702] Making new env: IW-v5702
[2017-11-01 09:17:25,713] EPLUS_ENV_IW-v5702_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:25,716] EPLUS_ENV_IW-v5702_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res23/Eplus-env-sub_run1
[2017-11-01 09:17:26,703] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:26,703] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2017-11-01 09:17:26,704] Making new env: IW-v5702
[2017-11-01 09:17:26,715] EPLUS_ENV_IW-v5702_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:26,718] EPLUS_ENV_IW-v5702_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res24/Eplus-env-sub_run1
[2017-11-01 09:17:27,704] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:27,705] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2017-11-01 09:17:27,706] Making new env: IW-v5702
[2017-11-01 09:17:27,718] EPLUS_ENV_IW-v5702_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:27,721] EPLUS_ENV_IW-v5702_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res25/Eplus-env-sub_run1
[2017-11-01 09:17:28,706] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:28,707] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2017-11-01 09:17:28,707] Making new env: IW-v5702
[2017-11-01 09:17:28,724] EPLUS_ENV_IW-v5702_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:28,727] EPLUS_ENV_IW-v5702_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res26/Eplus-env-sub_run1
[2017-11-01 09:17:29,708] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:29,709] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2017-11-01 09:17:29,709] Making new env: IW-v5702
[2017-11-01 09:17:29,722] EPLUS_ENV_IW-v5702_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:29,727] EPLUS_ENV_IW-v5702_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res27/Eplus-env-sub_run1
[2017-11-01 09:17:30,710] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:30,711] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2017-11-01 09:17:30,711] Making new env: IW-v5702
[2017-11-01 09:17:30,725] EPLUS_ENV_IW-v5702_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:30,728] EPLUS_ENV_IW-v5702_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res28/Eplus-env-sub_run1
[2017-11-01 09:17:31,712] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:31,712] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2017-11-01 09:17:31,712] Making new env: IW-v5702
[2017-11-01 09:17:31,725] EPLUS_ENV_IW-v5702_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:31,728] EPLUS_ENV_IW-v5702_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res29/Eplus-env-sub_run1
[2017-11-01 09:17:32,713] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:32,713] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2017-11-01 09:17:32,714] Making new env: IW-v5702
[2017-11-01 09:17:32,726] EPLUS_ENV_IW-v5702_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:32,741] EPLUS_ENV_IW-v5702_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res30/Eplus-env-sub_run1
[2017-11-01 09:17:33,714] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:33,715] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2017-11-01 09:17:33,715] Making new env: IW-v5702
[2017-11-01 09:17:33,726] EPLUS_ENV_IW-v5702_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:33,729] EPLUS_ENV_IW-v5702_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res31/Eplus-env-sub_run1
[2017-11-01 09:17:34,716] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:34,717] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2017-11-01 09:17:34,717] Making new env: IW-v5702
[2017-11-01 09:17:34,728] EPLUS_ENV_IW-v5702_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:34,731] EPLUS_ENV_IW-v5702_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res32/Eplus-env-sub_run1
[2017-11-01 09:17:35,718] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:35,719] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2017-11-01 09:17:35,719] Making new env: IW-v5702
[2017-11-01 09:17:35,731] EPLUS_ENV_IW-v5702_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:35,734] EPLUS_ENV_IW-v5702_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res33/Eplus-env-sub_run1
[2017-11-01 09:17:36,720] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:36,720] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2017-11-01 09:17:36,720] Making new env: IW-v5702
[2017-11-01 09:17:36,733] EPLUS_ENV_IW-v5702_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:36,736] EPLUS_ENV_IW-v5702_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res34/Eplus-env-sub_run1
[2017-11-01 09:17:37,721] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:37,721] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2017-11-01 09:17:37,722] Making new env: IW-v5702
[2017-11-01 09:17:37,735] EPLUS_ENV_IW-v5702_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:37,750] EPLUS_ENV_IW-v5702_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res35/Eplus-env-sub_run1
[2017-11-01 09:18:55,416] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-01 09:18:55,416] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:18:55,419] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res19/Eplus-env-sub_run1
[2017-11-01 09:19:25,689] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00033812  0.20055266  0.25390753  0.27985179  0.09906512  0.05771368
  0.03613063  0.03951829  0.03292217]
[2017-11-01 09:19:26,744] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09280442  0.11842548  0.15382092  0.13698819  0.09226593  0.1338478
  0.09857879  0.10602844  0.06724003]
[2017-11-01 09:19:27,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.00530469e-01   1.86200440e-01   2.56374776e-01   2.39518806e-01
   1.16327621e-01   4.90136270e-04   2.50753801e-04   2.34104809e-04
   7.28444720e-05]
[2017-11-01 09:19:30,522] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.20046323e-09   3.04006070e-01   1.53560519e-01   4.57022220e-01
   8.30802023e-02   6.46106142e-04   4.15632618e-04   4.73192107e-04
   7.96034932e-04]
[2017-11-01 09:19:37,740] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.27021670e-01   2.14550033e-01   2.85493135e-01   2.80839771e-01
   9.20953602e-02   1.28632227e-09   4.87548002e-10   5.18208698e-10
   2.49305993e-10]
[2017-11-01 09:19:40,734] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.16134857e-12   5.82347438e-02   2.95281466e-02   9.65593979e-02
   1.65744070e-02   2.43789673e-01   1.29934892e-01   1.68066144e-01
   2.57312536e-01]
[2017-11-01 09:19:44,557] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.11798720e-12   1.42979519e-02   5.89101389e-03   1.82617046e-02
   3.79066193e-03   2.91668892e-01   1.88637704e-01   2.23364294e-01
   2.54087776e-01]
[2017-11-01 09:19:44,872] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.21799121e-08   3.52245361e-01   1.47502422e-01   4.09585595e-01
   8.80024955e-02   8.44176335e-04   5.17011969e-04   6.32393931e-04
   6.70493988e-04]
[2017-11-01 09:19:52,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.21291692e-11   6.91152457e-03   8.71847384e-03   1.47723546e-02
   3.33145168e-03   3.62335771e-01   1.72203138e-01   1.79169521e-01
   2.52557725e-01]
[2017-11-01 09:19:54,214] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.60418545e-07   2.53814846e-01   2.23294660e-01   4.22209203e-01
   1.00585379e-01   3.46468114e-05   1.66320933e-05   1.85487806e-05
   2.57323991e-05]
[2017-11-01 09:19:56,662] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.63464777e-06   3.33710819e-01   1.73385978e-01   4.01354522e-01
   9.15410221e-02   1.64623888e-08   8.31604208e-09   1.08236797e-08
   1.33813769e-08]
[2017-11-01 09:19:57,666] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.04573884e-08   3.06535006e-01   1.72918826e-01   4.24699485e-01
   9.55356508e-02   9.82119382e-05   5.48503376e-05   6.67869535e-05
   9.10921372e-05]
[2017-11-01 09:19:58,247] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.52476266e-01   3.09858412e-01   1.80325598e-01   2.78153986e-01
   7.91857690e-02   1.31944342e-13   5.33811446e-14   8.04347298e-14
   5.36743671e-14]
[2017-11-01 09:20:08,690] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.50852121e-14   2.42819428e-04   3.34686803e-04   5.75672137e-04
   1.27541643e-04   3.87836993e-01   1.88642085e-01   1.78186253e-01
   2.44053960e-01]
[2017-11-01 09:20:09,163] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30541176e-01   2.55193621e-01   2.56157249e-01   2.77538925e-01
   8.05690214e-02   1.31951377e-11   4.61077400e-12   4.87909669e-12
   3.03551542e-12]
[2017-11-01 09:20:35,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   1.01062058e-19   1.85723422e-20   1.39265601e-19
   1.68567243e-20   2.89185077e-01   1.71959847e-01   2.21354038e-01
   3.17501068e-01]
[2017-11-01 09:20:37,265] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.16782578e-09   2.85483807e-01   1.59050912e-01   4.54659075e-01
   9.82879177e-02   8.64618632e-04   4.43494762e-04   4.98908514e-04
   7.11302680e-04]
[2017-11-01 09:20:40,852] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.03167864e-05   2.54499257e-01   2.80512542e-01   3.26681286e-01
   1.01215810e-01   1.40896151e-02   8.17400217e-03   8.30139313e-03
   6.46587182e-03]
[2017-11-01 09:20:44,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20323561e-01   2.73334235e-01   2.40213886e-01   2.89254069e-01
   7.68742636e-02   9.85826438e-13   4.06085295e-13   5.88403458e-13
   4.97637250e-13]
[2017-11-01 09:20:49,178] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08127458  0.13513254  0.20254095  0.16884111  0.0953835   0.10549255
  0.07380372  0.08277836  0.05475262]
[2017-11-01 09:20:50,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.49285182e-01   2.91849434e-01   2.00340286e-01   2.79408306e-01
   7.91167766e-02   4.10050640e-15   1.44167718e-15   1.99946426e-15
   1.78916588e-15]
[2017-11-01 09:20:52,136] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.78124623e-02   3.72047156e-01   1.85609892e-01   3.23506624e-01
   9.10239518e-02   2.56640575e-13   1.06537351e-13   1.64101859e-13
   1.18505141e-13]
[2017-11-01 09:20:52,960] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.50515311e-22   9.63695079e-09   5.14618126e-09   1.53613158e-08
   3.02168512e-09   2.87313491e-01   1.97919980e-01   2.18856931e-01
   2.95909584e-01]
[2017-11-01 09:20:54,106] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.97685017e-03   3.57720405e-01   2.12253019e-01   3.44394505e-01
   7.96551779e-02   6.21892078e-12   2.71336534e-12   3.82418186e-12
   3.12668793e-12]
[2017-11-01 09:20:58,267] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.41234249e-01   2.30181694e-01   2.56015509e-01   2.85710543e-01
   8.68580192e-02   2.89552453e-12   1.00990082e-12   1.09762622e-12
   7.01472517e-13]
[2017-11-01 09:20:58,676] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.79261288e-22   4.26135482e-09   5.74671777e-09   1.05151372e-08
   2.03705319e-09   3.55605751e-01   1.82075158e-01   1.88072830e-01
   2.74246275e-01]
[2017-11-01 09:20:59,666] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.36913002e-01   2.23125339e-01   2.64442831e-01   2.82022446e-01
   9.34962854e-02   1.53672960e-11   5.16108423e-12   5.66877448e-12
   2.73493142e-12]
[2017-11-01 09:21:06,644] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.40719358e-10   2.73221821e-01   1.10658057e-01   3.24399531e-01
   6.22062907e-02   6.85102418e-02   4.30995598e-02   5.03946394e-02
   6.75098673e-02]
[2017-11-01 09:21:14,061] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.60583501e-08   3.08943331e-01   1.65249407e-01   4.31906998e-01
   8.97020847e-02   1.29714515e-03   8.20474466e-04   9.88564338e-04
   1.09193916e-03]
[2017-11-01 09:21:14,876] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09435183e-04   3.89406919e-01   1.79764047e-01   3.51821303e-01
   7.88982287e-02   1.97578398e-08   1.14524212e-08   1.39628140e-08
   1.12951870e-08]
[2017-11-01 09:21:20,630] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.48486853e-01   2.37227023e-01   2.57605731e-01   2.67234802e-01
   8.94455388e-02   1.03877379e-10   3.54856977e-11   3.96536588e-11
   1.83965395e-11]
[2017-11-01 09:21:27,980] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.32313743e-01   2.98442185e-01   2.16084555e-01   2.75030136e-01
   7.81293884e-02   1.95760140e-12   7.83220223e-13   1.10701465e-12
   7.61722120e-13]
[2017-11-01 09:21:29,241] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.45368949e-01   2.87841767e-01   2.08861455e-01   2.82377809e-01
   7.55500197e-02   5.84175991e-14   2.09758341e-14   3.04057757e-14
   2.29381808e-14]
[2017-11-01 09:21:32,008] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.03154223  0.12334371  0.19696212  0.17023037  0.08315948  0.13794093
  0.08665115  0.10197388  0.06819616]
[2017-11-01 09:21:32,016] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.02029695  0.11023276  0.17422147  0.15294848  0.07375453  0.16229936
  0.10290395  0.12129305  0.08204938]
[2017-11-01 09:21:34,500] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20144222e-07   2.77062833e-01   2.15543121e-01   3.97486299e-01
   9.12555531e-02   5.38080512e-03   3.39731015e-03   4.05867118e-03
   5.81528665e-03]
[2017-11-01 09:21:37,041] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1435293   0.15504423  0.20556407  0.18033674  0.11319116  0.07496191
  0.05041659  0.0514451   0.02551093]
[2017-11-01 09:21:37,184] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11790899  0.20227724  0.29654756  0.25495827  0.12120343  0.00234934
  0.00145925  0.00181568  0.00148025]
[2017-11-01 09:21:37,574] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13256849  0.2053919   0.28728971  0.23890312  0.1225469   0.00455645
  0.00272441  0.00346085  0.00255819]
[2017-11-01 09:21:37,876] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.08222216e-01   2.10657328e-01   3.14367414e-01   2.64883518e-01
   1.01849355e-01   6.85219038e-06   3.52583265e-06   5.21561606e-06
   4.59841249e-06]
[2017-11-01 09:21:40,239] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18775375  0.13555418  0.16574393  0.15465839  0.09952336  0.08958405
  0.0626644   0.07272526  0.03179259]
[2017-11-01 09:21:40,365] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12483242  0.12256023  0.14613135  0.13769518  0.08750218  0.12383924
  0.09179249  0.1051754   0.0604715 ]
[2017-11-01 09:21:41,027] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08379184  0.09104995  0.12124149  0.10778999  0.0976382   0.13109981
  0.13378628  0.12686384  0.10673861]
[2017-11-01 09:21:41,398] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08284155  0.0892642   0.12601314  0.11142617  0.10006483  0.12804615
  0.12979618  0.12787701  0.10467081]
[2017-11-01 09:21:43,374] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10177415  0.10179336  0.13384672  0.11896288  0.1073212   0.11227703
  0.11753813  0.11382043  0.09266606]
[2017-11-01 09:21:51,844] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37490660e-01   2.75157213e-01   2.22038284e-01   2.90659428e-01
   7.46543482e-02   1.94992460e-13   7.71259819e-14   1.07708073e-13
   8.91093839e-14]
[2017-11-01 09:21:52,908] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06888062  0.1266121   0.20132469  0.17103747  0.08952219  0.11849227
  0.07538898  0.08915889  0.05958279]
[2017-11-01 09:21:56,663] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.05496401e-08   2.11693764e-01   1.41464576e-01   2.42778465e-01
   5.41018099e-02   9.66974124e-02   6.57148957e-02   7.39224553e-02
   1.13626614e-01]
[2017-11-01 09:21:59,035] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09244405  0.09918631  0.13028622  0.11535918  0.11119023  0.11440296
  0.12415813  0.11297397  0.09999895]
[2017-11-01 09:22:00,842] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.23932984  0.15276554  0.19196941  0.16896096  0.10470514  0.05441841
  0.03510784  0.03889999  0.01384281]
[2017-11-01 09:22:01,414] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14919199  0.17482813  0.21678013  0.194736    0.10453252  0.05600176
  0.03882712  0.04107568  0.0240266 ]
[2017-11-01 09:22:04,169] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1489685   0.1791086   0.22611672  0.21252073  0.11162759  0.04050324
  0.02850607  0.03150091  0.02114766]
[2017-11-01 09:22:06,206] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.94498682e-15   2.72300065e-04   1.75718960e-04   4.54960391e-04
   9.61861952e-05   2.71492541e-01   1.66487619e-01   2.01362446e-01
   3.59658182e-01]
[2017-11-01 09:22:09,534] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.91712643e-08   2.81078726e-01   1.80522487e-01   4.54055101e-01
   8.43307823e-02   3.75272634e-06   2.23620987e-06   2.65345875e-06
   4.26018960e-06]
[2017-11-01 09:22:11,027] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.52695209e-01   2.90127367e-01   1.87126055e-01   2.94579327e-01
   7.54720569e-02   3.67489395e-15   1.36545576e-15   2.08661950e-15
   1.74791083e-15]
[2017-11-01 09:22:18,305] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.04254289e-14   9.49269452e-04   5.01085480e-04   1.56584510e-03
   2.94878759e-04   3.07578295e-01   1.82590380e-01   2.23373309e-01
   2.83146948e-01]
[2017-11-01 09:22:19,770] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.55160487e-01   3.08234662e-01   1.76928669e-01   2.84462124e-01
   7.52141178e-02   5.57009628e-15   2.01047166e-15   3.17888246e-15
   2.23042050e-15]
[2017-11-01 09:22:21,163] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.84238695e-07   3.33124548e-01   1.44888788e-01   4.42302585e-01
   7.96837807e-02   2.35851569e-08   1.25769271e-08   1.66063892e-08
   2.14516049e-08]
[2017-11-01 09:22:26,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.25406712e-01   2.34498039e-01   2.82979488e-01   2.71206021e-01
   8.59097019e-02   1.91458738e-10   6.70679901e-11   7.59574140e-11
   4.01405090e-11]
[2017-11-01 09:22:27,063] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.52012580e-10   7.75650963e-02   1.04208156e-01   1.67668954e-01
   3.84291597e-02   2.43336037e-01   1.11183189e-01   1.12665564e-01
   1.44943848e-01]
[2017-11-01 09:22:30,234] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.65994394e-03   3.93789470e-01   1.72517568e-01   3.37762684e-01
   8.72703716e-02   4.82617906e-13   2.07596703e-13   3.14323518e-13
   2.36237868e-13]
[2017-11-01 09:22:32,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.06869184e-14   9.41810105e-03   2.78526032e-03   1.12802507e-02
   1.90780580e-03   2.82694548e-01   1.75277442e-01   2.20411465e-01
   2.96225160e-01]
[2017-11-01 09:22:38,402] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.84135984e-09   1.34962602e-02   1.94636229e-02   2.75479704e-02
   6.71240129e-03   3.64521563e-01   1.87883139e-01   1.86341405e-01
   1.94033638e-01]
[2017-11-01 09:22:47,707] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11653598  0.193176    0.28736073  0.24344766  0.11797626  0.01654327
  0.00949989  0.00994259  0.00551763]
[2017-11-01 09:22:52,802] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.09462767e-15   1.78159185e-04   7.81246854e-05   2.29810496e-04
   4.72363026e-05   3.01028103e-01   1.91836238e-01   2.28103355e-01
   2.78498948e-01]
[2017-11-01 09:22:54,574] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.01106176e-02   3.52818638e-01   1.98566705e-01   3.60910058e-01
   7.75939077e-02   2.07147599e-13   8.56956582e-14   1.23908845e-13
   1.15802794e-13]
[2017-11-01 09:22:57,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08482356  0.1509884   0.22120135  0.18969715  0.1023636   0.08843401
  0.05786274  0.06421336  0.04041582]
[2017-11-01 09:23:03,714] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.23471942e-15   7.02226069e-04   2.84887617e-04   8.72255827e-04
   1.52684937e-04   3.04844975e-01   1.88027456e-01   2.10433006e-01
   2.94682443e-01]
[2017-11-01 09:23:15,801] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17329493e-01   3.30134958e-01   1.89910620e-01   2.83908814e-01
   7.87160248e-02   5.63104285e-14   2.08486335e-14   2.46644746e-14
   1.87317033e-14]
[2017-11-01 09:23:17,977] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09664786  0.12704316  0.15485905  0.14004286  0.10317903  0.11909746
  0.09743208  0.09651799  0.06518053]
[2017-11-01 09:23:18,359] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09023023  0.12627357  0.15983739  0.14082697  0.10047399  0.12472581
  0.09593349  0.09825439  0.06344421]
[2017-11-01 09:23:22,306] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.38563099e-25   4.94801179e-11   2.44533543e-11   6.77035789e-11
   1.20698763e-11   2.66590744e-01   2.04658136e-01   2.06817955e-01
   3.21933150e-01]
[2017-11-01 09:23:30,427] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.82088721e-03   3.96419138e-01   1.86599120e-01   3.30150872e-01
   8.50099847e-02   7.45622175e-11   3.55256553e-11   4.82314223e-11
   3.47159454e-11]
[2017-11-01 09:23:30,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.12300224e-30   1.53314671e-13   6.27208314e-14   2.19747208e-13
   4.24273823e-14   2.88409203e-01   2.03460693e-01   2.19262883e-01
   2.88867235e-01]
[2017-11-01 09:23:31,227] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.10036217e-03   3.76472741e-01   2.05266416e-01   3.37983310e-01
   7.41771385e-02   6.71917860e-12   2.65182472e-12   3.88330730e-12
   3.25911368e-12]
[2017-11-01 09:23:35,421] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.24812083e-04   3.24219167e-01   2.64123797e-01   3.24981928e-01
   8.62523541e-02   1.31444191e-04   6.67632703e-05   6.27221234e-05
   3.70433045e-05]
[2017-11-01 09:23:35,866] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08045051  0.14875953  0.21256129  0.17474613  0.10416632  0.09444916
  0.06718764  0.07210436  0.04557499]
[2017-11-01 09:23:44,453] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11421356  0.11508279  0.13653287  0.1232155   0.1117175   0.10722496
  0.11392897  0.09879308  0.07929077]
[2017-11-01 09:23:48,364] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.35522514e-22   7.27180272e-09   3.38283801e-09   1.01760138e-08
   1.79814752e-09   2.77409405e-01   1.98788702e-01   2.02511594e-01
   3.21290284e-01]
[2017-11-01 09:23:52,317] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08122973  0.12458818  0.17858657  0.15075544  0.09249693  0.12132501
  0.0883166   0.09708917  0.06561229]
[2017-11-01 09:23:52,964] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13799681  0.15081412  0.1850042   0.15466703  0.10093155  0.09078751
  0.07152437  0.06925137  0.03902302]
[2017-11-01 09:23:58,430] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.38408183e-08   4.57078755e-01   1.22578867e-01   3.85898650e-01
   3.38607207e-02   2.21909679e-04   7.69478065e-05   1.47715473e-04
   1.36435337e-04]
[2017-11-01 09:24:00,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.29078344e-01   2.83036470e-01   2.31872857e-01   2.75986791e-01
   8.00255910e-02   2.74580306e-11   9.67152920e-12   9.57520261e-12
   5.14184268e-12]
[2017-11-01 09:24:00,923] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00398081  0.24064653  0.30232236  0.27637032  0.09712175  0.03117251
  0.01851311  0.01906133  0.0108113 ]
[2017-11-01 09:24:01,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.16231529  0.21039884  0.25971574  0.22887506  0.11571777  0.00951821
  0.00593844  0.00532625  0.00219447]
[2017-11-01 09:24:02,489] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15095393  0.14793542  0.16435505  0.15233067  0.11727525  0.08759017
  0.07222059  0.06875609  0.0385828 ]
[2017-11-01 09:24:05,641] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.07574701e-07   3.65366548e-01   1.70118764e-01   3.73905420e-01
   8.96134675e-02   3.39162245e-04   2.00359136e-04   2.27494384e-04
   2.28545134e-04]
[2017-11-01 09:24:09,967] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.02287032e-01   2.33092889e-01   3.04602474e-01   2.58747578e-01
   1.01074532e-01   8.80279113e-05   4.03491867e-05   4.47395578e-05
   2.23597435e-05]
[2017-11-01 09:24:14,654] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.48680972e-11   2.25595646e-02   1.37320105e-02   3.06135193e-02
   6.45534135e-03   2.80153990e-01   1.80781677e-01   2.02756479e-01
   2.62947500e-01]
[2017-11-01 09:24:15,874] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.01616803e-08   3.11506331e-01   1.83735296e-01   4.16690499e-01
   8.51844847e-02   8.80313863e-04   5.53616555e-04   6.16154284e-04
   8.33362632e-04]
[2017-11-01 09:24:18,587] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09585293  0.1290364   0.18072113  0.16065702  0.0939918   0.1177591
  0.07923996  0.08843196  0.05430974]
[2017-11-01 09:24:22,532] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.49787706e-03   3.49030614e-01   1.97245747e-01   3.71189833e-01
   8.10360014e-02   4.93809767e-12   2.39623013e-12   3.12966341e-12
   3.09367375e-12]
[2017-11-01 09:24:22,656] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30635502e-10   1.86710432e-01   9.82394665e-02   2.64972508e-01
   5.04906997e-02   1.20398581e-01   7.54378289e-02   8.43035057e-02
   1.19447045e-01]
[2017-11-01 09:24:26,982] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06955541  0.11431585  0.16103417  0.14038123  0.09636738  0.13276307
  0.10061512  0.1096295   0.07533827]
[2017-11-01 09:24:29,210] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.05168773e-03   3.75562042e-01   2.19669253e-01   3.12766075e-01
   8.89509916e-02   1.46959456e-09   7.10627723e-10   9.47640633e-10
   6.84781898e-10]
[2017-11-01 09:24:31,315] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.83215536e-22   2.05182058e-08   8.37299208e-09   2.58410537e-08
   4.45175097e-09   2.84903944e-01   1.95131391e-01   2.13793844e-01
   3.06170791e-01]
[2017-11-01 09:24:40,471] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0917031   0.10501748  0.13216536  0.1169146   0.099216    0.13160464
  0.1263589   0.11286562  0.08415439]
[2017-11-01 09:24:43,918] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.05428001  0.12744769  0.19860409  0.17143485  0.07499469  0.11857156
  0.08742119  0.09692566  0.07032023]
[2017-11-01 09:24:46,711] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07866332  0.09084312  0.12290277  0.10985541  0.09930385  0.13598388
  0.13376436  0.12476441  0.10391879]
[2017-11-01 09:24:53,915] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09672245  0.12306646  0.15259214  0.13658667  0.1067095   0.11919254
  0.10186079  0.09636557  0.06690395]
[2017-11-01 09:24:54,077] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07596034  0.10087766  0.13132082  0.12258226  0.10213805  0.13387462
  0.11966958  0.1189625   0.09461408]
[2017-11-01 09:24:57,027] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.06347188e-10   3.70708592e-02   2.07194854e-02   4.63711508e-02
   1.07716201e-02   2.81959027e-01   1.83049202e-01   1.97887123e-01
   2.22171590e-01]
[2017-11-01 09:24:58,538] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.34746686e-01   2.97447056e-01   2.05382660e-01   2.92737275e-01
   6.96862713e-02   3.77006877e-14   1.27879275e-14   1.90801422e-14
   1.37596970e-14]
[2017-11-01 09:25:06,568] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.86869130e-01   2.71851480e-01   1.88110754e-01   2.76419193e-01
   7.67494664e-02   2.13548166e-15   7.56138212e-16   1.12810495e-15
   9.06886625e-16]
[2017-11-01 09:25:06,775] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.80418112e-13   9.71124880e-03   5.64140454e-03   1.50383217e-02
   2.89615779e-03   2.81303674e-01   1.80964902e-01   2.01616213e-01
   3.02828074e-01]
[2017-11-01 09:25:10,291] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11019944  0.10850689  0.14090879  0.12379568  0.11432317  0.10339137
  0.11187614  0.10305196  0.08394652]
[2017-11-01 09:25:10,704] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.23879974  0.19126712  0.2303604   0.21685891  0.10334946  0.00820151
  0.00459635  0.00469371  0.00187278]
[2017-11-01 09:25:13,641] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09698188  0.15122321  0.20058981  0.1730928   0.10683767  0.08592445
  0.06805616  0.06818531  0.04910867]
[2017-11-01 09:25:14,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12015382  0.19015095  0.26659426  0.21804571  0.11721252  0.03383152
  0.02204973  0.02153952  0.01042191]
[2017-11-01 09:25:16,436] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.24060670e-01   2.69560367e-01   2.10463047e-01   2.16991484e-01
   7.89243951e-02   1.00521529e-10   3.98300316e-11   5.27251715e-11
   2.51726712e-11]
[2017-11-01 09:25:17,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.55630543e-12   5.17334603e-03   2.77738692e-03   6.31862413e-03
   1.48291257e-03   3.07736427e-01   2.01719955e-01   2.19326079e-01
   2.55465239e-01]
[2017-11-01 09:25:17,700] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.15614664e-07   3.23793143e-01   2.17000008e-01   3.69264662e-01
   8.37797597e-02   1.69672701e-03   9.74675408e-04   1.39991264e-03
   2.09064339e-03]
[2017-11-01 09:25:24,803] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09149292  0.10970881  0.1402044   0.12870911  0.09909456  0.1258869
  0.1161502   0.10664582  0.08210732]
[2017-11-01 09:25:25,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07367834  0.08653343  0.11617924  0.10712225  0.09273434  0.1451209
  0.14131591  0.12869045  0.10862505]
[2017-11-01 09:25:26,356] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12817553  0.13408849  0.15876789  0.14585181  0.1058379   0.09851769
  0.09131683  0.08155962  0.05588425]
[2017-11-01 09:25:27,554] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.69359629e-11   3.02117355e-02   1.86009854e-02   4.50002439e-02
   9.82389227e-03   2.59853095e-01   1.80831850e-01   1.95221767e-01
   2.60456473e-01]
[2017-11-01 09:25:29,286] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.10228726e-01   2.59684980e-01   1.94293380e-01   2.68788189e-01
   6.70047477e-02   2.12431247e-15   6.70886728e-16   1.06384458e-15
   7.21075548e-16]
[2017-11-01 09:25:29,909] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.73412734e-04   3.58295590e-01   2.07049400e-01   3.58481526e-01
   7.59000555e-02   6.26940444e-10   3.15062726e-10   3.82499088e-10
   3.87989391e-10]
[2017-11-01 09:25:34,940] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13143364  0.13775389  0.18152706  0.16776408  0.09246489  0.1039678
  0.06747582  0.07699104  0.04062176]
[2017-11-01 09:25:35,321] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.25479375e-03   2.79251575e-01   3.06057394e-01   3.04985166e-01
   1.04546316e-01   2.69177806e-04   1.69395717e-04   2.28321049e-04
   2.37876870e-04]
[2017-11-01 09:25:39,980] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08918954  0.09476112  0.12537861  0.11086804  0.10658091  0.11972088
  0.12887906  0.11866058  0.10596127]
[2017-11-01 09:25:41,537] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.28953742e-09   3.17206353e-01   1.57292321e-01   4.14954245e-01
   9.52280909e-02   4.92954114e-03   2.92458083e-03   3.54487705e-03
   3.91999120e-03]
[2017-11-01 09:25:42,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.82517683e-05   4.01053339e-01   1.67280868e-01   3.49879682e-01
   8.17479193e-02   8.89880702e-09   4.51107240e-09   5.82565951e-09
   4.99848563e-09]
[2017-11-01 09:25:43,919] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.93527699e-14   1.89534540e-03   5.86792361e-04   2.02066544e-03
   2.29307829e-04   3.22544754e-01   1.61149621e-01   2.24740028e-01
   2.86833465e-01]
[2017-11-01 09:25:47,393] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08204442  0.10279495  0.12974809  0.12133569  0.10447589  0.13139024
  0.12046266  0.11565351  0.09209454]
[2017-11-01 09:25:49,181] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.70311078e-01   3.18513274e-01   1.90451443e-01   2.39485443e-01
   8.12387392e-02   6.74648705e-13   2.51291284e-13   3.48659903e-13
   2.00864200e-13]
[2017-11-01 09:25:54,001] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13882634  0.19255389  0.20964772  0.18139414  0.11606679  0.05560921
  0.04200438  0.04010457  0.02379292]
[2017-11-01 09:25:58,634] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17227040e-01   3.14434677e-01   2.03871071e-01   2.90902168e-01
   7.35650584e-02   1.45625848e-13   5.33704076e-14   7.99438437e-14
   5.66627298e-14]
[2017-11-01 09:26:00,313] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06566882  0.08148771  0.11747061  0.10115982  0.09251714  0.14911437
  0.14158288  0.13851616  0.11248253]
[2017-11-01 09:26:02,041] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.27194640e-06   3.40074450e-01   2.10873678e-01   3.60216588e-01
   8.88207257e-02   2.81566554e-06   1.68341569e-06   1.95652456e-06
   1.80791631e-06]
[2017-11-01 09:26:02,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.22286060e-01   2.73182988e-01   1.89291865e-01   2.39214331e-01
   7.60247186e-02   1.51317422e-14   5.12644499e-15   7.93042813e-15
   4.77115956e-15]
[2017-11-01 09:26:04,441] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11524243  0.18231505  0.27130172  0.22873189  0.11945526  0.03185855
  0.01986028  0.02020492  0.01102986]
[2017-11-01 09:26:04,906] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07290038  0.08655038  0.12399046  0.10811114  0.09801664  0.14001031
  0.13613403  0.1302143   0.10407243]
[2017-11-01 09:26:07,290] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.16907947e-01   2.10034311e-01   2.90730745e-01   2.60778397e-01
   1.20671466e-01   2.95017031e-04   1.81811571e-04   2.18963891e-04
   1.81307361e-04]
[2017-11-01 09:26:07,314] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.05531044e-01   2.07542434e-01   2.99542487e-01   2.70719409e-01
   1.16550505e-01   3.81093814e-05   2.22115432e-05   2.81707162e-05
   2.57436368e-05]
[2017-11-01 09:26:11,032] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08175747  0.09113158  0.11834899  0.10814405  0.10206427  0.13012953
  0.14189668  0.11961965  0.10690778]
[2017-11-01 09:26:11,446] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12737755  0.1266457   0.15833446  0.14355192  0.10152712  0.11139179
  0.08559933  0.09002683  0.05554533]
[2017-11-01 09:26:11,578] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09457955  0.11706603  0.1566938   0.14691271  0.09843556  0.11885899
  0.0889091   0.10268119  0.07586299]
[2017-11-01 09:26:11,678] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09459003  0.11832608  0.15904364  0.14865129  0.0980303   0.11874797
  0.08777764  0.10114     0.07369307]
[2017-11-01 09:26:11,774] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11081313  0.12617971  0.16457219  0.15105565  0.09998195  0.11387499
  0.08208838  0.09190203  0.05953195]
[2017-11-01 09:26:12,424] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0938338   0.13257898  0.19073685  0.16595037  0.08190732  0.11403242
  0.07746284  0.09046379  0.05303364]
[2017-11-01 09:26:13,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.23550569  0.18249425  0.23105811  0.20063958  0.1040698   0.01888461
  0.01183925  0.01161903  0.00388969]
[2017-11-01 09:26:15,864] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.24671027e-20   6.40119993e-08   3.59820689e-08   1.01913862e-07
   2.09759907e-08   2.64073133e-01   1.78147227e-01   2.17718378e-01
   3.40061069e-01]
[2017-11-01 09:26:17,095] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.65868216e-05   3.20313931e-01   2.05692992e-01   3.85971665e-01
   8.79747644e-02   1.09584164e-08   6.26845109e-09   7.64134089e-09
   8.35748359e-09]
[2017-11-01 09:26:19,424] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10858174  0.12730742  0.15540272  0.13856727  0.09902427  0.1213479
  0.09577901  0.09433457  0.05965515]
[2017-11-01 09:26:19,722] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11472277  0.1182327   0.14526735  0.13073145  0.10428348  0.118079
  0.10273273  0.10207042  0.06388012]
[2017-11-01 09:26:19,779] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11903327  0.12336938  0.14903742  0.13099955  0.10435971  0.11799707
  0.1014656   0.0956638   0.05807418]
[2017-11-01 09:26:22,353] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.54783750e-04   3.60501558e-01   2.37054855e-01   3.08593363e-01
   9.29950550e-02   1.37274924e-07   7.62093890e-08   9.18685856e-08
   7.18997271e-08]
[2017-11-01 09:26:24,469] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.48723885e-01   2.37087831e-01   2.66866177e-01   2.49729738e-01
   9.75920856e-02   1.47945968e-07   6.34092956e-08   6.67847715e-08
   3.33326149e-08]
[2017-11-01 09:26:28,862] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07838983  0.13119414  0.19552793  0.17135502  0.09874573  0.11436935
  0.07471198  0.08293429  0.05277177]
[2017-11-01 09:26:28,869] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07877377  0.12978387  0.18941736  0.16629082  0.09806958  0.11724684
  0.07842028  0.0864237   0.05557374]
[2017-11-01 09:26:30,918] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11148722  0.11862524  0.14251764  0.13070199  0.10376856  0.11842246
  0.10412127  0.10221767  0.06813803]
[2017-11-01 09:26:31,934] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.00131819e-01   2.71746367e-01   1.98238328e-01   2.48218223e-01
   8.16652998e-02   6.87384559e-15   2.45809893e-15   3.45296030e-15
   2.45161849e-15]
[2017-11-01 09:26:34,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.01530742e-10   1.53639361e-01   7.47864991e-02   1.99364856e-01
   3.81343104e-02   1.64398938e-01   1.02324009e-01   1.13172531e-01
   1.54179499e-01]
[2017-11-01 09:26:37,695] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07286109  0.08787469  0.12375995  0.11068872  0.09978515  0.13980334
  0.13295573  0.12904491  0.10322637]
[2017-11-01 09:26:38,960] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.05923855e-01   2.10982561e-01   2.59261668e-01   2.28846490e-01
   9.48335677e-02   6.76604686e-05   3.36285339e-05   3.52779134e-05
   1.53086530e-05]
[2017-11-01 09:26:39,787] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.70873186e-16   7.43344617e-06   4.30812634e-06   8.68183088e-06
   2.01622265e-06   2.94474989e-01   2.04244703e-01   2.23638803e-01
   2.77618915e-01]
[2017-11-01 09:26:40,700] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.78106977e-04   3.56629163e-01   2.23578438e-01   3.36960047e-01
   8.19542557e-02   1.06360931e-09   5.32942690e-10   6.44432785e-10
   5.97924876e-10]
[2017-11-01 09:26:43,282] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07026118  0.08872025  0.12431327  0.11207635  0.10041976  0.13926488
  0.13238102  0.12884933  0.103714  ]
[2017-11-01 09:26:46,358] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.25315055e-01   2.91731000e-01   2.29052171e-01   2.73512810e-01
   8.03889334e-02   4.55916728e-12   1.92329876e-12   2.52743421e-12
   1.83382476e-12]
[2017-11-01 09:26:49,639] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15841663  0.14657125  0.16961361  0.15442348  0.10975753  0.08415145
  0.07289288  0.06600639  0.03816668]
[2017-11-01 09:26:51,189] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09218452  0.10002852  0.12410132  0.11389545  0.10613248  0.12277533
  0.13197848  0.11155285  0.09735103]
[2017-11-01 09:26:54,132] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09551077  0.11051793  0.1357391   0.11949838  0.1041125   0.12432741
  0.11973543  0.1076356   0.08292281]
[2017-11-01 09:26:54,927] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10156775  0.10516609  0.13398635  0.11970894  0.11481398  0.10600689
  0.11698027  0.1067322   0.09503756]
[2017-11-01 09:26:56,500] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13961068  0.11846684  0.15873279  0.14753169  0.11692596  0.10293696
  0.07727406  0.08756999  0.05095107]
[2017-11-01 09:27:01,587] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13825546  0.20918341  0.27375445  0.23300692  0.11432786  0.01042735
  0.00698011  0.00830472  0.00575972]
[2017-11-01 09:27:04,935] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09566204e-01   3.12878489e-01   1.96461722e-01   2.91487992e-01
   8.96056294e-02   1.41392974e-13   5.93257404e-14   8.56623867e-14
   6.74046187e-14]
[2017-11-01 09:27:07,529] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.08911350e-18   1.80429515e-06   9.78377216e-07   2.59607464e-06
   5.02351384e-07   2.93639749e-01   1.98492661e-01   2.07359359e-01
   3.00502330e-01]
[2017-11-01 09:27:07,586] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.81823584e-18   1.54333804e-06   8.04371382e-07   2.11723250e-06
   4.05699581e-07   2.94932157e-01   1.98201537e-01   2.12289095e-01
   2.94572353e-01]
[2017-11-01 09:27:08,452] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11407504  0.16683072  0.22349213  0.19064808  0.10932807  0.06794526
  0.04874444  0.04894026  0.029996  ]
[2017-11-01 09:27:09,138] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1039368   0.10660879  0.13887259  0.12342823  0.11391624  0.10665882
  0.1139395   0.1054502   0.08718883]
[2017-11-01 09:27:10,830] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10631229  0.10572889  0.13870312  0.12195344  0.11665436  0.10053012
  0.11341366  0.10525384  0.0914503 ]
[2017-11-01 09:27:12,017] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.65286589e-02   2.49791309e-01   3.05299759e-01   2.61747062e-01
   9.66269597e-02   2.05150309e-06   1.08632457e-06   1.60039610e-06
   1.45154058e-06]
[2017-11-01 09:27:12,939] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.68689962e-07   3.58906060e-01   1.97337642e-01   3.33477139e-01
   8.53765309e-02   7.86240119e-03   5.36996126e-03   5.89235127e-03
   5.77741303e-03]
[2017-11-01 09:27:15,768] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14384741  0.21184303  0.26563367  0.22856988  0.12007856  0.00995835
  0.00677393  0.00785313  0.00544213]
[2017-11-01 09:27:16,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07980547  0.08917355  0.12249057  0.10758497  0.10366692  0.12710841
  0.13592935  0.12430068  0.10994004]
[2017-11-01 09:27:17,414] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08062573  0.08812023  0.1240078   0.10933761  0.10615835  0.1199328
  0.13200361  0.12472893  0.11508487]
[2017-11-01 09:27:18,050] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10030612  0.10252668  0.13846113  0.12255073  0.11396521  0.10679792
  0.11641463  0.10847767  0.09049985]
[2017-11-01 09:27:18,844] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13331357  0.1118843   0.14506492  0.141399    0.10457297  0.1116332
  0.09253023  0.09863807  0.06096373]
[2017-11-01 09:27:18,873] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13147293  0.11766112  0.14255351  0.14378123  0.10277756  0.11077183
  0.09082388  0.09923966  0.06091832]
[2017-11-01 09:27:19,446] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.90432649e-02   2.38116547e-01   3.47243488e-01   2.98346251e-01
   9.56296623e-02   5.10086596e-04   2.83713220e-04   4.06394247e-04
   4.20601806e-04]
[2017-11-01 09:27:21,916] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09637579  0.1024382   0.12941501  0.11765629  0.10789666  0.11728301
  0.12595524  0.109665    0.09331482]
[2017-11-01 09:27:24,268] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13870014  0.12859611  0.1723447   0.14796014  0.08181428  0.11751206
  0.07431494  0.09324666  0.04551098]
[2017-11-01 09:27:26,143] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10187953  0.10914371  0.14042665  0.12480875  0.11068879  0.11297898
  0.11574846  0.10453632  0.07978883]
[2017-11-01 09:27:27,928] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11194902  0.11684166  0.13895631  0.13079831  0.08370932  0.13032492
  0.10063528  0.11548989  0.07129525]
[2017-11-01 09:27:28,017] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18904319  0.13059545  0.16523492  0.15148845  0.09944752  0.08994949
  0.06573494  0.07540415  0.03310186]
[2017-11-01 09:27:28,492] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08344781  0.09309666  0.12752576  0.11270155  0.10486602  0.12490876
  0.12971547  0.12122355  0.10251439]
[2017-11-01 09:27:29,738] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.14813092
  0.13596162  0.16799782  0.54790968]
[2017-11-01 09:27:30,754] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.49691803e-09   2.03798264e-01   1.40027761e-01   3.03969115e-01
   6.18786365e-02   8.87006521e-02   5.43251336e-02   6.71880990e-02
   8.01123530e-02]
[2017-11-01 09:27:40,747] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.54725003e-05   1.36199191e-01   2.00544372e-01   2.32045263e-01
   7.41559342e-02   1.03255033e-01   6.70618117e-02   8.37653279e-02
   1.02957681e-01]
[2017-11-01 09:27:43,608] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.90780233e-09   3.00329179e-01   1.80317059e-01   4.25812960e-01
   8.58542696e-02   2.32851179e-03   1.47243345e-03   1.64753816e-03
   2.23807828e-03]
[2017-11-01 09:27:43,897] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10044879  0.16294001  0.22557609  0.19494745  0.1129544   0.06847347
  0.05094537  0.05022715  0.03348735]
[2017-11-01 09:27:52,415] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.96397707e-01   1.93403006e-01   2.48897716e-01   2.54041195e-01
   1.07088789e-01   8.42914669e-05   4.11955662e-05   3.53433206e-05
   1.06922844e-05]
[2017-11-01 09:27:56,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07340914  0.14031193  0.21792206  0.1869013   0.08282661  0.09964229
  0.07129322  0.07797271  0.04972078]
[2017-11-01 09:27:57,787] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10025799  0.11141153  0.13501407  0.12319978  0.10058553  0.12457191
  0.11767896  0.10631043  0.08096979]
[2017-11-01 09:27:59,798] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11499532  0.11502472  0.14359495  0.12650813  0.11350113  0.10251234
  0.10834197  0.09871593  0.07680544]
[2017-11-01 09:28:00,601] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10249737  0.1069953   0.1419825   0.12705958  0.07841063  0.14660831
  0.10258049  0.12228806  0.07157777]
[2017-11-01 09:28:01,077] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1435208   0.2092745   0.28215158  0.23478618  0.1056691   0.00852869
  0.00561176  0.00648329  0.00397406]
[2017-11-01 09:28:03,285] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10313085  0.10987649  0.14444067  0.12766869  0.11130025  0.11216485
  0.11167387  0.10381926  0.07592494]
[2017-11-01 09:28:03,578] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0764619   0.0897559   0.12516087  0.10946459  0.09953471  0.13707301
  0.13459598  0.12695305  0.101     ]
[2017-11-01 09:28:06,151] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11108035  0.10813611  0.1393273   0.12352146  0.110475    0.10560153
  0.11092389  0.10645819  0.08447614]
[2017-11-01 09:28:06,653] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09735948  0.09923656  0.129834    0.11519659  0.10871867  0.11300093
  0.12120351  0.1154599   0.09999037]
[2017-11-01 09:28:08,469] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12840435  0.14163408  0.17479636  0.15786265  0.10253879  0.09200551
  0.07868852  0.0732753   0.05079447]
[2017-11-01 09:28:10,361] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0939218   0.09756213  0.13183926  0.1175691   0.10972867  0.11419927
  0.12347202  0.1142254   0.09748233]
[2017-11-01 09:28:13,620] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.35681808e-01   2.96831518e-01   2.16042832e-01   2.80935824e-01
   7.05079660e-02   4.21217531e-13   1.49091460e-13   2.07166790e-13
   1.40257353e-13]
[2017-11-01 09:28:15,536] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09092233  0.12144933  0.15064593  0.13762905  0.10685024  0.11966363
  0.1028302   0.10033001  0.06967933]
[2017-11-01 09:28:21,190] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0762138   0.08634904  0.12333732  0.10843535  0.10262556  0.12928031
  0.13587512  0.12744556  0.11043788]
[2017-11-01 09:28:23,248] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.92628956e-05   3.17850024e-01   2.44572058e-01   3.64005595e-01
   7.35123232e-02   9.30117949e-06   5.64403308e-06   6.49634148e-06
   9.27312067e-06]
[2017-11-01 09:28:23,730] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08469346  0.18014961  0.290923    0.24153167  0.11020941  0.03250732
  0.02263273  0.02259926  0.01475349]
[2017-11-01 09:28:24,843] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10573005  0.11171068  0.13682067  0.12444863  0.10742231  0.11613104
  0.11689619  0.10270073  0.07813969]
[2017-11-01 09:28:26,408] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10797575  0.11302905  0.13897216  0.12573397  0.09975216  0.1229777
  0.11268142  0.10380895  0.07506873]
[2017-11-01 09:28:32,732] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.04400837e-02   2.24150360e-01   3.20488304e-01   2.72734642e-01
   1.11912139e-01   8.77559796e-05   5.15670399e-05   6.69479123e-05
   6.80707017e-05]
[2017-11-01 09:28:33,806] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.31115763e-04   3.27328295e-01   2.56108791e-01   3.27403218e-01
   8.82283598e-02   8.44573833e-08   4.58283864e-08   5.56825555e-08
   5.66000047e-08]
[2017-11-01 09:28:35,272] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10299791  0.10790506  0.13462393  0.11710995  0.10996239  0.11305442
  0.12008006  0.10713194  0.08713437]
[2017-11-01 09:28:35,397] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09376579  0.10102922  0.13109711  0.11672011  0.10319589  0.12458893
  0.12238488  0.1159506   0.09126741]
[2017-11-01 09:28:38,176] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.20557532  0.15791556  0.20244917  0.18357176  0.1086594   0.05482487
  0.03400604  0.03767702  0.01532085]
[2017-11-01 09:28:40,021] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10392974  0.10472729  0.13323708  0.1167442   0.11398154  0.10409618
  0.11906357  0.10766104  0.09655938]
[2017-11-01 09:28:40,873] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.20700407  0.14056402  0.18425058  0.17050244  0.10717458  0.06280012
  0.04721245  0.05699212  0.02349961]
[2017-11-01 09:28:41,596] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10824789  0.10962649  0.14439929  0.12759244  0.11496562  0.10307456
  0.10953182  0.10215858  0.08040327]
[2017-11-01 09:28:42,363] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15476738  0.18415084  0.27815574  0.22287692  0.11678223  0.01801871
  0.01070028  0.01058316  0.00396476]
[2017-11-01 09:28:42,600] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.51061669e-01   2.12966084e-01   2.79755026e-01   2.66199738e-01
   9.00174230e-02   4.33162395e-09   1.99248884e-09   2.58629407e-09
   2.24449237e-09]
[2017-11-01 09:28:46,180] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.01426686  0.1324942   0.22826234  0.19194944  0.08519687  0.12840994
  0.07172326  0.09502005  0.05267702]
[2017-11-01 09:28:46,549] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17323324e-01   2.01168135e-01   3.01356196e-01   2.76913673e-01
   1.03237733e-01   3.33860157e-07   1.67945871e-07   2.31853505e-07
   2.39754144e-07]
[2017-11-01 09:28:46,784] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1354119   0.19061495  0.25018042  0.21984637  0.1210897   0.02817728
  0.01919927  0.02112806  0.01435202]
[2017-11-01 09:28:47,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12920852  0.11503699  0.13681582  0.12847055  0.10058145  0.11457671
  0.10032529  0.10547543  0.06950927]
[2017-11-01 09:28:47,751] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14316456  0.12112699  0.14229274  0.12833005  0.10499155  0.10717019
  0.09477085  0.09659047  0.06156263]
[2017-11-01 09:28:48,554] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07511047  0.0834059   0.1233932   0.10719912  0.10343628  0.12187005
  0.13514946  0.13041598  0.12001954]
[2017-11-01 09:28:49,515] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10630485  0.17013407  0.27750444  0.22308913  0.11538666  0.04194744
  0.02420186  0.02814457  0.01328695]
[2017-11-01 09:28:49,798] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.26253843e-01   1.97007298e-01   2.99590021e-01   2.82342046e-01
   9.48068053e-02   8.58038796e-09   3.78782206e-09   5.76306203e-09
   6.35954445e-09]
[2017-11-01 09:28:56,907] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12139811  0.12722945  0.18137945  0.14751783  0.07651753  0.12099496
  0.0747031   0.09860603  0.05165362]
[2017-11-01 09:28:58,240] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17848714  0.13392159  0.17227225  0.1589852   0.11112448  0.07582036
  0.06305097  0.07002533  0.03631267]
[2017-11-01 09:28:59,434] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10202769  0.10927762  0.13604516  0.12429226  0.10174804  0.12424794
  0.11708961  0.10790875  0.07736287]
[2017-11-01 09:29:01,584] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0937094   0.10279623  0.13088265  0.11917933  0.09977178  0.13002571
  0.12419973  0.11404274  0.08539241]
[2017-11-01 09:29:03,443] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.26995128  0.15712339  0.20828055  0.17975704  0.09265427  0.03765707
  0.02004722  0.02677068  0.00775846]
[2017-11-01 09:29:03,520] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.26752403  0.16040233  0.21489765  0.1860586   0.09018098  0.03397309
  0.01740562  0.02297972  0.006578  ]
[2017-11-01 09:29:06,521] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17162824  0.13204399  0.16959992  0.15504372  0.1065221   0.08349477
  0.06821615  0.07559212  0.03785903]
[2017-11-01 09:29:09,247] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11233433  0.11719172  0.14286701  0.12807103  0.10712415  0.11251188
  0.10843736  0.10015377  0.07130864]
[2017-11-01 09:29:11,263] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18553258  0.1603594   0.21250328  0.19196607  0.09721281  0.05863016
  0.03481549  0.04111447  0.01786578]
[2017-11-01 09:29:12,412] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10218686  0.16005208  0.23125616  0.20159444  0.09709501  0.06822893
  0.04727685  0.05458538  0.03772432]
[2017-11-01 09:29:22,652] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15644896  0.1284501   0.17297812  0.15562516  0.11334991  0.08247647
  0.07122159  0.07708678  0.04236287]
[2017-11-01 09:29:22,725] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15173757  0.1269993   0.17000513  0.15231954  0.11349564  0.08500382
  0.07513274  0.07980787  0.0454984 ]
[2017-11-01 09:29:23,551] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13621581  0.12208211  0.15428475  0.15184267  0.11119456  0.10622489
  0.0782962   0.08798748  0.05187158]
[2017-11-01 09:29:25,897] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07361355  0.08279705  0.10929387  0.09472525  0.09651067  0.13384736
  0.15428393  0.13002694  0.12490147]
[2017-11-01 09:29:28,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13884909  0.12545741  0.15518686  0.13915159  0.12166198  0.08427183
  0.09022786  0.08391399  0.06127942]
[2017-11-01 09:29:30,168] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08440134  0.09044171  0.12706855  0.1117456   0.10910664  0.11450013
  0.12810938  0.12161909  0.11300763]
[2017-11-01 09:29:31,621] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.10660243e-01   1.75790906e-01   2.16472447e-01   2.09690675e-01
   8.71104971e-02   1.35219554e-04   5.92011820e-05   6.28906055e-05
   1.79457493e-05]
[2017-11-01 09:29:32,383] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14323503  0.11160177  0.14535376  0.13201445  0.11000229  0.10601258
  0.09395159  0.09571265  0.06211592]
[2017-11-01 09:29:32,569] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -13680.4570
[2017-11-01 09:29:32,569] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, -13680.457001338711]
[2017-11-01 09:29:39,517] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.27200598e-01   1.60014212e-01   1.79081678e-01   3.11177284e-01
   1.22526266e-01   8.51563354e-14   3.31872896e-14   3.10218770e-14
   2.74515857e-14], sum to 1.0000
[2017-11-01 09:29:39,569] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.199999999999999, 96.0, 4.683333333333333, 220.0, 0.0, 0.0, 12.2, 22.67210946634166, 13.0, 20.46757693566648, 21.5, 0.0, 13.72459297097778], 
actual action is [2.1999999999999993, 10], 
sim time next is 10500.0000, 
raw observation next is [7.2, 96.0, 4.641666666666666, 220.0, 0.0, 0.0, 2.199999999999999, 23.78877497985173, 10.0, 20.41075759146695, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.5179487179487179, 0.96, 0.4219696969696969, 0.6111111111111112, 0.0, 0.0, 0.5366666666666666, 0.23788774979851732, 0.0, 0.5205378795733475, 0.575, 0.0, 0.0], 
reward next is -0.2723. 
=============================================
[2017-11-01 09:29:40,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.16855435e-02   2.32649669e-01   2.00734109e-01   2.97881454e-01
   2.07049236e-01   1.03911867e-13   2.84886657e-14   5.23411406e-14
   1.03062327e-13], sum to 1.0000
[2017-11-01 09:29:40,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [7.575, 93.75, 4.975, 235.0, 0.0, 0.0, 12.53333333333333, 26.0719990651383, 17.0, 19.93389845392485, 21.5, 0.0, 9.79860637277672], 
actual action is [12.575, 15.0], 
sim time next is 13800.0000, 
raw observation next is [7.616666666666667, 93.5, 5.016666666666667, 236.6666666666667, 0.0, 0.0, 12.575, 26.46545424590899, 15.0, 19.8794495212935, 21.5, 0.0, 9.608277804219027], 
processed observation next is [1.0, 0.13043478260869565, 0.5286324786324786, 0.935, 0.45606060606060606, 0.6574074074074076, 0.0, 0.0, 0.7095833333333333, 0.2646545424590899, 0.25, 0.4939724760646749, 0.575, 0.0, 0.11303856240257679], 
reward next is -0.4617. 
=============================================
[2017-11-01 09:29:43,672] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.76847167e-09   1.27355263e-01   2.56942987e-01   3.64410341e-01
   2.51289845e-01   4.80966037e-07   1.69340666e-07   3.05953961e-07
   6.39650807e-07], sum to 1.0000
[2017-11-01 09:29:43,707] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 12.65833333333333, 24.48998296120365, 16.0, 20.04511832109044, 21.5, 0.0, 10.91878341925177], 
actual action is [12.7, 15.5], 
sim time next is 14700.0000, 
raw observation next is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 12.7, 24.85585527406662, 15.5, 19.99706134557636, 21.5, 0.0, 10.51038484577025], 
processed observation next is [1.0, 0.17391304347826086, 0.5307692307692308, 0.93, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.7116666666666667, 0.2485585527406662, 0.275, 0.49985306727881795, 0.575, 0.0, 0.12365158642082648], 
reward next is -0.4376. 
=============================================
[2017-11-01 09:29:48,791] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.98586041e-01   1.55178830e-01   1.91950962e-01   1.81322783e-01
   1.72961354e-01   3.78684844e-12   1.74483908e-12   3.17007098e-12
   1.23282862e-12], sum to 1.0000
[2017-11-01 09:29:48,865] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [7.7, 93.0, 6.1, 245.8333333333333, 0.0, 0.0, 12.7, 12.88006975497184, 21.5, 21.58823793479645, 21.5, 0.0, 25.13439612877023], 
actual action is [12.7, 21.0], 
sim time next is 27600.0000, 
raw observation next is [7.699999999999999, 93.0, 6.1, 246.6666666666667, 0.0, 0.0, 12.7, 13.15368038248368, 21.0, 21.56289334052171, 21.5, 0.0, 24.01879619186623], 
processed observation next is [1.0, 0.30434782608695654, 0.5307692307692308, 0.93, 0.5545454545454546, 0.6851851851851853, 0.0, 0.0, 0.7116666666666667, 0.1315368038248368, 0.55, 0.5781446670260856, 0.575, 0.0, 0.2825740728454851], 
reward next is -0.1413. 
=============================================
[2017-11-01 09:29:51,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-29.10006523]
 [-30.82395554]
 [-31.12874794]
 [-30.86192703]
 [-31.31096077]], R is [[-30.97624588]
 [-30.89171028]
 [-30.81926918]
 [-30.76073647]
 [-30.71729851]].
[2017-11-01 09:30:09,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.91666049e-02   2.78241932e-01   2.66703051e-02   1.69019967e-01
   4.76901203e-01   1.11359638e-24   7.49003511e-25   5.98177092e-24
   5.40112995e-25], sum to 1.0000
[2017-11-01 09:30:09,340] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [2.975000000000001, 88.25, 5.725, 300.0, 0.0, 0.0, 8.066666666666666, 16.00853353584887, 17.0, 21.78451922670673, 21.5, 0.0, 13.84186079315661], 
actual action is [7.975000000000001, 17.0], 
sim time next is 71400.0000, 
raw observation next is [2.883333333333334, 88.5, 5.683333333333334, 300.0, 0.0, 0.0, 7.975000000000001, 16.4213873659182, 17.0, 21.72015094401717, 21.5, 0.0, 13.34003227414686], 
processed observation next is [1.0, 0.8260869565217391, 0.4072649572649573, 0.885, 0.5166666666666667, 0.8333333333333334, 0.0, 0.0, 0.6329166666666667, 0.164213873659182, 0.35, 0.5860075472008586, 0.575, 0.0, 0.15694155616643365], 
reward next is -0.0785. 
=============================================
[2017-11-01 09:30:29,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.70338738e-01   1.36961192e-01   2.21612260e-01   1.14027493e-01
   1.57060325e-01   1.21388455e-18   6.24663534e-19   8.23966344e-19
   9.19172816e-19], sum to 1.0000
[2017-11-01 09:30:29,709] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-5.566666666666667, 74.33333333333334, 7.133333333333333, 263.3333333333334, 0.0, 0.0, -0.4249999999999998, 14.74813189508585, 26.5, 20.87981594753295, 21.5, 0.0, 47.79576324325013], 
actual action is [-0.5666666666666673, 24.5], 
sim time next is 105900.0000, 
raw observation next is [-5.708333333333333, 74.41666666666666, 7.266666666666666, 264.1666666666666, 0.0, 0.0, -0.5666666666666673, 14.63875559624771, 24.5, 20.91633137746322, 21.5, 0.0, 47.85047364309482], 
processed observation next is [0.0, 0.21739130434782608, 0.18696581196581197, 0.7441666666666665, 0.6606060606060605, 0.7337962962962961, 0.0, 0.0, 0.4905555555555556, 0.1463875559624771, 0.725, 0.545816568873161, 0.575, 0.0, 0.562946748742292], 
reward next is -0.4274. 
=============================================
[2017-11-01 09:30:50,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  8.78175207e-22   8.46704570e-05   1.90214792e-04   9.48293091e-05
   3.98492921e-05   3.21977198e-01   1.70199022e-01   4.45468575e-01
   6.19456135e-02], sum to 1.0000
[2017-11-01 09:30:50,387] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.1, 73.5, 6.899999999999999, 265.0, 184.0, 13.0, -3.049999999999999, 18.88085920091318, 15.5, 21.36682258052287, 22.7, 1.0, 27.30437350378074], 
actual action is [-3.0999999999999996, 20.5], 
sim time next is 128100.0000, 
raw observation next is [-8.15, 71.41666666666666, 7.199999999999999, 264.1666666666667, 179.5, 62.16666666666669, -3.1, 19.47879028287598, 20.5, 21.29504669918197, 22.7, 1.0, 25.54203933168209], 
processed observation next is [0.0, 0.4782608695652174, 0.12435897435897435, 0.7141666666666666, 0.6545454545454544, 0.7337962962962964, 0.4748677248677249, 0.06216666666666669, 0.4483333333333333, 0.1947879028287598, 0.525, 0.5647523349590985, 0.635, 1.0, 0.30049458037273047], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:30:51,000] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.11428601e-31   6.21019569e-10   1.07328768e-09   5.43567191e-10
   1.78234857e-10   2.77661085e-01   1.78921670e-01   5.02043307e-01
   4.13740389e-02], sum to 1.0000
[2017-11-01 09:30:51,073] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-7.799999999999999, 82.0, 5.966666666666667, 263.3333333333334, 189.0, 32.16666666666666, -2.799999999999999, 15.33518432061753, 17.5, 21.77626840160373, 22.7, 1.0, 36.76575559378254], 
actual action is [-2.799999999999999, 19.5], 
sim time next is 125100.0000, 
raw observation next is [-7.8, 83.0, 5.75, 265.0, 188.5, 30.25, -2.799999999999999, 15.82898094770364, 19.5, 21.74410184042648, 22.7, 1.0, 34.13757918879235], 
processed observation next is [0.0, 0.43478260869565216, 0.13333333333333333, 0.83, 0.5227272727272727, 0.7361111111111112, 0.49867724867724866, 0.03025, 0.45333333333333337, 0.1582898094770364, 0.475, 0.5872050920213241, 0.635, 1.0, 0.4016185786916747], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:30:58,046] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   4.32171485e-31   1.96591895e-30   4.55349535e-30
   1.70620219e-31   8.75514597e-02   2.82188654e-01   5.69410861e-01
   6.08490519e-02], sum to 1.0000
[2017-11-01 09:30:58,310] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.7, 61.0, 7.783333333333333, 265.8333333333333, 140.75, 100.9166666666667, -1.7, 17.49360652825753, 21.0, 21.25288476579655, 22.7, 1.0, 56.64425611818885], 
actual action is [-1.7000000000000002, 22.0], 
sim time next is 139200.0000, 
raw observation next is [-6.700000000000001, 61.0, 7.866666666666666, 266.6666666666667, 133.5, 95.83333333333334, -1.7, 17.26050294067599, 22.0, 21.46570890641692, 22.7, 1.0, 49.44615057587177], 
processed observation next is [0.0, 0.6086956521739131, 0.16153846153846152, 0.61, 0.7151515151515151, 0.7407407407407408, 0.3531746031746032, 0.09583333333333334, 0.4716666666666667, 0.17260502940675992, 0.6, 0.573285445320846, 0.635, 1.0, 0.5817194185396679], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:30:58,993] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  8.23356373e-24   1.52100445e-04   1.82992278e-03   2.50824005e-03
   9.54671268e-05   9.49055478e-02   3.19751054e-01   5.06551385e-01
   7.42063224e-02], sum to 1.0000
[2017-11-01 09:30:59,070] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 61.0, 7.2, 260.0, 143.5, 295.0, -1.791666666666667, 16.05071738214527, 24.0, 22.02264173284299, 22.7, 1.0, 55.20156295398037], 
actual action is [-1.7000000000000002, 26.0], 
sim time next is 137100.0000, 
raw observation next is [-6.7, 61.0, 7.283333333333333, 260.8333333333333, 144.25, 263.5, -1.7, 15.16082935839628, 26.0, 22.0030468497182, 22.7, 1.0, 70.06056637054084], 
processed observation next is [0.0, 0.6086956521739131, 0.16153846153846155, 0.61, 0.6621212121212121, 0.724537037037037, 0.3816137566137566, 0.2635, 0.4716666666666667, 0.1516082935839628, 0.8, 0.60015234248591, 0.635, 1.0, 0.8242419573004804], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:31:02,283] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.44345495e-02   1.01443768e-01   4.76109207e-01   3.59803110e-01
   2.82094907e-02   7.69251854e-30   1.18180794e-29   9.23375150e-30
   2.13235747e-30], sum to 1.0000
[2017-11-01 09:31:02,655] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.7, 61.0, 8.116666666666665, 269.1666666666667, 111.75, 80.58333333333334, -1.7, 14.3723339829057, 22.5, 21.92519637453515, 22.7, 1.0, 65.34439405330487], 
actual action is [-1.7000000000000002, 21.5], 
sim time next is 140400.0000, 
raw observation next is [-6.7, 61.0, 8.2, 270.0, 104.5, 75.5, -1.7, 14.16112127332728, 21.5, 22.06307646194625, 22.7, 1.0, 60.45870901233649], 
processed observation next is [0.0, 0.6521739130434783, 0.16153846153846155, 0.61, 0.7454545454545454, 0.75, 0.27645502645502645, 0.0755, 0.4716666666666667, 0.14161121273327282, 0.575, 0.6031538230973125, 0.635, 1.0, 0.7112789295568999], 
reward next is -0.4264. 
=============================================
[2017-11-01 09:31:04,031] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7774: loss 56.3877
[2017-11-01 09:31:06,307] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 7893: loss -0.0846
[2017-11-01 09:31:06,498] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7900: loss 111.1826
[2017-11-01 09:31:06,916] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7925: loss 24.5517
[2017-11-01 09:31:07,081] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7936: loss 96.4266
[2017-11-01 09:31:07,263] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7946: loss 54.9126
[2017-11-01 09:31:07,660] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7967: loss -56.8089
[2017-11-01 09:31:07,910] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 7973: loss 4.6916
[2017-11-01 09:31:08,092] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7986: loss 5.6239
[2017-11-01 09:31:08,173] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7988: loss 262.9944
[2017-11-01 09:31:08,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7997: loss 122.1075
[2017-11-01 09:31:09,232] A3C_AGENT_WORKER-Thread-8 INFO:Local step 500, global step 8036: loss -60.4168
[2017-11-01 09:31:09,389] A3C_AGENT_WORKER-Thread-7 INFO:Local step 500, global step 8041: loss -0.5745
[2017-11-01 09:31:12,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8153: loss 14.3022
[2017-11-01 09:31:12,367] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8168: loss -1.3262
[2017-11-01 09:31:13,945] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8227: loss -23.3613
[2017-11-01 09:31:20,510] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   1.52386556e-38   2.64799167e-38
   0.00000000e+00   3.76642644e-01   4.55456078e-01   9.83611047e-02
   6.95401877e-02], sum to 1.0000
[2017-11-01 09:31:20,738] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-7.949999999999999, 65.0, 6.425000000000001, 262.5, 0.0, 0.0, -2.9, 13.30874336079772, 30.0, 22.89238228150838, 22.7, 1.0, 64.28777619694246], 
actual action is [-2.9499999999999993, 30], 
sim time next is 156000.0000, 
raw observation next is [-8.0, 65.33333333333334, 6.166666666666667, 263.3333333333334, 0.0, 0.0, -2.949999999999999, 13.30759948161779, 30.0, 22.89508852576774, 22.7, 1.0, 64.1557148655361], 
processed observation next is [0.0, 0.8260869565217391, 0.1282051282051282, 0.6533333333333334, 0.5606060606060607, 0.7314814814814817, 0.0, 0.0, 0.45083333333333336, 0.1330759948161779, 1.0, 0.644754426288387, 0.635, 1.0, 0.7547731160651305], 
reward next is -0.4439. 
=============================================
[2017-11-01 09:31:21,606] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.77883703
  0.10489071  0.08798786  0.02828442], sum to 1.0000
[2017-11-01 09:31:21,807] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 70.5, 4.683333333333333, 260.0, 0.0, 0.0, -3.4, 13.73938669275722, 30.0, 22.54595204881383, 21.5, 0.0, 46.4991198509538], 
actual action is [-3.4000000000000004, 30], 
sim time next is 165300.0000, 
raw observation next is [-8.4, 70.75, 4.641666666666666, 260.0, 0.0, 0.0, -3.4, 13.7447681805298, 30.0, 22.52987860422164, 21.5, 0.0, 46.46640050382332], 
processed observation next is [0.0, 0.9130434782608695, 0.11794871794871795, 0.7075, 0.4219696969696969, 0.7222222222222222, 0.0, 0.0, 0.44333333333333336, 0.13744768180529798, 1.0, 0.626493930211082, 0.575, 0.0, 0.546663535339098], 
reward next is -0.2733. 
=============================================
[2017-11-01 09:31:33,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.12738594
  0.09053439  0.36065862  0.42142108], sum to 1.0000
[2017-11-01 09:31:34,021] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.858333333333334, 73.75, 4.058333333333333, 230.0, 0.0, 0.0, -3.816666666666666, 14.3924026651734, 30.0, 21.89654745365873, 21.5, 0.0, 46.19717220634409], 
actual action is [-3.8583333333333343, 30], 
sim time next is 176400.0000, 
raw observation next is [-8.9, 74.0, 4.1, 230.0, 0.0, 0.0, -3.858333333333334, 14.46985132735159, 30.0, 21.87126470426061, 21.5, 0.0, 46.24762875699941], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.10512820512820512, 0.74, 0.3727272727272727, 0.6388888888888888, 0.0, 0.0, 0.43569444444444444, 0.1446985132735159, 1.0, 0.5935632352130306, 0.575, 0.0, 0.5440897500823461], 
reward next is -0.2720. 
=============================================
[2017-11-01 09:31:36,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.26023756e-02   1.21714644e-01   4.38980609e-01   2.87355095e-01
   1.29347280e-01   4.60435728e-16   1.48685397e-16   3.28617020e-16
   6.56593802e-17], sum to 1.0000
[2017-11-01 09:31:37,127] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-8.9, 74.0, 3.366666666666667, 210.0, 0.0, 0.0, -3.9, 14.37923715410549, 30.0, 21.75744958962946, 21.5, 0.0, 45.90890972368702], 
actual action is [-3.9000000000000004, 29.5], 
sim time next is 179100.0000, 
raw observation next is [-8.9, 74.0, 3.275, 207.5, 0.0, 0.0, -3.9, 14.43579673349811, 29.5, 21.73678324439191, 21.5, 0.0, 45.84051247665221], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.10512820512820512, 0.74, 0.29772727272727273, 0.5763888888888888, 0.0, 0.0, 0.435, 0.1443579673349811, 0.975, 0.5868391622195954, 0.575, 0.0, 0.5393001467841436], 
reward next is -0.2697. 
=============================================
[2017-11-01 09:32:05,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.09756286
  0.11817992  0.37392819  0.41032898], sum to 1.0000
[2017-11-01 09:32:05,471] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-7.391666666666667, 75.25, 5.141666666666667, 199.1666666666667, 97.75, 0.0, -2.483333333333333, 14.0967370482446, 30.0, 22.18154664650217, 22.7, 1.0, 63.97334884365997], 
actual action is [-2.3916666666666666, 30], 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 5.1, 200.0, 101.5, 0.0, -2.391666666666667, 13.99800603060801, 30.0, 22.20896212731268, 22.7, 1.0, 63.86678912052152], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.14615384615384616, 0.75, 0.4636363636363636, 0.5555555555555556, 0.26851851851851855, 0.0, 0.46013888888888893, 0.1399800603060801, 1.0, 0.6104481063656341, 0.635, 1.0, 0.7513739896531944], 
reward next is -0.4457. 
=============================================
[2017-11-01 09:32:19,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   1.13191049e-34   1.32463049e-34   8.52871110e-34
   1.54883905e-34   3.96324545e-01   1.67303026e-01   1.69316471e-01
   2.67055899e-01], sum to 1.0000
[2017-11-01 09:32:19,443] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.2, 61.0, 6.633333333333333, 230.0, 49.66666666666667, 0.0, 1.85, 9.093501590989382, 30.0, 23.98825761527869, 22.7, 1.0, 61.68756955507093], 
actual action is [1.7999999999999998, 30], 
sim time next is 229500.0000, 
raw observation next is [-3.25, 61.25, 6.499999999999999, 230.0, 46.5, 0.0, 1.8, 9.082053678738289, 30.0, 23.98997610991171, 22.7, 1.0, 61.66986818712505], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.25, 0.6125, 0.5909090909090908, 0.6388888888888888, 0.12301587301587301, 0.0, 0.53, 0.09082053678738289, 1.0, 0.6994988054955854, 0.635, 1.0, 0.7255278610250006], 
reward next is -0.4082. 
=============================================
[2017-11-01 09:32:19,932] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-38.40668488]
 [-36.53125   ]
 [-37.00181198]
 [-37.07566452]
 [-36.75069809]], R is [[-37.82056046]
 [-37.85488129]
 [-37.88917542]
 [-37.92352676]
 [-37.95782471]].
[2017-11-01 09:32:53,834] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.32903913
  0.22694704  0.17842658  0.26558721], sum to 1.0000
[2017-11-01 09:32:53,989] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.2, 80.5, 6.65, 260.0, 0.0, 0.0, 0.8500000000000014, 7.902318073067317, 30.0, 23.58127384313065, 21.5, 0.0, 46.2863385617056], 
actual action is [0.7999999999999998, 30], 
sim time next is 257700.0000, 
raw observation next is [-4.25, 80.25, 6.558333333333334, 263.3333333333333, 0.0, 0.0, 0.7999999999999998, 7.902625621549863, 30.0, 23.56160220712786, 21.5, 0.0, 46.25283135348322], 
processed observation next is [0.16666666666666666, 1.0, 0.22435897435897437, 0.8025, 0.5962121212121212, 0.7314814814814814, 0.0, 0.0, 0.5133333333333333, 0.07902625621549862, 1.0, 0.6780801103563929, 0.575, 0.0, 0.5441509570998025], 
reward next is -0.2721. 
=============================================
[2017-11-01 09:32:56,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.15292245
  0.24598552  0.2345635   0.36652854], sum to 1.0000
[2017-11-01 09:32:56,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.9, 78.5, 6.65, 235.0, 0.0, 0.0, 1.100000000000001, 7.817479024419763, 30.0, 23.82188548415152, 21.5, 0.0, 45.95608480535714], 
actual action is [1.1, 30], 
sim time next is 254100.0000, 
raw observation next is [-3.899999999999999, 79.08333333333333, 6.741666666666666, 235.8333333333333, 0.0, 0.0, 1.1, 7.806412095176524, 30.0, 23.80609486418489, 21.5, 0.0, 46.01200343536368], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.23333333333333336, 0.7908333333333333, 0.6128787878787878, 0.6550925925925924, 0.0, 0.0, 0.5183333333333333, 0.07806412095176524, 1.0, 0.6903047432092444, 0.575, 0.0, 0.5413176874748669], 
reward next is -0.2707. 
=============================================
[2017-11-01 09:33:18,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.13820965e-05   2.02028796e-01   6.08452499e-01   1.62686825e-01
   2.68005189e-02   5.49263682e-15   5.96001816e-15   4.73076033e-15
   5.67235603e-15], sum to 1.0000
[2017-11-01 09:33:19,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-12.71666666666667, 69.5, 5.183333333333334, 248.3333333333333, 20.0, 265.6666666666667, -7.758333333333329, 14.47165295726397, 30.0, 21.29474224137402, 22.7, 1.0, 64.80995235024334], 
actual action is [-7.71666666666667, 29.5], 
sim time next is 288900.0000, 
raw observation next is [-12.675, 69.25, 5.225, 247.5, 22.5, 295.75, -7.71666666666667, 14.23105737594273, 29.5, 21.35596096155212, 22.7, 1.0, 64.60111033780811], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.008333333333333316, 0.6925, 0.475, 0.6875, 0.05952380952380952, 0.29575, 0.3713888888888889, 0.1423105737594273, 0.975, 0.567798048077606, 0.635, 1.0, 0.7600130627977425], 
reward next is -0.4512. 
=============================================
[2017-11-01 09:33:26,525] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15620: loss 25.0767
[2017-11-01 09:33:27,707] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   9.81171916e-21   4.70482658e-20   1.68129888e-20
   1.28055324e-21   2.24153876e-01   1.92867458e-01   2.56288797e-01
   3.26689839e-01], sum to 1.0000
[2017-11-01 09:33:27,809] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-11.33333333333333, 62.00000000000001, 6.133333333333333, 260.0, 88.33333333333333, 490.5, -6.425000000000001, 17.22836284897075, 18.0, 21.60383248859056, 22.7, 1.0, 24.08093053836434], 
actual action is [-6.33333333333333, 18.5], 
sim time next is 296700.0000, 
raw observation next is [-11.24166666666667, 61.74999999999999, 6.266666666666666, 260.0, 87.66666666666667, 501.25, -6.33333333333333, 17.91499223565067, 18.5, 21.49204951808543, 22.7, 1.0, 22.46179156330663], 
processed observation next is [0.3333333333333333, 0.43478260869565216, 0.04508547008546998, 0.6174999999999999, 0.5696969696969696, 0.7222222222222222, 0.23192239858906527, 0.50125, 0.39444444444444454, 0.17914992235650667, 0.425, 0.5746024759042715, 0.635, 1.0, 0.26425637133301916], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:33:29,829] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.90481275e-01   1.80578098e-01   4.42085505e-01   1.51494592e-01
   3.53604481e-02   5.04329380e-14   2.74128034e-14   2.62302217e-14
   9.06091218e-15], sum to 1.0000
[2017-11-01 09:33:30,078] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-11.24166666666667, 61.74999999999999, 6.266666666666666, 260.0, 87.66666666666667, 501.25, -6.33333333333333, 10.54670094345582, 17.5, 22.74504173062214, 22.7, 1.0, 52.27759541409346], 
actual action is [-6.241666666666671, 16.5], 
sim time next is 297000.0000, 
raw observation next is [-11.15, 61.5, 6.4, 260.0, 87.0, 512.0, -6.241666666666671, 10.77712514555702, 16.5, 22.76236486760022, 22.7, 1.0, 44.58705829040486], 
processed observation next is [0.3333333333333333, 0.43478260869565216, 0.04743589743589743, 0.615, 0.5818181818181819, 0.7222222222222222, 0.23015873015873015, 0.512, 0.39597222222222217, 0.1077712514555702, 0.325, 0.638118243380011, 0.635, 1.0, 0.5245536269459395], 
reward next is -0.3162. 
=============================================
[2017-11-01 09:33:30,200] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 15851: loss 47.1902
[2017-11-01 09:33:30,316] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15860: loss -204.8752
[2017-11-01 09:33:30,424] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15867: loss 35.7110
[2017-11-01 09:33:30,845] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15894: loss 21.8276
[2017-11-01 09:33:30,897] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 15897: loss -75.9216
[2017-11-01 09:33:30,993] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15906: loss -1.4442
[2017-11-01 09:33:31,706] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15966: loss -60.2036
[2017-11-01 09:33:32,427] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1000, global step 16032: loss 22.7165
[2017-11-01 09:33:32,689] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1000, global step 16050: loss 113.8107
[2017-11-01 09:33:32,947] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16069: loss -27.6137
[2017-11-01 09:33:33,172] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16100: loss -6.5348
[2017-11-01 09:33:33,201] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16100: loss -97.9539
[2017-11-01 09:33:33,673] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16148: loss -59.5372
[2017-11-01 09:33:34,260] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16220: loss -43.2122
[2017-11-01 09:33:37,039] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16427: loss 44.3731
[2017-11-01 09:33:45,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  4.02951583e-09   1.10400222e-01   4.40603524e-01   3.36053848e-01
   1.12942442e-01   8.76894802e-13   4.79634344e-13   1.34924244e-13
   4.07568640e-12], sum to 1.0000
[2017-11-01 09:33:46,041] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-9.5, 42.0, 6.499999999999999, 272.5, 58.5, 417.75, -4.5, 16.05965746308625, 17.0, 22.29778040323819, 22.7, 1.0, 24.99259747361251], 
actual action is [-4.5, 17.0], 
sim time next is 316200.0000, 
raw observation next is [-9.5, 42.0, 6.366666666666666, 271.6666666666666, 54.66666666666667, 398.0000000000001, -4.5, 16.76722748272136, 17.0, 22.17742240978061, 22.7, 1.0, 23.26638390263193], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.08974358974358974, 0.42, 0.5787878787878787, 0.7546296296296293, 0.14462081128747797, 0.39800000000000013, 0.425, 0.16767227482721359, 0.35, 0.6088711204890306, 0.635, 1.0, 0.27372216356037565], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:33:54,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.10843130e-37   2.48398680e-11   1.61419211e-11   2.42363317e-11
   5.54963237e-12   4.67465788e-01   4.12853360e-02   1.32229980e-02
   4.78025973e-01], sum to 1.0000
[2017-11-01 09:33:54,897] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-11.425, 55.0, 5.225, 272.5, 0.0, 0.0, -6.33333333333333, 29.08995054567589, 10.5, 20.43221046389184, 22.7, 1.0, 15.19930944612631], 
actual action is [-6.425000000000001, 15.5], 
sim time next is 323400.0000, 
raw observation next is [-11.51666666666667, 55.66666666666666, 5.183333333333333, 271.6666666666666, 0.0, 0.0, -6.425000000000001, 30.07930339044516, 15.5, 20.30341912990756, 22.7, 1.0, 14.55224987698077], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.03803418803418797, 0.5566666666666665, 0.47121212121212114, 0.7546296296296293, 0.0, 0.0, 0.39291666666666664, 0.30079303390445156, 0.275, 0.515170956495378, 0.635, 1.0, 0.17120293972918554], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:34:03,560] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-96.43133545]
 [-95.61206818]
 [-94.37243652]
 [-98.14692688]
 [-97.12889862]], R is [[-98.35469055]
 [-97.72279358]
 [-97.09512329]
 [-96.52416992]
 [-95.95513153]].
[2017-11-01 09:34:03,749] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.65691119
  0.10672849  0.03214953  0.2042108 ], sum to 1.0000
[2017-11-01 09:34:03,866] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-12.8, 71.75, 5.975, 287.5, 0.0, 0.0, -7.800000000000001, 19.73400307195417, 19.5, 21.83724372908444, 21.5, 0.0, 29.06742635993351], 
actual action is [-7.800000000000001, 24.5], 
sim time next is 332400.0000, 
raw observation next is [-12.8, 72.33333333333334, 5.933333333333334, 286.6666666666667, 0.0, 0.0, -7.800000000000001, 20.61469338085953, 24.5, 21.70765210944139, 21.5, 0.0, 27.89739726328522], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.00512820512820511, 0.7233333333333334, 0.5393939393939394, 0.7962962962962964, 0.0, 0.0, 0.37, 0.2061469338085953, 0.725, 0.5853826054720696, 0.575, 0.0, 0.3282046736857085], 
reward next is -0.1641. 
=============================================
[2017-11-01 09:34:19,958] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.4424825   0.12604041  0.04843006  0.22397932  0.15906766  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:34:20,123] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-15.55, 72.66666666666666, 5.141666666666667, 241.6666666666667, 0.0, 0.0, -10.5, 34.06181543218676, 30.0, 19.1508914434516, 21.5, 0.0, 45.3973524639835], 
actual action is [-10.55, 29.5], 
sim time next is 360000.0000, 
raw observation next is [-15.6, 73.0, 5.1, 240.0, 0.0, 0.0, -10.55, 34.30408265867855, 29.5, 19.10173776506052, 21.5, 0.0, 49.49402256367317], 
processed observation next is [0.5, 0.17391304347826086, -0.06666666666666665, 0.73, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.32416666666666666, 0.34304082658678553, 0.975, 0.455086888253026, 0.575, 0.0, 0.5822826183961549], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:34:29,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.34508348  0.05358658  0.06349984  0.34218907  0.19564103  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:34:30,480] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-16.24166666666666, 78.25, 5.558333333333333, 260.0, 0.0, 0.0, -11.2, 41.14503571852337, 29.5, 18.13882606631208, 22.7, 1.0, 79.82288220690354], 
actual action is [-11.24166666666666, 29.5], 
sim time next is 371400.0000, 
raw observation next is [-16.28333333333333, 78.5, 5.516666666666667, 260.0, 0.0, 0.0, -11.24166666666666, 40.44038116091805, 29.5, 18.2028113729545, 22.7, 1.0, 72.77240377638411], 
processed observation next is [0.5, 0.30434782608695654, -0.08418803418803414, 0.785, 0.5015151515151515, 0.7222222222222222, 0.0, 0.0, 0.312638888888889, 0.4044038116091805, 0.975, 0.41014056864772497, 0.635, 1.0, 0.8561459267809896], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:34:45,385] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.11237708
  0.5584653   0.15226644  0.1768911 ], sum to 1.0000
[2017-11-01 09:34:45,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-13.58333333333333, 61.0, 5.266666666666667, 228.3333333333333, 66.66666666666666, 740.6666666666666, -8.675, 25.94397465534639, 28.5, 20.91923587292786, 22.7, 1.0, 63.5126703881057], 
actual action is [-8.58333333333333, 29.5], 
sim time next is 384900.0000, 
raw observation next is [-13.49166666666667, 60.5, 5.433333333333333, 229.1666666666667, 65.58333333333334, 743.5833333333333, -8.58333333333333, 25.70742563465986, 29.5, 20.95922156203826, 22.7, 1.0, 63.61917290355475], 
processed observation next is [0.5, 0.43478260869565216, -0.01260683760683771, 0.605, 0.4939393939393939, 0.6365740740740742, 0.1735008818342152, 0.7435833333333333, 0.3569444444444445, 0.2570742563465986, 0.975, 0.547961078101913, 0.635, 1.0, 0.7484608576888794], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:34:46,740] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.17669151e-04   9.65992361e-02   1.51444152e-01   6.74389720e-01
   7.74492994e-02   2.67904156e-22   3.18960647e-22   6.67884478e-23
   9.96512509e-23], sum to 1.0000
[2017-11-01 09:34:47,040] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-13.25, 57.75, 5.475, 227.5, 61.25, 755.25, -8.3, 22.35631367036475, 30.0, 21.33082944989783, 22.7, 1.0, 63.64866453562699], 
actual action is [-8.25, 29.5], 
sim time next is 386400.0000, 
raw observation next is [-13.2, 57.00000000000001, 5.433333333333334, 226.6666666666667, 60.16666666666666, 758.1666666666667, -8.25, 22.19728596117833, 29.5, 21.36040967317959, 22.7, 1.0, 63.63545285736177], 
processed observation next is [0.5, 0.4782608695652174, -0.00512820512820511, 0.5700000000000001, 0.49393939393939396, 0.6296296296296298, 0.15917107583774248, 0.7581666666666668, 0.3625, 0.2219728596117833, 0.975, 0.5680204836589795, 0.635, 1.0, 0.7486523865571973], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:34:54,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-96.95631409]
 [-95.5297699 ]
 [-91.92990875]
 [-97.68564606]
 [-93.47883606]], R is [[-94.16320801]
 [-94.22158051]
 [-94.27936554]
 [-94.33657074]
 [-94.39320374]].
[2017-11-01 09:35:06,780] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.97736470e-02   1.36250854e-01   2.65888423e-01   2.72027731e-01
   2.96059281e-01   9.61865808e-29   1.05801611e-28   4.42259749e-29
   2.48850251e-28], sum to 1.0000
[2017-11-01 09:35:06,902] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-9.0, 38.33333333333334, 6.1, 215.0, 31.66666666666666, 605.6666666666667, -4.050000000000001, 19.89525193967281, 19.5, 22.25226700349478, 22.7, 1.0, 31.41294920749226], 
actual action is [-4.0, 19.5], 
sim time next is 402900.0000, 
raw observation next is [-8.95, 38.16666666666666, 6.1, 212.5, 30.33333333333334, 580.3333333333334, -4.0, 20.85256521017208, 19.5, 22.11060138598787, 22.7, 1.0, 29.20597620441876], 
processed observation next is [0.5, 0.6521739130434783, 0.10384615384615387, 0.3816666666666666, 0.5545454545454546, 0.5902777777777778, 0.08024691358024692, 0.5803333333333334, 0.43333333333333335, 0.2085256521017208, 0.475, 0.6055300692993935, 0.635, 1.0, 0.3435997200519854], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:35:17,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.13306113e-03   2.03610137e-01   2.30551586e-01   3.91703039e-01
   1.73002198e-01   6.86713452e-23   1.44149563e-23   7.45081649e-24
   8.74898493e-24], sum to 1.0000
[2017-11-01 09:35:17,493] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-10.69166666666667, 49.41666666666666, 3.05, 199.1666666666667, 0.0, 0.0, -5.6, 22.48612139972339, 24.0, 21.25217686480801, 21.5, 0.0, 46.23183343441777], 
actual action is [-5.69166666666667, 22.0], 
sim time next is 425400.0000, 
raw observation next is [-10.78333333333333, 49.83333333333334, 3.1, 198.3333333333333, 0.0, 0.0, -5.69166666666667, 22.49996552680869, 22.0, 21.24671799232688, 21.5, 0.0, 46.26427097928062], 
processed observation next is [0.5, 0.9565217391304348, 0.056837606837606934, 0.4983333333333334, 0.2818181818181818, 0.5509259259259258, 0.0, 0.0, 0.4051388888888888, 0.2249996552680869, 0.6, 0.5623358996163439, 0.575, 0.0, 0.5442855409327132], 
reward next is -0.3355. 
=============================================
[2017-11-01 09:35:26,410] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  4.22305391e-08   1.78860337e-01   2.18703315e-01   5.12488663e-01
   8.99476036e-02   1.13711939e-21   2.80582168e-21   2.74836332e-21
   5.48180953e-21], sum to 1.0000
[2017-11-01 09:35:26,485] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-11.7, 54.0, 3.725, 190.0, 0.0, 0.0, -6.699999999999999, 37.36050941014476, 17.5, 19.72071117998884, 21.5, 0.0, 20.76532098818004], 
actual action is [-6.699999999999999, 17.0], 
sim time next is 429600.0000, 
raw observation next is [-11.7, 54.00000000000001, 3.766666666666667, 190.0, 0.0, 0.0, -6.699999999999999, 38.5698849790729, 17.0, 19.58009169132673, 21.5, 0.0, 19.99020887195414], 
processed observation next is [0.5, 1.0, 0.033333333333333354, 0.54, 0.34242424242424246, 0.5277777777777778, 0.0, 0.0, 0.38833333333333336, 0.38569884979072905, 0.35, 0.47900458456633643, 0.575, 0.0, 0.23517892790534284], 
reward next is -0.5976. 
=============================================
[2017-11-01 09:35:28,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03364089
  0.30174732  0.07651751  0.58809429], sum to 1.0000
[2017-11-01 09:35:28,715] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-10.95, 52.0, 5.391666666666666, 164.1666666666667, 0.0, 0.0, -6.0, 40.10859958900452, 28.0, 18.56933446891073, 21.5, 0.0, 54.60064360401662], 
actual action is [-5.949999999999999, 29.0], 
sim time next is 448200.0000, 
raw observation next is [-10.9, 52.0, 5.35, 165.0, 0.0, 0.0, -5.949999999999999, 39.15093153306863, 29.0, 18.61392577847021, 21.5, 0.0, 52.18376336427475], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.053846153846153835, 0.52, 0.48636363636363633, 0.4583333333333333, 0.0, 0.0, 0.4008333333333333, 0.3915093153306863, 0.95, 0.43069628892351053, 0.575, 0.0, 0.6139266278149971], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:35:29,074] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23566: loss -125.6339
[2017-11-01 09:35:29,861] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23648: loss 36.6907
[2017-11-01 09:35:31,390] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1500, global step 23819: loss 378.6544
[2017-11-01 09:35:31,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   6.27879764e-21   2.25234293e-21   9.17415193e-21
   8.27226303e-22   6.19144924e-02   2.97421753e-01   1.29143313e-01
   5.11520445e-01], sum to 1.0000
[2017-11-01 09:35:31,766] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.9, 50.5, 5.1, 170.0, 0.0, 0.0, -5.85, 38.95473812356973, 27.5, 18.89130492847141, 21.5, 0.0, 49.19418830497856], 
actual action is [-5.9, 30], 
sim time next is 444900.0000, 
raw observation next is [-10.95, 50.75, 5.183333333333333, 168.3333333333333, 0.0, 0.0, -5.9, 38.6280599927756, 30.0, 18.93899613914515, 21.5, 0.0, 49.07001792620198], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.052564102564102586, 0.5075, 0.47121212121212114, 0.46759259259259245, 0.0, 0.0, 0.40166666666666667, 0.386280599927756, 1.0, 0.4469498069572575, 0.575, 0.0, 0.5772943285435527], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:35:32,148] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 23904: loss -210.5686
[2017-11-01 09:35:32,279] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23914: loss 172.6453
[2017-11-01 09:35:32,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23917: loss -52.0049
[2017-11-01 09:35:32,440] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23925: loss 13.2145
[2017-11-01 09:35:32,564] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23941: loss -49.6172
[2017-11-01 09:35:33,039] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24006: loss 22.4000
[2017-11-01 09:35:33,048] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24008: loss 65.2413
[2017-11-01 09:35:33,354] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24039: loss -44.1955
[2017-11-01 09:35:33,962] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24104: loss -239.6571
[2017-11-01 09:35:34,143] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24125: loss -51.3593
[2017-11-01 09:35:34,349] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24144: loss 61.9659
[2017-11-01 09:35:34,595] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-100.35079193]
 [-105.07461548]
 [-103.1756897 ]
 [-102.10081482]
 [-105.91770172]], R is [[-105.56876373]
 [-105.51307678]
 [-105.45794678]
 [-105.40336609]
 [-105.34933472]].
[2017-11-01 09:35:36,177] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1500, global step 24297: loss -88.3270
[2017-11-01 09:35:37,064] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.09544797
  0.33217159  0.53233355  0.04004689], sum to 1.0000
[2017-11-01 09:35:37,456] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-8.35, 42.75, 4.183333333333333, 180.8333333333333, 0.0, 0.0, -3.4, 33.68497825859004, 29.0, 19.18644202560665, 22.7, 1.0, 76.02223191712982], 
actual action is [-3.3499999999999996, 30], 
sim time next is 457800.0000, 
raw observation next is [-8.3, 42.5, 4.266666666666667, 181.6666666666667, 0.0, 0.0, -3.35, 32.63996352764152, 30.0, 19.30023242052624, 22.7, 1.0, 69.18211465380888], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.1205128205128205, 0.425, 0.3878787878787879, 0.5046296296296298, 0.0, 0.0, 0.44416666666666665, 0.3263996352764152, 1.0, 0.46501162102631194, 0.635, 1.0, 0.813907231221281], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:35:37,975] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24416: loss 28.2472
[2017-11-01 09:35:43,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  7.95526462e-17   2.42150426e-01   3.06574255e-01   3.60351920e-01
   9.08502489e-02   2.78462066e-05   2.75806451e-05   1.45997701e-05
   3.09314078e-06], sum to 1.0000
[2017-11-01 09:35:43,807] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.641666666666667, 32.08333333333334, 3.766666666666667, 179.1666666666667, 77.0, 0.0, 0.2166666666666668, 29.59176183732894, 17.5, 20.75358003773753, 22.7, 1.0, 33.92469772734641], 
actual action is [0.3583333333333334, 16.5], 
sim time next is 468000.0000, 
raw observation next is [-4.5, 32.0, 3.6, 180.0, 80.0, 0.0, 0.3583333333333334, 30.47497809025691, 16.5, 20.67895142040792, 22.7, 1.0, 31.51058340797893], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.21794871794871795, 0.32, 0.32727272727272727, 0.5, 0.21164021164021163, 0.0, 0.5059722222222223, 0.3047497809025691, 0.325, 0.533947571020396, 0.635, 1.0, 0.3707127459762227], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:35:44,044] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.42443352e-08   2.82778174e-01   2.79023528e-01   3.43917757e-01
   9.42804739e-02   8.51053093e-21   8.24818624e-21   2.95429474e-21
   6.93235111e-22], sum to 1.0000
[2017-11-01 09:35:44,376] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.2, 42.0, 4.433333333333334, 183.3333333333333, 0.0, 0.0, -3.25, 30.85103399237611, 25.0, 19.82607412688822, 22.7, 1.0, 65.74089678228246], 
actual action is [-3.1999999999999993, 24.0], 
sim time next is 458700.0000, 
raw observation next is [-8.149999999999999, 41.75, 4.516666666666666, 184.1666666666667, 0.0, 0.0, -3.199999999999999, 30.50440811431339, 24.0, 19.92024526313238, 22.7, 1.0, 65.48956616799383], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.12435897435897439, 0.4175, 0.41060606060606053, 0.5115740740740742, 0.0, 0.0, 0.44666666666666666, 0.30504408114313386, 0.7, 0.49601226315661895, 0.635, 1.0, 0.7704654843293391], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:36:16,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.58249456e-02   1.72549933e-01   3.06273401e-01   2.97794014e-01
   2.07557738e-01   7.27175850e-21   1.09478962e-20   7.34939634e-21
   1.41870991e-20], sum to 1.0000
[2017-11-01 09:36:16,897] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.55, 85.0, 6.058333333333333, 167.5, 0.0, 0.0, 5.5, 12.42283182077878, 30.0, 23.59966467981524, 22.7, 1.0, 61.44015246574948], 
actual action is [5.55, 29.5], 
sim time next is 497400.0000, 
raw observation next is [0.6000000000000001, 86.0, 6.016666666666667, 165.0, 0.0, 0.0, 5.55, 12.32497558717397, 29.5, 23.61496599733938, 22.7, 1.0, 61.39905076504045], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3487179487179487, 0.86, 0.546969696969697, 0.4583333333333333, 0.0, 0.0, 0.5924999999999999, 0.1232497558717397, 0.975, 0.6807482998669689, 0.635, 1.0, 0.7223417737063582], 
reward next is -0.4228. 
=============================================
[2017-11-01 09:36:18,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   1.95494154e-38   2.13519098e-38   1.44266681e-37
   4.07892676e-38   1.53684080e-01   1.38867438e-01   1.55932844e-01
   5.51515579e-01], sum to 1.0000
[2017-11-01 09:36:19,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.55, 80.58333333333333, 6.1, 170.0, 0.0, 0.0, 5.6, 13.05724513493753, 30.0, 23.33203939697748, 22.7, 1.0, 62.47732006400869], 
actual action is [5.55, 30], 
sim time next is 496800.0000, 
raw observation next is [0.5, 84.0, 6.1, 170.0, 0.0, 0.0, 5.55, 12.86205023840068, 30.0, 23.38425492446683, 22.7, 1.0, 61.8822392484248], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.34615384615384615, 0.84, 0.5545454545454546, 0.4722222222222222, 0.0, 0.0, 0.5924999999999999, 0.1286205023840068, 1.0, 0.6692127462233415, 0.635, 1.0, 0.7280263440991154], 
reward next is -0.4283. 
=============================================
[2017-11-01 09:36:27,271] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-28.93973923]
 [-28.88941383]
 [-28.97381973]
 [-29.9568119 ]
 [-29.82112122]], R is [[-28.50341415]
 [-28.47437859]
 [-28.44584084]
 [-28.41770744]
 [-28.38999367]].
[2017-11-01 09:36:31,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.14137033
  0.19155115  0.26413068  0.40294787], sum to 1.0000
[2017-11-01 09:36:31,632] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [3.591666666666667, 96.58333333333334, 4.683333333333334, 193.3333333333333, 0.0, 0.0, 8.55, 7.419183653700539, 30.0, 24.17123035501985, 21.5, 0.0, 43.21271857180933], 
actual action is [8.591666666666667, 30], 
sim time next is 517200.0000, 
raw observation next is [3.633333333333333, 96.66666666666666, 4.766666666666666, 196.6666666666667, 0.0, 0.0, 8.591666666666667, 7.368580100532401, 30.0, 24.17435265427878, 21.5, 0.0, 43.31837538340516], 
processed observation next is [0.6666666666666666, 1.0, 0.4264957264957265, 0.9666666666666666, 0.43333333333333324, 0.5462962962962964, 0.0, 0.0, 0.6431944444444445, 0.07368580100532401, 1.0, 0.7087176327139391, 0.575, 0.0, 0.5096279456871196], 
reward next is -0.2548. 
=============================================
[2017-11-01 09:36:46,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.28147319
  0.23562506  0.20213211  0.28076971], sum to 1.0000
[2017-11-01 09:36:46,624] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.6, 85.0, 6.1, 280.0, 0.0, 0.0, 6.691666666666667, 5.614323907852643, 30.0, 23.94234016959964, 21.5, 0.0, 44.48468438536418], 
actual action is [6.6, 30], 
sim time next is 536700.0000, 
raw observation next is [1.558333333333334, 85.24999999999999, 6.016666666666666, 279.9999999999999, 0.0, 0.0, 6.6, 5.611875662798548, 30.0, 23.92332405910512, 21.5, 0.0, 44.49747049876643], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.3732905982905983, 0.8524999999999998, 0.5469696969696969, 0.7777777777777775, 0.0, 0.0, 0.61, 0.05611875662798548, 1.0, 0.696166202955256, 0.575, 0.0, 0.5234996529266639], 
reward next is -0.2617. 
=============================================
[2017-11-01 09:36:47,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.29192591
  0.41445479  0.19735824  0.09626108], sum to 1.0000
[2017-11-01 09:36:47,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 5.266666666666666, 290.0, 0.0, 0.0, 5.5, 5.861582421058503, 30.0, 23.31503728030598, 21.5, 0.0, 44.49461225733629], 
actual action is [5.5, 30], 
sim time next is 546300.0000, 
raw observation next is [0.5, 92.0, 5.225, 290.0, 0.0, 0.0, 5.5, 5.862913746441238, 30.0, 23.30492268098658, 21.5, 0.0, 44.47017619306342], 
processed observation next is [0.8333333333333334, 0.30434782608695654, 0.34615384615384615, 0.92, 0.475, 0.8055555555555556, 0.0, 0.0, 0.5916666666666667, 0.05862913746441238, 1.0, 0.665246134049329, 0.575, 0.0, 0.523178543447805], 
reward next is -0.2616. 
=============================================
[2017-11-01 09:36:57,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.33710518e-01   6.75217360e-02   1.22688435e-01   1.13961041e-01
   5.62118292e-01   1.69487769e-14   1.84224431e-14   9.12840207e-15
   4.01195080e-15], sum to 1.0000
[2017-11-01 09:36:57,463] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.5, 92.0, 5.266666666666666, 290.0, 0.0, 0.0, 5.5, 5.830012122464935, 18.5, 23.38078242553535, 21.5, 0.0, 29.62151607107404], 
actual action is [5.5, 18.5], 
sim time next is 546300.0000, 
raw observation next is [0.5, 92.0, 5.225, 290.0, 0.0, 0.0, 5.5, 5.977131933556105, 18.5, 23.29181375910909, 21.5, 0.0, 28.26046999476102], 
processed observation next is [0.8333333333333334, 0.30434782608695654, 0.34615384615384615, 0.92, 0.475, 0.8055555555555556, 0.0, 0.0, 0.5916666666666667, 0.059771319335561054, 0.425, 0.6645906879554545, 0.575, 0.0, 0.3324761175854238], 
reward next is -0.1662. 
=============================================
[2017-11-01 09:37:01,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-31.65106964]
 [-31.51474762]
 [-31.03775978]
 [-30.67243576]
 [-30.46472931]], R is [[-31.48404121]
 [-31.22345543]
 [-30.96355629]
 [-30.70423317]
 [-30.44540024]].
[2017-11-01 09:37:02,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.56602968e-04   1.83785379e-01   4.83176678e-01   1.91778407e-01
   1.41102478e-01   1.10312904e-07   1.04962986e-07   9.94437030e-08
   1.38093398e-07], sum to 1.0000
[2017-11-01 09:37:02,130] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-1.2, 80.0, 6.800000000000001, 325.0, 136.0, 545.25, -6.2, 11.93254544906761, 10.0, 22.19067867070113, 22.7, 1.0, 0.0], 
actual action is [-6.2, 10], 
sim time next is 566400.0000, 
raw observation next is [-1.2, 80.0, 6.666666666666667, 323.3333333333334, 136.6666666666667, 561.8333333333334, -6.2, 12.26667349557197, 10.0, 22.10543495126214, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.3025641025641026, 0.8, 0.6060606060606061, 0.8981481481481484, 0.36155202821869503, 0.5618333333333334, 0.39666666666666667, 0.1226667349557197, 0.0, 0.605271747563107, 0.635, 1.0, 0.0], 
reward next is -0.0613. 
=============================================
[2017-11-01 09:37:03,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  6.18669333e-07   2.39271745e-01   3.16326439e-01   3.08207631e-01
   1.36174917e-01   5.30046918e-06   5.43146825e-06   4.58129807e-06
   3.31249794e-06], sum to 1.0000
[2017-11-01 09:37:03,576] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.7500000000000001, 81.5, 6.1, 327.5, 99.25, 200.25, 4.266666666666667, 14.80882185625313, 16.5, 21.25098642445914, 22.7, 1.0, 8.70153212154426], 
actual action is [4.25, 14.5], 
sim time next is 561000.0000, 
raw observation next is [-0.7666666666666667, 81.33333333333333, 6.1, 328.3333333333333, 102.6666666666667, 222.0, 4.25, 15.05787579951905, 14.5, 21.2141737529789, 22.7, 1.0, 8.496532196692476], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.31367521367521367, 0.8133333333333332, 0.5545454545454546, 0.912037037037037, 0.27160493827160503, 0.222, 0.5708333333333333, 0.1505787579951905, 0.225, 0.5607086876489451, 0.635, 1.0, 0.09995920231402913], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:13,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.59898445e-01   3.79512787e-01   9.24969465e-02   1.71185151e-01
   1.96906671e-01   1.39257763e-20   1.09809527e-20   1.10670772e-20
   3.91800883e-21], sum to 1.0000
[2017-11-01 09:37:13,109] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.591666666666666, 87.0, 5.391666666666666, 278.3333333333333, 0.0, 0.0, 2.45, 20.81310673222837, 19.5, 20.93647262107149, 22.7, 1.0, 11.77003200728005], 
actual action is [2.408333333333334, 14.5], 
sim time next is 585600.0000, 
raw observation next is [-2.633333333333333, 87.0, 5.433333333333334, 276.6666666666667, 0.0, 0.0, 2.408333333333334, 21.25360271189738, 14.5, 20.86092755451272, 22.7, 1.0, 11.23435147506552], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.2658119658119658, 0.87, 0.49393939393939396, 0.7685185185185186, 0.0, 0.0, 0.5401388888888888, 0.2125360271189738, 0.225, 0.543046377725636, 0.635, 1.0, 0.13216884088312375], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:13,324] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.09881950e-23   3.38294193e-09   6.25685892e-10   1.04939479e-09
   1.37763645e-09   2.25800917e-01   1.73890069e-01   3.19501072e-01
   2.80808032e-01], sum to 1.0000
[2017-11-01 09:37:13,345] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.75, 87.0, 5.1, 280.8333333333333, 0.0, 0.0, 3.3, 16.19359045270388, 12.0, 21.50497257064563, 22.7, 1.0, 24.57068373791718], 
actual action is [3.25, 14.0], 
sim time next is 580200.0000, 
raw observation next is [-1.8, 87.0, 5.1, 281.6666666666667, 0.0, 0.0, 3.25, 16.37767492472545, 14.0, 21.44433808767716, 22.7, 1.0, 13.98363119663619], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.28717948717948716, 0.87, 0.4636363636363636, 0.7824074074074074, 0.0, 0.0, 0.5541666666666667, 0.1637767492472545, 0.2, 0.572216904383858, 0.635, 1.0, 0.16451330819571988], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:13,460] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31290: loss -6.8571
[2017-11-01 09:37:17,419] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  8.33888427e-12   3.76515120e-01   1.54672474e-01   1.32048294e-01
   3.14062566e-01   9.51546803e-03   5.76016167e-03   5.62020624e-03
   1.80555915e-03], sum to 1.0000
[2017-11-01 09:37:17,482] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.716666666666667, 87.0, 5.516666666666667, 273.3333333333333, 0.0, 0.0, 2.325, 18.78080141078308, 19.5, 21.15547878411388, 22.7, 1.0, 27.05373408189958], 
actual action is [2.283333333333333, 19.5], 
sim time next is 586500.0000, 
raw observation next is [-2.758333333333333, 87.0, 5.558333333333333, 271.6666666666667, 0.0, 0.0, 2.283333333333333, 19.18824543016487, 19.5, 21.14616193864287, 22.7, 1.0, 25.14137911649305], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.2626068376068376, 0.87, 0.5053030303030303, 0.7546296296296297, 0.0, 0.0, 0.5380555555555555, 0.19188245430164869, 0.475, 0.5573080969321434, 0.635, 1.0, 0.29578093078227113], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:18,283] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31753: loss 9.3241
[2017-11-01 09:37:19,240] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31861: loss -41.4441
[2017-11-01 09:37:19,646] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31908: loss 18.4589
[2017-11-01 09:37:19,648] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 31908: loss 19.9616
[2017-11-01 09:37:19,660] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31910: loss -3.3432
[2017-11-01 09:37:19,682] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2000, global step 31911: loss -22.2297
[2017-11-01 09:37:19,765] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31924: loss 4.6962
[2017-11-01 09:37:20,306] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 31996: loss -18.8128
[2017-11-01 09:37:20,550] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32025: loss 9.1939
[2017-11-01 09:37:20,552] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32025: loss -40.6827
[2017-11-01 09:37:21,162] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32102: loss 48.5942
[2017-11-01 09:37:21,383] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32123: loss 24.9808
[2017-11-01 09:37:22,102] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2000, global step 32213: loss -15.1632
[2017-11-01 09:37:24,965] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32582: loss 14.6432
[2017-11-01 09:37:25,021] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32587: loss 59.3480
[2017-11-01 09:37:38,989] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.75656009e-01   2.24478811e-01   9.45930928e-02   1.14561617e-01
   1.90710470e-01   1.56177421e-30   1.14579215e-29   2.65828944e-30
   3.65279584e-30], sum to 1.0000
[2017-11-01 09:37:39,250] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.899999999999999, 67.5, 8.991666666666665, 250.0, 132.0833333333333, 46.75, 1.1, 18.2313954123123, 29.5, 20.93254085416583, 22.7, 1.0, 67.73674395228127], 
actual action is [1.100000000000001, 28.5], 
sim time next is 639600.0000, 
raw observation next is [-3.899999999999999, 67.0, 9.033333333333333, 250.0, 129.1666666666667, 42.5, 1.100000000000001, 17.39129759193855, 28.5, 21.16345442969415, 22.7, 1.0, 66.12321249360623], 
processed observation next is [1.0, 0.391304347826087, 0.23333333333333336, 0.67, 0.8212121212121212, 0.6944444444444444, 0.34171075837742515, 0.0425, 0.5183333333333333, 0.17391297591938548, 0.925, 0.5581727214847074, 0.635, 1.0, 0.7779201469836027], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:42,677] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.05380339e-02   4.79142368e-01   2.96780825e-01   1.03533305e-01
   1.00005507e-01   8.60044046e-27   8.66231335e-26   2.22983167e-26
   4.53721916e-26], sum to 1.0000
[2017-11-01 09:37:42,708] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.899999999999999, 67.0, 9.033333333333333, 250.0, 129.1666666666667, 42.5, 1.100000000000001, 19.45080131822498, 11.5, 21.45402406377102, 22.7, 1.0, 30.53814302108235], 
actual action is [-8.899999999999999, 10], 
sim time next is 639900.0000, 
raw observation next is [-3.9, 66.5, 9.075, 250.0, 126.25, 38.25, -8.899999999999999, 21.7794123064326, 10.0, 21.36016169505292, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.23333333333333334, 0.665, 0.825, 0.6944444444444444, 0.333994708994709, 0.03825, 0.3516666666666667, 0.217794123064326, 0.0, 0.568008084752646, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:48,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00557213
  0.08575912  0.04690902  0.86175972], sum to 1.0000
[2017-11-01 09:37:48,917] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.566666666666666, 65.0, 8.866666666666665, 243.3333333333333, 98.16666666666667, 6.333333333333332, 1.391666666666667, 13.90161540638075, 29.0, 22.15477200077928, 22.7, 1.0, 64.91997889083798], 
actual action is [1.433333333333334, 30], 
sim time next is 643500.0000, 
raw observation next is [-3.525, 65.0, 8.825, 242.5, 97.25, 9.5, 1.433333333333334, 13.73869289870134, 30.0, 22.20610048445014, 22.7, 1.0, 64.84678996299685], 
processed observation next is [1.0, 0.43478260869565216, 0.24294871794871795, 0.65, 0.8022727272727272, 0.6736111111111112, 0.25727513227513227, 0.0095, 0.5238888888888888, 0.1373869289870134, 1.0, 0.610305024222507, 0.635, 1.0, 0.7629034113293747], 
reward next is -0.4501. 
=============================================
[2017-11-01 09:38:22,587] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.70618994e-32   5.35061734e-15   2.14057465e-15   3.45788813e-15
   5.09672133e-15   1.87626600e-01   2.44935364e-01   4.38326716e-01
   1.29111260e-01], sum to 1.0000
[2017-11-01 09:38:22,694] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.1, 67.0, 3.85, 240.0, 0.0, 0.0, 1.95, 7.973539013257789, 30.0, 24.03093064794039, 21.5, 0.0, 43.92896166148227], 
actual action is [1.9, 30], 
sim time next is 678900.0000, 
raw observation next is [-3.15, 67.33333333333333, 3.891666666666667, 240.0, 0.0, 0.0, 1.9, 7.960438083001741, 30.0, 24.01823993459296, 21.5, 0.0, 43.96092967916727], 
processed observation next is [1.0, 0.8695652173913043, 0.25256410256410255, 0.6733333333333333, 0.3537878787878788, 0.6666666666666666, 0.0, 0.0, 0.5316666666666666, 0.07960438083001742, 1.0, 0.700911996729648, 0.575, 0.0, 0.5171874079902032], 
reward next is -0.2586. 
=============================================
[2017-11-01 09:38:23,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.22173479
  0.2152015   0.43898508  0.12407865], sum to 1.0000
[2017-11-01 09:38:23,751] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.716666666666667, 64.5, 3.85, 241.6666666666667, 0.0, 0.0, 2.325, 7.821363554258658, 30.0, 24.19072420774873, 21.5, 0.0, 43.88111473179519], 
actual action is [2.283333333333333, 30], 
sim time next is 676500.0000, 
raw observation next is [-2.758333333333333, 64.75, 3.725, 240.8333333333333, 0.0, 0.0, 2.283333333333333, 7.800387765026056, 30.0, 24.1812612958361, 21.5, 0.0, 43.80930264024152], 
processed observation next is [1.0, 0.8260869565217391, 0.2626068376068376, 0.6475, 0.3386363636363636, 0.6689814814814814, 0.0, 0.0, 0.5380555555555555, 0.07800387765026055, 1.0, 0.709063064791805, 0.575, 0.0, 0.5154035604734296], 
reward next is -0.2577. 
=============================================
[2017-11-01 09:38:26,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.27101621
  0.2711817   0.32258704  0.13521501], sum to 1.0000
[2017-11-01 09:38:26,402] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.2, 57.0, 6.249999999999999, 252.5, 0.0, 0.0, 3.8, 7.914156834981201, 30.0, 24.33464174021771, 22.7, 1.0, 60.63200909403978], 
actual action is [3.8, 30], 
sim time next is 669000.0000, 
raw observation next is [-1.2, 57.0, 6.033333333333333, 251.6666666666667, 0.0, 0.0, 3.8, 7.896724757583057, 30.0, 24.34029652237976, 22.7, 1.0, 60.48671758346484], 
processed observation next is [1.0, 0.7391304347826086, 0.3025641025641026, 0.57, 0.5484848484848485, 0.6990740740740742, 0.0, 0.0, 0.5633333333333332, 0.07896724757583057, 1.0, 0.7170148261189879, 0.635, 1.0, 0.7116084421584099], 
reward next is -0.3953. 
=============================================
[2017-11-01 09:38:36,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.32121646
  0.29716733  0.21713379  0.16448243], sum to 1.0000
[2017-11-01 09:38:36,396] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 69.0, 3.766666666666667, 240.0, 0.0, 0.0, 1.6, 7.280195703932899, 30.0, 23.97959534838514, 21.5, 0.0, 44.05986542405243], 
actual action is [1.6, 30], 
sim time next is 683100.0000, 
raw observation next is [-3.4, 69.0, 3.725, 240.0, 0.0, 0.0, 1.6, 7.268109083235563, 30.0, 23.96641663150035, 21.5, 0.0, 44.0585008026513], 
processed observation next is [1.0, 0.9130434782608695, 0.24615384615384614, 0.69, 0.3386363636363636, 0.6666666666666666, 0.0, 0.0, 0.5266666666666667, 0.07268109083235563, 1.0, 0.6983208315750176, 0.575, 0.0, 0.5183353035606035], 
reward next is -0.2592. 
=============================================
[2017-11-01 09:38:36,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.32248032
  0.2977908   0.21576431  0.16396458], sum to 1.0000
[2017-11-01 09:38:36,736] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.399999999999999, 69.0, 3.641666666666667, 240.0, 0.0, 0.0, 1.6, 7.242969288954834, 30.0, 23.94095910047794, 21.5, 0.0, 43.98504265428684], 
actual action is [1.600000000000001, 30], 
sim time next is 684000.0000, 
raw observation next is [-3.4, 69.0, 3.6, 240.0, 0.0, 0.0, 1.600000000000001, 7.229524418336479, 30.0, 23.92791254604557, 21.5, 0.0, 43.95459977012935], 
processed observation next is [1.0, 0.9565217391304348, 0.24615384615384614, 0.69, 0.32727272727272727, 0.6666666666666666, 0.0, 0.0, 0.5266666666666667, 0.07229524418336479, 1.0, 0.6963956273022784, 0.575, 0.0, 0.51711293847211], 
reward next is -0.2586. 
=============================================
[2017-11-01 09:38:44,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   1.73594401e-37   7.19531168e-38   1.04302109e-37
   1.47031219e-37   2.68287152e-01   2.53049761e-01   2.29506180e-01
   2.49157012e-01], sum to 1.0000
[2017-11-01 09:38:44,786] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.3, 76.0, 5.475, 250.0, 0.0, 0.0, 2.7, 7.86459928106315, 30.0, 22.63967378817137, 21.5, 0.0, 45.34022761595271], 
actual action is [2.7, 30], 
sim time next is 714000.0000, 
raw observation next is [-2.3, 76.0, 5.433333333333334, 250.0, 0.0, 0.0, 2.7, 7.87475303090019, 30.0, 22.62975137364063, 21.5, 0.0, 45.33045834757173], 
processed observation next is [0.0, 0.2608695652173913, 0.27435897435897433, 0.76, 0.49393939393939396, 0.6944444444444444, 0.0, 0.0, 0.545, 0.0787475303090019, 1.0, 0.6314875686820315, 0.575, 0.0, 0.533299509971432], 
reward next is -0.2666. 
=============================================
[2017-11-01 09:38:52,863] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  8.01942515e-05   2.09688589e-01   2.60866106e-01   2.55906403e-01
   2.73452103e-01   1.85703175e-06   1.50934159e-06   2.32207162e-06
   8.69284975e-07], sum to 1.0000
[2017-11-01 09:38:53,238] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 76.0, 4.183333333333333, 260.0, 52.99999999999999, 16.33333333333333, 2.7, 6.886750812440742, 30.0, 23.72230356204189, 22.7, 1.0, 60.80792101286112], 
actual action is [2.7, 30.0], 
sim time next is 723300.0000, 
raw observation next is [-2.3, 76.0, 4.141666666666667, 260.0, 59.0, 20.41666666666666, 2.7, 6.85090809666457, 30.0, 23.76186507947813, 22.7, 1.0, 60.69306068320236], 
processed observation next is [0.0, 0.34782608695652173, 0.27435897435897433, 0.76, 0.3765151515151515, 0.7222222222222222, 0.15608465608465608, 0.02041666666666666, 0.545, 0.06850908096664571, 1.0, 0.6880932539739065, 0.635, 1.0, 0.7140360080376749], 
reward next is -0.3913. 
=============================================
[2017-11-01 09:39:00,727] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39106: loss 5.9949
[2017-11-01 09:39:04,572] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 39674: loss -15.6348
[2017-11-01 09:39:06,458] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39903: loss -52.0646
[2017-11-01 09:39:06,495] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39907: loss 22.0274
[2017-11-01 09:39:06,510] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39911: loss 1.5984
[2017-11-01 09:39:06,670] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39932: loss -17.3829
[2017-11-01 09:39:06,787] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39946: loss -12.9394
[2017-11-01 09:39:06,854] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 39957: loss 16.1119
[2017-11-01 09:39:07,279] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40006: loss -40.4072
[2017-11-01 09:39:07,298] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 40008: loss -39.8614
[2017-11-01 09:39:08,094] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40088: loss -26.4272
[2017-11-01 09:39:08,239] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40098: loss -19.5558
[2017-11-01 09:39:08,258] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40100: loss 1.6605
[2017-11-01 09:39:10,458] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 40290: loss 1.6718
[2017-11-01 09:39:11,663] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40390: loss 11.6262
[2017-11-01 09:39:12,478] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40468: loss 2.2716
[2017-11-01 09:39:39,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   3.39306917e-26   4.20550962e-26   1.08204360e-26
   3.75761936e-26   2.45577037e-01   2.03515992e-01   2.32096493e-01
   3.18810552e-01], sum to 1.0000
[2017-11-01 09:39:39,412] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.058333333333334, 74.66666666666667, 2.458333333333333, 78.33333333333333, 76.16666666666666, 0.0, -1.2, 16.50955430987598, 23.5, 21.78176270697959, 22.7, 1.0, 57.33454642505245], 
actual action is [-1.0583333333333336, 24.0], 
sim time next is 814200.0000, 
raw observation next is [-5.916666666666667, 74.33333333333333, 2.416666666666667, 76.66666666666667, 78.33333333333334, 0.0, -1.058333333333334, 16.15864627203677, 24.0, 21.80362357249956, 22.7, 1.0, 60.53741580368858], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.18162393162393162, 0.7433333333333333, 0.21969696969696972, 0.21296296296296297, 0.20723104056437391, 0.0, 0.48236111111111113, 0.1615864627203677, 0.7, 0.590181178624978, 0.635, 1.0, 0.712204891808101], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:39:44,691] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.29267214e-28   1.70609887e-10   4.10486471e-11   4.67675759e-11
   7.56707197e-11   2.55475849e-01   2.37810120e-01   1.57029480e-01
   3.49684626e-01], sum to 1.0000
[2017-11-01 09:39:44,729] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 71.0, 2.416666666666667, 60.0, 106.3333333333333, 0.0, 0.5, 19.31424912279158, 18.5, 21.83459217195067, 22.7, 1.0, 22.59863155729203], 
actual action is [0.5, 23.5], 
sim time next is 820500.0000, 
raw observation next is [-4.5, 71.0, 2.458333333333333, 60.0, 105.4166666666667, 0.0, 0.5, 20.03071597928956, 23.5, 21.73239210366055, 22.7, 1.0, 21.11174670035754], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.22348484848484845, 0.16666666666666666, 0.2788800705467373, 0.0, 0.5083333333333333, 0.2003071597928956, 0.675, 0.5866196051830276, 0.635, 1.0, 0.24837349059244163], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:39:50,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-63.99795914]
 [-63.7050972 ]
 [-62.83498001]
 [-63.57675934]
 [-64.48623657]], R is [[-64.83821869]
 [-65.18983459]
 [-65.53793335]
 [-65.16497803]
 [-64.80793762]].
[2017-11-01 09:39:53,352] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   1.15760148e-29   5.02886828e-30   1.17429290e-30
   1.16068284e-30   1.80142745e-01   1.77588180e-01   1.49261564e-01
   4.93007541e-01], sum to 1.0000
[2017-11-01 09:39:53,404] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 83.0, 3.6, 62.5, 0.0, 0.0, 1.6, 21.20486308256056, 20.5, 21.1310438704587, 21.5, 0.0, 51.48364088606769], 
actual action is [1.6, 25.5], 
sim time next is 852600.0000, 
raw observation next is [-3.4, 83.0, 3.6, 61.66666666666666, 0.0, 0.0, 1.6, 20.40872244166488, 25.5, 21.2234117057115, 21.5, 0.0, 40.80630782050464], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.24615384615384614, 0.83, 0.32727272727272727, 0.17129629629629628, 0.0, 0.0, 0.5266666666666667, 0.2040872244166488, 0.775, 0.561170585285575, 0.575, 0.0, 0.4800742096529958], 
reward next is -0.3092. 
=============================================
[2017-11-01 09:39:53,519] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   5.28076115e-18   2.55704027e-18   7.33320118e-19
   7.33275347e-19   1.72286466e-01   1.71897829e-01   1.49931952e-01
   5.05883813e-01], sum to 1.0000
[2017-11-01 09:39:53,543] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.4, 83.0, 3.6, 62.5, 0.0, 0.0, 1.6, 25.32912701579236, 15.5, 21.08782743307393, 21.5, 0.0, 15.66365082372459], 
actual action is [1.6, 16.0], 
sim time next is 852600.0000, 
raw observation next is [-3.4, 83.0, 3.6, 61.66666666666666, 0.0, 0.0, 1.6, 26.03921770631063, 16.0, 20.99651001152312, 21.5, 0.0, 15.07536545370092], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.24615384615384614, 0.83, 0.32727272727272727, 0.17129629629629628, 0.0, 0.0, 0.5266666666666667, 0.2603921770631063, 0.3, 0.5498255005761561, 0.575, 0.0, 0.17735724063177552], 
reward next is -0.2146. 
=============================================
[2017-11-01 09:39:53,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.29460296
  0.20343129  0.22271757  0.27924812], sum to 1.0000
[2017-11-01 09:39:53,909] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.3, 80.0, 2.416666666666667, 60.0, 0.0, 0.0, 2.7, 28.23659705265318, 16.0, 20.23223276557067, 21.5, 0.0, 12.58383557472303], 
actual action is [2.7, 17.0], 
sim time next is 867600.0000, 
raw observation next is [-2.3, 80.0, 2.5, 60.0, 0.0, 0.0, 2.7, 28.90890649331293, 17.0, 20.14447895242731, 21.5, 0.0, 12.16546806109337], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.27435897435897433, 0.8, 0.22727272727272727, 0.16666666666666666, 0.0, 0.0, 0.545, 0.2890890649331293, 0.35, 0.5072239476213655, 0.575, 0.0, 0.14312315365992198], 
reward next is -0.4104. 
=============================================
[2017-11-01 09:39:55,854] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.92453259e-01   1.32670552e-01   1.92452192e-01   1.38613880e-01
   2.43810073e-01   4.26591283e-16   2.93120066e-16   5.02785417e-16
   2.45269984e-16], sum to 1.0000
[2017-11-01 09:39:55,944] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.4, 83.0, 3.6, 54.16666666666666, 0.0, 0.0, 1.6, 17.50117712688085, 24.0, 21.47655516701244, 21.5, 0.0, 46.86064065918651], 
actual action is [1.6, 22.0], 
sim time next is 855600.0000, 
raw observation next is [-3.4, 83.0, 3.6, 53.33333333333333, 0.0, 0.0, 1.6, 16.82730223537843, 22.0, 21.62093505565973, 21.5, 0.0, 46.2648943357125], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.24615384615384614, 0.83, 0.32727272727272727, 0.14814814814814814, 0.0, 0.0, 0.5266666666666667, 0.1682730223537843, 0.6, 0.5810467527829865, 0.575, 0.0, 0.5442928745377941], 
reward next is -0.2721. 
=============================================
[2017-11-01 09:39:59,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.52849477e-05   3.05838823e-01   2.13751122e-01   1.55394137e-01
   3.24759960e-01   7.51444386e-05   4.98040499e-05   7.73407301e-05
   2.83627724e-05], sum to 1.0000
[2017-11-01 09:39:59,574] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.3, 80.0, 1.916666666666667, 59.99999999999999, 0.0, 0.0, 2.7, 16.94489200964637, 25.5, 21.46901325951967, 21.5, 0.0, 43.92619642862448], 
actual action is [2.7, 24.5], 
sim time next is 865800.0000, 
raw observation next is [-2.3, 80.0, 2.0, 60.0, 0.0, 0.0, 2.7, 16.50107125232829, 24.5, 21.56023841565548, 21.5, 0.0, 43.68526619521862], 
processed observation next is [0.3333333333333333, 0.0, 0.27435897435897433, 0.8, 0.18181818181818182, 0.16666666666666666, 0.0, 0.0, 0.545, 0.16501071252328292, 0.725, 0.578011920782774, 0.575, 0.0, 0.5139443081790426], 
reward next is -0.2570. 
=============================================
[2017-11-01 09:40:00,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  5.84682482e-07   2.28207022e-01   1.64667577e-01   3.85807544e-01
   2.21037373e-01   7.41067925e-05   5.18534289e-05   1.08829736e-04
   4.51887354e-05], sum to 1.0000
[2017-11-01 09:40:01,001] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.7, 79.0, 2.708333333333333, 64.16666666666666, 0.0, 0.0, 3.3, 22.39068715679952, 23.0, 20.87623901194774, 21.5, 0.0, 25.62977924390165], 
actual action is [3.3, 22.0], 
sim time next is 873600.0000, 
raw observation next is [-1.7, 79.0, 2.666666666666667, 63.33333333333334, 0.0, 0.0, 3.3, 22.00805522923079, 22.0, 20.85468218581052, 21.5, 0.0, 38.92639154779447], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.28974358974358977, 0.79, 0.24242424242424246, 0.17592592592592596, 0.0, 0.0, 0.5549999999999999, 0.2200805522923079, 0.6, 0.542734109290526, 0.575, 0.0, 0.45795754762111146], 
reward next is -0.3903. 
=============================================
[2017-11-01 09:40:02,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.82828215e-02   2.21916765e-01   3.33238214e-01   2.29548857e-01
   1.17013313e-01   3.48586647e-15   2.17887113e-15   4.94384290e-15
   3.09047467e-15], sum to 1.0000
[2017-11-01 09:40:02,379] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [0.09166666666666667, 72.66666666666667, 3.05, 122.5, 16.91666666666667, 0.0, 5.0, 24.21447012383112, 17.0, 20.51737044213781, 22.7, 1.0, 21.81838595542915], 
actual action is [5.091666666666667, 16.0], 
sim time next is 893400.0000, 
raw observation next is [0.1833333333333333, 73.33333333333333, 3.1, 125.0, 19.33333333333334, 0.0, 5.091666666666667, 24.70388676914361, 16.0, 20.46619756785948, 22.7, 1.0, 20.12031019185492], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.33803418803418805, 0.7333333333333333, 0.2818181818181818, 0.3472222222222222, 0.05114638447971783, 0.0, 0.5848611111111112, 0.24703886769143613, 0.3, 0.523309878392974, 0.635, 1.0, 0.2367095316688814], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:40:05,418] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47276: loss -89.4936
[2017-11-01 09:40:07,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.63933279e-02   2.67443180e-01   3.12424749e-01   2.13439122e-01
   1.80299610e-01   3.87401130e-13   1.15016395e-13   2.66646948e-13
   9.84117640e-14], sum to 1.0000
[2017-11-01 09:40:07,173] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.5, 87.25, 3.6, 122.5, 92.0, 0.0, 6.366666666666667, 14.65655036020892, 14.5, 22.16369224638529, 22.7, 1.0, 33.50346788436476], 
actual action is [6.5, 13.5], 
sim time next is 904800.0000, 
raw observation next is [1.633333333333334, 88.33333333333334, 3.600000000000001, 123.3333333333333, 93.66666666666667, 0.0, 6.5, 14.89329736774602, 13.5, 22.17534489635447, 22.7, 1.0, 31.13716648995788], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.37521367521367527, 0.8833333333333334, 0.3272727272727274, 0.3425925925925925, 0.24779541446208114, 0.0, 0.6083333333333333, 0.1489329736774602, 0.175, 0.6087672448177235, 0.635, 1.0, 0.36631960576421035], 
reward next is -0.2576. 
=============================================
[2017-11-01 09:40:07,224] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.07146409e-20   4.20085797e-08   1.70243570e-08   2.60550799e-08
   1.94905461e-08   3.26656759e-01   1.95490703e-01   3.49767745e-01
   1.28084704e-01], sum to 1.0000
[2017-11-01 09:40:07,304] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [0.0, 72.0, 2.375, 90.0, 0.0, 0.0, -5.0, 19.61481769683218, 10.0, 21.03107301649765, 21.5, 0.0, 0.0], 
actual action is [5.0, 12.0], 
sim time next is 888600.0000, 
raw observation next is [0.0, 72.0, 2.416666666666667, 90.0, 0.0, 0.0, 5.0, 19.07802660432411, 12.0, 20.93037305022306, 21.5, 0.0, 46.72660389272568], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.3333333333333333, 0.72, 0.21969696969696972, 0.25, 0.0, 0.0, 0.5833333333333334, 0.19078026604324108, 0.1, 0.5465186525111531, 0.575, 0.0, 0.5497247516791256], 
reward next is -0.4173. 
=============================================
[2017-11-01 09:40:07,317] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47547: loss 30.9694
[2017-11-01 09:40:09,360] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47822: loss 55.1683
[2017-11-01 09:40:09,416] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3000, global step 47828: loss -26.6540
[2017-11-01 09:40:09,455] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47833: loss -2.6784
[2017-11-01 09:40:09,933] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3000, global step 47898: loss 34.1845
[2017-11-01 09:40:10,179] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47935: loss 35.5802
[2017-11-01 09:40:10,426] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47966: loss -33.9088
[2017-11-01 09:40:11,051] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48068: loss 18.7831
[2017-11-01 09:40:11,124] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3000, global step 48078: loss 203.9100
[2017-11-01 09:40:11,252] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3000, global step 48093: loss -35.3254
[2017-11-01 09:40:12,224] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48237: loss -0.5382
[2017-11-01 09:40:12,668] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48279: loss 145.0366
[2017-11-01 09:40:13,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-89.90577698]
 [-95.32585907]
 [-94.88503265]
 [-91.99712372]
 [-89.09290314]], R is [[-89.94194031]
 [-89.22546387]
 [-88.52241516]
 [-87.83330536]
 [-87.15872955]].
[2017-11-01 09:40:13,660] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3000, global step 48402: loss -16.9952
[2017-11-01 09:40:14,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48476: loss 35.9529
[2017-11-01 09:40:16,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48647: loss -3.7936
[2017-11-01 09:40:29,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.44518882e-01   1.29143253e-01   2.67895669e-01   1.66899532e-01
   2.91491032e-01   1.86573434e-05   1.29346117e-05   1.33228205e-05
   6.68137181e-06], sum to 1.0000
[2017-11-01 09:40:29,337] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [5.333333333333334, 91.33333333333333, 4.766666666666666, 146.6666666666667, 0.0, 0.0, 0.2916666666666661, 12.98213365685614, 10.0, 22.42904636999229, 21.5, 0.0, 0.0], 
actual action is [0.3333333333333339, 10.0], 
sim time next is 953100.0000, 
raw observation next is [5.375, 90.75, 4.85, 150.0, 0.0, 0.0, 0.3333333333333339, 13.71533622299657, 10.0, 22.28909802779634, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.0, 0.47115384615384615, 0.9075, 0.44090909090909086, 0.4166666666666667, 0.0, 0.0, 0.5055555555555556, 0.1371533622299657, 0.0, 0.614454901389817, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:40:39,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.39374304e-01   1.76393136e-01   1.55985013e-01   2.21347839e-01
   1.06899731e-01   1.35244760e-09   1.42376888e-09   2.08890261e-09
   1.33742561e-09], sum to 1.0000
[2017-11-01 09:40:39,799] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.36666666666667, 86.0, 6.133333333333333, 203.3333333333334, 126.6666666666667, 0.0, 17.325, 9.517907155703389, 22.0, 22.95088623798208, 22.7, 1.0, 19.70096077149615], 
actual action is [17.36666666666667, 17.0], 
sim time next is 995100.0000, 
raw observation next is [12.40833333333333, 86.0, 6.266666666666666, 201.6666666666667, 127.3333333333333, 0.0, 17.36666666666667, 9.424347976822922, 17.0, 23.05735406168836, 22.7, 1.0, 18.27420125396464], 
processed observation next is [0.5, 0.5217391304347826, 0.6514957264957264, 0.86, 0.5696969696969696, 0.5601851851851853, 0.33686067019400345, 0.0, 0.7894444444444446, 0.09424347976822922, 0.35, 0.6528677030844181, 0.635, 1.0, 0.2149906029878193], 
reward next is -0.1546. 
=============================================
[2017-11-01 09:40:42,519] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-10.65922165]
 [-10.13428688]
 [-10.47465038]
 [-10.16144466]
 [-10.18083477]], R is [[-10.47786713]
 [-10.43580437]
 [-10.39296246]
 [-10.34961033]
 [-10.69185066]].
[2017-11-01 09:40:47,783] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  7.62274787e-02   3.46309483e-01   1.10444218e-01   2.41372272e-01
   2.25643784e-01   6.44344027e-07   5.83646113e-07   8.57952500e-07
   6.55790529e-07], sum to 1.0000
[2017-11-01 09:40:47,798] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [13.8, 78.0, 4.1, 180.0, 0.0, 0.0, 8.85, 14.46215550610392, 10.0, 22.05560373500249, 22.7, 1.0, 0.0], 
actual action is [8.8, 10], 
sim time next is 1044300.0000, 
raw observation next is [13.85, 77.91666666666667, 4.183333333333333, 182.5, 0.0, 0.0, 8.8, 14.50393600466044, 10.0, 22.04651211127044, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.6884615384615385, 0.7791666666666667, 0.38030303030303025, 0.5069444444444444, 0.0, 0.0, 0.6466666666666666, 0.1450393600466044, 0.0, 0.6023256055635221, 0.635, 1.0, 0.0], 
reward next is -0.0725. 
=============================================
[2017-11-01 09:40:48,919] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 54675: loss 59.8333
[2017-11-01 09:40:49,903] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.39395816e-24   5.47776841e-12   2.38380279e-12   3.23548219e-12
   3.10972927e-12   3.47432494e-01   1.65609747e-01   3.55432898e-01
   1.31524861e-01], sum to 1.0000
[2017-11-01 09:40:50,033] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [14.4, 75.0, 4.1, 190.0, 0.0, 0.0, 9.4, 13.87458117471708, 10.0, 22.23409951599091, 21.5, 0.0, 0.0], 
actual action is [19.4, 12.0], 
sim time next is 1037100.0000, 
raw observation next is [14.4, 75.0, 4.141666666666666, 190.8333333333333, 0.0, 0.0, 19.4, 13.63712106131128, 12.0, 22.22800633332378, 21.5, 0.0, 10.5078870483259], 
processed observation next is [0.6666666666666666, 0.0, 0.7025641025641025, 0.75, 0.3765151515151514, 0.5300925925925924, 0.0, 0.0, 0.8233333333333334, 0.1363712106131128, 0.1, 0.611400316666189, 0.575, 0.0, 0.12362220056854], 
reward next is -0.0618. 
=============================================
[2017-11-01 09:40:51,641] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55322: loss 2.0789
[2017-11-01 09:40:51,765] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55347: loss 2.1211
[2017-11-01 09:40:52,567] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55586: loss -2.9999
[2017-11-01 09:40:52,761] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55656: loss -0.7146
[2017-11-01 09:40:52,860] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55698: loss 1.5831
[2017-11-01 09:40:53,656] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56000: loss -7.3115
[2017-11-01 09:40:53,848] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3500, global step 56077: loss 0.9425
[2017-11-01 09:40:53,860] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3500, global step 56081: loss -0.7417
[2017-11-01 09:40:54,093] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3500, global step 56175: loss -25.0880
[2017-11-01 09:40:54,251] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3500, global step 56233: loss -3.4497
[2017-11-01 09:40:54,635] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56366: loss -0.5822
[2017-11-01 09:40:55,387] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56646: loss -0.1097
[2017-11-01 09:40:55,505] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3500, global step 56692: loss -2.7615
[2017-11-01 09:40:55,592] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 56724: loss 2.5942
[2017-11-01 09:40:55,710] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56760: loss -9.1275
[2017-11-01 09:40:55,831] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.04966827e-01   1.42221510e-01   2.06609264e-01   2.54498512e-01
   2.91703850e-01   3.87226232e-12   2.82575460e-12   4.27340368e-12
   2.11129616e-12], sum to 1.0000
[2017-11-01 09:40:55,837] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.35, 77.08333333333333, 5.475, 209.1666666666667, 0.0, 0.0, 9.4, 15.61687755821726, 10.0, 21.82663613977348, 21.5, 0.0, 0.0], 
actual action is [9.35, 10], 
sim time next is 1051800.0000, 
raw observation next is [14.3, 77.16666666666667, 5.350000000000001, 208.3333333333333, 0.0, 0.0, 9.35, 15.64123531847403, 10.0, 21.82228754550696, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.7000000000000001, 0.7716666666666667, 0.4863636363636365, 0.5787037037037036, 0.0, 0.0, 0.6558333333333334, 0.15641235318474028, 0.0, 0.591114377275348, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:40:57,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.58970222e-01   1.19166799e-01   2.60002375e-01   1.80748105e-01
   2.81112462e-01   2.72939505e-12   2.34367690e-12   3.00805496e-12
   1.31928539e-12], sum to 1.0000
[2017-11-01 09:40:57,625] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.55, 79.0, 4.1, 195.0, 0.0, 0.0, 18.59166666666667, 7.383137525514352, 14.0, 23.15518804111279, 21.5, 0.0, 26.65540132826193], 
actual action is [18.55, 13.0], 
sim time next is 1056900.0000, 
raw observation next is [13.50833333333333, 79.16666666666667, 4.1, 194.1666666666667, 0.0, 0.0, 18.55, 7.385332616027966, 13.0, 23.21094922901724, 21.5, 0.0, 25.35447005370246], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.6797008547008546, 0.7916666666666667, 0.3727272727272727, 0.539351851851852, 0.0, 0.0, 0.8091666666666666, 0.07385332616027966, 0.15, 0.660547461450862, 0.575, 0.0, 0.29828788298473485], 
reward next is -0.1491. 
=============================================
[2017-11-01 09:41:01,991] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.47619510e-01   2.05977216e-01   1.79596201e-01   1.96799904e-01
   1.70007154e-01   1.28432962e-08   1.07599973e-08   1.20802657e-08
   9.41443989e-09], sum to 1.0000
[2017-11-01 09:41:02,030] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [19.4, 49.0, 4.225, 175.8333333333333, 96.0, 0.0, 14.4, 8.381543026540989, 10.0, 24.38548124952655, 22.7, 1.0, 0.0], 
actual action is [14.399999999999999, 10], 
sim time next is 1092600.0000, 
raw observation next is [19.4, 49.0, 4.05, 175.0, 92.0, 0.0, 14.4, 8.381561251147374, 10.0, 24.38850933204031, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.8307692307692307, 0.49, 0.36818181818181817, 0.4861111111111111, 0.24338624338624337, 0.0, 0.74, 0.08381561251147375, 0.0, 0.7194254666020156, 0.635, 1.0, 0.0], 
reward next is -0.0419. 
=============================================
[2017-11-01 09:41:03,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.02066436e-01   2.06747860e-01   1.63144752e-01   2.06959337e-01
   2.21081600e-01   5.35492362e-09   4.22937640e-09   5.20484189e-09
   4.18929735e-09], sum to 1.0000
[2017-11-01 09:41:03,055] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [19.4, 49.0, 4.925, 179.1666666666667, 112.0, 0.0, 14.4, 9.44302123914601, 10.0, 23.74412845809636, 22.7, 1.0, 0.0], 
actual action is [14.399999999999999, 10.0], 
sim time next is 1091400.0000, 
raw observation next is [19.4, 49.0, 4.75, 178.3333333333333, 108.0, 0.0, 14.4, 9.430649249809862, 10.0, 23.75122632751394, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.8307692307692307, 0.49, 0.4318181818181818, 0.49537037037037024, 0.2857142857142857, 0.0, 0.74, 0.09430649249809862, 0.0, 0.6875613163756971, 0.635, 1.0, 0.0], 
reward next is -0.0472. 
=============================================
[2017-11-01 09:41:05,806] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-11.96213531]
 [-11.30943298]
 [-11.8282938 ]
 [-11.40634346]
 [-11.69658947]], R is [[-12.00664711]
 [-12.03576851]
 [-12.06508446]
 [-12.09487343]
 [-12.13501072]].
[2017-11-01 09:41:07,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.77496746e-01   2.03085348e-01   2.00927719e-01   2.34221101e-01
   1.84269145e-01   7.27984295e-09   4.41208003e-09   4.46449722e-09
   2.65183564e-09], sum to 1.0000
[2017-11-01 09:41:07,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [10.95833333333333, 74.5, 4.808333333333333, 140.0, 0.0, 0.0, 6.050000000000001, 12.5961218617596, 10.0, 22.66922565061092, 22.7, 1.0, 0.0], 
actual action is [5.95833333333333, 10], 
sim time next is 1125600.0000, 
raw observation next is [10.86666666666667, 75.0, 4.766666666666667, 140.0, 0.0, 0.0, 5.95833333333333, 12.6633853422592, 10.0, 22.6490408030576, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.0, 0.6119658119658121, 0.75, 0.43333333333333335, 0.3888888888888889, 0.0, 0.0, 0.5993055555555554, 0.126633853422592, 0.0, 0.6324520401528799, 0.635, 1.0, 0.0], 
reward next is -0.0633. 
=============================================
[2017-11-01 09:41:17,997] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 62492: loss -0.5988
[2017-11-01 09:41:18,553] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-2.17974806]
 [-2.06560874]
 [-2.24252653]
 [-2.03153372]
 [-2.32851648]], R is [[-2.0820713 ]
 [-2.06125069]
 [-2.04063821]
 [-2.02023196]
 [-2.00002956]].
[2017-11-01 09:41:20,093] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63005: loss -3.0846
[2017-11-01 09:41:20,729] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.21620008  0.18735413  0.19553669  0.21093015  0.15822002  0.01067124
  0.01026882  0.00723809  0.00358079], sum to 1.0000
[2017-11-01 09:41:20,742] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [18.50833333333333, 64.16666666666667, 8.408333333333333, 144.1666666666667, 26.58333333333333, 0.0, 13.55, 11.89043926418412, 10.0, 22.12237767318024, 21.5, 0.0, 0.0], 
actual action is [13.50833333333333, 10], 
sim time next is 1183200.0000, 
raw observation next is [18.46666666666667, 64.33333333333333, 8.366666666666665, 143.3333333333333, 24.16666666666667, 0.0, 13.50833333333333, 11.89342758805628, 10.0, 22.11758123735836, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.8068376068376069, 0.6433333333333333, 0.7606060606060605, 0.39814814814814803, 0.06393298059964728, 0.0, 0.7251388888888888, 0.1189342758805628, 0.0, 0.605879061867918, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:41:21,685] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63327: loss -0.6655
[2017-11-01 09:41:23,430] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.52909958e-01   1.72806785e-01   1.68803737e-01   2.10233554e-01
   1.95245892e-01   2.53759347e-09   1.29528510e-09   1.73025083e-09
   6.60971611e-10], sum to 1.0000
[2017-11-01 09:41:23,447] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [18.15, 64.0, 8.95, 147.5, 0.0, 0.0, 13.2, 9.462585939837572, 10.0, 23.13893940322294, 22.7, 1.0, 0.0], 
actual action is [13.149999999999999, 10], 
sim time next is 1189200.0000, 
raw observation next is [18.1, 64.33333333333334, 8.866666666666667, 146.6666666666667, 0.0, 0.0, 13.15, 9.469892244414215, 10.0, 23.13034644637267, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.7974358974358975, 0.6433333333333334, 0.8060606060606061, 0.40740740740740755, 0.0, 0.0, 0.7191666666666666, 0.09469892244414214, 0.0, 0.6565173223186335, 0.635, 1.0, 0.0], 
reward next is -0.0473. 
=============================================
[2017-11-01 09:41:23,835] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63750: loss -1.3054
[2017-11-01 09:41:23,873] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63757: loss 1.8366
[2017-11-01 09:41:24,603] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4000, global step 63954: loss -0.8711
[2017-11-01 09:41:25,453] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4000, global step 64160: loss -0.9348
[2017-11-01 09:41:25,709] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64225: loss -2.0765
[2017-11-01 09:41:25,718] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4000, global step 64227: loss -2.8857
[2017-11-01 09:41:25,753] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4000, global step 64234: loss -0.2736
[2017-11-01 09:41:26,103] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64342: loss 0.4868
[2017-11-01 09:41:26,546] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64480: loss -0.7611
[2017-11-01 09:41:26,790] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64557: loss -0.5368
[2017-11-01 09:41:26,890] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4000, global step 64587: loss -0.4925
[2017-11-01 09:41:26,946] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64603: loss -1.0468
[2017-11-01 09:41:27,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-3.72255945]
 [-3.91920757]
 [-4.03558493]
 [-3.92112803]
 [-3.95644879]], R is [[-4.00879717]
 [-4.01612139]
 [-4.02334118]
 [-4.03046179]
 [-4.03748703]].
[2017-11-01 09:41:27,486] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64788: loss -1.6902
[2017-11-01 09:41:28,108] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.76293895e-01   2.26993620e-01   1.86366901e-01   2.07297504e-01
   2.03036904e-01   4.45821479e-06   2.36474307e-06   3.22497885e-06
   1.22890162e-06], sum to 1.0000
[2017-11-01 09:41:28,117] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [16.1, 82.5, 7.516666666666667, 138.3333333333333, 0.0, 0.0, 11.1, 9.92008706337149, 10.0, 22.60137480773313, 22.7, 1.0, 0.0], 
actual action is [11.100000000000001, 10], 
sim time next is 1216500.0000, 
raw observation next is [16.1, 82.75, 7.608333333333334, 139.1666666666667, 0.0, 0.0, 11.1, 9.919345492357076, 10.0, 22.59775473235188, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.7461538461538462, 0.8275, 0.6916666666666668, 0.3865740740740742, 0.0, 0.0, 0.685, 0.09919345492357076, 0.0, 0.629887736617594, 0.635, 1.0, 0.0], 
reward next is -0.0496. 
=============================================
[2017-11-01 09:41:28,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-5.04261827]
 [-4.2451148 ]
 [-4.26291752]
 [-3.9901154 ]
 [-4.80357361]], R is [[-4.11280584]
 [-4.11726379]
 [-4.12178802]
 [-4.12638712]
 [-4.13107252]].
[2017-11-01 09:41:41,336] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.19643785  0.14620984  0.15134209  0.16291855  0.20621407  0.03619817
  0.0443648   0.02934124  0.02697336], sum to 1.0000
[2017-11-01 09:41:41,452] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [12.73333333333333, 100.0, 5.8, 253.3333333333333, 15.83333333333333, 0.0, 17.86666666666667, 9.49321467955028, 19.5, 22.17063218654405, 22.7, 1.0, 1.404778718884941], 
actual action is [17.73333333333333, 18.5], 
sim time next is 1269900.0000, 
raw observation next is [12.6, 100.0, 6.15, 280.0, 14.25, 0.0, 17.73333333333333, 9.549603963747993, 18.5, 22.1471265115676, 22.7, 1.0, 1.455434671847485], 
processed observation next is [1.0, 0.6956521739130435, 0.6564102564102564, 1.0, 0.5590909090909091, 0.7777777777777778, 0.037698412698412696, 0.0, 0.7955555555555556, 0.09549603963747993, 0.425, 0.6073563255783799, 0.635, 1.0, 0.01712276084526453], 
reward next is -0.0563. 
=============================================
[2017-11-01 09:41:46,725] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.13921991  0.1233853   0.24509282  0.15567641  0.33127615  0.00075188
  0.0010517   0.00109723  0.00244863], sum to 1.0000
[2017-11-01 09:41:46,785] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.833333333333334, 96.0, 6.433333333333334, 333.3333333333334, 0.0, 0.0, 11.925, 6.819927817420094, 26.0, 22.46320126107759, 21.5, 0.0, 46.03488458727321], 
actual action is [11.833333333333334, 21.0], 
sim time next is 1279500.0000, 
raw observation next is [6.741666666666665, 96.0, 6.391666666666666, 334.1666666666666, 0.0, 0.0, 11.83333333333333, 6.653086182447288, 21.0, 22.80162007145867, 21.5, 0.0, 44.99738307945962], 
processed observation next is [1.0, 0.8260869565217391, 0.5061965811965812, 0.96, 0.5810606060606059, 0.9282407407407405, 0.0, 0.0, 0.6972222222222222, 0.06653086182447289, 0.55, 0.6400810035729336, 0.575, 0.0, 0.5293809774054072], 
reward next is -0.2647. 
=============================================
[2017-11-01 09:41:47,872] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00229408e-06   8.82355787e-04   3.22447158e-03   2.04416434e-03
   5.51926484e-03   9.42389388e-03   1.98072139e-02   1.95860136e-02
   9.39511597e-01], sum to 1.0000
[2017-11-01 09:41:47,901] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [5.408333333333333, 99.66666666666666, 8.575, 250.0, 0.0, 0.0, 0.5, 26.55788390182963, 10.0, 19.24931420063238, 21.5, 0.0, 0.0], 
actual action is [10.408333333333333, 15.0], 
sim time next is 1293000.0000, 
raw observation next is [5.316666666666667, 99.33333333333334, 8.45, 250.0, 0.0, 0.0, 10.40833333333333, 26.3906578148108, 15.0, 19.22928115930718, 21.5, 0.0, 8.527735646674675], 
processed observation next is [1.0, 1.0, 0.46965811965811965, 0.9933333333333334, 0.7681818181818181, 0.6944444444444444, 0.0, 0.0, 0.6734722222222221, 0.26390657814810803, 0.25, 0.46146405796535905, 0.575, 0.0, 0.1003263017255844], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:41:51,232] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-31.80700684]
 [-31.74236679]
 [-31.5151329 ]
 [-31.64729691]
 [-31.86008072]], R is [[-33.02488708]
 [-33.01177979]
 [-32.99513245]
 [-32.97720337]
 [-32.96061325]].
[2017-11-01 09:42:00,017] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 70865: loss -2.4145
[2017-11-01 09:42:01,826] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.30757062e-05   6.92031463e-05   1.68582832e-04   1.14844283e-04
   2.27879907e-04   4.12872463e-01   8.49958882e-02   2.12716699e-01
   2.88821369e-01], sum to 1.0000
[2017-11-01 09:42:01,885] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.1, 92.0, 3.6, 290.0, 114.5, 0.0, 6.05, 7.840629114586581, 30.0, 25.88547905006448, 22.7, 1.0, 50.12226556378538], 
actual action is [6.1, 30], 
sim time next is 1335900.0000, 
raw observation next is [1.1, 92.0, 3.85, 288.3333333333333, 116.5833333333333, 0.0, 6.1, 7.934238751343369, 30.0, 25.91367649493382, 22.7, 1.0, 49.69130314958836], 
processed observation next is [0.0, 0.4782608695652174, 0.36153846153846153, 0.92, 0.35000000000000003, 0.8009259259259258, 0.30842151675485, 0.0, 0.6016666666666667, 0.0793423875134337, 1.0, 0.7956838247466911, 0.635, 1.0, 0.5846035664657454], 
reward next is -0.3320. 
=============================================
[2017-11-01 09:42:02,762] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71128: loss -10.0800
[2017-11-01 09:42:03,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.00242682  0.01014212  0.0188505   0.01447878  0.02900174  0.45888516
  0.09550312  0.2252868   0.14542501], sum to 1.0000
[2017-11-01 09:42:03,780] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.5, 92.0, 5.6, 275.0, 45.0, 0.0, 5.5, 6.245960940127485, 29.5, 25.04313281371638, 22.7, 1.0, 58.47441469800509], 
actual action is [5.5, 30.0], 
sim time next is 1330500.0000, 
raw observation next is [0.5, 92.0, 5.683333333333334, 275.8333333333333, 49.75, 0.0, 5.5, 6.301707830184855, 30.0, 25.09671119802529, 22.7, 1.0, 58.37472842088911], 
processed observation next is [0.0, 0.391304347826087, 0.34615384615384615, 0.92, 0.5166666666666667, 0.7662037037037036, 0.13161375661375663, 0.0, 0.5916666666666667, 0.06301707830184855, 1.0, 0.7548355599012645, 0.635, 1.0, 0.6867615108339896], 
reward next is -0.3749. 
=============================================
[2017-11-01 09:42:06,102] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71539: loss 5.5667
[2017-11-01 09:42:06,267] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4500, global step 71577: loss -2.4415
[2017-11-01 09:42:06,547] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71609: loss 0.9781
[2017-11-01 09:42:07,292] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71739: loss 7.6557
[2017-11-01 09:42:07,335] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4500, global step 71745: loss -3.8652
[2017-11-01 09:42:07,991] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-13.32855129]
 [-13.11433887]
 [-12.7962532 ]
 [-13.08590984]
 [-12.84960079]], R is [[-12.9750452 ]
 [-12.89143276]
 [-12.807024  ]
 [-12.72151661]
 [-12.634799  ]].
[2017-11-01 09:42:09,166] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72150: loss 0.4624
[2017-11-01 09:42:09,304] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72196: loss 2.5459
[2017-11-01 09:42:09,851] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72306: loss -1.9993
[2017-11-01 09:42:09,857] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72306: loss -2.7302
[2017-11-01 09:42:10,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.70603448e-01   1.07796401e-01   1.38139024e-01   2.60880888e-01
   2.22541377e-01   1.19936476e-05   4.00170666e-06   6.84598581e-06
   1.59928641e-05], sum to 1.0000
[2017-11-01 09:42:10,920] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.75, 94.75, 5.516666666666666, 284.1666666666667, 16.5, 0.0, -4.2, 13.17635961106544, 10.0, 21.78722989894253, 22.7, 1.0, 0.0], 
actual action is [-4.25, 10], 
sim time next is 1356000.0000, 
raw observation next is [0.7000000000000001, 95.0, 5.433333333333334, 283.3333333333333, 15.0, 0.0, -4.25, 13.33407127925073, 10.0, 21.74341880943646, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.35128205128205126, 0.95, 0.49393939393939396, 0.787037037037037, 0.03968253968253968, 0.0, 0.42916666666666664, 0.1333407127925073, 0.0, 0.5871709404718229, 0.635, 1.0, 0.0], 
reward next is -0.0667. 
=============================================
[2017-11-01 09:42:10,944] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4500, global step 72542: loss 2.2835
[2017-11-01 09:42:11,045] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72560: loss -3.7240
[2017-11-01 09:42:11,414] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4500, global step 72649: loss 3.0978
[2017-11-01 09:42:11,633] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4500, global step 72691: loss 3.9643
[2017-11-01 09:42:11,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  5.71535416e-02   7.45331720e-02   2.95477927e-01   3.17253172e-01
   2.55582184e-01   5.00223682e-11   6.89341943e-12   2.55333376e-11
   1.55995938e-10], sum to 1.0000
[2017-11-01 09:42:11,900] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 5.391666666666666, 285.8333333333333, 0.0, 0.0, 5.5, 21.83702975191563, 17.5, 20.2096036845252, 21.5, 0.0, 2.961220022066598], 
actual action is [5.5, 12.5], 
sim time next is 1369800.0000, 
raw observation next is [0.5, 96.0, 5.35, 285.0, 0.0, 0.0, 5.5, 22.09994272368994, 12.5, 20.18108117179089, 21.5, 0.0, 3.005328514885157], 
processed observation next is [0.0, 0.8695652173913043, 0.34615384615384615, 0.96, 0.48636363636363633, 0.7916666666666666, 0.0, 0.0, 0.5916666666666667, 0.2209994272368994, 0.125, 0.5090540585895444, 0.575, 0.0, 0.035356806057472434], 
reward next is -0.3474. 
=============================================
[2017-11-01 09:42:12,958] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72937: loss 1.3974
[2017-11-01 09:42:18,927] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   4.24367830e-29   2.04173912e-29   8.09228442e-30
   1.14290273e-29   9.33435559e-02   1.10341959e-01   1.13421522e-01
   6.82892978e-01], sum to 1.0000
[2017-11-01 09:42:18,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 96.0, 5.766666666666667, 280.0, 0.0, 0.0, 5.5, 13.82977076030725, 16.0, 21.58595265069006, 21.5, 0.0, 30.63088312074461], 
actual action is [5.5, 21.0], 
sim time next is 1374300.0000, 
raw observation next is [0.5, 96.0, 5.85, 280.0, 0.0, 0.0, 5.5, 13.78916396596093, 21.0, 21.58240555850367, 21.5, 0.0, 23.66579738095285], 
processed observation next is [0.0, 0.9130434782608695, 0.34615384615384615, 0.96, 0.5318181818181817, 0.7777777777777778, 0.0, 0.0, 0.5916666666666667, 0.1378916396596093, 0.55, 0.5791202779251835, 0.575, 0.0, 0.2784211456582688], 
reward next is -0.1392. 
=============================================
[2017-11-01 09:42:26,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.94175079e-01   2.20170245e-01   1.55425265e-01   2.56479830e-01
   1.73749596e-01   6.88869983e-09   6.23844398e-09   1.01705906e-08
   6.48517373e-09], sum to 1.0000
[2017-11-01 09:42:26,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-0.6, 100.0, 2.375, 275.0, 13.5, 0.0, 4.4, 9.932224927035518, 24.5, 21.11680518464052, 22.7, 1.0, 75.91144136803806], 
actual action is [4.4, 24.0], 
sim time next is 1412400.0000, 
raw observation next is [-0.6, 100.0, 2.333333333333333, 246.6666666666667, 15.0, 0.0, 4.4, 8.407798322117419, 24.0, 21.48958948822838, 22.7, 1.0, 68.42879062137361], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 1.0, 0.2121212121212121, 0.6851851851851853, 0.03968253968253968, 0.0, 0.5733333333333334, 0.08407798322117419, 0.7, 0.574479474411419, 0.635, 1.0, 0.8050445955455718], 
reward next is -0.4446. 
=============================================
[2017-11-01 09:42:28,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.00058983  0.28332254  0.20089658  0.26393658  0.2354496   0.00249667
  0.00259577  0.0041364   0.00657604], sum to 1.0000
[2017-11-01 09:42:28,589] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.0, 95.0, 1.75, 15.0, 90.0, 0.0, 5.0, 14.03804189724829, 14.0, 21.79766064387278, 22.7, 1.0, 10.0912628333701], 
actual action is [5.0, 13.5], 
sim time next is 1424100.0000, 
raw observation next is [0.0, 95.0, 1.791666666666667, 15.83333333333333, 90.5, 0.0, 5.0, 13.98206390045166, 13.5, 21.81962821782588, 22.7, 1.0, 7.108143752416355], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.3333333333333333, 0.95, 0.1628787878787879, 0.043981481481481476, 0.23941798941798942, 0.0, 0.5833333333333334, 0.1398206390045166, 0.175, 0.590981410891294, 0.635, 1.0, 0.083625220616663], 
reward next is -0.1117. 
=============================================
[2017-11-01 09:42:28,760] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.80825377e-01   1.56751886e-01   1.25229284e-01   2.11358011e-01
   2.25835532e-01   2.15967633e-10   2.05067699e-10   4.06545908e-10
   2.66026007e-10], sum to 1.0000
[2017-11-01 09:42:28,832] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 2.5, 360.0, 9.0, 0.0, 4.4, 9.9423486970047, 11.5, 22.57312225511084, 22.7, 1.0, 26.45515894023124], 
actual action is [4.4, 11.5], 
sim time next is 1411500.0000, 
raw observation next is [-0.6, 99.99999999999999, 2.458333333333333, 331.6666666666667, 10.5, 0.0, 4.4, 10.03124756589081, 11.5, 22.4822518548354, 22.7, 1.0, 24.79469345962802], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 0.9999999999999999, 0.22348484848484845, 0.9212962962962964, 0.027777777777777776, 0.0, 0.5733333333333334, 0.1003124756589081, 0.075, 0.62411259274177, 0.635, 1.0, 0.29170227599562376], 
reward next is -0.1960. 
=============================================
[2017-11-01 09:42:28,857] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-17.99204445]
 [-17.14714432]
 [-17.96618843]
 [-17.66213989]
 [-17.68624687]], R is [[-16.37576866]
 [-16.31521797]
 [-16.2583313 ]
 [-16.20747185]
 [-16.17494774]].
[2017-11-01 09:42:36,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.35456411e-14   2.32441907e-05   1.30890421e-05   1.16125393e-05
   9.68695895e-06   2.23466024e-01   1.49292663e-01   4.50849324e-01
   1.76334351e-01], sum to 1.0000
[2017-11-01 09:42:36,872] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.1666666666666667, 94.0, 2.333333333333333, 126.6666666666667, 95.0, 0.0, 5.125, 9.733411260616947, 13.5, 22.70874210426221, 22.7, 1.0, 24.2248924197839], 
actual action is [5.166666666666667, 14.0], 
sim time next is 1427100.0000, 
raw observation next is [0.2083333333333333, 93.75, 2.416666666666667, 153.3333333333333, 95.5, 0.0, 5.166666666666667, 9.89664435291193, 14.0, 22.68103320134312, 22.7, 1.0, 22.46487804027227], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.3386752136752137, 0.9375, 0.21969696969696972, 0.4259259259259258, 0.2526455026455027, 0.0, 0.586111111111111, 0.09896644352911929, 0.2, 0.634051660067156, 0.635, 1.0, 0.26429268282673263], 
reward next is -0.1816. 
=============================================
[2017-11-01 09:42:37,072] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.33666688e-05   3.28574568e-01   2.36093506e-01   2.30715916e-01
   2.04378009e-01   4.13289054e-05   2.32933362e-05   1.05090308e-04
   4.49100407e-05], sum to 1.0000
[2017-11-01 09:42:37,313] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.1, 92.0, 3.0, 40.0, 81.0, 0.0, 6.05, 12.0213784530563, 26.5, 21.34125070304738, 22.7, 1.0, 86.05714069592197], 
actual action is [6.1, 26.0], 
sim time next is 1433100.0000, 
raw observation next is [1.1, 92.0, 3.0, 42.5, 79.5, 0.0, 6.1, 9.815340376832046, 26.0, 21.55154164882683, 22.7, 1.0, 78.45445566699901], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.36153846153846153, 0.92, 0.2727272727272727, 0.11805555555555555, 0.21031746031746032, 0.0, 0.6016666666666667, 0.09815340376832045, 0.8, 0.5775770824413415, 0.635, 1.0, 0.9229935960823413], 
reward next is -0.5106. 
=============================================
[2017-11-01 09:42:42,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-20.90867615]
 [-21.54637909]
 [-21.76033783]
 [-21.4659462 ]
 [-21.44192886]], R is [[-21.30515671]
 [-21.16480637]
 [-21.02884483]
 [-20.89715195]
 [-20.76988411]].
[2017-11-01 09:42:43,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-16.05497742]
 [-16.68649483]
 [-16.35740662]
 [-16.00640488]
 [-15.83000851]], R is [[-15.63633347]
 [-15.58732986]
 [-15.54059982]
 [-15.49828911]
 [-15.5387125 ]].
[2017-11-01 09:42:44,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  5.44454787e-26   3.46094477e-14   8.71120447e-15   1.23005235e-14
   1.30722790e-14   4.26049083e-01   1.80350989e-01   2.65786082e-01
   1.27813861e-01], sum to 1.0000
[2017-11-01 09:42:44,671] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 2.083333333333333, 233.3333333333333, 0.0, 0.0, 6.6, 11.96377145383571, 18.0, 22.42662111238533, 21.5, 0.0, 16.91268195823743], 
actual action is [6.6, 18.5], 
sim time next is 1472100.0000, 
raw observation next is [1.6, 92.0, 2.291666666666667, 256.6666666666666, 0.0, 0.0, 6.6, 12.30979283163818, 18.5, 22.35181170678377, 21.5, 0.0, 16.29086764848283], 
processed observation next is [0.3333333333333333, 0.0, 0.37435897435897436, 0.92, 0.20833333333333337, 0.7129629629629627, 0.0, 0.0, 0.61, 0.1230979283163818, 0.425, 0.6175905853391885, 0.575, 0.0, 0.19165726645273917], 
reward next is -0.0958. 
=============================================
[2017-11-01 09:42:48,835] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 78799: loss -17.9640
[2017-11-01 09:42:49,230] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  5.57929922e-24   2.19569328e-12   1.05250910e-12   7.21350009e-13
   6.45056979e-13   3.73623252e-01   2.06756666e-01   2.51106858e-01
   1.68513149e-01], sum to 1.0000
[2017-11-01 09:42:49,299] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [1.6, 92.0, 2.083333333333333, 233.3333333333333, 0.0, 0.0, 6.6, 9.33723634485881, 15.0, 22.63324743034574, 21.5, 0.0, 22.47277831253848], 
actual action is [6.6, 15.5], 
sim time next is 1472100.0000, 
raw observation next is [1.6, 92.0, 2.291666666666667, 256.6666666666666, 0.0, 0.0, 6.6, 9.605897931084378, 15.5, 22.5607175273405, 21.5, 0.0, 21.68381591370546], 
processed observation next is [0.3333333333333333, 0.0, 0.37435897435897436, 0.92, 0.20833333333333337, 0.7129629629629627, 0.0, 0.0, 0.61, 0.09605897931084378, 0.275, 0.6280358763670251, 0.575, 0.0, 0.2551037166318289], 
reward next is -0.1276. 
=============================================
[2017-11-01 09:42:52,354] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79298: loss -0.7460
[2017-11-01 09:42:53,343] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  3.07136059e-01   1.82650864e-01   1.66452751e-01   1.61945671e-01
   1.81813896e-01   2.14043851e-07   1.73804125e-07   1.93898430e-07
   1.21297816e-07], sum to 1.0000
[2017-11-01 09:42:53,400] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.266666666666667, 100.0, 0.6666666666666666, 40.0, 15.0, 0.0, -3.775, 8.280938007304373, 10.0, 23.44572203775457, 22.7, 1.0, 0.0], 
actual action is [-3.733333333333333, 10], 
sim time next is 1499100.0000, 
raw observation next is [1.308333333333333, 100.0, 0.8333333333333334, 50.0, 16.5, 0.0, -3.733333333333333, 8.993555287362547, 10.0, 23.33682559635319, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.3668803418803419, 1.0, 0.07575757575757576, 0.1388888888888889, 0.04365079365079365, 0.0, 0.43777777777777777, 0.08993555287362547, 0.0, 0.6668412798176595, 0.635, 1.0, 0.0], 
reward next is -0.0450. 
=============================================
[2017-11-01 09:42:53,660] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5000, global step 79498: loss -3.4983
[2017-11-01 09:42:54,139] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5000, global step 79564: loss -66.7742
[2017-11-01 09:42:54,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.21628068  0.16961564  0.19055855  0.22138935  0.1941925   0.00222049
  0.0019168   0.00199662  0.0018294 ], sum to 1.0000
[2017-11-01 09:42:54,741] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [8.833333333333334, 67.16666666666666, 0.0, 0.0, 84.16666666666666, 697.8333333333333, 3.6, 8.475435869164599, 10.0, 22.52911892371626, 22.7, 1.0, 0.0], 
actual action is [3.833333333333334, 10.0], 
sim time next is 1518000.0000, 
raw observation next is [9.066666666666666, 66.33333333333334, 0.0, 0.0, 83.33333333333334, 694.6666666666667, 3.833333333333334, 8.407166480823896, 10.0, 22.559421753412, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.5658119658119658, 0.6633333333333334, 0.0, 0.0, 0.22045855379188714, 0.6946666666666668, 0.5638888888888889, 0.08407166480823897, 0.0, 0.6279710876706, 0.635, 1.0, 0.0], 
reward next is -0.0420. 
=============================================
[2017-11-01 09:42:55,750] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79805: loss -7.0948
[2017-11-01 09:42:56,215] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79862: loss -26.1276
[2017-11-01 09:42:56,263] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79870: loss -6.2420
[2017-11-01 09:42:57,590] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5000, global step 80033: loss -9.0798
[2017-11-01 09:42:57,607] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80038: loss -7.0319
[2017-11-01 09:42:58,035] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80069: loss -10.2819
[2017-11-01 09:42:59,375] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80240: loss 17.1469
[2017-11-01 09:42:59,821] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5000, global step 80271: loss -82.5436
[2017-11-01 09:43:00,433] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80342: loss 19.3040
[2017-11-01 09:43:02,115] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80600: loss 14.9056
[2017-11-01 09:43:04,899] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5000, global step 80989: loss -8.0402
[2017-11-01 09:43:05,924] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 81127: loss -33.8781
[2017-11-01 09:43:09,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.86875188e-01   1.50946707e-01   1.36364833e-01   2.69765824e-01
   1.56047508e-01   6.25675400e-10   3.48331142e-10   3.73989950e-10
   2.52753263e-10], sum to 1.0000
[2017-11-01 09:43:09,497] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [4.85, 80.75, 3.45, 97.5, 0.0, 0.0, 9.9, 16.72409208700775, 11.5, 20.67316702414429, 21.5, 0.0, 11.04628059255352], 
actual action is [9.85, 11.0], 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 3.4, 96.66666666666667, 0.0, 0.0, 9.85, 17.07713752576816, 11.0, 20.61749207560461, 21.5, 0.0, 10.61267490625319], 
processed observation next is [0.5, 0.08695652173913043, 0.45641025641025645, 0.8133333333333335, 0.3090909090909091, 0.26851851851851855, 0.0, 0.0, 0.6641666666666667, 0.17077137525768157, 0.05, 0.5308746037802304, 0.575, 0.0, 0.12485499889709635], 
reward next is -0.2831. 
=============================================
[2017-11-01 09:43:12,947] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.00090361  0.00098164  0.00132747  0.0018088   0.00206707  0.3341777
  0.21166563  0.29118603  0.15588205], sum to 1.0000
[2017-11-01 09:43:13,000] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [9.450000000000001, 60.91666666666666, 1.833333333333333, 55.0, 0.0, 0.0, 14.5, 7.691284937507584, 21.0, 23.35142714682667, 22.7, 1.0, 3.667717118653308], 
actual action is [14.450000000000001, 26.0], 
sim time next is 1537200.0000, 
raw observation next is [9.4, 61.0, 2.0, 60.0, 0.0, 0.0, 14.45, 7.759909638219911, 26.0, 23.30301151148865, 22.7, 1.0, 3.6106821313209], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.5743589743589743, 0.61, 0.18181818181818182, 0.16666666666666666, 0.0, 0.0, 0.7408333333333333, 0.07759909638219911, 0.8, 0.6651505755744325, 0.635, 1.0, 0.042478613309657645], 
reward next is -0.0600. 
=============================================
[2017-11-01 09:43:15,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.08768303  0.11623029  0.14932694  0.14814904  0.24184217  0.0807047
  0.0983593   0.0521188   0.02558584], sum to 1.0000
[2017-11-01 09:43:15,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [4.9, 82.66666666666667, 2.566666666666666, 90.0, 0.0, 0.0, 9.875, 11.69870082692804, 13.5, 21.60195634976694, 21.5, 0.0, 22.16421255406627], 
actual action is [9.9, 12.5], 
sim time next is 1575900.0000, 
raw observation next is [4.925, 82.5, 2.55, 90.0, 0.0, 0.0, 9.9, 11.918316702353, 12.5, 21.56822810683878, 21.5, 0.0, 21.12556065652162], 
processed observation next is [0.5, 0.21739130434782608, 0.45961538461538465, 0.825, 0.2318181818181818, 0.25, 0.0, 0.0, 0.6649999999999999, 0.11918316702352999, 0.125, 0.578411405341939, 0.575, 0.0, 0.2485360077237838], 
reward next is -0.1243. 
=============================================
[2017-11-01 09:43:20,309] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.00409028  0.00303352  0.00455851  0.00732125  0.00823251  0.30564061
  0.26157591  0.29379269  0.11175471], sum to 1.0000
[2017-11-01 09:43:20,461] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [5.208333333333334, 82.0, 3.808333333333333, 125.8333333333333, 0.0, 0.0, 10.25, 16.53032580269756, 15.5, 20.57589215712408, 21.5, 0.0, 9.424135104868343], 
actual action is [10.208333333333334, 17.5], 
sim time next is 1554000.0000, 
raw observation next is [5.166666666666666, 82.0, 3.766666666666667, 126.6666666666667, 0.0, 0.0, 10.20833333333333, 16.92358026995213, 17.5, 20.50432980726304, 21.5, 0.0, 9.097980274652894], 
processed observation next is [0.3333333333333333, 1.0, 0.46581196581196577, 0.82, 0.34242424242424246, 0.35185185185185197, 0.0, 0.0, 0.6701388888888888, 0.1692358026995213, 0.375, 0.525216490363152, 0.575, 0.0, 0.10703506205473994], 
reward next is -0.3024. 
=============================================
[2017-11-01 09:43:20,940] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-24.72923851]
 [-23.84231949]
 [-24.72877312]
 [-24.55328369]
 [-23.83571815]], R is [[-23.81294632]
 [-23.88955307]
 [-23.9586525 ]
 [-24.020998  ]
 [-24.07597542]].
[2017-11-01 09:43:22,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.24965082  0.10801601  0.10682277  0.17274347  0.12975846  0.09412989
  0.07818779  0.04704921  0.01364164], sum to 1.0000
[2017-11-01 09:43:22,888] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.125, 81.25, 3.825, 115.0, 10.0, 12.5, 10.16666666666667, 7.829981456805839, 24.5, 22.29291416084525, 22.7, 1.0, 63.89209747484782], 
actual action is [10.125, 19.5], 
sim time next is 1583400.0000, 
raw observation next is [5.083333333333334, 81.5, 3.916666666666667, 116.6666666666667, 13.0, 15.0, 10.125, 7.636831222058225, 19.5, 22.58117454211353, 22.7, 1.0, 50.00703274017461], 
processed observation next is [0.5, 0.30434782608695654, 0.46367521367521375, 0.815, 0.3560606060606061, 0.3240740740740742, 0.03439153439153439, 0.015, 0.66875, 0.07636831222058225, 0.475, 0.6290587271056765, 0.635, 1.0, 0.5883180322373484], 
reward next is -0.3323. 
=============================================
[2017-11-01 09:43:31,681] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.17806358e-05   1.57215345e-05   2.73065034e-05   3.92391012e-05
   4.41769880e-05   4.02304381e-01   1.71907872e-01   2.82150954e-01
   1.43498585e-01], sum to 1.0000
[2017-11-01 09:43:31,906] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [5.0, 82.0, 3.6, 121.6666666666667, 0.0, 0.0, 10.0, 7.85325579908805, 30.0, 25.3453609874893, 21.5, 0.0, 39.62024169672522], 
actual action is [10.0, 30], 
sim time next is 1557000.0000, 
raw observation next is [5.0, 82.0, 3.6, 120.0, 0.0, 0.0, 10.0, 7.878548868523585, 30.0, 25.35416933686877, 21.5, 0.0, 39.57587980325452], 
processed observation next is [0.5, 0.0, 0.46153846153846156, 0.82, 0.32727272727272727, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.07878548868523585, 1.0, 0.7677084668434386, 0.575, 0.0, 0.46559858592064146], 
reward next is -0.2328. 
=============================================
[2017-11-01 09:43:32,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.39093972e-04   1.54452413e-04   2.79361557e-04   3.88631219e-04
   3.90771893e-04   4.18178707e-01   1.83322623e-01   2.44070396e-01
   1.53075993e-01], sum to 1.0000
[2017-11-01 09:43:32,256] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [4.65, 84.5, 2.75, 90.0, 0.0, 0.0, 9.641666666666666, 7.458959789495051, 30.0, 25.26913130691217, 21.5, 0.0, 39.34142475457359], 
actual action is [9.65, 30], 
sim time next is 1571700.0000, 
raw observation next is [4.658333333333333, 84.41666666666666, 2.741666666666667, 90.0, 0.0, 0.0, 9.65, 7.473335886808256, 30.0, 25.26929401601982, 21.5, 0.0, 39.33238601994659], 
processed observation next is [0.5, 0.17391304347826086, 0.4527777777777777, 0.8441666666666666, 0.2492424242424243, 0.25, 0.0, 0.0, 0.6608333333333333, 0.07473335886808256, 1.0, 0.763464700800991, 0.575, 0.0, 0.4627339531758422], 
reward next is -0.2314. 
=============================================
[2017-11-01 09:43:35,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.01921391e-09   9.19081458e-07   3.86429775e-07   7.65698189e-07
   9.17708121e-07   2.93588936e-01   2.22989723e-01   2.75372356e-01
   2.08046004e-01], sum to 1.0000
[2017-11-01 09:43:35,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [5.0, 81.25, 3.6, 107.5, 0.0, 0.0, 10.0, 8.189028960190045, 22.5, 25.42543624059119, 21.5, 0.0, 32.6068220789013], 
actual action is [10.0, 24.5], 
sim time next is 1560000.0000, 
raw observation next is [5.0, 81.0, 3.600000000000001, 106.6666666666667, 0.0, 0.0, 10.0, 8.059035772808182, 24.5, 25.41203316977598, 21.5, 0.0, 30.88452984839441], 
processed observation next is [0.5, 0.043478260869565216, 0.46153846153846156, 0.81, 0.3272727272727274, 0.2962962962962964, 0.0, 0.0, 0.6666666666666666, 0.08059035772808182, 0.725, 0.770601658488799, 0.575, 0.0, 0.3633474099811107], 
reward next is -0.1817. 
=============================================
[2017-11-01 09:43:37,722] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.56295055e-01   2.24830747e-01   1.23157613e-01   2.28374809e-01
   1.66530252e-01   3.11065582e-04   1.78649017e-04   1.97487127e-04
   1.24350379e-04], sum to 1.0000
[2017-11-01 09:43:37,811] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [4.533333333333333, 85.33333333333334, 2.866666666666666, 90.0, 0.0, 0.0, 9.516666666666666, 6.68901324753776, 30.0, 24.78978551353168, 21.5, 0.0, 46.0549475449687], 
actual action is [9.533333333333333, 29.0], 
sim time next is 1568700.0000, 
raw observation next is [4.55, 85.25, 2.85, 90.0, 0.0, 0.0, 9.533333333333333, 6.93612549693449, 29.0, 24.80146980045444, 21.5, 0.0, 45.3528644243513], 
processed observation next is [0.5, 0.13043478260869565, 0.45, 0.8525, 0.2590909090909091, 0.25, 0.0, 0.0, 0.6588888888888889, 0.0693612549693449, 0.95, 0.740073490022722, 0.575, 0.0, 0.5335631108747212], 
reward next is -0.2668. 
=============================================
[2017-11-01 09:43:45,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.26306483  0.22319551  0.10531674  0.173397    0.13647103  0.03298199
  0.02699748  0.02338113  0.01519432], sum to 1.0000
[2017-11-01 09:43:45,201] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.8, 49.0, 7.050000000000001, 140.0, 169.25, 31.0, 18.8, 8.941129729663547, 12.5, 25.69501218828888, 22.7, 1.0, 17.47090617011782], 
actual action is [8.8, 10], 
sim time next is 1603200.0000, 
raw observation next is [13.8, 49.0, 7.0, 140.0, 171.5, 20.66666666666666, 8.8, 8.76200199685929, 10.0, 25.76647366528076, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.6871794871794872, 0.49, 0.6363636363636364, 0.3888888888888889, 0.4537037037037037, 0.02066666666666666, 0.6466666666666666, 0.0876200199685929, 0.0, 0.788323683264038, 0.635, 1.0, 0.0], 
reward next is -0.0438. 
=============================================
[2017-11-01 09:43:46,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.15691222  0.16479048  0.10535111  0.1445874   0.1503603   0.08439372
  0.07330827  0.06415537  0.05614119], sum to 1.0000
[2017-11-01 09:43:46,387] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.8, 49.0, 6.475, 139.1666666666667, 157.9166666666667, 0.0, 18.8, 8.9236813136063, 14.0, 25.78560657425625, 22.7, 1.0, 11.69545087756235], 
actual action is [18.8, 13.0], 
sim time next is 1606200.0000, 
raw observation next is [13.8, 49.0, 6.35, 138.3333333333333, 155.3333333333333, 0.0, 18.8, 9.012217932963226, 13.0, 25.87813333411048, 22.7, 1.0, 10.44003629045834], 
processed observation next is [0.5, 0.6086956521739131, 0.6871794871794872, 0.49, 0.5772727272727273, 0.38425925925925913, 0.41093474426807747, 0.0, 0.8133333333333332, 0.09012217932963226, 0.15, 0.793906666705524, 0.635, 1.0, 0.1228239563583334], 
reward next is -0.1065. 
=============================================
[2017-11-01 09:43:48,509] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 86292: loss 1.0076
[2017-11-01 09:43:52,099] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.10102486  0.08850893  0.05041702  0.04643712  0.06122794  0.21836753
  0.14255922  0.21218261  0.07927475], sum to 1.0000
[2017-11-01 09:43:52,179] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.491666666666666, 74.83333333333333, 7.408333333333333, 120.0, 0.0, 0.0, 12.53333333333333, 6.991997816480312, 22.0, 23.09104285442925, 21.5, 0.0, 4.579049609606531], 
actual action is [12.491666666666667, 17.0], 
sim time next is 1629000.0000, 
raw observation next is [7.45, 75.0, 7.45, 120.0, 0.0, 0.0, 12.49166666666667, 7.05895408925814, 17.0, 23.03856603503267, 21.5, 0.0, 4.343086635451035], 
processed observation next is [0.5, 0.8695652173913043, 0.5243589743589744, 0.75, 0.6772727272727272, 0.3333333333333333, 0.0, 0.0, 0.7081944444444446, 0.0705895408925814, 0.35, 0.6519283017516335, 0.575, 0.0, 0.05109513688765924], 
reward next is -0.0255. 
=============================================
[2017-11-01 09:43:52,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 86781: loss 5.0457
[2017-11-01 09:43:55,805] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5500, global step 87291: loss -0.7257
[2017-11-01 09:43:57,982] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87570: loss -0.0620
[2017-11-01 09:44:00,347] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87882: loss -2.5656
[2017-11-01 09:44:00,481] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87903: loss 1.9332
[2017-11-01 09:44:00,551] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5500, global step 87911: loss -6.5079
[2017-11-01 09:44:01,881] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5500, global step 88089: loss 1.9546
[2017-11-01 09:44:02,373] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88154: loss 2.7604
[2017-11-01 09:44:02,804] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88211: loss 1.4095
[2017-11-01 09:44:04,666] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88466: loss 2.7609
[2017-11-01 09:44:05,077] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5500, global step 88493: loss 0.7180
[2017-11-01 09:44:05,137] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88495: loss -0.7627
[2017-11-01 09:44:05,734] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88584: loss 1.6467
[2017-11-01 09:44:08,293] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88919: loss 9.3878
[2017-11-01 09:44:09,400] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5500, global step 89043: loss -22.2946
[2017-11-01 09:44:34,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.31295466e-01   7.34362826e-02   2.49099821e-01   2.37446204e-01
   2.08722234e-01   5.72442687e-14   4.14794982e-14   6.55478140e-14
   4.67856175e-14], sum to 1.0000
[2017-11-01 09:44:34,287] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.1, 88.0, 7.325, 232.5, 0.0, 0.0, 6.1, 12.56714170579192, 12.0, 21.98503277489485, 22.7, 1.0, 27.83978744678419], 
actual action is [6.1, 11.5], 
sim time next is 1711200.0000, 
raw observation next is [1.1, 88.0, 7.366666666666667, 233.3333333333333, 0.0, 0.0, 6.1, 12.88799570208128, 11.5, 21.97065242358837, 22.7, 1.0, 25.88555171583686], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.88, 0.6696969696969698, 0.648148148148148, 0.0, 0.0, 0.6016666666666667, 0.1288799570208128, 0.075, 0.5985326211794184, 0.635, 1.0, 0.3045359025392572], 
reward next is -0.2167. 
=============================================
[2017-11-01 09:44:50,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   8.53259343e-19   2.69186450e-18   1.40902111e-18
   1.24099260e-18   1.24380432e-01   1.77390903e-01   3.45928818e-01
   3.52299809e-01], sum to 1.0000
[2017-11-01 09:44:50,982] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.6, 84.33333333333333, 9.533333333333333, 250.0, 0.0, 0.0, 4.4, 21.96252592756355, 13.0, 20.5138744872418, 21.5, 0.0, 25.92409233722648], 
actual action is [4.4, 15.0], 
sim time next is 1745100.0000, 
raw observation next is [-0.6, 84.0, 9.575, 250.0, 0.0, 0.0, 4.4, 22.38709786111915, 15.0, 20.49797300007345, 21.5, 0.0, 24.75572783884675], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.317948717948718, 0.84, 0.8704545454545454, 0.6944444444444444, 0.0, 0.0, 0.5733333333333334, 0.22387097861119148, 0.25, 0.5248986500036725, 0.575, 0.0, 0.2912438569276088], 
reward next is -0.3961. 
=============================================
[2017-11-01 09:44:52,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  6.42332882e-02   1.40080666e-02   1.43897489e-01   3.14684927e-01
   4.63176191e-01   3.12295583e-31   3.01359982e-31   1.31501415e-30
   2.76129341e-30], sum to 1.0000
[2017-11-01 09:44:52,771] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.05, 86.0, 9.7, 250.0, 0.0, 0.0, 4.0, 28.87036476979569, 23.5, 19.68525488287776, 21.5, 0.0, 40.16303907482552], 
actual action is [3.95, 23.0], 
sim time next is 1749000.0000, 
raw observation next is [-1.1, 86.33333333333333, 9.7, 250.0, 0.0, 0.0, 3.95, 26.00733549788308, 23.0, 19.66841089111094, 21.5, 0.0, 65.94287582214679], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.30512820512820515, 0.8633333333333333, 0.8818181818181817, 0.6944444444444444, 0.0, 0.0, 0.5658333333333334, 0.2600733549788308, 0.65, 0.48342054455554706, 0.575, 0.0, 0.7757985390840799], 
reward next is -0.8458. 
=============================================
[2017-11-01 09:44:56,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.02409867e-10   2.17128471e-02   3.13326597e-01   2.23112702e-01
   4.41847861e-01   1.10110260e-14   8.79162432e-15   3.04860371e-14
   1.89846850e-13], sum to 1.0000
[2017-11-01 09:44:56,574] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 83.66666666666667, 9.283333333333331, 251.6666666666667, 121.3333333333333, 0.0, 2.7, 22.3534118616314, 16.0, 21.14237790931069, 22.7, 1.0, 16.92732818347006], 
actual action is [2.7, 16.0], 
sim time next is 1770900.0000, 
raw observation next is [-2.3, 83.33333333333333, 9.241666666666665, 250.8333333333333, 121.9166666666667, 0.0, 2.7, 23.08591546672335, 16.0, 21.04045975037274, 22.7, 1.0, 15.79424545823644], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.27435897435897433, 0.8333333333333333, 0.840151515151515, 0.6967592592592591, 0.32253086419753096, 0.0, 0.545, 0.2308591546672335, 0.3, 0.552022987518637, 0.635, 1.0, 0.18581465244984047], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:45:01,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.37851828e-01   2.87790708e-02   1.96213648e-01   1.42097190e-01
   3.95058244e-01   8.23512128e-34   6.64929216e-34   1.31011839e-33
   3.77548251e-33], sum to 1.0000
[2017-11-01 09:45:01,712] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.591666666666666, 83.0, 9.491666666666665, 250.0, 125.4166666666667, 0.0, 2.45, 15.48100709230189, 24.0, 21.4590180767949, 22.7, 1.0, 68.77709730774495], 
actual action is [2.408333333333334, 24.0], 
sim time next is 1773600.0000, 
raw observation next is [-2.633333333333333, 83.0, 9.533333333333333, 250.0, 124.8333333333333, 0.0, 2.408333333333334, 14.50854705705477, 24.0, 21.686502279438, 22.7, 1.0, 66.79177501944571], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.2658119658119658, 0.83, 0.8666666666666667, 0.6944444444444444, 0.3302469135802468, 0.0, 0.5401388888888888, 0.1450854705705477, 0.7, 0.5843251139718999, 0.635, 1.0, 0.7857855884640672], 
reward next is -0.4654. 
=============================================
[2017-11-01 09:45:02,761] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 94747: loss -10.2913
[2017-11-01 09:45:13,697] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95598: loss -2.6548
[2017-11-01 09:45:14,686] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6000, global step 95686: loss 86.0195
[2017-11-01 09:45:14,726] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95687: loss 12.2090
[2017-11-01 09:45:16,423] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95843: loss -2.9417
[2017-11-01 09:45:18,240] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6000, global step 96015: loss -195.9457
[2017-11-01 09:45:18,322] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.93001950e-01   3.73010710e-02   1.82786062e-01   2.04367384e-01
   2.82543600e-01   1.99119024e-24   1.75925823e-24   1.63192119e-24
   1.10907631e-24], sum to 1.0000
[2017-11-01 09:45:18,398] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 83.0, 8.95, 250.0, 0.0, 0.0, 0.5, 20.62155694456449, 16.0, 21.58851829150592, 21.5, 0.0, 25.73363787418607], 
actual action is [0.5, 16.0], 
sim time next is 1798500.0000, 
raw observation next is [-4.5, 83.0, 9.075, 250.0, 0.0, 0.0, 0.5, 21.26110452961393, 16.0, 21.51583514802808, 21.5, 0.0, 24.64249454174324], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.21794871794871795, 0.83, 0.825, 0.6944444444444444, 0.0, 0.0, 0.5083333333333333, 0.2126110452961393, 0.3, 0.5757917574014041, 0.575, 0.0, 0.28991170049109694], 
reward next is -0.1450. 
=============================================
[2017-11-01 09:45:18,485] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96051: loss -32.3199
[2017-11-01 09:45:18,848] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96095: loss 189.1949
[2017-11-01 09:45:18,973] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6000, global step 96107: loss 98.9901
[2017-11-01 09:45:19,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96123: loss -5.0617
[2017-11-01 09:45:19,901] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96228: loss -9.9714
[2017-11-01 09:45:20,884] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96348: loss 19.6566
[2017-11-01 09:45:21,148] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6000, global step 96378: loss -74.0422
[2017-11-01 09:45:22,069] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6000, global step 96480: loss -32.6384
[2017-11-01 09:45:23,221] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96604: loss 102.5812
[2017-11-01 09:45:24,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96688: loss 238.6064
[2017-11-01 09:45:24,269] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   8.43385213e-17   2.89541352e-16   1.04519882e-16
   9.68599844e-17   3.48331481e-01   4.89251316e-01   8.40747952e-02
   7.83424154e-02], sum to 1.0000
[2017-11-01 09:45:24,367] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-5.766666666666666, 80.08333333333333, 9.2, 250.0, 0.0, 0.0, -0.7333333333333334, 30.62347132479094, 22.0, 19.88475627976355, 21.5, 0.0, 42.36851728523285], 
actual action is [-0.7666666666666657, 22.5], 
sim time next is 1819800.0000, 
raw observation next is [-5.8, 80.5, 9.2, 250.0, 0.0, 0.0, -0.7666666666666657, 29.28725939601178, 22.5, 19.83615398855798, 21.5, 0.0, 56.4918878466992], 
processed observation next is [1.0, 0.043478260869565216, 0.18461538461538463, 0.805, 0.8363636363636363, 0.6944444444444444, 0.0, 0.0, 0.4872222222222222, 0.2928725939601178, 0.625, 0.4918076994278991, 0.575, 0.0, 0.6646104452552847], 
reward next is -0.7483. 
=============================================
[2017-11-01 09:45:26,655] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   2.71979757e-38   8.07829227e-38   0.00000000e+00
   0.00000000e+00   3.55801731e-01   4.70440984e-01   1.03917748e-01
   6.98394999e-02], sum to 1.0000
[2017-11-01 09:45:26,728] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.05, 84.0, 9.2, 247.5, 0.0, 0.0, -1.033333333333333, 26.65509774236746, 17.5, 20.1891235295333, 21.5, 0.0, 32.97024161708658], 
actual action is [-1.0499999999999998, 18.0], 
sim time next is 1822800.0000, 
raw observation next is [-6.066666666666666, 84.33333333333334, 9.2, 246.6666666666667, 0.0, 0.0, -1.05, 27.37777885462021, 18.0, 20.15247410838171, 21.5, 0.0, 31.41914520552886], 
processed observation next is [1.0, 0.08695652173913043, 0.17777777777777778, 0.8433333333333334, 0.8363636363636363, 0.6851851851851853, 0.0, 0.0, 0.4825, 0.2737777885462021, 0.4, 0.5076237054190855, 0.575, 0.0, 0.3696370024179866], 
reward next is -0.5217. 
=============================================
[2017-11-01 09:45:27,575] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.38466659
  0.52200377  0.05526111  0.03806856], sum to 1.0000
[2017-11-01 09:45:27,590] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.866666666666667, 81.33333333333333, 9.2, 250.0, 0.0, 0.0, -0.833333333333333, 51.09925409477744, 14.5, 18.01298313574589, 21.5, 0.0, 7.232705679092519], 
actual action is [-0.8666666666666671, 15.5], 
sim time next is 1820700.0000, 
raw observation next is [-5.9, 81.75, 9.2, 250.0, 0.0, 0.0, -0.8666666666666671, 51.74761356018585, 15.5, 17.95825316071598, 21.5, 0.0, 6.763386554819984], 
processed observation next is [1.0, 0.043478260869565216, 0.18205128205128204, 0.8175, 0.8363636363636363, 0.6944444444444444, 0.0, 0.0, 0.4855555555555556, 0.5174761356018585, 0.275, 0.397912658035799, 0.575, 0.0, 0.07956925358611747], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:45:37,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   1.85103240e-33   3.93685511e-33   1.43202662e-33
   1.16068193e-33   1.11712113e-01   4.77994591e-01   1.91063762e-01
   2.19229564e-01], sum to 1.0000
[2017-11-01 09:45:37,900] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.699999999999999, 78.0, 7.824999999999999, 248.3333333333333, 24.83333333333333, 0.0, -1.700000000000001, 32.29696426060993, 30.0, 19.31848847382081, 22.7, 1.0, 67.5346186897078], 
actual action is [-1.6999999999999993, 30], 
sim time next is 1845000.0000, 
raw observation next is [-6.7, 78.0, 7.949999999999999, 250.0, 27.0, 0.0, -1.699999999999999, 31.55969695079903, 30.0, 19.45991471197732, 22.7, 1.0, 67.40258223310582], 
processed observation next is [1.0, 0.34782608695652173, 0.16153846153846155, 0.78, 0.7227272727272727, 0.6944444444444444, 0.07142857142857142, 0.0, 0.4716666666666667, 0.3155969695079903, 1.0, 0.472995735598866, 0.635, 1.0, 0.7929715556835979], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:45:55,311] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.01184728  0.01304748  0.18470156  0.12786098  0.66254276  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:45:55,393] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.791666666666666, 71.0, 7.908333333333333, 240.0, 125.3333333333333, 6.750000000000003, 0.1666666666666661, 20.89027627616653, 18.0, 21.71445418364091, 22.7, 1.0, 35.61783701727155], 
actual action is [0.20833333333333393, 17.5], 
sim time next is 1859400.0000, 
raw observation next is [-4.75, 71.0, 7.949999999999999, 240.0, 120.0, 0.0, 0.2083333333333339, 21.77432986046656, 17.5, 21.63431521561831, 22.7, 1.0, 33.21764247119823], 
processed observation next is [1.0, 0.5217391304347826, 0.21153846153846154, 0.71, 0.7227272727272727, 0.6666666666666666, 0.31746031746031744, 0.0, 0.5034722222222222, 0.21774329860466557, 0.375, 0.5817157607809156, 0.635, 1.0, 0.39079579377880275], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:05,467] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.24175993e-02   8.23239051e-03   1.18424438e-01   5.50101459e-01
   3.00824225e-01   2.61255270e-36   4.28796039e-36   3.80646545e-36
   9.60016637e-36], sum to 1.0000
[2017-11-01 09:46:05,697] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 81.0, 5.35, 232.5, 22.0, 0.0, 0.5, 22.75066229639801, 22.0, 20.89528408345586, 22.7, 1.0, 67.3008530823632], 
actual action is [0.5, 21.0], 
sim time next is 1875000.0000, 
raw observation next is [-4.5, 81.66666666666667, 5.266666666666667, 231.6666666666667, 19.66666666666667, 0.0, 0.5, 21.70997057596983, 21.0, 21.14008005098197, 22.7, 1.0, 65.17270162180873], 
processed observation next is [1.0, 0.6956521739130435, 0.21794871794871795, 0.8166666666666668, 0.47878787878787876, 0.6435185185185186, 0.05202821869488537, 0.0, 0.5083333333333333, 0.2170997057596983, 0.55, 0.5570040025490985, 0.635, 1.0, 0.7667376661389262], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:08,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.18862633e-02   3.25239003e-02   3.78562778e-01   4.36814845e-01
   1.40212178e-01   2.00812232e-26   1.32740503e-25   5.26733828e-26
   6.56291474e-26], sum to 1.0000
[2017-11-01 09:46:08,853] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.625, 83.75, 4.85, 230.0, 8.0, 0.0, 0.416666666666667, 20.43486948367096, 23.5, 21.70568131116817, 22.7, 1.0, 63.14308930236284], 
actual action is [0.375, 22.5], 
sim time next is 1876800.0000, 
raw observation next is [-4.666666666666667, 84.0, 4.766666666666667, 230.0, 0.0, 0.0, 0.375, 20.13253909097685, 22.5, 21.78657452815526, 22.7, 1.0, 63.04378164599351], 
processed observation next is [1.0, 0.7391304347826086, 0.21367521367521364, 0.84, 0.43333333333333335, 0.6388888888888888, 0.0, 0.0, 0.50625, 0.20132539090976848, 0.625, 0.589328726407763, 0.635, 1.0, 0.7416915487763942], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:09,731] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  5.59875709e-18   4.61163782e-02   3.70181292e-01   5.31264484e-01
   4.72301729e-02   3.30326206e-04   2.50738882e-03   6.19319151e-04
   1.75065326e-03], sum to 1.0000
[2017-11-01 09:46:09,902] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 75.66666666666667, 6.016666666666666, 239.1666666666667, 46.91666666666666, 0.0, 0.5, 23.27005114342755, 14.5, 21.81025310336531, 22.7, 1.0, 34.91220308467529], 
actual action is [0.5, 13.5], 
sim time next is 1872600.0000, 
raw observation next is [-4.5, 76.33333333333333, 5.933333333333333, 238.3333333333333, 43.33333333333333, 0.0, 0.5, 24.1412342021053, 13.5, 21.71721850759946, 22.7, 1.0, 32.52831890044973], 
processed observation next is [1.0, 0.6956521739130435, 0.21794871794871795, 0.7633333333333333, 0.5393939393939393, 0.6620370370370369, 0.1146384479717813, 0.0, 0.5083333333333333, 0.241412342021053, 0.175, 0.5858609253799729, 0.635, 1.0, 0.3826861047111733], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:19,012] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.21631128e-29   2.52412952e-11   4.82135642e-12   7.65598869e-12
   1.03249549e-12   3.72223668e-02   1.43180832e-01   5.01752079e-01
   3.17844778e-01], sum to 1.0000
[2017-11-01 09:46:19,097] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.566666666666666, 76.33333333333334, 6.266666666666667, 256.6666666666667, 0.0, 0.0, -1.475000000000001, 19.09234494292319, 28.0, 21.56803911435184, 21.5, 0.0, 47.76855006216664], 
actual action is [-1.5666666666666664, 30.0], 
sim time next is 1895100.0000, 
raw observation next is [-6.658333333333333, 76.66666666666666, 6.183333333333333, 255.8333333333333, 0.0, 0.0, -1.566666666666666, 18.98078841943047, 30.0, 21.58038580120778, 21.5, 0.0, 47.68974057583408], 
processed observation next is [1.0, 0.9565217391304348, 0.1626068376068376, 0.7666666666666666, 0.562121212121212, 0.710648148148148, 0.0, 0.0, 0.4738888888888889, 0.18980788419430472, 1.0, 0.579019290060389, 0.575, 0.0, 0.561055771480401], 
reward next is -0.2805. 
=============================================
[2017-11-01 09:46:20,445] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-40.39659882]
 [-40.63657761]
 [-40.87243652]
 [-39.3586235 ]
 [-40.19805145]], R is [[-41.59628296]
 [-41.51568604]
 [-41.43770218]
 [-41.36268234]
 [-41.28656769]].
[2017-11-01 09:46:23,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.50291935e-01   2.68251598e-01   8.38340670e-02   3.70661646e-01
   1.26960814e-01   7.03182931e-31   6.77481593e-30   1.28806887e-29
   2.08043151e-29], sum to 1.0000
[2017-11-01 09:46:23,867] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-8.4, 78.0, 5.1, 246.6666666666667, 0.0, 0.0, -3.4, 35.1922507096054, 21.0, 18.97900430205644, 21.5, 0.0, 24.63871746603479], 
actual action is [-3.4000000000000004, 20.5], 
sim time next is 1913100.0000, 
raw observation next is [-8.4, 78.0, 5.225, 245.8333333333333, 0.0, 0.0, -3.4, 34.59670827606634, 20.5, 18.95380665892845, 21.5, 0.0, 41.54868423440905], 
processed observation next is [0.0, 0.13043478260869565, 0.11794871794871795, 0.78, 0.475, 0.6828703703703702, 0.0, 0.0, 0.44333333333333336, 0.34596708276066335, 0.525, 0.44769033294642246, 0.575, 0.0, 0.4888080498165771], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:25,233] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.72718078e-01   1.43188313e-01   2.81249825e-02   4.21728134e-01
   2.34240457e-01   0.00000000e+00   5.11706387e-38   1.22437713e-37
   1.45017284e-37], sum to 1.0000
[2017-11-01 09:46:25,278] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.95, 82.74999999999999, 3.05, 220.8333333333333, 0.0, 0.0, -3.9, 37.94495608443529, 17.0, 18.64591219965584, 21.5, 0.0, 20.53780396027357], 
actual action is [-3.9499999999999993, 12.0], 
sim time next is 1923000.0000, 
raw observation next is [-9.0, 83.50000000000001, 3.1, 221.6666666666667, 0.0, 0.0, -3.949999999999999, 38.96944427325916, 12.0, 18.55206056746451, 21.5, 0.0, 19.68265527619542], 
processed observation next is [0.0, 0.2608695652173913, 0.10256410256410256, 0.8350000000000002, 0.2818181818181818, 0.6157407407407409, 0.0, 0.0, 0.4341666666666667, 0.3896944427325916, 0.1, 0.4276030283732254, 0.575, 0.0, 0.2315606503081814], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:27,530] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 102482: loss 174.8871
[2017-11-01 09:46:40,661] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103422: loss 34.0213
[2017-11-01 09:46:42,219] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103585: loss 52.1001
[2017-11-01 09:46:43,330] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103700: loss 75.0715
[2017-11-01 09:46:43,401] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6500, global step 103710: loss 136.6788
[2017-11-01 09:46:45,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103874: loss 91.2990
[2017-11-01 09:46:47,685] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6500, global step 104028: loss 0.5010
[2017-11-01 09:46:48,895] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104140: loss 18.6710
[2017-11-01 09:46:48,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.56218603e-01   5.30858599e-02   1.39854074e-01   4.25437421e-01
   2.25404024e-01   5.63440175e-19   8.28958069e-19   9.49042825e-19
   2.84518925e-18], sum to 1.0000
[2017-11-01 09:46:48,945] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.199999999999999, 68.33333333333333, 5.433333333333334, 220.0, 231.1666666666667, 9.0, -10.25, 18.99803777248497, 10.0, 22.09766943431867, 22.7, 1.0, 0.0], 
actual action is [-10.2, 10], 
sim time next is 1943100.0000, 
raw observation next is [-5.15, 67.5, 5.475, 220.0, 230.75, 8.5, -10.2, 19.78466722973715, 10.0, 22.00056082140554, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.20128205128205126, 0.675, 0.4977272727272727, 0.6111111111111112, 0.6104497354497355, 0.0085, 0.33, 0.1978466722973715, 0.0, 0.600028041070277, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:49,158] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6500, global step 104168: loss -2.0552
[2017-11-01 09:46:49,544] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104219: loss 61.3405
[2017-11-01 09:46:50,327] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.26106864e-19   2.13715865e-07   1.75572694e-07   2.50393498e-07
   1.47702721e-07   1.52216315e-01   1.88450277e-01   1.87314987e-01
   4.72017705e-01], sum to 1.0000
[2017-11-01 09:46:50,383] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.266666666666667, 65.0, 4.933333333333334, 226.6666666666667, 212.0, 3.333333333333333, 0.6416666666666666, 13.42023560224078, 14.5, 22.41809477428168, 22.7, 1.0, 27.64479459574886], 
actual action is [0.7333333333333334, 19.5], 
sim time next is 1946700.0000, 
raw observation next is [-4.175, 65.0, 4.85, 227.5, 204.5, 3.0, 0.7333333333333334, 13.72996321620272, 19.5, 22.38058395741772, 22.7, 1.0, 25.62766267583704], 
processed observation next is [0.0, 0.5217391304347826, 0.22628205128205126, 0.65, 0.44090909090909086, 0.6319444444444444, 0.541005291005291, 0.003, 0.5122222222222222, 0.1372996321620272, 0.475, 0.619029197870886, 0.635, 1.0, 0.30150191383337693], 
reward next is -0.2194. 
=============================================
[2017-11-01 09:46:50,437] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104325: loss 119.1781
[2017-11-01 09:46:52,009] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104519: loss -15.0914
[2017-11-01 09:46:52,025] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104520: loss 7.7751
[2017-11-01 09:46:52,084] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6500, global step 104523: loss 112.0628
[2017-11-01 09:46:52,297] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104542: loss 3.1993
[2017-11-01 09:46:55,213] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6500, global step 104813: loss 0.6728
[2017-11-01 09:47:20,554] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-52.98624039]
 [-53.97962189]
 [-52.73871994]
 [-52.33001709]
 [-52.11364746]], R is [[-52.12992477]
 [-52.60862732]
 [-53.08254242]
 [-53.55171585]
 [-54.01620102]].
[2017-11-01 09:47:46,922] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 110008: loss 61.1958
[2017-11-01 09:47:57,113] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 110853: loss -233.4134
[2017-11-01 09:47:59,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-33.16702652]
 [-33.55056763]
 [-34.94493484]
 [-34.49773407]
 [-33.41321182]], R is [[-32.61684418]
 [-32.76128006]
 [-32.96292496]
 [-33.22670746]
 [-33.55878067]].
[2017-11-01 09:48:00,751] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111187: loss 7.7235
[2017-11-01 09:48:02,655] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7000, global step 111373: loss -1.7362
[2017-11-01 09:48:04,983] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111587: loss 30.4448
[2017-11-01 09:48:07,211] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111807: loss -201.6780
[2017-11-01 09:48:07,665] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   7.56461082e-28   3.45341026e-28   8.70790507e-29
   1.23666128e-28   1.99016407e-01   2.39174798e-01   2.12992787e-01
   3.48815978e-01], sum to 1.0000
[2017-11-01 09:48:07,807] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111870: loss -192.5393
[2017-11-01 09:48:07,877] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.95, 88.66666666666666, 4.808333333333333, 240.0, 0.0, 0.0, -0.9000000000000004, 22.20972831736505, 25.5, 19.88955774041411, 21.5, 0.0, 51.46724660424689], 
actual action is [-0.9500000000000002, 26.5], 
sim time next is 2090400.0000, 
raw observation next is [-6.0, 88.33333333333334, 4.766666666666667, 240.0, 0.0, 0.0, -0.9500000000000002, 21.38025030074112, 26.5, 19.97658499244829, 21.5, 0.0, 49.43765551634026], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.1794871794871795, 0.8833333333333334, 0.43333333333333335, 0.6666666666666666, 0.0, 0.0, 0.4841666666666667, 0.21380250300741122, 0.825, 0.4988292496224146, 0.575, 0.0, 0.5816194766628265], 
reward next is -0.6717. 
=============================================
[2017-11-01 09:48:09,895] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112058: loss 330.8102
[2017-11-01 09:48:10,160] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112087: loss -17.2771
[2017-11-01 09:48:10,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.59354904e-02   9.22324136e-02   2.38125533e-01   1.17848314e-01
   4.75858122e-01   6.41563688e-26   3.80868670e-26   4.02928672e-26
   1.54081705e-25], sum to 1.0000
[2017-11-01 09:48:10,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.3, 79.0, 2.0, 230.0, 36.5, 18.5, -2.25, 18.53466480479183, 26.0, 20.72509286510465, 22.7, 1.0, 62.58737559638197], 
actual action is [-2.3, 25.5], 
sim time next is 2102700.0000, 
raw observation next is [-7.341666666666667, 79.24999999999999, 2.041666666666667, 230.0, 42.41666666666666, 21.58333333333334, -2.3, 17.33029113825586, 25.5, 20.89971653631975, 22.7, 1.0, 62.25728232970876], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.14508547008547007, 0.7924999999999999, 0.18560606060606064, 0.6388888888888888, 0.11221340388007052, 0.02158333333333334, 0.46166666666666667, 0.1733029113825586, 0.775, 0.5449858268159875, 0.635, 1.0, 0.7324386156436324], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:48:11,051] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7000, global step 112174: loss -114.6093
[2017-11-01 09:48:12,650] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112312: loss -253.1372
[2017-11-01 09:48:13,813] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112390: loss -15.7819
[2017-11-01 09:48:17,325] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7000, global step 112618: loss 131.7280
[2017-11-01 09:48:17,514] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112627: loss 151.2816
[2017-11-01 09:48:19,062] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7000, global step 112738: loss -351.8072
[2017-11-01 09:48:21,121] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7000, global step 112874: loss -8.2152
[2017-11-01 09:48:36,789] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.20629173e-22   2.67306488e-09   3.13143023e-09   2.53235233e-09
   1.46919565e-09   2.20748544e-01   3.35780561e-01   2.68337399e-01
   1.75133482e-01], sum to 1.0000
[2017-11-01 09:48:36,936] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.2, 78.33333333333334, 3.0, 270.0, 0.0, 0.0, -1.2, 13.97556389757454, 25.0, 21.33608463610184, 21.5, 0.0, 44.9227727356427], 
actual action is [-1.2000000000000002, 26.0], 
sim time next is 2181300.0000, 
raw observation next is [-6.2, 78.66666666666666, 3.0, 270.0, 0.0, 0.0, -1.2, 13.99284149604542, 26.0, 21.32838923642132, 21.5, 0.0, 44.92872890323031], 
processed observation next is [0.5, 0.21739130434782608, 0.17435897435897435, 0.7866666666666666, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.1399284149604542, 0.8, 0.566419461821066, 0.575, 0.0, 0.5285732812144742], 
reward next is -0.3072. 
=============================================
[2017-11-01 09:48:41,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.29507089
  0.23363408  0.40851676  0.06277822], sum to 1.0000
[2017-11-01 09:48:41,231] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-7.25, 78.91666666666666, 3.641666666666667, 269.1666666666667, 0.0, 0.0, -2.3, 12.14564439120248, 29.5, 21.88121903581736, 21.5, 0.0, 45.75554295817698], 
actual action is [-2.25, 30], 
sim time next is 2164200.0000, 
raw observation next is [-7.199999999999999, 78.83333333333334, 3.683333333333333, 268.3333333333333, 0.0, 0.0, -2.25, 12.12501348253213, 30.0, 21.87864814695739, 21.5, 0.0, 45.65072309778246], 
processed observation next is [0.5, 0.043478260869565216, 0.14871794871794874, 0.7883333333333334, 0.33484848484848484, 0.7453703703703703, 0.0, 0.0, 0.4625, 0.1212501348253213, 1.0, 0.5939324073478695, 0.575, 0.0, 0.5370673305621466], 
reward next is -0.2685. 
=============================================
[2017-11-01 09:48:47,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.15513662e-01   1.73291683e-01   1.56484351e-01   2.66448915e-01
   1.88261405e-01   3.87817127e-15   4.83766944e-15   4.12162039e-15
   2.16499271e-15], sum to 1.0000
[2017-11-01 09:48:47,727] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-5.6, 83.0, 4.466666666666666, 260.0, 0.0, 0.0, -0.5999999999999996, 9.87244892948865, 22.0, 22.47059871118266, 21.5, 0.0, 40.0513411877624], 
actual action is [-0.5999999999999996, 22.0], 
sim time next is 2149200.0000, 
raw observation next is [-5.6, 83.0, 4.6, 260.0, 0.0, 0.0, -0.5999999999999996, 9.949908446085226, 22.0, 22.52066632473159, 21.5, 0.0, 34.49486382652803], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.18974358974358976, 0.83, 0.41818181818181815, 0.7222222222222222, 0.0, 0.0, 0.49, 0.09949908446085226, 0.6, 0.6260333162365794, 0.575, 0.0, 0.40582192737091805], 
reward next is -0.2029. 
=============================================
[2017-11-01 09:48:50,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.54528945e-29   3.45666285e-13   1.17923290e-13   1.53458721e-13
   7.49955043e-14   2.04842374e-01   2.56499022e-01   2.60808766e-01
   2.77849853e-01], sum to 1.0000
[2017-11-01 09:48:50,888] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.199999999999999, 77.66666666666667, 3.0, 270.0, 0.0, 0.0, -1.2, 16.84277837057111, 27.0, 20.72694862147314, 21.5, 0.0, 45.19399375455411], 
actual action is [-1.1999999999999993, 27.5], 
sim time next is 2180700.0000, 
raw observation next is [-6.2, 78.0, 3.0, 270.0, 0.0, 0.0, -1.199999999999999, 16.71870246579987, 27.5, 20.76243130028763, 21.5, 0.0, 45.17621750966648], 
processed observation next is [0.5, 0.21739130434782608, 0.17435897435897435, 0.78, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.16718702465799867, 0.875, 0.5381215650143816, 0.575, 0.0, 0.5314849118784292], 
reward next is -0.4501. 
=============================================
[2017-11-01 09:48:54,509] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.15345617
  0.19647719  0.10482061  0.54524606], sum to 1.0000
[2017-11-01 09:48:54,548] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.4, 80.0, 2.833333333333333, 260.0, 0.0, 0.0, -0.3499999999999996, 18.08971855925459, 13.5, 21.29808049751081, 22.7, 1.0, 19.28712369395103], 
actual action is [-0.40000000000000036, 18.5], 
sim time next is 2144700.0000, 
raw observation next is [-5.449999999999999, 80.75, 2.875, 260.0, 0.0, 0.0, -0.4000000000000004, 18.67274660033031, 18.5, 21.22190536197932, 22.7, 1.0, 17.90770067464354], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.1935897435897436, 0.8075, 0.26136363636363635, 0.7222222222222222, 0.0, 0.0, 0.4933333333333333, 0.1867274660033031, 0.425, 0.561095268098966, 0.635, 1.0, 0.21067883146639457], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:49:03,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.29808748
  0.07533611  0.14098714  0.48558921], sum to 1.0000
[2017-11-01 09:49:03,229] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.199999999999999, 77.66666666666667, 3.0, 270.0, 0.0, 0.0, -1.2, 22.25715099289672, 30.0, 19.8495535084388, 21.5, 0.0, 47.02862943437611], 
actual action is [-1.1999999999999993, 30], 
sim time next is 2180700.0000, 
raw observation next is [-6.2, 78.0, 3.0, 270.0, 0.0, 0.0, -1.199999999999999, 21.64913330584396, 30.0, 19.94946402324154, 21.5, 0.0, 46.56071865078362], 
processed observation next is [0.5, 0.21739130434782608, 0.17435897435897435, 0.78, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.2164913330584396, 1.0, 0.49747320116207694, 0.575, 0.0, 0.5477731605974544], 
reward next is -0.6615. 
=============================================
[2017-11-01 09:49:06,049] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.24227578e-08   3.50362271e-01   2.76365429e-01   1.50965095e-01
   2.04964116e-01   3.57198576e-03   2.66250642e-03   3.89490626e-03
   7.21362839e-03], sum to 1.0000
[2017-11-01 09:49:06,385] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-5.6, 75.0, 5.1, 280.0, 71.5, 356.5, -0.5999999999999996, 10.84036606721486, 28.0, 22.56083777002516, 22.7, 1.0, 53.37357684856542], 
actual action is [-0.5999999999999996, 26.0], 
sim time next is 2192700.0000, 
raw observation next is [-5.55, 74.66666666666667, 5.225, 277.4999999999999, 76.58333333333334, 372.25, -0.5999999999999996, 10.23999322632171, 26.0, 22.62062592241205, 22.7, 1.0, 62.0704873135586], 
processed observation next is [0.5, 0.391304347826087, 0.19102564102564104, 0.7466666666666667, 0.475, 0.770833333333333, 0.2026014109347443, 0.37225, 0.49, 0.1023999322632171, 0.8, 0.6310312961206025, 0.635, 1.0, 0.7302410272183365], 
reward next is -0.4163. 
=============================================
[2017-11-01 09:49:07,182] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-32.69125748]
 [-32.82711792]
 [-32.56599426]
 [-32.45902634]
 [-32.5050087 ]], R is [[-33.57133865]
 [-33.5615921 ]
 [-33.55423737]
 [-33.55014038]
 [-33.5474472 ]].
[2017-11-01 09:49:25,050] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 117615: loss 6.7008
[2017-11-01 09:49:31,717] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.32537179e-18   6.65041516e-05   1.16373412e-04   3.29641662e-05
   5.76864295e-05   2.41027996e-01   2.64854819e-01   2.26348847e-01
   2.67494798e-01], sum to 1.0000
[2017-11-01 09:49:32,002] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.858333333333333, 70.5, 6.516666666666667, 270.0, 134.0, 0.0, 1.183333333333334, 6.355248128429505, 21.0, 24.71031470530458, 22.7, 1.0, 59.6454261332094], 
actual action is [1.141666666666667, 23.0], 
sim time next is 2210400.0000, 
raw observation next is [-3.9, 71.0, 6.6, 270.0, 132.0, 0.0, 1.141666666666667, 6.37274045556403, 23.0, 24.7278666421142, 22.7, 1.0, 52.49804214082047], 
processed observation next is [0.5, 0.6086956521739131, 0.23333333333333334, 0.71, 0.6, 0.75, 0.3492063492063492, 0.0, 0.5190277777777778, 0.0637274045556403, 0.65, 0.73639333210571, 0.635, 1.0, 0.6176240251861232], 
reward next is -0.3407. 
=============================================
[2017-11-01 09:49:39,312] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.18874514e-01   1.20017543e-01   1.84908003e-01   1.22186899e-01
   3.54012966e-01   2.02615112e-16   1.57488915e-16   2.35281639e-16
   1.72677659e-16], sum to 1.0000
[2017-11-01 09:49:39,436] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.608333333333333, 66.25, 5.808333333333333, 274.1666666666666, 129.3333333333333, 0.0, 1.35, 6.744669296216629, 18.5, 24.43754256165045, 22.7, 1.0, 36.79923820181671], 
actual action is [1.391666666666667, 17.5], 
sim time next is 2205600.0000, 
raw observation next is [-3.566666666666666, 66.0, 5.766666666666667, 273.3333333333334, 130.6666666666667, 0.0, 1.391666666666667, 6.851303902839195, 17.5, 24.35691004226899, 22.7, 1.0, 34.17164263288165], 
processed observation next is [0.5, 0.5217391304347826, 0.24188034188034188, 0.66, 0.5242424242424243, 0.7592592592592595, 0.34567901234567916, 0.0, 0.5231944444444444, 0.06851303902839195, 0.375, 0.7178455021134494, 0.635, 1.0, 0.4020193250927253], 
reward next is -0.2353. 
=============================================
[2017-11-01 09:49:40,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-33.79253769]
 [-33.38204956]
 [-33.81757355]
 [-33.76780701]
 [-33.60403061]], R is [[-33.30029297]
 [-33.18221664]
 [-33.0774231 ]
 [-32.9875145 ]
 [-32.91389465]].
[2017-11-01 09:49:40,910] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 118663: loss 5.8389
[2017-11-01 09:49:41,116] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 118680: loss -25.2216
[2017-11-01 09:49:46,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   2.64841999e-30   4.87833052e-30   1.23678970e-30
   1.73116106e-30   2.43469611e-01   2.11478427e-01   4.06914443e-01
   1.38137579e-01], sum to 1.0000
[2017-11-01 09:49:46,105] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 78.0, 2.5, 230.0, 139.5, 44.5, -1.841666666666667, 12.66493482870674, 25.0, 22.34040271343478, 22.7, 1.0, 20.63864041005364], 
actual action is [-1.7000000000000002, 27.0], 
sim time next is 2282700.0000, 
raw observation next is [-6.558333333333334, 77.16666666666667, 2.5, 230.8333333333333, 145.9166666666667, 45.41666666666667, -1.7, 12.20994207997368, 27.0, 22.29649942961504, 22.7, 1.0, 46.69382587709799], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.16517094017094017, 0.7716666666666667, 0.22727272727272727, 0.6412037037037036, 0.3860229276895945, 0.045416666666666675, 0.4716666666666667, 0.1220994207997368, 0.85, 0.614824971480752, 0.635, 1.0, 0.5493391279658587], 
reward next is -0.3357. 
=============================================
[2017-11-01 09:49:46,788] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7500, global step 119363: loss -46.2783
[2017-11-01 09:49:47,427] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.54670075e-01   8.94833878e-02   3.03106666e-01   2.26794809e-01
   2.25945085e-01   5.16257211e-16   6.72874397e-16   7.78074566e-16
   2.49843829e-16], sum to 1.0000
[2017-11-01 09:49:47,501] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.95, 73.33333333333333, 4.808333333333333, 270.0, 0.0, 0.0, -0.9000000000000004, 20.01451648877111, 16.0, 20.64592717540243, 21.5, 0.0, 18.85221490999857], 
actual action is [-0.9500000000000002, 15.0], 
sim time next is 2241600.0000, 
raw observation next is [-6.0, 73.66666666666667, 4.766666666666667, 270.0, 0.0, 0.0, -0.9500000000000002, 20.57395520582668, 15.0, 20.58270430636984, 21.5, 0.0, 17.88123300877248], 
processed observation next is [0.5, 0.9565217391304348, 0.1794871794871795, 0.7366666666666667, 0.43333333333333335, 0.75, 0.0, 0.0, 0.4841666666666667, 0.20573955205826683, 0.25, 0.5291352153184921, 0.575, 0.0, 0.21036744716202918], 
reward next is -0.3345. 
=============================================
[2017-11-01 09:49:49,725] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.70126671e-01   6.48912638e-02   1.45247355e-01   2.94331431e-01
   2.25403309e-01   3.39021111e-19   3.91152800e-19   3.12292269e-19
   3.72648769e-19], sum to 1.0000
[2017-11-01 09:49:49,789] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 68.25, 6.058333333333333, 278.3333333333333, 0.0, 0.0, 0.5, 8.54592831006986, 15.0, 23.50672463842756, 22.7, 1.0, 47.75487266487272], 
actual action is [0.5, 14.5], 
sim time next is 2224800.0000, 
raw observation next is [-4.5, 68.0, 6.1, 280.0, 0.0, 0.0, 0.5, 8.666489855711529, 14.5, 23.33034997878184, 22.7, 1.0, 29.49675913049791], 
processed observation next is [0.5, 0.782608695652174, 0.21794871794871795, 0.68, 0.5545454545454546, 0.7777777777777778, 0.0, 0.0, 0.5083333333333333, 0.08666489855711529, 0.225, 0.666517498939092, 0.635, 1.0, 0.3470206956529166], 
reward next is -0.2168. 
=============================================
[2017-11-01 09:49:50,779] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7500, global step 119825: loss -28.0028
[2017-11-01 09:49:51,582] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119932: loss -42.0864
[2017-11-01 09:49:52,148] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120007: loss 27.3911
[2017-11-01 09:49:52,533] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120061: loss -56.4666
[2017-11-01 09:49:54,877] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120366: loss -68.3634
[2017-11-01 09:49:55,074] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120401: loss -1.4414
[2017-11-01 09:49:56,334] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7500, global step 120551: loss -1.2980
[2017-11-01 09:49:56,815] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.99629837e-01   5.37715182e-02   7.64224082e-02   2.61421561e-01
   3.08754563e-01   4.09339174e-24   6.15429244e-24   2.89398139e-24
   1.21997434e-23], sum to 1.0000
[2017-11-01 09:49:56,918] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.7, 77.25, 5.6, 262.5, 0.0, 0.0, -1.700000000000001, 19.00648956630671, 27.5, 20.58826109853726, 21.5, 0.0, 48.18164870640971], 
actual action is [-1.7000000000000002, 27.0], 
sim time next is 2247600.0000, 
raw observation next is [-6.700000000000001, 77.0, 5.433333333333334, 263.3333333333334, 0.0, 0.0, -1.7, 18.4488149001429, 27.0, 20.70567737518863, 21.5, 0.0, 47.84427019120771], 
processed observation next is [0.6666666666666666, 0.0, 0.16153846153846152, 0.77, 0.49393939393939396, 0.7314814814814817, 0.0, 0.0, 0.4716666666666667, 0.18448814900142899, 0.85, 0.5352838687594315, 0.575, 0.0, 0.5628737669553848], 
reward next is -0.4800. 
=============================================
[2017-11-01 09:49:57,775] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120706: loss 15.5324
[2017-11-01 09:49:57,800] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120707: loss -2.3834
[2017-11-01 09:49:58,302] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120753: loss 2.8430
[2017-11-01 09:49:59,578] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7500, global step 120897: loss 44.5596
[2017-11-01 09:49:59,878] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7500, global step 120929: loss 96.5969
[2017-11-01 09:50:07,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.75783828e-01   1.23913608e-01   4.18070078e-01   1.32526726e-01
   1.49705723e-01   4.80901000e-28   6.49536822e-28   1.38661583e-27
   2.18545093e-27], sum to 1.0000
[2017-11-01 09:50:07,465] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-9.25, 91.0, 2.416666666666667, 244.1666666666667, 0.0, 0.0, -4.199999999999999, 31.86120895963408, 19.5, 18.84864387309494, 21.5, 0.0, 31.86755427996183], 
actual action is [-4.25, 14.5], 
sim time next is 2270400.0000, 
raw observation next is [-9.3, 91.0, 2.333333333333333, 243.3333333333333, 0.0, 0.0, -4.25, 32.23604902934472, 14.5, 18.86058571054617, 21.5, 0.0, 30.26366450659239], 
processed observation next is [0.6666666666666666, 0.2608695652173913, 0.09487179487179485, 0.91, 0.2121212121212121, 0.6759259259259258, 0.0, 0.0, 0.42916666666666664, 0.3223604902934472, 0.225, 0.4430292855273086, 0.575, 0.0, 0.35604311184226345], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:50:24,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.98191807e-01   1.37690440e-01   3.18979353e-01   1.03778891e-01
   2.41359442e-01   3.78715829e-19   8.75770546e-19   5.42038582e-19
   8.05174196e-19], sum to 1.0000
[2017-11-01 09:50:24,136] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-37.83698654]
 [-38.46599579]
 [-38.1868782 ]
 [-38.58145142]
 [-38.375     ]], R is [[-38.65552521]
 [-38.38907623]
 [-38.12600327]
 [-37.86635971]
 [-37.61024094]].
[2017-11-01 09:50:24,243] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.95, 66.0, 5.225, 70.0, 125.5, 382.5, 2.0, 13.07431474975578, 24.5, 22.05742134624575, 22.7, 1.0, 62.86879343823225], 
actual action is [2.05, 23.5], 
sim time next is 2368200.0000, 
raw observation next is [-2.9, 65.66666666666667, 5.183333333333333, 70.0, 127.0, 390.0, 2.05, 12.52422372980969, 23.5, 22.26936336175618, 22.7, 1.0, 61.81939009195113], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.25897435897435894, 0.6566666666666667, 0.47121212121212114, 0.19444444444444445, 0.335978835978836, 0.39, 0.5341666666666666, 0.1252422372980969, 0.675, 0.613468168087809, 0.635, 1.0, 0.7272869422582485], 
reward next is -0.4263. 
=============================================
[2017-11-01 09:50:28,620] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.10589750e-01   1.04947403e-01   4.76641655e-01   1.20183334e-01
   1.87637880e-01   5.99742082e-19   3.33552181e-19   2.20477987e-19
   2.97810405e-19], sum to 1.0000
[2017-11-01 09:50:28,866] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 53.5, 2.0, 242.5, 0.0, 0.0, 3.8, 13.22428644760352, 23.0, 21.63391008717699, 22.7, 1.0, 62.6178573062551], 
actual action is [3.8, 22.0], 
sim time next is 2314200.0000, 
raw observation next is [-1.2, 53.66666666666666, 2.0, 245.0, 0.0, 0.0, 3.8, 12.58110280880436, 22.0, 21.96276665714874, 22.7, 1.0, 49.90195026242112], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3025641025641026, 0.5366666666666666, 0.18181818181818182, 0.6805555555555556, 0.0, 0.0, 0.5633333333333332, 0.1258110280880436, 0.6, 0.598138332857437, 0.635, 1.0, 0.5870817677931897], 
reward next is -0.3564. 
=============================================
[2017-11-01 09:50:40,178] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 125677: loss -2.6528
[2017-11-01 09:50:41,661] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  4.19671349e-02   9.53539759e-02   4.16099191e-01   2.87397861e-01
   1.59181848e-01   2.84379686e-20   3.08832567e-20   2.57866076e-20
   1.18644415e-19], sum to 1.0000
[2017-11-01 09:50:41,958] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.4, 69.0, 5.6, 62.5, 28.25, 0.0, 1.6, 20.24899277951654, 22.5, 20.42438145798016, 22.7, 1.0, 65.44901060083626], 
actual action is [1.6, 22.0], 
sim time next is 2362800.0000, 
raw observation next is [-3.4, 69.0, 5.6, 63.33333333333334, 31.16666666666667, 0.0, 1.6, 19.46672682808804, 22.0, 20.75523853818558, 22.7, 1.0, 64.6866603374114], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.24615384615384614, 0.69, 0.509090909090909, 0.17592592592592596, 0.0824514991181658, 0.0, 0.5266666666666667, 0.19466726828088038, 0.6, 0.537761926909279, 0.635, 1.0, 0.7610195333813106], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:50:45,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.07319526
  0.08504283  0.21796121  0.62380064], sum to 1.0000
[2017-11-01 09:50:45,705] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.625, 43.25, 5.1, 67.5, 0.0, 0.0, 0.416666666666667, 27.86438608820494, 15.0, 20.41253850461536, 21.5, 0.0, 32.93979220981797], 
actual action is [0.375, 16.0], 
sim time next is 2413200.0000, 
raw observation next is [-4.666666666666667, 43.0, 5.1, 66.66666666666667, 0.0, 0.0, 0.375, 27.96777925365331, 16.0, 20.36499666774433, 21.5, 0.0, 22.03742694008307], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.21367521367521364, 0.43, 0.4636363636363636, 0.1851851851851852, 0.0, 0.0, 0.50625, 0.2796777925365331, 0.3, 0.5182498333872164, 0.575, 0.0, 0.25926384635391847], 
reward next is -0.4134. 
=============================================
[2017-11-01 09:50:48,341] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 126446: loss -73.9401
[2017-11-01 09:50:51,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 126732: loss 125.2929
[2017-11-01 09:51:01,929] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8000, global step 127640: loss -8.8693
[2017-11-01 09:51:03,816] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127881: loss 15.3530
[2017-11-01 09:51:04,097] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127911: loss 130.0797
[2017-11-01 09:51:06,458] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128164: loss -10.1187
[2017-11-01 09:51:06,794] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128203: loss -36.6447
[2017-11-01 09:51:06,918] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8000, global step 128214: loss -84.3714
[2017-11-01 09:51:07,669] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128322: loss 253.5258
[2017-11-01 09:51:08,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.41105996e-02   3.53410184e-01   2.01951697e-01   1.92315906e-01
   2.38211557e-01   6.16297065e-22   5.24643191e-22   9.57047969e-22
   4.47916484e-22], sum to 1.0000
[2017-11-01 09:51:08,596] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.65, 42.75, 5.725, 67.5, 0.0, 0.0, 2.433333333333334, 23.19152339035037, 12.5, 21.12268133717891, 21.5, 0.0, 20.4337043673068], 
actual action is [2.35, 11.5], 
sim time next is 2402400.0000, 
raw observation next is [-2.733333333333333, 42.66666666666667, 5.766666666666667, 66.66666666666667, 0.0, 0.0, 2.35, 23.68427391526015, 11.5, 21.08506756892972, 21.5, 0.0, 19.61088012510755], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.26324786324786326, 0.4266666666666667, 0.5242424242424243, 0.1851851851851852, 0.0, 0.0, 0.5391666666666667, 0.23684273915260148, 0.075, 0.554253378446486, 0.575, 0.0, 0.23071623676597117], 
reward next is -0.2191. 
=============================================
[2017-11-01 09:51:09,159] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128522: loss -61.1729
[2017-11-01 09:51:13,275] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8000, global step 128983: loss -9.3541
[2017-11-01 09:51:13,985] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8000, global step 129056: loss -91.8139
[2017-11-01 09:51:14,833] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8000, global step 129149: loss -2.1563
[2017-11-01 09:51:15,744] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 129256: loss -133.3337
[2017-11-01 09:51:16,531] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 129353: loss -1.3942
[2017-11-01 09:51:19,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.80279728e-13   3.73639256e-01   1.33730277e-01   4.58939433e-01
   3.36681567e-02   1.07769063e-06   2.66308075e-06   1.32667046e-05
   5.86590295e-06], sum to 1.0000
[2017-11-01 09:51:19,556] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-3.399999999999999, 42.0, 5.641666666666667, 69.16666666666666, 0.0, 0.0, 1.6, 30.86881742289484, 19.5, 20.09204580838427, 21.5, 0.0, 21.69589368985056], 
actual action is [1.600000000000001, 19.5], 
sim time next is 2408400.0000, 
raw observation next is [-3.4, 42.0, 5.6, 70.0, 0.0, 0.0, 1.600000000000001, 31.027682716387, 19.5, 20.11689321392339, 21.5, 0.0, 20.95154363403348], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.24615384615384614, 0.42, 0.509090909090909, 0.19444444444444445, 0.0, 0.0, 0.5266666666666667, 0.31027682716387, 0.475, 0.5058446606961695, 0.575, 0.0, 0.246488748635688], 
reward next is -0.4690. 
=============================================
[2017-11-01 09:51:22,774] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-65.39698029]
 [-63.63693237]
 [-62.55082321]
 [-62.40252686]
 [-62.39818573]], R is [[-64.56397247]
 [-64.35652924]
 [-64.1309967 ]
 [-63.88943481]
 [-63.63441849]].
[2017-11-01 09:51:35,435] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.10046381e-14   2.19947025e-01   4.01175886e-01   3.32911432e-01
   4.42642048e-02   1.97420115e-04   4.80092422e-05   3.75140924e-04
   1.08094432e-03], sum to 1.0000
[2017-11-01 09:51:35,477] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 27.33333333333334, 4.433333333333334, 70.0, 85.5, 824.0, 6.95, 27.44509516837606, 14.0, 20.84915883974951, 22.7, 1.0, 9.151895705323405], 
actual action is [7.0, 13.5], 
sim time next is 2468700.0000, 
raw observation next is [2.05, 27.25, 4.475, 70.0, 84.75, 820.0, 7.0, 27.60206469568452, 13.5, 20.82515130817317, 22.7, 1.0, 8.80452989308872], 
processed observation next is [1.0, 0.5652173913043478, 0.3858974358974359, 0.2725, 0.4068181818181818, 0.19444444444444445, 0.22420634920634921, 0.82, 0.6166666666666667, 0.2760206469568452, 0.175, 0.5412575654086584, 0.635, 1.0, 0.10358270462457317], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:51:44,750] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-83.31047821]
 [-83.05454254]
 [-85.08939362]
 [-83.39769745]
 [-83.45326233]], R is [[-84.46629333]
 [-84.62162781]
 [-84.77541351]
 [-84.92765808]
 [-85.0783844 ]].
[2017-11-01 09:51:47,445] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-82.25469971]
 [-83.41216278]
 [-83.99291229]
 [-83.60764313]
 [-82.82286835]], R is [[-84.9553299 ]
 [-85.10577393]
 [-85.25471497]
 [-85.40216827]
 [-85.54814911]].
[2017-11-01 09:51:48,149] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.73501261e-02   2.51419455e-01   2.36085832e-01   4.68796879e-01
   2.63478160e-02   1.54856865e-28   8.09663175e-29   7.26750194e-28
   2.14866302e-28], sum to 1.0000
[2017-11-01 09:51:48,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.283333333333333, 27.75, 3.725, 110.0, 0.0, 0.0, 6.466666666666667, 32.4068718651019, 20.5, 20.50666534840378, 22.7, 1.0, 8.075186072982975], 
actual action is [6.283333333333333, 20.0], 
sim time next is 2484000.0000, 
raw observation next is [1.1, 28.0, 3.6, 110.0, 0.0, 0.0, 6.283333333333333, 32.91721430373288, 20.0, 20.45267254327682, 22.7, 1.0, 8.128900378642095], 
processed observation next is [1.0, 0.782608695652174, 0.36153846153846153, 0.28, 0.32727272727272727, 0.3055555555555556, 0.0, 0.0, 0.6047222222222222, 0.3291721430373288, 0.5, 0.522633627163841, 0.635, 1.0, 0.09563412210167171], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:51:50,130] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 132859: loss -76.5154
[2017-11-01 09:51:59,449] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.05974296
  0.16497572  0.74466872  0.03061258], sum to 1.0000
[2017-11-01 09:51:59,497] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.8666666666666667, 31.66666666666667, 3.033333333333333, 116.6666666666667, 0.0, 0.0, 4.175, 29.43120889739972, 13.5, 20.84930828681443, 21.5, 0.0, 9.989705271087415], 
actual action is [4.133333333333333, 14.5], 
sim time next is 2492700.0000, 
raw observation next is [-0.9083333333333332, 32.33333333333333, 3.166666666666666, 108.3333333333333, 0.0, 0.0, 4.133333333333333, 29.95496089181627, 14.5, 20.78506177182282, 21.5, 0.0, 9.690431008408591], 
processed observation next is [1.0, 0.8695652173913043, 0.31004273504273505, 0.3233333333333333, 0.28787878787878785, 0.3009259259259258, 0.0, 0.0, 0.5688888888888889, 0.2995496089181627, 0.225, 0.5392530885911411, 0.575, 0.0, 0.1140050706871599], 
reward next is -0.2357. 
=============================================
[2017-11-01 09:52:03,666] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 134485: loss -84.6580
[2017-11-01 09:52:03,789] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 134501: loss -168.6832
[2017-11-01 09:52:13,598] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8500, global step 135570: loss -46.3417
[2017-11-01 09:52:14,049] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135613: loss 1.3377
[2017-11-01 09:52:18,098] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136072: loss 19.1954
[2017-11-01 09:52:18,464] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136120: loss -187.2205
[2017-11-01 09:52:18,878] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8500, global step 136175: loss 22.2922
[2017-11-01 09:52:19,192] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136213: loss 7.4726
[2017-11-01 09:52:19,450] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136250: loss -98.5717
[2017-11-01 09:52:23,707] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136679: loss -0.9363
[2017-11-01 09:52:26,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.15516081e-01   2.24046767e-01   2.76407659e-01   2.30053887e-01
   1.53975546e-01   8.01325583e-19   2.62127870e-18   2.39384994e-18
   1.87557434e-18], sum to 1.0000
[2017-11-01 09:52:26,864] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.04166666666666663, 35.41666666666666, 4.391666666666666, 151.6666666666667, 0.0, 0.0, 5.133333333333334, 13.31236749385107, 20.5, 21.85363229064797, 22.7, 1.0, 40.37160106840079], 
actual action is [5.041666666666667, 18.5], 
sim time next is 2572200.0000, 
raw observation next is [-0.04999999999999999, 35.5, 4.35, 180.0, 0.0, 0.0, 5.041666666666667, 13.11765053430822, 18.5, 22.04553312816637, 22.7, 1.0, 33.90886737430223], 
processed observation next is [0.0, 0.782608695652174, 0.33205128205128204, 0.355, 0.39545454545454545, 0.5, 0.0, 0.0, 0.5840277777777777, 0.1311765053430822, 0.425, 0.6022766564083184, 0.635, 1.0, 0.3989278514623792], 
reward next is -0.2651. 
=============================================
[2017-11-01 09:52:27,610] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8500, global step 137162: loss -12.8049
[2017-11-01 09:52:28,093] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 137225: loss -15.3895
[2017-11-01 09:52:28,505] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8500, global step 137293: loss -67.4474
[2017-11-01 09:52:30,853] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 137531: loss -89.3528
[2017-11-01 09:52:33,822] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8500, global step 137853: loss -2.9770
[2017-11-01 09:52:41,557] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-38.77906799]
 [-38.34125137]
 [-39.36301041]
 [-38.52457809]
 [-39.05364609]], R is [[-39.11697388]
 [-38.99220657]
 [-38.86966324]
 [-38.75024414]
 [-38.63549042]].
[2017-11-01 09:52:49,375] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.13292485e-01   5.61112389e-02   4.42468405e-01   2.54367530e-01
   1.33760318e-01   2.77271567e-21   1.84950250e-20   1.18320981e-20
   9.20079700e-21], sum to 1.0000
[2017-11-01 09:52:49,533] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.366666666666667, 81.33333333333334, 5.800000000000001, 246.6666666666667, 0.0, 0.0, -1.325, 19.34175578045941, 17.5, 20.59239049323204, 21.5, 0.0, 35.91037420539263], 
actual action is [-1.3666666666666671, 17.0], 
sim time next is 2611500.0000, 
raw observation next is [-6.408333333333333, 80.91666666666666, 5.975, 248.3333333333333, 0.0, 0.0, -1.366666666666667, 19.7195327417858, 17.0, 20.59794073034622, 21.5, 0.0, 34.60225638588744], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.16901709401709403, 0.8091666666666666, 0.5431818181818181, 0.6898148148148147, 0.0, 0.0, 0.4772222222222222, 0.19719532741785803, 0.35, 0.529897036517311, 0.575, 0.0, 0.40708536924573463], 
reward next is -0.4291. 
=============================================
[2017-11-01 09:53:00,976] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.88353053e-02   4.08923104e-02   2.30598554e-01   5.08104384e-01
   1.61569417e-01   1.95628525e-19   5.26637824e-19   5.15790177e-19
   6.95110216e-19], sum to 1.0000
[2017-11-01 09:53:01,001] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.833333333333333, 56.66666666666667, 8.033333333333333, 233.3333333333333, 227.5, 167.0, 2.033333333333334, 17.76791609139266, 18.0, 21.9928602395258, 22.7, 1.0, 9.14003975718444], 
actual action is [2.166666666666667, 13.0], 
sim time next is 2634300.0000, 
raw observation next is [-2.7, 56.0, 7.95, 232.5, 229.25, 165.0, 2.166666666666667, 17.94447219809051, 13.0, 21.96629519418579, 22.7, 1.0, 8.916222050160185], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.2641025641025641, 0.56, 0.7227272727272728, 0.6458333333333334, 0.6064814814814815, 0.165, 0.5361111111111111, 0.17944472198090508, 0.15, 0.5983147597092895, 0.635, 1.0, 0.10489673000188453], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:53:04,566] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 140904: loss 97.8371
[2017-11-01 09:53:15,473] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.83908565e-04   6.23848513e-02   3.48805308e-01   1.08729646e-01
   4.79796261e-01   5.56948619e-11   2.17837415e-10   2.58018162e-10
   1.88620397e-10], sum to 1.0000
[2017-11-01 09:53:15,482] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.5, 43.33333333333333, 7.783333333333333, 239.1666666666667, 194.3333333333333, 163.75, -4.5, 12.04904177836349, 10.0, 23.1611324271425, 22.7, 1.0, 0.0], 
actual action is [-4.5, 10.0], 
sim time next is 2643000.0000, 
raw observation next is [0.5, 43.66666666666667, 7.866666666666667, 238.3333333333333, 198.6666666666667, 157.0, -4.5, 12.21756283421524, 10.0, 23.15257037542541, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.34615384615384615, 0.4366666666666667, 0.7151515151515152, 0.6620370370370369, 0.525573192239859, 0.157, 0.425, 0.1221756283421524, 0.0, 0.6576285187712705, 0.635, 1.0, 0.0], 
reward next is -0.0611. 
=============================================
[2017-11-01 09:53:18,201] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 142463: loss 14.8650
[2017-11-01 09:53:18,489] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 142498: loss -57.5220
[2017-11-01 09:53:22,578] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   1.10229866e-28   3.44459161e-29   3.11829815e-29
   2.36930986e-29   1.35196969e-01   2.58618325e-01   1.81716561e-01
   4.24468070e-01], sum to 1.0000
[2017-11-01 09:53:22,688] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 70.75, 4.475000000000001, 0.0, 0.0, 0.0, -4.333333333333334, 25.02609215776432, 24.0, 19.90958444845448, 21.5, 0.0, 49.46850726208375], 
actual action is [-4.5, 24.5], 
sim time next is 2683200.0000, 
raw observation next is [-9.666666666666668, 71.33333333333334, 4.4, 0.0, 0.0, 0.0, -4.5, 24.18917772352876, 24.5, 20.05858471986654, 21.5, 0.0, 48.92677370728801], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.08547008547008544, 0.7133333333333334, 0.4, 0.0, 0.0, 0.0, 0.425, 0.24189177723528762, 0.725, 0.5029292359933271, 0.575, 0.0, 0.5756091024386825], 
reward next is -0.6482. 
=============================================
[2017-11-01 09:53:23,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.04587433e-02   1.84975982e-01   3.27259064e-01   1.34626940e-01
   2.62679309e-01   5.51629070e-19   4.85816564e-19   2.71903651e-19
   5.71524107e-19], sum to 1.0000
[2017-11-01 09:53:23,519] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-1.2, 62.25, 8.174999999999999, 240.0, 0.0, 0.0, 3.8, 16.02322233036993, 28.0, 21.02810457107737, 22.7, 1.0, 66.9282571499575], 
actual action is [3.8, 28.0], 
sim time next is 2663400.0000, 
raw observation next is [-1.2, 62.5, 8.35, 240.0, 0.0, 0.0, 3.8, 14.85735346953433, 28.0, 21.40861013151104, 22.7, 1.0, 65.51174666771783], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3025641025641026, 0.625, 0.759090909090909, 0.6666666666666666, 0.0, 0.0, 0.5633333333333332, 0.1485735346953433, 0.9, 0.5704305065755519, 0.635, 1.0, 0.7707264313849157], 
reward next is -0.4596. 
=============================================
[2017-11-01 09:53:23,701] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.15720101e-01   1.21566363e-01   1.79176122e-01   1.16201386e-01
   4.67335969e-01   6.33166814e-21   8.23766392e-21   4.29679090e-21
   9.46645849e-21], sum to 1.0000
[2017-11-01 09:53:23,790] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.833333333333333, 71.75, 5.675, 270.0, 0.0, 0.0, -1.666666666666667, 19.65357299319529, 16.0, 21.26721601852705, 21.5, 0.0, 30.07564237983467], 
actual action is [-1.833333333333333, 16.0], 
sim time next is 2678400.0000, 
raw observation next is [-7.0, 72.0, 5.6, 270.0, 0.0, 0.0, -1.833333333333333, 20.36191884991518, 16.0, 21.20597703108878, 21.5, 0.0, 28.7104061656426], 
processed observation next is [0.3333333333333333, 0.0, 0.15384615384615385, 0.72, 0.509090909090909, 0.75, 0.0, 0.0, 0.46944444444444444, 0.2036191884991518, 0.3, 0.5602988515544389, 0.575, 0.0, 0.33776948430167764], 
reward next is -0.2424. 
=============================================
[2017-11-01 09:53:26,085] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9000, global step 143347: loss -2.4395
[2017-11-01 09:53:28,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.86903866e-02   1.94691852e-01   2.75314659e-01   2.44101435e-01
   2.57201672e-01   3.54112811e-17   1.86843656e-17   2.18229138e-17
   2.92166611e-17], sum to 1.0000
[2017-11-01 09:53:28,537] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.666666666666667, 52.66666666666667, 1.0, 226.6666666666667, 0.0, 0.0, 1.416666666666667, 11.35516271047448, 22.0, 22.99721631127526, 22.7, 1.0, 55.71354469162522], 
actual action is [1.333333333333333, 21.5], 
sim time next is 2742300.0000, 
raw observation next is [-3.75, 53.0, 1.125, 255.0, 0.0, 0.0, 1.333333333333333, 11.52202004604729, 21.5, 22.96192079096486, 22.7, 1.0, 45.75820269692676], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.23717948717948717, 0.53, 0.10227272727272728, 0.7083333333333334, 0.0, 0.0, 0.5222222222222223, 0.1152202004604729, 0.575, 0.648096039548243, 0.635, 1.0, 0.5383317964344324], 
reward next is -0.3268. 
=============================================
[2017-11-01 09:53:29,097] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9000, global step 143648: loss 466.8383
[2017-11-01 09:53:29,784] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143719: loss -132.5395
[2017-11-01 09:53:30,233] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143756: loss -140.0599
[2017-11-01 09:53:30,863] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143831: loss -141.7241
[2017-11-01 09:53:31,612] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.18576528e-02   1.02194607e-01   3.64140362e-01   3.27191204e-01
   1.84616223e-01   2.19847255e-20   1.24423199e-20   1.96301511e-20
   3.67478897e-20], sum to 1.0000
[2017-11-01 09:53:31,726] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.258333333333333, 69.0, 7.233333333333333, 260.8333333333333, 0.0, 0.0, 1.9, 15.947308967879, 26.0, 21.33857977446874, 21.5, 0.0, 48.06367100353949], 
actual action is [1.7416666666666671, 25.0], 
sim time next is 2671800.0000, 
raw observation next is [-3.416666666666667, 69.0, 7.166666666666666, 261.6666666666667, 0.0, 0.0, 1.741666666666667, 15.61990768759648, 25.0, 21.45645097091904, 21.5, 0.0, 47.72546055168539], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.2457264957264957, 0.69, 0.6515151515151515, 0.7268518518518519, 0.0, 0.0, 0.5290277777777778, 0.1561990768759648, 0.75, 0.5728225485459519, 0.575, 0.0, 0.5614760064904163], 
reward next is -0.2916. 
=============================================
[2017-11-01 09:53:34,429] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144136: loss 29.8831
[2017-11-01 09:53:35,100] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144206: loss -7.1223
[2017-11-01 09:53:36,900] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144367: loss -23.5510
[2017-11-01 09:53:37,537] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9000, global step 144423: loss 51.3343
[2017-11-01 09:53:40,094] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9000, global step 144648: loss -231.7449
[2017-11-01 09:53:40,738] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144712: loss -324.0369
[2017-11-01 09:53:41,167] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-70.93810272]
 [-71.2109375 ]
 [-73.07215881]
 [-73.24137878]
 [-75.77639771]], R is [[-72.47229767]
 [-72.74757385]
 [-73.02009583]
 [-73.2898941 ]
 [-73.55699921]].
[2017-11-01 09:53:45,141] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9000, global step 145028: loss -57.9021
[2017-11-01 09:53:48,169] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 145294: loss 23.9220
[2017-11-01 09:54:02,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.96019616e-13   2.38640346e-02   2.41688475e-01   1.56881422e-01
   1.16016500e-01   8.61714259e-02   3.34938504e-02   5.02633490e-02
   2.91620940e-01], sum to 1.0000
[2017-11-01 09:54:02,230] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.0, 59.0, 1.5, 30.0, 0.0, 0.0, 0.08333333333333393, 26.65874375662784, 16.0, 20.39574088971031, 22.7, 1.0, 18.11680355068547], 
actual action is [0.0, 21.0], 
sim time next is 2747100.0000, 
raw observation next is [-5.0, 58.99999999999999, 1.5, 32.5, 0.0, 0.0, 0.0, 27.7687835561431, 21.0, 20.27913733208468, 22.7, 1.0, 17.34901756126208], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.20512820512820512, 0.59, 0.13636363636363635, 0.09027777777777778, 0.0, 0.0, 0.5, 0.277687835561431, 0.55, 0.513956866604234, 0.635, 1.0, 0.20410608895602447], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:54:16,249] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.33683482e-01   2.97584236e-01   2.19706282e-01   1.04538433e-01
   1.44487590e-01   5.03708946e-18   4.41102664e-18   2.56375883e-18
   6.32409894e-18], sum to 1.0000
[2017-11-01 09:54:16,365] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-5.75, 62.75, 1.5, 60.0, 0.0, 0.0, -0.666666666666667, 14.99114915591525, 26.0, 21.9696835935145, 21.5, 0.0, 44.86432718023175], 
actual action is [-0.75, 26.0], 
sim time next is 2753400.0000, 
raw observation next is [-5.833333333333333, 63.16666666666666, 1.5, 60.0, 0.0, 0.0, -0.75, 14.70394403623525, 26.0, 22.01743821904729, 21.5, 0.0, 44.50269742356988], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.18376068376068377, 0.6316666666666666, 0.13636363636363635, 0.16666666666666666, 0.0, 0.0, 0.4875, 0.1470394403623525, 0.8, 0.6008719109523645, 0.575, 0.0, 0.5235611461596457], 
reward next is -0.2618. 
=============================================
[2017-11-01 09:54:25,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.95579597e-33   5.03458808e-15   1.70043230e-15   4.92021364e-15
   1.94112508e-15   2.59565890e-01   2.97403097e-01   2.64225334e-01
   1.78805634e-01], sum to 1.0000
[2017-11-01 09:54:25,290] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 64.0, 2.641666666666667, 60.0, 0.0, 0.0, -2.0, 21.12547074469105, 13.5, 20.68465967598812, 21.5, 0.0, 26.30617939469457], 
actual action is [-2.0, 14.0], 
sim time next is 2786400.0000, 
raw observation next is [-7.0, 64.0, 2.6, 60.0, 0.0, 0.0, -2.0, 21.99956603009659, 14.0, 20.57481817753133, 21.5, 0.0, 25.14581693379462], 
processed observation next is [0.5, 0.2608695652173913, 0.15384615384615385, 0.64, 0.23636363636363636, 0.16666666666666666, 0.0, 0.0, 0.4666666666666667, 0.21999566030096593, 0.2, 0.5287409088765666, 0.575, 0.0, 0.2958331403975838], 
reward next is -0.3792. 
=============================================
[2017-11-01 09:54:31,547] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 149322: loss -14.1894
[2017-11-01 09:54:38,797] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.88632980e-01   1.59812495e-01   1.02329746e-01   2.64267385e-01
   2.84957439e-01   3.03194319e-17   2.33369885e-17   3.16535121e-17
   2.93444837e-17], sum to 1.0000
[2017-11-01 09:54:39,030] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.333333333333334, 64.0, 1.7, 50.0, 18.0, 34.49999999999999, -1.416666666666666, 23.71360278654567, 27.0, 20.25722875016217, 22.7, 1.0, 79.60368367194742], 
actual action is [-1.333333333333334, 26.5], 
sim time next is 2792700.0000, 
raw observation next is [-6.25, 64.0, 1.65, 50.0, 27.0, 51.75, -1.333333333333334, 23.22666199041671, 26.5, 20.37260123590858, 22.7, 1.0, 79.46554863153479], 
processed observation next is [0.5, 0.30434782608695654, 0.17307692307692307, 0.64, 0.15, 0.1388888888888889, 0.07142857142857142, 0.05175, 0.47777777777777775, 0.23226661990416708, 0.825, 0.5186300617954289, 0.635, 1.0, 0.9348888074298211], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:54:39,538] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 150158: loss -48.2099
[2017-11-01 09:54:40,730] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 150278: loss 19.1002
[2017-11-01 09:54:41,102] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.52553532e-22   5.97025458e-23   2.11683289e-22
   1.52721212e-22   2.66035289e-01   1.60078436e-01   2.93693423e-01
   2.80192912e-01], sum to 1.0000
[2017-11-01 09:54:41,161] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [6.35, 26.25, 4.391666666666666, 125.8333333333333, 73.0, 69.66666666666666, 11.4, 12.05690880011688, 17.0, 22.94568605387793, 22.7, 1.0, 9.504947153355085], 
actual action is [11.35, 18.0], 
sim time next is 2824200.0000, 
raw observation next is [6.3, 26.5, 4.35, 125.0, 71.0, 76.0, 11.35, 12.05113654480646, 18.0, 22.93716257200759, 22.7, 1.0, 8.23232705685494], 
processed observation next is [0.5, 0.6956521739130435, 0.4948717948717949, 0.265, 0.39545454545454545, 0.3472222222222222, 0.18783068783068782, 0.076, 0.6891666666666667, 0.1205113654480646, 0.4, 0.6468581286003795, 0.635, 1.0, 0.09685090655123459], 
reward next is -0.1087. 
=============================================
[2017-11-01 09:54:41,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.03096484e-25   4.66075234e-11   1.38771633e-11   3.67819282e-11
   3.63356567e-11   2.61611462e-01   1.99564785e-01   2.51788974e-01
   2.87034750e-01], sum to 1.0000
[2017-11-01 09:54:41,735] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [6.083333333333333, 29.5, 4.183333333333333, 112.5, 172.5833333333333, 72.08333333333333, 11.0, 16.58754987369088, 22.0, 21.88087149411102, 22.7, 1.0, 13.21593855020669], 
actual action is [11.083333333333332, 22.5], 
sim time next is 2815800.0000, 
raw observation next is [6.166666666666666, 29.0, 4.266666666666667, 115.0, 161.6666666666667, 57.66666666666666, 11.08333333333333, 16.15902738327275, 22.5, 21.94627217660777, 22.7, 1.0, 25.79197384637521], 
processed observation next is [0.5, 0.6086956521739131, 0.4914529914529914, 0.29, 0.3878787878787879, 0.3194444444444444, 0.42768959435626114, 0.05766666666666666, 0.6847222222222221, 0.1615902738327275, 0.625, 0.5973136088303885, 0.635, 1.0, 0.30343498642794364], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:54:45,868] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.24907771e-01   1.93003014e-01   7.70059451e-02   1.36709347e-01
   3.68373960e-01   1.77963528e-16   3.34852188e-16   1.70556675e-16
   2.47417450e-16], sum to 1.0000
[2017-11-01 09:54:45,941] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.333333333333333, 35.83333333333334, 4.266666666666667, 121.6666666666667, 0.0, 0.0, 8.5, 11.97280717829019, 23.0, 22.71575478818944, 22.7, 1.0, 39.66480335164368], 
actual action is [8.333333333333332, 18.0], 
sim time next is 2832900.0000, 
raw observation next is [3.166666666666667, 36.41666666666666, 4.183333333333333, 120.8333333333333, 0.0, 0.0, 8.333333333333332, 12.39953408106647, 18.0, 22.64918284263857, 22.7, 1.0, 36.88476564629803], 
processed observation next is [0.5, 0.782608695652174, 0.41452991452991456, 0.3641666666666666, 0.38030303030303025, 0.33564814814814803, 0.0, 0.0, 0.6388888888888888, 0.1239953408106647, 0.4, 0.6324591421319286, 0.635, 1.0, 0.4339384193682121], 
reward next is -0.2790. 
=============================================
[2017-11-01 09:54:50,956] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9500, global step 151231: loss 12.6311
[2017-11-01 09:54:55,291] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9500, global step 151619: loss 11.0686
[2017-11-01 09:54:56,419] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151720: loss 52.7757
[2017-11-01 09:54:58,156] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151906: loss -6.2938
[2017-11-01 09:54:58,660] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151954: loss 16.4175
[2017-11-01 09:55:01,293] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152234: loss -4.3439
[2017-11-01 09:55:01,819] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152288: loss -24.9951
[2017-11-01 09:55:03,118] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152417: loss 0.4158
[2017-11-01 09:55:06,209] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9500, global step 152754: loss -17.7703
[2017-11-01 09:55:08,397] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   8.29071840e-30   4.25521131e-30   1.93336449e-29
   3.11755264e-30   2.06711784e-01   1.86788425e-01   3.33718836e-01
   2.72780985e-01], sum to 1.0000
[2017-11-01 09:55:08,515] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [2.0, 50.0, 4.266666666666667, 130.0, 0.0, 0.0, 7.0, 6.306459021366416, 18.0, 24.46073120670698, 21.5, 0.0, 27.15370226967294], 
actual action is [7.0, 23.0], 
sim time next is 2845500.0000, 
raw observation next is [2.0, 51.5, 4.183333333333333, 132.5, 0.0, 0.0, 7.0, 6.369908666463266, 23.0, 24.38868359118063, 21.5, 0.0, 25.8807132005784], 
processed observation next is [0.5, 0.9565217391304348, 0.38461538461538464, 0.515, 0.38030303030303025, 0.3680555555555556, 0.0, 0.0, 0.6166666666666667, 0.06369908666463266, 0.65, 0.7194341795590316, 0.575, 0.0, 0.3044789788303341], 
reward next is -0.1522. 
=============================================
[2017-11-01 09:55:10,317] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 153205: loss 2.6074
[2017-11-01 09:55:12,042] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9500, global step 153417: loss -14.1019
[2017-11-01 09:55:14,838] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9500, global step 153699: loss -22.6792
[2017-11-01 09:55:14,851] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.68926415e-12   2.25119620e-05   2.80490949e-05   1.50103924e-05
   1.57139621e-05   2.57829845e-01   3.41944486e-01   2.63011366e-01
   1.37133121e-01], sum to 1.0000
[2017-11-01 09:55:14,922] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.0, 76.66666666666667, 7.033333333333333, 130.0, 0.0, 0.0, 6.0, 5.636381266909373, 28.0, 24.24753969741884, 21.5, 0.0, 56.73801260775318], 
actual action is [6.0, 30], 
sim time next is 2857500.0000, 
raw observation next is [1.0, 77.25, 6.95, 130.0, 0.0, 0.0, 6.0, 5.628572100589663, 30.0, 24.21703055764293, 21.5, 0.0, 56.8090355919883], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.358974358974359, 0.7725, 0.6318181818181818, 0.3611111111111111, 0.0, 0.0, 0.6, 0.05628572100589663, 1.0, 0.7108515278821465, 0.575, 0.0, 0.6683415951998624], 
reward next is -0.3342. 
=============================================
[2017-11-01 09:55:15,458] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 153763: loss -0.2067
[2017-11-01 09:55:24,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-20.67990303]
 [-20.62168503]
 [-20.2740612 ]
 [-20.41340065]
 [-20.13199615]], R is [[-20.56672287]
 [-20.64372635]
 [-20.72950554]
 [-20.82930374]
 [-20.93318748]].
[2017-11-01 09:55:29,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.37097928
  0.0998599   0.1618316   0.36732921], sum to 1.0000
[2017-11-01 09:55:29,100] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 79.75, 7.45, 260.0, 0.0, 0.0, -6.0, 22.03843499875459, 10.0, 20.07700010396476, 21.5, 0.0, 0.0], 
actual action is [4.0, 10.5], 
sim time next is 2924400.0000, 
raw observation next is [-1.0, 80.33333333333334, 7.366666666666667, 260.0, 0.0, 0.0, 4.0, 22.17398280352808, 10.5, 20.04843105752948, 21.5, 0.0, 6.511059459763461], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.3076923076923077, 0.8033333333333335, 0.6696969696969698, 0.7222222222222222, 0.0, 0.0, 0.5666666666666667, 0.2217398280352808, 0.025, 0.502421552876474, 0.575, 0.0, 0.07660069952662894], 
reward next is -0.4012. 
=============================================
[2017-11-01 09:55:35,926] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 157331: loss 19.5874
[2017-11-01 09:55:36,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.32908800e-01   3.37034166e-01   1.28095627e-01   6.74049035e-02
   2.34556511e-01   9.54484290e-20   1.80197535e-19   4.10055305e-20
   1.52414477e-19], sum to 1.0000
[2017-11-01 09:55:36,229] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 84.33333333333334, 5.133333333333333, 273.3333333333333, 0.0, 0.0, 2.416666666666667, 14.54627762332794, 22.0, 21.05525233073052, 21.5, 0.0, 46.84269842870079], 
actual action is [2.333333333333333, 17.0], 
sim time next is 2947500.0000, 
raw observation next is [-2.75, 84.25, 5.0, 275.0, 0.0, 0.0, 2.333333333333333, 14.28675104453854, 17.0, 21.17095301276154, 21.5, 0.0, 40.82756072606718], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.26282051282051283, 0.8425, 0.45454545454545453, 0.7638888888888888, 0.0, 0.0, 0.538888888888889, 0.1428675104453854, 0.35, 0.558547650638077, 0.575, 0.0, 0.4803242438360845], 
reward next is -0.3224. 
=============================================
[2017-11-01 09:55:38,567] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  6.23639059e-33   3.97998997e-16   2.08944949e-16   2.52682634e-16
   2.48993011e-16   2.21468240e-01   2.48434171e-01   2.18167827e-01
   3.11929762e-01], sum to 1.0000
[2017-11-01 09:55:38,639] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 84.0, 5.300000000000001, 280.0, 0.0, 0.0, 2.0, 15.5072816276688, 14.5, 21.23336322504125, 21.5, 0.0, 27.64702131838], 
actual action is [2.0, 16.5], 
sim time next is 2949900.0000, 
raw observation next is [-3.0, 84.0, 5.475, 280.0, 0.0, 0.0, 2.0, 16.06046039413094, 16.5, 21.17072451536183, 21.5, 0.0, 26.50178350084122], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.4977272727272727, 0.7777777777777778, 0.0, 0.0, 0.5333333333333333, 0.16060460394130938, 0.325, 0.5585362257680915, 0.575, 0.0, 0.3117856882451908], 
reward next is -0.2382. 
=============================================
[2017-11-01 09:55:39,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   5.29212869e-20   2.09065861e-20   2.72748170e-20
   2.15110693e-20   1.79830134e-01   1.75546497e-01   2.14180142e-01
   4.30443257e-01], sum to 1.0000
[2017-11-01 09:55:39,886] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.083333333333333, 83.41666666666667, 4.6, 289.1666666666666, 0.0, 0.0, 2.0, 18.90805328073208, 15.5, 20.83659201741292, 21.5, 0.0, 23.29104385163821], 
actual action is [1.916666666666667, 16.0], 
sim time next is 2956200.0000, 
raw observation next is [-3.166666666666667, 82.83333333333333, 4.6, 288.3333333333334, 0.0, 0.0, 1.916666666666667, 19.58589888587746, 16.0, 20.74449551632556, 21.5, 0.0, 22.29615948939293], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.25213675213675213, 0.8283333333333333, 0.41818181818181815, 0.8009259259259262, 0.0, 0.0, 0.5319444444444444, 0.1958589888587746, 0.3, 0.537224775816278, 0.575, 0.0, 0.26230775869874035], 
reward next is -0.3200. 
=============================================
[2017-11-01 09:55:40,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.16290045
  0.13824338  0.24794668  0.45090953], sum to 1.0000
[2017-11-01 09:55:40,341] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 85.00000000000001, 7.2, 266.6666666666667, 0.0, 0.0, 3.0, 19.29693947994458, 20.0, 20.74328347636217, 21.5, 0.0, 39.40411323481124], 
actual action is [3.0, 25.0], 
sim time next is 2938500.0000, 
raw observation next is [-2.0, 85.0, 7.2, 265.0, 0.0, 0.0, 3.0, 18.62503407667445, 25.0, 20.71925052497349, 21.5, 0.0, 41.62213800867881], 
processed observation next is [0.8333333333333334, 0.0, 0.28205128205128205, 0.85, 0.6545454545454545, 0.7361111111111112, 0.0, 0.0, 0.55, 0.1862503407667445, 0.75, 0.5359625262486745, 0.575, 0.0, 0.48967221186680954], 
reward next is -0.4400. 
=============================================
[2017-11-01 09:55:43,473] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 158322: loss -40.7300
[2017-11-01 09:55:45,233] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 158542: loss 36.2067
[2017-11-01 09:55:47,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.07995144
  0.41644278  0.03455711  0.46904871], sum to 1.0000
[2017-11-01 09:55:47,571] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 65.0, 3.95, 261.6666666666667, 157.3333333333333, 727.3333333333334, 2.0, 17.44397977679613, 23.5, 21.53164425217106, 22.7, 1.0, 44.19705859886504], 
actual action is [2.0, 28.5], 
sim time next is 2984100.0000, 
raw observation next is [-3.0, 65.0, 3.775, 260.8333333333333, 151.4166666666667, 736.4166666666667, 2.0, 15.41624193771392, 28.5, 21.53551664187376, 22.7, 1.0, 77.76382935471628], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.2564102564102564, 0.65, 0.3431818181818182, 0.724537037037037, 0.40057319223985904, 0.7364166666666667, 0.5333333333333333, 0.1541624193771392, 0.925, 0.576775832093688, 0.635, 1.0, 0.9148685806437209], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:54,704] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10000, global step 159512: loss -1.6471
[2017-11-01 09:55:55,176] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159569: loss 51.8029
[2017-11-01 09:55:55,894] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.50338271e-23   7.69527386e-10   4.08082207e-10   1.73845452e-10
   2.97086938e-10   2.36172825e-01   2.86072373e-01   8.57844800e-02
   3.91970366e-01], sum to 1.0000
[2017-11-01 09:55:56,013] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.0, 60.0, 2.1, 240.0, 0.0, 0.0, 3.0, 16.53928659464302, 16.0, 22.10208772092316, 22.7, 1.0, 18.59222980887923], 
actual action is [3.0, 17.0], 
sim time next is 3003600.0000, 
raw observation next is [-2.0, 60.00000000000001, 2.1, 240.0, 0.0, 0.0, 3.0, 16.91236295043189, 17.0, 22.03107748659403, 22.7, 1.0, 15.01044002094991], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.28205128205128205, 0.6000000000000001, 0.19090909090909092, 0.6666666666666666, 0.0, 0.0, 0.55, 0.16912362950431892, 0.35, 0.6015538743297014, 0.635, 1.0, 0.1765934120111754], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:56,440] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10000, global step 159734: loss -111.0397
[2017-11-01 09:55:57,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159806: loss -117.5088
[2017-11-01 09:56:01,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   8.96396205e-27   5.02066055e-27   4.52486648e-27
   1.40439303e-27   1.96618974e-01   4.06203270e-01   1.19069979e-01
   2.78107703e-01], sum to 1.0000
[2017-11-01 09:56:01,598] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.0, 65.0, 6.158333333333333, 279.1666666666666, 223.5, 175.6666666666667, 2.0, 15.59289603555702, 15.0, 21.15661508720472, 22.7, 1.0, 36.80333563510569], 
actual action is [2.0, 16.0], 
sim time next is 2977800.0000, 
raw observation next is [-3.0, 65.0, 6.116666666666667, 278.3333333333334, 230.0, 197.3333333333333, 2.0, 15.44586709347504, 16.0, 21.29508471015238, 22.7, 1.0, 34.19566021577764], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.2564102564102564, 0.65, 0.5560606060606061, 0.7731481481481484, 0.6084656084656085, 0.19733333333333328, 0.5333333333333333, 0.1544586709347504, 0.3, 0.564754235507619, 0.635, 1.0, 0.4023018848915017], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:56:01,958] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160324: loss -150.5242
[2017-11-01 09:56:02,665] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160406: loss -44.5366
[2017-11-01 09:56:02,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160412: loss 30.3148
[2017-11-01 09:56:03,358] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10000, global step 160496: loss -153.2592
[2017-11-01 09:56:03,641] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160530: loss -57.8282
[2017-11-01 09:56:10,693] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 161324: loss -170.7647
[2017-11-01 09:56:11,533] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 161393: loss -64.8241
[2017-11-01 09:56:12,536] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10000, global step 161479: loss -38.0755
[2017-11-01 09:56:13,070] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10000, global step 161533: loss 19.4427
[2017-11-01 09:56:16,333] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-31.71032715]
 [-29.95318031]
 [-29.4986763 ]
 [-30.7828331 ]
 [-30.15166473]], R is [[-30.75465584]
 [-30.69946289]
 [-30.64469528]
 [-30.59059143]
 [-30.53741264]].
[2017-11-01 09:56:19,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.19883552e-01   2.38664433e-01   1.77810162e-01   1.99052870e-01
   2.64588922e-01   2.38542020e-12   6.09370800e-12   2.38363756e-12
   1.84055549e-12], sum to 1.0000
[2017-11-01 09:56:19,429] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.583333333333333, 46.66666666666666, 3.725, 74.16666666666666, 109.4166666666667, 806.9166666666666, 3.333333333333333, 11.50956113223663, 13.5, 22.85468946627426, 22.7, 1.0, 26.56150612660862], 
actual action is [-6.583333333333333, 10], 
sim time next is 3072600.0000, 
raw observation next is [-1.5, 46.0, 3.85, 75.0, 109.0, 806.0, -6.583333333333333, 12.36156249022605, 10.0, 22.8279639645086, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.2948717948717949, 0.46, 0.35000000000000003, 0.20833333333333334, 0.28835978835978837, 0.806, 0.3902777777777778, 0.1236156249022605, 0.0, 0.6413981982254301, 0.635, 1.0, 0.0], 
reward next is -0.0618. 
=============================================
[2017-11-01 09:56:32,108] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-42.19915009]
 [-41.22653961]
 [-42.27959442]
 [-40.21107483]
 [-41.77173615]], R is [[-41.7520752 ]
 [-42.33455658]
 [-42.91121292]
 [-43.48210144]
 [-44.04727936]].
[2017-11-01 09:56:34,973] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.15418498
  0.32123145  0.21768798  0.30689558], sum to 1.0000
[2017-11-01 09:56:35,079] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.833333333333333, 54.16666666666666, 2.683333333333334, 58.33333333333334, 109.3333333333333, 789.6666666666667, 1.083333333333333, 23.11487667321691, 16.5, 20.93584977834404, 22.7, 1.0, 8.831281882667012], 
actual action is [1.166666666666667, 17.5], 
sim time next is 3064500.0000, 
raw observation next is [-3.75, 54.25, 2.725, 62.5, 109.75, 793.5, 1.166666666666667, 23.35018216017469, 17.5, 20.89211479151475, 22.7, 1.0, 8.606490519976145], 
processed observation next is [1.0, 0.4782608695652174, 0.23717948717948717, 0.5425, 0.24772727272727274, 0.1736111111111111, 0.29034391534391535, 0.7935, 0.5194444444444445, 0.2335018216017469, 0.375, 0.5446057395757375, 0.635, 1.0, 0.10125282964677818], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:56:40,052] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 164349: loss 69.4745
[2017-11-01 09:56:54,599] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 165905: loss -7.6033
[2017-11-01 09:56:55,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.26653263e-01   1.70693114e-01   1.54401436e-01   2.57000357e-01
   1.91251814e-01   2.38265224e-12   2.93187523e-12   2.19466719e-12
   1.49951330e-12], sum to 1.0000
[2017-11-01 09:56:55,742] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 95.33333333333333, 4.6, 94.16666666666666, 0.0, 0.0, 4.0, 14.06148403644867, 22.0, 22.02551275480153, 21.5, 0.0, 37.74581979853362], 
actual action is [4.0, 22.0], 
sim time next is 3097800.0000, 
raw observation next is [-1.0, 96.0, 4.6, 95.0, 0.0, 0.0, 4.0, 13.73065585006302, 22.0, 22.21484950408123, 21.5, 0.0, 27.41857151207998], 
processed observation next is [1.0, 0.8695652173913043, 0.3076923076923077, 0.96, 0.41818181818181815, 0.2638888888888889, 0.0, 0.0, 0.5666666666666667, 0.1373065585006302, 0.6, 0.6107424752040614, 0.575, 0.0, 0.32257142955388207], 
reward next is -0.1613. 
=============================================
[2017-11-01 09:56:58,735] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 166451: loss 17.0397
[2017-11-01 09:57:00,881] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10500, global step 166780: loss 7.3059
[2017-11-01 09:57:01,555] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.67080992e-01   1.81739196e-01   1.51196793e-01   1.94259048e-01
   2.05723926e-01   2.55874525e-14   5.75795718e-14   2.69376315e-14
   3.73558538e-14], sum to 1.0000
[2017-11-01 09:57:01,604] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.0, 100.0, 2.433333333333333, 79.16666666666666, 0.0, 0.0, 6.0, 20.07162059225146, 12.5, 21.0454982839169, 21.5, 0.0, 14.08505829922261], 
actual action is [6.0, 12.0], 
sim time next is 3115800.0000, 
raw observation next is [1.0, 100.0, 2.3, 75.0, 0.0, 0.0, 6.0, 20.32435219311649, 12.0, 21.01238791424873, 21.5, 0.0, 12.62125589786718], 
processed observation next is [0.0, 0.043478260869565216, 0.358974358974359, 1.0, 0.20909090909090908, 0.20833333333333334, 0.0, 0.0, 0.6, 0.2032435219311649, 0.1, 0.5506193957124366, 0.575, 0.0, 0.14848536350431976], 
reward next is -0.1961. 
=============================================
[2017-11-01 09:57:01,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-30.39228821]
 [-29.3887291 ]
 [-29.61257935]
 [-30.02577591]
 [-28.99999237]], R is [[-28.97843361]
 [-28.70672417]
 [-28.67702866]
 [-28.39025879]
 [-28.10635567]].
[2017-11-01 09:57:02,660] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.30180293e-01   1.49352118e-01   1.41136453e-01   2.27082431e-01
   2.52248734e-01   1.03636514e-15   2.54060523e-15   8.94985388e-16
   2.33876596e-15], sum to 1.0000
[2017-11-01 09:57:02,738] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.0, 100.0, 7.866666666666666, 163.3333333333333, 28.33333333333333, 185.3333333333333, 11.0, 20.47584977462891, 19.5, 20.25175232901192, 22.7, 1.0, 13.69456325816858], 
actual action is [11.0, 19.0], 
sim time next is 3138900.0000, 
raw observation next is [6.0, 100.0, 8.033333333333333, 161.6666666666667, 35.16666666666666, 211.1666666666667, 11.0, 20.38344390070147, 19.0, 20.26636732506367, 22.7, 1.0, 12.34782217390245], 
processed observation next is [0.0, 0.30434782608695654, 0.48717948717948717, 1.0, 0.7303030303030303, 0.4490740740740742, 0.09303350970017635, 0.21116666666666672, 0.6833333333333333, 0.2038344390070147, 0.45, 0.5133183662531835, 0.635, 1.0, 0.14526849616355825], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:57:04,405] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167349: loss 13.0215
[2017-11-01 09:57:05,491] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167529: loss -1.2235
[2017-11-01 09:57:08,370] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10500, global step 168025: loss 10.6744
[2017-11-01 09:57:10,488] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168376: loss 30.2000
[2017-11-01 09:57:11,700] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10500, global step 168606: loss -12.5408
[2017-11-01 09:57:12,509] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168775: loss -0.6171
[2017-11-01 09:57:12,642] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168805: loss 7.8092
[2017-11-01 09:57:12,859] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.32019728e-01   5.01119316e-01   1.05841547e-01   1.60338521e-01
   1.00680821e-01   5.68130327e-25   1.15958944e-24   4.47402758e-25
   2.59505577e-24], sum to 1.0000
[2017-11-01 09:57:12,892] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [3.083333333333333, 99.99999999999999, 3.225, 150.0, 0.0, 0.0, 8.0, 26.46307844480121, 17.0, 19.69270605704239, 21.5, 0.0, 32.12624943245471], 
actual action is [8.083333333333332, 16.5], 
sim time next is 3129000.0000, 
raw observation next is [3.166666666666667, 100.0, 3.35, 150.0, 0.0, 0.0, 8.083333333333332, 26.0794022574719, 16.5, 19.75978965382196, 21.5, 0.0, 25.27253319451513], 
processed observation next is [0.0, 0.21739130434782608, 0.41452991452991456, 1.0, 0.30454545454545456, 0.4166666666666667, 0.0, 0.0, 0.6347222222222222, 0.260794022574719, 0.325, 0.4879894826910981, 0.575, 0.0, 0.29732391993547214], 
reward next is -0.5837. 
=============================================
[2017-11-01 09:57:13,812] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 169056: loss 7.4573
[2017-11-01 09:57:14,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.07982437  0.20702419  0.12263532  0.15912867  0.21982531  0.04855002
  0.09298195  0.03419623  0.03583393], sum to 1.0000
[2017-11-01 09:57:15,068] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [7.416666666666667, 97.08333333333334, 4.308333333333333, 195.8333333333333, 112.9166666666667, 821.5833333333334, 12.5, 8.176392849025982, 11.0, 23.04054439013225, 22.7, 1.0, 11.11258113529622], 
actual action is [12.416666666666668, 11.0], 
sim time next is 3156000.0000, 
raw observation next is [7.333333333333333, 97.66666666666666, 4.266666666666667, 196.6666666666667, 112.8333333333333, 820.1666666666667, 12.41666666666667, 8.170161052376278, 11.0, 23.00271156540385, 22.7, 1.0, 5.326241448307702], 
processed observation next is [0.0, 0.5217391304347826, 0.5213675213675213, 0.9766666666666666, 0.3878787878787879, 0.5462962962962964, 0.2985008818342151, 0.8201666666666667, 0.7069444444444445, 0.08170161052376278, 0.05, 0.6501355782701925, 0.635, 1.0, 0.06266166409773767], 
reward next is -0.0722. 
=============================================
[2017-11-01 09:57:17,422] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 169765: loss 5.3948
[2017-11-01 09:57:17,928] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 169870: loss 21.0091
[2017-11-01 09:57:18,091] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10500, global step 169902: loss -7.9732
[2017-11-01 09:57:20,257] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10500, global step 170315: loss 8.5302
[2017-11-01 09:57:24,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.10311338  0.18040442  0.17435442  0.13389857  0.16050644  0.08700591
  0.09264203  0.03902293  0.02905186], sum to 1.0000
[2017-11-01 09:57:24,026] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.0, 100.0, 3.1, 287.5, 7.333333333333333, 106.3333333333333, 1.0, 8.344711162658689, 10.0, 22.6623580543433, 22.7, 1.0, 0.0], 
actual action is [1.0, 10], 
sim time next is 3174000.0000, 
raw observation next is [6.0, 100.0, 3.1, 290.0, 0.0, 0.0, 1.0, 8.556530299458268, 10.0, 22.56270251378373, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.48717948717948717, 1.0, 0.2818181818181818, 0.8055555555555556, 0.0, 0.0, 0.5166666666666667, 0.08556530299458269, 0.0, 0.6281351256891865, 0.635, 1.0, 0.0], 
reward next is -0.0428. 
=============================================
[2017-11-01 09:57:24,843] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.04067046e-02   7.84338936e-02   4.72670585e-01   2.79544264e-01
   1.58944473e-01   4.76467824e-12   1.39024426e-12   1.19934368e-12
   1.98239168e-11], sum to 1.0000
[2017-11-01 09:57:24,859] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 95.91666666666666, 2.808333333333334, 320.0, 0.0, 0.0, -3.0, 25.11539000833887, 10.0, 19.32411459281123, 21.5, 0.0, 0.0], 
actual action is [-3.0, 10], 
sim time next is 3192000.0000, 
raw observation next is [2.0, 95.33333333333334, 2.766666666666667, 320.0, 0.0, 0.0, -3.0, 25.48458023674082, 10.0, 19.29130157018755, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.38461538461538464, 0.9533333333333335, 0.2515151515151515, 0.8888888888888888, 0.0, 0.0, 0.45, 0.25484580236740817, 0.0, 0.46456507850937745, 0.575, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:57:26,269] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-51.75843811]
 [-51.6182251 ]
 [-50.73707962]
 [-51.42258453]
 [-50.21176147]], R is [[-49.96430969]
 [-49.66914749]
 [-49.3805275 ]
 [-49.10132217]
 [-48.83537292]].
[2017-11-01 09:57:27,945] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.84544027e-02   6.20391928e-02   3.59097928e-01   3.74544054e-01
   1.85758233e-01   2.63479906e-05   1.70421972e-05   2.37468303e-05
   3.89219822e-05], sum to 1.0000
[2017-11-01 09:57:27,964] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [3.0, 100.0, 2.416666666666667, 340.0, 0.0, 0.0, 8.0, 17.90006769984378, 17.0, 20.0871096503685, 21.5, 0.0, 1.890880223772664], 
actual action is [8.0, 16.5], 
sim time next is 3185700.0000, 
raw observation next is [3.0, 100.0, 2.508333333333333, 340.0, 0.0, 0.0, 8.0, 18.12538989606754, 16.5, 20.05706399956917, 21.5, 0.0, 2.129105812588504], 
processed observation next is [0.0, 0.8695652173913043, 0.41025641025641024, 1.0, 0.228030303030303, 0.9444444444444444, 0.0, 0.0, 0.6333333333333333, 0.1812538989606754, 0.325, 0.5028531999784585, 0.575, 0.0, 0.02504830367751181], 
reward next is -0.3733. 
=============================================
[2017-11-01 09:57:34,176] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 172511: loss -54.9703
[2017-11-01 09:57:37,200] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.60139238e-02   6.85522035e-02   3.30364615e-01   2.01264918e-01
   3.73747140e-01   8.61293120e-06   1.04527826e-05   1.91132876e-05
   1.90410974e-05], sum to 1.0000
[2017-11-01 09:57:37,281] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.8, 88.0, 7.033333333333334, 253.3333333333333, 107.6666666666667, 735.5, 2.15, 12.9193842992473, 15.0, 21.63712607564764, 22.0, 1.0, 75.11656613923], 
actual action is [2.2, 14.0], 
sim time next is 3234300.0000, 
raw observation next is [-2.75, 87.0, 6.991666666666666, 254.1666666666667, 108.3333333333333, 743.75, 2.2, 11.60834213326152, 14.0, 21.81198630157949, 22.0, 1.0, 36.22146863425327], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.26282051282051283, 0.87, 0.6356060606060606, 0.7060185185185186, 0.28659611992945316, 0.74375, 0.5366666666666667, 0.11608342133261519, 0.2, 0.5905993150789746, 0.6, 1.0, 0.42613492510886203], 
reward next is -0.2711. 
=============================================
[2017-11-01 09:57:38,645] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  8.23025391e-14   2.23607117e-06   4.50872449e-06   4.05506080e-06
   1.75302466e-06   1.65151790e-01   1.51066944e-01   1.99174613e-01
   4.84594047e-01], sum to 1.0000
[2017-11-01 09:57:38,675] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 92.0, 5.1, 266.6666666666667, 0.0, 0.0, 2.0, 15.91803564279229, 12.5, 21.03776599059812, 22.0, 1.0, 27.44951581132613], 
actual action is [2.0, 14.5], 
sim time next is 3223500.0000, 
raw observation next is [-3.0, 92.0, 5.1, 265.8333333333333, 0.0, 0.0, 2.0, 16.61261278446488, 14.5, 20.94292868016424, 22.0, 1.0, 25.51777721790978], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.92, 0.4636363636363636, 0.7384259259259258, 0.0, 0.0, 0.5333333333333333, 0.16612612784464878, 0.225, 0.547146434008212, 0.6, 1.0, 0.3002091437401151], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:57:41,807] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 173786: loss 13.1110
[2017-11-01 09:57:42,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.07933071
  0.18134613  0.39728275  0.34204045], sum to 1.0000
[2017-11-01 09:57:42,326] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-10.08333333333333, 75.99999999999999, 3.141666666666667, 315.8333333333333, 0.0, 0.0, -5.0, 33.65488088825704, 24.5, 18.89661512712715, 20.8, 0.0, 26.56170141994169], 
actual action is [-5.08333333333333, 26.5], 
sim time next is 3301800.0000, 
raw observation next is [-10.16666666666667, 76.0, 3.183333333333334, 311.6666666666667, 0.0, 0.0, -5.08333333333333, 33.02581666990301, 26.5, 18.86770847262729, 20.8, 0.0, 42.09290676029022], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.07264957264957257, 0.76, 0.2893939393939395, 0.8657407407407408, 0.0, 0.0, 0.41527777777777786, 0.3302581666990301, 0.825, 0.44338542363136446, 0.54, 0.0, 0.4952106677681202], 
reward next is -0.7307. 
=============================================
[2017-11-01 09:57:44,131] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 174118: loss 18.5938
[2017-11-01 09:57:50,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.01454623e-30   4.07043800e-17   1.78700129e-17   1.89454767e-17
   3.91235221e-17   1.07827134e-01   5.93118250e-01   9.32824388e-02
   2.05772161e-01], sum to 1.0000
[2017-11-01 09:57:50,033] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.75, 71.0, 5.675000000000001, 312.5, 78.5, 642.25, -7.666666666666667, 12.19385658916874, 10.0, 22.09632748745204, 22.0, 1.0, 0.0], 
actual action is [2.25, 15.0], 
sim time next is 3253800.0000, 
raw observation next is [-2.833333333333333, 71.0, 5.85, 315.0, 76.33333333333333, 627.6666666666666, 2.25, 11.8769188770729, 15.0, 22.07519532261791, 22.0, 1.0, 17.96864233242194], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2606837606837607, 0.71, 0.5318181818181817, 0.875, 0.2019400352733686, 0.6276666666666666, 0.5375, 0.11876918877072899, 0.25, 0.6037597661308954, 0.6, 1.0, 0.21139579214614046], 
reward next is -0.1651. 
=============================================
[2017-11-01 09:57:53,122] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175170: loss 21.0048
[2017-11-01 09:57:54,485] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11000, global step 175308: loss -4.5364
[2017-11-01 09:57:55,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.62602568e-01   1.07387759e-01   2.19359100e-01   1.15830719e-01
   2.94819832e-01   3.03252319e-11   2.54050427e-11   1.27273730e-11
   2.08326689e-11], sum to 1.0000
[2017-11-01 09:57:55,203] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 74.66666666666667, 5.866666666666667, 336.6666666666667, 0.0, 0.0, -2.0, 16.77398583224313, 23.0, 21.31163346261516, 20.8, 0.0, 42.86267891476157], 
actual action is [-2.0, 18.0], 
sim time next is 3285900.0000, 
raw observation next is [-7.0, 73.5, 5.825, 335.0, 0.0, 0.0, -2.0, 16.58271275313076, 18.0, 21.29939207100961, 20.8, 0.0, 48.0248598858733], 
processed observation next is [0.3333333333333333, 0.0, 0.15384615384615385, 0.735, 0.5295454545454545, 0.9305555555555556, 0.0, 0.0, 0.4666666666666667, 0.1658271275313076, 0.4, 0.5649696035504805, 0.54, 0.0, 0.5649983515985094], 
reward next is -0.2825. 
=============================================
[2017-11-01 09:57:56,661] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175525: loss -30.2784
[2017-11-01 09:58:00,057] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11000, global step 175914: loss -1.3490
[2017-11-01 09:58:00,288] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   3.30525750e-29   4.79475998e-29   1.60677362e-28
   3.53261870e-28   4.58763093e-01   2.56683916e-01   7.67981410e-02
   2.07754821e-01], sum to 1.0000
[2017-11-01 09:58:00,429] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.816666666666666, 76.16666666666667, 3.266666666666667, 320.0, 0.0, 0.0, -4.725, 24.96540615038813, 11.0, 19.96527083409738, 20.8, 0.0, 26.02750704170737], 
actual action is [-4.816666666666666, 11.5], 
sim time next is 3300900.0000, 
raw observation next is [-9.908333333333333, 76.08333333333333, 3.183333333333334, 320.0, 0.0, 0.0, -4.816666666666666, 26.00750663931246, 11.5, 19.84477554733618, 20.8, 0.0, 24.90622873545197], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.07927350427350428, 0.7608333333333333, 0.2893939393939395, 0.8888888888888888, 0.0, 0.0, 0.4197222222222222, 0.2600750663931246, 0.075, 0.492238777366809, 0.54, 0.0, 0.2930144557111996], 
reward next is -0.3853. 
=============================================
[2017-11-01 09:58:02,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176178: loss -27.5454
[2017-11-01 09:58:02,670] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.19180933e-01   3.41386124e-02   1.35615498e-01   2.51821399e-01
   4.59243566e-01   5.11138973e-21   2.74479429e-21   4.36015918e-22
   1.14074507e-20], sum to 1.0000
[2017-11-01 09:58:02,740] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-8.3, 77.0, 4.766666666666667, 320.0, 0.0, 0.0, -3.225, 30.19556154280876, 30.0, 19.00613798832458, 20.8, 0.0, 63.75061297761973], 
actual action is [-3.3000000000000007, 29.5], 
sim time next is 3295500.0000, 
raw observation next is [-8.375, 77.0, 4.683333333333333, 320.0, 0.0, 0.0, -3.300000000000001, 27.9907901595539, 29.5, 19.10419074234248, 20.8, 0.0, 57.43484459246896], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.11858974358974358, 0.77, 0.4257575757575757, 0.8888888888888888, 0.0, 0.0, 0.445, 0.279907901595539, 0.975, 0.4552095371171241, 0.54, 0.0, 0.6757040540290467], 
reward next is -0.7618. 
=============================================
[2017-11-01 09:58:02,989] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176268: loss -14.9373
[2017-11-01 09:58:04,163] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11000, global step 176417: loss -7.1959
[2017-11-01 09:58:04,703] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.11575484e-01   4.16075513e-02   3.51612061e-01   1.60083205e-01
   3.35121721e-01   1.33740758e-16   4.53090033e-17   1.51151408e-17
   1.04731137e-16], sum to 1.0000
[2017-11-01 09:58:04,729] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176493: loss 50.2518
[2017-11-01 09:58:04,783] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.999999999999999, 82.83333333333333, 6.158333333333333, 348.3333333333333, 0.0, 0.0, -2.0, 24.16469411801046, 16.5, 20.42412508237933, 20.8, 0.0, 24.41518218677807], 
actual action is [-1.9999999999999991, 16.5], 
sim time next is 3283800.0000, 
raw observation next is [-7.0, 81.66666666666667, 6.116666666666667, 346.6666666666667, 0.0, 0.0, -1.999999999999999, 24.54804104479232, 16.5, 20.36431112006097, 20.8, 0.0, 22.96008272711174], 
processed observation next is [0.3333333333333333, 0.0, 0.15384615384615385, 0.8166666666666668, 0.5560606060606061, 0.962962962962963, 0.0, 0.0, 0.4666666666666667, 0.2454804104479232, 0.325, 0.5182155560030486, 0.54, 0.0, 0.27011862031896167], 
reward next is -0.2440. 
=============================================
[2017-11-01 09:58:07,561] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176823: loss 3.1685
[2017-11-01 09:58:07,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.92596689e-01   4.73291017e-02   3.45231920e-01   2.28267938e-01
   1.86574280e-01   1.90881294e-18   2.00708427e-18   6.52122053e-19
   1.48418257e-18], sum to 1.0000
[2017-11-01 09:58:08,048] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.0, 77.0, 5.1, 327.5, 0.0, 0.0, -3.0, 19.79526442204183, 29.5, 20.50997649587037, 20.8, 0.0, 47.52968931121629], 
actual action is [-3.0, 28.5], 
sim time next is 3291600.0000, 
raw observation next is [-8.0, 77.0, 5.1, 326.6666666666667, 0.0, 0.0, -3.0, 19.4567173305465, 28.5, 20.58445885471317, 20.8, 0.0, 47.44450337186366], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.1282051282051282, 0.77, 0.4636363636363636, 0.9074074074074074, 0.0, 0.0, 0.45, 0.194567173305465, 0.925, 0.5292229427356585, 0.54, 0.0, 0.5581706279042784], 
reward next is -0.3330. 
=============================================
[2017-11-01 09:58:09,890] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-44.86220169]
 [-44.97094727]
 [-46.92059708]
 [-47.87481689]
 [-48.03123474]], R is [[-44.99064636]
 [-44.96837616]
 [-44.95755768]
 [-45.50798416]
 [-46.05290604]].
[2017-11-01 09:58:10,933] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11000, global step 177167: loss 48.2423
[2017-11-01 09:58:11,513] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 177218: loss -11.6688
[2017-11-01 09:58:12,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 177273: loss -5.4258
[2017-11-01 09:58:15,022] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11000, global step 177569: loss -21.5950
[2017-11-01 09:58:26,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-26.5634861 ]
 [-26.92194557]
 [-29.11658669]
 [-25.83371544]
 [-26.50225258]], R is [[-26.39876366]
 [-26.35621262]
 [-26.32899094]
 [-26.34313583]
 [-26.48710823]].
[2017-11-01 09:58:32,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.46462873e-01   1.40341386e-01   2.51824826e-01   1.70538858e-01
   2.90832102e-01   4.69996424e-19   1.51393439e-19   1.19200539e-19
   6.90891168e-20], sum to 1.0000
[2017-11-01 09:58:32,501] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.0, 77.0, 3.1, 169.1666666666667, 0.0, 0.0, -1.0, 20.00823652529145, 13.5, 21.00302017261141, 20.8, 0.0, 22.19800617595815], 
actual action is [-1.0, 13.5], 
sim time next is 3376800.0000, 
raw observation next is [-6.0, 77.0, 3.1, 170.0, 0.0, 0.0, -1.0, 20.75829925298736, 13.5, 20.89618064223266, 20.8, 0.0, 21.30510654745643], 
processed observation next is [0.5, 0.08695652173913043, 0.1794871794871795, 0.77, 0.2818181818181818, 0.4722222222222222, 0.0, 0.0, 0.48333333333333334, 0.2075829925298736, 0.175, 0.544809032111633, 0.54, 0.0, 0.2506483123230168], 
reward next is -0.1253. 
=============================================
[2017-11-01 09:58:34,827] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.74649581e-01   1.18712395e-01   2.93305337e-01   2.26075441e-01
   1.87257320e-01   2.84547087e-16   1.62298368e-16   6.97802286e-17
   1.40234801e-16], sum to 1.0000
[2017-11-01 09:58:34,909] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.0, 55.0, 2.183333333333334, 201.6666666666667, 0.0, 0.0, 2.0, 16.06652926197795, 20.5, 20.96564681928715, 22.0, 1.0, 40.0059931811825], 
actual action is [2.0, 18.5], 
sim time next is 3351300.0000, 
raw observation next is [-3.0, 55.0, 2.141666666666667, 200.8333333333333, 0.0, 0.0, 2.0, 15.74138036489285, 18.5, 21.17439389730733, 22.0, 1.0, 26.63384551144584], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.2564102564102564, 0.55, 0.19469696969696973, 0.5578703703703702, 0.0, 0.0, 0.5333333333333333, 0.15741380364892849, 0.425, 0.5587196948653664, 0.6, 1.0, 0.3133393589581864], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:36,737] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 180431: loss 27.8117
[2017-11-01 09:58:41,670] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.20213675e-01   1.80872247e-01   2.00678349e-01   1.32328972e-01
   1.65906817e-01   9.91012457e-22   6.96456238e-22   6.17402783e-22
   7.03484092e-22], sum to 1.0000
[2017-11-01 09:58:41,865] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.166666666666667, 60.83333333333333, 4.6, 188.3333333333333, 30.33333333333333, 212.0, 2.75, 23.95681351872319, 22.0, 19.73117070881736, 22.0, 1.0, 75.36979692063895], 
actual action is [2.833333333333333, 20.0], 
sim time next is 3398100.0000, 
raw observation next is [-2.083333333333333, 60.41666666666667, 4.6, 189.1666666666667, 37.41666666666666, 238.25, 2.833333333333333, 21.72612350482085, 20.0, 20.02804611184586, 22.0, 1.0, 50.17389164043078], 
processed observation next is [0.5, 0.30434782608695654, 0.2799145299145299, 0.6041666666666667, 0.41818181818181815, 0.5254629629629631, 0.09898589065255729, 0.23825, 0.5472222222222223, 0.21726123504820852, 0.5, 0.501402305592293, 0.6, 1.0, 0.5902810781227151], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:42,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-41.80850983]
 [-41.58534241]
 [-41.33774185]
 [-40.74679565]
 [-41.47505569]], R is [[-42.19258881]
 [-42.08118439]
 [-41.95110703]
 [-41.80321121]
 [-41.63843918]].
[2017-11-01 09:58:43,592] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.01066960e-06   3.59564066e-01   1.86408490e-01   1.32822305e-01
   3.19822431e-01   2.30783917e-04   4.26163984e-04   2.34575695e-04
   4.82156029e-04], sum to 1.0000
[2017-11-01 09:58:43,634] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.25, 51.0, 6.425000000000001, 202.5, 101.5, 684.5, 6.0, 16.61638672105599, 12.5, 21.98852872225616, 22.0, 1.0, 10.53140926751988], 
actual action is [6.25, 10.5], 
sim time next is 3405000.0000, 
raw observation next is [1.5, 50.0, 6.683333333333334, 205.0, 102.3333333333333, 693.3333333333334, 6.25, 16.40379199821636, 10.5, 22.03660190119811, 22.0, 1.0, 9.605783760084718], 
processed observation next is [0.5, 0.391304347826087, 0.3717948717948718, 0.5, 0.6075757575757575, 0.5694444444444444, 0.2707231040564373, 0.6933333333333334, 0.6041666666666666, 0.1640379199821636, 0.025, 0.6018300950599056, 0.6, 1.0, 0.11300922070687903], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:44,070] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 181727: loss 7.4084
[2017-11-01 09:58:45,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-37.9071312 ]
 [-38.04893112]
 [-39.04836273]
 [-37.20848083]
 [-38.16182327]], R is [[-38.5265274 ]
 [-38.46738434]
 [-38.41831207]
 [-38.41428375]
 [-38.45631027]].
[2017-11-01 09:58:45,559] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.08914921e-01   1.87641978e-01   2.80551523e-01   6.25116900e-02
   2.60379940e-01   1.71710330e-25   1.65217894e-25   1.12947675e-25
   8.59916442e-26], sum to 1.0000
[2017-11-01 09:58:45,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.0, 86.0, 6.016666666666667, 220.0, 0.0, 0.0, 6.0, 32.94886191078039, 17.0, 19.2733008107181, 20.8, 0.0, 5.805391527065961], 
actual action is [6.0, 16.0], 
sim time next is 3449700.0000, 
raw observation next is [1.0, 86.0, 5.925000000000001, 220.0, 0.0, 0.0, 6.0, 33.48902173849205, 16.0, 19.23729595804134, 20.8, 0.0, 5.623954830278368], 
processed observation next is [0.5, 0.9565217391304348, 0.358974358974359, 0.86, 0.5386363636363637, 0.6111111111111112, 0.0, 0.0, 0.6, 0.3348902173849205, 0.3, 0.461864797902067, 0.54, 0.0, 0.06616417447386315], 
reward next is -0.4238. 
=============================================
[2017-11-01 09:58:45,769] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 182001: loss -69.4100
[2017-11-01 09:58:46,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   1.67673383e-22   4.36948509e-23   2.51148258e-23
   1.11279458e-22   1.89337388e-01   2.73941696e-01   2.90162444e-01
   2.46558458e-01], sum to 1.0000
[2017-11-01 09:58:47,013] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [0.5, 54.0, 5.65, 195.0, 99.0, 658.0, 5.25, 13.45284263935083, 16.0, 22.78378586411882, 22.0, 1.0, 20.31858365709601], 
actual action is [5.5, 18.0], 
sim time next is 3404100.0000, 
raw observation next is [0.7500000000000001, 53.0, 5.908333333333333, 197.5, 99.83333333333334, 666.8333333333334, 5.5, 13.32990273533608, 18.0, 22.81579757549767, 22.0, 1.0, 17.20563671955732], 
processed observation next is [0.5, 0.391304347826087, 0.3525641025641026, 0.53, 0.5371212121212121, 0.5486111111111112, 0.2641093474426808, 0.6668333333333334, 0.5916666666666667, 0.1332990273533608, 0.4, 0.6407898787748835, 0.6, 1.0, 0.20241925552420376], 
reward next is -0.1679. 
=============================================
[2017-11-01 09:58:47,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.21848205e-01   2.93256044e-01   1.86900452e-01   6.18102886e-02
   2.36185014e-01   4.36404626e-20   5.49147566e-20   1.70705651e-20
   3.61185377e-20], sum to 1.0000
[2017-11-01 09:58:48,076] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.25, 61.25, 4.6, 187.5, 23.25, 185.75, 2.666666666666667, 23.23319623564266, 23.0, 20.39650676525708, 22.0, 1.0, 54.50586740684994], 
actual action is [2.75, 23.0], 
sim time next is 3397800.0000, 
raw observation next is [-2.166666666666667, 60.83333333333333, 4.6, 188.3333333333333, 30.33333333333333, 212.0, 2.75, 22.00938339777973, 23.0, 20.50954370028923, 22.0, 1.0, 66.11206229557648], 
processed observation next is [0.5, 0.30434782608695654, 0.27777777777777773, 0.6083333333333333, 0.41818181818181815, 0.523148148148148, 0.0802469135802469, 0.212, 0.5458333333333333, 0.22009383397779728, 0.65, 0.5254771850144614, 0.6, 1.0, 0.7777889681832527], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:51,159] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  3.14908544e-09   3.98861617e-01   3.40654641e-01   5.46780527e-02
   2.05805659e-01   9.10310022e-12   3.04794709e-12   1.85183553e-12
   1.41526114e-11], sum to 1.0000
[2017-11-01 09:58:51,188] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.0, 86.0, 6.2, 220.0, 0.0, 0.0, 6.0, 32.78459653422105, 14.5, 19.27812008775695, 20.8, 0.0, 4.001033691804481], 
actual action is [6.0, 13.5], 
sim time next is 3449100.0000, 
raw observation next is [1.0, 86.0, 6.108333333333333, 220.0, 0.0, 0.0, 6.0, 33.33360721550373, 13.5, 19.24473466251008, 20.8, 0.0, 3.87977236727671], 
processed observation next is [0.5, 0.9565217391304348, 0.358974358974359, 0.86, 0.5553030303030303, 0.6111111111111112, 0.0, 0.0, 0.6, 0.33333607215503736, 0.175, 0.462236733125504, 0.54, 0.0, 0.045644380791490705], 
reward next is -0.4116. 
=============================================
[2017-11-01 09:58:51,508] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 182898: loss 55.7405
[2017-11-01 09:58:53,698] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11500, global step 183208: loss 38.1693
[2017-11-01 09:58:57,535] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183706: loss 12.2122
[2017-11-01 09:58:58,095] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11500, global step 183825: loss 12.1900
[2017-11-01 09:58:58,096] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.21410262e-05   2.69752204e-01   3.13826531e-01   6.14275858e-02
   3.54961514e-01   4.19830881e-09   2.38570874e-09   1.19176446e-09
   6.22613205e-09], sum to 1.0000
[2017-11-01 09:58:58,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 79.0, 6.575, 210.0, 0.0, 0.0, -4.0, 22.53988882838723, 10.0, 20.77180524602016, 22.0, 1.0, 0.0], 
actual action is [-4.0, 10], 
sim time next is 3441000.0000, 
raw observation next is [1.0, 79.0, 6.616666666666667, 210.0, 0.0, 0.0, -4.0, 23.04536676553919, 10.0, 20.71972185848197, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.8260869565217391, 0.358974358974359, 0.79, 0.6015151515151516, 0.5833333333333334, 0.0, 0.0, 0.43333333333333335, 0.23045366765539188, 0.0, 0.5359860929240986, 0.6, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:59:00,154] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184185: loss -63.5289
[2017-11-01 09:59:00,881] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11500, global step 184291: loss -81.2620
[2017-11-01 09:59:01,192] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184348: loss -34.0183
[2017-11-01 09:59:05,309] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184985: loss 22.8093
[2017-11-01 09:59:06,495] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 185149: loss 6.8680
[2017-11-01 09:59:07,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.61180973e-11   2.11323142e-01   2.00345576e-01   1.44965589e-01
   4.05339569e-01   1.21164350e-02   1.29463831e-02   4.69703274e-03
   8.26622173e-03], sum to 1.0000
[2017-11-01 09:59:07,871] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 71.0, 2.6, 320.0, 0.0, 0.0, 2.083333333333333, 28.80929467909831, 19.0, 20.02877591053059, 21.5, 0.0, 14.84395734589281], 
actual action is [2.0, 19.0], 
sim time next is 3549900.0000, 
raw observation next is [-3.0, 70.5, 2.858333333333333, 316.6666666666666, 0.0, 0.0, 2.0, 29.43540405857718, 19.0, 19.96430468429332, 21.5, 0.0, 14.25489553199691], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.2564102564102564, 0.705, 0.25984848484848483, 0.8796296296296293, 0.0, 0.0, 0.5333333333333333, 0.2943540405857718, 0.45, 0.49821523421466607, 0.575, 0.0, 0.1677046533176107], 
reward next is -0.4678. 
=============================================
[2017-11-01 09:59:08,051] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11500, global step 185393: loss 17.5760
[2017-11-01 09:59:08,805] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 185503: loss 27.9420
[2017-11-01 09:59:10,368] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 185750: loss 4.7645
[2017-11-01 09:59:10,971] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11500, global step 185830: loss 32.2038
[2017-11-01 09:59:12,509] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.87222385e-02   2.19706580e-01   2.58846015e-01   1.42330229e-01
   3.00394952e-01   2.98627215e-25   1.85982907e-25   1.79301258e-26
   6.33857256e-26], sum to 1.0000
[2017-11-01 09:59:12,600] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.916666666666667, 69.58333333333333, 2.641666666666667, 280.8333333333333, 0.0, 0.0, -0.833333333333333, 31.9673296004364, 19.5, 19.66168063794082, 21.5, 0.0, 18.08154241771209], 
actual action is [-0.916666666666667, 18.5], 
sim time next is 3564000.0000, 
raw observation next is [-6.0, 70.0, 2.6, 280.0, 0.0, 0.0, -0.916666666666667, 32.99762142807377, 18.5, 19.54242622014655, 21.5, 0.0, 17.32043267487597], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.1794871794871795, 0.7, 0.23636363636363636, 0.7777777777777778, 0.0, 0.0, 0.4847222222222222, 0.3299762142807377, 0.425, 0.47712131100732746, 0.575, 0.0, 0.20376979617501143], 
reward next is -0.5913. 
=============================================
[2017-11-01 09:59:15,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.47636786e-01   1.22037135e-01   2.06373051e-01   1.90811470e-01
   3.33141506e-01   1.94837966e-22   2.04300636e-22   1.72448954e-23
   7.34797301e-23], sum to 1.0000
[2017-11-01 09:59:15,770] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.833333333333333, 69.16666666666667, 2.766666666666667, 315.0, 0.0, 0.0, 2.25, 21.79811987886169, 22.0, 20.64198381726612, 21.5, 0.0, 25.69189503079305], 
actual action is [2.166666666666667, 22.0], 
sim time next is 3549300.0000, 
raw observation next is [-2.916666666666667, 70.08333333333333, 2.683333333333334, 317.5, 0.0, 0.0, 2.166666666666667, 21.64121453440517, 22.0, 20.59570939756725, 21.5, 0.0, 39.06843714914463], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.2585470085470085, 0.7008333333333333, 0.243939393939394, 0.8819444444444444, 0.0, 0.0, 0.5361111111111111, 0.21641214534405168, 0.6, 0.5297854698783626, 0.575, 0.0, 0.45962867234287796], 
reward next is -0.4559. 
=============================================
[2017-11-01 09:59:22,134] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.61575931e-01   1.39557421e-01   1.21950962e-01   2.16104597e-01
   1.60811096e-01   2.61081859e-24   2.80998920e-24   3.27131496e-25
   7.95161981e-25], sum to 1.0000
[2017-11-01 09:59:22,215] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.0, 72.0, 6.7, 245.0, 0.0, 0.0, 5.0, 24.15309187880572, 16.0, 19.93413217244199, 20.8, 0.0, 31.13329292992272], 
actual action is [5.0, 15.5], 
sim time next is 3477000.0000, 
raw observation next is [0.0, 72.0, 6.533333333333333, 243.3333333333333, 0.0, 0.0, 5.0, 24.09045276034051, 15.5, 20.01197412705758, 20.8, 0.0, 29.97232736583329], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.3333333333333333, 0.72, 0.5939393939393939, 0.6759259259259258, 0.0, 0.0, 0.5833333333333334, 0.2409045276034051, 0.275, 0.5005987063528791, 0.54, 0.0, 0.35261561606862696], 
reward next is -0.3733. 
=============================================
[2017-11-01 09:59:33,777] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 188867: loss -20.5624
[2017-11-01 09:59:33,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.17969611e-01   1.81122750e-01   1.49547815e-01   3.04148495e-01
   1.47211313e-01   8.28544108e-11   8.77108872e-11   2.70631555e-11
   2.20842598e-11], sum to 1.0000
[2017-11-01 09:59:33,987] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333333, 74.0, 6.033333333333334, 273.3333333333334, 0.0, 0.0, -5.25, 17.01318867285137, 10.0, 21.08422363053493, 20.8, 0.0, 0.0], 
actual action is [-5.333333333333333, 10], 
sim time next is 3533100.0000, 
raw observation next is [-0.4166666666666667, 74.5, 6.116666666666667, 274.1666666666666, 0.0, 0.0, -5.333333333333333, 17.39484170475937, 10.0, 21.03195532740281, 20.8, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.32264957264957267, 0.745, 0.5560606060606061, 0.7615740740740738, 0.0, 0.0, 0.41111111111111115, 0.17394841704759367, 0.0, 0.5515977663701405, 0.54, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:59:34,274] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.35116893
  0.32760525  0.23414321  0.0870827 ], sum to 1.0000
[2017-11-01 09:59:34,318] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.5, 65.5, 3.1, 305.0, 0.0, 0.0, 2.583333333333333, 23.23321344504054, 11.0, 20.26703412012953, 21.5, 0.0, 62.85957895369848], 
actual action is [2.5, 13.0], 
sim time next is 3548100.0000, 
raw observation next is [-2.583333333333333, 66.41666666666667, 3.016666666666667, 307.5, 0.0, 0.0, 2.5, 22.42464896201219, 13.0, 20.27409516535381, 21.5, 0.0, 33.76808211708782], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.26709401709401714, 0.6641666666666667, 0.2742424242424243, 0.8541666666666666, 0.0, 0.0, 0.5416666666666666, 0.2242464896201219, 0.15, 0.5137047582676905, 0.575, 0.0, 0.3972715543186803], 
reward next is -0.5051. 
=============================================
[2017-11-01 09:59:40,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 189954: loss 26.9604
[2017-11-01 09:59:42,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.01941073e-01   1.84825823e-01   2.74223953e-01   2.38453567e-01
   1.00555547e-01   7.05539938e-32   5.00272176e-32   1.18304022e-32
   5.34896949e-31], sum to 1.0000
[2017-11-01 09:59:42,096] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.833333333333334, 66.0, 3.1, 291.6666666666667, 0.0, 0.0, 0.25, 37.16554519864565, 14.5, 18.96903824175929, 21.5, 0.0, 17.93159507239774], 
actual action is [-9.833333333333334, 10], 
sim time next is 3560100.0000, 
raw observation next is [-4.916666666666666, 65.5, 3.1, 290.8333333333333, 0.0, 0.0, -9.833333333333334, 38.50154312824458, 10.0, 18.92638031514297, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.20726495726495728, 0.655, 0.2818181818181818, 0.8078703703703703, 0.0, 0.0, 0.3361111111111111, 0.38501543128244575, 0.0, 0.44631901575714855, 0.575, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:59:42,809] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 190233: loss 79.1390
[2017-11-01 09:59:47,207] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.30400494e-01   1.32405505e-01   2.10578486e-01   3.20770651e-01
   2.05844879e-01   6.18428185e-26   4.12402276e-26   1.06897563e-26
   4.36408546e-26], sum to 1.0000
[2017-11-01 09:59:47,226] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.0, 60.0, 5.35, 290.0, 0.0, 0.0, 3.0, 36.85291452815913, 18.5, 18.94662598411313, 21.5, 0.0, 6.834593154649741], 
actual action is [3.0, 17.5], 
sim time next is 3543300.0000, 
raw observation next is [-2.0, 60.0, 5.175000000000001, 290.0, 0.0, 0.0, 3.0, 37.39504543151561, 17.5, 18.89763495471561, 21.5, 0.0, 6.582320609563785], 
processed observation next is [0.8333333333333334, 0.0, 0.28205128205128205, 0.6, 0.4704545454545455, 0.8055555555555556, 0.0, 0.0, 0.55, 0.3739504543151561, 0.375, 0.4448817477357805, 0.575, 0.0, 0.07743906599486806], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:59:48,424] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12000, global step 191002: loss -9.7920
[2017-11-01 09:59:50,168] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191242: loss 82.5140
[2017-11-01 09:59:53,761] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191747: loss 17.8007
[2017-11-01 09:59:54,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.34603637e-01   1.27350509e-01   1.60613179e-01   1.93973124e-01
   1.83459610e-01   3.68956596e-24   3.19441749e-24   8.84570638e-25
   3.29531615e-24], sum to 1.0000
[2017-11-01 09:59:54,560] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [8.466666666666667, 26.33333333333334, 3.433333333333334, 176.6666666666667, 0.0, 0.0, 13.53333333333333, 29.11157378132242, 17.5, 20.42300958823187, 21.5, 0.0, 6.48224512328588], 
actual action is [13.466666666666667, 15.5], 
sim time next is 3638700.0000, 
raw observation next is [8.399999999999999, 26.5, 3.475, 177.5, 0.0, 0.0, 13.46666666666667, 29.32853372162754, 15.5, 20.40384978692315, 21.5, 0.0, 6.202116581357892], 
processed observation next is [1.0, 0.08695652173913043, 0.5487179487179487, 0.265, 0.3159090909090909, 0.4930555555555556, 0.0, 0.0, 0.7244444444444444, 0.2932853372162754, 0.275, 0.5201924893461575, 0.575, 0.0, 0.0729660774277399], 
reward next is -0.3105. 
=============================================
[2017-11-01 09:59:55,805] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12000, global step 192068: loss 0.5979
[2017-11-01 09:59:56,515] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192175: loss -78.0587
[2017-11-01 09:59:58,094] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12000, global step 192451: loss -73.0509
[2017-11-01 09:59:59,892] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192667: loss 17.0574
[2017-11-01 10:00:01,957] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192926: loss 49.0887
[2017-11-01 10:00:04,150] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 193243: loss 98.9438
[2017-11-01 10:00:04,573] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12000, global step 193315: loss -92.5083
[2017-11-01 10:00:07,845] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 193851: loss -21.4181
[2017-11-01 10:00:08,591] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 193988: loss 31.4625
[2017-11-01 10:00:09,872] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  7.03068043e-04   2.83412933e-01   3.06582749e-01   1.07102998e-01
   3.02198291e-01   4.05552951e-13   5.53513778e-13   2.12469324e-13
   9.74772997e-13], sum to 1.0000
[2017-11-01 10:00:09,946] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [5.75, 42.75, 5.375, 235.0, 110.75, 807.5, 10.66666666666667, 12.48935144356026, 15.0, 22.97693506019117, 22.7, 1.0, 23.70804788178752], 
actual action is [10.75, 15.0], 
sim time next is 3678600.0000, 
raw observation next is [5.833333333333333, 42.83333333333334, 5.283333333333333, 236.6666666666667, 110.0, 804.0, 10.75, 12.28268481801816, 15.0, 22.9913740929989, 22.7, 1.0, 12.99944874482681], 
processed observation next is [1.0, 0.5652173913043478, 0.48290598290598286, 0.42833333333333345, 0.4803030303030303, 0.6574074074074076, 0.291005291005291, 0.804, 0.6791666666666667, 0.1228268481801816, 0.25, 0.649568704649945, 0.635, 1.0, 0.15293469111560953], 
reward next is -0.1379. 
=============================================
[2017-11-01 10:00:09,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.02355581e-28   1.13346259e-11   1.41652697e-11   5.61395852e-12
   1.19058045e-11   1.54434651e-01   2.23708972e-01   1.11357376e-01
   5.10499001e-01], sum to 1.0000
[2017-11-01 10:00:10,031] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.5, 40.5, 1.8, 280.0, 14.0, 142.0, 4.583333333333333, 19.01972729879756, 15.0, 22.09176218462205, 22.7, 1.0, 12.9463220024897], 
actual action is [4.5, 20.0], 
sim time next is 3605700.0000, 
raw observation next is [-0.5833333333333334, 40.75, 1.75, 283.3333333333333, 12.83333333333333, 130.1666666666667, 4.5, 19.41501128077335, 20.0, 22.01691374698386, 22.7, 1.0, 7.989274074737764], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.31837606837606836, 0.4075, 0.1590909090909091, 0.787037037037037, 0.03395061728395061, 0.1301666666666667, 0.575, 0.1941501128077335, 0.5, 0.600845687349193, 0.635, 1.0, 0.09399145970279722], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:10,125] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12000, global step 194301: loss -164.0272
[2017-11-01 10:00:24,076] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 196619: loss -99.0219
[2017-11-01 10:00:28,545] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.80292633e-02   1.67339638e-01   1.14112243e-01   2.67049164e-01
   3.53469700e-01   2.19381688e-21   2.05248976e-21   8.02198233e-22
   1.12690474e-21], sum to 1.0000
[2017-11-01 10:00:28,613] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 60.0, 6.5, 230.0, 110.5, 797.0, 4.916666666666667, 19.94669738334975, 21.0, 21.02408221061921, 22.7, 1.0, 11.57173946239216], 
actual action is [5.0, 21.0], 
sim time next is 3765900.0000, 
raw observation next is [0.0, 60.0, 6.516666666666667, 229.1666666666667, 109.75, 793.5, 5.0, 19.34950293787919, 21.0, 21.05118327971788, 22.7, 1.0, 8.978474752229058], 
processed observation next is [0.0, 0.6086956521739131, 0.3333333333333333, 0.6, 0.5924242424242424, 0.6365740740740742, 0.29034391534391535, 0.7935, 0.5833333333333334, 0.1934950293787919, 0.55, 0.552559163985894, 0.635, 1.0, 0.10562911473210657], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:34,320] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.06776068e-01   2.98953712e-01   1.01748034e-01   1.42431930e-01
   2.50090271e-01   1.34480257e-11   1.08252652e-11   1.16015938e-11
   5.00365938e-12], sum to 1.0000
[2017-11-01 10:00:34,335] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.0, 59.0, 5.1, 250.0, 39.5, 343.5, -0.916666666666667, 11.90179445938244, 10.0, 24.00199893121272, 22.7, 1.0, 0.0], 
actual action is [-1.0, 10.0], 
sim time next is 3690300.0000, 
raw observation next is [4.0, 58.99999999999999, 5.016666666666667, 251.6666666666667, 35.41666666666666, 313.75, -1.0, 12.16285996958343, 10.0, 23.88688823379976, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4358974358974359, 0.59, 0.45606060606060606, 0.6990740740740742, 0.093694885361552, 0.31375, 0.48333333333333334, 0.1216285996958343, 0.0, 0.694344411689988, 0.635, 1.0, 0.0], 
reward next is -0.0608. 
=============================================
[2017-11-01 10:00:35,501] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 198249: loss -47.6674
[2017-11-01 10:00:36,062] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 198320: loss 0.0175
[2017-11-01 10:00:37,213] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  8.08036305e-09   2.49899164e-01   1.14136681e-01   2.99492031e-01
   2.79080600e-01   1.05440393e-02   7.36182416e-03   2.42226161e-02
   1.52630331e-02], sum to 1.0000
[2017-11-01 10:00:37,228] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.0, 44.33333333333334, 5.800000000000001, 240.0, 105.5, 783.0, 11.0, 13.89377973528664, 15.5, 22.99713654959721, 22.7, 1.0, 5.821140366287022], 
actual action is [11.0, 15.0], 
sim time next is 3680700.0000, 
raw observation next is [6.0, 44.66666666666666, 5.975, 240.0, 104.75, 779.5, 11.0, 13.8550397378455, 15.0, 23.00954388651701, 22.7, 1.0, 5.612438612416402], 
processed observation next is [1.0, 0.6086956521739131, 0.48717948717948717, 0.44666666666666655, 0.5431818181818181, 0.6666666666666666, 0.2771164021164021, 0.7795, 0.6833333333333333, 0.138550397378455, 0.25, 0.6504771943258506, 0.635, 1.0, 0.06602868955784003], 
reward next is -0.1023. 
=============================================
[2017-11-01 10:00:42,410] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12500, global step 199051: loss -130.3672
[2017-11-01 10:00:46,536] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199566: loss 75.1596
[2017-11-01 10:00:46,588] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199572: loss -90.3963
[2017-11-01 10:00:48,074] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12500, global step 199773: loss -13.4707
[2017-11-01 10:00:51,330] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200166: loss 51.8077
[2017-11-01 10:00:54,780] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12500, global step 200618: loss -2.4125
[2017-11-01 10:00:55,536] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200726: loss 45.5026
[2017-11-01 10:00:55,638] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200748: loss 0.5912
[2017-11-01 10:00:55,760] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12500, global step 200773: loss 37.1310
[2017-11-01 10:01:00,389] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 201357: loss -6.2939
[2017-11-01 10:01:00,753] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 201403: loss 1.3398
[2017-11-01 10:01:02,670] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  6.99181546e-05   1.95547551e-01   1.30302519e-01   3.32039207e-01
   3.11836302e-01   7.59354839e-03   5.62773971e-03   8.23241193e-03
   8.75079539e-03], sum to 1.0000
[2017-11-01 10:01:02,702] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 60.0, 6.575, 222.5, 91.75, 727.25, -5.0, 9.409978261045744, 10.0, 23.79895422814227, 22.7, 1.0, 0.0], 
actual action is [-5.0, 10.0], 
sim time next is 3770400.0000, 
raw observation next is [0.0, 60.00000000000001, 6.533333333333334, 223.3333333333333, 90.16666666666666, 721.8333333333333, -5.0, 9.459526587843214, 10.0, 23.80308235817295, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.3333333333333333, 0.6000000000000001, 0.593939393939394, 0.6203703703703702, 0.23853615520282184, 0.7218333333333332, 0.4166666666666667, 0.09459526587843214, 0.0, 0.6901541179086476, 0.635, 1.0, 0.0], 
reward next is -0.0473. 
=============================================
[2017-11-01 10:01:04,153] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12500, global step 201955: loss -41.4150
[2017-11-01 10:01:07,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.42038025e-03   3.52032006e-01   1.17768504e-01   2.31474951e-01
   2.95844197e-01   1.92552528e-04   1.17755299e-04   8.64782414e-05
   6.31588773e-05], sum to 1.0000
[2017-11-01 10:01:07,645] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [2.0, 48.0, 6.616666666666667, 241.6666666666667, 108.3333333333333, 796.0, 7.0, 8.877609021813395, 17.5, 23.36174286315937, 22.7, 1.0, 9.350696477693822], 
actual action is [7.0, 17.5], 
sim time next is 3852900.0000, 
raw observation next is [2.0, 48.0, 6.575, 242.5, 107.75, 792.5, 7.0, 8.761374220017698, 17.5, 23.48489405275313, 22.7, 1.0, 8.877878647051826], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.38461538461538464, 0.48, 0.5977272727272728, 0.6736111111111112, 0.28505291005291006, 0.7925, 0.6166666666666667, 0.08761374220017698, 0.375, 0.6742447026376566, 0.635, 1.0, 0.10444563114178619], 
reward next is -0.0960. 
=============================================
[2017-11-01 10:01:07,715] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 202427: loss 47.8121
[2017-11-01 10:01:09,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.08956128
  0.06662945  0.17904031  0.66476899], sum to 1.0000
[2017-11-01 10:01:09,852] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.083333333333333, 65.5, 6.025, 229.1666666666667, 0.0, 0.0, 3.0, 25.82739805127462, 13.0, 20.2869921005011, 21.5, 0.0, 8.903185851985022], 
actual action is [2.916666666666667, 18.0], 
sim time next is 3787800.0000, 
raw observation next is [-2.166666666666667, 66.0, 5.850000000000001, 228.3333333333333, 0.0, 0.0, 2.916666666666667, 26.21768877652524, 18.0, 20.23698003678451, 21.5, 0.0, 7.3049857920317], 
processed observation next is [0.0, 0.8695652173913043, 0.27777777777777773, 0.66, 0.531818181818182, 0.6342592592592591, 0.0, 0.0, 0.548611111111111, 0.2621768877652524, 0.4, 0.5118490018392254, 0.575, 0.0, 0.08594100931802], 
reward next is -0.3587. 
=============================================
[2017-11-01 10:01:10,315] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-51.77269363]
 [-52.47454071]
 [-50.21874619]
 [-50.02314377]
 [-51.1835556 ]], R is [[-53.51282883]
 [-53.37995911]
 [-53.22880936]
 [-53.05989838]
 [-52.87329483]].
[2017-11-01 10:01:12,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.74119861e-02   1.93722114e-01   3.11215252e-01   2.27294207e-01
   2.40356430e-01   1.17372793e-19   7.07375779e-20   4.14564990e-20
   4.14057844e-19], sum to 1.0000
[2017-11-01 10:01:12,415] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.0, 71.0, 7.45, 231.6666666666667, 0.0, 0.0, 1.0, 27.6777378418394, 12.0, 19.97905244871439, 21.5, 0.0, 29.59669273857909], 
actual action is [1.0, 12.0], 
sim time next is 3816900.0000, 
raw observation next is [-4.0, 71.0, 7.325, 232.5, 0.0, 0.0, 1.0, 27.97087639622897, 12.0, 19.95392472853427, 21.5, 0.0, 27.05200406709832], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.23076923076923078, 0.71, 0.6659090909090909, 0.6458333333333334, 0.0, 0.0, 0.5166666666666667, 0.2797087639622897, 0.1, 0.4976962364267134, 0.575, 0.0, 0.3182588713776273], 
reward next is -0.5456. 
=============================================
[2017-11-01 10:01:13,813] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.49501130e-16   7.75033757e-17   6.21276498e-17
   8.92657517e-17   4.11559232e-02   4.35888730e-02   5.14795035e-02
   8.63775730e-01], sum to 1.0000
[2017-11-01 10:01:13,859] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-4.0, 71.0, 7.45, 231.6666666666667, 0.0, 0.0, 1.0, 31.58299169041824, 14.5, 19.61350482924202, 21.5, 0.0, 17.6608629071345], 
actual action is [1.0, 15.0], 
sim time next is 3816900.0000, 
raw observation next is [-4.0, 71.0, 7.325, 232.5, 0.0, 0.0, 1.0, 32.41802595184645, 15.0, 19.53371222933109, 21.5, 0.0, 16.92462724679839], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.23076923076923078, 0.71, 0.6659090909090909, 0.6458333333333334, 0.0, 0.0, 0.5166666666666667, 0.3241802595184645, 0.25, 0.4766856114665545, 0.575, 0.0, 0.1991132617270399], 
reward next is -0.5911. 
=============================================
[2017-11-01 10:01:23,455] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 204562: loss -119.1612
[2017-11-01 10:01:33,633] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 205991: loss 167.3594
[2017-11-01 10:01:34,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 206179: loss 279.7584
[2017-11-01 10:01:36,042] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.60304382e-01   3.21313560e-01   1.52097717e-01   2.25087896e-01
   1.41196400e-01   1.84802569e-20   1.84870889e-21   1.55814726e-21
   4.80309491e-21], sum to 1.0000
[2017-11-01 10:01:36,108] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-2.0, 65.0, 3.141666666666667, 345.8333333333333, 0.0, 0.0, 3.0, 29.15656495264727, 15.5, 19.55747788303909, 21.5, 0.0, 34.72712070572109], 
actual action is [3.0, 15.0], 
sim time next is 3897000.0000, 
raw observation next is [-2.0, 65.0, 3.35, 345.0, 0.0, 0.0, 3.0, 28.85759168885712, 15.0, 19.6581456307928, 21.5, 0.0, 18.5874376183054], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.28205128205128205, 0.65, 0.30454545454545456, 0.9583333333333334, 0.0, 0.0, 0.55, 0.2885759168885712, 0.25, 0.4829072815396399, 0.575, 0.0, 0.2186757366859459], 
reward next is -0.5698. 
=============================================
[2017-11-01 10:01:37,356] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13000, global step 206636: loss 4.1478
[2017-11-01 10:01:40,001] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.56100963e-02   1.71328887e-01   2.89172232e-01   1.87565982e-01
   3.06322873e-01   8.66872241e-10   2.47666720e-10   5.21724719e-10
   1.32553868e-09], sum to 1.0000
[2017-11-01 10:01:40,032] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.5, 62.5, 2.6, 310.0, 0.0, 0.0, 3.583333333333333, 33.02439252641053, 11.0, 19.63672573165791, 21.5, 0.0, 2.978944074973799], 
actual action is [3.5, 10.5], 
sim time next is 3886500.0000, 
raw observation next is [-1.583333333333333, 62.91666666666667, 2.6, 311.6666666666667, 0.0, 0.0, 3.5, 33.40939178656873, 10.5, 19.60271614017788, 21.5, 0.0, 2.995403684538799], 
processed observation next is [0.16666666666666666, 1.0, 0.29273504273504275, 0.6291666666666668, 0.23636363636363636, 0.8657407407407408, 0.0, 0.0, 0.5583333333333333, 0.3340939178656873, 0.025, 0.48013580700889397, 0.575, 0.0, 0.03524004334751528], 
reward next is -0.4919. 
=============================================
[2017-11-01 10:01:41,432] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.12594196  0.21355563  0.25152254  0.1794098   0.22580764  0.00181875
  0.00045907  0.00103905  0.00044554], sum to 1.0000
[2017-11-01 10:01:41,468] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.1666666666666667, 56.25, 3.016666666666667, 310.8333333333333, 0.0, 0.0, 5.0, 14.0449750811423, 14.5, 22.13067654783586, 21.5, 0.0, 13.66803150650066], 
actual action is [4.833333333333333, 13.5], 
sim time next is 3876000.0000, 
raw observation next is [-0.3333333333333333, 57.0, 2.933333333333334, 316.6666666666667, 0.0, 0.0, 4.833333333333333, 14.3031431813831, 13.5, 22.08218459776951, 21.5, 0.0, 12.30923163811379], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.3247863247863248, 0.57, 0.2666666666666667, 0.8796296296296297, 0.0, 0.0, 0.5805555555555556, 0.143031431813831, 0.175, 0.6041092298884754, 0.575, 0.0, 0.14481448986016224], 
reward next is -0.0724. 
=============================================
[2017-11-01 10:01:41,856] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207247: loss -61.3887
[2017-11-01 10:01:41,953] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207267: loss -11.3571
[2017-11-01 10:01:44,624] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13000, global step 207665: loss 137.7861
[2017-11-01 10:01:47,050] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207997: loss 36.0619
[2017-11-01 10:01:50,214] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13000, global step 208353: loss -22.2757
[2017-11-01 10:01:50,861] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208424: loss 17.9029
[2017-11-01 10:01:51,136] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13000, global step 208454: loss -13.0525
[2017-11-01 10:01:52,177] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208563: loss -5.5497
[2017-11-01 10:01:53,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.70244049e-06   1.60603449e-05   2.78218613e-05   2.27130877e-05
   2.76550982e-05   3.51975799e-01   1.43339574e-01   3.64314228e-01
   1.40271455e-01], sum to 1.0000
[2017-11-01 10:01:53,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.916666666666667, 70.5, 5.058333333333334, 340.0, 0.0, 0.0, 2.166666666666667, 8.144433402046236, 30.0, 23.1146364049485, 21.5, 0.0, 45.05917359530945], 
actual action is [2.083333333333333, 30], 
sim time next is 3902400.0000, 
raw observation next is [-3.0, 71.0, 5.1, 340.0, 0.0, 0.0, 2.083333333333333, 8.11794016432418, 30.0, 23.11296672491874, 21.5, 0.0, 45.10281807687613], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.2564102564102564, 0.71, 0.4636363636363636, 0.9444444444444444, 0.0, 0.0, 0.5347222222222222, 0.0811794016432418, 1.0, 0.6556483362459369, 0.575, 0.0, 0.5306213891397192], 
reward next is -0.2653. 
=============================================
[2017-11-01 10:01:57,675] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 209029: loss 6.6257
[2017-11-01 10:02:00,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 209297: loss 13.3664
[2017-11-01 10:02:00,717] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   1.07771083e-25   8.86825473e-26   8.50045450e-26
   1.26962121e-25   2.07679689e-01   1.94698513e-01   2.70526677e-01
   3.27095151e-01], sum to 1.0000
[2017-11-01 10:02:00,816] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.583333333333334, 36.33333333333334, 4.308333333333333, 155.8333333333333, 62.08333333333334, 505.4166666666666, 0.5, 9.418698115108349, 20.0, 26.17252213133641, 22.7, 1.0, 37.06821522676008], 
actual action is [0.4166666666666661, 21.0], 
sim time next is 3948000.0000, 
raw observation next is [-4.666666666666666, 36.66666666666666, 4.266666666666667, 126.6666666666667, 58.16666666666666, 474.8333333333334, 0.4166666666666661, 9.335138150584806, 21.0, 26.1469223154538, 22.7, 1.0, 35.65695960314662], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.2136752136752137, 0.3666666666666666, 0.3878787878787879, 0.35185185185185197, 0.1538800705467372, 0.47483333333333344, 0.5069444444444444, 0.09335138150584806, 0.55, 0.80734611577269, 0.635, 1.0, 0.41949364238996023], 
reward next is -0.2564. 
=============================================
[2017-11-01 10:02:01,912] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13000, global step 209430: loss 7.5794
[2017-11-01 10:02:08,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.58849761e-01   1.75203949e-01   1.46223187e-01   2.72298604e-01
   2.47424290e-01   6.43726494e-08   3.68590882e-08   3.74795448e-08
   4.39546355e-08], sum to 1.0000
[2017-11-01 10:02:08,172] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-12.83333333333333, 68.0, 2.683333333333334, 66.66666666666666, 0.0, 0.0, -7.75, 16.86942669437788, 27.0, 20.72928659592232, 21.5, 0.0, 46.18369202690054], 
actual action is [-7.83333333333333, 27.0], 
sim time next is 3992100.0000, 
raw observation next is [-12.91666666666667, 68.5, 2.641666666666667, 38.33333333333334, 0.0, 0.0, -7.83333333333333, 16.99165606502231, 27.0, 20.70665167702123, 21.5, 0.0, 46.17165015779029], 
processed observation next is [0.5, 0.17391304347826086, 0.0021367521367520606, 0.685, 0.2401515151515152, 0.10648148148148151, 0.0, 0.0, 0.3694444444444445, 0.1699165606502231, 0.85, 0.5353325838510615, 0.575, 0.0, 0.5431958842092975], 
reward next is -0.4699. 
=============================================
[2017-11-01 10:02:11,241] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 210392: loss 9.0160
[2017-11-01 10:02:12,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-30.06684494]
 [-33.16914368]
 [-29.50450897]
 [-30.20557976]
 [-30.59049988]], R is [[-31.18514061]
 [-31.21664238]
 [-31.23027229]
 [-31.2299633 ]
 [-31.25660324]].
[2017-11-01 10:02:13,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-27.93852425]
 [-28.50840569]
 [-27.61357689]
 [-28.97162056]
 [-28.39127922]], R is [[-28.02784538]
 [-27.9747963 ]
 [-27.93416786]
 [-27.90642166]
 [-27.89258957]].
[2017-11-01 10:02:18,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-26.56479645]
 [-26.50396347]
 [-25.98147964]
 [-26.71784973]
 [-26.32824707]], R is [[-26.63634682]
 [-26.68344116]
 [-26.77975845]
 [-26.88154411]
 [-27.00214577]].
[2017-11-01 10:02:19,156] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.03756826  0.07139001  0.05868799  0.06308419  0.05216315  0.10955998
  0.15196978  0.33599898  0.11957766], sum to 1.0000
[2017-11-01 10:02:19,272] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-7.916666666666667, 48.66666666666666, 3.641666666666667, 350.0, 0.0, 0.0, -2.833333333333334, 6.3165293039979, 29.0, 24.03888789137333, 21.5, 0.0, 45.00376680110227], 
actual action is [-2.916666666666667, 30], 
sim time next is 3967200.0000, 
raw observation next is [-8.0, 49.0, 3.6, 350.0, 0.0, 0.0, -2.916666666666667, 6.29744363575182, 30.0, 24.02337744918846, 21.5, 0.0, 44.74974589886285], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.1282051282051282, 0.49, 0.32727272727272727, 0.9722222222222222, 0.0, 0.0, 0.4513888888888889, 0.0629744363575182, 1.0, 0.7011688724594229, 0.575, 0.0, 0.5264675988101511], 
reward next is -0.2632. 
=============================================
[2017-11-01 10:02:27,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.16107257  0.10975147  0.18589194  0.09250467  0.13093509  0.04397302
  0.09152187  0.11203573  0.07231364], sum to 1.0000
[2017-11-01 10:02:27,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-11.41666666666667, 60.08333333333333, 3.1, 355.8333333333333, 0.0, 0.0, -6.33333333333333, 8.62345671766255, 26.5, 22.18207795487276, 21.5, 0.0, 46.52471351674934], 
actual action is [-6.41666666666667, 25.5], 
sim time next is 3979800.0000, 
raw observation next is [-11.5, 60.5, 3.1, 355.0, 0.0, 0.0, -6.41666666666667, 8.56412900053889, 25.5, 22.20169198686043, 21.5, 0.0, 46.01605277025737], 
processed observation next is [0.5, 0.043478260869565216, 0.038461538461538464, 0.605, 0.2818181818181818, 0.9861111111111112, 0.0, 0.0, 0.3930555555555555, 0.08564129000538889, 0.775, 0.6100845993430214, 0.575, 0.0, 0.5413653267089102], 
reward next is -0.2707. 
=============================================
[2017-11-01 10:02:33,429] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13500, global step 213270: loss -7.3876
[2017-11-01 10:02:34,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-57.33059692]
 [-60.43803406]
 [-57.78356934]
 [-56.3335762 ]
 [-56.24343109]], R is [[-58.13358307]
 [-57.98382568]
 [-57.85903549]
 [-57.82862091]
 [-57.55138779]].
[2017-11-01 10:02:35,996] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.68387472e-04   1.52368233e-01   4.54138488e-01   1.51561275e-01
   2.41463631e-01   3.54343326e-11   2.74576785e-11   6.16788773e-11
   1.58036959e-10], sum to 1.0000
[2017-11-01 10:02:36,054] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.333333333333333, 27.0, 0.5, 16.66666666666667, 112.3333333333333, 824.0, 1.583333333333333, 9.207685414434556, 21.5, 22.40025944820407, 22.7, 1.0, 43.08633922122347], 
actual action is [1.666666666666667, 19.5], 
sim time next is 4023900.0000, 
raw observation next is [-3.25, 26.75, 0.375, 12.5, 111.5, 821.0, 1.666666666666667, 8.913896704006769, 19.5, 22.56233317937239, 22.7, 1.0, 27.38620221640329], 
processed observation next is [0.5, 0.5652173913043478, 0.25, 0.2675, 0.03409090909090909, 0.034722222222222224, 0.294973544973545, 0.821, 0.5277777777777778, 0.08913896704006768, 0.475, 0.6281166589686196, 0.635, 1.0, 0.32219061431062695], 
reward next is -0.2057. 
=============================================
[2017-11-01 10:02:41,568] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13500, global step 214381: loss -42.6190
[2017-11-01 10:02:42,461] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13500, global step 214515: loss 56.2531
[2017-11-01 10:02:44,429] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13500, global step 214810: loss 21.7289
[2017-11-01 10:02:48,123] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13500, global step 215551: loss -24.4154
[2017-11-01 10:02:48,953] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13500, global step 215729: loss 22.2019
[2017-11-01 10:02:49,025] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13500, global step 215741: loss 1.4729
[2017-11-01 10:02:50,659] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13500, global step 216084: loss 121.4455
[2017-11-01 10:02:50,659] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13500, global step 216084: loss 22.7252
[2017-11-01 10:02:51,508] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  5.98269378e-10   2.66934842e-01   3.01518321e-01   3.86802882e-01
   4.43879366e-02   1.54289482e-05   8.59799184e-06   1.38089099e-05
   3.18120292e-04], sum to 1.0000
[2017-11-01 10:02:51,527] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 30.66666666666667, 2.183333333333334, 33.33333333333333, 0.0, 0.0, -9.0, 28.79216638015314, 10.0, 19.93778111753343, 21.5, 0.0, 0.0], 
actual action is [-9.0, 10], 
sim time next is 4047300.0000, 
raw observation next is [-4.0, 30.5, 2.225, 35.0, 0.0, 0.0, -9.0, 29.61300382842623, 10.0, 19.90134042118429, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.23076923076923078, 0.305, 0.20227272727272727, 0.09722222222222222, 0.0, 0.0, 0.35, 0.2961300382842623, 0.0, 0.4950670210592145, 0.575, 0.0, 0.0], 
reward next is -0.3997. 
=============================================
[2017-11-01 10:02:51,783] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13500, global step 216260: loss 5.2893
[2017-11-01 10:02:51,945] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01592241
  0.02780349  0.17605625  0.78021783], sum to 1.0000
[2017-11-01 10:02:51,993] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 37.0, 2.6, 100.0, 0.0, 0.0, -1.0, 40.75567531257428, 15.0, 18.92137022458013, 21.5, 0.0, 11.43088949518364], 
actual action is [-1.0, 20.0], 
sim time next is 4058400.0000, 
raw observation next is [-6.0, 37.0, 2.600000000000001, 103.3333333333333, 0.0, 0.0, -1.0, 41.32270262989961, 20.0, 18.86624649371262, 21.5, 0.0, 7.975909435538517], 
processed observation next is [0.5, 1.0, 0.1794871794871795, 0.37, 0.23636363636363644, 0.2870370370370369, 0.0, 0.0, 0.48333333333333334, 0.4132270262989961, 0.5, 0.443312324685631, 0.575, 0.0, 0.09383422865339432], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:02:52,294] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13500, global step 216341: loss 91.3949
[2017-11-01 10:02:54,602] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13500, global step 216711: loss -49.8258
[2017-11-01 10:02:54,955] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13500, global step 216770: loss 3.4491
[2017-11-01 10:02:56,519] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13500, global step 217064: loss -24.8919
[2017-11-01 10:02:56,747] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  4.65969592e-01   1.64015591e-01   9.99216586e-02   1.61586136e-01
   1.08506978e-01   5.07108136e-13   2.11465096e-13   8.07271079e-13
   2.10871511e-12], sum to 1.0000
[2017-11-01 10:02:56,829] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.916666666666667, 25.83333333333333, 2.141666666666667, 68.33333333333333, 0.0, 0.0, -7.833333333333333, 16.49284067925259, 10.0, 22.25550197749629, 22.7, 1.0, 0.0], 
actual action is [-7.916666666666667, 10], 
sim time next is 4039200.0000, 
raw observation next is [-3.0, 26.0, 2.1, 70.0, 0.0, 0.0, -7.916666666666667, 17.22905868111532, 10.0, 22.12227922209049, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.2564102564102564, 0.26, 0.19090909090909092, 0.19444444444444445, 0.0, 0.0, 0.3680555555555555, 0.1722905868111532, 0.0, 0.6061139611045245, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:03:01,349] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13500, global step 217875: loss -32.6447
[2017-11-01 10:03:05,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13500, global step 218571: loss 8.8714
[2017-11-01 10:03:10,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.10187422e-32   8.87600697e-18   7.32217962e-18   1.04789391e-17
   5.34950565e-18   3.91105473e-01   1.63156480e-01   3.09843451e-01
   1.35894507e-01], sum to 1.0000
[2017-11-01 10:03:10,128] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [4.0, 35.0, 2.35, 205.0, 98.0, 728.0, 9.0, 8.605783216557564, 27.5, 26.37735573346142, 22.7, 1.0, 35.80302211165093], 
actual action is [9.0, 29.5], 
sim time next is 4115700.0000, 
raw observation next is [4.0, 35.0, 2.475, 202.5, 97.0, 719.75, 9.0, 8.83187077489404, 29.5, 26.45841149008158, 22.7, 1.0, 35.36626170614698], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.4358974358974359, 0.35, 0.225, 0.5625, 0.2566137566137566, 0.71975, 0.65, 0.0883187077489404, 0.975, 0.8229205745040791, 0.635, 1.0, 0.4160736671311409], 
reward next is -0.2522. 
=============================================
[2017-11-01 10:03:12,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.52487448e-04   2.02876955e-01   2.47144222e-01   2.55983531e-01
   2.91625053e-01   5.76354330e-04   2.82513211e-04   4.90708044e-04
   3.68140725e-04], sum to 1.0000
[2017-11-01 10:03:13,057] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 28.0, 2.6, 140.0, 120.5, 828.5, 5.833333333333333, 6.465903436910732, 24.0, 25.72040201529547, 22.7, 1.0, 43.57441137094891], 
actual action is [6.0, 22.0], 
sim time next is 4104300.0000, 
raw observation next is [1.166666666666667, 28.08333333333333, 2.641666666666667, 150.8333333333333, 120.4166666666667, 830.5833333333333, 6.0, 6.541606271133309, 22.0, 25.75680257438624, 22.7, 1.0, 36.27403131028183], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.3632478632478633, 0.28083333333333327, 0.2401515151515152, 0.41898148148148134, 0.318562610229277, 0.8305833333333332, 0.6, 0.0654160627113331, 0.6, 0.787840128719312, 0.635, 1.0, 0.4267533095327274], 
reward next is -0.2461. 
=============================================
[2017-11-01 10:03:15,561] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.41151278e-02   1.43714517e-01   2.29501024e-01   2.64541268e-01
   3.08121324e-01   1.51698043e-06   1.00214277e-06   1.21058690e-06
   2.95419341e-06], sum to 1.0000
[2017-11-01 10:03:15,616] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-3.0, 49.99999999999999, 3.058333333333334, 339.9999999999999, 0.0, 0.0, 2.0, 18.06488840699341, 20.0, 21.1942829075038, 21.5, 0.0, 25.95768581347112], 
actual action is [2.0, 20.0], 
sim time next is 4158600.0000, 
raw observation next is [-3.0, 50.0, 3.016666666666667, 340.0000000000001, 0.0, 0.0, 2.0, 18.39171300101827, 20.0, 21.18776330792696, 21.5, 0.0, 24.73730088451677], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.5, 0.2742424242424243, 0.9444444444444448, 0.0, 0.0, 0.5333333333333333, 0.1839171300101827, 0.5, 0.5593881653963481, 0.575, 0.0, 0.2910270692296091], 
reward next is -0.2236. 
=============================================
[2017-11-01 10:03:15,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-28.37966919]
 [-26.81776237]
 [-28.77066422]
 [-27.35889435]
 [-20.96347809]], R is [[-29.20591354]
 [-29.0212841 ]
 [-28.84373474]
 [-28.67288399]
 [-28.50943184]].
[2017-11-01 10:03:16,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.27672517e-01   1.80175245e-01   1.98300928e-01   1.28185183e-01
   2.65664876e-01   3.19482893e-07   2.50543167e-07   2.84301422e-07
   3.74757860e-07], sum to 1.0000
[2017-11-01 10:03:17,004] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.0, 35.5, 1.05, 155.0, 0.0, 0.0, -2.0, 7.128942753414346, 10.0, 25.24908962961016, 22.7, 1.0, 0.0], 
actual action is [-2.0, 10], 
sim time next is 4127700.0000, 
raw observation next is [3.0, 35.75, 1.225, 180.8333333333333, 0.0, 0.0, -2.0, 6.966441041692078, 10.0, 25.08174463753188, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.41025641025641024, 0.3575, 0.11136363636363637, 0.5023148148148147, 0.0, 0.0, 0.4666666666666667, 0.06966441041692079, 0.0, 0.754087231876594, 0.635, 1.0, 0.0], 
reward next is -0.0348. 
=============================================
[2017-11-01 10:03:18,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.97812908e-03   2.61050642e-01   2.35343516e-01   1.85480192e-01
   3.15146744e-01   2.39726489e-07   1.54868815e-07   1.99256448e-07
   2.00776341e-07], sum to 1.0000
[2017-11-01 10:03:18,365] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [4.0, 35.0, 2.475, 202.5, 97.0, 719.75, 9.0, 8.3389432541197, 21.5, 26.16279903377369, 22.7, 1.0, 10.27211213492352], 
actual action is [9.0, 19.5], 
sim time next is 4116000.0000, 
raw observation next is [4.0, 35.0, 2.6, 200.0, 96.0, 711.5, 9.0, 8.374949129909746, 19.5, 26.15572164458222, 22.7, 1.0, 9.751201378745778], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.4358974358974359, 0.35, 0.23636363636363636, 0.5555555555555556, 0.25396825396825395, 0.7115, 0.65, 0.08374949129909746, 0.475, 0.807786082229111, 0.635, 1.0, 0.11472001622053857], 
reward next is -0.0992. 
=============================================
[2017-11-01 10:03:21,330] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14000, global step 221256: loss -33.4752
[2017-11-01 10:03:28,627] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14000, global step 222489: loss -31.9885
[2017-11-01 10:03:31,768] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14000, global step 222901: loss -9.7626
[2017-11-01 10:03:32,920] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14000, global step 223031: loss -9.3560
[2017-11-01 10:03:37,427] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.55054346e-11   2.59967695e-04   3.03099427e-04   5.29865967e-04
   4.54118301e-04   3.04728746e-01   1.55526266e-01   2.39271939e-01
   2.98925966e-01], sum to 1.0000
[2017-11-01 10:03:37,530] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.0, 40.33333333333333, 3.725, 259.1666666666666, 198.25, 330.6666666666667, 7.0, 7.094412669368164, 30.0, 25.66087536341036, 22.7, 1.0, 48.43298989906191], 
actual action is [7.0, 30], 
sim time next is 4198200.0000, 
raw observation next is [2.0, 40.66666666666667, 3.85, 258.3333333333334, 196.0, 282.3333333333333, 7.0, 7.112007367663656, 30.0, 25.67141814236387, 22.7, 1.0, 48.85382445601509], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.38461538461538464, 0.40666666666666673, 0.35000000000000003, 0.7175925925925929, 0.5185185185185185, 0.2823333333333333, 0.6166666666666667, 0.07112007367663656, 1.0, 0.7835709071181934, 0.635, 1.0, 0.5747508759531187], 
reward next is -0.3229. 
=============================================
[2017-11-01 10:03:38,196] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14000, global step 223622: loss 6.2814
[2017-11-01 10:03:38,214] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14000, global step 223622: loss -15.9683
[2017-11-01 10:03:43,961] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14000, global step 224215: loss -5.5079
[2017-11-01 10:03:45,111] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14000, global step 224318: loss 31.1761
[2017-11-01 10:03:47,367] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14000, global step 224571: loss 29.4550
[2017-11-01 10:03:47,766] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14000, global step 224625: loss -3.7762
[2017-11-01 10:03:47,891] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14000, global step 224630: loss 51.7885
[2017-11-01 10:03:49,459] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14000, global step 224871: loss 42.3882
[2017-11-01 10:03:50,897] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14000, global step 225051: loss -38.4507
[2017-11-01 10:03:51,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.60096988e-06   1.08453422e-03   1.28234713e-03   2.07539764e-03
   1.94941764e-03   3.33034843e-01   3.46142977e-01   1.71011016e-01
   1.43415838e-01], sum to 1.0000
[2017-11-01 10:03:51,290] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [7.0, 53.25, 6.325, 257.5, 171.0, 749.5, 12.0, 9.782430091146216, 17.0, 23.62499153712485, 22.7, 1.0, 6.560610498229337], 
actual action is [12.0, 19.0], 
sim time next is 4281600.0000, 
raw observation next is [7.0, 53.66666666666667, 6.366666666666667, 256.6666666666667, 176.6666666666667, 738.6666666666666, 12.0, 9.851118128972132, 19.0, 23.60489999438986, 22.7, 1.0, 6.364070774773185], 
processed observation next is [1.0, 0.5652173913043478, 0.5128205128205128, 0.5366666666666667, 0.5787878787878789, 0.712962962962963, 0.46737213403880085, 0.7386666666666666, 0.7, 0.09851118128972132, 0.45, 0.680244999719493, 0.635, 1.0, 0.07487142087968453], 
reward next is -0.0867. 
=============================================
[2017-11-01 10:03:51,330] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14000, global step 225098: loss -10.0457
[2017-11-01 10:03:54,517] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14000, global step 225560: loss -158.4668
[2017-11-01 10:03:55,031] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.35195011  0.10437652  0.15936175  0.19725448  0.16684158  0.00690268
  0.00521591  0.00605906  0.00203791], sum to 1.0000
[2017-11-01 10:03:55,137] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.75, 45.75, 5.95, 227.5, 0.0, 0.0, 7.666666666666667, 5.87827976763591, 24.0, 24.39550160018748, 21.5, 0.0, 38.84563014838135], 
actual action is [7.75, 23.5], 
sim time next is 4240200.0000, 
raw observation next is [2.833333333333333, 45.5, 5.866666666666666, 228.3333333333333, 0.0, 0.0, 7.75, 5.896035615288253, 23.5, 24.40327201832467, 21.5, 0.0, 33.29092441640067], 
processed observation next is [1.0, 0.043478260869565216, 0.40598290598290593, 0.455, 0.5333333333333333, 0.6342592592592591, 0.0, 0.0, 0.6291666666666667, 0.058960356152882525, 0.675, 0.7201636009162335, 0.575, 0.0, 0.39165793431059615], 
reward next is -0.1958. 
=============================================
[2017-11-01 10:03:57,932] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.04247221e-01   2.21272290e-01   1.26986519e-01   2.99047530e-01
   1.48446426e-01   6.22866736e-09   7.01516445e-09   3.20228266e-09
   2.26321761e-09], sum to 1.0000
[2017-11-01 10:03:57,970] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.825, 40.58333333333333, 3.541666666666667, 264.1666666666667, 22.0, 149.4166666666667, -3.15, 13.35735745047294, 10.0, 22.33827731851301, 22.7, 1.0, 0.0], 
actual action is [-3.175, 10], 
sim time next is 4210800.0000, 
raw observation next is [1.8, 40.66666666666667, 3.533333333333333, 263.3333333333333, 20.0, 135.8333333333333, -3.175, 14.14264375625597, 10.0, 22.33405339974918, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.3794871794871795, 0.40666666666666673, 0.3212121212121212, 0.7314814814814814, 0.05291005291005291, 0.13583333333333328, 0.44708333333333333, 0.14142643756255968, 0.0, 0.616702669987459, 0.635, 1.0, 0.0], 
reward next is -0.0707. 
=============================================
[2017-11-01 10:04:00,551] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14000, global step 226649: loss -148.8192
[2017-11-01 10:04:06,234] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-24.77763557]
 [-25.91937065]
 [-25.24244499]
 [-25.4759655 ]
 [-26.83245468]], R is [[-24.45602417]
 [-24.43426323]
 [-24.42883682]
 [-24.4368782 ]
 [-24.51498222]].
[2017-11-01 10:04:07,516] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.62076995e-01   2.63623416e-01   1.61339208e-01   1.59749359e-01
   2.53211021e-01   3.20327875e-10   3.20362098e-10   1.33426617e-10
   4.55972926e-10], sum to 1.0000
[2017-11-01 10:04:07,551] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [6.999999999999999, 52.0, 5.191666666666666, 250.8333333333333, 120.4166666666667, 836.5833333333333, 2.0, 10.76554425658882, 10.0, 23.07903057537999, 22.7, 1.0, 0.0], 
actual action is [1.9999999999999991, 10.0], 
sim time next is 4277400.0000, 
raw observation next is [7.0, 52.0, 5.283333333333333, 251.6666666666667, 120.3333333333333, 838.6666666666667, 1.999999999999999, 11.04042930216379, 10.0, 23.01770141449595, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.5128205128205128, 0.52, 0.4803030303030303, 0.6990740740740742, 0.3183421516754849, 0.8386666666666668, 0.5333333333333333, 0.1104042930216379, 0.0, 0.6508850707247975, 0.635, 1.0, 0.0], 
reward next is -0.0552. 
=============================================
[2017-11-01 10:04:09,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-23.88332748]
 [-25.26176834]
 [-23.25027466]
 [-23.55736351]
 [-24.63157654]], R is [[-23.34902191]
 [-23.3866539 ]
 [-23.44240379]
 [-23.51659966]
 [-23.64398384]].
[2017-11-01 10:04:12,638] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 228395: loss -10.8163
[2017-11-01 10:04:16,212] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-23.77286148]
 [-23.55391312]
 [-22.28261757]
 [-22.80594444]
 [-22.40909767]], R is [[-24.81022835]
 [-25.56212616]
 [-26.3065052 ]
 [-27.04343987]
 [-27.77300644]].
[2017-11-01 10:04:20,016] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 229615: loss -3.1607
[2017-11-01 10:04:25,406] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 230663: loss 284.4091
[2017-11-01 10:04:25,796] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 230748: loss 29.7482
[2017-11-01 10:04:29,211] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 231374: loss -15.1508
[2017-11-01 10:04:29,389] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.18529657e-01   2.07057640e-01   2.18803257e-01   2.07120836e-01
   1.48488596e-01   1.78836666e-12   2.14245310e-12   1.29542481e-12
   3.80102200e-12], sum to 1.0000
[2017-11-01 10:04:29,436] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.275, 74.25, 6.075, 210.0, 0.0, 0.0, 9.25, 19.05399034600629, 18.5, 20.83064422294228, 21.5, 0.0, 19.57211239852862], 
actual action is [9.275, 18.5], 
sim time next is 4324800.0000, 
raw observation next is [4.300000000000001, 74.0, 6.033333333333333, 210.0, 0.0, 0.0, 9.275, 18.82695176707241, 18.5, 20.91459790121405, 21.5, 0.0, 18.67029802059175], 
processed observation next is [0.0, 0.043478260869565216, 0.4435897435897436, 0.74, 0.5484848484848485, 0.5833333333333334, 0.0, 0.0, 0.6545833333333333, 0.18826951767072408, 0.425, 0.5457298950607026, 0.575, 0.0, 0.21965056494813825], 
reward next is -0.2562. 
=============================================
[2017-11-01 10:04:30,249] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14500, global step 231612: loss 57.5370
[2017-11-01 10:04:31,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.07692413  0.12482066  0.11320765  0.12783067  0.13638815  0.13199414
  0.13518359  0.07736881  0.07628228], sum to 1.0000
[2017-11-01 10:04:31,258] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [14.35, 31.25, 4.475000000000001, 250.0, 175.0, 682.25, 9.4, 5.777513147406575, 10.0, 23.70744311577221, 22.7, 1.0, 0.0], 
actual action is [9.35, 10.0], 
sim time next is 4371600.0000, 
raw observation next is [14.3, 31.33333333333334, 4.500000000000001, 250.0, 181.6666666666667, 664.5, 9.35, 5.712796266876499, 10.0, 23.81676088403978, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.7000000000000001, 0.3133333333333334, 0.40909090909090917, 0.6944444444444444, 0.48059964726631405, 0.6645, 0.6558333333333334, 0.057127962668764985, 0.0, 0.690838044201989, 0.635, 1.0, 0.0], 
reward next is -0.0286. 
=============================================
[2017-11-01 10:04:33,729] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 232357: loss 6.0385
[2017-11-01 10:04:33,933] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 232406: loss -1.9604
[2017-11-01 10:04:34,050] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14500, global step 232435: loss 44.3001
[2017-11-01 10:04:34,316] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14500, global step 232488: loss 86.9622
[2017-11-01 10:04:34,413] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.38824964e-01   2.81095594e-01   1.60258785e-01   1.74813420e-01
   1.45007253e-01   1.04249231e-11   4.52252558e-12   5.53351028e-12
   4.86256044e-12], sum to 1.0000
[2017-11-01 10:04:34,438] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [3.525, 69.5, 5.200000000000001, 217.5, 0.0, 0.0, -1.45, 14.44592337998848, 10.0, 21.61411324089606, 21.5, 0.0, 0.0], 
actual action is [-1.475, 10], 
sim time next is 4339200.0000, 
raw observation next is [3.5, 69.66666666666667, 5.133333333333334, 216.6666666666667, 0.0, 0.0, -1.475, 16.17165333803063, 10.0, 21.53213814555431, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.4230769230769231, 0.6966666666666668, 0.46666666666666673, 0.601851851851852, 0.0, 0.0, 0.47541666666666665, 0.1617165333803063, 0.0, 0.5766069072777155, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 10:04:35,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.12335648  0.17578967  0.15728197  0.19306497  0.20090443  0.04722822
  0.05257445  0.02640143  0.0233984 ], sum to 1.0000
[2017-11-01 10:04:35,291] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [9.075, 45.75, 3.725, 190.0, 109.0, 702.75, 3.766666666666666, 10.48054314870797, 10.0, 22.65143723309749, 22.7, 1.0, 0.0], 
actual action is [4.074999999999999, 10.0], 
sim time next is 4355400.0000, 
raw observation next is [9.383333333333333, 44.5, 3.683333333333333, 190.0, 109.6666666666667, 711.3333333333333, 4.074999999999999, 10.33659448678903, 10.0, 22.75040680198359, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5739316239316239, 0.445, 0.33484848484848484, 0.5277777777777778, 0.2901234567901235, 0.7113333333333333, 0.5679166666666667, 0.1033659448678903, 0.0, 0.6375203400991796, 0.635, 1.0, 0.0], 
reward next is -0.0517. 
=============================================
[2017-11-01 10:04:35,335] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 232703: loss 82.6808
[2017-11-01 10:04:36,508] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 233002: loss 112.6592
[2017-11-01 10:04:37,295] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 233186: loss 5.3626
[2017-11-01 10:04:37,841] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 233316: loss 5.7526
[2017-11-01 10:04:38,602] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-30.73591042]
 [-29.43274498]
 [-31.11738777]
 [-29.69356155]
 [-29.92407036]], R is [[-30.27157021]
 [-30.03435326]
 [-29.79881096]
 [-29.56492615]
 [-29.33267784]].
[2017-11-01 10:04:39,876] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 233851: loss 81.2521
[2017-11-01 10:04:42,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.89354795e-01   2.41015568e-01   1.16218969e-01   1.02720290e-01
   1.50690258e-01   3.99062863e-08   2.65091913e-08   1.69981096e-08
   1.31022926e-08], sum to 1.0000
[2017-11-01 10:04:42,660] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [1.125, 85.16666666666667, 5.641666666666667, 265.8333333333333, 172.1666666666667, 40.58333333333334, 6.15, 10.9419262633796, 11.5, 22.61200659225986, 22.7, 1.0, 28.18975279587653], 
actual action is [6.125, 11.5], 
sim time next is 4441200.0000, 
raw observation next is [1.1, 85.33333333333333, 5.533333333333333, 266.6666666666667, 179.3333333333333, 50.16666666666666, 6.125, 10.67395744672466, 11.5, 22.70104515557143, 22.7, 1.0, 20.99786385410648], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.36153846153846153, 0.8533333333333333, 0.503030303030303, 0.7407407407407408, 0.47442680776014096, 0.05016666666666666, 0.6020833333333333, 0.1067395744672466, 0.075, 0.6350522577785714, 0.635, 1.0, 0.2470336924012527], 
reward next is -0.1769. 
=============================================
[2017-11-01 10:04:46,380] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 235111: loss 77.4379
[2017-11-01 10:04:47,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.94996044e-01   3.47162187e-01   1.09026283e-01   1.50460705e-01
   1.98354125e-01   1.23552951e-07   7.59771979e-08   1.37057299e-07
   2.66354419e-07], sum to 1.0000
[2017-11-01 10:04:47,769] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [9.325000000000001, 61.08333333333333, 4.833333333333333, 250.0, 0.0, 0.0, 4.4, 11.42848534423093, 10.0, 21.9411833185234, 22.7, 1.0, 0.0], 
actual action is [4.325000000000001, 10.0], 
sim time next is 4399800.0000, 
raw observation next is [9.25, 61.16666666666667, 4.866666666666667, 250.0, 0.0, 0.0, 4.325000000000001, 11.64890026257699, 10.0, 21.91237214818698, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.5705128205128205, 0.6116666666666667, 0.44242424242424244, 0.6944444444444444, 0.0, 0.0, 0.5720833333333334, 0.1164890026257699, 0.0, 0.5956186074093489, 0.635, 1.0, 0.0], 
reward next is -0.0582. 
=============================================
[2017-11-01 10:04:48,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.19506800e-01   4.12867874e-01   1.10540129e-01   1.53048828e-01
   1.04036331e-01   5.17528745e-15   2.81508605e-15   1.03076896e-14
   1.87404396e-14], sum to 1.0000
[2017-11-01 10:04:48,225] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [6.508333333333333, 65.41666666666666, 6.066666666666666, 260.0, 0.0, 0.0, 1.566666666666667, 17.46823356727818, 10.0, 20.42766462005275, 21.5, 0.0, 0.0], 
actual action is [1.5083333333333329, 10.0], 
sim time next is 4411800.0000, 
raw observation next is [6.449999999999999, 65.5, 6.1, 260.0, 0.0, 0.0, 1.508333333333333, 17.71128685534827, 10.0, 20.40700067440525, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.4987179487179487, 0.655, 0.5545454545454546, 0.7222222222222222, 0.0, 0.0, 0.5251388888888889, 0.1771128685534827, 0.0, 0.5203500337202625, 0.575, 0.0, 0.0], 
reward next is -0.2732. 
=============================================
[2017-11-01 10:04:48,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-33.28151703]
 [-34.67434692]
 [-32.04094696]
 [-32.69182587]
 [-31.29013824]], R is [[-33.31673431]
 [-33.18214035]
 [-33.07878876]
 [-33.02182388]
 [-33.01534271]].
[2017-11-01 10:04:50,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.19454139e-01   4.54210281e-01   8.36494789e-02   1.51918679e-01
   9.07674059e-02   3.07641208e-17   1.45155424e-17   3.82106952e-17
   1.79018296e-16], sum to 1.0000
[2017-11-01 10:04:50,275] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [6.866666666666666, 64.83333333333333, 5.866666666666667, 259.1666666666666, 0.0, 0.0, 1.933333333333334, 13.03527926333935, 10.0, 22.05091602009044, 21.5, 0.0, 0.0], 
actual action is [1.8666666666666663, 10], 
sim time next is 4410000.0000, 
raw observation next is [6.8, 65.0, 5.9, 260.0, 0.0, 0.0, 1.866666666666666, 13.29906555525771, 10.0, 22.01732060528247, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.5076923076923077, 0.65, 0.5363636363636364, 0.7222222222222222, 0.0, 0.0, 0.5311111111111111, 0.1329906555525771, 0.0, 0.6008660302641236, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 10:04:50,734] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.84469992e-01   4.19932127e-01   6.19958974e-02   1.63252711e-01
   7.03492388e-02   3.84885772e-23   1.78361451e-23   2.98799464e-23
   2.35160319e-22], sum to 1.0000
[2017-11-01 10:04:50,774] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [3.975, 67.75, 7.225, 267.5, 0.0, 0.0, 9.033333333333333, 20.68435376800575, 17.5, 20.16600437965505, 21.5, 0.0, 9.797805382270692], 
actual action is [8.975, 15.5], 
sim time next is 4423800.0000, 
raw observation next is [3.916666666666666, 67.83333333333334, 7.25, 268.3333333333333, 0.0, 0.0, 8.975, 21.00622288404882, 15.5, 20.12760019609453, 21.5, 0.0, 9.558981497963021], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.4337606837606837, 0.6783333333333335, 0.6590909090909091, 0.7453703703703703, 0.0, 0.0, 0.6495833333333334, 0.2100622288404882, 0.275, 0.5063800098047265, 0.575, 0.0, 0.11245860585838849], 
reward next is -0.3993. 
=============================================
[2017-11-01 10:04:51,311] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 236571: loss -21.1987
[2017-11-01 10:04:51,405] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-33.67971802]
 [-34.87842941]
 [-35.92493439]
 [-33.56637573]
 [-34.3962059 ]], R is [[-32.90667343]
 [-32.63760376]
 [-32.3704834 ]
 [-32.1053009 ]
 [-31.84207344]].
[2017-11-01 10:04:54,347] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 237532: loss -63.0310
[2017-11-01 10:04:58,000] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 238470: loss -18.3950
[2017-11-01 10:04:58,703] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-19.94242287]
 [-18.84494591]
 [-18.93212318]
 [-19.10448647]
 [-19.61531258]], R is [[-20.7181015 ]
 [-20.70405006]
 [-20.55597115]
 [-20.40799332]
 [-20.26013756]].
[2017-11-01 10:05:00,446] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   3.84304215e-25   1.18877226e-24   3.89642018e-25
   7.15939984e-25   3.70410532e-01   1.01261511e-01   1.67314157e-01
   3.61013800e-01], sum to 1.0000
[2017-11-01 10:05:00,505] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 8.2, 292.5, 0.0, 0.0, 5.0, 13.75939066838923, 10.5, 21.76355033557564, 22.7, 1.0, 53.79109044234391], 
actual action is [5.0, 11.0], 
sim time next is 4476000.0000, 
raw observation next is [0.0, 72.0, 8.2, 293.3333333333334, 0.0, 0.0, 5.0, 13.9229147480523, 11.0, 21.672943343087, 22.7, 1.0, 33.4911819316517], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3333333333333333, 0.72, 0.7454545454545454, 0.8148148148148151, 0.0, 0.0, 0.5833333333333334, 0.139229147480523, 0.05, 0.5836471671543499, 0.635, 1.0, 0.39401390507825534], 
reward next is -0.2666. 
=============================================
[2017-11-01 10:05:01,019] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15000, global step 239258: loss -0.1658
[2017-11-01 10:05:01,424] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 239363: loss 18.3491
[2017-11-01 10:05:02,003] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 239552: loss 2.9531
[2017-11-01 10:05:03,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.30574214e-01   2.05198705e-01   1.09828249e-01   9.19976681e-02
   2.62401074e-01   6.18670740e-11   2.55413538e-11   2.76990809e-11
   5.06410400e-11], sum to 1.0000
[2017-11-01 10:05:03,171] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [2.0, 49.66666666666666, 4.1, 310.0, 126.25, 0.0, 7.0, 13.72453555103155, 15.0, 22.34615855658289, 22.7, 1.0, 21.77683920010637], 
actual action is [7.0, 15.0], 
sim time next is 4537800.0000, 
raw observation next is [2.0, 50.0, 4.1, 310.0, 127.0, 0.0, 7.0, 13.7831596829196, 15.0, 22.28831694800894, 22.7, 1.0, 13.05908171534097], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.38461538461538464, 0.5, 0.3727272727272727, 0.8611111111111112, 0.335978835978836, 0.0, 0.6166666666666667, 0.137831596829196, 0.25, 0.6144158474004471, 0.635, 1.0, 0.15363625547459964], 
reward next is -0.1457. 
=============================================
[2017-11-01 10:05:04,722] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 240353: loss 0.1203
[2017-11-01 10:05:04,794] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 240371: loss -29.3368
[2017-11-01 10:05:04,958] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15000, global step 240411: loss 35.2013
[2017-11-01 10:05:05,069] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15000, global step 240441: loss -3.4528
[2017-11-01 10:05:05,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  5.81286550e-01   1.14271894e-01   6.13466650e-02   6.69477582e-02
   1.76147178e-01   9.43742653e-12   4.36830043e-12   5.11993442e-12
   5.04725298e-12], sum to 1.0000
[2017-11-01 10:05:05,778] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.0, 75.0, 9.75, 290.0, 25.0, 55.0, 5.0, 17.82099620133727, 12.0, 21.17077713071845, 22.7, 1.0, 20.90113452230597], 
actual action is [-5.0, 10.0], 
sim time next is 4469700.0000, 
raw observation next is [0.0, 74.5, 9.325, 290.0, 22.91666666666666, 50.41666666666666, -5.0, 18.30666625882676, 10.0, 21.12917690687522, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.3333333333333333, 0.745, 0.8477272727272727, 0.8055555555555556, 0.06062610229276894, 0.05041666666666666, 0.4166666666666667, 0.1830666625882676, 0.0, 0.556458845343761, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:05:05,985] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 240694: loss -14.4074
[2017-11-01 10:05:06,083] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 240723: loss 33.4454
[2017-11-01 10:05:06,530] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 240855: loss 23.0384
[2017-11-01 10:05:06,589] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 240870: loss 59.5042
[2017-11-01 10:05:07,384] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 241072: loss -92.2485
[2017-11-01 10:05:08,253] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.39570367e-01   1.39491141e-01   1.30413473e-01   6.09987155e-02
   2.29526266e-01   1.82134815e-17   1.79393174e-17   1.39592221e-17
   1.30468146e-17], sum to 1.0000
[2017-11-01 10:05:08,287] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, 7.0, 22.24762436270647, 20.5, 20.89660042177306, 22.7, 1.0, 2.790922552115048], 
actual action is [7.0, 15.5], 
sim time next is 4557900.0000, 
raw observation next is [2.0, 52.0, 3.1, 339.9999999999999, 0.0, 0.0, 7.0, 23.09586901088577, 15.5, 20.84364728926304, 22.7, 1.0, 2.772409077362977], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.38461538461538464, 0.52, 0.2818181818181818, 0.9444444444444441, 0.0, 0.0, 0.6166666666666667, 0.23095869010885772, 0.275, 0.5421823644631519, 0.635, 1.0, 0.032616577380740905], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:05:11,770] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 242111: loss 21.4410
[2017-11-01 10:05:16,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.17501536e-01   1.48191959e-01   5.70599101e-02   3.25732201e-01
   2.51514375e-01   5.84317949e-16   2.67740762e-16   2.56934316e-16
   2.77651206e-16], sum to 1.0000
[2017-11-01 10:05:16,284] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, 7.0, 11.91653446601869, 11.0, 22.40897709901927, 22.7, 1.0, 30.21204071724903], 
actual action is [7.0, 10.5], 
sim time next is 4559400.0000, 
raw observation next is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, 7.0, 12.10548811960106, 10.5, 22.41948797514575, 22.7, 1.0, 28.02748868667915], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.38461538461538464, 0.52, 0.2818181818181818, 0.9444444444444444, 0.0, 0.0, 0.6166666666666667, 0.12105488119601061, 0.025, 0.6209743987572874, 0.635, 1.0, 0.3297351610197547], 
reward next is -0.2254. 
=============================================
[2017-11-01 10:05:16,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.09726954e-01   2.23367274e-01   5.42148203e-02   2.51545101e-01
   1.61145836e-01   4.47353370e-14   2.39743477e-14   1.83347109e-14
   1.66939420e-14], sum to 1.0000
[2017-11-01 10:05:16,913] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.41666666666666, 0.0, 0.0, 0.0, 0.0, 7.0, 13.47631054453567, 24.5, 21.13479325144272, 21.5, 0.0, 46.39345269474633], 
actual action is [7.0, 19.5], 
sim time next is 4565400.0000, 
raw observation next is [2.0, 52.83333333333334, 0.0, 0.0, 0.0, 0.0, 7.0, 12.44327289671397, 19.5, 21.45134190079159, 21.5, 0.0, 36.26788063388211], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.38461538461538464, 0.5283333333333334, 0.0, 0.0, 0.0, 0.0, 0.6166666666666667, 0.1244327289671397, 0.475, 0.5725670950395795, 0.575, 0.0, 0.42668094863390715], 
reward next is -0.2255. 
=============================================
[2017-11-01 10:05:17,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.31423488e-01   9.33554545e-02   1.96239173e-01   4.12293434e-01
   1.66688398e-01   2.05552101e-13   7.53580751e-14   8.32002314e-14
   5.06561915e-13], sum to 1.0000
[2017-11-01 10:05:17,968] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.083333333333333, 60.66666666666666, 0.0, 0.0, 0.0, 0.0, -3.833333333333333, 20.66012633298211, 10.0, 21.21011503703477, 21.5, 0.0, 0.0], 
actual action is [-3.916666666666667, 10], 
sim time next is 4572000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, -3.916666666666667, 21.65716141004868, 10.0, 21.09642240118504, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.4347222222222222, 0.2165716141004868, 0.0, 0.5548211200592521, 0.575, 0.0, 0.0], 
reward next is -0.1009. 
=============================================
[2017-11-01 10:05:18,104] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.21351570e-01   1.06873639e-01   1.67690024e-01   3.97362560e-01
   2.06722274e-01   3.28082657e-12   1.27284815e-12   1.55790875e-12
   1.03965786e-11], sum to 1.0000
[2017-11-01 10:05:18,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, -4.0, 22.96183329918265, 10.0, 20.98007143527548, 21.5, 0.0, 0.0], 
actual action is [-4.0, 10], 
sim time next is 4572600.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, -4.0, 23.91539565994147, 10.0, 20.88016072792311, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.43333333333333335, 0.2391539565994147, 0.0, 0.5440080363961555, 0.575, 0.0, 0.0], 
reward next is -0.1550. 
=============================================
[2017-11-01 10:05:19,228] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 244406: loss -8.4920
[2017-11-01 10:05:21,091] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  3.73363882e-01   2.94338375e-01   4.37708609e-02   1.17160134e-01
   1.71366736e-01   4.30844770e-12   1.92647482e-12   1.57476788e-12
   1.23924102e-12], sum to 1.0000
[2017-11-01 10:05:21,115] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.583333333333333, 50.25, 2.725, 88.33333333333334, 121.8333333333333, 835.1666666666666, -2.5, 12.14078634403226, 10.0, 23.08882899344923, 22.7, 1.0, 0.0], 
actual action is [-2.416666666666667, 10], 
sim time next is 4621200.0000, 
raw observation next is [2.666666666666667, 50.0, 2.6, 86.66666666666666, 121.6666666666667, 837.3333333333334, -2.416666666666667, 12.07860306168, 10.0, 23.10017800186785, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.4017094017094017, 0.5, 0.23636363636363636, 0.24074074074074073, 0.32186948853615527, 0.8373333333333334, 0.4597222222222222, 0.1207860306168, 0.0, 0.6550089000933925, 0.635, 1.0, 0.0], 
reward next is -0.0604. 
=============================================
[2017-11-01 10:05:22,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 245374: loss -9.1211
[2017-11-01 10:05:23,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.98505807e-01   2.22405136e-01   2.39022076e-02   1.20165445e-01
   2.35021368e-01   1.54155714e-13   6.79018067e-14   3.91794039e-14
   5.52518135e-14], sum to 1.0000
[2017-11-01 10:05:23,302] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [0.3333333333333333, 58.66666666666666, 3.183333333333334, 108.3333333333333, 140.6666666666667, 681.0, -4.833333333333333, 14.83035480704675, 10.0, 22.08956749388489, 22.7, 1.0, 0.0], 
actual action is [-4.666666666666667, 10], 
sim time next is 4616100.0000, 
raw observation next is [0.5, 58.0, 3.225, 107.5, 137.75, 702.5, -4.666666666666667, 14.7429816753901, 10.0, 22.15042416747385, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.34615384615384615, 0.58, 0.2931818181818182, 0.2986111111111111, 0.3644179894179894, 0.7025, 0.4222222222222222, 0.147429816753901, 0.0, 0.6075212083736925, 0.635, 1.0, 0.0], 
reward next is -0.0737. 
=============================================
[2017-11-01 10:05:25,404] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 246344: loss -52.2083
[2017-11-01 10:05:26,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.32242456e-01   1.95429742e-01   6.46113083e-02   4.29916948e-01
   1.77799672e-01   1.36921387e-18   8.65108550e-19   5.92144324e-19
   2.77506129e-18], sum to 1.0000
[2017-11-01 10:05:26,417] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666666, 93.33333333333334, 0.0, 0.0, 21.0, 0.0, 4.75, 27.96184408457753, 16.0, 19.82069711980675, 22.7, 1.0, 12.77004033708283], 
actual action is [4.833333333333333, 11.0], 
sim time next is 4694100.0000, 
raw observation next is [-0.08333333333333337, 92.66666666666667, 0.0, 0.0, 26.25, 0.0, 4.833333333333333, 28.48827014268092, 11.0, 19.75444199566385, 22.7, 1.0, 11.96911527031304], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.3311965811965812, 0.9266666666666667, 0.0, 0.0, 0.06944444444444445, 0.0, 0.5805555555555556, 0.2848827014268092, 0.05, 0.4877220997831925, 0.635, 1.0, 0.14081312082721223], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:05:27,787] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.79741490e-01   3.02308530e-01   5.11951856e-02   7.80621469e-02
   1.88692629e-01   2.70168155e-08   2.44923459e-08   1.40431116e-08
   5.42940715e-09], sum to 1.0000
[2017-11-01 10:05:27,815] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.666666666666667, 49.0, 2.1, 60.0, 123.1666666666667, 851.3333333333334, -1.416666666666667, 14.84784861438815, 10.0, 22.2795615084044, 22.7, 1.0, 0.0], 
actual action is [-1.333333333333333, 10], 
sim time next is 4625100.0000, 
raw observation next is [3.75, 49.0, 2.1, 57.5, 124.75, 847.5, -1.333333333333333, 14.86054201009676, 10.0, 22.25235703506453, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.42948717948717946, 0.49, 0.19090909090909092, 0.1597222222222222, 0.330026455026455, 0.8475, 0.4777777777777778, 0.14860542010096758, 0.0, 0.6126178517532266, 0.635, 1.0, 0.0], 
reward next is -0.0743. 
=============================================
[2017-11-01 10:05:27,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 247036: loss -9.6874
[2017-11-01 10:05:28,435] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 247248: loss -12.4241
[2017-11-01 10:05:28,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-33.4980545 ]
 [-33.57004166]
 [-33.42995453]
 [-33.06148148]
 [-37.02165604]], R is [[-33.51530457]
 [-33.62692261]
 [-33.63779068]
 [-33.6402092 ]
 [-33.63463593]].
[2017-11-01 10:05:28,689] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15500, global step 247357: loss -301.7987
[2017-11-01 10:05:30,282] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 248044: loss -148.3048
[2017-11-01 10:05:30,569] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 248161: loss -12.3078
[2017-11-01 10:05:31,213] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15500, global step 248412: loss -16.3238
[2017-11-01 10:05:31,460] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 248517: loss -51.6713
[2017-11-01 10:05:32,146] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 248773: loss -83.8437
[2017-11-01 10:05:32,640] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 248947: loss 1.5831
[2017-11-01 10:05:32,647] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15500, global step 248950: loss 130.4506
[2017-11-01 10:05:32,995] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 249058: loss -54.8207
[2017-11-01 10:05:33,504] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 249203: loss 137.7841
[2017-11-01 10:05:33,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.17861301e-36   2.60614998e-18   1.14418145e-17   1.10880955e-17
   4.39803991e-18   2.00346544e-01   1.53925419e-01   1.24337271e-01
   5.21390855e-01], sum to 1.0000
[2017-11-01 10:05:33,691] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [2.0, 57.0, 2.0, 360.0, 0.0, 0.0, 7.0, 24.39553129981042, 15.0, 20.50994187326887, 21.5, 0.0, 10.82080680921234], 
actual action is [7.0, 20.0], 
sim time next is 4661700.0000, 
raw observation next is [2.0, 57.0, 2.05, 360.0, 0.0, 0.0, 7.0, 24.64935341255249, 20.0, 20.47649533052649, 21.5, 0.0, 7.436099743767303], 
processed observation next is [0.5, 0.9565217391304348, 0.38461538461538464, 0.57, 0.18636363636363634, 1.0, 0.0, 0.0, 0.6166666666666667, 0.24649353412552488, 0.5, 0.5238247665263245, 0.575, 0.0, 0.0874835263972624], 
reward next is -0.2996. 
=============================================
[2017-11-01 10:05:35,336] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.54732627
  0.15351133  0.1553825   0.1437799 ], sum to 1.0000
[2017-11-01 10:05:35,370] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 53.66666666666667, 2.1, 320.0, 0.0, 0.0, 7.0, 19.98778268606631, 20.0, 20.81491355548939, 21.5, 0.0, 22.942235597413], 
actual action is [7.0, 20.5], 
sim time next is 4664700.0000, 
raw observation next is [2.0, 53.25, 2.1, 315.0, 0.0, 0.0, 7.0, 20.03109016728672, 20.5, 20.81767772878482, 21.5, 0.0, 19.3542672451034], 
processed observation next is [0.5, 1.0, 0.38461538461538464, 0.5325, 0.19090909090909092, 0.875, 0.0, 0.0, 0.6166666666666667, 0.2003109016728672, 0.525, 0.5408838864392409, 0.575, 0.0, 0.22769726170709884], 
reward next is -0.2844. 
=============================================
[2017-11-01 10:05:36,054] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2017-11-01 10:05:36,055] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-01 10:05:36,055] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-01 10:05:36,056] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-01 10:05:36,056] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.01 09:18

[2017-11-01 10:05:36,056] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-01 10:05:36,057] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-01 10:05:36,058] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=00hr 46min 40.56sec

[2017-11-01 10:05:37,056] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 10:05:37,058] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res19/Eplus-env-sub_run2
[2017-11-01 10:06:01,356] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.09490485e-08   1.54820979e-01   1.93609104e-01   2.04535648e-01
   1.23630069e-01   1.17161378e-01   7.21568093e-02   6.85045868e-02
   6.55813366e-02]
[2017-11-01 10:06:02,441] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.31906431e-19   2.31493374e-07   4.10633817e-07   4.13564095e-07
   2.22414485e-07   3.95546168e-01   2.14726821e-01   2.17377320e-01
   1.72348395e-01]
[2017-11-01 10:06:06,682] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.15369248e-13   3.18779385e-05   4.17891024e-05   4.63467513e-05
   2.77087129e-05   3.51111799e-01   2.38933787e-01   2.16465577e-01
   1.93341017e-01]
[2017-11-01 10:06:13,993] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.93274343e-01   2.95168906e-01   6.47826418e-02   1.24369808e-01
   2.22404361e-01   5.93704773e-14   3.28430723e-14   9.68265215e-15
   7.77987395e-15]
[2017-11-01 10:06:24,700] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.13013736e-03   3.85022730e-01   9.76137519e-02   1.86976284e-01
   3.29257041e-01   8.16483947e-09   6.93385216e-09   1.78734827e-09
   1.13116050e-09]
[2017-11-01 10:06:26,493] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.85881281e-01   2.81062841e-01   6.80438131e-02   1.15326844e-01
   2.49685124e-01   3.32026046e-13   2.21143294e-13   6.06327393e-14
   3.25138476e-14]
[2017-11-01 10:06:33,454] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.57974092e-11   4.73677088e-03   6.51323982e-03   6.60551991e-03
   3.67035973e-03   3.93829614e-01   2.18271330e-01   2.07071811e-01
   1.59301326e-01]
[2017-11-01 10:06:36,796] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.02742749e-01   2.83715665e-01   7.04459026e-02   1.14873126e-01
   2.28222549e-01   1.48150982e-13   8.62655149e-14   2.53975223e-14
   1.42380258e-14]
[2017-11-01 10:06:37,256] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.43443505e-29   3.59148034e-14   2.93486142e-14   3.98621870e-14
   4.83596351e-14   4.18716937e-01   3.83112192e-01   1.36053696e-01
   6.21171743e-02]
[2017-11-01 10:06:41,240] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.52689771e-24   1.54283860e-11   1.03736290e-11   1.38776907e-11
   1.88905662e-11   4.24381346e-01   3.86981845e-01   1.35004446e-01
   5.36322743e-02]
[2017-11-01 10:06:43,210] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.02268884e-01   2.78492630e-01   1.16025701e-01   1.65107206e-01
   2.38105625e-01   5.01161511e-14   2.86915945e-14   1.21465600e-14
   8.34208868e-15]
[2017-11-01 10:06:50,418] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   3.24343666e-27   9.06125618e-27   1.53794150e-26
   8.67697307e-27   4.24733758e-01   2.87951112e-01   1.17416382e-01
   1.69898763e-01]
[2017-11-01 10:06:54,100] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.56868370e-27   1.20823241e-12   1.34911537e-12   1.52818817e-12
   1.49789881e-12   4.71646994e-01   3.17674816e-01   1.36868104e-01
   7.38100186e-02]
[2017-11-01 10:06:59,118] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.48710424e-14   1.40800612e-05   7.82024927e-06   1.04867486e-05
   1.50601309e-05   4.46570784e-01   3.72145891e-01   1.25669256e-01
   5.55666387e-02]
[2017-11-01 10:07:13,418] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.39140280e-23   1.88144667e-10   1.06095029e-10   1.74606468e-10
   2.60822697e-10   4.04488504e-01   4.01499987e-01   1.29649729e-01
   6.43617213e-02]
[2017-11-01 10:07:20,061] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.07676810e-17   1.04009246e-06   5.98351278e-07   9.19392278e-07
   1.30943442e-06   4.13484812e-01   3.75289202e-01   1.34144679e-01
   7.70774856e-02]
[2017-11-01 10:07:24,386] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.09520174e-28   5.91874775e-14   1.21563472e-13   1.11518867e-13
   6.01030253e-14   3.78205270e-01   2.33746201e-01   2.41903216e-01
   1.46145239e-01]
[2017-11-01 10:07:26,131] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.87914918e-05   2.64621675e-01   2.71965563e-01   2.87577420e-01
   1.75803274e-01   1.29635316e-06   6.84340307e-07   6.43840281e-07
   6.09873439e-07]
[2017-11-01 10:07:32,390] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.31418395e-01   2.62125522e-01   6.39022738e-02   1.06918246e-01
   2.35635623e-01   3.08232308e-14   1.88320920e-14   5.82199372e-15
   3.32832491e-15]
[2017-11-01 10:07:33,802] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.14601799e-24   1.76185247e-11   3.23579913e-11   2.95225892e-11
   1.65768527e-11   3.92125636e-01   2.28397027e-01   2.46376440e-01
   1.33100882e-01]
[2017-11-01 10:07:33,985] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.34224498e-01   2.13811219e-01   1.96455851e-01   2.01797083e-01
   1.53711334e-01   1.38696360e-13   5.85890047e-14   5.84202825e-14
   4.72935832e-14]
[2017-11-01 10:07:34,391] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.61160944e-33   4.19703072e-17   9.66355603e-17   8.95562112e-17
   4.64143846e-17   3.69689524e-01   2.36160785e-01   2.47630373e-01
   1.46519274e-01]
[2017-11-01 10:07:37,622] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.94861778e-27   6.64327195e-14   1.16401057e-13   1.26205714e-13
   7.09832041e-14   3.22412372e-01   2.57701457e-01   2.31002092e-01
   1.88883960e-01]
[2017-11-01 10:07:41,128] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.56891803e-31   1.44975756e-15   1.04425313e-15   2.27397768e-15
   2.57754095e-15   3.58342230e-01   3.86775136e-01   1.25242203e-01
   1.29640445e-01]
[2017-11-01 10:07:41,444] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.79305667e-01   2.96015620e-01   6.44628927e-02   1.31960824e-01
   2.28255019e-01   4.45183766e-13   2.56464121e-13   7.50910971e-14
   7.11686230e-14]
[2017-11-01 10:07:46,111] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.30252019e-03   2.70865709e-01   2.44318753e-01   2.66357273e-01
   2.09155560e-01   7.59493801e-08   4.88111560e-08   3.62014880e-08
   3.58463979e-08]
[2017-11-01 10:07:55,956] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.62358386e-13   1.25123097e-05   1.57198356e-05   1.66247519e-05
   1.05712052e-05   3.52984697e-01   2.53888696e-01   2.15860844e-01
   1.77210405e-01]
[2017-11-01 10:07:57,734] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34745702e-01   2.19194964e-01   2.20247701e-01   2.37991974e-01
   1.87819541e-01   2.04318243e-10   1.19922045e-10   9.65793973e-11
   1.00804358e-10]
[2017-11-01 10:08:01,743] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.95859344e-12   4.57193091e-04   2.73202517e-04   4.42073244e-04
   5.64747723e-04   3.57845336e-01   3.31842810e-01   1.53630495e-01
   1.54944152e-01]
[2017-11-01 10:08:03,064] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.30988520e-14   3.42560597e-05   4.82454343e-05   4.83471340e-05
   2.88632236e-05   3.82522285e-01   2.29077667e-01   2.18807682e-01
   1.69432715e-01]
[2017-11-01 10:08:04,825] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.32748148e-09   7.38655254e-02   9.09615755e-02   1.01360448e-01
   6.11675642e-02   2.55747229e-01   1.48621663e-01   1.37473553e-01
   1.30802408e-01]
[2017-11-01 10:08:06,324] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.04798834e-06   3.22015554e-01   8.85704160e-02   1.68611407e-01
   4.12467927e-01   3.24563123e-03   3.16059240e-03   1.13887165e-03
   7.83499097e-04]
[2017-11-01 10:08:08,040] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.64864528e-01   2.65778184e-01   4.78408299e-02   8.46734643e-02
   2.36842945e-01   3.18328731e-11   2.33022230e-11   8.32871879e-12
   3.98350016e-12]
[2017-11-01 10:08:08,069] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.52197289e-01   2.64921069e-01   4.92784157e-02   8.87482837e-02
   2.44854972e-01   1.53184635e-11   1.14066673e-11   4.03699947e-12
   2.03483085e-12]
[2017-11-01 10:08:08,713] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.76973015e-02   2.69642204e-01   1.22382127e-01   1.77224651e-01
   3.63053679e-01   1.81392856e-08   1.43752157e-08   7.81900855e-09
   9.94132865e-09]
[2017-11-01 10:08:08,830] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.96445410e-08   4.10424136e-02   5.38045503e-02   5.66142835e-02
   4.11867052e-02   2.52045214e-01   1.58150017e-01   1.74815878e-01
   2.22340882e-01]
[2017-11-01 10:08:09,420] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.85098346e-14   2.62501388e-04   1.48799372e-04   3.51921539e-04
   4.09646338e-04   3.52563024e-01   3.09960604e-01   1.21731028e-01
   2.14572430e-01]
[2017-11-01 10:08:09,511] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.00251588e-06   2.92044997e-01   1.06120870e-01   2.29088858e-01
   3.72722745e-01   8.20099376e-06   6.92048661e-06   2.25912891e-06
   3.07657569e-06]
[2017-11-01 10:08:11,138] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.05065951e-01   2.79267311e-01   6.69991076e-02   1.19529977e-01
   3.29137683e-01   1.16483767e-11   9.45793270e-12   3.49640954e-12
   2.92341086e-12]
[2017-11-01 10:08:11,815] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.07118825e-04   2.85844862e-01   2.57295340e-01   2.72197962e-01
   1.84054732e-01   1.30717104e-09   6.00753836e-10   5.53220858e-10
   5.33132538e-10]
[2017-11-01 10:08:12,082] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.02952325e-01   2.25843817e-01   2.00502187e-01   2.13095024e-01
   1.57606661e-01   5.69150745e-15   2.27806356e-15   2.20871613e-15
   2.42417208e-15]
[2017-11-01 10:08:13,889] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.80984472e-02   2.29801476e-01   2.45954826e-01   2.71898448e-01
   2.24245325e-01   4.80574727e-07   3.29528689e-07   2.64319539e-07
   3.82195822e-07]
[2017-11-01 10:08:14,044] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.88520396e-15   8.66858386e-07   1.07632343e-06   1.28007855e-06
   8.07409265e-07   3.16430718e-01   2.52180487e-01   2.08822668e-01
   2.22562090e-01]
[2017-11-01 10:08:14,259] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.65691507e-02   2.19496161e-01   2.25911513e-01   2.55226821e-01
   2.02796429e-01   1.08656384e-09   6.75332290e-10   5.42214329e-10
   7.16904758e-10]
[2017-11-01 10:08:14,374] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.75261770e-03   2.98819214e-01   1.08768165e-01   2.75394380e-01
   3.14265609e-01   1.02884625e-08   8.97813912e-09   2.83606738e-09
   6.21812157e-09]
[2017-11-01 10:08:14,476] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.64628851e-02   2.96707720e-01   8.73180553e-02   2.29827866e-01
   2.99683452e-01   2.99761951e-11   2.21905879e-11   6.37568210e-12
   1.15739709e-11]
[2017-11-01 10:08:14,758] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34980319e-10   2.36314698e-03   8.02427006e-04   2.05712044e-03
   2.91080377e-03   3.55072975e-01   3.79817516e-01   1.07155338e-01
   1.49820641e-01]
[2017-11-01 10:08:15,603] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.13033408e-01   3.02767664e-01   7.11419880e-02   1.53084397e-01
   2.59972602e-01   1.44712358e-11   1.04257852e-11   2.99859139e-12
   3.64491467e-12]
[2017-11-01 10:08:17,882] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.80917591e-01   2.22057566e-01   2.00367555e-01   2.16999680e-01
   1.79657653e-01   1.83542903e-11   1.01270806e-11   8.49201785e-12
   7.51524971e-12]
[2017-11-01 10:08:18,373] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.41886968e-27   9.09252735e-14   1.65092197e-13   1.79819443e-13
   1.01196395e-13   3.37330788e-01   2.46375054e-01   2.33683601e-01
   1.82610512e-01]
[2017-11-01 10:08:18,697] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.81678180e-18   3.11180166e-08   4.46289476e-08   5.16347924e-08
   3.00485361e-08   3.35504651e-01   2.45685264e-01   2.15253994e-01
   2.03555971e-01]
[2017-11-01 10:08:20,288] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.47314246e-12   2.76264745e-05   3.36765952e-05   3.78347358e-05
   2.39605797e-05   3.28619272e-01   2.53248513e-01   2.16925845e-01
   2.01083332e-01]
[2017-11-01 10:08:21,841] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.28821349e-02   3.69119227e-01   8.17880481e-02   1.58828884e-01
   3.37381691e-01   3.03545578e-10   2.46871218e-10   6.11909759e-11
   3.89749656e-11]
[2017-11-01 10:08:22,382] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.67618748e-06   2.41974518e-01   6.13452643e-02   1.26453683e-01
   2.56200761e-01   1.31250486e-01   1.28206164e-01   3.49417478e-02
   1.96256824e-02]
[2017-11-01 10:08:22,525] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.17214965e-03   3.84598553e-01   7.97402784e-02   1.66390926e-01
   3.66091639e-01   2.86067166e-06   2.60665911e-06   6.79427615e-07
   4.06609587e-07]
[2017-11-01 10:08:25,183] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.39694887e-17   7.33363095e-08   1.01708693e-07   1.15289737e-07
   6.97434785e-08   3.28774363e-01   2.48224914e-01   2.16862708e-01
   2.06137672e-01]
[2017-11-01 10:08:25,439] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.31167710e-01   2.12639987e-01   2.12536171e-01   2.52971292e-01
   1.90684885e-01   3.52779715e-11   2.07097586e-11   1.64974076e-11
   2.06532690e-11]
[2017-11-01 10:08:27,845] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.29060137e-01   2.48476714e-01   7.05883577e-02   9.71513242e-02
   2.54687607e-01   1.60973887e-05   1.32897276e-05   4.48049695e-06
   1.94856352e-06]
[2017-11-01 10:08:28,011] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.45732033e-01   2.56826282e-01   6.78318888e-02   9.39585119e-02
   2.35641092e-01   4.57937267e-06   3.68305587e-06   1.31135175e-06
   5.64694233e-07]
[2017-11-01 10:08:30,559] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.94138821e-15   2.96706321e-06   4.17186220e-06   4.67212158e-06
   2.93813946e-06   3.20536733e-01   2.33296186e-01   2.13836491e-01
   2.32315749e-01]
[2017-11-01 10:08:31,284] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.91806573e-01   2.64640749e-01   5.48865534e-02   8.32919702e-02
   2.05374107e-01   5.21526289e-09   3.65603836e-09   1.42644818e-09
   6.66108779e-10]
[2017-11-01 10:08:32,280] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.36041640e-08   1.89874664e-01   2.29599416e-01   2.42268622e-01
   1.45577520e-01   7.84804747e-02   4.26860228e-02   3.92331108e-02
   3.22801545e-02]
[2017-11-01 10:08:36,296] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.86180517e-01   2.93610036e-01   6.90123215e-02   1.29555166e-01
   3.21641982e-01   2.29335214e-11   1.81635141e-11   5.38619236e-12
   3.82754982e-12]
[2017-11-01 10:08:40,275] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.36803791e-01   2.19956920e-01   2.23448023e-01   2.46114641e-01
   1.73676625e-01   2.40348778e-12   1.20031621e-12   1.09845087e-12
   1.40914819e-12]
[2017-11-01 10:08:46,031] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.66636934e-24   1.31235758e-10   1.16923166e-10   1.78727796e-10
   1.97242833e-10   3.92863542e-01   3.39031458e-01   1.47705629e-01
   1.20399408e-01]
[2017-11-01 10:08:46,132] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.95970028e-11   5.34854177e-03   3.17422953e-03   5.00383228e-03
   6.47939369e-03   3.89042735e-01   3.26977581e-01   1.39643401e-01
   1.24330357e-01]
[2017-11-01 10:08:46,597] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.06998989e-01   2.67101109e-01   1.07219383e-01   1.62336603e-01
   2.56343961e-01   3.48965750e-14   2.12240537e-14   9.17275357e-15
   7.34469299e-15]
[2017-11-01 10:08:51,811] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.08729386e-07   2.49280438e-01   2.92847008e-01   2.89170355e-01
   1.68229491e-01   2.00977986e-04   9.79428660e-05   9.69289104e-05
   7.63455246e-05]
[2017-11-01 10:08:55,448] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.04515922e-17   3.92845777e-06   3.18097386e-06   4.03009562e-06
   4.80136396e-06   4.57499087e-01   3.22766274e-01   1.34512052e-01
   8.52067173e-02]
[2017-11-01 10:08:56,325] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   4.29030286e-25   7.34497246e-25   8.74182326e-25
   8.22622969e-25   3.88406485e-01   3.57511193e-01   1.75100580e-01
   7.89818391e-02]
[2017-11-01 10:09:02,884] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.58078692e-05   2.57100970e-01   2.64817387e-01   2.90312916e-01
   1.85471311e-01   8.51516612e-04   5.48707729e-04   4.55561560e-04
   4.25836886e-04]
[2017-11-01 10:09:08,561] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.63606281e-11   3.47309629e-04   1.66001453e-04   2.91386066e-04
   3.24242312e-04   3.78022641e-01   3.47051919e-01   1.41308486e-01
   1.32488012e-01]
[2017-11-01 10:09:15,467] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34157185e-10   4.02777689e-03   1.21579680e-03   2.51744338e-03
   4.24445421e-03   4.09867615e-01   4.10844415e-01   1.03893593e-01
   6.33888245e-02]
[2017-11-01 10:09:17,822] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.12916818e-02   3.65044236e-01   9.85085219e-02   1.76955342e-01
   3.48200113e-01   4.08540259e-08   3.38464474e-08   9.96172744e-09
   6.91019153e-09]
[2017-11-01 10:09:20,629] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.55091077e-30   1.01172961e-15   2.01495268e-15   2.14936156e-15
   1.14615988e-15   3.36623192e-01   2.50592649e-01   2.37778232e-01
   1.75005928e-01]
[2017-11-01 10:09:20,904] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.10762715e-01   2.23174006e-01   2.34871417e-01   2.51565337e-01
   1.79626599e-01   5.21547701e-11   2.81113570e-11   2.38272388e-11
   3.06274762e-11]
[2017-11-01 10:09:24,320] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.72819821e-13   4.95802778e-05   1.63638160e-05   3.44387627e-05
   5.39422072e-05   4.07756180e-01   4.20430213e-01   1.04966812e-01
   6.66924715e-02]
[2017-11-01 10:09:24,921] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.62116903e-01   2.62620091e-01   6.06711358e-02   1.00234531e-01
   2.14357361e-01   6.93757714e-13   4.04523257e-13   1.22281850e-13
   5.82042349e-14]
[2017-11-01 10:09:25,110] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.81018845e-06   3.39045078e-01   1.22013278e-01   1.96188316e-01
   3.38331908e-01   1.90979301e-03   1.72072696e-03   5.09484846e-04
   2.77696148e-04]
[2017-11-01 10:09:34,556] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.67800256e-18   3.30335688e-08   1.59910609e-08   2.48970267e-08
   4.02260696e-08   3.99840325e-01   4.10886675e-01   1.30963057e-01
   5.83099201e-02]
[2017-11-01 10:09:37,315] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.03986180e-15   1.92013795e-06   1.14171326e-06   1.71286899e-06
   2.23748202e-06   3.73468578e-01   3.57182801e-01   1.57260656e-01
   1.12080857e-01]
[2017-11-01 10:09:37,993] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.99418658e-01   2.61612266e-01   8.64445120e-02   1.37150794e-01
   2.15373784e-01   7.83668615e-15   3.97216651e-15   1.80234656e-15
   9.24602848e-16]
[2017-11-01 10:09:39,260] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.92962161e-12   2.24998366e-04   3.04129673e-04   2.93686113e-04
   1.74386019e-04   3.91819477e-01   2.32634708e-01   2.20005542e-01
   1.54543072e-01]
[2017-11-01 10:09:45,868] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.33555162e-01   2.65576512e-01   6.82056919e-02   1.04912952e-01
   2.27749661e-01   1.02093052e-12   6.43107258e-13   1.99480853e-13
   1.03044946e-13]
[2017-11-01 10:09:48,214] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.70275953e-03   2.78823167e-01   2.65933156e-01   2.65673578e-01
   1.87856853e-01   4.00085491e-06   2.44418129e-06   2.17602383e-06
   1.82831820e-06]
[2017-11-01 10:09:49,310] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.01682940e-29   2.41476705e-15   4.84340131e-15   4.81260785e-15
   2.59589023e-15   3.48394126e-01   2.47199267e-01   2.42862284e-01
   1.61544338e-01]
[2017-11-01 10:09:52,140] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.52310908e-01   2.40035862e-01   1.67331859e-01   2.25692466e-01
   2.14628980e-01   3.19019388e-13   1.85883698e-13   1.03132021e-13
   1.43867909e-13]
[2017-11-01 10:09:52,766] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.93916494e-23   1.58625890e-10   7.96429242e-11   1.85684634e-10
   2.45527154e-10   3.90500069e-01   4.09652919e-01   1.07870258e-01
   9.19767469e-02]
[2017-11-01 10:09:57,121] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.42476910e-01   2.17866242e-01   1.97909921e-01   1.87835366e-01
   1.53911486e-01   5.55835065e-12   2.75628955e-12   2.47358883e-12
   1.48586352e-12]
[2017-11-01 10:10:08,097] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.42752150e-12   5.80559608e-05   6.97600990e-05   8.29129858e-05
   5.28863711e-05   3.25094134e-01   2.54352957e-01   2.05893338e-01
   2.14395940e-01]
[2017-11-01 10:10:09,925] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.66613702e-17   2.53750922e-08   2.89889925e-08   3.48629783e-08
   2.38449669e-08   3.08720380e-01   2.91142166e-01   2.13948801e-01
   1.86188504e-01]
[2017-11-01 10:10:11,713] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.83888927e-01   2.85354316e-01   1.08914010e-01   1.73456863e-01
   2.48001456e-01   1.43331228e-04   1.32025772e-04   5.22612208e-05
   5.67610587e-05]
[2017-11-01 10:10:12,210] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.16585737e-06   2.48602971e-01   9.30067748e-02   1.62913471e-01
   2.03114480e-01   1.11256801e-01   9.59913433e-02   4.30651382e-02
   4.20418680e-02]
[2017-11-01 10:10:13,146] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.05769455e-08   3.17929988e-03   2.99078040e-03   3.22513143e-03
   2.52164248e-03   3.37164491e-01   2.74657071e-01   2.14478344e-01
   1.61783159e-01]
[2017-11-01 10:10:17,242] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.01874446e-05   2.65129656e-01   2.70020783e-01   2.84538090e-01
   1.80125296e-01   3.69045774e-05   2.20980128e-05   1.95139291e-05
   1.74527140e-05]
[2017-11-01 10:10:19,300] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.78354540e-15   1.59172373e-06   6.43664293e-07   9.48491333e-07
   1.80112920e-06   4.05586839e-01   3.92413050e-01   1.45333171e-01
   5.66620007e-02]
[2017-11-01 10:10:20,923] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.22667262e-01   3.04015875e-01   9.66340527e-02   1.48686409e-01
   2.27996364e-01   7.77165918e-12   4.41506900e-12   1.89397825e-12
   8.24770753e-13]
[2017-11-01 10:10:21,440] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.39284784e-01   2.86596209e-01   9.59596261e-02   1.50138676e-01
   2.28020743e-01   1.06725132e-12   5.96794857e-13   2.56474692e-13
   1.24550272e-13]
[2017-11-01 10:10:27,002] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.29495904e-01   3.23640823e-01   7.06381351e-02   1.71821415e-01
   3.04403782e-01   1.03111835e-13   6.38967232e-14   1.29292176e-14
   1.58421758e-14]
[2017-11-01 10:10:38,387] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.06692235e-07   8.25920701e-02   3.25902291e-02   4.55727167e-02
   7.89615735e-02   3.34088236e-01   2.71997541e-01   1.04388632e-01
   4.98088002e-02]
[2017-11-01 10:10:44,150] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.65248156e-01   2.82998800e-01   7.67818913e-02   1.77756712e-01
   2.97214448e-01   2.42677840e-13   1.58700960e-13   4.28783426e-14
   4.72005586e-14]
[2017-11-01 10:10:44,276] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.20164451e-07   2.98567802e-01   9.27633643e-02   2.47952357e-01
   3.60108554e-01   2.44669995e-04   2.32264749e-04   5.47935451e-05
   7.53409186e-05]
[2017-11-01 10:10:44,409] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.42430734e-08   1.42653629e-01   5.37993200e-02   1.04030557e-01
   1.69617474e-01   2.12929845e-01   2.07123205e-01   6.20455891e-02
   4.78004813e-02]
[2017-11-01 10:10:44,889] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.23192422e-07   2.96818942e-01   1.10053353e-01   2.07529426e-01
   3.50871354e-01   1.44090103e-02   1.32960957e-02   3.96211166e-03
   3.05953436e-03]
[2017-11-01 10:10:50,495] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.27210387e-06   2.47901529e-01   2.68544912e-01   3.00013512e-01
   1.82880402e-01   2.56813568e-04   1.40679287e-04   1.28893793e-04
   1.31877969e-04]
[2017-11-01 10:10:52,772] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.80565573e-20   1.69990262e-08   1.15714744e-08   1.58840496e-08
   2.11021103e-08   4.23606068e-01   3.69927078e-01   1.36942610e-01
   6.95242137e-02]
[2017-11-01 10:10:53,468] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.44770521e-01   2.72469729e-01   8.47427174e-02   1.08156286e-01
   1.89860746e-01   6.21557493e-13   3.32011111e-13   1.30801443e-13
   8.82094148e-14]
[2017-11-01 10:10:56,934] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.79234996e-01   2.35628709e-01   2.02796370e-01   1.92590579e-01
   1.89749464e-01   3.86546295e-10   2.29230870e-10   1.71382367e-10
   1.23355479e-10]
[2017-11-01 10:10:58,221] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.55531736e-15   8.77525326e-06   1.29496038e-05   1.30994513e-05
   7.36518905e-06   3.73744965e-01   2.34247923e-01   2.17525005e-01
   1.74439892e-01]
[2017-11-01 10:10:59,304] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.22330125e-20   2.22166618e-09   3.65944497e-09   3.82034671e-09
   2.10458695e-09   3.58824134e-01   2.37936705e-01   2.20210001e-01
   1.83029085e-01]
[2017-11-01 10:11:01,821] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.26189984e-05   3.40652436e-01   1.51412919e-01   1.95083678e-01
   3.12185526e-01   3.03855952e-04   2.03129515e-04   7.77786991e-05
   4.79992959e-05]
[2017-11-01 10:11:02,232] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.15669460e-08   7.58372247e-02   3.46964486e-02   4.56062295e-02
   7.57597312e-02   3.44983667e-01   2.62746245e-01   1.05145060e-01
   5.52252382e-02]
[2017-11-01 10:11:06,658] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.48659756e-05   2.61053860e-01   2.52351195e-01   2.82792479e-01
   1.93578869e-01   3.42387496e-03   2.45816004e-03   2.07434152e-03
   2.25236360e-03]
[2017-11-01 10:11:07,413] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.10373593  0.15334335  0.10398772  0.12261819  0.16794191  0.13395448
  0.10892542  0.06082731  0.04466574]
[2017-11-01 10:11:08,484] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.59824923e-01   3.61646920e-01   8.78391415e-02   1.43776402e-01
   2.46896625e-01   7.00751571e-06   4.97772407e-06   2.41892576e-06
   1.51647623e-06]
[2017-11-01 10:11:11,705] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.84487283e-01   3.12623799e-01   7.11077303e-02   1.48282677e-01
   2.83498555e-01   9.19553045e-10   7.40473016e-10   1.61052546e-10
   1.23133309e-10]
[2017-11-01 10:11:12,245] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.60836095e-01   2.88287818e-01   7.57525787e-02   1.16453923e-01
   2.58668065e-01   6.19937964e-07   5.49175979e-07   2.00831835e-07
   1.22470425e-07]
[2017-11-01 10:11:13,947] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.27859914e-01   2.13806495e-01   1.92387402e-01   1.95619941e-01
   1.70326203e-01   7.54987392e-11   4.32522039e-11   3.53078816e-11
   2.13044981e-11]
[2017-11-01 10:11:16,291] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.01209485e-33   1.31349259e-17   2.89567147e-17   2.95810474e-17
   1.51713577e-17   3.36635113e-01   2.59322971e-01   2.41295502e-01
   1.62746370e-01]
[2017-11-01 10:11:19,600] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.13721636e-04   3.50508511e-01   1.10867776e-01   1.83746427e-01
   3.44553500e-01   4.09394922e-03   3.92355910e-03   1.33022666e-03
   7.62278098e-04]
[2017-11-01 10:11:20,142] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.61328130e-05   3.45050812e-01   1.22200944e-01   1.86707020e-01
   3.36323053e-01   4.23226133e-03   3.54991877e-03   1.23563013e-03
   6.64318271e-04]
[2017-11-01 10:11:20,576] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   8.21407075e-29   1.01749563e-28   1.30203228e-28
   1.36260398e-28   3.49593043e-01   3.76848400e-01   2.14322403e-01
   5.92361316e-02]
[2017-11-01 10:11:20,611] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  0.00000000e+00   3.85351865e-26   5.39302971e-26   7.08575881e-26
   6.81930070e-26   3.30084950e-01   3.66599321e-01   2.08773673e-01
   9.45420638e-02]
[2017-11-01 10:11:25,389] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.33303672e-01   2.23105431e-01   2.32162923e-01   2.40851969e-01
   1.70576066e-01   2.92891648e-11   1.53478792e-11   1.34682040e-11
   1.43534637e-11]
[2017-11-01 10:11:26,599] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.17953080e-01   2.70634979e-01   7.17713386e-02   1.06320716e-01
   2.33319744e-01   7.03448322e-08   5.66160203e-08   2.18154312e-08
   1.36949367e-08]
[2017-11-01 10:11:26,862] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.29887658e-01   2.68397361e-01   7.14423433e-02   1.03959098e-01
   2.26313472e-01   3.71494657e-08   2.87572988e-08   1.12556799e-08
   6.93315316e-09]
[2017-11-01 10:11:32,880] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.38452578e-01   2.70200491e-01   7.02337176e-02   1.01913825e-01
   2.19199345e-01   4.89199117e-08   3.52652734e-08   1.37661083e-08
   7.83161269e-09]
[2017-11-01 10:11:32,947] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.55073899e-01   2.67052263e-01   6.80665374e-02   9.77958292e-02
   2.12011367e-01   3.25166170e-08   2.27158505e-08   9.02375419e-09
   4.88886709e-09]
[2017-11-01 10:11:36,008] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.22296393e-01   2.22330466e-01   2.35358670e-01   2.45377451e-01
   1.74637035e-01   2.69470418e-11   1.41671969e-11   1.25721412e-11
   1.50303606e-11]
[2017-11-01 10:11:40,863] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.83270961e-01   2.30132997e-01   2.10609108e-01   1.97354451e-01
   1.78632557e-01   1.26221728e-10   7.18509696e-11   5.75193226e-11
   4.19666142e-11]
[2017-11-01 10:11:43,938] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.21668786e-04   3.60492796e-01   1.32016227e-01   1.76951975e-01
   3.29300940e-01   4.54099732e-04   3.36471072e-04   1.42383884e-04
   8.34099264e-05]
[2017-11-01 10:11:44,246] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.11973894e-06   3.41855258e-01   1.20479524e-01   1.72731727e-01
   3.44368279e-01   8.76969006e-03   7.64089404e-03   2.84215342e-03
   1.30732253e-03]
[2017-11-01 10:11:45,621] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.89232329e-02   2.47668564e-01   2.50351042e-01   2.43241683e-01
   1.79815531e-01   5.23612126e-11   2.51623149e-11   2.34180956e-11
   2.49185464e-11]
[2017-11-01 10:11:47,230] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.10149908e-02   2.24544510e-01   2.31990695e-01   2.48866886e-01
   2.13582903e-01   3.37150752e-08   2.21426237e-08   1.69607670e-08
   2.15085745e-08]
[2017-11-01 10:11:48,709] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [ 0.16064845  0.25802323  0.12494764  0.18376468  0.25720757  0.00606368
  0.00529875  0.00223139  0.00181462]
[2017-11-01 10:11:50,295] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.01922312e-01   3.10821414e-01   1.01177208e-01   1.68527156e-01
   2.17551917e-01   2.80035196e-12   1.55487743e-12   7.00463992e-13
   4.28400696e-13]
[2017-11-01 10:11:51,320] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.16216430e-01   2.28404909e-01   1.80997729e-01   1.93951234e-01
   1.80429682e-01   2.41435778e-11   1.36657959e-11   1.05927081e-11
   7.18994959e-12]
[2017-11-01 10:11:53,835] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.14697099e-01   2.23117828e-01   2.29772210e-01   2.38422722e-01
   1.93990156e-01   1.96270067e-09   1.17112409e-09   9.38959244e-10
   9.80453607e-10]
[2017-11-01 10:11:55,766] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.09664696e-01   2.66463369e-01   7.18786865e-02   1.07775994e-01
   2.44214788e-01   1.04013270e-06   8.87753799e-07   3.32304381e-07
   1.87608592e-07]
[2017-11-01 10:11:56,585] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.86159647e-18   8.94212437e-09   5.21796473e-09   8.71846861e-09
   1.02637792e-08   3.60888243e-01   3.46026421e-01   1.67628989e-01
   1.25456393e-01]
[2017-11-01 10:11:58,106] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.63639143e-01   2.15119287e-01   2.06802443e-01   2.29875505e-01
   1.84563667e-01   6.72198547e-11   3.87332770e-11   3.17553171e-11
   2.87560323e-11]
[2017-11-01 10:12:01,627] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.68542886e-02   3.53299856e-01   9.42256525e-02   1.54493719e-01
   3.21119189e-01   2.98823556e-06   2.78016114e-06   9.57519660e-07
   5.72896397e-07]
[2017-11-01 10:12:03,517] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.24606900e-02   2.64348000e-01   2.67031789e-01   2.57940829e-01
   1.98217228e-01   5.56773898e-07   3.41514379e-07   2.88639029e-07
   2.53281257e-07]
[2017-11-01 10:12:11,413] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.22968595e-17   1.13363603e-08   4.26202273e-09   6.40430464e-09
   1.20866579e-08   4.05286640e-01   4.05806452e-01   1.43779188e-01
   4.51276749e-02]
[2017-11-01 10:12:13,514] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.06288046e-02   2.77749836e-01   2.53798693e-01   2.44284466e-01
   2.13537395e-01   3.43568701e-07   2.17520878e-07   1.65329723e-07
   1.32947562e-07]
[2017-11-01 10:12:13,695] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.29992469e-37   2.09918681e-20   4.97383121e-20   4.84854049e-20
   2.54426362e-20   3.32970083e-01   2.64206082e-01   2.46282175e-01
   1.56541690e-01]
[2017-11-01 10:12:15,595] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.12515305e-07   1.43400788e-01   1.63828820e-01   1.75462544e-01
   1.09959260e-01   1.45939320e-01   9.78087410e-02   8.44477341e-02
   7.91523531e-02]
[2017-11-01 10:12:16,013] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.35424525e-01   2.27868721e-01   2.26413056e-01   2.26585850e-01
   1.83707744e-01   2.22182772e-10   1.24747393e-10   1.02554930e-10
   9.62297811e-11]
[2017-11-01 10:12:17,704] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.38944584e-01   2.63194054e-01   7.06498921e-02   1.02422364e-01
   2.24788859e-01   1.14302779e-07   8.60882565e-08   3.39661739e-08
   1.91626341e-08]
[2017-11-01 10:12:17,922] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.23195159e-01   2.69998461e-01   7.18454942e-02   1.02125503e-01
   2.32834905e-01   2.46141553e-07   1.84817651e-07   6.86421231e-08
   3.43040938e-08]
[2017-11-01 10:12:18,662] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.30136707e-02   2.32490599e-01   2.59853214e-01   2.38979235e-01
   1.95663229e-01   3.09429744e-08   1.83510203e-08   1.60241260e-08
   1.64281744e-08]
[2017-11-01 10:12:20,298] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.68750511e-15   7.59576960e-06   1.08884105e-05   1.11398203e-05
   6.42876512e-06   3.67379844e-01   2.35740513e-01   2.22392350e-01
   1.74451247e-01]
