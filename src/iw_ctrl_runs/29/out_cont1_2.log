Using TensorFlow backend.
[2017-11-01 09:16:46,817] A3C_AGENT_MAIN INFO:Namespace(act_func='5', action_space='iw_af5_1', agent_num=5, clip_norm=5.0, decay_steps=1000000, dropout_prob=0.5, end_e=0.0, env='IW-v5702', err_penalty_scl=0.3, eval_epi_num=1, eval_freq=250000, gamma=0.99, h_regu_frac=0.01, init_e=0.0, is_warm_start=True, job_mode='Train', learning_rate=0.0001, max_interactions=15000000, model_dir='a3c-res-v0.1/IW-v5702-run1/model_data/model.ckpt-15000000', num_threads=16, output='a3c-res-v0.1/IW-v5702-run3', p_loss_frac=1.0, reward_func='10', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=0.5, rwd_p_para=0.5, save_freq=500000, save_scope='all', state_dim=13, test_env='IW-eval-v5702', test_mode='Multiple', train_freq=5, v_loss_frac=0.5, window_len=24)
[2017-11-01 09:16:46,817] A3C_AGENT_MAIN INFO:Start compiling...
2017-11-01 09:16:50.225072: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:16:50.225089: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:16:50.225103: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:16:50.225106: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-01 09:16:50.225108: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[2017-11-01 09:16:52,825] A3C_AGENT_MAIN INFO:Start the learning...
[2017-11-01 09:16:52,831] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['IW-v5702'] ...
[2017-11-01 09:16:52,831] Making new env: IW-v5702
[2017-11-01 09:16:52,859] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:52,860] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2017-11-01 09:16:52,860] Making new env: IW-v5702
[2017-11-01 09:16:52,874] EPLUS_ENV_IW-v5702_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:52,877] EPLUS_ENV_IW-v5702_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res3/Eplus-env-sub_run1
[2017-11-01 09:16:53,861] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:53,862] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2017-11-01 09:16:53,862] Making new env: IW-v5702
[2017-11-01 09:16:53,877] EPLUS_ENV_IW-v5702_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:53,880] EPLUS_ENV_IW-v5702_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res4/Eplus-env-sub_run1
[2017-11-01 09:16:54,863] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:54,864] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2017-11-01 09:16:54,864] Making new env: IW-v5702
[2017-11-01 09:16:54,878] EPLUS_ENV_IW-v5702_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:54,881] EPLUS_ENV_IW-v5702_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res5/Eplus-env-sub_run1
[2017-11-01 09:16:55,864] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:55,866] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2017-11-01 09:16:55,866] Making new env: IW-v5702
[2017-11-01 09:16:55,880] EPLUS_ENV_IW-v5702_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:55,883] EPLUS_ENV_IW-v5702_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res6/Eplus-env-sub_run1
[2017-11-01 09:16:56,867] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:56,868] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2017-11-01 09:16:56,868] Making new env: IW-v5702
[2017-11-01 09:16:56,882] EPLUS_ENV_IW-v5702_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:56,886] EPLUS_ENV_IW-v5702_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res7/Eplus-env-sub_run1
[2017-11-01 09:16:57,869] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:57,869] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2017-11-01 09:16:57,869] Making new env: IW-v5702
[2017-11-01 09:16:57,880] EPLUS_ENV_IW-v5702_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:57,883] EPLUS_ENV_IW-v5702_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res8/Eplus-env-sub_run1
[2017-11-01 09:16:58,870] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:58,871] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2017-11-01 09:16:58,871] Making new env: IW-v5702
[2017-11-01 09:16:58,886] EPLUS_ENV_IW-v5702_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:58,889] EPLUS_ENV_IW-v5702_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res9/Eplus-env-sub_run1
[2017-11-01 09:16:59,872] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:16:59,873] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2017-11-01 09:16:59,873] Making new env: IW-v5702
[2017-11-01 09:16:59,883] EPLUS_ENV_IW-v5702_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:16:59,886] EPLUS_ENV_IW-v5702_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res10/Eplus-env-sub_run1
[2017-11-01 09:17:00,874] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:00,875] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2017-11-01 09:17:00,875] Making new env: IW-v5702
[2017-11-01 09:17:00,887] EPLUS_ENV_IW-v5702_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:00,890] EPLUS_ENV_IW-v5702_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res11/Eplus-env-sub_run1
[2017-11-01 09:17:01,876] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:01,876] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2017-11-01 09:17:01,877] Making new env: IW-v5702
[2017-11-01 09:17:01,888] EPLUS_ENV_IW-v5702_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:01,891] EPLUS_ENV_IW-v5702_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res12/Eplus-env-sub_run1
[2017-11-01 09:17:02,877] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:02,877] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2017-11-01 09:17:02,878] Making new env: IW-v5702
[2017-11-01 09:17:02,890] EPLUS_ENV_IW-v5702_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:02,893] EPLUS_ENV_IW-v5702_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res13/Eplus-env-sub_run1
[2017-11-01 09:17:03,878] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:03,879] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2017-11-01 09:17:03,880] Making new env: IW-v5702
[2017-11-01 09:17:03,890] EPLUS_ENV_IW-v5702_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:03,893] EPLUS_ENV_IW-v5702_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res14/Eplus-env-sub_run1
[2017-11-01 09:17:04,880] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:04,881] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2017-11-01 09:17:04,881] Making new env: IW-v5702
[2017-11-01 09:17:04,892] EPLUS_ENV_IW-v5702_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:04,895] EPLUS_ENV_IW-v5702_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res15/Eplus-env-sub_run1
[2017-11-01 09:17:05,882] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:05,883] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2017-11-01 09:17:05,883] Making new env: IW-v5702
[2017-11-01 09:17:05,894] EPLUS_ENV_IW-v5702_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:05,897] EPLUS_ENV_IW-v5702_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res16/Eplus-env-sub_run1
[2017-11-01 09:17:06,884] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:06,885] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2017-11-01 09:17:06,885] Making new env: IW-v5702
[2017-11-01 09:17:06,896] EPLUS_ENV_IW-v5702_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:06,899] EPLUS_ENV_IW-v5702_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res17/Eplus-env-sub_run1
[2017-11-01 09:17:07,886] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-01 09:17:07,886] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2017-11-01 09:17:07,887] Making new env: IW-v5702
[2017-11-01 09:17:07,897] EPLUS_ENV_IW-v5702_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:07,900] EPLUS_ENV_IW-v5702_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res18/Eplus-env-sub_run1
[2017-11-01 09:17:59,155] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2017-11-01 09:17:59,155] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 09:17:59,158] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res2/Eplus-env-sub_run1
[2017-11-01 09:19:09,437] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.53609738e-02   2.94144213e-01   3.00023496e-01   3.02838355e-01
   8.76187757e-02   5.20916274e-06   3.12070711e-06   3.10001428e-06
   2.71210342e-06]
[2017-11-01 09:19:09,535] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.27447835e-08   2.84941196e-01   2.09439889e-01   3.64350826e-01
   7.20323324e-02   1.85299423e-02   1.04221487e-02   1.51782576e-02
   2.51054149e-02]
[2017-11-01 09:19:15,230] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.85331742e-03   3.57098341e-01   1.86377302e-01   3.77723902e-01
   7.59471357e-02   1.16882036e-12   5.41813014e-13   7.61913373e-13
   8.11621983e-13]
[2017-11-01 09:19:18,051] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.94075721e-07   2.83346146e-01   1.91826910e-01   4.27656710e-01
   9.71627310e-02   2.47818889e-06   1.25265069e-06   1.37923575e-06
   1.89011712e-06]
[2017-11-01 09:19:35,096] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.45824179e-01   2.52785683e-01   2.38687158e-01   2.80013263e-01
   8.26897025e-02   1.95311952e-12   7.08010148e-13   7.41139626e-13
   5.36755102e-13]
[2017-11-01 09:19:37,411] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.38122232e-05   2.65597016e-01   2.64218658e-01   3.79128873e-01
   9.10388380e-02   1.21093842e-06   5.09950269e-07   5.53224936e-07
   5.54382609e-07]
[2017-11-01 09:19:42,633] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.25719628e-15   2.89029034e-04   1.54786379e-04   4.56096255e-04
   9.18843798e-05   3.01237524e-01   1.92826957e-01   2.27997497e-01
   2.76946187e-01]
[2017-11-01 09:19:49,089] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.17728380e-22   2.56939781e-09   2.78153234e-09   5.73588244e-09
   1.18162713e-09   3.65052849e-01   2.05073133e-01   1.82081610e-01
   2.47792318e-01]
[2017-11-01 09:19:50,820] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.25235170e-01   2.38210082e-01   2.58326173e-01   2.91825473e-01
   8.64030868e-02   8.96480286e-12   3.03544863e-12   3.14262310e-12
   1.71671564e-12]
[2017-11-01 09:19:57,086] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.96217354e-29   1.17522068e-11   3.36080122e-12   1.93672439e-11
   2.64558189e-12   3.12753022e-01   1.66284472e-01   2.35100582e-01
   2.85861969e-01]
[2017-11-01 09:19:57,331] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.54953332e-22   2.53389373e-07   7.06347763e-08   3.61041316e-07
   5.40024239e-08   3.20073336e-01   1.57950521e-01   2.30723187e-01
   2.91252255e-01]
[2017-11-01 09:20:04,054] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.81246353e-31   2.54949599e-13   1.89641786e-13   8.21682403e-13
   1.24089568e-13   3.15799356e-01   1.56351104e-01   1.78771213e-01
   3.49078298e-01]
[2017-11-01 09:20:14,942] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.79968087e-13   9.34996828e-03   2.97323777e-03   1.05108479e-02
   1.97879085e-03   3.32547963e-01   1.71714693e-01   2.30461746e-01
   2.40462780e-01]
[2017-11-01 09:20:18,016] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  0.00000000e+00   1.92174157e-18   3.53970876e-19   2.56492206e-18
   2.96223459e-19   2.89856821e-01   1.65442988e-01   2.22641438e-01
   3.22058678e-01]
[2017-11-01 09:20:23,487] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.59654501e-07   2.12710515e-01   2.58570522e-01   3.44216466e-01
   9.01731923e-02   3.80253308e-02   1.92206707e-02   1.93528067e-02
   1.77301634e-02]
[2017-11-01 09:20:23,734] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.01084008e-10   1.28764175e-02   1.67678967e-02   2.43978910e-02
   5.85375167e-03   3.62916648e-01   1.93728387e-01   1.87725022e-01
   1.95734039e-01]
[2017-11-01 09:20:24,980] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.27551623e-08   8.14978182e-02   1.04841858e-01   1.49260655e-01
   3.65617126e-02   2.29240403e-01   1.26214743e-01   1.27597332e-01
   1.44785434e-01]
[2017-11-01 09:20:28,437] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.24746715e-10   1.59028113e-01   1.07883289e-01   2.40286320e-01
   5.23555540e-02   1.31670058e-01   8.79470408e-02   9.64348242e-02
   1.24394782e-01]
[2017-11-01 09:20:29,794] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.06974646e-18   1.72669195e-06   1.06482344e-06   2.80886252e-06
   5.11641190e-07   2.63268650e-01   1.76885113e-01   2.03947976e-01
   3.55892122e-01]
[2017-11-01 09:20:36,349] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.76843435e-01   3.04422557e-01   1.80193841e-01   2.60267258e-01
   7.82728940e-02   2.45499642e-14   8.71916658e-15   1.38684950e-14
   8.67431364e-15]
[2017-11-01 09:20:36,864] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.48257735e-04   3.73444885e-01   1.96425632e-01   3.53214622e-01
   7.67666027e-02   1.31656253e-09   6.81326939e-10   8.69942396e-10
   7.56719187e-10]
[2017-11-01 09:20:39,052] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.67628639e-06   3.60138744e-01   1.62987441e-01   3.97204310e-01
   7.96667933e-02   2.76134351e-08   1.50434332e-08   1.93356122e-08
   2.06266701e-08]
[2017-11-01 09:20:39,795] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.53901160e-01   2.70472020e-01   2.30522409e-01   2.66339689e-01
   7.87647143e-02   2.63709519e-13   9.45652180e-14   1.04083266e-13
   7.32149665e-14]
[2017-11-01 09:20:43,527] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.42034918e-01   2.27366328e-01   2.68746436e-01   2.76664555e-01
   8.51877630e-02   1.65775050e-11   5.75733818e-12   6.56145667e-12
   3.89560996e-12]
[2017-11-01 09:20:48,027] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.17392482e-06   3.96153718e-01   1.50588006e-01   3.80315155e-01
   7.29397014e-02   7.19067899e-08   4.06040606e-08   5.22274135e-08
   5.87836162e-08]
[2017-11-01 09:20:50,913] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.56129855e-03   3.45867664e-01   2.37976074e-01   3.25806230e-01
   8.27887729e-02   2.93364673e-11   1.29557554e-11   1.49495728e-11
   1.36077954e-11]
[2017-11-01 09:20:52,871] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08890489  0.11775333  0.155352    0.1404932   0.09841023  0.11792032
  0.10331042  0.10079932  0.07705634]
[2017-11-01 09:20:55,554] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.40667337e-03   3.84354353e-01   1.95543647e-01   3.35608333e-01
   8.00870359e-02   1.23324389e-11   5.77824594e-12   7.74445699e-12
   6.95576452e-12]
[2017-11-01 09:20:58,362] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.11317105e-09   2.40318701e-01   1.33929059e-01   3.38841647e-01
   7.29204789e-02   6.56654015e-02   4.39634062e-02   5.01664318e-02
   5.41948602e-02]
[2017-11-01 09:20:58,507] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.12686574e-06   3.46271336e-01   1.80831283e-01   3.87758166e-01
   8.51297900e-02   1.44274884e-06   8.88485602e-07   1.06041296e-06
   9.68216796e-07]
[2017-11-01 09:20:58,572] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.10657492e-04   3.78762186e-01   1.86490804e-01   3.54610890e-01
   7.97254965e-02   1.93183558e-09   1.08554832e-09   1.36056499e-09
   1.06276665e-09]
[2017-11-01 09:21:00,964] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.29400787e-09   3.43312979e-01   1.44518584e-01   3.75585526e-01
   6.95611984e-02   2.08663084e-02   1.28181446e-02   1.45022711e-02
   1.88350398e-02]
[2017-11-01 09:21:02,384] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.02420508e-05   3.87104303e-01   1.66745722e-01   3.67825180e-01
   7.83144981e-02   4.60691467e-08   2.54565560e-08   2.93916642e-08
   3.04229104e-08]
[2017-11-01 09:21:02,846] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.88147213e-04   3.59431356e-01   2.14609891e-01   3.41785878e-01
   8.39847475e-02   1.81710984e-08   9.16408993e-09   9.24259069e-09
   8.22743207e-09]
[2017-11-01 09:21:07,181] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.47107974e-01   2.39180952e-01   2.60080487e-01   2.64276952e-01
   8.93535763e-02   5.22978848e-11   1.85370278e-11   2.04093322e-11
   1.06733832e-11]
[2017-11-01 09:21:11,424] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.83476411e-07   3.45389187e-01   1.89223021e-01   3.75695258e-01
   8.95874351e-02   3.41666819e-05   2.08818510e-05   2.39163310e-05
   2.50740468e-05]
[2017-11-01 09:21:13,020] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.17673171e-17   5.67137386e-06   3.14592035e-06   7.59495833e-06
   1.43421050e-06   2.80089766e-01   1.99872047e-01   2.03565508e-01
   3.16454828e-01]
[2017-11-01 09:21:17,553] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.18620084e-06   2.40459040e-01   2.80597955e-01   3.73141259e-01
   1.01458512e-01   1.47619972e-03   8.33435101e-04   9.44492174e-04
   1.08494947e-03]
[2017-11-01 09:21:22,066] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07888678  0.10032069  0.1380361   0.12394853  0.08764458  0.15282293
  0.11686271  0.12364299  0.07783473]
[2017-11-01 09:21:22,524] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.54622146e-02   2.10004851e-01   3.21673632e-01   2.90457189e-01
   1.02401294e-01   2.65964843e-07   1.33484747e-07   2.07366057e-07
   2.57807528e-07]
[2017-11-01 09:21:23,165] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07160047  0.09218828  0.12559541  0.11347271  0.08891248  0.15499943
  0.12945946  0.1300083   0.09376353]
[2017-11-01 09:21:25,306] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09782135  0.09964573  0.13285305  0.11779628  0.10709283  0.11399342
  0.11962073  0.11579385  0.09538287]
[2017-11-01 09:21:26,248] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12701739  0.14378907  0.17982224  0.16406263  0.09538127  0.09718053
  0.06919079  0.07761575  0.0459404 ]
[2017-11-01 09:21:28,209] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11359292  0.11031601  0.14492249  0.12785049  0.11088643  0.10481949
  0.10632627  0.10402501  0.0772609 ]
[2017-11-01 09:21:28,233] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10408804  0.10449663  0.13938166  0.12312429  0.10766307  0.11171704
  0.11371032  0.11083052  0.08498838]
[2017-11-01 09:21:29,945] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12873119  0.11889259  0.14387514  0.13221474  0.107671    0.10450751
  0.09945469  0.09670915  0.06794392]
[2017-11-01 09:21:30,370] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09656025  0.09799334  0.13187653  0.11697861  0.10585284  0.1157135
  0.12069928  0.11778618  0.09653945]
[2017-11-01 09:21:30,905] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10262393  0.1025048   0.1355065   0.121141    0.10592419  0.11746272
  0.11502568  0.11361406  0.0861971 ]
[2017-11-01 09:21:30,972] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11368082  0.11023536  0.140728    0.12686028  0.10771976  0.11422789
  0.1058533   0.10588803  0.07480653]
[2017-11-01 09:21:31,418] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11950624  0.11875911  0.13913667  0.13681637  0.08921271  0.12554114
  0.09482743  0.10895039  0.06725002]
[2017-11-01 09:21:33,346] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08378194  0.11272287  0.15694231  0.13780098  0.09068219  0.13322392
  0.10090353  0.10751538  0.07642691]
[2017-11-01 09:21:33,757] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.43058583e-01   2.06592217e-01   2.84492940e-01   2.61382282e-01
   1.04458876e-01   6.69646988e-06   3.27342377e-06   3.36989478e-06
   1.72746218e-06]
[2017-11-01 09:21:33,821] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.03121661e-03   2.38929674e-01   3.13873112e-01   3.24563712e-01
   1.13148630e-01   1.53025918e-04   9.58137898e-05   1.07151740e-04
   9.77132368e-05]
[2017-11-01 09:21:36,620] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.35304651e-06   2.88714737e-01   2.43341178e-01   3.33090425e-01
   7.49294460e-02   1.70381088e-02   1.05687147e-02   1.36442082e-02
   1.86707769e-02]
[2017-11-01 09:21:43,785] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.1036628   0.12163038  0.14890191  0.13428248  0.09779111  0.12532677
  0.10404471  0.09901464  0.06534527]
[2017-11-01 09:21:45,802] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13230562  0.12000057  0.14889686  0.14384009  0.11094978  0.11043695
  0.08504219  0.09168144  0.05684645]
[2017-11-01 09:21:46,300] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.09980106e-01   2.09324285e-01   3.02187979e-01   2.65217036e-01
   1.12773895e-01   1.67499253e-04   1.02963662e-04   1.33150374e-04
   1.13213813e-04]
[2017-11-01 09:21:47,617] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09702528  0.10062338  0.13305514  0.1163897   0.11135381  0.10970838
  0.12224413  0.11189545  0.09770478]
[2017-11-01 09:21:47,776] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11479479  0.11227896  0.1442821   0.12628655  0.11473547  0.10087799
  0.1075306   0.10038356  0.07882999]
[2017-11-01 09:21:48,851] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13967068  0.12498025  0.15826038  0.14983848  0.10502875  0.1097943
  0.07866155  0.08674401  0.04702169]
[2017-11-01 09:21:49,095] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.18367767  0.18345219  0.21842238  0.20068581  0.10626151  0.03938179
  0.02669274  0.02738751  0.01403832]
[2017-11-01 09:21:49,689] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.86254215e-02   2.28737846e-01   3.12652349e-01   2.68079430e-01
   9.19037536e-02   3.98933423e-07   1.89987446e-07   3.08982948e-07
   2.93357203e-07]
[2017-11-01 09:21:50,193] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08270271  0.1045211   0.14309494  0.12847294  0.08904902  0.14805771
  0.11053914  0.11810157  0.07546099]
[2017-11-01 09:21:52,690] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.14211890e-02   3.25236857e-01   2.00067103e-01   3.04647237e-01
   8.86276439e-02   7.98629216e-14   3.28182170e-14   4.76490558e-14
   3.98098472e-14]
[2017-11-01 09:21:55,988] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.70481741e-01   2.90566176e-01   1.73711613e-01   2.90903330e-01
   7.43371695e-02   6.00047669e-16   2.11067667e-16   3.38915405e-16
   2.76235073e-16]
[2017-11-01 09:21:58,161] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.29457933e-02   2.62424439e-01   2.95412123e-01   3.26961488e-01
   9.22560915e-02   3.81795873e-10   1.46914939e-10   1.66575545e-10
   1.19685470e-10]
[2017-11-01 09:22:16,846] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.54195338e-38   3.76556438e-18   1.09664462e-18   5.75618651e-18
   8.89201788e-19   2.59516239e-01   1.91717699e-01   2.04899937e-01
   3.43866140e-01]
[2017-11-01 09:22:19,903] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.30642006e-04   3.49431634e-01   1.95219398e-01   3.66558999e-01
   8.85593593e-02   5.43493972e-10   2.49148785e-10   2.81363571e-10
   2.61324934e-10]
[2017-11-01 09:22:23,000] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.94440382e-04   2.78363645e-01   2.95544386e-01   3.33462805e-01
   9.20245796e-02   4.48251649e-06   2.04028697e-06   2.19817980e-06
   1.52093946e-06]
[2017-11-01 09:22:23,194] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.73547203e-07   5.73538132e-02   7.12620765e-02   9.27732363e-02
   2.61090640e-02   2.59823978e-01   1.65725946e-01   1.63977727e-01
   1.62973732e-01]
[2017-11-01 09:22:28,772] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.97494100e-02   3.35110873e-01   2.22837195e-01   3.26529890e-01
   7.57725909e-02   1.71524914e-12   6.74268421e-13   9.69447612e-13
   8.63284596e-13]
[2017-11-01 09:22:32,459] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.03448816  0.16852559  0.24658309  0.21796438  0.10136517  0.0828171
  0.0526295   0.05743361  0.03819341]
[2017-11-01 09:22:37,394] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.53746956e-26   1.63473627e-11   7.62034706e-12   2.35828961e-11
   4.62945611e-12   2.85585374e-01   2.03222305e-01   2.17394546e-01
   2.93797821e-01]
[2017-11-01 09:22:38,337] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.92737968e-07   3.40387523e-01   1.74613282e-01   4.03874904e-01
   8.11185092e-02   1.71259683e-06   9.94113520e-07   1.13368594e-06
   1.40595205e-06]
[2017-11-01 09:22:40,747] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.32587518e-05   3.14988762e-01   2.33819187e-01   3.68056953e-01
   8.31091478e-02   1.11799898e-06   5.63900585e-07   4.91602748e-07
   4.88991759e-07]
[2017-11-01 09:22:41,519] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09600478  0.14806627  0.19641201  0.16736428  0.10116443  0.09819603
  0.07085515  0.07422015  0.04771692]
[2017-11-01 09:22:43,190] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12301409  0.20510963  0.29076657  0.25649688  0.11821218  0.00267001
  0.00140286  0.00150736  0.00082042]
[2017-11-01 09:22:50,338] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.39870603e-08   1.96628451e-01   2.02867016e-01   3.29521894e-01
   7.27695301e-02   7.61745870e-02   4.38844524e-02   3.47504355e-02
   4.34036329e-02]
[2017-11-01 09:22:50,487] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.15870675e-05   1.09035678e-01   1.02715179e-01   1.18970931e-01
   3.77856493e-02   2.26668075e-01   1.56022042e-01   1.50143415e-01
   9.86273587e-02]
[2017-11-01 09:22:51,367] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.00161378  0.25153008  0.30273265  0.32193285  0.11207318  0.00376756
  0.00218955  0.00238162  0.00177868]
[2017-11-01 09:22:51,893] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.25002831e-01   2.25262105e-01   2.83678114e-01   2.67672777e-01
   9.83842015e-02   7.33459249e-09   2.85076340e-09   3.24823102e-09
   1.76712434e-09]
[2017-11-01 09:22:56,117] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.55530232e-07   3.41360629e-01   1.65535301e-01   4.02700096e-01
   9.03991237e-02   1.32790490e-06   7.47597198e-07   9.44042483e-07
   9.39931624e-07]
[2017-11-01 09:22:58,322] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.69665334e-04   4.12770033e-01   1.65198818e-01   3.52996290e-01
   6.85652345e-02   8.66086976e-12   3.42451111e-12   5.25452598e-12
   4.65923177e-12]
[2017-11-01 09:23:02,490] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07496984  0.11054872  0.14734145  0.1320055   0.0937451   0.14207385
  0.10737193  0.11488607  0.07705749]
[2017-11-01 09:23:09,242] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.30842954e-01   2.54759163e-01   2.68541962e-01   2.55935818e-01
   8.99200961e-02   1.36688811e-08   5.59793989e-09   5.62516878e-09
   3.06809689e-09]
[2017-11-01 09:23:13,932] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.17398546e-04   4.00039434e-01   1.80014998e-01   3.37082922e-01
   8.25452432e-02   7.32815364e-10   3.75475262e-10   4.93854235e-10
   3.74342612e-10]
[2017-11-01 09:23:19,477] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.27327851e-04   3.22592348e-01   2.70203084e-01   3.20688099e-01
   8.60923678e-02   8.60433211e-05   4.37265626e-05   4.23334095e-05
   2.46732761e-05]
[2017-11-01 09:23:19,970] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.05534732  0.1168048   0.18826823  0.15557872  0.09109581  0.1270916
  0.08868092  0.10352043  0.07361224]
[2017-11-01 09:23:22,331] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.44799754e-01   3.13341588e-01   1.98853180e-01   2.61870623e-01
   8.11348706e-02   9.13162341e-13   3.60596752e-13   5.43347268e-13
   3.38057327e-13]
[2017-11-01 09:23:24,603] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.11436366e-22   5.46503465e-09   2.45450460e-09   6.82734047e-09
   1.22867805e-09   2.67747343e-01   2.05282748e-01   2.08623677e-01
   3.18346202e-01]
[2017-11-01 09:23:25,618] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.55993658e-02   3.33944649e-01   2.43518904e-01   3.09626877e-01
   7.73101449e-02   1.42797302e-10   6.12665960e-11   8.31240632e-11
   7.07156833e-11]
[2017-11-01 09:23:25,830] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.40077858e-26   8.28242336e-12   3.58064555e-12   1.03224382e-11
   1.86226880e-12   2.60195315e-01   2.09091946e-01   2.12177366e-01
   3.18535388e-01]
[2017-11-01 09:23:28,548] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.90575305e-24   1.50371920e-11   1.06076276e-11   2.20616910e-11
   4.58692416e-12   2.61445284e-01   1.78091705e-01   2.01628909e-01
   3.58834088e-01]
[2017-11-01 09:23:35,039] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.16692868e-03   3.03462446e-01   2.44931519e-01   3.55509698e-01
   9.49293822e-02   1.43152579e-09   6.22379093e-10   6.62701061e-10
   5.87246030e-10]
[2017-11-01 09:23:35,189] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.15577693e-03   2.91289121e-01   2.96658337e-01   3.14973056e-01
   9.29227769e-02   4.19840859e-07   1.90610749e-07   2.07747505e-07
   1.38774539e-07]
[2017-11-01 09:23:35,235] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.02314659  0.18029206  0.25337631  0.22437195  0.09661867  0.08077567
  0.05205768  0.05489627  0.03446478]
[2017-11-01 09:23:38,381] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.47604881e-29   4.47637261e-13   2.24051301e-13   8.44632307e-13
   1.41752251e-13   2.80378252e-01   1.86106488e-01   2.17593819e-01
   3.15921515e-01]
[2017-11-01 09:23:40,883] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.92443997e-02   3.60530019e-01   1.89499572e-01   3.16616863e-01
   6.41090497e-02   7.96811009e-14   2.37275562e-14   3.90449866e-14
   3.07563830e-14]
[2017-11-01 09:23:40,964] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.81556149e-02   3.66613805e-01   1.91624120e-01   3.20313185e-01
   6.32932186e-02   2.48952877e-13   7.62049047e-14   1.24526013e-13
   1.02776748e-13]
[2017-11-01 09:23:46,847] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  0.00000000e+00   1.13441520e-27   6.61940870e-28   2.23542515e-27
   3.58362142e-28   2.30337366e-01   1.69964567e-01   1.99115410e-01
   4.00582701e-01]
[2017-11-01 09:23:50,224] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.03131502e-18   8.16569809e-07   3.64279884e-07   9.42681197e-07
   2.08201172e-07   3.08372110e-01   2.07062840e-01   2.23512828e-01
   2.61049956e-01]
[2017-11-01 09:23:51,387] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.64217227e-21   5.32519238e-08   2.18298837e-08   6.43635900e-08
   1.06855662e-08   2.82114059e-01   1.93888068e-01   2.11029455e-01
   3.12968254e-01]
[2017-11-01 09:24:00,563] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.23590365e-01   2.78889418e-01   2.22655594e-01   2.98748463e-01
   7.61162564e-02   2.38807509e-13   9.79555724e-14   1.36951594e-13
   1.16855269e-13]
[2017-11-01 09:24:03,351] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.52086029e-04   2.20615551e-01   2.92837292e-01   3.25035304e-01
   1.05361015e-01   1.68338716e-02   1.11237094e-02   1.34426532e-02
   1.44985355e-02]
[2017-11-01 09:24:05,637] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.64853074e-05   3.34372520e-01   2.14236483e-01   3.65018457e-01
   8.63258988e-02   5.77510484e-08   3.29030421e-08   4.01595486e-08
   3.87278725e-08]
[2017-11-01 09:24:06,925] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.92891225e-01   2.73802519e-01   1.90643966e-01   2.72103220e-01
   7.05590621e-02   1.90789555e-15   6.20102815e-16   9.96972814e-16
   6.92852199e-16]
[2017-11-01 09:24:09,104] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.21085521e-31   1.19341860e-13   5.05279005e-14   1.90370492e-13
   3.03377793e-14   2.75299460e-01   1.88956484e-01   2.05085278e-01
   3.30658793e-01]
[2017-11-01 09:24:09,974] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.26704767e-01   2.49545127e-01   2.66244054e-01   2.69896746e-01
   8.76092762e-02   3.98254818e-10   1.47694898e-10   1.52480931e-10
   7.78273695e-11]
[2017-11-01 09:24:13,509] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.54722464e-02   3.24247509e-01   2.19366699e-01   2.78348386e-01
   8.25651139e-02   9.77141892e-12   4.00742937e-12   5.78416438e-12
   3.82730176e-12]
[2017-11-01 09:24:18,846] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12099628  0.16413537  0.19011584  0.16471869  0.11199336  0.08325372
  0.06467059  0.06313057  0.03698556]
[2017-11-01 09:24:20,259] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.17427477  0.21259287  0.25425795  0.2333843   0.1136869   0.00515218
  0.00310646  0.00264961  0.00089499]
[2017-11-01 09:24:22,468] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.79304400e-11   2.41406281e-02   1.48676168e-02   3.23309749e-02
   7.19532650e-03   2.75904119e-01   1.79684967e-01   2.02043742e-01
   2.63832569e-01]
[2017-11-01 09:24:22,663] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.58857897e-01   2.82344818e-01   2.10352987e-01   2.70378977e-01
   7.80652910e-02   8.89232129e-14   3.24837169e-14   4.77965818e-14
   3.42840007e-14]
[2017-11-01 09:24:24,893] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.80475295e-01   2.23852426e-01   2.60900587e-01   2.51515120e-01
   8.32566097e-02   2.88866275e-11   1.07317375e-11   1.21293331e-11
   6.82650507e-12]
[2017-11-01 09:24:27,902] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.04972043  0.08927692  0.13426001  0.11520637  0.05718291  0.17094602
  0.1262681   0.15108509  0.10605416]
[2017-11-01 09:24:29,168] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.10148846e-09   2.63156056e-01   1.56443864e-01   3.83650094e-01
   7.51290470e-02   3.58542129e-02   2.34249551e-02   2.46301908e-02
   3.77115980e-02]
[2017-11-01 09:24:31,701] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.80039099e-12   5.15104970e-04   3.98528471e-04   6.72695402e-04
   1.62684591e-04   2.69675732e-01   1.68660939e-01   2.04071954e-01
   3.55842322e-01]
[2017-11-01 09:24:32,048] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.80469096e-20   6.05790120e-08   3.43718227e-08   8.93116692e-08
   1.88026181e-08   2.88445473e-01   1.97695702e-01   2.03238040e-01
   3.10620606e-01]
[2017-11-01 09:24:39,585] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.19757855e-01   2.25698188e-01   2.29088068e-01   2.46391430e-01
   7.90644810e-02   1.17593726e-10   4.13492539e-11   4.50413006e-11
   1.80724220e-11]
[2017-11-01 09:24:54,456] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10216223  0.15767398  0.21337727  0.19773732  0.10628987  0.07617348
  0.05256394  0.05587318  0.03814874]
[2017-11-01 09:24:54,595] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.13819745e-02   2.19004989e-01   3.04862022e-01   2.77940273e-01
   1.06736951e-01   2.35580410e-05   1.41452829e-05   1.84599103e-05
   1.76381018e-05]
[2017-11-01 09:24:55,763] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.54339238e-06   3.42088580e-01   1.84396580e-01   3.93237174e-01
   8.02746788e-02   1.58851392e-07   9.19838428e-08   1.07074989e-07
   1.26581696e-07]
[2017-11-01 09:24:56,280] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.06239432e-17   1.47111559e-05   7.21111746e-06   1.95004195e-05
   3.72581098e-06   2.96354502e-01   1.97197899e-01   2.12461799e-01
   2.93940604e-01]
[2017-11-01 09:24:58,072] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09308141  0.13590336  0.17672747  0.15364574  0.1020291   0.10898211
  0.0850885   0.08680165  0.05774058]
[2017-11-01 09:25:01,160] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.36834544e-04   3.76164079e-01   2.10828692e-01   3.24625224e-01
   8.75451788e-02   2.40824383e-09   1.27155575e-09   1.53313384e-09
   1.19506305e-09]
[2017-11-01 09:25:07,421] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.67706787e-04   3.73106301e-01   1.93700895e-01   3.55846703e-01
   7.69783929e-02   1.45784795e-09   7.41953277e-10   9.42148248e-10
   9.36101086e-10]
[2017-11-01 09:25:09,124] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07297721  0.08572502  0.11490895  0.10602114  0.09246059  0.14519481
  0.14264691  0.12943511  0.11063023]
[2017-11-01 09:25:12,863] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.70393752e-19   4.29478547e-07   2.20241589e-07   6.18399554e-07
   1.09420817e-07   2.78261542e-01   1.93276256e-01   2.00198099e-01
   3.28262687e-01]
[2017-11-01 09:25:14,820] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08825648  0.20161307  0.30773532  0.25645247  0.10956496  0.01403405
  0.00873551  0.00858323  0.00502496]
[2017-11-01 09:25:15,246] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10635975  0.11690851  0.14216879  0.12946418  0.1053633   0.11775826
  0.10965521  0.09980317  0.07251887]
[2017-11-01 09:25:17,133] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.06189004e-10   9.41833016e-03   6.40385645e-03   1.11332908e-02
   2.77650147e-03   2.53535628e-01   1.61928594e-01   2.19906166e-01
   3.34897578e-01]
[2017-11-01 09:25:23,183] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.08018002e-08   3.36276650e-01   1.66068152e-01   3.16515446e-01
   7.94206113e-02   3.27107422e-02   1.98615734e-02   2.19793916e-02
   2.71674413e-02]
[2017-11-01 09:25:27,323] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.58868063e-09   4.48532432e-01   1.13168202e-01   3.88599157e-01
   4.72201779e-02   8.61574837e-04   3.67159228e-04   6.08473259e-04
   6.42832834e-04]
[2017-11-01 09:25:32,890] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.52561234e-19   1.57850010e-07   7.09263688e-08   1.64591981e-07
   3.85602306e-08   3.01655233e-01   2.11149141e-01   2.30659753e-01
   2.56535470e-01]
[2017-11-01 09:25:34,994] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.39823808e-12   6.31158240e-03   2.99762003e-03   7.21950084e-03
   1.36060861e-03   2.98172474e-01   1.95129007e-01   2.12834284e-01
   2.75974929e-01]
[2017-11-01 09:25:37,475] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11320299  0.11247081  0.14311126  0.12805089  0.11617832  0.10068405
  0.10685837  0.09933885  0.08010454]
[2017-11-01 09:25:39,019] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.41741711e-02   2.34192297e-01   3.03650588e-01   2.64307767e-01
   1.13546476e-01   4.28260828e-05   2.54150764e-05   3.11969852e-05
   2.93119992e-05]
[2017-11-01 09:25:40,274] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.81663945e-09   3.14659268e-01   1.72219232e-01   3.98811907e-01
   8.19486156e-02   1.00801932e-02   6.28822669e-03   6.88648270e-03
   9.10613965e-03]
[2017-11-01 09:25:44,932] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08521864  0.21353957  0.29622388  0.26374251  0.11770752  0.00738037
  0.00540116  0.00581977  0.00496649]
[2017-11-01 09:25:46,680] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.92060889e-14   8.05904332e-04   4.75461362e-04   1.17685006e-03
   2.24962467e-04   2.85289079e-01   1.88035890e-01   2.09839642e-01
   3.14152181e-01]
[2017-11-01 09:25:46,785] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.37398916e-02   2.83989519e-01   2.42901713e-01   3.11012775e-01
   7.83560723e-02   4.76825339e-13   1.97853507e-13   2.75179022e-13
   2.44648485e-13]
[2017-11-01 09:25:48,704] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.15730178  0.13806209  0.17237218  0.15642992  0.11205886  0.0839439
  0.07003562  0.07249334  0.03730228]
[2017-11-01 09:25:50,576] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10474528  0.12931922  0.172849    0.15654045  0.09450123  0.11501978
  0.07918058  0.09093296  0.05691155]
[2017-11-01 09:25:50,903] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.79182538e-02   2.19014525e-01   3.12538892e-01   2.86434442e-01
   1.04093283e-01   1.74674369e-07   8.90272744e-08   1.29384773e-07
   1.51241892e-07]
[2017-11-01 09:25:55,801] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08206152  0.10034138  0.14222269  0.13251859  0.08366966  0.14492878
  0.10320381  0.12435466  0.08669887]
[2017-11-01 09:25:57,298] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07252707  0.08215791  0.10915484  0.09661808  0.09257131  0.13948728
  0.15233085  0.13216205  0.12299066]
[2017-11-01 09:25:59,299] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.06421243e-05   2.25762129e-01   3.01179111e-01   3.66235673e-01
   1.01098105e-01   1.54590642e-03   9.21976694e-04   1.20918173e-03
   2.01725774e-03]
[2017-11-01 09:25:59,429] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.17583092e-12   2.93322548e-04   2.78582273e-04   4.76545567e-04
   1.13393486e-04   2.43757486e-01   1.49135619e-01   1.93098933e-01
   4.12846178e-01]
[2017-11-01 09:26:00,257] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  7.85111543e-03   3.37175786e-01   2.22183883e-01   3.42166901e-01
   9.06223282e-02   1.79478012e-11   8.82387392e-12   1.13444367e-11
   9.99220064e-12]
[2017-11-01 09:26:06,323] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.07048945e-08   2.64117271e-01   1.48432419e-01   2.73826718e-01
   6.39735833e-02   7.16218725e-02   4.85394895e-02   5.63626699e-02
   7.31259286e-02]
[2017-11-01 09:26:10,564] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14898103  0.12476093  0.15629078  0.14877829  0.11729575  0.0989866
  0.0754137   0.08223529  0.04725754]
[2017-11-01 09:26:10,922] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14980029  0.15400518  0.20126636  0.18426523  0.10234058  0.07505528
  0.04839338  0.05572148  0.02915221]
[2017-11-01 09:26:13,451] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08652803  0.10071716  0.12960096  0.11966757  0.09737761  0.13793293
  0.11976485  0.12154929  0.08686156]
[2017-11-01 09:26:19,879] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07744461  0.10807819  0.14228223  0.13267577  0.10315942  0.12808901
  0.11030573  0.11391667  0.08404833]
[2017-11-01 09:26:20,257] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11781278  0.13207699  0.15608698  0.14274718  0.11374114  0.10240574
  0.09179661  0.08711792  0.05621474]
[2017-11-01 09:26:21,189] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.1853448   0.13683762  0.18205865  0.16748659  0.11346661  0.06694051
  0.05432736  0.06288803  0.03064988]
[2017-11-01 09:26:21,758] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.40383054e-04   2.76882887e-01   2.82580972e-01   3.32114369e-01
   1.05237313e-01   8.61697423e-04   5.37855958e-04   7.10122928e-04
   9.34407988e-04]
[2017-11-01 09:26:21,783] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.84827467e-07   1.55338228e-01   1.43270329e-01   1.99839041e-01
   5.85634373e-02   1.16657600e-01   7.16297999e-02   9.53731090e-02
   1.59328014e-01]
[2017-11-01 09:26:22,466] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.74337982e-08   3.16611320e-01   1.97144181e-01   3.81265670e-01
   9.35130417e-02   3.63614387e-03   2.37773801e-03   2.53580511e-03
   2.91602290e-03]
[2017-11-01 09:26:25,397] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.34900719e-01   2.37295225e-01   2.78869241e-01   2.50093132e-01
   9.88047197e-02   1.74330580e-05   8.01255192e-06   7.90899867e-06
   3.68260271e-06]
[2017-11-01 09:26:29,452] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.07738517e-01   2.85634577e-01   2.46578306e-01   2.89822936e-01
   7.02256337e-02   3.01890023e-12   1.20320149e-12   1.51341906e-12
   1.21304551e-12]
[2017-11-01 09:26:31,257] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.60030628e-04   3.16357791e-01   2.66347140e-01   3.30792248e-01
   8.63357708e-02   2.72056968e-06   1.63951768e-06   1.42855140e-06
   1.27023111e-06]
[2017-11-01 09:26:31,591] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09534754  0.10680801  0.13105375  0.1185097   0.10146518  0.12785952
  0.12514709  0.10897612  0.08483314]
[2017-11-01 09:26:31,882] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08361019  0.09437978  0.12037743  0.11160902  0.09942534  0.13418959
  0.13633813  0.11867107  0.10139948]
[2017-11-01 09:26:33,594] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08258419  0.11351289  0.16838051  0.14811255  0.08034467  0.13425694
  0.09285952  0.1094428   0.07050595]
[2017-11-01 09:26:34,336] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  5.23550334e-05   3.27275336e-01   2.46261343e-01   3.46051633e-01
   8.03517103e-02   2.48560718e-06   1.52434427e-06   1.64311166e-06
   1.86356635e-06]
[2017-11-01 09:26:34,469] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.05709171e-06   2.82111883e-01   2.16203690e-01   3.03827912e-01
   7.21247271e-02   3.54664996e-02   2.43712813e-02   2.86507346e-02
   3.72412391e-02]
[2017-11-01 09:26:37,820] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09276445  0.09876363  0.12842102  0.11403129  0.11068726  0.11281506
  0.12534164  0.11364003  0.10353559]
[2017-11-01 09:26:38,343] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.15517704  0.11773878  0.16667639  0.15498684  0.11206827  0.10049836
  0.06971509  0.08130722  0.04183207]
[2017-11-01 09:26:38,689] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14446098  0.11249217  0.14558123  0.14022672  0.10058013  0.11535858
  0.08648515  0.10052086  0.05429421]
[2017-11-01 09:26:39,656] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08146717  0.09315048  0.12263636  0.10995001  0.09453459  0.14133003
  0.13027808  0.12755276  0.0991005 ]
[2017-11-01 09:26:42,093] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10735094  0.10856892  0.13013022  0.12887199  0.08336869  0.13909929
  0.1057227   0.12027276  0.07661453]
[2017-11-01 09:26:44,257] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12910226  0.16914073  0.24541676  0.21823822  0.12192141  0.04545108
  0.02830056  0.02855976  0.01386915]
[2017-11-01 09:26:44,682] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09219427  0.11110044  0.14211509  0.12779026  0.09361932  0.1387224
  0.11068715  0.11175355  0.07201754]
[2017-11-01 09:26:45,809] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.66338657e-06   2.85081714e-01   2.12722838e-01   3.99625987e-01
   1.02563560e-01   1.03828108e-06   5.66687106e-07   6.76375407e-07
   9.85999236e-07]
[2017-11-01 09:26:49,657] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09735635  0.12505549  0.1543861   0.14053395  0.10282978  0.11778098
  0.09823228  0.09679127  0.06703384]
[2017-11-01 09:26:57,906] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.57809898e-03   3.01192880e-01   2.86205530e-01   3.14752847e-01
   9.12690461e-02   4.76607852e-07   2.40228275e-07   3.77787984e-07
   4.53901947e-07]
[2017-11-01 09:27:02,060] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.26645555e-05   3.05229366e-01   2.38119453e-01   3.10646892e-01
   8.17200318e-02   1.92397721e-02   1.31632984e-02   1.47057977e-02
   1.71626769e-02]
[2017-11-01 09:27:05,709] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09579315  0.10563246  0.13452253  0.12136443  0.10570502  0.12414159
  0.12345918  0.10814365  0.08123798]
[2017-11-01 09:27:08,452] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.19959907  0.14167604  0.17877448  0.16741793  0.11105549  0.06417121
  0.05184664  0.05803958  0.02741956]
[2017-11-01 09:27:09,283] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08244167  0.09206827  0.12479927  0.11066688  0.10423134  0.1243476
  0.13266279  0.12186553  0.10691662]
[2017-11-01 09:27:10,309] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07404149  0.20369713  0.33128706  0.27883551  0.11001974  0.00063898
  0.00038627  0.00053845  0.00055532]
[2017-11-01 09:27:10,423] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09764339  0.19482517  0.2906011   0.24233624  0.11452132  0.01899616
  0.01280436  0.01565768  0.0126146 ]
[2017-11-01 09:27:10,847] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10061278  0.12294391  0.15681426  0.14238939  0.08303266  0.12415018
  0.09407721  0.10673507  0.06924445]
[2017-11-01 09:27:11,818] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08201196  0.09479392  0.13110374  0.11642896  0.10228147  0.13240598
  0.1266614   0.12135618  0.09295636]
[2017-11-01 09:27:17,558] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13121067  0.14664938  0.18564403  0.16916756  0.09573101  0.09260216
  0.06412383  0.07270008  0.04217119]
[2017-11-01 09:27:18,967] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13631426  0.12065377  0.15087922  0.13470688  0.11684666  0.09050211
  0.09318618  0.0907924   0.06611861]
[2017-11-01 09:27:19,733] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.1170748   0.11184042  0.1414239   0.12963611  0.11751588  0.11237948
  0.09904204  0.10048272  0.0706047 ]
[2017-11-01 09:27:19,994] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13008119  0.10863965  0.13640742  0.13703915  0.1027504   0.11834453
  0.09591092  0.10440005  0.06642662]
[2017-11-01 09:27:20,664] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.48900452e-02   2.49300212e-01   3.02799255e-01   2.73443639e-01
   8.95660371e-02   2.70779282e-07   1.32076053e-07   2.01739482e-07
   2.01948922e-07]
[2017-11-01 09:27:20,876] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10228743  0.17065221  0.23300935  0.20780884  0.12181503  0.05682521
  0.04154425  0.03997086  0.02608684]
[2017-11-01 09:27:21,022] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.01697756  0.107705    0.1686969   0.15360613  0.0759501   0.161529
  0.10766392  0.12225917  0.08561218]
[2017-11-01 09:27:24,851] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.30785927e-01   2.77677655e-01   2.16044500e-01   3.00378621e-01
   7.51132071e-02   3.84899022e-14   1.51887627e-14   2.18610564e-14
   1.96572173e-14]
[2017-11-01 09:27:24,907] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.98209510e-06   3.29571337e-01   1.91032529e-01   3.99704278e-01
   7.96828195e-02   9.89333948e-09   5.78854786e-09   6.86861901e-09
   8.14052292e-09]
[2017-11-01 09:27:30,593] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.72203501e-11   1.32452818e-02   7.55788200e-03   1.56394150e-02
   3.58658028e-03   2.94945568e-01   1.84964105e-01   2.21075982e-01
   2.58985132e-01]
[2017-11-01 09:27:34,607] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10789137  0.11440943  0.13618627  0.12512492  0.10516275  0.11886355
  0.11565411  0.10110895  0.07559866]
[2017-11-01 09:27:37,294] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  9.75160856e-06   2.74025887e-01   2.29993641e-01   2.89910793e-01
   7.88506866e-02   3.55310291e-02   2.29762886e-02   2.97607630e-02
   3.89411189e-02]
[2017-11-01 09:27:37,470] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.28339332e-06   3.17119449e-01   2.31284961e-01   3.49053711e-01
   8.28594640e-02   5.48782013e-03   3.65723856e-03   4.20483341e-03
   6.33130223e-03]
[2017-11-01 09:27:40,133] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10810734  0.11108257  0.1410085   0.12594388  0.11279421  0.1065304
  0.11291625  0.10142929  0.0801876 ]
[2017-11-01 09:27:40,771] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.11454669  0.11325797  0.14158881  0.12491904  0.11416804  0.1016129
  0.10945079  0.09977306  0.08068272]
[2017-11-01 09:27:42,904] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09150036  0.0969786   0.13106072  0.11532981  0.11065676  0.11260836
  0.12323668  0.11583796  0.10279071]
[2017-11-01 09:27:44,600] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14434683  0.12674122  0.16971466  0.15160261  0.11002503  0.09345543
  0.07715049  0.08365156  0.04331211]
[2017-11-01 09:27:45,117] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.84166476e-01   2.05449417e-01   2.62283087e-01   2.43720472e-01
   1.04311496e-01   2.63634738e-05   1.46052407e-05   1.67892522e-05
   1.12508924e-05]
[2017-11-01 09:27:45,891] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14957489  0.11319993  0.14278363  0.13022636  0.10683051  0.10531639
  0.09400073  0.09651692  0.0615506 ]
[2017-11-01 09:27:45,909] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.15638596  0.11360299  0.1459533   0.13208047  0.10734615  0.10190009
  0.09068828  0.09409022  0.05795255]
[2017-11-01 09:27:46,311] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.16019459  0.11126715  0.15047209  0.1339256   0.10820623  0.10060406
  0.08780141  0.09350985  0.05401901]
[2017-11-01 09:27:46,683] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10810865  0.10538699  0.13642305  0.12093284  0.10906924  0.10829046
  0.11380889  0.1094024   0.0885775 ]
[2017-11-01 09:27:47,128] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14288847  0.12192771  0.15809526  0.14049461  0.11365888  0.09071394
  0.08612771  0.08875837  0.05733513]
[2017-11-01 09:27:48,697] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09685216  0.09996127  0.12221143  0.11754482  0.07761788  0.15417945
  0.11291893  0.13466406  0.08405005]
[2017-11-01 09:27:52,162] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.19162634  0.135489    0.18441148  0.16700722  0.11449561  0.06394227
  0.05250536  0.06103894  0.0294837 ]
[2017-11-01 09:27:54,753] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.13064758e-01   3.12973559e-01   2.14173242e-01   2.88315952e-01
   7.14724511e-02   3.76049804e-13   1.34498613e-13   1.86687254e-13
   1.33645522e-13]
[2017-11-01 09:27:54,820] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.22926138e-01   3.04310113e-01   2.14629009e-01   2.86047429e-01
   7.20872357e-02   3.02069134e-13   1.09554211e-13   1.51177749e-13
   1.08172172e-13]
[2017-11-01 09:28:00,356] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.03700318  0.18267183  0.27113563  0.23003609  0.10918739  0.06506361
  0.0369634   0.04299819  0.02494075]
[2017-11-01 09:28:01,525] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12086918  0.11867976  0.15168086  0.13330297  0.11300918  0.09977725
  0.10058762  0.09544502  0.06664815]
[2017-11-01 09:28:02,670] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.00367070e-05   2.49612048e-01   2.66555279e-01   3.76839340e-01
   1.06623799e-01   9.14519042e-05   4.96798275e-05   7.32865883e-05
   1.44973703e-04]
[2017-11-01 09:28:03,522] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  6.37334160e-05   3.27032566e-01   2.42241383e-01   3.58961344e-01
   7.17004463e-02   1.67796472e-07   9.68467830e-08   1.06693733e-07
   1.30805702e-07]
[2017-11-01 09:28:04,058] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10535899  0.12570797  0.15807964  0.14005293  0.09780162  0.11668719
  0.09850159  0.09361693  0.06419311]
[2017-11-01 09:28:05,286] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.0962909   0.10507848  0.13084538  0.11996152  0.10079235  0.12854928
  0.1213765   0.11199038  0.08511527]
[2017-11-01 09:28:08,179] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.12891643e-05   3.29845339e-01   2.32362196e-01   3.59659046e-01
   7.81004503e-02   5.43908527e-07   3.33505909e-07   3.54479283e-07
   4.29008367e-07]
[2017-11-01 09:28:09,424] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10628029  0.12145256  0.14590549  0.1307634   0.10000785  0.12413084
  0.10644177  0.09943572  0.065582  ]
[2017-11-01 09:28:11,287] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  2.18757197e-01   2.45407999e-01   2.24406660e-01   2.33427912e-01
   7.80002847e-02   2.31931770e-13   8.22573414e-14   1.06854128e-13
   7.11476166e-14]
[2017-11-01 09:28:14,284] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.10425019  0.12280535  0.15108168  0.13837855  0.09651722  0.11627642
  0.10462208  0.09507471  0.0709938 ]
[2017-11-01 09:28:17,138] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.27872658  0.14610043  0.20561261  0.18569034  0.10006186  0.03367943
  0.01881341  0.02424113  0.00707416]
[2017-11-01 09:28:18,653] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.20706101  0.16733421  0.20432806  0.19502625  0.1041482   0.04665389
  0.02821961  0.03299975  0.01422901]
[2017-11-01 09:28:21,935] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.15543905  0.1139017   0.14962021  0.13602044  0.10897493  0.1009865
  0.08795255  0.09141085  0.05569372]
[2017-11-01 09:28:22,098] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.1378213   0.11265738  0.14074104  0.13142124  0.10708903  0.11021677
  0.09696745  0.0975372   0.06554855]
[2017-11-01 09:28:22,133] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14918445  0.11463179  0.14632952  0.1342493   0.10941863  0.10311633
  0.0908066   0.092572    0.05969128]
[2017-11-01 09:28:22,475] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.16412129  0.12143973  0.1389724   0.13714258  0.09516292  0.11247332
  0.08292946  0.09797588  0.04978234]
[2017-11-01 09:28:23,319] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.14846015  0.12293327  0.16070138  0.14177708  0.12033636  0.08311547
  0.08306286  0.08345908  0.05615439]
[2017-11-01 09:28:23,847] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08625735  0.09194667  0.12716757  0.11145639  0.10966314  0.11371279
  0.12762487  0.12041682  0.11175441]
[2017-11-01 09:28:25,752] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  4.70603891e-02   2.44488239e-01   2.98727095e-01   3.14518869e-01
   9.52054113e-02   8.26575142e-10   3.84047266e-10   5.62420943e-10
   7.25177307e-10]
[2017-11-01 09:28:27,577] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.0906286   0.09641018  0.13635074  0.11926114  0.11070742  0.11422796
  0.120623    0.1162971   0.09549385]
[2017-11-01 09:28:28,859] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  1.33750111e-01   2.14630798e-01   2.98545152e-01   2.62662351e-01
   9.04115215e-02   2.29031833e-08   9.78103998e-09   1.31883642e-08
   9.26036137e-09]
[2017-11-01 09:28:29,706] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13814884  0.13295126  0.15628807  0.14692327  0.09277564  0.10908439
  0.08058612  0.09204032  0.05120207]
[2017-11-01 09:28:31,451] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09063075  0.09422705  0.13133658  0.114939    0.11206143  0.11007059
  0.12310147  0.11753528  0.10609782]
[2017-11-01 09:28:32,108] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13605997  0.12550029  0.1629997   0.14597912  0.11674287  0.08970761
  0.0851872   0.08435259  0.0534707 ]
[2017-11-01 09:28:33,776] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.1570276   0.15015778  0.17662767  0.16814564  0.10360635  0.08242371
  0.05980639  0.06565928  0.03654566]
[2017-11-01 09:28:34,494] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.12720504  0.13053794  0.18540943  0.15115426  0.07701849  0.11713985
  0.07101613  0.09425423  0.04626469]
[2017-11-01 09:28:39,549] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.0798275   0.08930907  0.1199472   0.10584072  0.10379733  0.12353919
  0.13682237  0.12441719  0.11649944]
[2017-11-01 09:28:40,039] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.0880834   0.1250667   0.17858957  0.15719345  0.08622433  0.12124469
  0.0851902   0.09488403  0.06352352]
[2017-11-01 09:28:40,412] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  3.79461912e-03   2.85597414e-01   2.94766665e-01   3.18621516e-01
   9.72067043e-02   3.89461502e-06   2.14347187e-06   3.14492081e-06
   3.87316186e-06]
[2017-11-01 09:28:41,811] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.09942511  0.10813965  0.13926624  0.12276871  0.10497861  0.11982098
  0.11483534  0.10973664  0.08102871]
[2017-11-01 09:28:44,986] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.21721801  0.13797003  0.17037188  0.16333237  0.09760428  0.07945789
  0.04973562  0.06094304  0.02336679]
[2017-11-01 09:28:45,198] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13894677  0.12051497  0.15061226  0.14043374  0.08628141  0.12574792
  0.08452967  0.10122687  0.05170636]
[2017-11-01 09:28:45,775] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [  8.81386623e-02   2.33005941e-01   3.15362275e-01   2.67709851e-01
   9.57714692e-02   3.89530896e-06   2.06465165e-06   3.02156582e-06
   2.82512474e-06]
[2017-11-01 09:28:47,213] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.08563023  0.09143081  0.12695365  0.11190891  0.10932738  0.11500346
  0.1279989   0.12060929  0.1111374 ]
[2017-11-01 09:28:47,998] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.07719497  0.08518829  0.12120615  0.1062627   0.10464     0.12061967
  0.13500366  0.12810811  0.12177642]
[2017-11-01 09:28:49,300] A3C_AGENT_WORKER-Thread-3 INFO:Softmax [ 0.13954842  0.17449559  0.23346439  0.20624706  0.10217723  0.05208043
  0.03363604  0.03813266  0.02021822]
[2017-11-01 09:28:53,167] A3C_AGENT_WORKER-Thread-3 INFO:Evaluation: average reward by now is -8912.2083
[2017-11-01 09:28:53,167] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 0, evaluation results [0.0, -8912.20829935259]
[2017-11-01 09:29:03,941] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.97309080e-09   8.77081677e-02   3.76973689e-01   3.86090070e-01
   1.49123788e-01   8.57848045e-06   2.51797246e-05   6.43990461e-06
   6.40440921e-05], sum to 1.0000
[2017-11-01 09:29:04,079] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [7.7, 93.0, 6.225, 260.0, 63.75, 0.0, 12.7, 7.25612432372729, 23.0, 23.59392077617759, 22.7, 1.0, 51.5639439573401], 
actual action is [12.7, 23.0], 
sim time next is 39000.0000, 
raw observation next is [7.7, 93.0, 6.183333333333333, 260.0, 65.0, 0.0, 12.7, 7.297615459357456, 23.0, 23.66515972236704, 22.7, 1.0, 42.51816615666706], 
processed observation next is [1.0, 0.43478260869565216, 0.5307692307692308, 0.93, 0.562121212121212, 0.7222222222222222, 0.17195767195767195, 0.0, 0.7116666666666667, 0.07297615459357455, 0.65, 0.683257986118352, 0.635, 1.0, 0.5002137194902007], 
reward next is -0.2866. 
=============================================
[2017-11-01 09:29:11,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  7.02724960e-15   1.29289161e-02   1.31253069e-02   1.18378391e-02
   1.17124282e-02   2.24587142e-01   2.05879018e-01   1.61280975e-01
   3.58648360e-01], sum to 1.0000
[2017-11-01 09:29:11,794] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.04999999999999999, 95.0, 4.066666666666666, 288.3333333333334, 0.0, 0.0, 5.075, 16.85374063060964, 30.0, 21.23657567833654, 21.5, 0.0, 52.31090450119571], 
actual action is [5.05, 30], 
sim time next is 86100.0000, 
raw observation next is [0.02500000000000001, 95.0, 4.083333333333333, 289.1666666666666, 0.0, 0.0, 5.05, 15.80625325270799, 30.0, 21.28834272018957, 21.5, 0.0, 51.29212264807914], 
processed observation next is [1.0, 1.0, 0.333974358974359, 0.95, 0.37121212121212116, 0.8032407407407405, 0.0, 0.0, 0.5841666666666666, 0.15806253252707989, 1.0, 0.5644171360094784, 0.575, 0.0, 0.6034367370362252], 
reward next is -0.3546. 
=============================================
[2017-11-01 09:29:12,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.60610533e-28   6.45987777e-12   7.48764592e-12   5.92267294e-12
   6.42468587e-12   3.25366825e-01   1.89576387e-01   1.17008686e-01
   3.68048131e-01], sum to 1.0000
[2017-11-01 09:29:12,557] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.35, 92.66666666666666, 5.908333333333333, 284.1666666666667, 0.0, 0.0, 4.7, 12.07902668232878, 26.0, 21.98019021617633, 21.5, 0.0, 45.56678044437758], 
actual action is [4.65, 30], 
sim time next is 88800.0000, 
raw observation next is [-0.4, 92.33333333333334, 6.166666666666666, 283.3333333333333, 0.0, 0.0, 4.65, 11.88697139000576, 30.0, 22.03386602035853, 21.5, 0.0, 45.69022970655024], 
processed observation next is [0.0, 0.0, 0.3230769230769231, 0.9233333333333335, 0.5606060606060606, 0.787037037037037, 0.0, 0.0, 0.5775, 0.1188697139000576, 1.0, 0.6016933010179265, 0.575, 0.0, 0.5375321141947087], 
reward next is -0.2688. 
=============================================
[2017-11-01 09:29:14,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-27.68869591]
 [-27.81429482]
 [-27.49497986]
 [-27.72076607]
 [-28.40629196]], R is [[-27.44638062]
 [-27.45789337]
 [-27.47620964]
 [-27.49429893]
 [-27.46496964]].
[2017-11-01 09:29:19,684] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.19619423
  0.33390063  0.17892058  0.29098454], sum to 1.0000
[2017-11-01 09:29:19,756] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 8.2, 270.0, 0.0, 0.0, -1.558333333333334, 12.27202386969232, 30.0, 21.45681055342425, 21.5, 0.0, 48.30346134447862], 
actual action is [-1.7000000000000002, 30], 
sim time next is 108300.0000, 
raw observation next is [-6.75, 74.41666666666667, 8.024999999999999, 268.3333333333333, 0.0, 0.0, -1.7, 12.38758858603457, 30.0, 21.42449955548675, 21.5, 0.0, 48.38134947900316], 
processed observation next is [0.0, 0.2608695652173913, 0.16025641025641027, 0.7441666666666668, 0.7295454545454544, 0.7453703703703703, 0.0, 0.0, 0.4716666666666667, 0.12387588586034569, 1.0, 0.5712249777743376, 0.575, 0.0, 0.5691923468118019], 
reward next is -0.3035. 
=============================================
[2017-11-01 09:29:22,537] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   3.41305933e-20   5.36327269e-20   1.61113296e-20
   1.96996924e-20   1.82019770e-01   3.88405502e-01   1.07948519e-01
   3.21626276e-01], sum to 1.0000
[2017-11-01 09:29:22,869] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-7.3, 68.0, 8.049999999999999, 265.0, 0.0, 0.0, -2.3, 11.48921534775628, 30.0, 21.87288865025055, 22.7, 1.0, 65.67861409719633], 
actual action is [-2.3, 30], 
sim time next is 114600.0000, 
raw observation next is [-7.299999999999999, 68.0, 8.266666666666666, 266.6666666666666, 12.33333333333333, 2.999999999999999, -2.3, 11.43718987994037, 30.0, 21.90419149107172, 22.7, 1.0, 65.77268664829889], 
processed observation next is [0.0, 0.30434782608695654, 0.1461538461538462, 0.68, 0.7515151515151515, 0.7407407407407405, 0.032627865961199286, 0.002999999999999999, 0.46166666666666667, 0.1143718987994037, 1.0, 0.595209574553586, 0.635, 1.0, 0.7737963135093987], 
reward next is -0.4441. 
=============================================
[2017-11-01 09:29:28,277] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  7.47712375e-06   3.37550044e-01   3.02661002e-01   1.23297878e-01
   2.36483589e-01   1.99948236e-09   3.12887294e-09   9.23595589e-10
   1.36461098e-09], sum to 1.0000
[2017-11-01 09:29:28,452] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-7.799999999999999, 79.0, 6.616666666666666, 258.3333333333333, 177.9166666666667, 33.0, -2.8, 10.46919754847694, 25.0, 22.61648869270754, 22.7, 1.0, 63.83954888412144], 
actual action is [-2.799999999999999, 23.0], 
sim time next is 124200.0000, 
raw observation next is [-7.8, 80.0, 6.4, 260.0, 190.0, 36.0, -2.799999999999999, 10.30469635715958, 23.0, 22.673109266529, 22.7, 1.0, 63.57289611388885], 
processed observation next is [0.0, 0.43478260869565216, 0.13333333333333333, 0.8, 0.5818181818181819, 0.7222222222222222, 0.5026455026455027, 0.036, 0.45333333333333337, 0.1030469635715958, 0.65, 0.63365546332645, 0.635, 1.0, 0.7479164248692806], 
reward next is -0.4255. 
=============================================
[2017-11-01 09:29:33,288] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   8.29599990e-37   1.48190375e-36   7.73508232e-37
   5.66999842e-37   8.81467834e-02   6.77060544e-01   5.26476949e-02
   1.82144985e-01], sum to 1.0000
[2017-11-01 09:29:33,353] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.7, 61.0, 7.2, 260.0, 143.5, 295.0, -1.791666666666667, 23.10980380141839, 13.0, 21.0331715807738, 22.7, 1.0, 13.51684984752731], 
actual action is [-1.7000000000000002, 18.0], 
sim time next is 137100.0000, 
raw observation next is [-6.7, 61.0, 7.283333333333333, 260.8333333333333, 144.25, 263.5, -1.7, 23.71242207799634, 18.0, 20.94700625704298, 22.7, 1.0, 13.08372607090156], 
processed observation next is [0.0, 0.6086956521739131, 0.16153846153846155, 0.61, 0.6621212121212121, 0.724537037037037, 0.3816137566137566, 0.2635, 0.4716666666666667, 0.2371242207799634, 0.4, 0.547350312852149, 0.635, 1.0, 0.15392618906943012], 
reward next is -0.1955. 
=============================================
[2017-11-01 09:29:39,245] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7842: loss -9.4726
[2017-11-01 09:29:39,904] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7901: loss -13.2523
[2017-11-01 09:29:40,028] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7908: loss -1.7310
[2017-11-01 09:29:40,097] A3C_AGENT_WORKER-Thread-7 INFO:Local step 500, global step 7916: loss 83.9230
[2017-11-01 09:29:40,142] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7919: loss -18.8488
[2017-11-01 09:29:40,340] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7939: loss 78.6886
[2017-11-01 09:29:40,353] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7940: loss -0.1961
[2017-11-01 09:29:40,678] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7972: loss -45.9360
[2017-11-01 09:29:40,861] A3C_AGENT_WORKER-Thread-8 INFO:Local step 500, global step 7988: loss 60.7350
[2017-11-01 09:29:40,889] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7989: loss -7.9015
[2017-11-01 09:29:41,225] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8013: loss 10.3446
[2017-11-01 09:29:41,809] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8056: loss 2.7215
[2017-11-01 09:29:41,939] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8067: loss -32.3161
[2017-11-01 09:29:42,074] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 8072: loss 82.4428
[2017-11-01 09:29:43,502] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 8155: loss 38.0703
[2017-11-01 09:29:43,565] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8158: loss -2.7488
[2017-11-01 09:29:43,975] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.21199611
  0.56885666  0.09946373  0.1196836 ], sum to 1.0000
[2017-11-01 09:29:44,218] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-7.508333333333333, 62.25, 7.491666666666666, 265.8333333333333, 0.0, 0.0, -2.466666666666667, 18.72639900358956, 30.0, 21.49928774198458, 22.7, 1.0, 65.50191630400158], 
actual action is [-2.508333333333333, 30], 
sim time next is 153000.0000, 
raw observation next is [-7.55, 62.5, 7.45, 265.0, 0.0, 0.0, -2.508333333333333, 18.42973817902441, 30.0, 21.5913847885557, 22.7, 1.0, 65.44207021799156], 
processed observation next is [0.0, 0.782608695652174, 0.13974358974358975, 0.625, 0.6772727272727272, 0.7361111111111112, 0.0, 0.0, 0.45819444444444446, 0.18429738179024413, 1.0, 0.579569239427785, 0.635, 1.0, 0.7699067084469595], 
reward next is -0.4771. 
=============================================
[2017-11-01 09:29:51,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.07383795
  0.78052449  0.11437642  0.03126114], sum to 1.0000
[2017-11-01 09:29:51,845] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.4, 69.0, 4.933333333333334, 260.0, 0.0, 0.0, -3.4, 24.02148995479457, 12.5, 21.0717999665747, 21.5, 0.0, 25.46726547129694], 
actual action is [-3.4000000000000004, 13.5], 
sim time next is 163500.0000, 
raw observation next is [-8.4, 69.25, 4.891666666666666, 260.0, 0.0, 0.0, -3.4, 24.81729402261514, 13.5, 20.98137570743789, 21.5, 0.0, 24.32826028884111], 
processed observation next is [0.0, 0.9130434782608695, 0.11794871794871795, 0.6925, 0.4446969696969696, 0.7222222222222222, 0.0, 0.0, 0.44333333333333336, 0.2481729402261514, 0.175, 0.5490687853718945, 0.575, 0.0, 0.28621482692754247], 
reward next is -0.2728. 
=============================================
[2017-11-01 09:30:03,113] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-64.42108917]
 [-67.4730072 ]
 [-66.12418365]
 [-65.73975372]
 [-64.75999451]], R is [[-67.6289978 ]
 [-67.66963959]
 [-67.71944427]
 [-67.78014374]
 [-67.85363007]].
[2017-11-01 09:30:04,688] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.07636270e-11   8.14987272e-02   8.36274207e-01   3.52937984e-03
   7.86977261e-02   1.58204528e-20   8.69833728e-22   1.09943134e-19
   7.72608048e-22], sum to 1.0000
[2017-11-01 09:30:04,767] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.9, 78.0, 3.766666666666667, 191.6666666666667, 0.0, 0.0, -3.9, 29.31831392421593, 30.0, 19.71326929541231, 21.5, 0.0, 47.45673775566019], 
actual action is [-3.9000000000000004, 29.0], 
sim time next is 194100.0000, 
raw observation next is [-8.9, 78.0, 3.683333333333333, 190.8333333333333, 0.0, 0.0, -3.9, 29.25322305837653, 29.0, 19.71862236033809, 21.5, 0.0, 47.35773268533102], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.10512820512820512, 0.78, 0.33484848484848484, 0.5300925925925924, 0.0, 0.0, 0.435, 0.2925322305837653, 0.95, 0.4859311180169046, 0.575, 0.0, 0.557149796298012], 
reward next is -0.7239. 
=============================================
[2017-11-01 09:30:14,620] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.4041068
  0.14092712  0.33161888  0.1233472 ], sum to 1.0000
[2017-11-01 09:30:14,843] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-8.608333333333334, 78.0, 5.391666666666666, 194.1666666666667, 37.75, 271.3333333333333, -13.65, 33.36137048269337, 10.0, 20.31680012386099, 22.7, 1.0, 0.0], 
actual action is [-3.6083333333333343, 12.0], 
sim time next is 204000.0000, 
raw observation next is [-8.566666666666666, 78.0, 5.433333333333334, 193.3333333333333, 41.5, 246.6666666666667, -3.608333333333334, 32.92501099372202, 12.0, 20.02630126690445, 22.7, 1.0, 61.18196999065449], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.11367521367521369, 0.78, 0.49393939393939396, 0.5370370370370369, 0.10978835978835978, 0.2466666666666667, 0.4398611111111111, 0.3292501099372202, 0.1, 0.5013150633452226, 0.635, 1.0, 0.719787882242994], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:30:15,083] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  4.79568504e-02   7.46041462e-02   8.05750191e-01   1.58299413e-02
   5.58588766e-02   8.35779929e-29   4.52511309e-30   2.17773535e-29
   4.55281676e-30], sum to 1.0000
[2017-11-01 09:30:15,332] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-8.733333333333334, 78.0, 5.266666666666667, 196.6666666666667, 28.33333333333334, 249.6666666666667, -3.775, 22.82491877934505, 15.0, 20.87159927031704, 22.7, 1.0, 45.14404169907245], 
actual action is [-3.7333333333333343, 14.0], 
sim time next is 203100.0000, 
raw observation next is [-8.691666666666666, 78.0, 5.308333333333333, 195.8333333333333, 31.16666666666666, 272.8333333333333, -3.733333333333334, 23.33901854365917, 14.0, 20.87284550458987, 22.7, 1.0, 42.26958440983648], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.11047008547008548, 0.78, 0.4825757575757575, 0.5439814814814814, 0.08245149911816577, 0.2728333333333333, 0.43777777777777777, 0.23339018543659168, 0.2, 0.5436422752294934, 0.635, 1.0, 0.49728922835101746], 
reward next is -0.3653. 
=============================================
[2017-11-01 09:30:24,109] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  7.44668692e-02   1.38191521e-01   7.12063313e-01   2.97894888e-02
   4.54887450e-02   6.32121485e-27   7.43302214e-28   1.17503066e-27
   3.33257178e-27], sum to 1.0000
[2017-11-01 09:30:24,290] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.2, 66.16666666666667, 5.933333333333333, 198.3333333333333, 145.0, 0.0, -0.2999999999999998, 26.4023637899084, 24.0, 20.70166574693122, 22.7, 1.0, 57.10843169954706], 
actual action is [-0.20000000000000018, 23.0], 
sim time next is 215700.0000, 
raw observation next is [-5.1, 65.58333333333333, 6.016666666666666, 199.1666666666667, 143.0, 0.0, -0.2000000000000002, 25.47591791353569, 23.0, 20.75327858301826, 22.7, 1.0, 67.23464191552894], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.20256410256410257, 0.6558333333333333, 0.5469696969696969, 0.5532407407407409, 0.3783068783068783, 0.0, 0.4966666666666667, 0.2547591791353569, 0.65, 0.5376639291509131, 0.635, 1.0, 0.790995787241517], 
reward next is -0.5229. 
=============================================
[2017-11-01 09:30:29,758] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.51807254e-02   1.09026834e-01   8.21168661e-01   2.07029879e-02
   2.39207987e-02   7.80880897e-34   4.08232055e-35   7.89582081e-35
   2.92944855e-34], sum to 1.0000
[2017-11-01 09:30:29,927] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.3, 61.5, 6.366666666666666, 230.0, 43.33333333333334, 0.0, 1.75, 23.85754690960654, 20.0, 21.21490867224334, 22.7, 1.0, 42.66441131163353], 
actual action is [1.7000000000000002, 19.0], 
sim time next is 230100.0000, 
raw observation next is [-3.35, 61.75, 6.233333333333333, 230.0, 40.16666666666667, 0.0, 1.7, 24.12118507711687, 19.0, 21.29861371832874, 22.7, 1.0, 39.68946790582728], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.24743589743589745, 0.6175, 0.5666666666666667, 0.6388888888888888, 0.1062610229276896, 0.0, 0.5283333333333333, 0.2412118507711687, 0.45, 0.5649306859164369, 0.635, 1.0, 0.46693491653914443], 
reward next is -0.3541. 
=============================================
[2017-11-01 09:30:37,522] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-60.3746376 ]
 [-62.7413826 ]
 [-62.36449814]
 [-62.43793869]
 [-60.82366562]], R is [[-63.06685638]
 [-63.43618774]
 [-63.80182648]
 [-64.1638031 ]
 [-64.52217102]].
[2017-11-01 09:30:47,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.05053373e-01   1.74674094e-01   5.53776443e-01   4.73859608e-02
   1.19110122e-01   8.83266831e-22   1.34006074e-22   6.83348576e-22
   6.13878329e-22], sum to 1.0000
[2017-11-01 09:30:47,357] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.4, 65.0, 6.324999999999999, 221.6666666666667, 0.0, 0.0, 1.6, 20.44689534213283, 19.5, 22.19025889780965, 21.5, 0.0, 29.52949338163055], 
actual action is [1.6, 17.5], 
sim time next is 247200.0000, 
raw observation next is [-3.4, 65.0, 6.5, 223.3333333333333, 0.0, 0.0, 1.6, 21.10174854224187, 17.5, 22.10529924361794, 21.5, 0.0, 28.28443347539432], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.24615384615384614, 0.65, 0.5909090909090909, 0.6203703703703702, 0.0, 0.0, 0.5266666666666667, 0.21101748542241872, 0.375, 0.605264962180897, 0.575, 0.0, 0.332758040886992], 
reward next is -0.1664. 
=============================================
[2017-11-01 09:30:53,116] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  4.56481315e-02   2.45060414e-01   4.62241381e-01   1.84333846e-02
   2.28616685e-01   3.58068298e-31   1.19426523e-31   1.14357846e-30
   1.39257327e-30], sum to 1.0000
[2017-11-01 09:30:53,167] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.483333333333333, 66.66666666666667, 7.016666666666667, 230.0, 0.0, 0.0, 1.558333333333334, 30.68496223881971, 16.0, 20.57644659838305, 21.5, 0.0, 21.0819225913201], 
actual action is [1.516666666666667, 15.0], 
sim time next is 249300.0000, 
raw observation next is [-3.525, 67.5, 6.925000000000001, 230.0, 0.0, 0.0, 1.516666666666667, 31.30707331230186, 15.0, 20.4992269445605, 21.5, 0.0, 18.4206138545966], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.24294871794871795, 0.675, 0.6295454545454546, 0.6388888888888888, 0.0, 0.0, 0.5252777777777777, 0.3130707331230186, 0.25, 0.524961347228025, 0.575, 0.0, 0.2167131041717247], 
reward next is -0.3585. 
=============================================
[2017-11-01 09:30:58,704] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   3.16237468e-36   4.16321083e-36   3.46103300e-37
   1.33789000e-36   2.43359618e-02   1.53559949e-02   1.77583858e-01
   7.82724142e-01], sum to 1.0000
[2017-11-01 09:30:58,841] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.35, 79.75, 6.374999999999999, 270.0, 0.0, 0.0, 0.7000000000000002, 25.88801940398925, 27.0, 20.85005838065729, 21.5, 0.0, 40.95131660067377], 
actual action is [0.6500000000000004, 29.0], 
sim time next is 258600.0000, 
raw observation next is [-4.399999999999999, 79.5, 6.283333333333333, 273.3333333333333, 0.0, 0.0, 0.6500000000000004, 24.87526941364778, 29.0, 20.78606235324263, 21.5, 0.0, 53.88227987336592], 
processed observation next is [0.16666666666666666, 1.0, 0.22051282051282056, 0.795, 0.5712121212121212, 0.7592592592592592, 0.0, 0.0, 0.5108333333333334, 0.2487526941364778, 0.95, 0.5393031176621316, 0.575, 0.0, 0.6339091749807755], 
reward next is -0.4954. 
=============================================
[2017-11-01 09:31:21,569] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15588: loss 1.8199
[2017-11-01 09:31:22,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15627: loss 127.6438
[2017-11-01 09:31:24,012] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15752: loss 12.5606
[2017-11-01 09:31:24,955] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15809: loss 235.3026
[2017-11-01 09:31:25,920] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15873: loss -42.2381
[2017-11-01 09:31:26,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.05853528e-28   4.94530650e-05   1.04490703e-03   1.74755351e-05
   9.60943653e-05   3.08522284e-01   1.06867123e-02   8.73899758e-02
   5.92193067e-01], sum to 1.0000
[2017-11-01 09:31:26,578] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.6, 53.58333333333333, 7.783333333333333, 265.8333333333333, 104.0833333333333, 666.3333333333334, -5.6, 37.89672872088225, 18.0, 19.11261282494986, 22.7, 1.0, 27.55535205196718], 
actual action is [-5.6, 23.0], 
sim time next is 301200.0000, 
raw observation next is [-10.6, 52.66666666666667, 7.866666666666666, 266.6666666666667, 102.1666666666667, 674.6666666666666, -5.6, 37.9877577535408, 23.0, 19.18393654441878, 22.7, 1.0, 25.51767936876807], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.06153846153846155, 0.5266666666666667, 0.7151515151515151, 0.7407407407407408, 0.2702821869488537, 0.6746666666666666, 0.4066666666666666, 0.37987757753540796, 0.65, 0.4591968272209391, 0.635, 1.0, 0.30020799257374203], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:31:26,810] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15931: loss -96.8912
[2017-11-01 09:31:27,048] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15957: loss 42.2248
[2017-11-01 09:31:27,591] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16000: loss -30.6223
[2017-11-01 09:31:28,010] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16033: loss 43.2216
[2017-11-01 09:31:28,093] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16040: loss -160.2551
[2017-11-01 09:31:29,743] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 16138: loss -156.7960
[2017-11-01 09:31:30,081] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1000, global step 16162: loss -1.7121
[2017-11-01 09:31:30,139] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16166: loss 43.9422
[2017-11-01 09:31:31,467] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16257: loss 21.7520
[2017-11-01 09:31:32,798] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 16348: loss 5.8245
[2017-11-01 09:31:32,979] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1000, global step 16365: loss -39.3371
[2017-11-01 09:31:39,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-62.40729141]
 [-63.91329956]
 [-64.74551392]
 [-64.01298523]
 [-62.62273026]], R is [[-63.68172455]
 [-63.55866623]
 [-63.43810272]
 [-63.32058716]
 [-63.20710373]].
[2017-11-01 09:31:44,505] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-62.97943115]
 [-60.21927643]
 [-62.77170944]
 [-61.8181839 ]
 [-63.03281403]], R is [[-60.22724915]
 [-60.14634705]
 [-60.07012558]
 [-60.0201416 ]
 [-59.98376083]].
[2017-11-01 09:31:50,046] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   1.76785001e-16   2.64447921e-16   4.09049151e-17
   3.67598005e-16   7.86957443e-02   1.93075985e-02   8.79523456e-02
   8.14044356e-01], sum to 1.0000
[2017-11-01 09:31:50,189] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-12.8, 71.16666666666667, 6.016666666666667, 288.3333333333334, 0.0, 0.0, -7.800000000000001, 34.78518140311888, 16.0, 20.44000291706867, 21.5, 0.0, 27.18434958311778], 
actual action is [-7.800000000000001, 21.0], 
sim time next is 332100.0000, 
raw observation next is [-12.8, 71.75, 5.975, 287.5, 0.0, 0.0, -7.800000000000001, 36.085642562834, 21.0, 20.30043256720227, 21.5, 0.0, 26.33506307482027], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.00512820512820511, 0.7175, 0.5431818181818181, 0.7986111111111112, 0.0, 0.0, 0.37, 0.36085642562834, 0.55, 0.5150216283601136, 0.575, 0.0, 0.30982427146847374], 
reward next is -0.4548. 
=============================================
[2017-11-01 09:31:53,245] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.02243272e-15   4.09102768e-01   1.66822881e-01   2.37893928e-02
   4.00285006e-01   1.27359410e-22   1.32850203e-23   9.00746310e-23
   2.76476476e-21], sum to 1.0000
[2017-11-01 09:31:53,310] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-12.38333333333333, 64.16666666666667, 5.266666666666667, 281.6666666666667, 0.0, 0.0, -7.34166666666667, 40.85480792709402, 23.0, 19.32888614774153, 22.7, 1.0, 35.28398700217296], 
actual action is [-7.383333333333329, 21.0], 
sim time next is 328500.0000, 
raw observation next is [-12.425, 64.75, 5.35, 282.5, 0.0, 0.0, -7.383333333333329, 40.2754547711461, 21.0, 19.30217529486454, 22.7, 1.0, 55.45166301825006], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.014743589743589726, 0.6475, 0.48636363636363633, 0.7847222222222222, 0.0, 0.0, 0.3769444444444445, 0.402754547711461, 0.55, 0.465108764743227, 0.635, 1.0, 0.6523725060970595], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:31:59,218] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-90.50090027]
 [-89.30872345]
 [-86.4442749 ]
 [-85.42247009]
 [-86.68961334]], R is [[-93.3133316 ]
 [-93.38019562]
 [-93.44639587]
 [-93.51193237]
 [-93.57681274]].
[2017-11-01 09:32:02,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.87283345e-02   4.58198786e-01   3.56171012e-01   1.65216438e-02
   1.50380284e-01   1.97402695e-33   7.71793316e-35   3.82436140e-33
   1.57960562e-33], sum to 1.0000
[2017-11-01 09:32:02,883] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-13.3, 81.16666666666667, 4.766666666666666, 263.3333333333334, 0.0, 0.0, -8.25, 31.5802678526397, 30.0, 20.26124058121885, 21.5, 0.0, 48.75161987796753], 
actual action is [-8.3, 29.0], 
sim time next is 338100.0000, 
raw observation next is [-13.35, 81.58333333333333, 4.683333333333333, 261.6666666666666, 0.0, 0.0, -8.3, 31.64509630772558, 29.0, 20.24563233830046, 21.5, 0.0, 48.6985112617795], 
processed observation next is [0.3333333333333333, 0.9130434782608695, -0.008974358974358965, 0.8158333333333333, 0.4257575757575757, 0.7268518518518516, 0.0, 0.0, 0.36166666666666664, 0.3164509630772558, 0.95, 0.512281616915023, 0.575, 0.0, 0.5729236619032883], 
reward next is -0.6001. 
=============================================
[2017-11-01 09:32:14,028] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.10019726  0.7937122   0.0749573   0.00417036  0.02696279  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:32:14,188] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-15.45, 72.0, 5.225, 245.0, 0.0, 0.0, -10.4, 45.61473704704228, 25.0, 18.35272832364608, 21.5, 0.0, 50.25956917300159], 
actual action is [-10.45, 23.0], 
sim time next is 359400.0000, 
raw observation next is [-15.5, 72.33333333333333, 5.183333333333333, 243.3333333333333, 0.0, 0.0, -10.45, 45.78933113180229, 23.0, 18.33074480786501, 21.5, 0.0, 50.24433490162268], 
processed observation next is [0.5, 0.13043478260869565, -0.0641025641025641, 0.7233333333333333, 0.47121212121212114, 0.6759259259259258, 0.0, 0.0, 0.32583333333333336, 0.4578933113180229, 0.65, 0.41653724039325046, 0.575, 0.0, 0.5911098223720315], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:17,987] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01084113
  0.00256464  0.17597365  0.81062055], sum to 1.0000
[2017-11-01 09:32:18,071] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-15.75, 74.25, 3.525, 267.5, 0.0, 0.0, -10.7, 48.29511562760035, 28.0, 17.99979332215739, 21.5, 0.0, 48.74445464486636], 
actual action is [-10.75, 30], 
sim time next is 364800.0000, 
raw observation next is [-15.8, 74.66666666666667, 3.7, 266.6666666666667, 0.0, 0.0, -10.75, 48.48198629128924, 30.0, 17.97947408545721, 21.5, 0.0, 48.8559730116814], 
processed observation next is [0.5, 0.21739130434782608, -0.07179487179487182, 0.7466666666666667, 0.33636363636363636, 0.7407407407407408, 0.0, 0.0, 0.32083333333333336, 0.48481986291289236, 1.0, 0.39897370427286044, 0.575, 0.0, 0.5747761530786047], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:18,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00233895
  0.0015575   0.05423116  0.94187248], sum to 1.0000
[2017-11-01 09:32:18,953] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-16.2, 78.0, 5.141666666666667, 260.0, 0.0, 0.0, -11.2, 48.87828456925758, 28.0, 17.80722388204967, 21.5, 0.0, 50.23448442248166], 
actual action is [-11.2, 30], 
sim time next is 367800.0000, 
raw observation next is [-16.2, 78.0, 5.183333333333334, 260.0, 0.0, 0.0, -11.2, 49.12767868941076, 30.0, 17.77835579956757, 21.5, 0.0, 50.34382192264439], 
processed observation next is [0.5, 0.2608695652173913, -0.08205128205128204, 0.78, 0.47121212121212125, 0.7222222222222222, 0.0, 0.0, 0.31333333333333335, 0.4912767868941076, 1.0, 0.38891778997837856, 0.575, 0.0, 0.5922802579134634], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:26,682] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-111.63594818]
 [-107.84712219]
 [-114.2215271 ]
 [-109.90119171]
 [-108.15026093]], R is [[-110.10680389]
 [-110.0057373 ]
 [-109.9056778 ]
 [-109.80662537]
 [-109.70855713]].
[2017-11-01 09:32:27,495] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00572213
  0.00407746  0.06712116  0.92307925], sum to 1.0000
[2017-11-01 09:32:27,709] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-16.2, 78.0, 5.516666666666667, 260.0, 0.0, 0.0, -11.2, 50.73454888632951, 30.0, 17.56377773392711, 21.5, 0.0, 50.77595428693636], 
actual action is [-11.2, 30], 
sim time next is 370500.0000, 
raw observation next is [-16.2, 78.0, 5.558333333333333, 260.0, 0.0, 0.0, -11.2, 50.94904447089628, 30.0, 17.53980893851338, 21.5, 0.0, 50.81866604186236], 
processed observation next is [0.5, 0.2608695652173913, -0.08205128205128204, 0.78, 0.5053030303030303, 0.7222222222222222, 0.0, 0.0, 0.31333333333333335, 0.5094904447089629, 1.0, 0.3769904469256691, 0.575, 0.0, 0.5978666593160278], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:42,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.14567317  0.27250236  0.28027871  0.28175378  0.01979188  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:32:42,884] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-15.05, 78.0, 4.6, 230.0, 39.0, 738.0, -10.14166666666667, 35.24131609239203, 25.5, 19.68484800829576, 22.7, 1.0, 64.8339517042304], 
actual action is [-10.05, 25.0], 
sim time next is 380100.0000, 
raw observation next is [-14.95833333333333, 76.0, 4.433333333333334, 228.3333333333333, 41.66666666666667, 737.25, -10.05, 34.67691886435734, 25.0, 19.76883788473127, 22.7, 1.0, 64.5866448082334], 
processed observation next is [0.5, 0.391304347826087, -0.05021367521367514, 0.76, 0.40303030303030307, 0.6342592592592591, 0.11022927689594357, 0.73725, 0.33249999999999996, 0.3467691886435734, 0.75, 0.4884418942365635, 0.635, 1.0, 0.7598428800968635], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:56,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.05291316e-02   2.38497276e-02   9.54827905e-01   6.77120220e-03
   4.02210141e-03   2.75276004e-34   8.98558213e-35   3.47366088e-34
   9.85575698e-34], sum to 1.0000
[2017-11-01 09:32:56,185] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.583333333333332, 40.5, 6.124999999999999, 239.1666666666667, 43.41666666666666, 779.9166666666667, -4.666666666666666, 40.13269331199538, 20.0, 19.66020294398191, 22.7, 1.0, 23.21722199797918], 
actual action is [-4.583333333333332, 19.0], 
sim time next is 399600.0000, 
raw observation next is [-9.5, 40.0, 6.1, 240.0, 42.5, 769.5, -4.583333333333332, 40.26619295915682, 19.0, 19.61484579857027, 22.7, 1.0, 17.76112228880818], 
processed observation next is [0.5, 0.6521739130434783, 0.08974358974358974, 0.4, 0.5545454545454546, 0.6666666666666666, 0.11243386243386243, 0.7695, 0.4236111111111111, 0.40266192959156816, 0.45, 0.4807422899285134, 0.635, 1.0, 0.20895437986833154], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:32:59,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-72.5796051 ]
 [-73.27162933]
 [-73.1971283 ]
 [-73.7986908 ]
 [-74.8660202 ]], R is [[-71.72898102]
 [-71.48583984]
 [-71.26828766]
 [-71.07978821]
 [-70.895401  ]].
[2017-11-01 09:33:01,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  4.68317166e-28   8.50029522e-08   3.19468086e-06   1.21149540e-07
   3.09830170e-08   8.44196081e-02   1.08934142e-01   9.77105349e-02
   7.08932221e-01], sum to 1.0000
[2017-11-01 09:33:01,269] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-9.4, 39.66666666666667, 6.1, 235.0, 40.66666666666666, 748.6666666666666, -4.449999999999999, 28.23624200793531, 14.0, 20.79347938389669, 22.7, 1.0, 39.13831523435277], 
actual action is [-4.4, 16.0], 
sim time next is 400500.0000, 
raw observation next is [-9.35, 39.5, 6.1, 232.5, 39.75, 738.25, -4.4, 28.61959514111585, 16.0, 20.81673351243141, 22.7, 1.0, 36.60597420283932], 
processed observation next is [0.5, 0.6521739130434783, 0.0935897435897436, 0.395, 0.5545454545454546, 0.6458333333333334, 0.10515873015873016, 0.73825, 0.4266666666666667, 0.2861959514111585, 0.3, 0.5408366756215705, 0.635, 1.0, 0.43065852003340377], 
reward next is -0.3584. 
=============================================
[2017-11-01 09:33:14,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   7.32824467e-25   7.15931219e-23   1.37646959e-24
   6.08497671e-25   1.82406120e-02   1.24515086e-01   2.35467508e-01
   6.21776819e-01], sum to 1.0000
[2017-11-01 09:33:14,917] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-9.958333333333332, 41.83333333333334, 5.141666666666667, 192.5, 0.0, 0.0, -4.916666666666668, 26.60141265924456, 28.0, 21.35183284916383, 22.7, 1.0, 65.25462775334708], 
actual action is [-4.958333333333332, 30], 
sim time next is 417600.0000, 
raw observation next is [-10.0, 42.0, 5.1, 190.0, 0.0, 0.0, -4.958333333333332, 26.56487210702215, 30.0, 21.35862360883527, 22.7, 1.0, 65.22050091216501], 
processed observation next is [0.5, 0.8695652173913043, 0.07692307692307693, 0.42, 0.4636363636363636, 0.5277777777777778, 0.0, 0.0, 0.4173611111111111, 0.2656487210702215, 1.0, 0.5679311804417635, 0.635, 1.0, 0.767300010731353], 
reward next is -0.5165. 
=============================================
[2017-11-01 09:33:20,658] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-48.2934227 ]
 [-50.36878586]
 [-48.22585678]
 [-50.41209793]
 [-48.57381058]], R is [[-47.91754532]
 [-47.73279953]
 [-47.54620743]
 [-47.35640335]
 [-47.1644516 ]].
[2017-11-01 09:33:35,547] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23651: loss 13.4629
[2017-11-01 09:33:36,817] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23751: loss -266.9476
[2017-11-01 09:33:36,883] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23755: loss -83.7507
[2017-11-01 09:33:37,153] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23778: loss 117.2287
[2017-11-01 09:33:37,330] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23784: loss -43.5698
[2017-11-01 09:33:37,457] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23795: loss 40.5252
[2017-11-01 09:33:37,851] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23826: loss -3.2882
[2017-11-01 09:33:38,408] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23869: loss 37.0068
[2017-11-01 09:33:38,449] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23869: loss 109.1768
[2017-11-01 09:33:38,555] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23874: loss -143.5195
[2017-11-01 09:33:39,275] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23920: loss 36.4794
[2017-11-01 09:33:42,088] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24116: loss -68.8137
[2017-11-01 09:33:44,268] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1500, global step 24229: loss -84.3402
[2017-11-01 09:33:45,333] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1500, global step 24280: loss -477.1911
[2017-11-01 09:33:47,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.20667216e-29   3.09732343e-07   4.04174061e-05   1.78265850e-06
   1.79281201e-07   3.91962267e-02   8.14104557e-01   4.77436520e-02
   9.89129022e-02], sum to 1.0000
[2017-11-01 09:33:47,582] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.05, 41.25, 4.683333333333334, 185.8333333333333, 0.0, 0.0, -3.1, 30.73186342723085, 30.0, 19.9581696621869, 22.7, 1.0, 65.69535126650462], 
actual action is [-3.0500000000000007, 30], 
sim time next is 459600.0000, 
raw observation next is [-8.0, 41.0, 4.766666666666666, 186.6666666666667, 0.0, 0.0, -3.050000000000001, 30.45894657502905, 30.0, 20.03776669630794, 22.7, 1.0, 65.75523107490868], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.1282051282051282, 0.41, 0.43333333333333324, 0.5185185185185186, 0.0, 0.0, 0.44916666666666666, 0.3045894657502905, 1.0, 0.5018883348153971, 0.635, 1.0, 0.773590953822455], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:33:49,519] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 24472: loss 54.6530
[2017-11-01 09:33:50,140] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24502: loss -80.5405
[2017-11-01 09:33:56,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.73361651e-29   2.39068186e-07   1.00801753e-05   1.11908525e-06
   1.94349198e-07   2.84494255e-02   6.90866947e-01   5.24864309e-02
   2.28185579e-01], sum to 1.0000
[2017-11-01 09:33:57,198] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.633333333333334, 32.66666666666667, 4.933333333333334, 173.3333333333333, 55.50000000000001, 0.0, -0.7750000000000004, 26.47835207684125, 26.5, 20.83918370194073, 22.7, 1.0, 64.66599288031513], 
actual action is [-0.6333333333333337, 30], 
sim time next is 465900.0000, 
raw observation next is [-5.491666666666666, 32.58333333333333, 4.766666666666666, 174.1666666666667, 58.74999999999999, 0.0, -0.6333333333333337, 26.16077643747264, 30.0, 20.89069840590276, 22.7, 1.0, 64.49364608423943], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.19252136752136753, 0.3258333333333333, 0.43333333333333324, 0.48379629629629645, 0.1554232804232804, 0.0, 0.48944444444444446, 0.26160776437472644, 1.0, 0.5445349202951381, 0.635, 1.0, 0.7587487774616404], 
reward next is -0.5102. 
=============================================
[2017-11-01 09:34:08,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.49485782e-01   6.81373999e-02   5.60771942e-01   1.72062337e-01
   4.95425127e-02   2.29792121e-23   1.21643424e-22   1.07632403e-23
   9.02574179e-24], sum to 1.0000
[2017-11-01 09:34:08,679] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.575, 25.75, 3.7, 225.0, 127.25, 0.0, 3.383333333333333, 19.48115082923211, 24.0, 21.94778035599172, 22.7, 1.0, 65.07037362169797], 
actual action is [3.425, 23.0], 
sim time next is 476400.0000, 
raw observation next is [-1.533333333333333, 26.0, 3.566666666666666, 220.0, 127.8333333333333, 0.0, 3.425, 19.07983240878404, 23.0, 22.07247155791136, 22.7, 1.0, 50.88457318792491], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.294017094017094, 0.26, 0.32424242424242417, 0.6111111111111112, 0.3381834215167548, 0.0, 0.5570833333333333, 0.1907983240878404, 0.65, 0.603623577895568, 0.635, 1.0, 0.5986420375049989], 
reward next is -0.3947. 
=============================================
[2017-11-01 09:34:16,011] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.72856507e-37   1.06892580e-16   7.11990537e-16   1.92016030e-16
   8.35712947e-17   2.74484120e-02   8.96788001e-01   3.43367346e-02
   4.14268561e-02], sum to 1.0000
[2017-11-01 09:34:16,099] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.4, 35.66666666666667, 4.1, 163.3333333333333, 98.16666666666667, 0.0, 4.55, 19.37095254647476, 16.0, 22.46307903325103, 22.7, 1.0, 31.57890795492992], 
actual action is [4.6, 17.0], 
sim time next is 483900.0000, 
raw observation next is [-0.3499999999999999, 35.83333333333333, 4.1, 164.1666666666667, 96.08333333333333, 0.0, 4.6, 20.01156584076231, 17.0, 22.3854921990376, 22.7, 1.0, 29.40359843292382], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3243589743589744, 0.3583333333333333, 0.3727272727272727, 0.45601851851851866, 0.25418871252204583, 0.0, 0.5766666666666667, 0.20011565840762308, 0.35, 0.61927460995188, 0.635, 1.0, 0.34592468744616256], 
reward next is -0.2730. 
=============================================
[2017-11-01 09:34:29,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.64944613e-01   2.30349496e-01   3.67850393e-01   7.85304829e-02
   5.83250672e-02   8.23602276e-23   1.49526537e-21   6.13395584e-23
   6.19074941e-23], sum to 1.0000
[2017-11-01 09:34:30,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.558333333333334, 96.0, 4.141666666666667, 110.8333333333333, 0.0, 0.0, 6.516666666666667, 13.69145501589222, 23.5, 22.95465109324342, 21.5, 0.0, 46.65885714617274], 
actual action is [6.558333333333334, 23.0], 
sim time next is 507600.0000, 
raw observation next is [1.6, 96.0, 4.1, 110.0, 0.0, 0.0, 6.558333333333334, 13.48018984652684, 23.0, 22.97487095153793, 21.5, 0.0, 38.92186119671828], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.37435897435897436, 0.96, 0.3727272727272727, 0.3055555555555556, 0.0, 0.0, 0.6093055555555557, 0.1348018984652684, 0.65, 0.6487435475768966, 0.575, 0.0, 0.45790424937315627], 
reward next is -0.2290. 
=============================================
[2017-11-01 09:34:48,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  4.11839762e-09   2.07992598e-01   5.95924973e-01   1.22362129e-01
   7.17203617e-02   1.21570520e-04   8.91137752e-04   7.72510946e-04
   2.14649510e-04], sum to 1.0000
[2017-11-01 09:34:48,890] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [3.8, 86.0, 6.1, 280.0, 0.0, 0.0, 8.841666666666665, 7.877890135951699, 30.0, 23.47847054246899, 21.5, 0.0, 44.4726223856652], 
actual action is [8.8, 30.0], 
sim time next is 529500.0000, 
raw observation next is [3.708333333333333, 85.66666666666666, 6.1, 281.6666666666666, 0.0, 0.0, 8.8, 7.836830909947964, 30.0, 23.47409917784867, 21.5, 0.0, 44.48830519735113], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.4284188034188034, 0.8566666666666666, 0.5545454545454546, 0.7824074074074071, 0.0, 0.0, 0.6466666666666666, 0.07836830909947964, 1.0, 0.6737049588924335, 0.575, 0.0, 0.5233918258511898], 
reward next is -0.2617. 
=============================================
[2017-11-01 09:35:06,920] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  7.68291720e-33   8.21339795e-13   2.76140574e-13   3.76876671e-14
   2.50457088e-14   6.28836751e-02   3.43177259e-01   5.27403057e-01
   6.65360689e-02], sum to 1.0000
[2017-11-01 09:35:07,057] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.85, 89.66666666666666, 5.308333333333333, 284.1666666666666, 0.0, 0.0, 5.9, 6.996064239031374, 28.0, 23.01331371356481, 21.5, 0.0, 40.68694386204763], 
actual action is [5.85, 28.5], 
sim time next is 541800.0000, 
raw observation next is [0.8, 90.0, 5.35, 285.0, 0.0, 0.0, 5.85, 7.000101709361728, 28.5, 22.98283776170601, 21.5, 0.0, 44.40420622211342], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.35384615384615387, 0.9, 0.48636363636363633, 0.7916666666666666, 0.0, 0.0, 0.5975, 0.07000101709361728, 0.925, 0.6491418880853004, 0.575, 0.0, 0.5224024261425109], 
reward next is -0.2612. 
=============================================
[2017-11-01 09:35:15,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.10898802e-28   4.43473990e-12   1.94658048e-12   3.16995670e-13
   2.08284561e-13   9.23684761e-02   3.63201171e-01   4.41392124e-01
   1.03038184e-01], sum to 1.0000
[2017-11-01 09:35:15,912] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 81.0, 5.766666666666667, 306.6666666666667, 128.8333333333333, 488.3333333333333, 3.8, 14.86936021828487, 11.5, 21.74805113884661, 22.7, 1.0, 27.82178206403191], 
actual action is [3.8, 13.5], 
sim time next is 570300.0000, 
raw observation next is [-1.2, 81.25, 5.808333333333333, 305.8333333333333, 127.9166666666667, 477.6666666666667, 3.8, 14.86647180375067, 13.5, 21.76338319211363, 22.7, 1.0, 21.69335826699302], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.3025641025641026, 0.8125, 0.528030303030303, 0.849537037037037, 0.33840388007054684, 0.4776666666666667, 0.5633333333333332, 0.1486647180375067, 0.175, 0.5881691596056815, 0.635, 1.0, 0.2552159796116826], 
reward next is -0.2019. 
=============================================
[2017-11-01 09:35:17,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-22.10747528]
 [-21.90438271]
 [-21.72953796]
 [-22.37490845]
 [-21.96178055]], R is [[-21.95569038]
 [-21.81682968]
 [-21.67555046]
 [-21.96114731]
 [-21.82315254]].
[2017-11-01 09:35:28,939] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31567: loss -72.3464
[2017-11-01 09:35:30,139] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31695: loss -3.0599
[2017-11-01 09:35:30,149] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31696: loss -34.7167
[2017-11-01 09:35:30,178] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31698: loss 47.7330
[2017-11-01 09:35:31,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31803: loss -0.7078
[2017-11-01 09:35:31,835] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31921: loss 43.0756
[2017-11-01 09:35:31,889] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31924: loss -13.6270
[2017-11-01 09:35:32,257] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31990: loss -139.8779
[2017-11-01 09:35:32,661] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32044: loss 15.1985
[2017-11-01 09:35:33,162] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32098: loss 11.8291
[2017-11-01 09:35:33,488] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 32135: loss -113.0000
[2017-11-01 09:35:33,542] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2000, global step 32146: loss -121.0008
[2017-11-01 09:35:34,277] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32239: loss -10.8627
[2017-11-01 09:35:34,410] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 32254: loss -34.8899
[2017-11-01 09:35:34,678] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2000, global step 32280: loss 31.9559
[2017-11-01 09:35:36,969] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32514: loss 54.2944
[2017-11-01 09:35:37,042] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02570302
  0.31815502  0.5568819   0.09926011], sum to 1.0000
[2017-11-01 09:35:37,114] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.483333333333333, 86.83333333333333, 4.516666666666667, 258.3333333333334, 0.0, 0.0, 1.558333333333334, 32.32744857276115, 14.0, 19.82899313255977, 21.5, 0.0, 13.7901788592994], 
actual action is [1.516666666666667, 19.0], 
sim time next is 605700.0000, 
raw observation next is [-3.525, 86.75, 4.475, 257.5, 0.0, 0.0, 1.516666666666667, 33.0610715546359, 19.0, 19.74323839201165, 21.5, 0.0, 13.24533867409813], 
processed observation next is [1.0, 0.0, 0.24294871794871795, 0.8675, 0.4068181818181818, 0.7152777777777778, 0.0, 0.0, 0.5252777777777777, 0.330610715546359, 0.45, 0.4871619196005826, 0.575, 0.0, 0.15582751381291918], 
reward next is -0.5171. 
=============================================
[2017-11-01 09:35:41,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-56.03956985]
 [-54.1229744 ]
 [-53.11060715]
 [-55.62918472]
 [-54.67966461]], R is [[-55.62841034]
 [-55.61066818]
 [-55.59095764]
 [-55.57667923]
 [-55.59586716]].
[2017-11-01 09:35:42,424] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  4.19062078e-01   1.89839602e-01   3.85340065e-01   3.83301848e-03
   1.92524656e-03   4.88502049e-30   1.28632899e-30   6.28552064e-30
   3.76955572e-30], sum to 1.0000
[2017-11-01 09:35:42,483] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 75.0, 7.449999999999999, 253.3333333333333, 0.0, 0.0, 1.05, 22.75248828617766, 17.0, 20.50340252061561, 21.5, 0.0, 31.92469973921011], 
actual action is [1.0, 16.0], 
sim time next is 616500.0000, 
raw observation next is [-4.05, 75.0, 7.575, 255.0, 0.0, 0.0, 1.0, 23.39315406553678, 16.0, 20.46468649772604, 21.5, 0.0, 30.50781923815168], 
processed observation next is [1.0, 0.13043478260869565, 0.22948717948717948, 0.75, 0.6886363636363636, 0.7083333333333334, 0.0, 0.0, 0.5166666666666667, 0.2339315406553678, 0.3, 0.523234324886302, 0.575, 0.0, 0.3589155204488433], 
reward next is -0.4383. 
=============================================
[2017-11-01 09:35:44,289] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   1.73362538e-16   3.26264783e-16   5.02655862e-18
   2.31675815e-18   1.70006156e-01   9.10144001e-02   6.41087651e-01
   9.78918448e-02], sum to 1.0000
[2017-11-01 09:35:44,414] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.899999999999999, 85.08333333333333, 5.274999999999999, 259.1666666666666, 0.0, 0.0, 1.1, 24.66328778123899, 28.0, 20.06365321163369, 21.5, 0.0, 49.86844815194886], 
actual action is [1.100000000000001, 30.0], 
sim time next is 612600.0000, 
raw observation next is [-3.9, 84.16666666666667, 5.45, 258.3333333333334, 0.0, 0.0, 1.100000000000001, 23.76691783973495, 30.0, 20.16857472713022, 21.5, 0.0, 48.5147685682846], 
processed observation next is [1.0, 0.08695652173913043, 0.23333333333333334, 0.8416666666666667, 0.4954545454545455, 0.7175925925925929, 0.0, 0.0, 0.5183333333333333, 0.23766917839734952, 1.0, 0.508428736356511, 0.575, 0.0, 0.5707619831562895], 
reward next is -0.6182. 
=============================================
[2017-11-01 09:35:51,336] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.10354941
  0.06623106  0.7219851   0.10823442], sum to 1.0000
[2017-11-01 09:35:51,429] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 65.5, 4.85, 231.6666666666667, 0.0, 0.0, 0.5, 26.1339910978541, 15.0, 20.17457245079062, 21.5, 0.0, 25.95698739489877], 
actual action is [0.5, 17.0], 
sim time next is 627300.0000, 
raw observation next is [-4.5, 65.75, 4.975, 232.5, 0.0, 0.0, 0.5, 26.98767492303922, 17.0, 20.08909130941511, 21.5, 0.0, 24.87813994617148], 
processed observation next is [1.0, 0.2608695652173913, 0.21794871794871795, 0.6575, 0.4522727272727272, 0.6458333333333334, 0.0, 0.0, 0.5083333333333333, 0.2698767492303922, 0.35, 0.5044545654707555, 0.575, 0.0, 0.2926839993667233], 
reward next is -0.4991. 
=============================================
[2017-11-01 09:35:58,453] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   6.85257490e-29   4.69620984e-29   2.46561558e-30
   4.59207526e-31   1.17509417e-01   1.44724429e-01   6.27504230e-01
   1.10261939e-01], sum to 1.0000
[2017-11-01 09:35:58,498] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.691666666666666, 65.0, 8.991666666666665, 245.8333333333333, 102.9166666666667, 4.250000000000002, 1.266666666666667, 30.40065625220925, 15.5, 19.89616307850064, 22.7, 1.0, 22.24283110791083], 
actual action is [1.308333333333334, 20.5], 
sim time next is 642600.0000, 
raw observation next is [-3.65, 65.0, 8.95, 245.0, 100.0, 0.0, 1.308333333333334, 31.17193225807527, 20.5, 19.83151798616849, 22.7, 1.0, 20.58417183987796], 
processed observation next is [1.0, 0.43478260869565216, 0.23974358974358972, 0.65, 0.8136363636363636, 0.6805555555555556, 0.26455026455026454, 0.0, 0.5218055555555555, 0.3117193225807527, 0.525, 0.49157589930842444, 0.635, 1.0, 0.242166727527976], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:36:07,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-61.56814575]
 [-62.64269257]
 [-64.20478821]
 [-63.47914124]
 [-67.22933197]], R is [[-62.43544769]
 [-62.29936981]
 [-62.16879272]
 [-62.04427719]
 [-61.9275589 ]].
[2017-11-01 09:36:10,122] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.75073664e-02   5.16447663e-01   4.40986812e-01   4.69287857e-03
   3.65293439e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-01 09:36:10,149] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.291666666666667, 59.91666666666667, 7.525, 259.1666666666666, 139.9166666666667, 77.58333333333333, 3.616666666666667, 31.61890846854592, 11.5, 20.22985797654752, 22.7, 1.0, 17.96027511216616], 
actual action is [3.708333333333333, 10.5], 
sim time next is 655200.0000, 
raw observation next is [-1.2, 60.0, 7.7, 260.0, 131.5, 74.5, 3.708333333333333, 32.11805136741607, 10.5, 20.20493677867102, 22.7, 1.0, 16.75052286395607], 
processed observation next is [1.0, 0.6086956521739131, 0.3025641025641026, 0.6, 0.7000000000000001, 0.7222222222222222, 0.3478835978835979, 0.0745, 0.5618055555555556, 0.32118051367416073, 0.025, 0.5102468389335509, 0.635, 1.0, 0.19706497487007144], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:36:18,954] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  4.90228608e-02   1.23461790e-01   8.18024635e-01   7.62255210e-03
   1.86815776e-03   1.24703543e-28   9.79380215e-30   1.42329488e-29
   6.24280141e-29], sum to 1.0000
[2017-11-01 09:36:19,045] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.6, 54.0, 8.2, 254.1666666666667, 78.33333333333333, 36.08333333333333, 4.4, 26.49849619310386, 17.0, 20.97667835413166, 22.7, 1.0, 30.75238901447996], 
actual action is [4.4, 15.0], 
sim time next is 661200.0000, 
raw observation next is [-0.6, 54.0, 8.2, 253.3333333333333, 73.66666666666667, 34.16666666666666, 4.4, 26.75423644771086, 15.0, 20.95887531039471, 22.7, 1.0, 25.63775244251649], 
processed observation next is [1.0, 0.6521739130434783, 0.317948717948718, 0.54, 0.7454545454545454, 0.7037037037037036, 0.19488536155202824, 0.03416666666666666, 0.5733333333333334, 0.2675423644771086, 0.25, 0.5479437655197354, 0.635, 1.0, 0.30162061697078224], 
reward next is -0.2846. 
=============================================
[2017-11-01 09:36:21,956] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  5.29545769e-02   1.80360824e-01   7.55464256e-01   8.05666670e-03
   3.16371350e-03   1.15113072e-26   1.86659493e-27   3.66981521e-27
   3.75569590e-27], sum to 1.0000
[2017-11-01 09:36:22,230] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.2, 57.0, 6.249999999999999, 252.5, 0.0, 0.0, 3.8, 21.95041257682583, 14.5, 21.65195746651497, 22.7, 1.0, 36.51121929189637], 
actual action is [3.8, 13.5], 
sim time next is 669000.0000, 
raw observation next is [-1.2, 57.0, 6.033333333333333, 251.6666666666667, 0.0, 0.0, 3.8, 22.50639164448928, 13.5, 21.62599348757113, 22.7, 1.0, 33.90669598694257], 
processed observation next is [1.0, 0.7391304347826086, 0.3025641025641026, 0.57, 0.5484848484848485, 0.6990740740740742, 0.0, 0.0, 0.5633333333333332, 0.2250639164448928, 0.175, 0.5812996743785565, 0.635, 1.0, 0.39890230572873614], 
reward next is -0.3120. 
=============================================
[2017-11-01 09:36:26,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.32557809e-01   3.60461473e-01   4.69628483e-01   2.84358636e-02
   8.91639385e-03   2.15991883e-20   8.11127493e-21   9.19997790e-21
   9.50158055e-21], sum to 1.0000
[2017-11-01 09:36:26,245] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.399999999999999, 69.0, 4.058333333333333, 240.0, 0.0, 0.0, 1.6, 17.31737144697302, 15.0, 21.96285861931853, 21.5, 0.0, 34.38595693499052], 
actual action is [1.600000000000001, 14.0], 
sim time next is 681000.0000, 
raw observation next is [-3.4, 69.0, 4.016666666666667, 240.0, 0.0, 0.0, 1.600000000000001, 17.70014770701086, 14.0, 21.94510655658166, 21.5, 0.0, 33.07285053909391], 
processed observation next is [1.0, 0.9130434782608695, 0.24615384615384614, 0.69, 0.36515151515151517, 0.6666666666666666, 0.0, 0.0, 0.5266666666666667, 0.1770014770701086, 0.2, 0.597255327829083, 0.575, 0.0, 0.3890923592834578], 
reward next is -0.1945. 
=============================================
[2017-11-01 09:36:29,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.50337854e-20   2.13334542e-02   8.58274754e-03   3.36496305e-04
   1.74055982e-04   2.83009797e-01   8.41851234e-02   1.88484907e-01
   4.13893431e-01], sum to 1.0000
[2017-11-01 09:36:29,570] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.85, 65.33333333333333, 3.641666666666667, 240.0, 0.0, 0.0, 2.2, 28.93632825615481, 30.0, 20.11868651210093, 21.5, 0.0, 57.96998004634129], 
actual action is [2.15, 30], 
sim time next is 677400.0000, 
raw observation next is [-2.9, 65.66666666666667, 3.683333333333333, 240.0, 0.0, 0.0, 2.15, 26.52148772609279, 30.0, 20.35268118374715, 21.5, 0.0, 52.26111237661276], 
processed observation next is [1.0, 0.8695652173913043, 0.25897435897435894, 0.6566666666666667, 0.33484848484848484, 0.6666666666666666, 0.0, 0.0, 0.5358333333333333, 0.2652148772609279, 1.0, 0.5176340591873576, 0.575, 0.0, 0.6148366161954442], 
reward next is -0.5942. 
=============================================
[2017-11-01 09:36:29,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.28794220e-02   5.55962205e-01   3.10375869e-01   2.37321500e-02
   1.70503836e-02   5.57441215e-20   1.31361500e-20   2.41242395e-20
   1.98065457e-20], sum to 1.0000
[2017-11-01 09:36:29,843] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.208333333333333, 61.58333333333333, 5.141666666666667, 250.0, 0.0, 0.0, 2.883333333333334, 18.9851416301351, 22.5, 21.83557822683088, 22.7, 1.0, 60.94029878545925], 
actual action is [2.791666666666667, 20.5], 
sim time next is 673200.0000, 
raw observation next is [-2.3, 62.0, 5.1, 250.0, 0.0, 0.0, 2.791666666666667, 18.76802984454626, 20.5, 21.90527294317181, 22.7, 1.0, 51.86769266389151], 
processed observation next is [1.0, 0.8260869565217391, 0.27435897435897433, 0.62, 0.4636363636363636, 0.6944444444444444, 0.0, 0.0, 0.5465277777777777, 0.18768029844546258, 0.525, 0.5952636471585905, 0.635, 1.0, 0.610208148986959], 
reward next is -0.3989. 
=============================================
[2017-11-01 09:36:35,982] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-37.59538651]
 [-37.74357605]
 [-39.18460846]
 [-37.24693298]
 [-38.44165802]], R is [[-36.69866943]
 [-36.85122681]
 [-37.03379059]
 [-37.25072479]
 [-37.51578903]].
[2017-11-01 09:36:54,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.07162975e-01   8.81256536e-02   7.25164950e-01   7.26518556e-02
   6.89453445e-03   1.19664283e-25   5.33801652e-26   3.50107686e-26
   2.48437050e-25], sum to 1.0000
[2017-11-01 09:36:54,672] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.058333333333333, 66.83333333333333, 4.808333333333333, 260.0, 134.4166666666667, 127.25, 3.85, 30.1212027436982, 17.0, 19.89492410856078, 22.7, 1.0, 10.97409281973132], 
actual action is [3.9416666666666673, 16.0], 
sim time next is 729600.0000, 
raw observation next is [-0.9666666666666668, 66.66666666666667, 4.766666666666667, 260.0, 129.8333333333333, 186.5, 3.941666666666667, 30.24512540790321, 16.0, 19.87055164166932, 22.7, 1.0, 10.30801330757531], 
processed observation next is [0.0, 0.43478260869565216, 0.30854700854700856, 0.6666666666666667, 0.43333333333333335, 0.7222222222222222, 0.34347442680776, 0.1865, 0.5656944444444445, 0.3024512540790321, 0.3, 0.493527582083466, 0.635, 1.0, 0.12127074479500365], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:37:06,313] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39681: loss 5.5160
[2017-11-01 09:37:06,470] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39698: loss 10.2845
[2017-11-01 09:37:07,022] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39755: loss 19.5168
[2017-11-01 09:37:07,173] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39772: loss 28.5032
[2017-11-01 09:37:07,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   1.84944557e-18   8.00132882e-18   1.42204920e-18
   5.53713565e-19   6.73353225e-02   1.45506859e-01   6.91533685e-02
   7.18004405e-01], sum to 1.0000
[2017-11-01 09:37:07,296] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.516666666666667, 48.75, 5.183333333333333, 306.6666666666666, 69.41666666666667, 5.333333333333334, 3.666666666666667, 23.42432466593777, 18.0, 21.13050325103857, 22.7, 1.0, 13.94445319387701], 
actual action is [3.483333333333333, 23.0], 
sim time next is 750600.0000, 
raw observation next is [-1.7, 49.5, 5.1, 310.0, 68.0, 3.0, 3.483333333333333, 23.77686394361234, 23.0, 21.08827394262693, 22.7, 1.0, 13.230474134282], 
processed observation next is [0.0, 0.6956521739130435, 0.28974358974358977, 0.495, 0.4636363636363636, 0.8611111111111112, 0.17989417989417988, 0.003, 0.5580555555555555, 0.23776863943612342, 0.65, 0.5544136971313465, 0.635, 1.0, 0.15565263687390588], 
reward next is -0.1967. 
=============================================
[2017-11-01 09:37:07,332] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39783: loss -14.5022
[2017-11-01 09:37:07,385] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39784: loss -23.3827
[2017-11-01 09:37:08,589] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39894: loss -1.0496
[2017-11-01 09:37:08,761] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39906: loss 1.0474
[2017-11-01 09:37:09,641] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 39979: loss 14.9864
[2017-11-01 09:37:10,341] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 40040: loss 36.5916
[2017-11-01 09:37:10,443] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 40048: loss 8.3037
[2017-11-01 09:37:10,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   7.27086205e-22   3.85056856e-21   5.58787817e-22
   1.26649750e-22   1.84509099e-01   1.57578364e-01   9.58799273e-02
   5.62032580e-01], sum to 1.0000
[2017-11-01 09:37:10,768] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.125, 46.5, 4.85, 292.5, 81.25, 543.25, -4.833333333333333, 19.43735171169152, 10.0, 21.7960610089686, 22.7, 1.0, 0.0], 
actual action is [5.125, 15.0], 
sim time next is 744600.0000, 
raw observation next is [0.08333333333333331, 46.66666666666667, 4.766666666666666, 295.0, 81.66666666666667, 486.3333333333334, 5.125, 18.88936437304869, 15.0, 21.70397156885546, 22.7, 1.0, 34.73681673506933], 
processed observation next is [0.0, 0.6086956521739131, 0.3354700854700855, 0.46666666666666673, 0.43333333333333324, 0.8194444444444444, 0.2160493827160494, 0.48633333333333345, 0.5854166666666667, 0.1888936437304869, 0.25, 0.5851985784427731, 0.635, 1.0, 0.40866843217728627], 
reward next is -0.2988. 
=============================================
[2017-11-01 09:37:11,281] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 40135: loss -38.5771
[2017-11-01 09:37:12,205] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 40223: loss 55.5440
[2017-11-01 09:37:12,211] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40223: loss 64.3793
[2017-11-01 09:37:12,800] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40271: loss 89.8178
[2017-11-01 09:37:12,989] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40286: loss 25.4564
[2017-11-01 09:37:14,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   4.17104079e-20   4.55367289e-20   5.28333788e-21
   2.31249064e-21   3.50904107e-01   2.56546795e-01   1.22605115e-01
   2.69943953e-01], sum to 1.0000
[2017-11-01 09:37:15,208] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.991666666666666, 53.41666666666666, 5.058333333333334, 331.6666666666667, 0.0, 0.0, 1.1, 13.03066699601565, 27.5, 22.8577554662745, 22.7, 1.0, 62.18707118958346], 
actual action is [1.0083333333333342, 30], 
sim time next is 760200.0000, 
raw observation next is [-4.083333333333333, 53.83333333333334, 5.016666666666667, 333.3333333333333, 0.0, 0.0, 1.008333333333334, 12.94444753247611, 30.0, 22.89193447763505, 22.7, 1.0, 62.19628570900714], 
processed observation next is [0.0, 0.8260869565217391, 0.22863247863247865, 0.5383333333333334, 0.45606060606060606, 0.9259259259259258, 0.0, 0.0, 0.5168055555555555, 0.1294444753247611, 1.0, 0.6445967238817525, 0.635, 1.0, 0.7317210083412605], 
reward next is -0.4306. 
=============================================
[2017-11-01 09:37:33,545] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.04158088e-04   2.54209071e-01   6.72024310e-01   6.61183894e-02
   7.14410935e-03   1.90912599e-21   8.51654031e-22   1.67895210e-22
   4.51122980e-21], sum to 1.0000
[2017-11-01 09:37:33,612] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-7.675, 74.25, 1.875, 72.5, 0.0, 0.0, -2.716666666666667, 19.36858901265537, 30.0, 20.95792733116804, 21.5, 0.0, 44.47983509802288], 
actual action is [-2.675, 29.0], 
sim time next is 789600.0000, 
raw observation next is [-7.633333333333333, 74.33333333333334, 2.0, 73.33333333333334, 0.0, 0.0, -2.675, 19.25280580246066, 29.0, 20.98090435857611, 21.5, 0.0, 44.52056899620793], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.13760683760683762, 0.7433333333333334, 0.18181818181818182, 0.20370370370370372, 0.0, 0.0, 0.45541666666666664, 0.1925280580246066, 0.95, 0.5490452179288056, 0.575, 0.0, 0.5237713999553874], 
reward next is -0.3917. 
=============================================
[2017-11-01 09:37:40,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.46217343e-34   3.56339513e-10   7.28913457e-11   1.88916435e-11
   1.18934159e-12   6.48487583e-02   7.39963576e-02   2.26946920e-02
   8.38460207e-01], sum to 1.0000
[2017-11-01 09:37:40,231] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.3, 71.0, 3.55, 88.33333333333333, 0.0, 0.0, -2.3, 23.07841786094198, 28.0, 20.10236516045622, 21.5, 0.0, 46.60430705199525], 
actual action is [-2.3, 30], 
sim time next is 796200.0000, 
raw observation next is [-7.3, 71.0, 3.5, 86.66666666666667, 0.0, 0.0, -2.3, 22.71071042217087, 30.0, 20.16915131880759, 21.5, 0.0, 46.38935585896402], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.14615384615384616, 0.71, 0.3181818181818182, 0.24074074074074076, 0.0, 0.0, 0.46166666666666667, 0.22710710422170868, 1.0, 0.5084575659403795, 0.575, 0.0, 0.5457571277525178], 
reward next is -0.6056. 
=============================================
[2017-11-01 09:37:40,813] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.77557806e-14   6.87960625e-01   2.55359739e-01   5.32022268e-02
   3.47740576e-03   5.23628030e-10   4.20233681e-10   1.26837207e-10
   5.13028597e-09], sum to 1.0000
[2017-11-01 09:37:41,258] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.7, 69.0, 2.625, 80.0, 0.0, 0.0, -1.700000000000001, 22.36767075165467, 28.0, 20.18352434215358, 22.7, 1.0, 70.51821877128368], 
actual action is [-1.7000000000000002, 27.0], 
sim time next is 804000.0000, 
raw observation next is [-6.700000000000001, 69.66666666666667, 2.666666666666667, 80.0, 0.0, 0.0, -1.7, 21.14057860699573, 27.0, 20.3842768000281, 22.7, 1.0, 66.79500601699836], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.16153846153846152, 0.6966666666666668, 0.24242424242424246, 0.2222222222222222, 0.0, 0.0, 0.4716666666666667, 0.2114057860699573, 0.85, 0.519213840001405, 0.635, 1.0, 0.7858236001999807], 
reward next is -0.4986. 
=============================================
[2017-11-01 09:38:00,154] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  8.56333822e-02   2.69546956e-01   4.12404686e-01   2.10983098e-01
   2.14319397e-02   1.42978272e-19   4.87923567e-20   2.25686617e-20
   1.25358446e-19], sum to 1.0000
[2017-11-01 09:38:00,420] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.45, 78.99999999999999, 2.5, 80.83333333333333, 94.33333333333333, 0.0, 0.5, 18.5618673864564, 28.0, 21.57965061978644, 22.7, 1.0, 61.29686648831132], 
actual action is [0.5499999999999998, 27.5], 
sim time next is 825000.0000, 
raw observation next is [-4.4, 79.00000000000001, 2.5, 81.66666666666667, 93.66666666666666, 0.0, 0.5499999999999998, 18.1226338621311, 27.5, 21.68968778248291, 22.7, 1.0, 61.09750662171876], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.2205128205128205, 0.7900000000000001, 0.22727272727272727, 0.22685185185185186, 0.24779541446208111, 0.0, 0.5091666666666667, 0.181226338621311, 0.875, 0.5844843891241455, 0.635, 1.0, 0.7187941955496324], 
reward next is -0.4500. 
=============================================
[2017-11-01 09:38:02,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.36783905e-02   2.63906538e-01   2.49290466e-01   4.60675299e-01
   1.24493754e-02   2.47085044e-27   5.64326555e-28   2.69818235e-28
   9.60593305e-27], sum to 1.0000
[2017-11-01 09:38:02,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.9, 82.5, 3.05, 85.0, 59.0, 0.0, 1.100000000000001, 30.81705481161479, 19.5, 20.45568469774774, 22.7, 1.0, 13.69078223751139], 
actual action is [1.1, 19.0], 
sim time next is 830100.0000, 
raw observation next is [-3.899999999999999, 83.08333333333334, 3.141666666666667, 84.16666666666667, 58.16666666666666, 0.0, 1.1, 31.55479426172828, 19.0, 20.36380342614337, 22.7, 1.0, 13.15618229158581], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.23333333333333336, 0.8308333333333334, 0.28560606060606064, 0.2337962962962963, 0.1538800705467372, 0.0, 0.5183333333333333, 0.3155479426172828, 0.45, 0.5181901713071685, 0.635, 1.0, 0.1547786151951272], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:38:23,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  6.12965494e-12   2.71792740e-01   1.55302972e-01   5.44331729e-01
   2.85533555e-02   3.04482091e-06   5.03018236e-06   8.75422700e-07
   1.02562690e-05], sum to 1.0000
[2017-11-01 09:38:23,407] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-3.4, 83.0, 3.6, 65.0, 0.0, 0.0, 1.600000000000001, 21.34745644742351, 27.0, 21.36579426483543, 21.5, 0.0, 27.04344757109607], 
actual action is [1.6, 25.0], 
sim time next is 851700.0000, 
raw observation next is [-3.4, 83.0, 3.6, 64.16666666666666, 0.0, 0.0, 1.6, 20.90099025901065, 25.0, 21.38098499854695, 21.5, 0.0, 39.94904456361481], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.24615384615384614, 0.83, 0.32727272727272727, 0.17824074074074073, 0.0, 0.0, 0.5266666666666667, 0.20900990259010652, 0.75, 0.5690492499273475, 0.575, 0.0, 0.469988759571939], 
reward next is -0.2647. 
=============================================
[2017-11-01 09:38:26,287] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.46301731e-17   7.59290019e-03   3.77001660e-03   1.45001039e-02
   8.02413444e-04   2.51810938e-01   2.32851505e-01   7.37973303e-02
   4.14874732e-01], sum to 1.0000
[2017-11-01 09:38:26,485] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 83.0, 3.6, 63.33333333333334, 0.0, 0.0, 1.6, 22.15068285252616, 29.5, 21.22155096855445, 21.5, 0.0, 54.08617844433959], 
actual action is [1.6, 30], 
sim time next is 852300.0000, 
raw observation next is [-3.4, 83.0, 3.6, 62.5, 0.0, 0.0, 1.6, 20.46224581941768, 30.0, 21.28371766225249, 21.5, 0.0, 55.16443404451746], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.24615384615384614, 0.83, 0.32727272727272727, 0.1736111111111111, 0.0, 0.0, 0.5266666666666667, 0.20462245819417682, 1.0, 0.5641858831126244, 0.575, 0.0, 0.6489933417002055], 
reward next is -0.3786. 
=============================================
[2017-11-01 09:38:26,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.80244437e-02   2.29883641e-01   2.20578238e-01   4.44928080e-01
   4.65855487e-02   2.08939586e-17   1.04282006e-17   4.25381270e-18
   8.03348960e-18], sum to 1.0000
[2017-11-01 09:38:26,955] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-2.675, 79.25, 2.25, 75.0, 0.0, 0.0, 2.283333333333333, 13.92601984236993, 23.5, 22.41654858709533, 21.5, 0.0, 43.62233749603936], 
actual action is [2.325, 23.0], 
sim time next is 861600.0000, 
raw observation next is [-2.633333333333333, 79.33333333333334, 2.166666666666667, 73.33333333333334, 0.0, 0.0, 2.325, 13.77428255077331, 23.0, 22.44724800774026, 21.5, 0.0, 43.53338762625198], 
processed observation next is [0.16666666666666666, 1.0, 0.2658119658119658, 0.7933333333333334, 0.196969696969697, 0.20370370370370372, 0.0, 0.0, 0.5387500000000001, 0.13774282550773312, 0.65, 0.622362400387013, 0.575, 0.0, 0.5121575014853174], 
reward next is -0.2561. 
=============================================
[2017-11-01 09:38:27,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.89792539e-12   2.57478029e-01   1.67482793e-01   5.35877466e-01
   3.36431228e-02   1.90864445e-03   1.49738090e-03   4.49924701e-04
   1.66266761e-03], sum to 1.0000
[2017-11-01 09:38:27,341] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.4, 83.0, 3.6, 60.0, 0.0, 0.0, 1.600000000000001, 18.05720113664503, 23.5, 21.63911271953522, 21.5, 0.0, 39.81533257334026], 
actual action is [1.6, 23.0], 
sim time next is 853500.0000, 
raw observation next is [-3.399999999999999, 83.0, 3.6, 59.16666666666666, 0.0, 0.0, 1.6, 17.84510435443502, 23.0, 21.71004476732742, 21.5, 0.0, 41.14584349763623], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.2461538461538462, 0.83, 0.32727272727272727, 0.16435185185185183, 0.0, 0.0, 0.5266666666666667, 0.17845104354435018, 0.65, 0.585502238366371, 0.575, 0.0, 0.48406874703101443], 
reward next is -0.2420. 
=============================================
[2017-11-01 09:38:46,894] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47474: loss -5.7048
[2017-11-01 09:38:47,090] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47489: loss 14.1503
[2017-11-01 09:38:49,181] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   4.12774396e-19   3.71832258e-20   1.21952582e-19
   1.14319385e-19   2.17683166e-01   1.26054570e-01   5.00125110e-01
   1.56137139e-01], sum to 1.0000
[2017-11-01 09:38:49,238] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [1.1, 80.0, 3.6, 150.0, 38.5, 0.0, 6.008333333333333, 23.48503021701627, 20.5, 20.51071555393974, 22.7, 1.0, 10.76106333836887], 
actual action is [6.1, 21.0], 
sim time next is 896700.0000, 
raw observation next is [1.1, 80.33333333333333, 3.55, 150.8333333333333, 40.08333333333333, 0.0, 6.1, 23.95453407944414, 21.0, 20.43952115375676, 22.7, 1.0, 10.27646214381079], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.36153846153846153, 0.8033333333333332, 0.3227272727272727, 0.41898148148148134, 0.1060405643738977, 0.0, 0.6016666666666667, 0.2395453407944414, 0.55, 0.5219760576878381, 0.635, 1.0, 0.12089955463306812], 
reward next is -0.1802. 
=============================================
[2017-11-01 09:38:50,302] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-24.81563568]
 [-24.93961334]
 [-25.4729538 ]
 [-24.34776115]
 [-24.65648842]], R is [[-24.95968056]
 [-24.98766327]
 [-25.02922821]
 [-25.08345032]
 [-25.16886711]].
[2017-11-01 09:38:51,133] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47781: loss -13.6500
[2017-11-01 09:38:51,244] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47791: loss 4.9365
[2017-11-01 09:38:51,949] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3000, global step 47838: loss -12.2693
[2017-11-01 09:38:53,126] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47908: loss 0.5385
[2017-11-01 09:38:54,375] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47973: loss 7.8325
[2017-11-01 09:38:54,538] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47986: loss -0.1235
[2017-11-01 09:38:55,505] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48054: loss -4.3312
[2017-11-01 09:38:55,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48055: loss -0.4701
[2017-11-01 09:38:56,285] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3000, global step 48102: loss -1.5386
[2017-11-01 09:38:57,116] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3000, global step 48180: loss -29.3247
[2017-11-01 09:38:57,405] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3000, global step 48193: loss -0.1382
[2017-11-01 09:38:57,437] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3000, global step 48199: loss 12.0071
[2017-11-01 09:38:59,747] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48451: loss 0.4030
[2017-11-01 09:39:00,125] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48501: loss 13.1895
[2017-11-01 09:39:13,341] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   1.09458880e-26   9.47233013e-28   4.45778393e-28
   3.00644424e-27   2.23530352e-01   4.05491926e-02   7.26026654e-01
   9.89373680e-03], sum to 1.0000
[2017-11-01 09:39:13,378] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [5.0, 100.0, 5.1, 117.5, 0.0, 0.0, 10.0, 22.29443911990661, 14.0, 21.08787704529854, 21.5, 0.0, 10.23341717756371], 
actual action is [10.0, 16.0], 
sim time next is 939000.0000, 
raw observation next is [5.0, 100.0, 5.1, 118.3333333333333, 0.0, 0.0, 10.0, 22.55140328818743, 16.0, 21.05674987112107, 21.5, 0.0, 8.940991113673988], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.46153846153846156, 1.0, 0.4636363636363636, 0.3287037037037036, 0.0, 0.0, 0.6666666666666666, 0.2255140328818743, 0.3, 0.5528374935560535, 0.575, 0.0, 0.10518813074910574], 
reward next is -0.1634. 
=============================================
[2017-11-01 09:39:15,795] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-17.9224987 ]
 [-17.39262772]
 [-18.23656464]
 [-17.9658432 ]
 [-18.06830978]], R is [[-17.85224342]
 [-17.83849716]
 [-17.83720016]
 [-17.87189102]
 [-18.03054428]].
[2017-11-01 09:39:21,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.63616588e-34   3.40806823e-14   5.42089185e-15   2.87795961e-15
   1.43779184e-14   5.30380487e-01   2.68071964e-02   4.13590521e-01
   2.92217415e-02], sum to 1.0000
[2017-11-01 09:39:21,879] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [5.0, 96.0, 4.1, 110.8333333333333, 0.0, 0.0, 10.0, 29.83311014252596, 11.5, 20.15587132705835, 21.5, 0.0, 6.120888224861086], 
actual action is [10.0, 12.0], 
sim time next is 946800.0000, 
raw observation next is [5.0, 96.0, 4.1, 110.0, 0.0, 0.0, 10.0, 30.07630231128118, 12.0, 20.12919043931879, 21.5, 0.0, 5.795255025377934], 
processed observation next is [0.3333333333333333, 1.0, 0.46153846153846156, 0.96, 0.3727272727272727, 0.3055555555555556, 0.0, 0.0, 0.6666666666666666, 0.3007630231128118, 0.1, 0.5064595219659396, 0.575, 0.0, 0.06817947088679922], 
reward next is -0.3768. 
=============================================
[2017-11-01 09:39:31,510] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-15.50959301]
 [-15.78731441]
 [-15.61949444]
 [-16.39285278]
 [-15.92675877]], R is [[-16.66186523]
 [-17.49524689]
 [-18.32029533]
 [-19.13709259]
 [-19.94572258]].
[2017-11-01 09:39:41,359] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.62581190e-01   3.42340708e-01   1.17475100e-01   1.28991634e-01
   2.48611331e-01   1.40281273e-13   3.37691165e-14   1.20804598e-13
   6.28125879e-15], sum to 1.0000
[2017-11-01 09:39:41,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [14.4, 81.0, 6.633333333333334, 223.3333333333333, 98.16666666666667, 0.0, 9.4, 25.07092623858102, 10.0, 20.27816237942153, 22.7, 1.0, 0.0], 
actual action is [9.4, 10], 
sim time next is 1002300.0000, 
raw observation next is [14.4, 81.0, 6.766666666666666, 224.1666666666667, 96.08333333333333, 0.0, 9.4, 25.03162712798015, 10.0, 20.28142820422373, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.7025641025641025, 0.81, 0.6151515151515151, 0.6226851851851853, 0.25418871252204583, 0.0, 0.6566666666666666, 0.2503162712798015, 0.0, 0.5140714102111865, 0.635, 1.0, 0.0], 
reward next is -0.1252. 
=============================================
[2017-11-01 09:39:48,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-18.49074936]
 [-17.28108025]
 [-18.52522659]
 [-17.50133133]
 [-17.97058105]], R is [[-19.66911125]
 [-19.5988121 ]
 [-19.52905846]
 [-19.45985222]
 [-19.39118767]].
[2017-11-01 09:39:48,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-23.85785484]
 [-25.80280113]
 [-25.20747185]
 [-24.56646538]
 [-24.35863876]], R is [[-24.81461143]
 [-24.95853233]
 [-25.10000038]
 [-25.23905754]
 [-25.37574196]].
[2017-11-01 09:39:48,673] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-20.4012146 ]
 [-21.32847786]
 [-20.38406181]
 [-19.78720284]
 [-19.45864296]], R is [[-19.98329735]
 [-19.91213799]
 [-19.84157181]
 [-19.77159309]
 [-19.70218658]].
[2017-11-01 09:39:48,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.12967739e-01   2.35539645e-01   5.58261834e-02   8.59863758e-02
   4.09680068e-01   1.82195612e-17   2.20549967e-18   1.06063166e-17
   4.08325172e-19], sum to 1.0000
[2017-11-01 09:39:48,982] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 4.35, 207.5, 0.0, 0.0, 9.4, 28.55480872887911, 10.0, 19.57749375712162, 22.7, 1.0, 0.0], 
actual action is [9.4, 10], 
sim time next is 1025400.0000, 
raw observation next is [14.4, 77.0, 4.266666666666667, 208.3333333333333, 0.0, 0.0, 9.4, 28.58281018164998, 10.0, 19.57325373568465, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.7025641025641025, 0.77, 0.3878787878787879, 0.5787037037037036, 0.0, 0.0, 0.6566666666666666, 0.2858281018164998, 0.0, 0.4786626867842324, 0.635, 1.0, 0.0], 
reward next is -0.1429. 
=============================================
[2017-11-01 09:39:49,211] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55250: loss -0.4481
[2017-11-01 09:39:49,546] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3500, global step 55295: loss -13.4126
[2017-11-01 09:39:50,739] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55532: loss 4.2524
[2017-11-01 09:39:51,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  4.16938782e-01   2.17503101e-01   5.05233333e-02   6.13757819e-02
   2.53659099e-01   1.85933741e-17   1.76127783e-18   7.51251719e-18
   3.10817587e-19], sum to 1.0000
[2017-11-01 09:39:51,308] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [14.4, 77.0, 5.183333333333334, 210.0, 0.0, 0.0, 9.4, 26.25900391136836, 10.0, 19.92696716285469, 22.7, 1.0, 0.0], 
actual action is [9.4, 10], 
sim time next is 1048500.0000, 
raw observation next is [14.4, 77.0, 5.225, 210.0, 0.0, 0.0, 9.4, 26.25627124551, 10.0, 19.92820959470068, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.7025641025641025, 0.77, 0.475, 0.5833333333333334, 0.0, 0.0, 0.6566666666666666, 0.2625627124551, 0.0, 0.49641047973503394, 0.635, 1.0, 0.0], 
reward next is -0.1313. 
=============================================
[2017-11-01 09:39:51,499] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55672: loss -48.7163
[2017-11-01 09:39:51,916] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55773: loss 6.7693
[2017-11-01 09:39:51,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55779: loss -7.4284
[2017-11-01 09:39:52,929] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56002: loss -4.2539
[2017-11-01 09:39:53,117] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56053: loss -81.6949
[2017-11-01 09:39:53,146] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3500, global step 56056: loss -48.8881
[2017-11-01 09:39:53,300] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56079: loss -30.0209
[2017-11-01 09:39:53,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.76726633e-01   2.93837726e-01   1.95398573e-02   3.70190814e-02
   3.72876734e-01   3.04532791e-24   1.36134050e-26   1.70739366e-25
   9.18437472e-28], sum to 1.0000
[2017-11-01 09:39:53,425] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.25, 77.25, 5.225, 207.5, 0.0, 0.0, 9.3, 27.7188017035686, 10.0, 19.70645689039549, 21.5, 0.0, 0.0], 
actual action is [9.25, 10], 
sim time next is 1052400.0000, 
raw observation next is [14.2, 77.33333333333334, 5.1, 206.6666666666667, 0.0, 0.0, 9.25, 27.78197322937332, 10.0, 19.70277803198979, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.6974358974358974, 0.7733333333333334, 0.4636363636363636, 0.5740740740740742, 0.0, 0.0, 0.6541666666666667, 0.2778197322937332, 0.0, 0.4851389015994895, 0.575, 0.0, 0.0], 
reward next is -0.4493. 
=============================================
[2017-11-01 09:39:53,727] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3500, global step 56153: loss -2.8051
[2017-11-01 09:39:54,009] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3500, global step 56222: loss -0.4046
[2017-11-01 09:39:55,369] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3500, global step 56466: loss -9.5318
[2017-11-01 09:39:56,059] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56611: loss -174.1329
[2017-11-01 09:39:56,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.08294160e-19   6.36201912e-06   1.45060801e-06   2.19048434e-06
   5.29155022e-06   8.60962331e-01   4.31114286e-02   8.82755220e-02
   7.63543928e-03], sum to 1.0000
[2017-11-01 09:39:56,095] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [12.2, 83.0, 4.1, 181.6666666666667, 15.0, 48.33333333333334, 7.199999999999999, 30.08643533050122, 10.0, 19.4387283773765, 22.7, 1.0, 0.0], 
actual action is [17.2, 10.5], 
sim time next is 1066500.0000, 
raw observation next is [12.2, 83.0, 4.1, 182.5, 16.75, 53.5, 17.2, 29.96271246843941, 10.5, 19.44076463327159, 22.7, 1.0, 2.003630144854198], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.6461538461538462, 0.83, 0.3727272727272727, 0.5069444444444444, 0.04431216931216931, 0.0535, 0.7866666666666667, 0.2996271246843941, 0.025, 0.47203823166357955, 0.635, 1.0, 0.02357211935122586], 
reward next is -0.1616. 
=============================================
[2017-11-01 09:39:56,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56624: loss -38.0324
[2017-11-01 09:39:57,389] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56853: loss 28.5200
[2017-11-01 09:39:58,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.91674161e-01   2.30323642e-01   9.21998173e-02   1.09516717e-01
   1.76285654e-01   2.13558581e-11   2.10197051e-12   2.57381659e-12
   5.79445454e-13], sum to 1.0000
[2017-11-01 09:39:58,763] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.5, 70.0, 4.1, 170.0, 184.0, 107.5, 10.31666666666667, 24.10031405272804, 10.0, 20.16579932156511, 22.7, 1.0, 0.0], 
actual action is [10.5, 10], 
sim time next is 1076700.0000, 
raw observation next is [15.59166666666667, 69.58333333333333, 4.058333333333333, 172.5, 195.6666666666667, 125.4166666666667, 10.5, 23.6946409814704, 10.0, 20.21206295571688, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.7331196581196582, 0.6958333333333333, 0.3689393939393939, 0.4791666666666667, 0.5176366843033511, 0.1254166666666667, 0.675, 0.236946409814704, 0.0, 0.510603147785844, 0.635, 1.0, 0.0], 
reward next is -0.1185. 
=============================================
[2017-11-01 09:40:00,224] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.05108956e-01   3.35003823e-01   9.75526795e-02   1.52233452e-01
   2.10101187e-01   1.99671425e-11   1.40776551e-12   2.53416407e-12
   5.73223543e-13], sum to 1.0000
[2017-11-01 09:40:00,269] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.93333333333333, 81.0, 3.766666666666667, 183.3333333333333, 102.3333333333333, 195.0, 7.84166666666667, 27.82659599642521, 10.0, 19.56500406681757, 22.7, 1.0, 0.0], 
actual action is [7.93333333333333, 10], 
sim time next is 1071900.0000, 
raw observation next is [13.025, 80.75, 3.725, 182.5, 103.5, 175.5, 7.93333333333333, 27.65151936943376, 10.0, 19.60022383581778, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.6673076923076923, 0.8075, 0.3386363636363636, 0.5069444444444444, 0.27380952380952384, 0.1755, 0.6322222222222221, 0.2765151936943376, 0.0, 0.48001119179088897, 0.635, 1.0, 0.0], 
reward next is -0.1383. 
=============================================
[2017-11-01 09:40:02,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.79228830e-01   2.19611466e-01   1.18459746e-01   1.44258946e-01
   1.38440654e-01   1.87666885e-07   4.64726106e-08   5.76229233e-08
   1.54042823e-08], sum to 1.0000
[2017-11-01 09:40:02,563] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [18.425, 55.5, 3.45, 200.0, 173.5, 79.25, 13.38333333333334, 18.14443659094352, 10.0, 21.03484244749968, 22.7, 1.0, 0.0], 
actual action is [13.425, 10], 
sim time next is 1084800.0000, 
raw observation next is [18.46666666666667, 55.33333333333334, 3.4, 196.6666666666667, 172.6666666666667, 52.83333333333332, 13.425, 18.13750649536257, 10.0, 21.04370347143799, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.8068376068376069, 0.5533333333333335, 0.3090909090909091, 0.5462962962962964, 0.45679012345679026, 0.05283333333333332, 0.72375, 0.18137506495362568, 0.0, 0.5521851735718994, 0.635, 1.0, 0.0], 
reward next is -0.0907. 
=============================================
[2017-11-01 09:40:05,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  4.00194883e-01   2.37505943e-01   5.41059710e-02   1.16470456e-01
   1.91722840e-01   2.94779930e-11   4.11303673e-12   7.24906810e-12
   1.15390314e-12], sum to 1.0000
[2017-11-01 09:40:05,137] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.7, 50.0, 3.0, 190.0, 18.0, 1.5, 12.84166666666667, 17.1485970022536, 10.0, 21.17508567269693, 22.7, 1.0, 0.0], 
actual action is [12.7, 10], 
sim time next is 1098300.0000, 
raw observation next is [17.56666666666666, 50.24999999999999, 2.958333333333333, 190.0, 15.16666666666667, 1.75, 12.7, 17.22047854633223, 10.0, 21.16014114293503, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.7837606837606835, 0.5025, 0.2689393939393939, 0.5277777777777778, 0.04012345679012346, 0.00175, 0.7116666666666667, 0.1722047854633223, 0.0, 0.5580070571467515, 0.635, 1.0, 0.0], 
reward next is -0.0861. 
=============================================
[2017-11-01 09:40:14,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  5.17049551e-01   1.83092535e-01   4.53353561e-02   7.63522834e-02
   1.78170249e-01   2.00176537e-21   2.94734312e-22   4.81491465e-22
   3.74322805e-22], sum to 1.0000
[2017-11-01 09:40:14,684] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.25, 78.0, 4.6, 130.0, 0.0, 0.0, 5.29166666666667, 16.15564193619609, 10.0, 21.0596818591535, 21.5, 0.0, 0.0], 
actual action is [5.25, 10], 
sim time next is 1128900.0000, 
raw observation next is [10.20833333333333, 78.16666666666666, 4.6, 128.3333333333333, 0.0, 0.0, 5.25, 16.95347634725623, 10.0, 21.02830870409682, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.59508547008547, 0.7816666666666666, 0.41818181818181815, 0.35648148148148134, 0.0, 0.0, 0.5875, 0.1695347634725623, 0.0, 0.5514154352048409, 0.575, 0.0, 0.0], 
reward next is -0.1179. 
=============================================
[2017-11-01 09:40:30,852] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 62791: loss 3.5768
[2017-11-01 09:40:32,335] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4000, global step 63312: loss -0.1811
[2017-11-01 09:40:32,833] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63501: loss 0.3485
[2017-11-01 09:40:33,077] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63581: loss 2.6843
[2017-11-01 09:40:33,133] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63597: loss -0.0285
[2017-11-01 09:40:33,336] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63667: loss -3.6612
[2017-11-01 09:40:33,583] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63749: loss 1.6279
[2017-11-01 09:40:34,465] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4000, global step 63953: loss -0.8737
[2017-11-01 09:40:34,474] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4000, global step 63953: loss -1.0838
[2017-11-01 09:40:35,429] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64179: loss -1.6779
[2017-11-01 09:40:35,972] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64311: loss 0.9737
[2017-11-01 09:40:37,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.06667900e-01   2.96757191e-01   5.39174788e-02   1.40812740e-01
   3.01844686e-01   4.39082035e-11   2.24380965e-11   1.16458830e-11
   1.44299832e-11], sum to 1.0000
[2017-11-01 09:40:37,136] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [16.35, 76.5, 7.2, 135.0, 0.0, 0.0, 11.39166666666667, 13.26356616023781, 10.0, 21.38542370227906, 22.7, 1.0, 0.0], 
actual action is [11.350000000000001, 10.0], 
sim time next is 1208100.0000, 
raw observation next is [16.30833333333333, 76.75, 7.2, 134.1666666666667, 0.0, 0.0, 11.35, 13.28689162109892, 10.0, 21.37966613570402, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.7514957264957264, 0.7675, 0.6545454545454545, 0.37268518518518534, 0.0, 0.0, 0.6891666666666667, 0.1328689162109892, 0.0, 0.568983306785201, 0.635, 1.0, 0.0], 
reward next is -0.0664. 
=============================================
[2017-11-01 09:40:37,196] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64560: loss -5.9580
[2017-11-01 09:40:37,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64668: loss -2.8411
[2017-11-01 09:40:37,818] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4000, global step 64670: loss -33.4772
[2017-11-01 09:40:37,836] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4000, global step 64670: loss -1.1168
[2017-11-01 09:40:39,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64952: loss -240.5029
[2017-11-01 09:40:40,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.61777236e-09   2.38720462e-01   2.22315844e-02   1.59405962e-01
   5.79640865e-01   6.55610563e-07   1.88208546e-07   7.27382172e-08
   2.73357529e-07], sum to 1.0000
[2017-11-01 09:40:40,091] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [16.1, 83.0, 7.7, 140.0, 0.0, 0.0, 21.1, 5.970743046241565, 22.0, 23.17941499449452, 21.5, 0.0, 30.72374338775136], 
actual action is [21.1, 22.0], 
sim time next is 1217100.0000, 
raw observation next is [16.05, 83.83333333333333, 7.7, 140.0, 0.0, 0.0, 21.1, 5.925650761544031, 22.0, 23.40090208841318, 21.5, 0.0, 29.28466100221997], 
processed observation next is [1.0, 0.08695652173913043, 0.7448717948717949, 0.8383333333333333, 0.7000000000000001, 0.3888888888888889, 0.0, 0.0, 0.8516666666666667, 0.0592565076154403, 0.6, 0.670045104420659, 0.575, 0.0, 0.34452542355552906], 
reward next is -0.1723. 
=============================================
[2017-11-01 09:40:48,161] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  3.38918388e-01   2.01639175e-01   1.20909624e-01   1.66445717e-01
   1.72086030e-01   4.69095625e-07   3.24776892e-07   2.00321423e-07
   1.84287259e-07], sum to 1.0000
[2017-11-01 09:40:48,205] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [14.9, 100.0, 2.016666666666667, 301.6666666666667, 76.66666666666667, 0.0, 9.95, 6.07329690106344, 10.0, 24.40565479846283, 22.7, 1.0, 0.0], 
actual action is [9.9, 10.0], 
sim time next is 1246500.0000, 
raw observation next is [14.85, 100.0, 2.275, 302.5, 77.0, 0.0, 9.9, 6.00349948406805, 10.0, 24.30640978457461, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.43478260869565216, 0.7141025641025641, 1.0, 0.20681818181818182, 0.8402777777777778, 0.2037037037037037, 0.0, 0.6649999999999999, 0.060034994840680506, 0.0, 0.7153204892287304, 0.635, 1.0, 0.0], 
reward next is -0.0300. 
=============================================
[2017-11-01 09:40:49,041] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.17977339e-01   1.94934055e-01   9.25719887e-02   1.94083720e-01
   2.00432599e-01   1.14057293e-07   8.78405970e-08   4.69008903e-08
   4.99851929e-08], sum to 1.0000
[2017-11-01 09:40:49,070] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.0, 99.33333333333334, 2.016666666666667, 216.6666666666667, 43.33333333333333, 0.0, 20.0, 8.527718494190072, 22.5, 25.1802727697008, 22.7, 1.0, 19.36879203169171], 
actual action is [20.0, 17.5], 
sim time next is 1241700.0000, 
raw observation next is [15.0, 99.66666666666666, 1.758333333333334, 213.3333333333333, 47.16666666666667, 0.0, 20.0, 8.351885734799957, 17.5, 25.13137520178959, 22.7, 1.0, 17.9616992216537], 
processed observation next is [1.0, 0.34782608695652173, 0.717948717948718, 0.9966666666666666, 0.1598484848484849, 0.5925925925925924, 0.12477954144620812, 0.0, 0.8333333333333334, 0.08351885734799958, 0.375, 0.7565687600894796, 0.635, 1.0, 0.21131410849004353], 
reward next is -0.1474. 
=============================================
[2017-11-01 09:40:52,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-14.89390278]
 [-14.81197262]
 [-14.91161919]
 [-13.96364403]
 [-14.38211155]], R is [[-13.80219364]
 [-13.72163391]
 [-13.76015472]
 [-13.80760479]
 [-13.8646698 ]].
[2017-11-01 09:40:53,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.50514281e-01   1.75547317e-01   7.17460811e-02   8.98114070e-02
   1.12380922e-01   2.74017822e-11   1.92321090e-11   1.24109317e-11
   1.51310839e-11], sum to 1.0000
[2017-11-01 09:40:53,035] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.383333333333333, 96.0, 6.699999999999999, 330.0, 0.0, 0.0, 2.475000000000001, 8.35722430989012, 10.0, 22.2045276740632, 22.7, 1.0, 0.0], 
actual action is [2.383333333333333, 10], 
sim time next is 1277700.0000, 
raw observation next is [7.291666666666667, 96.0, 6.65, 330.0, 0.0, 0.0, 2.383333333333333, 8.462892568440466, 10.0, 22.16397451668333, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.5202991452991453, 0.96, 0.6045454545454546, 0.9166666666666666, 0.0, 0.0, 0.5397222222222222, 0.08462892568440467, 0.0, 0.6081987258341665, 0.635, 1.0, 0.0], 
reward next is -0.0423. 
=============================================
[2017-11-01 09:40:55,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-6.07414007]
 [-5.67933655]
 [-6.06310987]
 [-5.999125  ]
 [-6.66801834]], R is [[-6.90590906]
 [-6.90843248]
 [-6.91017628]
 [-6.91117239]
 [-6.91143036]].
[2017-11-01 09:40:56,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-5.7136631 ]
 [-5.69440985]
 [-4.89960861]
 [-5.02464104]
 [-5.21784163]], R is [[-5.59819126]
 [-5.62678385]
 [-5.65234423]
 [-5.67663336]
 [-5.70171213]].
[2017-11-01 09:41:04,314] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71041: loss 3.7999
[2017-11-01 09:41:04,770] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.07634342e-01   1.40231252e-01   1.88603893e-01   9.65295583e-02
   6.70009255e-02   7.39867271e-15   8.79445764e-15   1.70591877e-14
   1.30029205e-14], sum to 1.0000
[2017-11-01 09:41:04,789] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.475, 92.0, 6.225, 257.5, 0.0, 0.0, 6.516666666666667, 10.85177973242041, 10.5, 21.61347718186798, 21.5, 0.0, 27.16201637282291], 
actual action is [-3.525, 10], 
sim time next is 1318800.0000, 
raw observation next is [1.433333333333334, 92.0, 6.266666666666667, 256.6666666666667, 0.0, 0.0, -3.525, 11.84831092833391, 10.0, 21.64677797498757, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.3700854700854701, 0.92, 0.5696969696969697, 0.712962962962963, 0.0, 0.0, 0.44125000000000003, 0.1184831092833391, 0.0, 0.5823388987493786, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:41:05,157] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.35912335e-01   1.42682448e-01   1.42132699e-01   1.04388721e-01
   7.48838186e-02   2.97496511e-13   3.57422994e-13   5.42656631e-13
   4.17041754e-13], sum to 1.0000
[2017-11-01 09:41:05,166] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 6.1, 273.3333333333333, 122.3333333333333, 0.0, -3.9, 20.32080939731331, 10.0, 21.11639481821025, 22.7, 1.0, 0.0], 
actual action is [-3.9, 10], 
sim time next is 1338900.0000, 
raw observation next is [1.1, 92.0, 6.35, 271.6666666666667, 121.1666666666667, 0.0, -3.9, 20.45462634871323, 10.0, 21.12792364036881, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.36153846153846153, 0.92, 0.5772727272727273, 0.7546296296296297, 0.320546737213404, 0.0, 0.435, 0.2045462634871323, 0.0, 0.5563961820184404, 0.635, 1.0, 0.0], 
reward next is -0.1023. 
=============================================
[2017-11-01 09:41:05,415] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.68843520e-01   1.42792970e-01   1.79940715e-01   1.25211254e-01
   8.32116380e-02   7.08383818e-14   7.13721888e-14   7.92335964e-14
   6.50029686e-14], sum to 1.0000
[2017-11-01 09:41:05,439] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.1, 92.0, 7.024999999999999, 288.3333333333333, 59.75, 0.0, 6.1, 20.45340026850259, 13.0, 20.94185770205937, 22.7, 1.0, 13.04777769672509], 
actual action is [6.1, 11.0], 
sim time next is 1350000.0000, 
raw observation next is [1.1, 92.0, 7.2, 290.0, 57.5, 0.0, 6.1, 20.32712650202943, 11.0, 20.98916514713678, 22.7, 1.0, 10.55120599095053], 
processed observation next is [0.0, 0.6521739130434783, 0.36153846153846153, 0.92, 0.6545454545454545, 0.8055555555555556, 0.15211640211640212, 0.0, 0.6016666666666667, 0.2032712650202943, 0.05, 0.5494582573568391, 0.635, 1.0, 0.12413183518765329], 
reward next is -0.1637. 
=============================================
[2017-11-01 09:41:05,517] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4500, global step 71457: loss -0.9405
[2017-11-01 09:41:05,856] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71575: loss 10.2394
[2017-11-01 09:41:05,928] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71603: loss 19.7549
[2017-11-01 09:41:05,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71614: loss 13.6136
[2017-11-01 09:41:06,002] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71614: loss -7.0185
[2017-11-01 09:41:06,159] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71680: loss -15.6364
[2017-11-01 09:41:06,546] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.94109985e-32   6.94405361e-33   4.38263489e-33
   3.56218722e-33   6.10806160e-02   1.72743246e-01   5.47621548e-01
   2.18554601e-01], sum to 1.0000
[2017-11-01 09:41:06,553] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.99095066e-05   3.60168904e-01   2.67818213e-01   2.56307632e-01
   1.15682133e-01   4.60257667e-07   6.64834772e-07   1.02352851e-06
   1.12549924e-06], sum to 1.0000
[2017-11-01 09:41:06,589] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.1, 92.0, 4.766666666666667, 276.6666666666667, 107.1666666666667, 0.0, -3.9, 27.05687852691472, 10.0, 19.7441325543478, 22.7, 1.0, 0.0], 
actual action is [-3.9, 10], 
sim time next is 1344300.0000, 
raw observation next is [1.1, 92.0, 4.808333333333333, 275.8333333333333, 106.5833333333333, 0.0, -3.9, 27.07884858630234, 10.0, 19.73577927084742, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.36153846153846153, 0.92, 0.4371212121212121, 0.7662037037037036, 0.28196649029982357, 0.0, 0.435, 0.2707884858630234, 0.0, 0.486788963542371, 0.635, 1.0, 0.0], 
reward next is -0.1354. 
=============================================
[2017-11-01 09:41:06,590] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.6, 95.5, 5.266666666666667, 281.6666666666667, 12.0, 0.0, -4.35, 25.14102590195155, 10.0, 20.41936509092398, 22.7, 1.0, 0.0], 
actual action is [5.6, 11.0], 
sim time next is 1356900.0000, 
raw observation next is [0.55, 95.75, 5.183333333333334, 280.8333333333333, 10.5, 0.0, 5.6, 24.3088297824309, 11.0, 20.37307001225548, 22.7, 1.0, 23.27914813417202], 
processed observation next is [0.0, 0.6956521739130435, 0.3474358974358975, 0.9575, 0.47121212121212125, 0.7800925925925926, 0.027777777777777776, 0.0, 0.5933333333333334, 0.24308829782430902, 0.05, 0.5186535006127739, 0.635, 1.0, 0.27387233099025904], 
reward next is -0.2585. 
=============================================
[2017-11-01 09:41:06,844] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4500, global step 71889: loss 1.9628
[2017-11-01 09:41:06,939] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71922: loss 3.1164
[2017-11-01 09:41:07,092] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4500, global step 71966: loss -18.8782
[2017-11-01 09:41:07,322] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72040: loss 19.1030
[2017-11-01 09:41:07,388] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4500, global step 72062: loss -33.0716
[2017-11-01 09:41:07,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72187: loss -5.0389
[2017-11-01 09:41:08,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.46111351e-01   2.55345047e-01   1.21417865e-01   1.10984907e-01
   6.61407858e-02   9.07460559e-19   1.36001655e-18   9.56409385e-19
   1.23768574e-18], sum to 1.0000
[2017-11-01 09:41:08,128] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.5, 96.0, 5.933333333333334, 286.6666666666667, 0.0, 0.0, 5.5, 33.12049022764472, 12.0, 19.05662934939777, 22.7, 1.0, 7.957534986905486], 
actual action is [5.5, 11.5], 
sim time next is 1362300.0000, 
raw observation next is [0.5, 96.0, 6.016666666666666, 288.3333333333333, 0.0, 0.0, 5.5, 33.61627677220876, 11.5, 18.9837586650554, 22.7, 1.0, 7.613978697690698], 
processed observation next is [0.0, 0.782608695652174, 0.34615384615384615, 0.96, 0.5469696969696969, 0.8009259259259258, 0.0, 0.0, 0.5916666666666667, 0.3361627677220876, 0.075, 0.44918793325277007, 0.635, 1.0, 0.08957621997283173], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:41:09,490] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72592: loss -0.7404
[2017-11-01 09:41:10,347] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4500, global step 72735: loss 6.6203
[2017-11-01 09:41:10,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.81279680e-14   5.64403892e-01   1.80295259e-01   6.39692172e-02
   4.86028790e-02   1.14718480e-02   3.34644355e-02   2.26549208e-02
   7.51376003e-02], sum to 1.0000
[2017-11-01 09:41:10,544] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.4166666666666667, 95.83333333333333, 5.766666666666667, 285.0, 0.0, 0.0, -4.541666666666667, 21.28565867932005, 10.0, 20.93349442077397, 21.5, 0.0, 0.0], 
actual action is [-4.583333333333333, 10.0], 
sim time next is 1376100.0000, 
raw observation next is [0.375, 95.75, 5.6, 287.5, 0.0, 0.0, -4.583333333333333, 24.00056914674002, 10.0, 20.72739810316824, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9565217391304348, 0.34294871794871795, 0.9575, 0.509090909090909, 0.7986111111111112, 0.0, 0.0, 0.4236111111111111, 0.2400056914674002, 0.0, 0.5363699051584121, 0.575, 0.0, 0.0], 
reward next is -0.1932. 
=============================================
[2017-11-01 09:41:12,501] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 73116: loss 21.1439
[2017-11-01 09:41:20,844] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.74618405e-01   2.46597260e-01   6.27695695e-02   8.13886598e-02
   1.34626105e-01   2.05967362e-24   2.79503713e-24   2.68878151e-24
   1.36514257e-23], sum to 1.0000
[2017-11-01 09:41:20,941] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 2.125, 310.0, 0.0, 0.0, 4.4, 13.6474544199938, 17.0, 21.21052582305903, 21.5, 0.0, 38.42283424311422], 
actual action is [4.4, 12.0], 
sim time next is 1398000.0000, 
raw observation next is [-0.6, 100.0, 2.166666666666667, 313.3333333333334, 0.0, 0.0, 4.4, 13.63697368955881, 12.0, 21.29372175092513, 21.5, 0.0, 32.83825595459368], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.317948717948718, 1.0, 0.196969696969697, 0.8703703703703707, 0.0, 0.0, 0.5733333333333334, 0.1363697368955881, 0.1, 0.5646860875462565, 0.575, 0.0, 0.38633242299521975], 
reward next is -0.2447. 
=============================================
[2017-11-01 09:41:24,163] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-23.76882172]
 [-22.06447601]
 [-23.53111458]
 [-24.62097168]
 [-23.74909019]], R is [[-22.85652161]
 [-22.73589897]
 [-22.61506653]
 [-22.49398994]
 [-22.37249374]].
[2017-11-01 09:41:28,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.47911185e-01   2.32269943e-01   7.15859085e-02   1.65515289e-01
   2.82717645e-01   7.75811537e-15   4.57435146e-15   2.87323338e-15
   6.45815739e-15], sum to 1.0000
[2017-11-01 09:41:28,226] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-0.6, 100.0, 2.5, 360.0, 9.0, 0.0, 4.4, 21.04268478260932, 10.5, 19.98466808411019, 22.7, 1.0, 26.96887423019465], 
actual action is [4.4, 10.5], 
sim time next is 1411500.0000, 
raw observation next is [-0.6, 99.99999999999999, 2.458333333333333, 331.6666666666667, 10.5, 0.0, 4.4, 20.48523652506658, 10.5, 20.02498835432669, 22.7, 1.0, 24.8687610082497], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 0.9999999999999999, 0.22348484848484845, 0.9212962962962964, 0.027777777777777776, 0.0, 0.5733333333333334, 0.2048523652506658, 0.025, 0.5012494177163346, 0.635, 1.0, 0.2925736589205847], 
reward next is -0.2487. 
=============================================
[2017-11-01 09:41:44,114] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79478: loss 21.6072
[2017-11-01 09:41:44,133] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79484: loss 32.1953
[2017-11-01 09:41:44,592] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79567: loss -15.9425
[2017-11-01 09:41:44,598] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5000, global step 79567: loss -11.0651
[2017-11-01 09:41:44,863] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79606: loss 51.6946
[2017-11-01 09:41:45,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79668: loss -1.9912
[2017-11-01 09:41:45,964] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5000, global step 79794: loss 4.7493
[2017-11-01 09:41:46,242] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79833: loss 13.8181
[2017-11-01 09:41:47,401] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80053: loss 7.7872
[2017-11-01 09:41:47,431] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80054: loss -3.5269
[2017-11-01 09:41:48,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  3.94222170e-01   2.34325707e-01   2.63086725e-02   4.53402363e-02
   2.99803168e-01   2.03601998e-16   1.41043903e-16   6.63110264e-17
   1.17959926e-16], sum to 1.0000
[2017-11-01 09:41:48,164] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.05, 92.0, 0.625, 70.0, 0.0, 0.0, -3.0, 12.82910204483987, 10.0, 22.2645475638651, 21.5, 0.0, 0.0], 
actual action is [-2.95, 10], 
sim time next is 1475400.0000, 
raw observation next is [2.1, 92.0, 0.4166666666666666, 46.66666666666666, 0.0, 0.0, -2.95, 14.26915629982927, 10.0, 22.19255738239322, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.3871794871794872, 0.92, 0.03787878787878787, 0.1296296296296296, 0.0, 0.0, 0.45083333333333336, 0.1426915629982927, 0.0, 0.6096278691196609, 0.575, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-01 09:41:48,316] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5000, global step 80218: loss 25.2023
[2017-11-01 09:41:48,841] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80315: loss 2.1489
[2017-11-01 09:41:48,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   2.83204872e-21   1.71071997e-22   3.80363056e-22
   4.52394367e-21   1.15125060e-01   1.93901598e-01   5.13411909e-02
   6.39632165e-01], sum to 1.0000
[2017-11-01 09:41:49,033] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 100.0, 0.0, 0.0, 9.0, 0.0, 6.1, 26.30561868569826, 18.0, 19.74315870782289, 22.7, 1.0, 13.67269315453945], 
actual action is [6.1, 23.0], 
sim time next is 1497900.0000, 
raw observation next is [1.141666666666667, 99.99999999999999, 0.1666666666666667, 10.0, 10.5, 0.0, 6.1, 24.08813231460101, 23.0, 19.69638210283873, 22.7, 1.0, 63.73468725745808], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.36260683760683765, 0.9999999999999999, 0.015151515151515155, 0.027777777777777776, 0.027777777777777776, 0.0, 0.6016666666666667, 0.24088132314601007, 0.65, 0.4848191051419365, 0.635, 1.0, 0.7498198500877421], 
reward next is -0.4954. 
=============================================
[2017-11-01 09:41:49,158] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5000, global step 80364: loss 3.1143
[2017-11-01 09:41:50,863] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80623: loss -3.5574
[2017-11-01 09:41:51,409] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5000, global step 80674: loss 8.3357
[2017-11-01 09:41:55,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.55973870e-01   1.86398089e-01   1.51906371e-01   1.18339553e-01
   1.87322617e-01   2.22295403e-05   1.83470074e-05   1.02326267e-05
   8.67488143e-06], sum to 1.0000
[2017-11-01 09:41:55,906] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.0, 63.0, 0.0, 0.0, 80.0, 682.0, 4.766666666666666, 13.08231631338067, 10.0, 22.16811090350194, 22.7, 1.0, 0.0], 
actual action is [5.0, 10], 
sim time next is 1519500.0000, 
raw observation next is [10.13333333333333, 62.08333333333334, 0.2083333333333333, 10.83333333333333, 79.16666666666666, 678.8333333333333, 5.0, 12.76339582398306, 10.0, 22.21278854041735, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.593162393162393, 0.6208333333333335, 0.018939393939393936, 0.030092592592592584, 0.20943562610229274, 0.6788333333333333, 0.5833333333333334, 0.1276339582398306, 0.0, 0.6106394270208675, 0.635, 1.0, 0.0], 
reward next is -0.0638. 
=============================================
[2017-11-01 09:42:00,329] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 81865: loss 34.0987
[2017-11-01 09:42:06,003] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.11043226e-19   3.13274935e-03   5.15860593e-05   7.73713400e-05
   1.20840920e-03   9.15775001e-02   1.27045810e-01   3.22755016e-02
   7.44630992e-01], sum to 1.0000
[2017-11-01 09:42:06,034] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  6.27107859e-01   2.00032398e-01   1.64824165e-02   1.46499248e-02
   1.41727388e-01   6.38703756e-23   6.57752791e-23   1.99236635e-23
   2.62202648e-22], sum to 1.0000
[2017-11-01 09:42:06,039] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [5.0, 80.0, 3.6, 103.3333333333333, 0.0, 0.0, 10.0, 15.79478378906003, 17.0, 20.92214867659663, 21.5, 0.0, 17.19509266526031], 
actual action is [10.0, 22.0], 
sim time next is 1561500.0000, 
raw observation next is [5.0, 79.75, 3.6, 102.5, 0.0, 0.0, 10.0, 16.18771617064769, 22.0, 20.86080501292454, 21.5, 0.0, 16.36645891670974], 
processed observation next is [0.5, 0.043478260869565216, 0.46153846153846156, 0.7975, 0.32727272727272727, 0.2847222222222222, 0.0, 0.0, 0.6666666666666666, 0.1618771617064769, 0.6, 0.5430402506462271, 0.575, 0.0, 0.1925465754907028], 
reward next is -0.2561. 
=============================================
[2017-11-01 09:42:06,044] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.575, 73.75, 4.225, 107.5, 0.0, 0.0, 12.53333333333333, 14.30317355421852, 14.5, 21.3396198535608, 21.5, 0.0, 13.89821326314212], 
actual action is [2.575, 10], 
sim time next is 1543800.0000, 
raw observation next is [7.616666666666667, 73.83333333333334, 4.183333333333333, 108.3333333333333, 0.0, 0.0, 2.575, 14.97212461020685, 10.0, 21.33429526709182, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.5286324786324786, 0.7383333333333334, 0.38030303030303025, 0.3009259259259258, 0.0, 0.0, 0.5429166666666667, 0.1497212461020685, 0.0, 0.566714763354591, 0.575, 0.0, 0.0], 
reward next is -0.0414. 
=============================================
[2017-11-01 09:42:08,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  6.31875992e-01   1.60285801e-01   3.17166336e-02   2.01449450e-02
   1.55976653e-01   6.26104793e-18   1.46502951e-17   3.93405900e-18
   7.81820178e-18], sum to 1.0000
[2017-11-01 09:42:08,808] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.65, 84.5, 2.75, 90.0, 0.0, 0.0, 9.641666666666666, 13.3817419193937, 22.5, 21.21913855083724, 21.5, 0.0, 19.1349361845875], 
actual action is [9.65, 17.5], 
sim time next is 1571700.0000, 
raw observation next is [4.658333333333333, 84.41666666666666, 2.741666666666667, 90.0, 0.0, 0.0, 9.65, 12.87793903107233, 17.5, 21.19488764833061, 21.5, 0.0, 37.03449263044949], 
processed observation next is [0.5, 0.17391304347826086, 0.4527777777777777, 0.8441666666666666, 0.2492424242424243, 0.25, 0.0, 0.0, 0.6608333333333333, 0.1287793903107233, 0.375, 0.5597443824165305, 0.575, 0.0, 0.43569991329940577], 
reward next is -0.2941. 
=============================================
[2017-11-01 09:42:14,712] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.54133809e-01   2.65201271e-01   7.04259127e-02   5.18148392e-02
   1.58424169e-01   1.26744657e-14   3.30702737e-14   1.41776273e-14
   1.95507808e-14], sum to 1.0000
[2017-11-01 09:42:14,927] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.4, 80.5, 4.35, 122.5, 28.0, 27.5, 10.26666666666667, 9.973790397670722, 22.5, 20.83180689323897, 22.7, 1.0, 77.16491343692768], 
actual action is [10.4, 17.5], 
sim time next is 1585200.0000, 
raw observation next is [5.533333333333333, 80.0, 4.433333333333334, 123.3333333333333, 31.0, 30.0, 10.4, 8.544709243170724, 17.5, 21.27936734963497, 22.7, 1.0, 47.71448170832596], 
processed observation next is [0.5, 0.34782608695652173, 0.4752136752136752, 0.8, 0.40303030303030307, 0.3425925925925925, 0.082010582010582, 0.03, 0.6733333333333333, 0.08544709243170724, 0.375, 0.5639683674817485, 0.635, 1.0, 0.5613468436273643], 
reward next is -0.3234. 
=============================================
[2017-11-01 09:42:20,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.37230593e-01   2.75979757e-01   5.28044365e-02   7.99734965e-02
   2.54011780e-01   5.83296280e-15   1.19763183e-14   9.78269437e-15
   7.63599524e-15], sum to 1.0000
[2017-11-01 09:42:20,902] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [10.225, 62.25, 6.15, 155.0, 0.0, 0.0, 5.31666666666667, 12.37525920663654, 10.0, 21.7982786677566, 22.7, 1.0, 0.0], 
actual action is [5.225, 10.0], 
sim time next is 1621200.0000, 
raw observation next is [10.13333333333333, 62.66666666666667, 5.800000000000001, 156.6666666666667, 0.0, 0.0, 5.225, 12.67898741018304, 10.0, 21.69320133884548, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.593162393162393, 0.6266666666666667, 0.5272727272727273, 0.43518518518518534, 0.0, 0.0, 0.5870833333333334, 0.1267898741018304, 0.0, 0.584660066942274, 0.635, 1.0, 0.0], 
reward next is -0.0634. 
=============================================
[2017-11-01 09:42:28,146] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 86758: loss 1.1205
[2017-11-01 09:42:28,431] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.09700191e-01   1.73396349e-01   2.28245378e-01   1.02528788e-01
   1.86129332e-01   1.58937738e-10   1.64053035e-10   6.40537137e-11
   7.10190171e-11], sum to 1.0000
[2017-11-01 09:42:28,440] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.8, 49.0, 5.225, 130.8333333333333, 117.0833333333333, 0.0, 8.8, 10.76877101817208, 10.0, 22.42055343925962, 22.7, 1.0, 0.0], 
actual action is [8.8, 10], 
sim time next is 1609200.0000, 
raw observation next is [13.8, 49.0, 5.1, 130.0, 111.5, 0.0, 8.8, 10.72832131847374, 10.0, 22.43592921790779, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.6871794871794872, 0.49, 0.4636363636363636, 0.3611111111111111, 0.294973544973545, 0.0, 0.6466666666666666, 0.1072832131847374, 0.0, 0.6217964608953895, 0.635, 1.0, 0.0], 
reward next is -0.0536. 
=============================================
[2017-11-01 09:42:28,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-22.19219208]
 [-23.03310013]
 [-23.09212112]
 [-22.9251976 ]
 [-23.57172012]], R is [[-23.42020988]
 [-23.5779686 ]
 [-23.56031036]
 [-23.53138351]
 [-23.49145889]].
[2017-11-01 09:42:29,879] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  5.16269565e-01   1.07848376e-01   1.80388942e-01   3.10891978e-02
   1.64403975e-01   1.15793176e-16   1.20613627e-16   6.31644579e-17
   1.81707387e-16], sum to 1.0000
[2017-11-01 09:42:29,926] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.04166666666667, 63.08333333333333, 5.449999999999999, 158.3333333333333, 0.0, 0.0, 5.133333333333329, 16.3775260613236, 10.0, 20.64560202748166, 22.7, 1.0, 0.0], 
actual action is [5.04166666666667, 10], 
sim time next is 1621800.0000, 
raw observation next is [9.95, 63.5, 5.1, 160.0, 0.0, 0.0, 5.04166666666667, 16.68862416198064, 10.0, 20.56479237397992, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5884615384615385, 0.635, 0.4636363636363636, 0.4444444444444444, 0.0, 0.0, 0.5840277777777778, 0.16688624161980642, 0.0, 0.5282396186989959, 0.635, 1.0, 0.0], 
reward next is -0.0834. 
=============================================
[2017-11-01 09:42:30,355] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87265: loss -18.5548
[2017-11-01 09:42:30,511] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87302: loss 81.8320
[2017-11-01 09:42:30,557] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.88745487e-01   8.17994103e-02   2.97943294e-01   1.64786670e-02
   2.15033174e-01   1.75135378e-28   2.47410474e-28   9.39608859e-29
   8.83891007e-28], sum to 1.0000
[2017-11-01 09:42:30,566] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.258333333333333, 66.66666666666667, 3.35, 165.8333333333333, 0.0, 0.0, 14.4, 20.10538554571911, 13.0, 19.61949433394701, 22.7, 1.0, 7.812647048688459], 
actual action is [4.258333333333333, 10], 
sim time next is 1624200.0000, 
raw observation next is [9.116666666666667, 67.33333333333333, 3.7, 161.6666666666667, 0.0, 0.0, 4.258333333333333, 20.65642593000155, 10.0, 19.58802696717056, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.8260869565217391, 0.5670940170940171, 0.6733333333333333, 0.33636363636363636, 0.4490740740740742, 0.0, 0.0, 0.5709722222222222, 0.2065642593000155, 0.0, 0.479401348358528, 0.635, 1.0, 0.0], 
reward next is -0.1033. 
=============================================
[2017-11-01 09:42:31,736] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5500, global step 87547: loss -17.4681
[2017-11-01 09:42:31,782] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87554: loss 7.5966
[2017-11-01 09:42:31,914] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5500, global step 87582: loss 17.5275
[2017-11-01 09:42:31,930] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87584: loss 187.1984
[2017-11-01 09:42:32,109] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87615: loss 75.2476
[2017-11-01 09:42:33,581] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87864: loss -101.8306
[2017-11-01 09:42:35,345] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88193: loss -10.7598
[2017-11-01 09:42:35,672] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88258: loss 146.8186
[2017-11-01 09:42:36,029] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5500, global step 88343: loss -74.6273
[2017-11-01 09:42:38,111] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5500, global step 88757: loss -22.6067
[2017-11-01 09:42:38,698] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88861: loss -48.1534
[2017-11-01 09:42:38,974] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5500, global step 88921: loss -79.3379
[2017-11-01 09:42:39,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   2.67927572e-17   1.04076507e-16   2.35307920e-17
   1.99624027e-17   7.95584098e-02   1.00319900e-01   5.90704903e-02
   7.61051238e-01], sum to 1.0000
[2017-11-01 09:42:39,940] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [6.6, 97.0, 4.85, 135.0, 0.0, 0.0, 11.6, 26.01103598595351, 14.0, 19.05108358646893, 21.5, 0.0, 10.89047113599429], 
actual action is [11.6, 19.0], 
sim time next is 1654500.0000, 
raw observation next is [6.6, 97.0, 4.891666666666667, 135.8333333333333, 0.0, 0.0, 11.6, 26.17000554628601, 19.0, 19.04058871948487, 21.5, 0.0, 9.033182689247017], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5025641025641026, 0.97, 0.4446969696969697, 0.37731481481481466, 0.0, 0.0, 0.6933333333333334, 0.2617000554628601, 0.45, 0.4520294359742435, 0.575, 0.0, 0.10627273752055313], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:42:43,339] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 89786: loss -220.7722
[2017-11-01 09:42:48,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.70600903e-01   1.30088285e-01   1.28871247e-01   1.13879554e-01
   1.56560063e-01   4.48242040e-19   1.00596061e-18   2.78069352e-19
   3.84425614e-18], sum to 1.0000
[2017-11-01 09:42:48,276] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.35, 235.0, 100.0, 0.0, -3.9, 21.68760246693595, 10.0, 20.35024300815001, 22.7, 1.0, 0.0], 
actual action is [-3.9, 10], 
sim time next is 1690500.0000, 
raw observation next is [1.1, 88.0, 6.391666666666666, 235.8333333333333, 98.33333333333333, 0.0, -3.9, 22.21864415837789, 10.0, 20.3098130839987, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.36153846153846153, 0.88, 0.5810606060606059, 0.6550925925925924, 0.2601410934744268, 0.0, 0.435, 0.22218644158377893, 0.0, 0.5154906541999351, 0.635, 1.0, 0.0], 
reward next is -0.1111. 
=============================================
[2017-11-01 09:42:51,722] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.87380767e-01   7.29004592e-02   1.35698140e-01   9.21323150e-02
   1.11888260e-01   2.31256057e-23   1.06732843e-22   2.77648620e-23
   2.76615881e-22], sum to 1.0000
[2017-11-01 09:42:51,843] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.55, 91.66666666666667, 7.7, 240.0, 0.0, 0.0, 5.6, 15.42489658346007, 19.0, 21.5959276602638, 21.5, 0.0, 28.39399068424669], 
actual action is [5.55, 14.0], 
sim time next is 1717200.0000, 
raw observation next is [0.5, 92.0, 7.7, 240.0, 0.0, 0.0, 5.55, 15.63558887332853, 14.0, 21.58405057920265, 21.5, 0.0, 26.84557428958414], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.34615384615384615, 0.92, 0.7000000000000001, 0.6666666666666666, 0.0, 0.0, 0.5924999999999999, 0.1563558887332853, 0.2, 0.5792025289601325, 0.575, 0.0, 0.3158302857598134], 
reward next is -0.1579. 
=============================================
[2017-11-01 09:42:56,338] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.78231688e-04   3.54927480e-01   3.29327881e-01   2.04147637e-01
   1.11318797e-01   4.15968693e-21   1.95353032e-20   3.55731729e-21
   1.10911711e-19], sum to 1.0000
[2017-11-01 09:42:56,391] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.2916666666666667, 93.25, 8.7, 245.8333333333333, 0.0, 0.0, 5.25, 16.35276584341403, 29.0, 21.30886993553979, 21.5, 0.0, 51.69412850291957], 
actual action is [5.291666666666667, 27.0], 
sim time next is 1726800.0000, 
raw observation next is [0.3333333333333333, 93.0, 8.7, 246.6666666666667, 0.0, 0.0, 5.291666666666667, 15.66623313377007, 27.0, 21.39626065855552, 21.5, 0.0, 49.68100246107839], 
processed observation next is [0.6666666666666666, 1.0, 0.3418803418803419, 0.93, 0.7909090909090909, 0.6851851851851853, 0.0, 0.0, 0.5881944444444444, 0.15666233133770072, 0.85, 0.569813032927776, 0.575, 0.0, 0.5844823818950399], 
reward next is -0.3182. 
=============================================
[2017-11-01 09:43:08,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   2.05599901e-21   8.10141500e-21   4.05663816e-20
   2.61190720e-21   8.32979232e-02   1.03432097e-01   4.70894985e-02
   7.66180456e-01], sum to 1.0000
[2017-11-01 09:43:08,962] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.8, 84.33333333333334, 9.7, 250.0, 0.0, 0.0, 4.25, 27.74976054495615, 30.0, 19.17151396063909, 21.5, 0.0, 64.89242741398097], 
actual action is [4.2, 30], 
sim time next is 1747500.0000, 
raw observation next is [-0.8499999999999999, 84.66666666666666, 9.7, 250.0, 0.0, 0.0, 4.2, 25.28841456639413, 30.0, 19.29297106604997, 21.5, 0.0, 58.25385895026113], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.31153846153846154, 0.8466666666666666, 0.8818181818181817, 0.6944444444444444, 0.0, 0.0, 0.5700000000000001, 0.2528841456639413, 1.0, 0.46464855330249843, 0.575, 0.0, 0.6853395170618957], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:43:10,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.69884199e-01   1.37423798e-02   4.13298875e-01   2.76115775e-01
   2.69588754e-02   4.64415527e-29   1.62905823e-29   1.49381341e-29
   4.03085040e-29], sum to 1.0000
[2017-11-01 09:43:10,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.7, 87.0, 9.158333333333331, 249.1666666666667, 11.41666666666667, 0.0, 3.3, 17.51944006359771, 28.5, 20.66894605513448, 21.5, 0.0, 48.20830382244576], 
actual action is [3.3, 27.5], 
sim time next is 1756800.0000, 
raw observation next is [-1.7, 87.0, 9.2, 250.0, 13.5, 0.0, 3.3, 17.22634974336449, 27.5, 20.7306948045198, 21.5, 0.0, 48.17194269155367], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.28974358974358977, 0.87, 0.8363636363636363, 0.6944444444444444, 0.03571428571428571, 0.0, 0.5549999999999999, 0.1722634974336449, 0.875, 0.53653474022599, 0.575, 0.0, 0.5667287375476902], 
reward next is -0.4757. 
=============================================
[2017-11-01 09:43:11,333] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.81118065e-01   1.10245803e-02   2.10483462e-01   4.60594773e-01
   3.67791355e-02   3.60523929e-30   2.18348753e-30   8.52538563e-31
   3.28210699e-30], sum to 1.0000
[2017-11-01 09:43:11,371] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.8, 83.66666666666667, 9.2, 250.0, 52.0, 0.0, 3.25, 23.52425701323831, 11.5, 20.44955717133181, 22.7, 1.0, 30.3862548957976], 
actual action is [3.2, 11.0], 
sim time next is 1761300.0000, 
raw observation next is [-1.85, 84.0, 9.2, 250.0, 55.25, 0.0, 3.2, 24.26680147356256, 11.0, 20.40243467136925, 22.7, 1.0, 28.24107223884759], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.2858974358974359, 0.84, 0.8363636363636363, 0.6944444444444444, 0.14616402116402116, 0.0, 0.5533333333333333, 0.2426680147356256, 0.05, 0.5201217335684625, 0.635, 1.0, 0.33224790869232457], 
reward next is -0.2875. 
=============================================
[2017-11-01 09:43:12,027] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.90567894e-16   4.36127521e-02   2.09927186e-01   7.03444660e-01
   4.29601893e-02   1.06234838e-05   8.63920286e-06   3.51599874e-06
   3.23532513e-05], sum to 1.0000
[2017-11-01 09:43:12,113] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.7, 87.0, 8.7, 240.0, 0.0, 0.0, 3.341666666666667, 18.76823550533732, 27.5, 20.31461195092311, 21.5, 0.0, 49.00204381777331], 
actual action is [3.3, 27.0], 
sim time next is 1753500.0000, 
raw observation next is [-1.7, 87.0, 8.741666666666665, 240.8333333333333, 0.0, 0.0, 3.3, 18.30635400854656, 27.0, 20.40167555044141, 21.5, 0.0, 48.53808557958931], 
processed observation next is [0.8333333333333334, 0.30434782608695654, 0.28974358974358977, 0.87, 0.7946969696969696, 0.6689814814814814, 0.0, 0.0, 0.5549999999999999, 0.1830635400854656, 0.85, 0.5200837775220706, 0.575, 0.0, 0.5710363009363448], 
reward next is -0.5601. 
=============================================
[2017-11-01 09:43:22,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00287177
  0.01135182  0.00234501  0.9834314 ], sum to 1.0000
[2017-11-01 09:43:22,824] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 83.0, 9.991666666666667, 250.0, 117.3333333333333, 0.0, 2.2, 34.16552508517, 20.5, 19.32338350966559, 22.7, 1.0, 46.98305009738877], 
actual action is [2.2, 25.5], 
sim time next is 1777200.0000, 
raw observation next is [-2.8, 83.0, 10.03333333333333, 250.0, 115.6666666666667, 0.0, 2.2, 30.50075023276317, 25.5, 19.33351708810222, 22.7, 1.0, 85.97345874050832], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.2615384615384615, 0.83, 0.9121212121212118, 0.6944444444444444, 0.3059964726631394, 0.0, 0.5366666666666667, 0.3050075023276317, 0.775, 0.46667585440511095, 0.635, 1.0, 1.011452455770686], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:43:23,764] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95093: loss 13.3862
[2017-11-01 09:43:28,361] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95454: loss 44.3284
[2017-11-01 09:43:28,625] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6000, global step 95473: loss 53.4957
[2017-11-01 09:43:28,791] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95490: loss 16.0481
[2017-11-01 09:43:31,624] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95725: loss -3.8979
[2017-11-01 09:43:32,593] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95814: loss 8.8508
[2017-11-01 09:43:32,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  5.02571929e-03   1.19359968e-02   5.06525755e-01   3.94410431e-01
   8.21021795e-02   3.77032650e-33   4.57935718e-33   1.05493583e-33
   1.63590713e-32], sum to 1.0000
[2017-11-01 09:43:32,869] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 83.0, 8.7, 250.0, 0.0, 0.0, -9.5, 31.72345151466835, 10.0, 20.64529826137758, 21.5, 0.0, 0.0], 
actual action is [-9.5, 10], 
sim time next is 1797900.0000, 
raw observation next is [-4.5, 83.0, 8.825, 250.0, 0.0, 0.0, -9.5, 34.20925617045258, 10.0, 20.48417504966423, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.21794871794871795, 0.83, 0.8022727272727272, 0.6944444444444444, 0.0, 0.0, 0.3416666666666667, 0.34209256170452584, 0.0, 0.5242087524832115, 0.575, 0.0, 0.0], 
reward next is -0.2540. 
=============================================
[2017-11-01 09:43:33,337] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6000, global step 95885: loss 0.8080
[2017-11-01 09:43:34,142] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95964: loss 10.4615
[2017-11-01 09:43:34,250] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95974: loss 14.9680
[2017-11-01 09:43:36,813] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96241: loss 105.4055
[2017-11-01 09:43:37,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96333: loss -64.9404
[2017-11-01 09:43:38,007] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96374: loss 58.9241
[2017-11-01 09:43:39,454] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6000, global step 96558: loss -0.3361
[2017-11-01 09:43:39,904] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6000, global step 96612: loss -7.0886
[2017-11-01 09:43:41,636] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6000, global step 96851: loss -7.1990
[2017-11-01 09:43:43,857] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 97184: loss -4.5329
[2017-11-01 09:43:47,889] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.38863416e-02   2.55109044e-03   8.88159692e-01   7.13440925e-02
   1.40587781e-02   1.84096962e-32   4.75230326e-33   1.13915266e-33
   1.45494962e-32], sum to 1.0000
[2017-11-01 09:43:47,996] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.183333333333334, 86.66666666666667, 9.2, 240.8333333333333, 0.0, 0.0, -1.166666666666667, 25.26892050531218, 29.0, 20.04646665761367, 21.5, 0.0, 49.65568546384038], 
actual action is [-1.1833333333333336, 28.5], 
sim time next is 1825200.0000, 
raw observation next is [-6.2, 87.0, 9.2, 240.0, 0.0, 0.0, -1.183333333333334, 25.12133164074462, 28.5, 20.06886908206959, 21.5, 0.0, 49.64285705611846], 
processed observation next is [1.0, 0.13043478260869565, 0.17435897435897435, 0.87, 0.8363636363636363, 0.6666666666666666, 0.0, 0.0, 0.48027777777777775, 0.2512133164074462, 0.925, 0.5034434541034795, 0.575, 0.0, 0.584033612424923], 
reward next is -0.6498. 
=============================================
[2017-11-01 09:43:49,558] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-55.70341873]
 [-56.24822617]
 [-55.41135788]
 [-55.84284592]
 [-55.84433365]], R is [[-54.72054672]
 [-54.78826523]
 [-54.8536377 ]
 [-54.91665649]
 [-54.97737503]].
[2017-11-01 09:43:55,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.38990597e-02   2.25775875e-03   8.63344848e-01   9.55230594e-02
   1.49752870e-02   8.67517983e-38   0.00000000e+00   0.00000000e+00
   1.55461467e-38], sum to 1.0000
[2017-11-01 09:43:55,868] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 78.0, 8.2, 240.0, 134.0, 72.5, -0.6916666666666664, 29.39327114611581, 19.0, 19.32196846764108, 22.7, 1.0, 48.60530226579529], 
actual action is [-0.5999999999999996, 14.0], 
sim time next is 1850700.0000, 
raw observation next is [-5.6, 77.75, 8.2, 240.8333333333333, 131.6666666666667, 68.91666666666667, -0.5999999999999996, 28.96731476320938, 14.0, 19.57661490776369, 22.7, 1.0, 40.55311410353145], 
processed observation next is [1.0, 0.43478260869565216, 0.18974358974358976, 0.7775, 0.7454545454545454, 0.6689814814814814, 0.3483245149911818, 0.06891666666666667, 0.49, 0.2896731476320938, 0.2, 0.47883074538818454, 0.635, 1.0, 0.47709546004154646], 
reward next is -0.3834. 
=============================================
[2017-11-01 09:44:00,156] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   1.17603835e-19   5.83386746e-18   1.75624775e-18
   1.51070839e-19   1.90506056e-01   2.46150568e-02   1.08094560e-02
   7.74069428e-01], sum to 1.0000
[2017-11-01 09:44:00,244] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 80.33333333333334, 6.100000000000001, 240.0, 91.0, 14.0, 0.5, 32.36606715994551, 12.5, 20.4109429226801, 22.7, 1.0, 15.54397585878569], 
actual action is [0.5, 17.5], 
sim time next is 1869900.0000, 
raw observation next is [-4.5, 79.66666666666666, 6.1, 240.0, 81.5, 7.000000000000004, 0.5, 33.39013457902048, 17.5, 20.29917189736057, 22.7, 1.0, 14.85045029022323], 
processed observation next is [1.0, 0.6521739130434783, 0.21794871794871795, 0.7966666666666665, 0.5545454545454546, 0.6666666666666666, 0.2156084656084656, 0.0070000000000000045, 0.5083333333333333, 0.3339013457902048, 0.375, 0.5149585948680284, 0.635, 1.0, 0.1747111798849792], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:44:10,953] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.54318342e-02   3.17772143e-02   4.87241775e-01   4.35190737e-01
   2.03584917e-02   1.08615998e-30   1.87998974e-31   1.02459990e-31
   1.75704977e-30], sum to 1.0000
[2017-11-01 09:44:11,005] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 71.0, 7.783333333333333, 240.0, 175.3333333333333, 54.66666666666666, 0.5, 27.91136354702455, 16.0, 20.84351838684287, 22.7, 1.0, 18.41246372368528], 
actual action is [0.5, 15.5], 
sim time next is 1864500.0000, 
raw observation next is [-4.5, 71.0, 7.741666666666667, 240.0, 176.6666666666667, 58.33333333333334, 0.5, 28.74257841463452, 15.5, 20.74339034595526, 22.7, 1.0, 17.1430379432535], 
processed observation next is [1.0, 0.5652173913043478, 0.21794871794871795, 0.71, 0.7037878787878789, 0.6666666666666666, 0.46737213403880085, 0.05833333333333334, 0.5083333333333333, 0.2874257841463452, 0.275, 0.537169517297763, 0.635, 1.0, 0.2016827993323941], 
reward next is -0.2446. 
=============================================
[2017-11-01 09:44:18,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.83669604e-14   7.47157857e-02   3.38448733e-01   5.38714528e-01
   2.62461249e-02   7.52147660e-03   2.83434335e-03   1.76440109e-03
   9.75462701e-03], sum to 1.0000
[2017-11-01 09:44:18,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-7.425, 75.75, 5.6, 255.0, 0.0, 0.0, -2.383333333333333, 18.22623135456168, 27.5, 21.14684421624729, 21.5, 0.0, 47.72830813319111], 
actual action is [-2.425, 26.5], 
sim time next is 1905600.0000, 
raw observation next is [-7.466666666666667, 76.0, 5.433333333333334, 253.3333333333333, 0.0, 0.0, -2.425, 18.19589939518845, 26.5, 21.14445079623408, 21.5, 0.0, 47.59913201911935], 
processed observation next is [0.0, 0.043478260869565216, 0.14188034188034188, 0.76, 0.49393939393939396, 0.7037037037037036, 0.0, 0.0, 0.45958333333333334, 0.18195899395188453, 0.825, 0.5572225398117039, 0.575, 0.0, 0.5599897884602276], 
reward next is -0.3689. 
=============================================
[2017-11-01 09:44:36,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   7.03683097e-24   8.37709760e-23   1.10677488e-22
   1.87198645e-24   1.18629970e-01   2.24530809e-02   2.50428710e-02
   8.33874047e-01], sum to 1.0000
[2017-11-01 09:44:36,906] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.5, 73.33333333333333, 5.183333333333334, 220.0, 211.6666666666667, 85.33333333333331, -0.5499999999999998, 31.24909143203966, 20.0, 20.0830992683802, 22.7, 1.0, 9.625504372698359], 
actual action is [-0.5, 25.0], 
sim time next is 1941300.0000, 
raw observation next is [-5.449999999999999, 72.5, 5.225, 220.0, 216.75, 66.5, -0.5, 31.3694282282112, 25.0, 20.08347599909459, 22.7, 1.0, 7.455301044226911], 
processed observation next is [0.0, 0.4782608695652174, 0.1935897435897436, 0.725, 0.475, 0.6111111111111112, 0.5734126984126984, 0.0665, 0.49166666666666664, 0.313694282282112, 0.75, 0.5041737999547294, 0.635, 1.0, 0.08770942404972837], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:44:39,079] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 102918: loss 12.1061
[2017-11-01 09:44:39,664] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.02444524e-02   2.09191386e-02   5.12626529e-01   4.47052568e-01
   9.15732048e-03   1.04202008e-24   1.84090319e-25   1.19177272e-25
   1.56206292e-24], sum to 1.0000
[2017-11-01 09:44:39,801] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.15, 67.5, 5.475, 220.0, 230.75, 8.5, -0.1999999999999993, 30.37570856326585, 15.0, 20.264437223706, 22.7, 1.0, 20.40098052400496], 
actual action is [-0.15000000000000036, 14.5], 
sim time next is 1943400.0000, 
raw observation next is [-5.1, 66.66666666666667, 5.516666666666667, 220.0, 230.3333333333333, 8.0, -0.1500000000000004, 30.37800350345619, 14.5, 20.2504233039581, 22.7, 1.0, 11.10909494592396], 
processed observation next is [0.0, 0.4782608695652174, 0.20256410256410257, 0.6666666666666667, 0.5015151515151515, 0.6111111111111112, 0.6093474426807759, 0.008, 0.49749999999999994, 0.30378003503456186, 0.225, 0.512521165197905, 0.635, 1.0, 0.13069523465792895], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:44:41,757] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103214: loss -3.4791
[2017-11-01 09:44:42,095] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6500, global step 103255: loss -14.5393
[2017-11-01 09:44:42,919] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-41.44003296]
 [-40.51462555]
 [-38.83987808]
 [-40.83492279]
 [-40.35590744]], R is [[-40.91769028]
 [-40.64312744]
 [-40.36878586]
 [-40.09453964]
 [-39.82060623]].
[2017-11-01 09:44:44,145] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103436: loss 0.2626
[2017-11-01 09:44:45,769] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103603: loss 51.8513
[2017-11-01 09:44:45,855] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103614: loss -103.2825
[2017-11-01 09:44:46,631] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103700: loss -18.4459
[2017-11-01 09:44:48,099] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103846: loss 9.3414
[2017-11-01 09:44:50,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-34.52029037]
 [-33.89304352]
 [-33.86364365]
 [-33.49668884]
 [-33.44476318]], R is [[-34.14004135]
 [-33.919384  ]
 [-33.8753624 ]
 [-33.84091949]
 [-33.81721115]].
[2017-11-01 09:44:51,056] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104142: loss 27.8739
[2017-11-01 09:44:51,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104181: loss 4.8899
[2017-11-01 09:44:51,558] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104203: loss -0.9241
[2017-11-01 09:44:52,833] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6500, global step 104361: loss 0.7301
[2017-11-01 09:44:54,594] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-43.06161499]
 [-46.82153702]
 [-45.71167755]
 [-47.69168091]
 [-48.29067612]], R is [[-43.04476929]
 [-43.61432266]
 [-44.17818069]
 [-44.7364006 ]
 [-45.2890358 ]].
[2017-11-01 09:44:57,061] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6500, global step 104738: loss 1.4433
[2017-11-01 09:44:57,197] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6500, global step 104751: loss -95.5651
[2017-11-01 09:44:57,714] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6500, global step 104795: loss 1.6492
[2017-11-01 09:45:03,649] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 105323: loss -32.4359
[2017-11-01 09:45:25,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.94188213e-03   6.34555425e-03   5.25916994e-01   3.37728322e-01
   1.22067250e-01   1.73072522e-34   8.46766394e-36   6.04141749e-36
   1.51140931e-34], sum to 1.0000
[2017-11-01 09:45:25,644] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.833333333333333, 84.75, 5.308333333333333, 240.0, 65.66666666666667, 0.0, -10.86666666666667, 32.35999029137631, 10.0, 20.03656096178847, 22.7, 1.0, 0.0], 
actual action is [-10.833333333333332, 10], 
sim time next is 2021400.0000, 
raw observation next is [-5.8, 84.5, 5.35, 240.0, 69.0, 0.0, -10.83333333333333, 33.35808215362187, 10.0, 19.95036963130905, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.18461538461538463, 0.845, 0.48636363636363633, 0.6666666666666666, 0.18253968253968253, 0.0, 0.31944444444444453, 0.3335808215362187, 0.0, 0.4975184815654526, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:45:28,014] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-53.13105011]
 [-52.57101059]
 [-52.1079483 ]
 [-52.05755615]
 [-52.88191223]], R is [[-52.76248932]
 [-52.69852448]
 [-52.62543488]
 [-52.58658218]
 [-52.55028915]].
[2017-11-01 09:45:34,841] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.08483339e-24   9.02700594e-06   1.94763197e-04   2.27819401e-04
   6.52136077e-05   1.51995316e-01   1.99764259e-02   1.70346759e-02
   8.10496747e-01], sum to 1.0000
[2017-11-01 09:45:34,940] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 87.0, 2.958333333333333, 260.0, 0.0, 0.0, -1.2, 24.65759160064972, 26.0, 20.07316254716766, 21.5, 0.0, 48.70137572898349], 
actual action is [-1.2000000000000002, 30], 
sim time next is 2008800.0000, 
raw observation next is [-6.2, 87.0, 3.0, 260.0, 0.0, 0.0, -1.2, 24.21268540636872, 30.0, 20.08703074505633, 21.5, 0.0, 47.3218739444563], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.17435897435897435, 0.87, 0.2727272727272727, 0.7222222222222222, 0.0, 0.0, 0.48000000000000004, 0.2421268540636872, 1.0, 0.5043515372528166, 0.575, 0.0, 0.5567279287583095], 
reward next is -0.6316. 
=============================================
[2017-11-01 09:45:51,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.61367748e-02   1.01268023e-01   2.48796552e-01   3.71577889e-01
   2.62220770e-01   2.08016589e-19   1.45241623e-20   8.15403225e-21
   1.61003501e-20], sum to 1.0000
[2017-11-01 09:45:52,495] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-3.9, 85.0, 4.225, 265.0, 0.0, 0.0, 1.100000000000001, 17.01212083282409, 26.0, 21.44527465246412, 22.7, 1.0, 63.84001604210888], 
actual action is [1.1, 26.0], 
sim time next is 2058600.0000, 
raw observation next is [-3.9, 85.33333333333334, 4.183333333333333, 266.6666666666666, 0.0, 0.0, 1.1, 16.55814538312804, 26.0, 21.56555157923284, 22.7, 1.0, 63.20931361719056], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.23333333333333334, 0.8533333333333334, 0.38030303030303025, 0.7407407407407405, 0.0, 0.0, 0.5183333333333333, 0.1655814538312804, 0.8, 0.5782775789616419, 0.635, 1.0, 0.7436389837316536], 
reward next is -0.4546. 
=============================================
[2017-11-01 09:45:59,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.23606361e-01   1.21623196e-01   3.00167173e-01   2.86080837e-01
   1.68522462e-01   1.75247220e-21   4.63694901e-23   7.63524334e-23
   5.06402095e-23], sum to 1.0000
[2017-11-01 09:45:59,693] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-3.899999999999999, 83.33333333333334, 3.6, 260.0, 0.0, 0.0, 1.100000000000001, 14.68424564292769, 25.5, 21.90927053543784, 21.5, 0.0, 45.01615737523029], 
actual action is [1.100000000000001, 25.5], 
sim time next is 2065500.0000, 
raw observation next is [-3.9, 83.0, 3.6, 260.0, 0.0, 0.0, 1.100000000000001, 14.48065565638679, 25.5, 21.95376000979275, 21.5, 0.0, 44.97123157269852], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.23333333333333334, 0.83, 0.32727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5183333333333333, 0.1448065565638679, 0.775, 0.5976880004896374, 0.575, 0.0, 0.5290733126199826], 
reward next is -0.2645. 
=============================================
[2017-11-01 09:46:02,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  8.10358822e-02   6.83244914e-02   4.53266472e-01   1.76771924e-01
   2.20601276e-01   1.38819261e-23   4.94690039e-25   7.70270264e-25
   9.42057101e-25], sum to 1.0000
[2017-11-01 09:46:02,907] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 89.33333333333334, 5.1, 263.3333333333334, 0.0, 0.0, 0.5, 18.61440442001171, 25.5, 21.14913870698804, 21.5, 0.0, 46.96452705830921], 
actual action is [0.5, 24.5], 
sim time next is 2078700.0000, 
raw observation next is [-4.5, 88.91666666666666, 5.1, 264.1666666666666, 0.0, 0.0, 0.5, 18.37066572293557, 24.5, 21.17905574126151, 21.5, 0.0, 47.05187524823451], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.21794871794871795, 0.8891666666666665, 0.4636363636363636, 0.7337962962962961, 0.0, 0.0, 0.5083333333333333, 0.1837066572293557, 0.725, 0.5589527870630755, 0.575, 0.0, 0.5535514735086413], 
reward next is -0.3570. 
=============================================
[2017-11-01 09:46:04,227] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 110779: loss -5.4397
[2017-11-01 09:46:04,464] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 110799: loss 51.2659
[2017-11-01 09:46:05,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   4.07035793e-17   7.16903408e-17   1.60485440e-16
   7.60512568e-17   6.71339810e-01   3.94770019e-02   9.53325406e-02
   1.93850622e-01], sum to 1.0000
[2017-11-01 09:46:05,741] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.0, 78.5, 2.5, 235.0, 0.0, 0.0, -1.949999999999999, 18.04103240258079, 21.0, 21.01290330157536, 22.7, 1.0, 52.09656031559182], 
actual action is [-2.0, 21.5], 
sim time next is 2100900.0000, 
raw observation next is [-7.050000000000001, 78.58333333333334, 2.416666666666667, 234.1666666666667, 0.0, 0.0, -2.0, 18.44852736401499, 21.5, 21.0530485697875, 22.7, 1.0, 44.65009201341925], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.15256410256410255, 0.7858333333333334, 0.21969696969696972, 0.6504629629629631, 0.0, 0.0, 0.4666666666666667, 0.18448527364014988, 0.575, 0.552652428489375, 0.635, 1.0, 0.5252952001578735], 
reward next is -0.3549. 
=============================================
[2017-11-01 09:46:06,633] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7000, global step 110957: loss 14.3732
[2017-11-01 09:46:10,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-45.78805923]
 [-44.73977661]
 [-47.88110733]
 [-48.116436  ]
 [-43.34280014]], R is [[-42.46062851]
 [-43.03602219]
 [-43.6056633 ]
 [-44.16960526]
 [-44.72790909]].
[2017-11-01 09:46:12,441] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111545: loss 2.8002
[2017-11-01 09:46:14,557] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111737: loss -81.0939
[2017-11-01 09:46:14,585] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111738: loss 131.2468
[2017-11-01 09:46:15,081] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111791: loss 65.2996
[2017-11-01 09:46:15,405] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111825: loss 111.2077
[2017-11-01 09:46:16,562] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111940: loss 176.8127
[2017-11-01 09:46:16,755] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.45030776e-02   2.75623500e-02   5.56042790e-01   2.89035141e-01
   1.12856679e-01   3.95752162e-38   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-01 09:46:16,834] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.35, 88.91666666666666, 5.725, 248.3333333333333, 0.0, 0.0, -0.2999999999999998, 39.89734057707779, 15.5, 18.79025272737093, 21.5, 0.0, 15.62939300412628], 
actual action is [-0.34999999999999964, 14.5], 
sim time next is 2086800.0000, 
raw observation next is [-5.4, 89.33333333333334, 5.6, 246.6666666666667, 0.0, 0.0, -0.3499999999999996, 40.8624202517345, 14.5, 18.68862470446161, 21.5, 0.0, 14.96595415348876], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.19487179487179487, 0.8933333333333334, 0.509090909090909, 0.6851851851851853, 0.0, 0.0, 0.4941666666666667, 0.408624202517345, 0.225, 0.43443123522308047, 0.575, 0.0, 0.17607004886457364], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:17,841] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-76.33258057]
 [-76.98171997]
 [-77.40023041]
 [-76.65438843]
 [-76.24025726]], R is [[-78.4238739 ]
 [-78.63963318]
 [-78.85324097]
 [-79.06471252]
 [-79.27406311]].
[2017-11-01 09:46:17,882] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112103: loss 66.0716
[2017-11-01 09:46:19,143] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.06364402  0.02935077  0.2374642   0.5617404   0.10780057  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:46:19,204] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.716666666666667, 81.5, 2.416666666666667, 230.0, 106.0, 63.99999999999999, -2.675, 29.13189749495105, 11.0, 19.93469170469831, 22.7, 1.0, 28.93679769671001], 
actual action is [-2.716666666666667, 10.5], 
sim time next is 2105700.0000, 
raw observation next is [-7.758333333333333, 81.75, 2.458333333333333, 230.0, 114.5, 70.75, -2.716666666666667, 29.16822031535927, 10.5, 19.95873748323441, 22.7, 1.0, 26.41861270512107], 
processed observation next is [0.3333333333333333, 0.34782608695652173, 0.13440170940170942, 0.8175, 0.22348484848484845, 0.6388888888888888, 0.3029100529100529, 0.07075, 0.4547222222222222, 0.2916822031535927, 0.025, 0.4979368741617206, 0.635, 1.0, 0.310807208295542], 
reward next is -0.3012. 
=============================================
[2017-11-01 09:46:19,412] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112325: loss -211.5849
[2017-11-01 09:46:20,269] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.03039591  0.01352768  0.32341358  0.5913012   0.04136158  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:46:20,395] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 65.5, 5.016666666666667, 278.3333333333334, 46.0, 0.0, 0.5, 44.262641380392, 10.5, 18.89786705578905, 22.7, 1.0, 3.911618098470391], 
actual action is [-9.5, 10], 
sim time next is 2132100.0000, 
raw observation next is [-4.5, 65.75, 4.975, 277.5, 41.0, 0.0, -9.5, 44.92432178565777, 10.0, 18.80043120544951, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.21794871794871795, 0.6575, 0.4522727272727272, 0.7708333333333334, 0.10846560846560846, 0.0, 0.3416666666666667, 0.44924321785657767, 0.0, 0.44002156027247546, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:20,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-106.87413788]
 [-109.71311188]
 [-104.51313019]
 [-102.95413208]
 [-102.61669159]], R is [[-104.46477509]
 [-104.42012787]
 [-104.37593079]
 [-104.33217621]
 [-104.28885651]].
[2017-11-01 09:46:21,737] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7000, global step 112675: loss 1108.8850
[2017-11-01 09:46:22,373] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   7.12427823e-03   2.82252617e-02   3.20038080e-01
   4.13088500e-02   5.80717981e-01   3.21707012e-05   2.11940054e-02
   1.35936041e-03], sum to 1.0000
[2017-11-01 09:46:22,422] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 73.0, 2.333333333333333, 256.6666666666666, 0.0, 0.0, 0.0, 59.55167137732788, 11.0, 17.16178907677355, 22.7, 1.0, 3.553813122998455], 
actual action is [0.0, 13.0], 
sim time next is 2141100.0000, 
raw observation next is [-5.0, 73.25, 2.375, 257.5, 0.0, 0.0, 0.0, 59.977593804019, 13.0, 17.11179423233951, 22.7, 1.0, 3.1776447296405], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.20512820512820512, 0.7325, 0.2159090909090909, 0.7152777777777778, 0.0, 0.0, 0.5, 0.59977593804019, 0.15, 0.35558971161697545, 0.635, 1.0, 0.037384055642829414], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:22,502] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.02051599  0.03384167  0.2946403   0.59974808  0.05125396  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:46:22,541] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.2, 64.0, 3.0, 250.0, 150.0, 67.0, -1.241666666666667, 50.05472485726902, 11.5, 17.95650730766049, 22.7, 1.0, 2.662128896491474], 
actual action is [-1.2000000000000002, 11.0], 
sim time next is 2120700.0000, 
raw observation next is [-6.15, 64.33333333333333, 3.133333333333333, 250.0, 149.8333333333333, 55.83333333333333, -1.2, 50.20210460832556, 11.0, 17.90900286534658, 22.7, 1.0, 2.607905945472103], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.17564102564102563, 0.6433333333333333, 0.2848484848484848, 0.6944444444444444, 0.39638447971781293, 0.05583333333333333, 0.48000000000000004, 0.5020210460832556, 0.05, 0.39545014326732897, 0.635, 1.0, 0.03068124641731886], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:22,948] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7000, global step 112854: loss 716.5530
[2017-11-01 09:46:23,249] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7000, global step 112913: loss -82.1420
[2017-11-01 09:46:24,129] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7000, global step 113091: loss -34.0748
[2017-11-01 09:46:28,112] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 113560: loss 80.0273
[2017-11-01 09:46:30,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.29018037e-04   1.07870288e-02   1.20849155e-01   8.45903218e-01
   2.23316625e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-01 09:46:30,991] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.583333333333333, 65.5, 5.1, 278.3333333333333, 66.0, 0.0, 0.375, 52.8723419300632, 15.5, 17.9822168677105, 22.7, 1.0, 12.45890247718896], 
actual action is [0.41666666666666696, 15.5], 
sim time next is 2130900.0000, 
raw observation next is [-4.541666666666667, 65.25, 5.1, 279.1666666666666, 61.0, 0.0, 0.416666666666667, 53.25074069331743, 15.5, 17.97207926270501, 22.7, 1.0, 11.68096737408942], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.21688034188034186, 0.6525, 0.4636363636363636, 0.7754629629629627, 0.16137566137566137, 0.0, 0.5069444444444444, 0.5325074069331743, 0.275, 0.3986039631352504, 0.635, 1.0, 0.13742314557752258], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:40,968] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99286711e-01   4.33734704e-06   4.43881989e-04
   2.65183480e-04], sum to 1.0000
[2017-11-01 09:46:41,020] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 78.0, 3.0, 255.8333333333333, 0.0, 0.0, -1.7, 60.52414478004121, 17.0, 17.15875775704831, 21.5, 0.0, 15.89571963397746], 
actual action is [-1.7000000000000002, 17.5], 
sim time next is 2173200.0000, 
raw observation next is [-6.700000000000001, 78.0, 3.0, 256.6666666666666, 0.0, 0.0, -1.7, 61.44634173515315, 17.5, 17.07527311490617, 21.5, 0.0, 15.2958467383235], 
processed observation next is [0.5, 0.13043478260869565, 0.16153846153846152, 0.78, 0.2727272727272727, 0.7129629629629627, 0.0, 0.0, 0.4716666666666667, 0.6144634173515314, 0.375, 0.35376365574530855, 0.575, 0.0, 0.1799511380979235], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:46:52,988] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-121.25801849]
 [-118.41947174]
 [-115.57909393]
 [-118.1414032 ]
 [-114.22893524]], R is [[-115.95993042]
 [-115.80033112]
 [-115.64232635]
 [-115.48590088]
 [-115.33103943]].
[2017-11-01 09:47:01,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.08478607  0.00141092  0.00954006  0.88305992  0.02120305  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:47:02,049] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 71.0, 5.6, 260.0, 19.0, 0.0, 0.5499999999999998, 64.89782310044414, 15.0, 17.20990886962281, 22.7, 1.0, 3.739335920308431], 
actual action is [0.5, 14.5], 
sim time next is 2221500.0000, 
raw observation next is [-4.5, 70.75, 5.641666666666666, 261.6666666666666, 16.33333333333333, 0.0, 0.5, 66.30414980018207, 14.5, 17.15787791325203, 22.7, 1.0, 3.690815327839388], 
processed observation next is [0.5, 0.7391304347826086, 0.21794871794871795, 0.7075, 0.5128787878787878, 0.7268518518518516, 0.04320987654320987, 0.0, 0.5083333333333333, 0.6630414980018208, 0.225, 0.3578938956626015, 0.635, 1.0, 0.04342135679811045], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:02,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-118.26950073]
 [-116.82267761]
 [-117.10585785]
 [-117.02944946]
 [-117.69285583]], R is [[-117.81269073]
 [-117.63456726]
 [-117.45822144]
 [-117.283638  ]
 [-117.1108017 ]].
[2017-11-01 09:47:07,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   4.56401283e-23   4.42482297e-24   2.91542170e-21
   1.56395571e-23   9.94854569e-01   2.56416213e-04   3.58231645e-03
   1.30672730e-03], sum to 1.0000
[2017-11-01 09:47:07,816] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-5.05, 71.33333333333333, 6.475, 252.5, 108.25, 263.0833333333334, -0.09999999999999964, 48.03732173474954, 15.0, 18.95246687315273, 22.7, 1.0, 9.522658630741233], 
actual action is [-0.04999999999999982, 15.5], 
sim time next is 2196000.0000, 
raw observation next is [-5.0, 71.0, 6.6, 250.0, 109.5, 225.5, -0.04999999999999982, 48.53536876769952, 15.5, 18.92295612215785, 22.7, 1.0, 9.316682913540667], 
processed observation next is [0.5, 0.43478260869565216, 0.20512820512820512, 0.71, 0.6, 0.6944444444444444, 0.2896825396825397, 0.2255, 0.49916666666666665, 0.48535368767699516, 0.275, 0.44614780610789245, 0.635, 1.0, 0.10960803427694903], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:13,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.71046448e-01   6.53611714e-05   2.47763610e-03
   2.64104586e-02], sum to 1.0000
[2017-11-01 09:47:13,647] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.241666666666667, 75.25, 4.725, 269.1666666666667, 0.0, 0.0, -1.2, 80.42557139445357, 10.5, 15.52263574080012, 21.5, 0.0, 8.74857824430841], 
actual action is [-1.2416666666666671, 11.0], 
sim time next is 2243400.0000, 
raw observation next is [-6.283333333333333, 75.5, 4.85, 268.3333333333333, 0.0, 0.0, -1.241666666666667, 80.75407579230016, 11.0, 15.47555335992498, 21.5, 0.0, 5.434174048180074], 
processed observation next is [0.5, 1.0, 0.17222222222222222, 0.755, 0.44090909090909086, 0.7453703703703703, 0.0, 0.0, 0.47930555555555554, 0.8075407579230016, 0.05, 0.27377766799624903, 0.575, 0.0, 0.06393145939035381], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:16,414] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 118757: loss 190.4772
[2017-11-01 09:47:16,753] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 118810: loss 187.0494
[2017-11-01 09:47:19,302] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119138: loss -196.1126
[2017-11-01 09:47:20,706] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7500, global step 119360: loss -57.6182
[2017-11-01 09:47:20,811] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119374: loss 46.7093
[2017-11-01 09:47:20,966] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119393: loss 41.6613
[2017-11-01 09:47:22,594] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119613: loss -24.7725
[2017-11-01 09:47:22,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119613: loss -42.3316
[2017-11-01 09:47:23,220] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119687: loss -117.1933
[2017-11-01 09:47:25,805] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119977: loss -82.6608
[2017-11-01 09:47:30,617] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120362: loss -55.3257
[2017-11-01 09:47:31,699] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7500, global step 120472: loss -95.8019
[2017-11-01 09:47:32,956] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-117.04240417]
 [-113.98685455]
 [-117.96583557]
 [-118.85102081]
 [-111.95368195]], R is [[-120.58880615]
 [-120.38291931]
 [-120.17909241]
 [-119.97730255]
 [-119.77752686]].
[2017-11-01 09:47:33,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.92784768
  0.00130981  0.0113385   0.05950388], sum to 1.0000
[2017-11-01 09:47:33,599] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.041666666666666, 89.33333333333333, 3.641666666666666, 274.1666666666666, 41.5, 16.33333333333333, -4.133333333333333, 64.20444903605497, 14.0, 17.56559509226793, 22.7, 1.0, 29.94111132339884], 
actual action is [-4.041666666666666, 14.5], 
sim time next is 2277000.0000, 
raw observation next is [-8.95, 89.0, 3.55, 275.0, 45.0, 16.0, -4.041666666666666, 64.7319207665243, 14.5, 17.52574998589803, 22.7, 1.0, 27.72625347730603], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.10384615384615387, 0.89, 0.3227272727272727, 0.7638888888888888, 0.11904761904761904, 0.016, 0.4326388888888889, 0.647319207665243, 0.225, 0.3762874992949016, 0.635, 1.0, 0.32619121738007095], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:36,009] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7500, global step 120959: loss 2.7109
[2017-11-01 09:47:36,221] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   3.51045179e-34   8.63400233e-34   2.89261794e-31
   8.30273241e-34   9.92174387e-01   4.74329485e-04   4.58866882e-04
   6.89237984e-03], sum to 1.0000
[2017-11-01 09:47:36,355] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.96195555e-01   9.25262066e-06   4.31719091e-05
   3.75196058e-03], sum to 1.0000
[2017-11-01 09:47:36,376] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.583333333333334, 87.66666666666666, 3.183333333333333, 278.3333333333333, 63.66666666666666, 23.66666666666666, -3.675000000000001, 83.71491465830204, 13.5, 14.87248612859792, 22.7, 1.0, 8.810885202457055], 
actual action is [-3.583333333333334, 14.0], 
sim time next is 2278500.0000, 
raw observation next is [-8.491666666666667, 87.33333333333334, 3.091666666666667, 279.1666666666666, 68.33333333333333, 25.58333333333334, -3.583333333333334, 83.89985617055505, 14.0, 14.85307243616179, 22.7, 1.0, 8.378307501956188], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.11559829059829059, 0.8733333333333334, 0.28106060606060607, 0.7754629629629627, 0.18077601410934743, 0.02558333333333334, 0.4402777777777777, 0.8389985617055505, 0.2, 0.24265362180808953, 0.635, 1.0, 0.09856832355242574], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:36,419] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.25, 86.75, 3.6, 255.0, 0.0, 0.0, -3.199999999999999, 87.44233404382776, 15.5, 14.44340987667969, 21.5, 0.0, 10.74421649710695], 
actual action is [-3.25, 16.0], 
sim time next is 2260200.0000, 
raw observation next is [-8.3, 86.83333333333333, 3.6, 256.6666666666667, 0.0, 0.0, -3.25, 86.6765521686931, 16.0, 14.36478651105041, 21.5, 0.0, 41.42263360273896], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.1205128205128205, 0.8683333333333333, 0.32727272727272727, 0.712962962962963, 0.0, 0.0, 0.44583333333333336, 0.8667655216869311, 0.3, 0.21823932555252049, 0.575, 0.0, 0.48732510120869366], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:36,650] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7500, global step 121027: loss 70.1285
[2017-11-01 09:47:36,669] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   1.68310123e-20   3.81498380e-20   5.27074606e-18
   2.04463263e-20   9.91313040e-01   9.70340916e-04   1.19908899e-03
   6.51752157e-03], sum to 1.0000
[2017-11-01 09:47:36,712] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.7, 75.0, 4.1, 270.0, 0.0, 0.0, -1.7, 84.79653050629959, 14.0, 15.00235916152119, 21.5, 0.0, 3.863861980019305], 
actual action is [-1.7000000000000002, 14.5], 
sim time next is 2250300.0000, 
raw observation next is [-6.75, 75.58333333333333, 4.141666666666666, 269.1666666666667, 0.0, 0.0, -1.7, 85.06044239924177, 14.5, 14.96655056198131, 21.5, 0.0, 3.782873395561524], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.16025641025641027, 0.7558333333333332, 0.3765151515151514, 0.7476851851851852, 0.0, 0.0, 0.4716666666666667, 0.8506044239924176, 0.225, 0.24832752809906547, 0.575, 0.0, 0.044504392888959105], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:36,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.23052196  0.02332472  0.251838    0.48646858  0.00784673  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:47:36,956] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-7.975000000000001, 84.75, 2.875, 267.5, 87.0, 33.25, -3.116666666666667, 37.02519009359782, 16.0, 20.07981301516879, 22.7, 1.0, 63.88351729790856], 
actual action is [-2.9750000000000014, 15.5], 
sim time next is 2280000.0000, 
raw observation next is [-7.833333333333334, 84.0, 2.833333333333333, 263.3333333333334, 91.66666666666667, 35.16666666666666, -2.975000000000001, 36.41782387430624, 15.5, 20.25664334141506, 22.7, 1.0, 54.5149413255348], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.13247863247863245, 0.84, 0.25757575757575757, 0.7314814814814817, 0.24250440917107585, 0.03516666666666666, 0.45041666666666663, 0.3641782387430624, 0.275, 0.512832167070753, 0.635, 1.0, 0.6413522508886447], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:38,550] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7500, global step 121246: loss 7.5846
[2017-11-01 09:47:38,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 121271: loss 8.5051
[2017-11-01 09:47:45,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.69514966e-12   1.37169674e-01   1.07685424e-01   6.50338531e-01
   1.04806378e-01   1.90252236e-33   4.06942656e-35   2.78138207e-35
   1.78443228e-35], sum to 1.0000
[2017-11-01 09:47:45,722] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-0.6, 49.0, 2.5, 230.0, 23.0, 0.0, 4.45, 65.0281891298679, 10.5, 17.60120441166572, 22.7, 1.0, 19.29501060640032], 
actual action is [-5.6, 10], 
sim time next is 2307900.0000, 
raw observation next is [-0.6499999999999999, 49.25, 2.458333333333333, 229.1666666666667, 20.0, 0.0, -5.6, 66.6389350577483, 10.0, 17.57085421200757, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.31666666666666665, 0.4925, 0.22348484848484845, 0.6365740740740742, 0.05291005291005291, 0.0, 0.4066666666666666, 0.6663893505774829, 0.0, 0.3785427106003786, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:47:49,096] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.03738457  0.04171823  0.6743263   0.1892067   0.05736416  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 09:47:49,513] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.5, 91.0, 4.1, 270.0, 24.0, 18.0, -4.5, 61.32621421963187, 18.5, 17.89487054608546, 22.7, 1.0, 42.96190632938944], 
actual action is [-4.5, 17.5], 
sim time next is 2275500.0000, 
raw observation next is [-9.408333333333331, 90.66666666666666, 4.008333333333333, 270.8333333333333, 27.5, 17.66666666666666, -4.5, 61.6089376100842, 17.5, 17.85590423669772, 22.7, 1.0, 40.58869785987455], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.09209401709401714, 0.9066666666666666, 0.3643939393939393, 0.7523148148148148, 0.07275132275132275, 0.01766666666666666, 0.425, 0.616089376100842, 0.375, 0.3927952118348861, 0.635, 1.0, 0.47751409246911236], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:48:23,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.17442077e-02   8.44997689e-02   7.64951766e-01   1.24236360e-01
   1.45678092e-02   2.33598117e-31   4.14393967e-32   6.35084509e-32
   2.31998856e-30], sum to 1.0000
[2017-11-01 09:48:24,169] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.4, 69.0, 5.6, 66.66666666666667, 51.0, 59.99999999999999, 1.6, 30.6249552866024, 30.0, 19.44274947433304, 22.7, 1.0, 69.7957993344831], 
actual action is [1.6, 29.0], 
sim time next is 2364300.0000, 
raw observation next is [-3.4, 69.0, 5.6, 67.5, 58.0, 90.0, 1.6, 28.79813287520412, 29.0, 19.76737648861558, 22.7, 1.0, 67.31641882720801], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.24615384615384614, 0.69, 0.509090909090909, 0.1875, 0.15343915343915343, 0.09, 0.5266666666666667, 0.2879813287520412, 0.95, 0.48836882443077895, 0.635, 1.0, 0.7919578685553884], 
reward next is -0.5400. 
=============================================
[2017-11-01 09:48:26,910] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  4.14326824e-02   1.36163831e-01   6.27122283e-01   1.56819299e-01
   3.84619012e-02   2.21270199e-26   5.90527561e-27   7.34811299e-27
   5.23352326e-26], sum to 1.0000
[2017-11-01 09:48:27,124] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.9, 57.0, 0.6666666666666666, 120.0, 0.0, 0.0, 3.15, 23.77928109079543, 23.5, 21.28021279624519, 21.5, 0.0, 42.84572270333857], 
actual action is [3.1, 22.5], 
sim time next is 2327100.0000, 
raw observation next is [-1.95, 57.25, 0.8333333333333334, 150.0, 0.0, 0.0, 3.1, 23.58085008774919, 22.5, 21.31776524172282, 21.5, 0.0, 42.83499202221995], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2833333333333333, 0.5725, 0.07575757575757576, 0.4166666666666667, 0.0, 0.0, 0.5516666666666666, 0.23580850087749192, 0.625, 0.5658882620861411, 0.575, 0.0, 0.5039410826143523], 
reward next is -0.2975. 
=============================================
[2017-11-01 09:48:34,001] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   2.31091179e-37   1.53812618e-36   3.71871232e-36
   9.97185547e-36   8.26227292e-03   2.23110197e-03   2.93935882e-03
   9.86567259e-01], sum to 1.0000
[2017-11-01 09:48:34,092] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.466666666666667, 63.0, 5.766666666666667, 50.0, 143.6666666666667, 426.0, -7.508333333333333, 38.78636558548268, 10.0, 19.4862778097602, 22.7, 1.0, 0.0], 
actual action is [2.533333333333333, 15.0], 
sim time next is 2371500.0000, 
raw observation next is [-2.425, 62.75, 5.85, 47.5, 146.0, 414.0, 2.533333333333333, 38.81972233377548, 15.0, 19.4258007283982, 22.7, 1.0, 19.40188618678897], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.27115384615384613, 0.6275, 0.5318181818181817, 0.13194444444444445, 0.3862433862433862, 0.414, 0.5422222222222222, 0.3881972233377548, 0.25, 0.4712900364199101, 0.635, 1.0, 0.2282574845504585], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:48:41,656] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 126671: loss 12.5576
[2017-11-01 09:48:42,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  6.55640736e-02   3.59810069e-02   2.93801934e-01   6.62438646e-02
   5.38409114e-01   7.62837905e-31   1.34714638e-31   2.25315583e-31
   3.71446164e-29], sum to 1.0000
[2017-11-01 09:48:42,743] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 47.0, 6.266666666666667, 80.0, 84.83333333333334, 293.8333333333334, 5.0, 23.12488468781118, 19.0, 21.66810067887732, 22.7, 1.0, 18.42511724595221], 
actual action is [5.0, 19.0], 
sim time next is 2389500.0000, 
raw observation next is [0.0, 47.0, 6.225, 80.0, 84.25, 270.25, 5.0, 23.73017158749453, 19.0, 21.59594479464163, 22.7, 1.0, 17.15598608570146], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.3333333333333333, 0.47, 0.5659090909090909, 0.2222222222222222, 0.22288359788359788, 0.27025, 0.5833333333333334, 0.2373017158749453, 0.45, 0.5797972397320814, 0.635, 1.0, 0.2018351304200172], 
reward next is -0.2196. 
=============================================
[2017-11-01 09:48:42,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.15908621e-25   2.78137813e-05   4.38561474e-05   5.90509262e-05
   3.49000271e-04   4.52259043e-03   1.28299498e-03   2.69611529e-03
   9.91018653e-01], sum to 1.0000
[2017-11-01 09:48:42,954] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-60.97490311]
 [-61.53090286]
 [-60.20711136]
 [-59.96653366]
 [-60.3621521 ]], R is [[-60.31562424]
 [-59.96542358]
 [-59.62549973]
 [-59.29706573]
 [-58.98145294]].
[2017-11-01 09:48:43,239] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.1, 67.0, 4.35, 70.0, 0.0, 0.0, 1.95, 24.85607190843162, 30.0, 20.4100288672806, 21.5, 0.0, 45.96136920941531], 
actual action is [1.9, 30], 
sim time next is 2356500.0000, 
raw observation next is [-3.15, 67.33333333333333, 4.391666666666666, 70.0, 0.0, 0.0, 1.9, 24.82260269985166, 30.0, 20.41010369071877, 21.5, 0.0, 45.99697121395067], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.25256410256410255, 0.6733333333333333, 0.3992424242424242, 0.19444444444444445, 0.0, 0.0, 0.5316666666666666, 0.24822602699851662, 1.0, 0.5205051845359385, 0.575, 0.0, 0.5411408378111844], 
reward next is -0.5430. 
=============================================
[2017-11-01 09:48:47,009] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127096: loss 69.6601
[2017-11-01 09:48:47,089] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127104: loss -6.2529
[2017-11-01 09:48:49,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127269: loss -2.5502
[2017-11-01 09:48:51,552] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8000, global step 127463: loss 6.3500
[2017-11-01 09:48:51,737] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127475: loss -0.8726
[2017-11-01 09:48:53,817] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127669: loss -15.8994
[2017-11-01 09:48:54,025] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127689: loss -1.1592
[2017-11-01 09:48:55,189] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127795: loss -0.5640
[2017-11-01 09:48:58,434] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128140: loss 5.8891
[2017-11-01 09:49:00,499] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.34680688e-01   7.47990934e-03   2.64384955e-01   9.59176719e-02
   4.97536749e-01   6.46275487e-35   1.90992685e-36   7.55990307e-36
   1.03271380e-34], sum to 1.0000
[2017-11-01 09:49:00,512] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-0.3, 53.0, 6.1, 75.0, 191.0, 0.0, -5.35, 27.49828288134229, 10.0, 20.96903458060317, 22.7, 1.0, 0.0], 
actual action is [-5.3, 10.0], 
sim time next is 2381700.0000, 
raw observation next is [-0.25, 52.83333333333333, 6.1, 75.83333333333334, 188.4166666666667, 0.0, -5.3, 28.98914981942164, 10.0, 20.8782053649752, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.3269230769230769, 0.5283333333333333, 0.5545454545454546, 0.21064814814814817, 0.4984567901234569, 0.0, 0.4116666666666667, 0.2898914981942164, 0.0, 0.5439102682487601, 0.635, 1.0, 0.0], 
reward next is -0.1449. 
=============================================
[2017-11-01 09:49:01,438] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8000, global step 128441: loss -0.2352
[2017-11-01 09:49:04,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128682: loss 31.8014
[2017-11-01 09:49:07,303] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.14438888e-02   1.35488492e-02   2.77859241e-01   4.53800410e-02
   5.71767986e-01   6.94660510e-25   6.58195464e-26   1.55331174e-25
   1.18838375e-24], sum to 1.0000
[2017-11-01 09:49:07,375] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.2, 48.0, 5.1, 70.0, 0.0, 0.0, -1.15, 22.39661938607731, 19.5, 21.08373327610416, 21.5, 0.0, 41.41343726652774], 
actual action is [-1.2000000000000002, 19.5], 
sim time next is 2423100.0000, 
raw observation next is [-6.291666666666667, 48.41666666666666, 5.016666666666667, 70.83333333333333, 0.0, 0.0, -1.2, 22.9503488487928, 19.5, 21.0562548618755, 21.5, 0.0, 35.71981626323812], 
processed observation next is [1.0, 0.043478260869565216, 0.172008547008547, 0.4841666666666666, 0.45606060606060606, 0.19675925925925924, 0.0, 0.0, 0.48000000000000004, 0.229503488487928, 0.475, 0.552812743093775, 0.575, 0.0, 0.42023313250868377], 
reward next is -0.3211. 
=============================================
[2017-11-01 09:49:10,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-46.05357361]
 [-46.03671646]
 [-45.64601517]
 [-45.80288315]
 [-45.71427536]], R is [[-45.75209045]
 [-45.81066895]
 [-45.86294937]
 [-45.90903854]
 [-45.94905853]].
[2017-11-01 09:49:11,111] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8000, global step 129206: loss -9.7011
[2017-11-01 09:49:12,087] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8000, global step 129277: loss 1.4195
[2017-11-01 09:49:15,094] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 129494: loss -1.4426
[2017-11-01 09:49:15,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.70885229e-02   4.63996036e-03   2.67181575e-01   2.30107866e-02
   6.78079069e-01   5.71837429e-29   5.39032583e-30   1.42141905e-29
   3.53483467e-29], sum to 1.0000
[2017-11-01 09:49:15,557] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-8.4, 61.0, 4.35, 77.5, 0.0, 0.0, -3.4, 30.28503993081513, 30.0, 19.61537234943927, 21.5, 0.0, 50.02826543361339], 
actual action is [-3.4000000000000004, 30.0], 
sim time next is 2434800.0000, 
raw observation next is [-8.4, 61.0, 4.266666666666667, 76.66666666666667, 0.0, 0.0, -3.4, 29.85326773372363, 30.0, 19.63797317488028, 21.5, 0.0, 48.72113442110354], 
processed observation next is [1.0, 0.17391304347826086, 0.11794871794871795, 0.61, 0.3878787878787879, 0.21296296296296297, 0.0, 0.0, 0.44333333333333336, 0.2985326773372363, 1.0, 0.481898658744014, 0.575, 0.0, 0.5731898167188652], 
reward next is -0.7521. 
=============================================
[2017-11-01 09:49:19,249] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8000, global step 129764: loss 1.0189
[2017-11-01 09:49:30,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.12324448e-02   3.69640789e-03   1.64798707e-01   3.87036242e-02
   7.71568894e-01   5.94914223e-29   4.27651510e-29   1.11491483e-29
   1.24559652e-28], sum to 1.0000
[2017-11-01 09:49:30,953] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.1333333333333333, 30.0, 4.433333333333334, 63.33333333333334, 89.33333333333333, 842.3333333333334, 4.95, 27.34311609540324, 12.0, 20.821247006977, 22.7, 1.0, 13.37149732634197], 
actual action is [-4.866666666666667, 10], 
sim time next is 2463900.0000, 
raw observation next is [0.3166666666666668, 29.75, 4.391666666666666, 64.16666666666666, 89.66666666666667, 843.6666666666666, -4.866666666666667, 28.46407064972412, 10.0, 20.7715652583177, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.34145299145299146, 0.2975, 0.3992424242424242, 0.17824074074074073, 0.23721340388007056, 0.8436666666666667, 0.41888888888888887, 0.2846407064972412, 0.0, 0.5385782629158851, 0.635, 1.0, 0.0], 
reward next is -0.1423. 
=============================================
[2017-11-01 09:49:48,282] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  4.97554630e-01   1.12926532e-02   3.42622042e-01   8.16036910e-02
   6.69269636e-02   7.70463821e-29   8.47429398e-29   1.72744661e-29
   7.14958640e-29], sum to 1.0000
[2017-11-01 09:49:48,349] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [2.566666666666667, 26.0, 4.600000000000001, 110.0, 13.0, 82.33333333333333, 7.75, 28.57253817808655, 17.0, 20.79534339018982, 22.7, 1.0, 10.85023345060932], 
actual action is [7.566666666666666, 17.0], 
sim time next is 2481900.0000, 
raw observation next is [2.383333333333333, 26.25, 4.475, 110.0, 9.500000000000002, 62.66666666666667, 7.566666666666666, 29.10425431767999, 17.0, 20.7588876042553, 22.7, 1.0, 10.09803183572131], 
processed observation next is [1.0, 0.7391304347826086, 0.39444444444444443, 0.2625, 0.4068181818181818, 0.3055555555555556, 0.025132275132275138, 0.06266666666666668, 0.6261111111111111, 0.2910425431767999, 0.35, 0.537944380212765, 0.635, 1.0, 0.11880037453789775], 
reward next is -0.2049. 
=============================================
[2017-11-01 09:49:48,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-52.1333847 ]
 [-50.30122375]
 [-52.59352112]
 [-49.96038055]
 [-52.62072754]], R is [[-51.94499588]
 [-51.63190842]
 [-51.32051086]
 [-51.01399231]
 [-50.7231636 ]].
[2017-11-01 09:49:50,056] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  5.83378732e-01   8.84274300e-03   1.96753770e-01   1.09099671e-01
   1.01925097e-01   2.92369308e-31   2.57841841e-31   5.97329041e-32
   3.15403872e-31], sum to 1.0000
[2017-11-01 09:49:50,289] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.591666666666666, 33.91666666666666, 4.6, 71.66666666666666, 85.16666666666666, 824.6666666666666, 3.266666666666667, 22.66241571024706, 26.5, 20.28962106764726, 22.7, 1.0, 66.07756376449775], 
actual action is [3.408333333333334, 21.5], 
sim time next is 2460600.0000, 
raw observation next is [-1.45, 33.5, 4.6, 70.0, 86.0, 829.0, 3.408333333333334, 21.05323229494595, 21.5, 20.80690079660921, 22.7, 1.0, 51.15714813893189], 
processed observation next is [1.0, 0.4782608695652174, 0.29615384615384616, 0.335, 0.41818181818181815, 0.19444444444444445, 0.2275132275132275, 0.829, 0.5568055555555556, 0.2105323229494595, 0.575, 0.5403450398304604, 0.635, 1.0, 0.6018488016344928], 
reward next is -0.4062. 
=============================================
[2017-11-01 09:49:52,554] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  6.03483140e-01   9.49795172e-03   1.45766035e-01   1.30170301e-01
   1.11082613e-01   2.13146158e-29   1.49418866e-29   3.43268650e-30
   4.85757058e-29], sum to 1.0000
[2017-11-01 09:49:52,626] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.591666666666667, 47.08333333333333, 4.808333333333333, 70.0, 59.25, 644.25, -11.73333333333333, 30.86006234560514, 10.0, 20.37983101428605, 22.7, 1.0, 0.0], 
actual action is [-11.591666666666667, 10], 
sim time next is 2453400.0000, 
raw observation next is [-6.449999999999999, 46.5, 4.85, 70.0, 61.0, 665.0, -11.59166666666667, 32.59926813285789, 10.0, 20.24818138319062, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.16794871794871796, 0.465, 0.44090909090909086, 0.19444444444444445, 0.16137566137566137, 0.665, 0.3068055555555555, 0.3259926813285789, 0.0, 0.512409069159531, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:49:58,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  5.01643598e-01   2.82119755e-02   1.51496619e-01   1.25606596e-01
   1.93041131e-01   1.84729892e-28   2.48043214e-28   1.97137301e-29
   7.16557403e-29], sum to 1.0000
[2017-11-01 09:49:58,913] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.608333333333333, 37.75, 2.5, 69.16666666666666, 0.0, 0.0, 3.483333333333333, 36.50989995398073, 15.0, 19.76189503472304, 21.5, 0.0, 14.10204361075968], 
actual action is [-6.6083333333333325, 10.0], 
sim time next is 2505600.0000, 
raw observation next is [-1.7, 38.0, 2.5, 70.0, 0.0, 0.0, -6.608333333333333, 37.8968998270626, 10.0, 19.71897105268735, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.0, 0.28974358974358977, 0.38, 0.22727272727272727, 0.19444444444444445, 0.0, 0.0, 0.3898611111111111, 0.37896899827062597, 0.0, 0.48594855263436754, 0.575, 0.0, 0.0], 
reward next is -0.4453. 
=============================================
[2017-11-01 09:49:59,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.38445548e-12   9.98363271e-02   1.53721467e-01   4.76248890e-01
   2.70193279e-01   8.16878676e-10   1.51023882e-09   1.51042831e-10
   1.87814653e-09], sum to 1.0000
[2017-11-01 09:49:59,651] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.7, 39.33333333333334, 2.333333333333333, 66.66666666666667, 0.0, 0.0, -6.7, 24.7517195958951, 10.0, 21.00657010400105, 21.5, 0.0, 0.0], 
actual action is [-6.7, 10], 
sim time next is 2510700.0000, 
raw observation next is [-1.7, 39.16666666666666, 2.291666666666667, 65.83333333333333, 0.0, 0.0, -6.7, 27.20720798824654, 10.0, 20.92534081935095, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.28974358974358977, 0.39166666666666655, 0.20833333333333337, 0.18287037037037035, 0.0, 0.0, 0.38833333333333336, 0.2720720798824654, 0.0, 0.5462670409675475, 0.575, 0.0, 0.0], 
reward next is -0.1437. 
=============================================
[2017-11-01 09:50:05,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 134408: loss -1.7489
[2017-11-01 09:50:05,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.59166207e-19   2.66043115e-02   5.71173608e-01   2.57346004e-01
   1.41916260e-01   2.57631444e-04   4.40646370e-04   2.29261805e-05
   2.23853835e-03], sum to 1.0000
[2017-11-01 09:50:05,302] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.466666666666667, 36.0, 3.366666666666666, 346.6666666666667, 220.3333333333333, 30.16666666666666, -3.625, 30.48540455414945, 10.0, 20.64556995004892, 22.7, 1.0, 0.0], 
actual action is [-3.533333333333333, 10], 
sim time next is 2550300.0000, 
raw observation next is [1.558333333333333, 35.25, 3.458333333333333, 345.8333333333333, 219.1666666666667, 26.08333333333334, -3.533333333333333, 30.90925188616928, 10.0, 20.58165740211557, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.3732905982905983, 0.3525, 0.3143939393939394, 0.9606481481481481, 0.5798059964726633, 0.02608333333333334, 0.4411111111111111, 0.3090925188616928, 0.0, 0.5290828701057786, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:50:08,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 134773: loss 1.6587
[2017-11-01 09:50:09,103] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 134853: loss 1.4602
[2017-11-01 09:50:10,190] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 134955: loss -0.9808
[2017-11-01 09:50:10,247] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  2.05159250e-21   1.93755713e-03   1.01393787e-02   1.57123264e-02
   1.31189302e-02   1.88102961e-01   1.68331623e-01   1.76626090e-02
   5.84994555e-01], sum to 1.0000
[2017-11-01 09:50:10,307] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.7, 39.83333333333333, 2.5, 70.0, 0.0, 0.0, 3.3, 26.43350269663711, 12.5, 21.0121870959416, 21.5, 0.0, 22.77404979429264], 
actual action is [3.3, 13.5], 
sim time next is 2509200.0000, 
raw observation next is [-1.7, 40.0, 2.5, 70.0, 0.0, 0.0, 3.3, 27.12116148934377, 13.5, 20.92463673685034, 21.5, 0.0, 21.85466563995019], 
processed observation next is [0.0, 0.043478260869565216, 0.28974358974358977, 0.4, 0.22727272727272727, 0.19444444444444445, 0.0, 0.0, 0.5549999999999999, 0.2712116148934377, 0.175, 0.546231836842517, 0.575, 0.0, 0.2571137134111787], 
reward next is -0.2724. 
=============================================
[2017-11-01 09:50:14,419] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8500, global step 135467: loss 25.7228
[2017-11-01 09:50:16,134] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135693: loss 17.9306
[2017-11-01 09:50:17,565] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135882: loss 5.1675
[2017-11-01 09:50:17,628] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135890: loss -10.8754
[2017-11-01 09:50:17,681] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.89099169e-01   1.39548508e-02   8.21112096e-02   2.14991599e-01
   9.98431668e-02   1.37813017e-29   6.04527555e-30   1.04189095e-30
   1.38137235e-29], sum to 1.0000
[2017-11-01 09:50:17,691] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 3.133333333333333, 340.8333333333333, 132.75, 319.3333333333333, -1.7, 24.04954655541525, 10.0, 21.50089313632233, 22.7, 1.0, 0.0], 
actual action is [-1.7000000000000002, 10], 
sim time next is 2560200.0000, 
raw observation next is [3.3, 29.0, 3.266666666666667, 341.6666666666667, 129.0, 325.6666666666667, -1.7, 23.9667838917004, 10.0, 21.50958549969412, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.41794871794871796, 0.29, 0.296969696969697, 0.9490740740740742, 0.3412698412698413, 0.32566666666666666, 0.4716666666666667, 0.239667838917004, 0.0, 0.575479274984706, 0.635, 1.0, 0.0], 
reward next is -0.1198. 
=============================================
[2017-11-01 09:50:18,701] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136020: loss -42.2158
[2017-11-01 09:50:19,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  6.73955619e-01   9.17014945e-03   7.08763227e-02   1.56742945e-01
   8.92549381e-02   1.47958712e-30   5.62891912e-31   5.70189874e-32
   1.31480792e-30], sum to 1.0000
[2017-11-01 09:50:19,792] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.675, 41.0, 3.15, 265.0, 228.5, 58.75, -4.466666666666667, 27.22266927920658, 10.0, 21.14657014834319, 22.7, 1.0, 0.0], 
actual action is [-4.325, 10.0], 
sim time next is 2548200.0000, 
raw observation next is [0.8166666666666668, 40.33333333333333, 3.1, 293.3333333333334, 227.3333333333333, 54.66666666666667, -4.325, 27.40482626205996, 10.0, 21.15230259356035, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.3542735042735043, 0.40333333333333327, 0.2818181818181818, 0.8148148148148151, 0.601410934744268, 0.05466666666666667, 0.42791666666666667, 0.2740482626205996, 0.0, 0.5576151296780175, 0.635, 1.0, 0.0], 
reward next is -0.1370. 
=============================================
[2017-11-01 09:50:20,313] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136211: loss -10.7301
[2017-11-01 09:50:22,405] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8500, global step 136495: loss 90.3043
[2017-11-01 09:50:23,288] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  7.11598277e-01   5.12517150e-03   6.63325191e-02   1.55936226e-01
   6.10077605e-02   1.30738933e-27   9.79518244e-28   1.06394208e-28
   3.30054703e-27], sum to 1.0000
[2017-11-01 09:50:23,324] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.733333333333333, 28.66666666666667, 3.4, 346.6666666666667, 178.8333333333333, 405.3333333333334, -2.4, 29.54169655423214, 10.0, 20.32424935087079, 22.7, 1.0, 0.0], 
actual action is [-2.266666666666667, 10], 
sim time next is 2553900.0000, 
raw observation next is [2.866666666666666, 28.33333333333333, 3.225, 348.3333333333333, 174.9166666666667, 443.6666666666666, -2.266666666666667, 29.3516094207163, 10.0, 20.34908990471545, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.4068376068376068, 0.28333333333333327, 0.2931818181818182, 0.9675925925925926, 0.4627425044091712, 0.4436666666666666, 0.46222222222222226, 0.293516094207163, 0.0, 0.5174544952357725, 0.635, 1.0, 0.0], 
reward next is -0.1468. 
=============================================
[2017-11-01 09:50:23,783] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136701: loss 14.8966
[2017-11-01 09:50:26,758] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8500, global step 137152: loss -47.2981
[2017-11-01 09:50:27,431] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8500, global step 137233: loss -8.6200
[2017-11-01 09:50:28,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.26990553e-05   1.81189068e-02   6.19175673e-01   2.77691036e-01
   8.50016996e-02   2.96803108e-29   1.82632010e-29   1.19120902e-30
   3.69883850e-28], sum to 1.0000
[2017-11-01 09:50:28,061] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.8, 56.0, 3.933333333333334, 296.6666666666667, 0.0, 0.0, -7.8, 38.89418812857591, 10.0, 19.55686282896071, 21.5, 0.0, 0.0], 
actual action is [-7.8, 10.0], 
sim time next is 2582700.0000, 
raw observation next is [-2.8, 56.0, 3.891666666666666, 295.8333333333333, 0.0, 0.0, -7.8, 40.47371785692371, 10.0, 19.43412491435488, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.2615384615384615, 0.56, 0.35378787878787876, 0.8217592592592592, 0.0, 0.0, 0.37, 0.40473717856923713, 0.0, 0.47170624571774394, 0.575, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:50:28,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 137320: loss -11.0402
[2017-11-01 09:50:33,305] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.23501868e-34   7.48400300e-11   9.59233137e-10   1.02178410e-09
   9.48263482e-11   2.36951001e-02   2.22282596e-02   2.88825925e-03
   9.51188326e-01], sum to 1.0000
[2017-11-01 09:50:33,392] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.541666666666667, 62.49999999999999, 4.058333333333333, 270.0, 0.0, 0.0, 0.5, 28.46466571132646, 16.0, 19.91420481197718, 21.5, 0.0, 40.8246057871113], 
actual action is [0.45833333333333304, 21.0], 
sim time next is 2592600.0000, 
raw observation next is [-4.583333333333333, 63.0, 4.016666666666667, 270.0, 0.0, 0.0, 0.458333333333333, 28.15513972712629, 21.0, 20.006109446585, 21.5, 0.0, 35.43069477122937], 
processed observation next is [0.16666666666666666, 0.0, 0.21581196581196585, 0.63, 0.36515151515151517, 0.75, 0.0, 0.0, 0.5076388888888889, 0.2815513972712629, 0.55, 0.50030547232925, 0.575, 0.0, 0.41683170319093377], 
reward next is -0.5819. 
=============================================
[2017-11-01 09:50:34,202] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8500, global step 138131: loss 18.3407
[2017-11-01 09:50:44,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  3.46605367e-09   6.97778165e-02   5.15387714e-01   2.85790443e-01
   1.29044056e-01   2.42940425e-11   3.13363363e-11   6.96609740e-12
   6.21903473e-10], sum to 1.0000
[2017-11-01 09:50:44,733] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.2, 60.5, 4.1, 275.0, 0.0, 0.0, 0.8500000000000014, 22.75671108232614, 13.0, 20.84175943929219, 21.5, 0.0, 32.10620068854899], 
actual action is [0.7999999999999998, 13.0], 
sim time next is 2590500.0000, 
raw observation next is [-4.25, 60.75, 4.1, 274.1666666666666, 0.0, 0.0, 0.7999999999999998, 23.22217101580672, 13.0, 20.82935197385789, 21.5, 0.0, 30.61757720859108], 
processed observation next is [0.0, 1.0, 0.22435897435897437, 0.6075, 0.3727272727272727, 0.7615740740740738, 0.0, 0.0, 0.5133333333333333, 0.2322217101580672, 0.15, 0.5414675986928945, 0.575, 0.0, 0.36020679068930683], 
reward next is -0.3478. 
=============================================
[2017-11-01 09:50:57,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-38.14103699]
 [-36.16652298]
 [-40.54830933]
 [-37.86154938]
 [-40.73217773]], R is [[-37.03891754]
 [-37.15244293]
 [-37.26797104]
 [-37.3898201 ]
 [-37.52845764]].
[2017-11-01 09:51:01,234] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-30.41580963]
 [-30.78632927]
 [-29.89252663]
 [-30.0621891 ]
 [-29.63462639]], R is [[-29.73662186]
 [-29.56973648]
 [-29.40371323]
 [-29.23856926]
 [-29.07431984]].
[2017-11-01 09:51:04,767] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   1.60684582e-35   3.74151766e-36   2.21197071e-35
   1.59687335e-35   5.84924268e-03   1.34029046e-01   9.01563093e-03
   8.51106107e-01], sum to 1.0000
[2017-11-01 09:51:05,073] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.616666666666667, 78.83333333333333, 6.85, 256.6666666666667, 0.0, 0.0, -1.575, 28.54713523497449, 19.0, 19.5942401016717, 21.5, 0.0, 26.58567196556159], 
actual action is [-1.6166666666666671, 24.0], 
sim time next is 2613300.0000, 
raw observation next is [-6.658333333333333, 78.41666666666667, 7.024999999999999, 258.3333333333333, 0.0, 0.0, -1.616666666666667, 29.44396644646408, 24.0, 19.51590933904795, 21.5, 0.0, 25.51920584023512], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.1626068376068376, 0.7841666666666667, 0.6386363636363636, 0.7175925925925926, 0.0, 0.0, 0.47305555555555556, 0.2944396644646408, 0.7, 0.47579546695239755, 0.575, 0.0, 0.30022595106158967], 
reward next is -0.6461. 
=============================================
[2017-11-01 09:51:17,324] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 142646: loss -121.4964
[2017-11-01 09:51:17,442] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.75851774e-01   2.72862380e-04   1.41040748e-02   6.73527457e-03
   3.03610414e-03   5.78230373e-31   2.00655381e-30   2.07379655e-31
   6.07960224e-30], sum to 1.0000
[2017-11-01 09:51:17,549] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.208333333333334, 69.0, 6.833333333333334, 265.8333333333333, 0.0, 0.0, 0.9500000000000002, 23.3198782652378, 25.0, 20.46505322026753, 21.5, 0.0, 49.01186545523777], 
actual action is [0.7916666666666661, 20.0], 
sim time next is 2673600.0000, 
raw observation next is [-4.366666666666666, 69.0, 6.766666666666667, 266.6666666666667, 0.0, 0.0, 0.7916666666666661, 22.65599167283352, 20.0, 20.56570137410164, 21.5, 0.0, 48.64158095709369], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.22136752136752136, 0.69, 0.6151515151515151, 0.7407407407407408, 0.0, 0.0, 0.5131944444444444, 0.2265599167283352, 0.5, 0.528285068705082, 0.575, 0.0, 0.5722538936128669], 
reward next is -0.5197. 
=============================================
[2017-11-01 09:51:17,922] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.64075267e-01   6.68128196e-04   2.50376817e-02   7.00531993e-03
   3.21363774e-03   1.01018902e-28   2.50047096e-28   2.75850254e-29
   2.89980049e-28], sum to 1.0000
[2017-11-01 09:51:18,117] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5083333333333333, 46.66666666666666, 8.158333333333331, 240.0, 197.75, 184.3333333333333, 4.4, 31.89548579722388, 15.0, 19.73459924055243, 22.7, 1.0, 53.80632602536443], 
actual action is [-5.508333333333333, 10.0], 
sim time next is 2639400.0000, 
raw observation next is [-0.4166666666666667, 46.33333333333334, 8.116666666666667, 240.0, 191.0, 189.6666666666667, -5.508333333333333, 31.82530755766593, 10.0, 19.84033859159962, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.32264957264957267, 0.46333333333333343, 0.7378787878787879, 0.6666666666666666, 0.5052910052910053, 0.1896666666666667, 0.40819444444444447, 0.3182530755766593, 0.0, 0.4920169295799811, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:51:18,537] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00285631
  0.18895045  0.00487538  0.80331784], sum to 1.0000
[2017-11-01 09:51:18,617] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-11.95, 79.5, 3.4, 95.0, 0.0, 0.0, -16.79166666666667, 29.6828931757374, 10.0, 19.93761803263461, 21.5, 0.0, 0.0], 
actual action is [-6.949999999999999, 15.0], 
sim time next is 2687700.0000, 
raw observation next is [-12.10833333333333, 80.08333333333334, 3.333333333333333, 110.8333333333333, 0.0, 0.0, -6.949999999999999, 29.37714932664793, 15.0, 19.75323418108017, 21.5, 0.0, 53.6082493219801], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.02286324786324793, 0.8008333333333334, 0.303030303030303, 0.3078703703703703, 0.0, 0.0, 0.38416666666666666, 0.29377149326647933, 0.25, 0.4876617090540085, 0.575, 0.0, 0.6306852861409423], 
reward next is -0.7520. 
=============================================
[2017-11-01 09:51:18,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.98530030e-01   1.03727889e-05   8.83335480e-04   4.40900738e-04
   1.35364695e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-01 09:51:19,163] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 1.6, 76.66666666666666, 0.0, 0.0, -10.0, 38.29523207865154, 29.0, 18.06010391124245, 22.7, 1.0, 75.44205592400695], 
actual action is [-10.0, 24.0], 
sim time next is 2704500.0000, 
raw observation next is [-15.0, 83.0, 1.65, 85.0, 0.0, 0.0, -10.0, 36.45969119549559, 24.0, 18.23088712047695, 22.7, 1.0, 70.04533321458658], 
processed observation next is [0.3333333333333333, 0.30434782608695654, -0.05128205128205128, 0.83, 0.15, 0.2361111111111111, 0.0, 0.0, 0.3333333333333333, 0.36459691195495586, 0.7, 0.41154435602384754, 0.635, 1.0, 0.8240627437010185], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:51:19,765] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 142954: loss 107.4210
[2017-11-01 09:51:22,166] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143224: loss -42.8272
[2017-11-01 09:51:22,593] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143269: loss 193.8331
[2017-11-01 09:51:23,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.47651369e-09   1.31461145e-02   5.69942474e-01   3.63895208e-01
   5.30161448e-02   5.51896765e-26   8.65052345e-25   3.45811137e-26
   6.66441920e-24], sum to 1.0000
[2017-11-01 09:51:23,738] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.33333333333333, 78.5, 2.0, 60.0, 103.6666666666667, 632.6666666666667, -17.5, 44.31424128863018, 10.0, 18.76374479043293, 22.7, 1.0, 0.0], 
actual action is [-17.33333333333333, 10], 
sim time next is 2714100.0000, 
raw observation next is [-12.16666666666667, 77.25, 2.05, 55.0, 105.3333333333333, 637.8333333333333, -17.33333333333333, 44.70339136035421, 10.0, 18.76007388649074, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.02136752136752129, 0.7725, 0.18636363636363634, 0.1527777777777778, 0.27865961199294526, 0.6378333333333333, 0.2111111111111112, 0.4470339136035421, 0.0, 0.438003694324537, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:51:24,213] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143454: loss 1.8073
[2017-11-01 09:51:24,292] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9000, global step 143462: loss 210.0528
[2017-11-01 09:51:27,421] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143751: loss -128.8943
[2017-11-01 09:51:27,653] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143768: loss 23.3841
[2017-11-01 09:51:28,701] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143867: loss -116.0102
[2017-11-01 09:51:32,035] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9000, global step 144167: loss -220.2301
[2017-11-01 09:51:32,450] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144212: loss 31.0355
[2017-11-01 09:51:34,053] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144353: loss 82.0370
[2017-11-01 09:51:34,515] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-99.8499527 ]
 [-96.30027008]
 [-99.05080414]
 [-99.35559082]
 [-94.97587585]], R is [[-100.78915405]
 [-100.78126526]
 [-100.77345276]
 [-100.76571655]
 [-100.75805664]].
[2017-11-01 09:51:38,593] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144811: loss -62.4156
[2017-11-01 09:51:39,456] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9000, global step 144911: loss 0.3994
[2017-11-01 09:51:40,401] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9000, global step 145010: loss -319.7795
[2017-11-01 09:51:48,037] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9000, global step 145753: loss -25.4020
[2017-11-01 09:52:03,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.15282534e-07   2.58196698e-04   1.82001968e-03   9.96213973e-01
   1.70745607e-03   3.47608500e-20   3.68887346e-19   1.94639295e-19
   2.63084504e-18], sum to 1.0000
[2017-11-01 09:52:03,456] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.0, 59.0, 2.558333333333334, 70.0, 0.0, 0.0, -1.0, 26.42886426740677, 18.5, 20.59018091046033, 21.5, 0.0, 28.74952670012839], 
actual action is [-1.0, 18.0], 
sim time next is 2768400.0000, 
raw observation next is [-6.0, 59.0, 2.6, 70.0, 0.0, 0.0, -1.0, 27.23123636521748, 18.0, 20.51728687285967, 21.5, 0.0, 27.51304601004151], 
processed observation next is [0.5, 0.043478260869565216, 0.1794871794871795, 0.59, 0.23636363636363636, 0.19444444444444445, 0.0, 0.0, 0.48333333333333334, 0.2723123636521748, 0.4, 0.5258643436429835, 0.575, 0.0, 0.32368289423578245], 
reward next is -0.4075. 
=============================================
[2017-11-01 09:52:10,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-71.30927277]
 [-71.83339691]
 [-73.56481171]
 [-75.20534515]
 [-75.71260071]], R is [[-72.39620209]
 [-72.29577637]
 [-72.57282257]
 [-72.84709167]
 [-73.11862183]].
[2017-11-01 09:52:22,058] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-86.91888428]
 [-86.00152588]
 [-85.92121887]
 [-88.56216431]
 [-86.97782135]], R is [[-89.47394562]
 [-89.57920837]
 [-89.68341827]
 [-89.78658295]
 [-89.88871765]].
[2017-11-01 09:52:29,725] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 150490: loss 1.1811
[2017-11-01 09:52:30,413] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 150553: loss 0.4889
[2017-11-01 09:52:32,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.49869488e-02   2.28399946e-03   2.71670707e-03   8.92237186e-01
   7.77750835e-02   2.10958774e-22   4.94220171e-22   3.90507226e-22
   2.66017610e-21], sum to 1.0000
[2017-11-01 09:52:32,339] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 44.0, 4.308333333333333, 114.1666666666667, 0.0, 0.0, 7.0, 17.81529148667437, 24.0, 21.72117166793342, 21.5, 0.0, 44.57829659185695], 
actual action is [7.0, 23.5], 
sim time next is 2842200.0000, 
raw observation next is [2.0, 44.0, 4.35, 115.0, 0.0, 0.0, 7.0, 17.53023635929774, 23.5, 21.77542500508858, 21.5, 0.0, 44.56530211678315], 
processed observation next is [0.5, 0.9130434782608695, 0.38461538461538464, 0.44, 0.39545454545454545, 0.3194444444444444, 0.0, 0.0, 0.6166666666666667, 0.17530236359297738, 0.675, 0.5887712502544289, 0.575, 0.0, 0.5242976719621547], 
reward next is -0.2621. 
=============================================
[2017-11-01 09:52:34,352] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 150940: loss 4.4315
[2017-11-01 09:52:35,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151065: loss 20.3172
[2017-11-01 09:52:38,833] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151360: loss 5.5109
[2017-11-01 09:52:39,285] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9500, global step 151402: loss -49.4420
[2017-11-01 09:52:40,813] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151539: loss 0.3630
[2017-11-01 09:52:41,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.79484152e-03   4.23320010e-03   1.78002112e-03   9.08609748e-01
   7.55822435e-02   3.42856307e-21   2.44043282e-21   1.57513293e-21
   2.38840712e-20], sum to 1.0000
[2017-11-01 09:52:41,572] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 44.0, 4.516666666666666, 118.3333333333333, 0.0, 0.0, 7.0, 12.62907961494141, 24.0, 22.65043293975837, 21.5, 0.0, 44.19607477801744], 
actual action is [7.0, 23.5], 
sim time next is 2843700.0000, 
raw observation next is [2.0, 44.0, 4.558333333333333, 119.1666666666667, 0.0, 0.0, 7.0, 12.49060899352714, 23.5, 22.67377667140055, 21.5, 0.0, 44.20685590349755], 
processed observation next is [0.5, 0.9130434782608695, 0.38461538461538464, 0.44, 0.4143939393939393, 0.3310185185185186, 0.0, 0.0, 0.6166666666666667, 0.1249060899352714, 0.675, 0.6336888335700275, 0.575, 0.0, 0.5200806576882064], 
reward next is -0.2600. 
=============================================
[2017-11-01 09:52:44,325] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151869: loss 12.8054
[2017-11-01 09:52:44,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.68037070e-07   5.93172060e-03   1.05589919e-03   8.55763495e-01
   1.37248605e-01   1.45731626e-12   2.31157888e-12   8.75477371e-13
   9.94073053e-12], sum to 1.0000
[2017-11-01 09:52:44,457] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  8.07193826e-11   1.01001393e-02   1.01363007e-03   8.60064387e-01
   1.28820136e-01   1.48636445e-07   2.71190572e-07   9.15974141e-08
   1.14391719e-06], sum to 1.0000
[2017-11-01 09:52:44,474] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [1.416666666666667, 67.83333333333333, 4.475, 138.3333333333333, 0.0, 0.0, 6.5, 12.71010698410702, 28.0, 22.59953524712591, 21.5, 0.0, 44.10777044370207], 
actual action is [6.416666666666667, 28.0], 
sim time next is 2850000.0000, 
raw observation next is [1.333333333333333, 68.66666666666667, 4.6, 136.6666666666667, 0.0, 0.0, 6.416666666666667, 12.65131074324761, 28.0, 22.59764745041889, 21.5, 0.0, 44.20367254089727], 
processed observation next is [0.5, 1.0, 0.3675213675213675, 0.6866666666666668, 0.41818181818181815, 0.37962962962962976, 0.0, 0.0, 0.6069444444444444, 0.1265131074324761, 0.9, 0.6298823725209445, 0.575, 0.0, 0.5200432063634973], 
reward next is -0.2600. 
=============================================
[2017-11-01 09:52:44,533] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 44.0, 4.308333333333333, 114.1666666666667, 0.0, 0.0, 7.0, 12.58551115691455, 23.0, 22.73372348189389, 21.5, 0.0, 33.07656695123354], 
actual action is [7.0, 22.5], 
sim time next is 2842200.0000, 
raw observation next is [2.0, 44.0, 4.35, 115.0, 0.0, 0.0, 7.0, 12.69097385500983, 22.5, 22.75388156380872, 21.5, 0.0, 31.65088228764087], 
processed observation next is [0.5, 0.9130434782608695, 0.38461538461538464, 0.44, 0.39545454545454545, 0.3194444444444444, 0.0, 0.0, 0.6166666666666667, 0.1269097385500983, 0.625, 0.6376940781904359, 0.575, 0.0, 0.37236332103106906], 
reward next is -0.1862. 
=============================================
[2017-11-01 09:52:44,559] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151893: loss -1.2440
[2017-11-01 09:52:45,692] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152011: loss 5.3219
[2017-11-01 09:52:47,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-28.3151741 ]
 [-28.44187355]
 [-28.9952774 ]
 [-28.7078476 ]
 [-28.11509895]], R is [[-28.10463333]
 [-28.08731842]
 [-28.07136726]
 [-28.05725861]
 [-28.04576111]].
[2017-11-01 09:52:48,520] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9500, global step 152244: loss 1.6825
[2017-11-01 09:52:50,459] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152403: loss 0.1235
[2017-11-01 09:52:55,961] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152895: loss 1.3226
[2017-11-01 09:53:00,894] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9500, global step 153383: loss -8.1439
[2017-11-01 09:53:02,725] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9500, global step 153675: loss -31.8885
[2017-11-01 09:53:08,042] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9500, global step 154371: loss 0.1272
[2017-11-01 09:53:08,361] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.37894069e-13   4.56613634e-05   4.85041846e-06   9.99394417e-01
   5.55116101e-04   8.66076687e-14   1.52540239e-13   2.37307512e-14
   1.59339122e-12], sum to 1.0000
[2017-11-01 09:53:08,383] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.75, 93.0, 8.7, 257.5, 22.25, 44.25, -3.166666666666667, 27.46714896820496, 10.0, 20.30790315222822, 22.7, 1.0, 0.0], 
actual action is [-3.25, 10], 
sim time next is 2913600.0000, 
raw observation next is [1.666666666666667, 93.0, 8.7, 256.6666666666667, 16.83333333333333, 43.16666666666667, -3.25, 28.19316797908419, 10.0, 20.22292802250379, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.3760683760683761, 0.93, 0.7909090909090909, 0.712962962962963, 0.04453262786596119, 0.04316666666666667, 0.44583333333333336, 0.2819316797908419, 0.0, 0.5111464011251895, 0.635, 1.0, 0.0], 
reward next is -0.1410. 
=============================================
[2017-11-01 09:53:25,176] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.16722304e-01   3.06725968e-02   2.77323779e-02   5.08179247e-01
   1.16693556e-01   9.04879109e-20   1.52918476e-19   2.75854653e-20
   3.21886220e-19], sum to 1.0000
[2017-11-01 09:53:25,312] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.0, 83.25, 7.075, 260.0, 0.0, 0.0, 4.0, 12.59777580302471, 23.5, 21.40625411790954, 21.5, 0.0, 46.91638927828523], 
actual action is [4.0, 23.0], 
sim time next is 2928000.0000, 
raw observation next is [-1.0, 82.66666666666667, 7.200000000000001, 260.0, 0.0, 0.0, 4.0, 12.25797850787589, 23.0, 21.51058796009567, 21.5, 0.0, 46.79829171124972], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.3076923076923077, 0.8266666666666667, 0.6545454545454547, 0.7222222222222222, 0.0, 0.0, 0.5666666666666667, 0.1225797850787589, 0.65, 0.5755293980047835, 0.575, 0.0, 0.5505681377794085], 
reward next is -0.2753. 
=============================================
[2017-11-01 09:53:48,270] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 158484: loss -83.3549
[2017-11-01 09:53:50,517] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 158684: loss 30.4087
[2017-11-01 09:53:53,199] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 158957: loss 53.0211
[2017-11-01 09:53:53,229] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 158958: loss 22.1144
[2017-11-01 09:53:53,357] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 158966: loss -11.2210
[2017-11-01 09:53:59,476] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.79699285e-02   1.05393594e-02   1.56256780e-02   8.88472736e-01
   5.73923178e-02   3.86728141e-21   3.45276594e-20   2.13976034e-21
   2.67870567e-21], sum to 1.0000
[2017-11-01 09:53:59,493] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.0, 65.0, 3.6, 260.0, 145.5, 745.5, -8.0, 20.81749133893738, 10.0, 21.166139881374, 22.7, 1.0, 0.0], 
actual action is [-8.0, 10], 
sim time next is 2984700.0000, 
raw observation next is [-2.916666666666667, 64.58333333333333, 3.6, 257.5, 139.5833333333333, 754.5833333333333, -8.0, 21.6814318556202, 10.0, 21.13315943488336, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.2585470085470085, 0.6458333333333333, 0.32727272727272727, 0.7152777777777778, 0.3692680776014108, 0.7545833333333333, 0.36666666666666664, 0.216814318556202, 0.0, 0.556657971744168, 0.635, 1.0, 0.0], 
reward next is -0.1084. 
=============================================
[2017-11-01 09:54:00,113] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159629: loss -82.3281
[2017-11-01 09:54:02,061] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159833: loss 66.9200
[2017-11-01 09:54:02,485] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10000, global step 159864: loss -154.2193
[2017-11-01 09:54:02,870] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159896: loss 91.6188
[2017-11-01 09:54:06,445] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160200: loss 22.2288
[2017-11-01 09:54:06,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.11459800e-08   1.15275336e-02   2.16476284e-02   9.22646105e-01
   4.41787653e-02   1.33245465e-12   6.35542790e-12   3.84080083e-13
   1.10903485e-12], sum to 1.0000
[2017-11-01 09:54:06,885] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.416666666666666, 73.5, 2.516666666666667, 30.0, 0.0, 0.0, -0.3333333333333339, 18.33757207098265, 30.0, 21.144210116952, 21.5, 0.0, 44.52146710284459], 
actual action is [-0.4166666666666661, 29.5], 
sim time next is 3033000.0000, 
raw observation next is [-5.5, 74.0, 2.6, 30.0, 0.0, 0.0, -0.4166666666666661, 18.34046505567808, 29.5, 21.14133420875491, 21.5, 0.0, 44.59468416107482], 
processed observation next is [1.0, 0.08695652173913043, 0.19230769230769232, 0.74, 0.23636363636363636, 0.08333333333333333, 0.0, 0.0, 0.4930555555555556, 0.18340465055678082, 0.975, 0.5570667104377455, 0.575, 0.0, 0.5246433430714684], 
reward next is -0.3520. 
=============================================
[2017-11-01 09:54:07,453] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10000, global step 160298: loss -13.7928
[2017-11-01 09:54:07,514] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160303: loss 0.4607
[2017-11-01 09:54:10,601] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160568: loss -134.0241
[2017-11-01 09:54:10,729] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.16400712e-03   1.22587318e-02   3.27110961e-02   8.88525844e-01
   6.53402954e-02   1.25676089e-15   1.38720735e-15   4.32486500e-16
   6.25893344e-16], sum to 1.0000
[2017-11-01 09:54:10,853] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.291666666666667, 65.0, 1.083333333333333, 104.1666666666667, 0.0, 0.0, 1.75, 12.02271101189731, 26.5, 22.8705553171426, 21.5, 0.0, 42.86484955510539], 
actual action is [1.708333333333333, 26.0], 
sim time next is 3012000.0000, 
raw observation next is [-3.333333333333333, 65.0, 0.8666666666666668, 83.33333333333334, 0.0, 0.0, 1.708333333333333, 11.95533373174369, 26.0, 22.87494555923462, 21.5, 0.0, 42.70907584414079], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.2478632478632479, 0.65, 0.0787878787878788, 0.2314814814814815, 0.0, 0.0, 0.5284722222222222, 0.11955333731743689, 0.8, 0.643747277961731, 0.575, 0.0, 0.5024597158134211], 
reward next is -0.2512. 
=============================================
[2017-11-01 09:54:16,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.16054222e-01   1.62394550e-02   4.33755629e-02   6.94471121e-01
   1.29859582e-01   9.45876765e-20   7.04763181e-20   1.97511650e-20
   3.71497476e-20], sum to 1.0000
[2017-11-01 09:54:17,018] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.791666666666667, 65.0, 0.0, 0.0, 0.0, 0.0, 1.25, 21.01818890784919, 18.5, 21.48761391518952, 21.5, 0.0, 14.27335614451206], 
actual action is [1.208333333333333, 18.0], 
sim time next is 3015600.0000, 
raw observation next is [-3.833333333333333, 65.0, 0.0, 0.0, 0.0, 0.0, 1.208333333333333, 21.69727985540314, 18.0, 21.38140711409396, 21.5, 0.0, 13.7732100900991], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.23504273504273507, 0.65, 0.0, 0.0, 0.0, 0.0, 0.5201388888888888, 0.2169727985540314, 0.4, 0.569070355704698, 0.575, 0.0, 0.16203776576587176], 
reward next is -0.1107. 
=============================================
[2017-11-01 09:54:18,233] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10000, global step 161326: loss -103.1757
[2017-11-01 09:54:18,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-27.49648476]
 [-26.70057869]
 [-27.47323036]
 [-27.88114929]
 [-27.40772247]], R is [[-27.72577477]
 [-27.79260063]
 [-27.88658333]
 [-27.97636604]
 [-28.06204796]].
[2017-11-01 09:54:19,233] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10000, global step 161435: loss -12.3760
[2017-11-01 09:54:23,633] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  7.60255978e-02   6.23808568e-03   2.51042675e-02   8.48771334e-01
   4.38608117e-02   3.02687469e-22   9.61267024e-23   2.04060598e-23
   7.31003322e-23], sum to 1.0000
[2017-11-01 09:54:23,739] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.0, 77.0, 2.416666666666667, 58.33333333333333, 0.0, 0.0, -1.0, 17.65431724935776, 29.5, 21.09825862808531, 21.5, 0.0, 44.74417191572754], 
actual action is [-1.0, 29.0], 
sim time next is 3039300.0000, 
raw observation next is [-6.0, 77.0, 2.325, 57.5, 0.0, 0.0, -1.0, 17.59127238893494, 29.0, 21.11025443049613, 21.5, 0.0, 44.67852819043907], 
processed observation next is [1.0, 0.17391304347826086, 0.1794871794871795, 0.77, 0.2113636363636364, 0.1597222222222222, 0.0, 0.0, 0.48333333333333334, 0.1759127238893494, 0.95, 0.5555127215248066, 0.575, 0.0, 0.5256297434169303], 
reward next is -0.3603. 
=============================================
[2017-11-01 09:54:25,970] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10000, global step 162057: loss 14.8094
[2017-11-01 09:54:37,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.46797839
  0.11769682  0.03769631  0.3766284 ], sum to 1.0000
[2017-11-01 09:54:37,428] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 39.5, 3.6, 100.0, 84.0, 673.0, 5.416666666666667, 25.48304576169602, 16.5, 20.5717532637875, 22.7, 1.0, 3.556210409267803], 
actual action is [5.5, 21.5], 
sim time next is 3080100.0000, 
raw observation next is [0.5833333333333334, 39.58333333333334, 3.516666666666667, 101.6666666666667, 81.75, 657.4166666666666, 5.5, 25.47003365536896, 21.5, 20.5819956952589, 22.7, 1.0, 3.400943090940377], 
processed observation next is [1.0, 0.6521739130434783, 0.34829059829059833, 0.3958333333333334, 0.31969696969696976, 0.2824074074074075, 0.21626984126984128, 0.6574166666666666, 0.5916666666666667, 0.2547003365536896, 0.575, 0.5290997847629451, 0.635, 1.0, 0.040011095187533846], 
reward next is -0.1474. 
=============================================
[2017-11-01 09:54:38,833] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  6.35764266e-26   1.14320471e-07   1.09221929e-07   1.43201005e-05
   6.16672992e-07   6.13975525e-01   1.55935302e-01   4.25302796e-02
   1.87543616e-01], sum to 1.0000
[2017-11-01 09:54:38,937] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 77.0, 2.325, 57.5, 0.0, 0.0, -1.0, 20.5541073478675, 16.5, 21.07499028573157, 21.5, 0.0, 28.4813384808748], 
actual action is [-1.0, 21.5], 
sim time next is 3039600.0000, 
raw observation next is [-6.0, 77.0, 2.233333333333333, 56.66666666666667, 0.0, 0.0, -1.0, 21.32795134996033, 21.5, 20.98502863415564, 21.5, 0.0, 27.18235111850118], 
processed observation next is [1.0, 0.17391304347826086, 0.1794871794871795, 0.77, 0.203030303030303, 0.1574074074074074, 0.0, 0.0, 0.48333333333333334, 0.2132795134996033, 0.575, 0.549251431707782, 0.575, 0.0, 0.3197923661000139], 
reward next is -0.2886. 
=============================================
[2017-11-01 09:54:55,380] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.89923327e-23   5.03325907e-07   2.71847341e-07   1.70558433e-05
   5.11375310e-06   4.88709688e-01   9.02643651e-02   5.13730422e-02
   3.69629920e-01], sum to 1.0000
[2017-11-01 09:54:55,541] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 54.0, 2.166666666666667, 41.66666666666667, 107.6666666666667, 774.3333333333333, -9.0, 24.3749770976032, 10.0, 20.80055534023881, 22.7, 1.0, 0.0], 
actual action is [1.0, 15.0], 
sim time next is 3063300.0000, 
raw observation next is [-4.0, 54.0, 2.383333333333333, 45.83333333333333, 108.0833333333333, 778.1666666666666, 1.0, 24.31871947240571, 15.0, 20.76093707080579, 22.7, 1.0, 15.0924080801186], 
processed observation next is [1.0, 0.43478260869565216, 0.23076923076923078, 0.54, 0.21666666666666662, 0.1273148148148148, 0.2859347442680775, 0.7781666666666667, 0.5166666666666667, 0.24318719472405712, 0.25, 0.5380468535402896, 0.635, 1.0, 0.17755774211904235], 
reward next is -0.2104. 
=============================================
[2017-11-01 09:55:03,390] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 166072: loss -0.4181
[2017-11-01 09:55:04,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  4.48144823e-01   7.68946558e-02   1.16467565e-01   2.65031278e-01
   9.34615880e-02   3.32688425e-11   7.05077923e-12   6.36673873e-12
   6.34114289e-12], sum to 1.0000
[2017-11-01 09:55:04,287] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [7.833333333333334, 94.16666666666666, 4.516666666666667, 191.6666666666667, 113.3333333333333, 817.0, 2.916666666666666, 10.959287038427, 10.0, 22.32568333282694, 22.7, 1.0, 0.0], 
actual action is [2.833333333333334, 10], 
sim time next is 3154500.0000, 
raw observation next is [7.75, 94.75, 4.475, 192.5, 113.25, 818.5, 2.833333333333334, 11.15802213617227, 10.0, 22.18685186500008, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.532051282051282, 0.9475, 0.4068181818181818, 0.5347222222222222, 0.2996031746031746, 0.8185, 0.5472222222222223, 0.1115802213617227, 0.0, 0.609342593250004, 0.635, 1.0, 0.0], 
reward next is -0.0558. 
=============================================
[2017-11-01 09:55:06,950] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 166480: loss 5.6392
[2017-11-01 09:55:08,617] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 166649: loss 4.1950
[2017-11-01 09:55:09,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.51782328e-01   8.20967555e-02   1.62618011e-02   5.35534143e-01
   1.14324935e-01   6.60894110e-20   9.35632392e-21   9.02125923e-21
   2.76613688e-20], sum to 1.0000
[2017-11-01 09:55:09,857] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 100.0, 7.199999999999999, 170.0, 1.0, 82.0, 1.0, 25.59611350627272, 10.0, 20.21487744856831, 22.7, 1.0, 0.0], 
actual action is [1.0, 10], 
sim time next is 3137700.0000, 
raw observation next is [6.0, 100.0, 7.366666666666666, 168.3333333333333, 7.833333333333337, 107.8333333333333, 1.0, 26.45611344746009, 10.0, 20.11758616484432, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.48717948717948717, 1.0, 0.6696969696969697, 0.46759259259259245, 0.0207231040564374, 0.1078333333333333, 0.5166666666666667, 0.2645611344746009, 0.0, 0.5058793082422159, 0.635, 1.0, 0.0], 
reward next is -0.1323. 
=============================================
[2017-11-01 09:55:10,416] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 166877: loss 3.4543
[2017-11-01 09:55:11,966] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167100: loss 0.1491
[2017-11-01 09:55:14,927] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167470: loss 1.3455
[2017-11-01 09:55:15,970] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.59556562e-01   7.71450475e-02   5.31781502e-02   4.11354125e-01
   1.98766142e-01   2.64382223e-16   4.88088773e-17   5.49292396e-17
   1.88640100e-16], sum to 1.0000
[2017-11-01 09:55:15,980] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [3.0, 100.0, 1.775, 340.0, 0.0, 0.0, -2.0, 23.6800455773636, 10.0, 19.04751108946765, 22.7, 1.0, 0.0], 
actual action is [-2.0, 10], 
sim time next is 3183600.0000, 
raw observation next is [3.0, 100.0, 1.866666666666667, 340.0, 0.0, 0.0, -2.0, 24.00487606385805, 10.0, 19.00922209648088, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.41025641025641024, 1.0, 0.1696969696969697, 0.9444444444444444, 0.0, 0.0, 0.4666666666666667, 0.2400487606385805, 0.0, 0.450461104824044, 0.635, 1.0, 0.0], 
reward next is -0.1200. 
=============================================
[2017-11-01 09:55:16,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  7.20880985e-01   4.11531143e-02   3.57697234e-02   1.22435689e-01
   7.97604322e-02   1.98714649e-15   4.41205645e-16   3.06524918e-16
   2.61613167e-16], sum to 1.0000
[2017-11-01 09:55:16,860] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.0, 100.0, 6.866666666666667, 173.3333333333333, 0.0, 0.0, 11.0, 13.91344951712771, 24.0, 21.10355318606926, 22.7, 1.0, 67.86825179600068], 
actual action is [11.0, 23.5], 
sim time next is 3137100.0000, 
raw observation next is [6.0, 100.0, 7.033333333333333, 171.6666666666667, 0.0, 0.0, 11.0, 12.78785216768273, 23.5, 21.49034801501897, 22.7, 1.0, 65.01691068629196], 
processed observation next is [0.0, 0.30434782608695654, 0.48717948717948717, 1.0, 0.6393939393939394, 0.47685185185185197, 0.0, 0.0, 0.6833333333333333, 0.1278785216768273, 0.675, 0.5745174007509485, 0.635, 1.0, 0.7649048316034349], 
reward next is -0.4464. 
=============================================
[2017-11-01 09:55:17,827] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10500, global step 167911: loss -0.2126
[2017-11-01 09:55:18,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.94089603e-01   9.92624015e-02   9.08093601e-02   1.99246809e-01
   1.16591744e-01   3.23604539e-08   1.42241117e-08   8.31459435e-09
   6.51878507e-09], sum to 1.0000
[2017-11-01 09:55:18,804] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 3.725, 178.3333333333333, 102.75, 688.25, 2.0, 17.52078666291656, 10.0, 21.32694947148319, 22.7, 1.0, 0.0], 
actual action is [2.0, 10], 
sim time next is 3146400.0000, 
raw observation next is [7.0, 100.0, 3.6, 180.0, 103.5, 696.5, 2.0, 17.20949708522602, 10.0, 21.38899932341393, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.5128205128205128, 1.0, 0.32727272727272727, 0.5, 0.27380952380952384, 0.6965, 0.5333333333333333, 0.1720949708522602, 0.0, 0.5694499661706965, 0.635, 1.0, 0.0], 
reward next is -0.0860. 
=============================================
[2017-11-01 09:55:19,159] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168136: loss -2.2565
[2017-11-01 09:55:19,605] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10500, global step 168210: loss -0.7548
[2017-11-01 09:55:19,895] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168258: loss -0.2761
[2017-11-01 09:55:21,431] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168536: loss 2.2907
[2017-11-01 09:55:22,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.85371134e-02   6.69832677e-02   1.04208991e-01   4.69218045e-01
   3.41052622e-01   2.23728140e-18   7.72594085e-19   3.71555469e-19
   2.99208929e-18], sum to 1.0000
[2017-11-01 09:55:22,314] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.1666666666666666, 100.0, 4.85, 295.0, 0.0, 0.0, 5.25, 26.73614326225815, 15.0, 18.59701816429027, 20.8, 0.0, 36.59344628677867], 
actual action is [5.166666666666667, 14.5], 
sim time next is 3203700.0000, 
raw observation next is [0.08333333333333337, 100.0, 4.975, 292.5, 0.0, 0.0, 5.166666666666667, 26.44491303970644, 14.5, 18.71177244291365, 20.8, 0.0, 22.8542982870851], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.3354700854700855, 1.0, 0.4522727272727272, 0.8125, 0.0, 0.0, 0.586111111111111, 0.2644491303970644, 0.225, 0.43558862214568245, 0.54, 0.0, 0.2688740974951188], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:22,417] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168697: loss 0.6450
[2017-11-01 09:55:22,992] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168777: loss 2.8406
[2017-11-01 09:55:26,292] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10500, global step 169371: loss -0.6376
[2017-11-01 09:55:29,715] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-27.80740929]
 [-29.95476532]
 [-35.47837448]
 [-33.30065155]
 [-38.1176033 ]], R is [[-30.25539398]
 [-30.95284081]
 [-31.64331245]
 [-32.32688141]
 [-33.00361252]].
[2017-11-01 09:55:29,732] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10500, global step 170146: loss 11.2144
[2017-11-01 09:55:32,209] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10500, global step 170613: loss 14.6925
[2017-11-01 09:55:32,972] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.51285005e-01   3.90194752e-03   3.13826017e-02   1.18036568e-02
   1.62677234e-03   1.12279409e-34   5.56826881e-36   6.82155285e-36
   6.97111496e-33], sum to 1.0000
[2017-11-01 09:55:33,009] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.416666666666667, 100.0, 4.475, 290.0, 0.0, 0.0, -6.333333333333333, 36.16761833454436, 10.0, 18.37117082476781, 20.8, 0.0, 0.0], 
actual action is [-6.416666666666667, 10], 
sim time next is 3213000.0000, 
raw observation next is [-1.5, 100.0, 4.35, 290.0, 0.0, 0.0, -6.416666666666667, 37.99230205156906, 10.0, 18.27440326048659, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.2948717948717949, 1.0, 0.39545454545454545, 0.8055555555555556, 0.0, 0.0, 0.39305555555555555, 0.3799230205156906, 0.0, 0.4137201630243295, 0.54, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:45,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.98757362e-01   9.02090804e-04   8.71887896e-05   1.61518925e-04
   9.18651567e-05   4.54548818e-27   4.62695858e-28   3.29063114e-28
   2.06493725e-26], sum to 1.0000
[2017-11-01 09:55:45,485] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.166666666666667, 86.24999999999999, 8.033333333333331, 255.0, 112.6666666666667, 816.5833333333333, -7.0, 30.75738638529424, 10.0, 19.54184551257225, 22.0, 1.0, 0.0], 
actual action is [-7.166666666666667, 10], 
sim time next is 3244200.0000, 
raw observation next is [-2.333333333333333, 87.5, 7.866666666666666, 260.0, 112.3333333333333, 815.6666666666666, -7.166666666666667, 30.85959392743491, 10.0, 19.53225866576156, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.27350427350427353, 0.875, 0.7151515151515151, 0.7222222222222222, 0.29717813051146375, 0.8156666666666667, 0.38055555555555554, 0.30859593927434914, 0.0, 0.476612933288078, 0.6, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:49,700] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.96548593e-01   2.17303331e-03   3.00373882e-04   4.73955413e-04
   5.04199648e-04   8.69141406e-25   1.06424818e-25   8.70312211e-26
   5.72785001e-24], sum to 1.0000
[2017-11-01 09:55:49,723] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.5, 7.199999999999999, 280.0, 111.0, 812.0, -7.833333333333333, 30.536531876658, 10.0, 19.54100986624652, 22.0, 1.0, 0.0], 
actual action is [-8.0, 10], 
sim time next is 3245700.0000, 
raw observation next is [-3.166666666666667, 93.75, 7.033333333333333, 285.0, 110.1666666666667, 808.4166666666666, -8.0, 30.53317498394975, 10.0, 19.51956849351362, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.25213675213675213, 0.9375, 0.6393939393939394, 0.7916666666666666, 0.29144620811287486, 0.8084166666666667, 0.36666666666666664, 0.3053317498394975, 0.0, 0.475978424675681, 0.6, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:55:51,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.98016477e-01   1.01665524e-03   4.04052116e-04   2.47384363e-04
   3.15387559e-04   1.04190353e-20   1.47093958e-21   1.63650071e-21
   2.64867627e-19], sum to 1.0000
[2017-11-01 09:55:51,546] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 100.0, 6.2, 310.0, 106.0, 790.5, -8.833333333333332, 27.87847896466426, 10.0, 20.05969729651288, 22.0, 1.0, 0.0], 
actual action is [-9.0, 10], 
sim time next is 3247500.0000, 
raw observation next is [-3.833333333333333, 97.58333333333333, 6.025, 308.3333333333333, 105.1666666666667, 786.9166666666667, -9.0, 27.70826005193095, 10.0, 20.04503851266654, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.23504273504273507, 0.9758333333333333, 0.5477272727272727, 0.8564814814814814, 0.27821869488536166, 0.7869166666666667, 0.35, 0.2770826005193095, 0.0, 0.502251925633327, 0.6, 1.0, 0.0], 
reward next is -0.1385. 
=============================================
[2017-11-01 09:55:52,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.93616223e-01   2.98157637e-03   1.22113700e-03   8.47200339e-04
   1.33401318e-03   2.02049308e-18   3.68858524e-19   2.98710739e-19
   2.07307707e-17], sum to 1.0000
[2017-11-01 09:55:52,279] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.166666666666667, 71.0, 4.449999999999999, 295.0, 90.33333333333333, 713.6666666666666, -7.083333333333333, 25.11624673276388, 10.0, 20.48168406187158, 22.0, 1.0, 0.0], 
actual action is [-7.166666666666667, 10], 
sim time next is 3251700.0000, 
raw observation next is [-2.25, 71.0, 4.625, 297.5, 89.0, 706.75, -7.166666666666667, 24.85213527393058, 10.0, 20.52615162235772, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.27564102564102566, 0.71, 0.42045454545454547, 0.8263888888888888, 0.23544973544973544, 0.70675, 0.38055555555555554, 0.24852135273930578, 0.0, 0.526307581117886, 0.6, 1.0, 0.0], 
reward next is -0.1243. 
=============================================
[2017-11-01 09:55:59,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.63986504e-03   2.75180101e-01   4.96738166e-01   2.32044104e-02
   2.02237442e-01   4.62773100e-21   6.63804969e-22   7.85094871e-22
   1.50684830e-19], sum to 1.0000
[2017-11-01 09:55:59,816] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.0, 67.5, 3.516666666666667, 320.0, 0.0, 0.0, 1.0, 30.26690157819054, 19.0, 19.01550066967031, 22.0, 1.0, 49.70793132185045], 
actual action is [1.0, 18.0], 
sim time next is 3267000.0000, 
raw observation next is [-4.0, 68.0, 3.6, 320.0, 0.0, 0.0, 1.0, 29.99749728456971, 18.0, 19.24779807720068, 22.0, 1.0, 36.85170691334196], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.23076923076923078, 0.68, 0.32727272727272727, 0.8888888888888888, 0.0, 0.0, 0.5166666666666667, 0.29997497284569713, 0.4, 0.46238990386003403, 0.6, 1.0, 0.43354949309814067], 
reward next is -0.3668. 
=============================================
[2017-11-01 09:56:01,603] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.92735550e-15   1.86563784e-03   1.25520851e-03   4.04285936e-04
   9.87060252e-04   2.33802758e-02   5.94492862e-03   2.85955472e-03
   9.63303089e-01], sum to 1.0000
[2017-11-01 09:56:01,688] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.0, 92.0, 5.5, 260.0, 87.66666666666667, 417.1666666666667, -8.0, 33.6497166079433, 10.0, 18.91712111036725, 22.0, 1.0, 0.0], 
actual action is [2.0, 15.0], 
sim time next is 3228300.0000, 
raw observation next is [-3.0, 92.0, 5.550000000000001, 260.0, 89.0, 440.75, 2.0, 30.11413409420972, 15.0, 18.91972107201755, 22.0, 1.0, 59.13837117421659], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.2564102564102564, 0.92, 0.5045454545454546, 0.7222222222222222, 0.23544973544973544, 0.44075, 0.5333333333333333, 0.3011413409420972, 0.25, 0.4459860536008774, 0.6, 1.0, 0.6957455432260775], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:56:02,472] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 174641: loss 71.1392
[2017-11-01 09:56:02,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 174675: loss -20.8955
[2017-11-01 09:56:04,570] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 174900: loss 0.4303
[2017-11-01 09:56:05,506] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.91995692e-01   3.07495566e-03   2.78104469e-03   3.47738183e-04
   1.80068088e-03   1.50319680e-22   2.81581691e-23   1.59736886e-23
   2.30598588e-21], sum to 1.0000
[2017-11-01 09:56:05,543] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-2.666666666666667, 90.0, 7.533333333333333, 270.0, 111.6666666666667, 813.8333333333334, -7.5, 28.46442901543193, 10.0, 19.97539382596311, 22.0, 1.0, 0.0], 
actual action is [-7.666666666666667, 10], 
sim time next is 3245100.0000, 
raw observation next is [-2.833333333333333, 91.25, 7.366666666666665, 275.0, 111.3333333333333, 812.9166666666666, -7.666666666666667, 28.53090247175193, 10.0, 19.95104059719239, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.2606837606837607, 0.9125, 0.6696969696969696, 0.7638888888888888, 0.2945326278659611, 0.8129166666666666, 0.3722222222222222, 0.2853090247175193, 0.0, 0.49755202985961944, 0.6, 1.0, 0.0], 
reward next is -0.1427. 
=============================================
[2017-11-01 09:56:05,704] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175037: loss 1.1062
[2017-11-01 09:56:07,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175285: loss -32.0122
[2017-11-01 09:56:11,754] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175707: loss 16.5656
[2017-11-01 09:56:12,140] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01307855
  0.00349222  0.00126349  0.98216575], sum to 1.0000
[2017-11-01 09:56:12,344] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-11.0, 81.33333333333334, 2.933333333333334, 243.3333333333333, 16.0, 144.3333333333333, -16.0, 33.54155287369776, 10.0, 19.76666601371818, 22.0, 1.0, 0.0], 
actual action is [-6.0, 15.0], 
sim time next is 3311100.0000, 
raw observation next is [-11.0, 82.0, 2.85, 240.0, 23.0, 169.5, -6.0, 32.13441576015341, 15.0, 19.52620908783231, 22.0, 1.0, 74.74182276409154], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.05128205128205128, 0.82, 0.2590909090909091, 0.6666666666666666, 0.06084656084656084, 0.1695, 0.4, 0.3213441576015341, 0.25, 0.4763104543916155, 0.6, 1.0, 0.8793155619304887], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:56:13,169] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11000, global step 175842: loss 0.5516
[2017-11-01 09:56:14,679] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175997: loss -14.3481
[2017-11-01 09:56:14,933] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176019: loss -2.1239
[2017-11-01 09:56:15,510] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11000, global step 176078: loss -10.4353
[2017-11-01 09:56:15,983] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176127: loss -16.5954
[2017-11-01 09:56:18,903] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176428: loss 23.6998
[2017-11-01 09:56:20,144] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176556: loss 15.5853
[2017-11-01 09:56:20,823] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11000, global step 176623: loss 76.7918
[2017-11-01 09:56:26,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.88418400e-01   2.89691845e-03   5.82023384e-03   1.47289349e-04
   2.71717063e-03   5.15949632e-16   9.88048448e-17   3.00309543e-17
   3.91400076e-15], sum to 1.0000
[2017-11-01 09:56:26,358] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.666666666666667, 48.66666666666667, 5.1, 233.3333333333334, 90.16666666666666, 687.0, -7.75, 25.04134949824684, 10.0, 20.86102516741948, 22.0, 1.0, 0.0], 
actual action is [-7.666666666666667, 10], 
sim time next is 3338700.0000, 
raw observation next is [-2.583333333333333, 48.33333333333333, 5.1, 231.6666666666666, 88.58333333333334, 680.5, -7.666666666666667, 25.01073505414462, 10.0, 20.88002297795932, 22.0, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.26709401709401714, 0.4833333333333333, 0.4636363636363636, 0.6435185185185184, 0.23434744268077604, 0.6805, 0.3722222222222222, 0.2501073505414462, 0.0, 0.544001148897966, 0.6, 1.0, 0.0], 
reward next is -0.1251. 
=============================================
[2017-11-01 09:56:30,725] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11000, global step 177740: loss -11.6165
[2017-11-01 09:56:32,615] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11000, global step 177923: loss 0.8884
[2017-11-01 09:56:39,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.92315685e-32   4.01645617e-15   2.34578300e-15   1.27258508e-16
   7.24672008e-15   1.15818866e-02   4.39558597e-03   2.28618341e-03
   9.81736302e-01], sum to 1.0000
[2017-11-01 09:56:39,492] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 65.0, 3.1, 170.0, 0.0, 0.0, 1.0, 13.72495523556879, 30.0, 22.28745710537403, 20.8, 0.0, 44.49842037358293], 
actual action is [1.0, 30], 
sim time next is 3361500.0000, 
raw observation next is [-4.0, 65.0, 3.1, 170.0, 0.0, 0.0, 1.0, 13.66011861416856, 30.0, 22.2881501983142, 20.8, 0.0, 44.49972734008656], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.23076923076923078, 0.65, 0.2818181818181818, 0.4722222222222222, 0.0, 0.0, 0.5166666666666667, 0.1366011861416856, 1.0, 0.6144075099157099, 0.54, 0.0, 0.5235262040010183], 
reward next is -0.2618. 
=============================================
[2017-11-01 09:56:46,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-30.79475403]
 [-30.83742714]
 [-30.13656998]
 [-30.37606812]
 [-30.25442696]], R is [[-31.16117859]
 [-31.11138344]
 [-31.06207466]
 [-31.01328278]
 [-30.965065  ]].
[2017-11-01 09:56:57,451] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.17606196e-24   1.34898398e-10   2.14930539e-11   3.86220439e-12
   3.85877545e-11   1.97598368e-01   3.10353965e-01   4.24515828e-02
   4.49596047e-01], sum to 1.0000
[2017-11-01 09:56:57,529] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 77.0, 3.1, 170.0, 0.0, 0.0, -1.0, 10.97932078981194, 30.0, 22.22226238155187, 20.8, 0.0, 44.64374619653488], 
actual action is [-1.0, 30], 
sim time next is 3378000.0000, 
raw observation next is [-6.0, 77.0, 3.1, 170.0, 0.0, 0.0, -1.0, 10.98986435263544, 30.0, 22.21052102819613, 20.8, 0.0, 44.6470568133427], 
processed observation next is [0.5, 0.08695652173913043, 0.1794871794871795, 0.77, 0.2818181818181818, 0.4722222222222222, 0.0, 0.0, 0.48333333333333334, 0.1098986435263544, 1.0, 0.6105260514098065, 0.54, 0.0, 0.5252594919216789], 
reward next is -0.2626. 
=============================================
[2017-11-01 09:57:02,805] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.35757554e-01   4.83619757e-02   3.18737514e-02   8.93406197e-03
   7.50726983e-02   5.81323444e-12   3.20107916e-12   1.13073635e-12
   7.60738174e-12], sum to 1.0000
[2017-11-01 09:57:02,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 52.0, 6.033333333333334, 230.0, 104.6666666666667, 780.1666666666667, -2.0, 17.1485893612079, 10.0, 21.56522912081286, 22.0, 1.0, 0.0], 
actual action is [-2.0, 10], 
sim time next is 3421500.0000, 
raw observation next is [3.0, 52.75, 6.116666666666667, 230.0, 103.8333333333333, 777.5833333333334, -2.0, 16.92217530518725, 10.0, 21.6402493144891, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.41025641025641024, 0.5275, 0.5560606060606061, 0.6388888888888888, 0.27469135802469125, 0.7775833333333334, 0.4666666666666667, 0.16922175305187248, 0.0, 0.582012465724455, 0.6, 1.0, 0.0], 
reward next is -0.0846. 
=============================================
[2017-11-01 09:57:08,619] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  7.33917892e-01   7.00728521e-02   6.90960363e-02   4.82147336e-02
   7.86985159e-02   2.46929255e-10   1.74498957e-10   6.46447756e-11
   1.26406205e-10], sum to 1.0000
[2017-11-01 09:57:08,737] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.333333333333333, 61.66666666666667, 4.6, 186.6666666666667, 16.16666666666666, 159.5, 2.583333333333333, 9.368958835804342, 15.0, 22.62688245444948, 22.0, 1.0, 53.57100665556541], 
actual action is [-7.333333333333333, 10.0], 
sim time next is 3397500.0000, 
raw observation next is [-2.25, 61.25, 4.6, 187.5, 23.25, 185.75, -7.333333333333333, 10.5274792746657, 10.0, 22.69904065347543, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.30434782608695654, 0.27564102564102566, 0.6125, 0.41818181818181815, 0.5208333333333334, 0.061507936507936505, 0.18575, 0.3777777777777778, 0.10527479274665699, 0.0, 0.6349520326737714, 0.6, 1.0, 0.0], 
reward next is -0.0526. 
=============================================
[2017-11-01 09:57:09,612] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 182207: loss 51.3396
[2017-11-01 09:57:11,271] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 182517: loss 0.4182
[2017-11-01 09:57:12,145] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 182697: loss 45.2922
[2017-11-01 09:57:12,393] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 182748: loss 5.7223
[2017-11-01 09:57:13,304] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 182928: loss 4.7446
[2017-11-01 09:57:16,719] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11500, global step 183596: loss 22.2161
[2017-11-01 09:57:17,439] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11500, global step 183750: loss 5.3579
[2017-11-01 09:57:18,246] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183912: loss -25.6798
[2017-11-01 09:57:18,247] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183913: loss -0.5695
[2017-11-01 09:57:18,690] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184002: loss -16.2258
[2017-11-01 09:57:18,737] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184009: loss -27.1825
[2017-11-01 09:57:20,761] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184355: loss 0.4726
[2017-11-01 09:57:22,864] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184675: loss -27.1609
[2017-11-01 09:57:22,950] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11500, global step 184689: loss -16.5259
[2017-11-01 09:57:28,741] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  6.17088854e-01   4.70260978e-02   5.31965606e-02   1.93312392e-01
   8.93761292e-02   6.79781099e-20   2.52531617e-20   7.22389996e-21
   1.09040551e-19], sum to 1.0000
[2017-11-01 09:57:28,781] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 71.0, 6.2, 220.0, 45.5, 253.0, 4.083333333333333, 35.68473573468452, 18.5, 18.66469123751967, 22.0, 1.0, 12.11289740773873], 
actual action is [4.0, 13.5], 
sim time next is 3485100.0000, 
raw observation next is [-1.0, 71.0, 6.025, 220.0, 52.58333333333334, 277.3333333333334, 4.0, 34.96232863884187, 13.5, 18.65061635449525, 22.0, 1.0, 10.64400566405917], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.3076923076923077, 0.71, 0.5477272727272727, 0.6111111111111112, 0.1391093474426808, 0.27733333333333343, 0.5666666666666667, 0.34962328638841866, 0.175, 0.43253081772476243, 0.6, 1.0, 0.12522359604775493], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:57:30,447] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  6.76761940e-02   2.97610741e-02   5.60063161e-02   5.91849625e-01
   2.54706770e-01   1.52394618e-20   9.34131754e-21   4.55398430e-21
   9.48025496e-19], sum to 1.0000
[2017-11-01 09:57:30,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [2.0, 52.0, 4.875, 277.5, 0.0, 0.0, -3.0, 30.81397600860614, 10.0, 19.30512622464755, 22.0, 1.0, 0.0], 
actual action is [-3.0, 10], 
sim time next is 3522000.0000, 
raw observation next is [2.0, 52.0, 5.133333333333333, 276.6666666666667, 0.0, 0.0, -3.0, 31.67787784502844, 10.0, 19.13052559490053, 22.0, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.38461538461538464, 0.52, 0.4666666666666666, 0.7685185185185186, 0.0, 0.0, 0.45, 0.3167787784502844, 0.0, 0.45652627974502646, 0.6, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:57:30,875] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11500, global step 185974: loss -9.3388
[2017-11-01 09:57:32,188] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11500, global step 186201: loss 16.3910
[2017-11-01 09:57:52,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.88272384e-08   5.43345548e-02   9.61461663e-02   7.23690093e-01
   1.25727788e-01   2.32760681e-06   2.67595419e-06   2.32320713e-06
   9.40719110e-05], sum to 1.0000
[2017-11-01 09:57:52,321] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [0.0, 72.0, 5.7, 273.3333333333333, 0.0, 0.0, 5.0, 16.76938858948501, 25.0, 21.08393629444171, 20.8, 0.0, 57.07212986863803], 
actual action is [5.0, 24.0], 
sim time next is 3531300.0000, 
raw observation next is [0.0, 72.0, 5.7, 271.6666666666667, 0.0, 0.0, 5.0, 15.01943206647923, 24.0, 21.35249965620711, 20.8, 0.0, 51.68725972116846], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.3333333333333333, 0.72, 0.5181818181818182, 0.7546296296296297, 0.0, 0.0, 0.5833333333333334, 0.1501943206647923, 0.7, 0.5676249828103556, 0.54, 0.0, 0.6080854084843348], 
reward next is -0.3040. 
=============================================
[2017-11-01 09:58:02,864] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 190267: loss 1.1017
[2017-11-01 09:58:03,528] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.82563716e-01   2.18989663e-02   2.21908659e-01   3.36568028e-01
   1.37060687e-01   7.31084068e-20   3.18636279e-19   6.92007474e-20
   6.89959724e-19], sum to 1.0000
[2017-11-01 09:58:03,545] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.333333333333334, 70.0, 4.766666666666666, 290.0, 90.0, 466.8333333333333, -11.41666666666667, 30.01311826612378, 10.0, 19.70374988064842, 22.7, 1.0, 0.0], 
actual action is [-11.333333333333334, 10], 
sim time next is 3573900.0000, 
raw observation next is [-6.25, 70.0, 4.85, 290.0, 91.0, 487.75, -11.33333333333333, 31.09859761902566, 10.0, 19.54896912581511, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.17307692307692307, 0.7, 0.44090909090909086, 0.8055555555555556, 0.24074074074074073, 0.48775, 0.31111111111111117, 0.3109859761902566, 0.0, 0.47744845629075544, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:05,089] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 190547: loss -11.0672
[2017-11-01 09:58:07,085] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 190811: loss 35.7349
[2017-11-01 09:58:07,870] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 190883: loss 3.5687
[2017-11-01 09:58:09,562] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191069: loss 40.8708
[2017-11-01 09:58:11,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.22607577e-01   6.98286528e-03   4.50019926e-01   1.78536385e-01
   4.18532640e-02   2.26088938e-26   1.47608596e-25   5.07079482e-26
   1.05256005e-24], sum to 1.0000
[2017-11-01 09:58:11,295] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-1.0, 42.0, 1.5, 300.0, 0.0, 0.0, 4.083333333333333, 20.86099577626295, 24.0, 20.53812838892854, 22.7, 1.0, 65.23019742116391], 
actual action is [4.0, 23.0], 
sim time next is 3607500.0000, 
raw observation next is [-1.0, 42.0, 1.375, 275.0, 0.0, 0.0, 4.0, 19.61117923859901, 23.0, 20.85353925425615, 22.7, 1.0, 62.91783182099583], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.3076923076923077, 0.42, 0.125, 0.7638888888888888, 0.0, 0.0, 0.5666666666666667, 0.1961117923859901, 0.65, 0.5426769627128076, 0.635, 1.0, 0.7402097861293627], 
reward next is -0.4682. 
=============================================
[2017-11-01 09:58:15,185] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191649: loss 87.2508
[2017-11-01 09:58:15,799] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12000, global step 191736: loss 27.9413
[2017-11-01 09:58:16,365] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191809: loss 20.0668
[2017-11-01 09:58:18,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.50956407e-01   2.63542552e-02   4.84032571e-01   2.79555827e-01
   5.91009445e-02   1.88605157e-22   6.54870318e-22   4.38546887e-22
   3.60187599e-21], sum to 1.0000
[2017-11-01 09:58:18,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.5, 42.5, 4.1, 265.0, 86.0, 699.0, -5.583333333333333, 26.52741120380049, 10.0, 20.55635598069124, 22.7, 1.0, 0.0], 
actual action is [-5.5, 10], 
sim time next is 3598500.0000, 
raw observation next is [-0.4166666666666666, 42.58333333333334, 4.016666666666667, 264.1666666666667, 84.08333333333333, 683.6666666666667, -5.5, 26.52529441630842, 10.0, 20.55781169984079, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.32264957264957267, 0.42583333333333345, 0.36515151515151517, 0.7337962962962964, 0.2224426807760141, 0.6836666666666668, 0.4083333333333333, 0.2652529441630842, 0.0, 0.5278905849920396, 0.635, 1.0, 0.0], 
reward next is -0.1326. 
=============================================
[2017-11-01 09:58:19,001] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192175: loss -0.1343
[2017-11-01 09:58:19,558] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12000, global step 192223: loss 15.6788
[2017-11-01 09:58:19,737] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192238: loss 2.9099
[2017-11-01 09:58:20,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.89774239e-01   2.52099335e-02   3.90791565e-01   2.45733127e-01
   4.84911986e-02   1.51295555e-21   7.67241037e-21   2.96276587e-21
   2.61023805e-20], sum to 1.0000
[2017-11-01 09:58:20,711] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-1.333333333333333, 44.66666666666667, 1.7, 260.0, 112.0, 808.0, -6.416666666666667, 27.4273042917403, 10.0, 20.52051391133725, 22.7, 1.0, 0.0], 
actual action is [-6.333333333333333, 10], 
sim time next is 3591900.0000, 
raw observation next is [-1.25, 44.0, 1.65, 260.0, 111.0, 806.0, -6.333333333333333, 27.80182699799517, 10.0, 20.4851112330166, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.30128205128205127, 0.44, 0.15, 0.7222222222222222, 0.29365079365079366, 0.806, 0.3944444444444445, 0.2780182699799517, 0.0, 0.52425556165083, 0.635, 1.0, 0.0], 
reward next is -0.1390. 
=============================================
[2017-11-01 09:58:21,607] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192456: loss -2.8058
[2017-11-01 09:58:21,635] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12000, global step 192457: loss -26.1817
[2017-11-01 09:58:23,649] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192753: loss 2.9064
[2017-11-01 09:58:25,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-23.82787323]
 [-24.08964539]
 [-24.20012474]
 [-24.59126091]
 [-23.81186295]], R is [[-23.8350029 ]
 [-24.10326004]
 [-24.44623566]
 [-24.64063454]
 [-24.67723656]].
[2017-11-01 09:58:31,010] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.03074998e-01   7.33727142e-02   3.22001457e-01   3.95899355e-01
   1.05651461e-01   3.15350843e-16   4.54977395e-16   1.09251707e-15
   1.53232601e-15], sum to 1.0000
[2017-11-01 09:58:31,056] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [8.866666666666667, 25.33333333333334, 3.183333333333334, 171.6666666666667, 0.0, 0.0, 13.93333333333333, 19.89069464681442, 15.0, 21.52019693791328, 21.5, 0.0, 36.77247681897083], 
actual action is [13.866666666666667, 14.0], 
sim time next is 3636900.0000, 
raw observation next is [8.8, 25.5, 3.225, 172.5, 0.0, 0.0, 13.86666666666667, 19.56634908176279, 14.0, 21.53192764353925, 21.5, 0.0, 23.02686684100557], 
processed observation next is [1.0, 0.08695652173913043, 0.558974358974359, 0.255, 0.2931818181818182, 0.4791666666666667, 0.0, 0.0, 0.7311111111111113, 0.1956634908176279, 0.2, 0.5765963821769626, 0.575, 0.0, 0.2709043157765361], 
reward next is -0.1355. 
=============================================
[2017-11-01 09:58:33,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.19638968e-01   5.60720451e-02   1.54626280e-01   2.66583860e-01
   2.03078806e-01   8.80093861e-16   5.27391777e-16   8.87822560e-16
   7.25283343e-16], sum to 1.0000
[2017-11-01 09:58:33,808] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [11.0, 27.5, 4.725, 185.0, 103.5, 688.0, 6.0, 20.75502869206309, 10.0, 21.32482321742822, 21.5, 0.0, 0.0], 
actual action is [6.0, 10.0], 
sim time next is 3664200.0000, 
raw observation next is [11.0, 27.66666666666667, 4.85, 186.6666666666667, 104.3333333333333, 696.3333333333334, 6.0, 20.66183873495999, 10.0, 21.33784575465191, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.6153846153846154, 0.2766666666666667, 0.44090909090909086, 0.5185185185185186, 0.2760141093474426, 0.6963333333333334, 0.6, 0.2066183873495999, 0.0, 0.5668922877325955, 0.575, 0.0, 0.0], 
reward next is -0.0405. 
=============================================
[2017-11-01 09:58:34,037] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12000, global step 194204: loss -3.9168
[2017-11-01 09:58:34,697] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12000, global step 194354: loss 1.8853
[2017-11-01 09:58:37,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.61421371e-01   6.10205010e-02   1.87752843e-01   1.84532031e-01
   1.05273210e-01   2.79140385e-14   2.07240214e-14   3.39887386e-14
   1.61687239e-14], sum to 1.0000
[2017-11-01 09:58:37,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.166666666666667, 57.5, 5.2, 250.0, 47.66666666666667, 403.0000000000001, -0.75, 24.14845080597957, 10.0, 20.33439783280192, 22.7, 1.0, 0.0], 
actual action is [-0.833333333333333, 10], 
sim time next is 3689700.0000, 
raw observation next is [4.083333333333333, 58.25, 5.15, 250.0, 43.58333333333334, 373.25, -0.833333333333333, 24.58183585277535, 10.0, 20.28505231063006, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.438034188034188, 0.5825, 0.4681818181818182, 0.6944444444444444, 0.115299823633157, 0.37325, 0.4861111111111111, 0.2458183585277535, 0.0, 0.514252615531503, 0.635, 1.0, 0.0], 
reward next is -0.1229. 
=============================================
[2017-11-01 09:58:41,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03053473
  0.05378017  0.28884915  0.62683594], sum to 1.0000
[2017-11-01 09:58:41,950] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [8.416666666666666, 29.91666666666666, 3.891666666666667, 184.1666666666667, 11.08333333333334, 144.5, 13.5, 38.47671772257641, 14.0, 19.48247610392991, 21.5, 0.0, 3.279014966513543], 
actual action is [13.416666666666666, 16.0], 
sim time next is 3656400.0000, 
raw observation next is [8.333333333333334, 30.33333333333334, 3.933333333333333, 183.3333333333333, 18.16666666666666, 168.0, 13.41666666666667, 38.41397497253479, 16.0, 19.47806081923085, 21.5, 0.0, 3.032851775084376], 
processed observation next is [1.0, 0.30434782608695654, 0.5470085470085471, 0.3033333333333334, 0.35757575757575755, 0.5092592592592591, 0.04805996472663138, 0.168, 0.7236111111111112, 0.38413974972534787, 0.3, 0.47390304096154257, 0.575, 0.0, 0.03568060911863972], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:44,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  6.88829720e-01   5.98067930e-03   2.67299414e-01   2.17758380e-02
   1.61144212e-02   2.29419359e-33   5.18679609e-33   1.04981005e-32
   9.80742928e-33], sum to 1.0000
[2017-11-01 09:58:44,856] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 70.5, 3.225, 291.6666666666667, 0.0, 0.0, 2.0, 30.91109680680678, 25.5, 18.54848090696333, 21.5, 0.0, 48.57246779719994], 
actual action is [2.0, 20.5], 
sim time next is 3715200.0000, 
raw observation next is [-3.0, 71.0, 3.1, 290.0, 0.0, 0.0, 2.0, 29.4154695532198, 20.5, 18.84007678846083, 21.5, 0.0, 47.19885720843237], 
processed observation next is [0.0, 0.0, 0.2564102564102564, 0.71, 0.2818181818181818, 0.8055555555555556, 0.0, 0.0, 0.5333333333333333, 0.29415469553219803, 0.525, 0.44200383942304156, 0.575, 0.0, 0.5552806730403809], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:58:46,190] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  6.28125906e-01   3.60593498e-02   2.26549894e-01   6.47197291e-02
   4.45450209e-02   1.79693093e-21   2.83768712e-21   3.18709136e-21
   2.19651168e-21], sum to 1.0000
[2017-11-01 09:58:46,262] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [5.666666666666666, 48.0, 6.700000000000001, 243.3333333333334, 89.83333333333333, 716.8333333333333, 0.75, 26.47552419087166, 10.0, 20.13693425756744, 22.7, 1.0, 0.0], 
actual action is [0.6666666666666661, 10], 
sim time next is 3684300.0000, 
raw observation next is [5.583333333333333, 48.25, 6.574999999999999, 244.1666666666666, 88.41666666666667, 710.9166666666667, 0.6666666666666661, 26.35229045132353, 10.0, 20.14691144827798, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.47649572649572647, 0.4825, 0.5977272727272727, 0.6782407407407406, 0.23390652557319225, 0.7109166666666668, 0.5111111111111111, 0.2635229045132353, 0.0, 0.507345572413899, 0.635, 1.0, 0.0], 
reward next is -0.1318. 
=============================================
[2017-11-01 09:58:58,619] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 198367: loss 0.1535
[2017-11-01 09:58:59,558] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 198528: loss 7.9546
[2017-11-01 09:59:00,875] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 198745: loss 1.5817
[2017-11-01 09:59:01,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.83216196e-01   9.55236331e-03   4.67549473e-01   3.25955302e-02
   7.08637619e-03   1.02679981e-23   8.63439184e-24   7.98916357e-24
   1.88356634e-23], sum to 1.0000
[2017-11-01 09:59:01,462] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 75.5, 6.075, 265.0, 0.0, 0.0, 1.0, 23.16444621052691, 21.0, 19.80557011816904, 22.7, 1.0, 73.57087382093141], 
actual action is [1.0, 16.0], 
sim time next is 3741600.0000, 
raw observation next is [-4.0, 75.0, 6.033333333333333, 266.6666666666667, 0.0, 0.0, 1.0, 21.82135389438984, 16.0, 20.15098906027359, 22.7, 1.0, 51.84838678672567], 
processed observation next is [0.0, 0.30434782608695654, 0.23076923076923078, 0.75, 0.5484848484848485, 0.7407407407407408, 0.0, 0.0, 0.5166666666666667, 0.21821353894389842, 0.3, 0.5075494530136796, 0.635, 1.0, 0.6099810210203019], 
reward next is -0.4141. 
=============================================
[2017-11-01 09:59:02,250] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 198951: loss 8.0875
[2017-11-01 09:59:04,602] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199296: loss 11.5870
[2017-11-01 09:59:05,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.89892101e-01   1.27654402e-02   5.21225989e-01   6.83553666e-02
   7.76108308e-03   1.99571664e-23   2.94596981e-23   2.29411354e-23
   5.63070549e-23], sum to 1.0000
[2017-11-01 09:59:05,973] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 65.0, 4.766666666666667, 273.3333333333334, 0.0, 0.0, 2.0, 21.2856942717154, 15.0, 20.96483081764668, 21.5, 0.0, 56.91091691311539], 
actual action is [2.0, 14.0], 
sim time next is 3723900.0000, 
raw observation next is [-3.0, 65.0, 4.808333333333333, 271.6666666666666, 0.0, 0.0, 2.0, 21.42649369052199, 14.0, 20.82858533906059, 21.5, 0.0, 33.35023526830904], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.65, 0.4371212121212121, 0.7546296296296293, 0.0, 0.0, 0.5333333333333333, 0.21426493690521992, 0.2, 0.5414292669530296, 0.575, 0.0, 0.3923557090389299], 
reward next is -0.3640. 
=============================================
[2017-11-01 09:59:09,651] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12500, global step 200067: loss 20.8505
[2017-11-01 09:59:09,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200100: loss 24.9086
[2017-11-01 09:59:10,283] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200163: loss 34.9316
[2017-11-01 09:59:10,965] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200247: loss 15.0469
[2017-11-01 09:59:11,848] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12500, global step 200383: loss -65.9621
[2017-11-01 09:59:12,553] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12500, global step 200478: loss 0.1430
[2017-11-01 09:59:13,443] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200611: loss 110.8023
[2017-11-01 09:59:13,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  4.76900965e-01   8.54462460e-02   2.32270524e-01   1.47928774e-01
   5.74534982e-02   6.70305071e-15   7.35826754e-15   4.09005910e-15
   5.85060988e-15], sum to 1.0000
[2017-11-01 09:59:13,711] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.0, 73.0, 5.833333333333333, 240.0, 111.6666666666667, 777.8333333333334, -8.0, 24.07772324078224, 10.0, 20.49017588962788, 22.7, 1.0, 0.0], 
actual action is [-8.0, 10], 
sim time next is 3753900.0000, 
raw observation next is [-3.0, 72.5, 5.925000000000001, 240.0, 112.0, 782.25, -8.0, 24.02320241602052, 10.0, 20.61752775997811, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.43478260869565216, 0.2564102564102564, 0.725, 0.5386363636363637, 0.6666666666666666, 0.2962962962962963, 0.78225, 0.36666666666666664, 0.2402320241602052, 0.0, 0.5308763879989055, 0.635, 1.0, 0.0], 
reward next is -0.1201. 
=============================================
[2017-11-01 09:59:15,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200945: loss 49.2367
[2017-11-01 09:59:16,653] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 201122: loss 3.9142
[2017-11-01 09:59:20,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.73169637e-01   1.42651927e-02   5.37408888e-01   1.67730913e-01
   7.42534315e-03   2.40355051e-24   2.27299857e-24   3.36882182e-24
   2.51313240e-23], sum to 1.0000
[2017-11-01 09:59:20,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 77.0, 7.199999999999999, 230.0, 0.0, 0.0, 1.0, 22.97482880149812, 30.0, 19.97760033381329, 21.5, 0.0, 52.83659694585268], 
actual action is [1.0, 29.5], 
sim time next is 3807000.0000, 
raw observation next is [-4.0, 77.0, 6.899999999999999, 230.0, 0.0, 0.0, 1.0, 21.81571335345712, 29.5, 20.16694639788469, 21.5, 0.0, 49.58724385639554], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.23076923076923078, 0.77, 0.6272727272727271, 0.6388888888888888, 0.0, 0.0, 0.5166666666666667, 0.2181571335345712, 0.975, 0.5083473198942345, 0.575, 0.0, 0.5833793394870064], 
reward next is -0.6250. 
=============================================
[2017-11-01 09:59:21,139] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12500, global step 201760: loss 26.9330
[2017-11-01 09:59:21,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  5.47601461e-01   1.35368211e-02   3.10939789e-01   1.24167383e-01
   3.75456829e-03   1.08601293e-27   1.02674253e-27   1.39873021e-27
   1.47942404e-26], sum to 1.0000
[2017-11-01 09:59:21,857] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-3.0, 71.0, 7.533333333333333, 238.3333333333333, 0.0, 0.0, 2.0, 25.99794605454985, 19.5, 20.07005243796129, 21.5, 0.0, 41.77413520751315], 
actual action is [2.0, 19.0], 
sim time next is 3801300.0000, 
raw observation next is [-3.0, 71.0, 7.616666666666667, 239.1666666666667, 0.0, 0.0, 2.0, 25.90435741897552, 19.0, 20.13057685961666, 21.5, 0.0, 30.89147130412998], 
processed observation next is [0.0, 1.0, 0.2564102564102564, 0.71, 0.6924242424242425, 0.664351851851852, 0.0, 0.0, 0.5333333333333333, 0.2590435741897552, 0.45, 0.506528842980833, 0.575, 0.0, 0.36342907416623504], 
reward next is -0.5241. 
=============================================
[2017-11-01 09:59:24,066] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12500, global step 202105: loss -8.0631
[2017-11-01 09:59:27,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.29815941e-09   7.71362558e-02   5.97572565e-01   2.90807307e-01
   3.44837867e-02   7.71584165e-15   1.20442571e-14   9.10897876e-15
   1.30798611e-13], sum to 1.0000
[2017-11-01 09:59:27,497] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 74.0, 4.9, 235.0, 0.0, 0.0, 0.5833333333333339, 28.98841985355152, 22.0, 19.46609016868552, 21.5, 0.0, 30.24786058936841], 
actual action is [0.5, 21.5], 
sim time next is 3821700.0000, 
raw observation next is [-4.583333333333334, 74.5, 4.683333333333334, 234.1666666666667, 0.0, 0.0, 0.5, 28.40037631945196, 21.5, 19.45590611408777, 21.5, 0.0, 42.44860483731244], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.2158119658119658, 0.745, 0.4257575757575758, 0.6504629629629631, 0.0, 0.0, 0.5083333333333333, 0.2840037631945196, 0.575, 0.47279530570438855, 0.575, 0.0, 0.49939535102720517], 
reward next is -1.0000. 
=============================================
[2017-11-01 09:59:30,954] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-47.36250687]
 [-46.92244339]
 [-46.6341095 ]
 [-62.75870895]
 [-61.55703354]], R is [[-43.30615616]
 [-43.2492218 ]
 [-43.22305679]
 [-43.28856277]
 [-43.85567856]].
[2017-11-01 09:59:38,396] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  3.06343675e-01   4.18902449e-02   3.50582212e-01   1.47749826e-01
   1.53434038e-01   3.32947620e-18   6.73807575e-19   7.61267139e-19
   1.95085750e-18], sum to 1.0000
[2017-11-01 09:59:38,502] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.0, 71.5, 4.141666666666666, 220.0, 0.0, 0.0, 2.0, 20.97770189275321, 24.5, 20.2709893507326, 21.5, 0.0, 52.0588864907356], 
actual action is [2.0, 23.5], 
sim time next is 3791400.0000, 
raw observation next is [-3.0, 72.0, 4.183333333333334, 220.0, 0.0, 0.0, 2.0, 19.3458512998603, 23.5, 20.54267338394209, 21.5, 0.0, 49.09548359398975], 
processed observation next is [0.0, 0.9130434782608695, 0.2564102564102564, 0.72, 0.3803030303030303, 0.6111111111111112, 0.0, 0.0, 0.5333333333333333, 0.193458512998603, 0.675, 0.5271336691971046, 0.575, 0.0, 0.5775939246351735], 
reward next is -0.5281. 
=============================================
[2017-11-01 09:59:42,338] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.67031914e-01   1.20504230e-01   2.08879307e-01   3.16970855e-01
   1.86613545e-01   7.55833440e-08   3.90184454e-08   1.60040994e-08
   6.98794000e-09], sum to 1.0000
[2017-11-01 09:59:42,403] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 67.33333333333334, 5.5, 233.3333333333333, 99.33333333333333, 641.1666666666667, -8.5, 27.21694876653122, 10.0, 20.28903345760526, 22.7, 1.0, 0.0], 
actual action is [-8.333333333333332, 10], 
sim time next is 3835500.0000, 
raw observation next is [-3.166666666666667, 66.41666666666666, 5.449999999999999, 234.1666666666667, 100.1666666666667, 660.5833333333333, -8.333333333333332, 27.1158890220181, 10.0, 20.35186389024064, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.25213675213675213, 0.6641666666666666, 0.49545454545454537, 0.6504629629629631, 0.2649911816578484, 0.6605833333333333, 0.3611111111111111, 0.27115889022018097, 0.0, 0.517593194512032, 0.635, 1.0, 0.0], 
reward next is -0.1356. 
=============================================
[2017-11-01 09:59:54,159] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 206461: loss 4.2125
[2017-11-01 09:59:54,345] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 206489: loss -32.2199
[2017-11-01 09:59:54,887] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 206554: loss 3.3284
[2017-11-01 09:59:56,829] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 206863: loss 32.7299
[2017-11-01 09:59:57,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207038: loss -37.5290
[2017-11-01 10:00:01,996] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207513: loss -3.4988
[2017-11-01 10:00:05,089] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207948: loss 0.5356
[2017-11-01 10:00:05,250] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13000, global step 207975: loss 6.7728
[2017-11-01 10:00:06,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208145: loss 1.0002
[2017-11-01 10:00:06,176] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.73498225e-02   1.03438772e-01   1.03383541e-01   3.98869783e-01
   2.96958089e-01   3.26317986e-14   3.68881968e-14   8.64762109e-15
   3.75543848e-14], sum to 1.0000
[2017-11-01 10:00:06,230] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 47.33333333333333, 4.016666666666666, 167.5, 119.0833333333333, 832.9166666666666, -11.0, 32.45010573291742, 10.0, 19.84577621254976, 22.7, 1.0, 0.0], 
actual action is [-11.0, 10], 
sim time next is 3933000.0000, 
raw observation next is [-6.0, 47.0, 4.1, 195.0, 119.0, 835.0, -11.0, 32.84330355350685, 10.0, 19.77316512725895, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.1794871794871795, 0.47, 0.3727272727272727, 0.5416666666666666, 0.3148148148148148, 0.835, 0.31666666666666665, 0.3284330355350685, 0.0, 0.48865825636294746, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:06,312] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13000, global step 208177: loss -80.9065
[2017-11-01 10:00:06,622] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-48.02880859]
 [-48.04343033]
 [-48.93278503]
 [-48.59734344]
 [-48.8132019 ]], R is [[-47.25743484]
 [-47.78486252]
 [-48.30701447]
 [-48.82394409]
 [-49.3357048 ]].
[2017-11-01 10:00:06,966] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208292: loss 4.1121
[2017-11-01 10:00:08,665] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13000, global step 208547: loss -8.6334
[2017-11-01 10:00:10,477] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208864: loss 2.2966
[2017-11-01 10:00:11,723] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 209069: loss 95.9860
[2017-11-01 10:00:13,309] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13000, global step 209315: loss 3.2309
[2017-11-01 10:00:18,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.61390810e-05   1.14319719e-01   3.25954914e-01   4.96567070e-01
   6.31121546e-02   9.78284331e-23   1.55719918e-22   2.00486680e-23
   4.75510349e-21], sum to 1.0000
[2017-11-01 10:00:18,237] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-6.583333333333334, 43.33333333333333, 3.308333333333334, 360.0, 0.0, 0.0, -11.5, 29.26767214099367, 10.0, 20.84641449222819, 22.7, 1.0, 0.0], 
actual action is [-11.583333333333334, 10], 
sim time next is 3958800.0000, 
raw observation next is [-6.666666666666666, 43.66666666666667, 3.266666666666667, 360.0, 0.0, 0.0, -11.58333333333333, 32.40533378664263, 10.0, 20.54833313350364, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.1623931623931624, 0.4366666666666667, 0.296969696969697, 1.0, 0.0, 0.0, 0.3069444444444445, 0.3240533378664263, 0.0, 0.527416656675182, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:18,641] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13000, global step 210242: loss -2.9353
[2017-11-01 10:00:26,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-52.76734924]
 [-52.76968765]
 [-52.07358551]
 [-53.44655228]
 [-51.84827805]], R is [[-53.13570404]
 [-52.92553329]
 [-52.82219315]
 [-52.43439484]
 [-52.03642273]].
[2017-11-01 10:00:29,479] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.46019489e-01   8.49128813e-02   4.44843829e-01   3.13885838e-01
   1.03379488e-02   1.63520351e-31   3.35030842e-31   4.25554140e-32
   5.20172613e-30], sum to 1.0000
[2017-11-01 10:00:29,626] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-13.0, 68.0, 2.416666666666667, 10.0, 0.0, 0.0, -8.0, 30.157570092492, 24.5, 19.3429448296228, 21.5, 0.0, 47.31815608371918], 
actual action is [-8.0, 24.0], 
sim time next is 3993300.0000, 
raw observation next is [-13.0, 67.5, 2.325, 10.0, 0.0, 0.0, -8.0, 30.16325985707292, 24.0, 19.33498981534041, 21.5, 0.0, 46.9951492910322], 
processed observation next is [0.5, 0.21739130434782608, 0.0, 0.675, 0.2113636363636364, 0.027777777777777776, 0.0, 0.0, 0.36666666666666664, 0.3016325985707292, 0.7, 0.46674949076702055, 0.575, 0.0, 0.5528841093062612], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:32,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  2.62911003e-02   2.06972301e-01   5.44617534e-01   2.13425040e-01
   8.69399495e-03   4.82051802e-31   1.07517277e-30   1.63430296e-31
   2.44223264e-29], sum to 1.0000
[2017-11-01 10:00:32,722] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.25, 64.5, 2.975, 265.0, 0.0, 0.0, -7.16666666666667, 30.43478297525379, 22.0, 19.52202909247562, 21.5, 0.0, 42.01937933071013], 
actual action is [-7.25, 21.0], 
sim time next is 3990000.0000, 
raw observation next is [-12.33333333333333, 65.0, 2.933333333333334, 236.6666666666667, 0.0, 0.0, -7.25, 30.31200796584942, 21.0, 19.45277639088213, 21.5, 0.0, 49.09419099318033], 
processed observation next is [0.5, 0.17391304347826086, 0.01709401709401717, 0.65, 0.2666666666666667, 0.6574074074074076, 0.0, 0.0, 0.37916666666666665, 0.3031200796584942, 0.55, 0.4726388195441064, 0.575, 0.0, 0.5775787175668273], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:00:45,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.36943907e-01   3.99612039e-01   1.97279707e-01   2.04463437e-01
   6.17009662e-02   2.98902645e-19   7.33642150e-19   7.13148078e-20
   5.10783304e-19], sum to 1.0000
[2017-11-01 10:00:45,990] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.333333333333333, 37.5, 2.183333333333334, 108.3333333333333, 118.6666666666667, 824.3333333333334, -1.5, 25.43540356643951, 15.0, 20.90529640150177, 22.7, 1.0, 8.631022341363554], 
actual action is [-1.333333333333333, 14.0], 
sim time next is 4017300.0000, 
raw observation next is [-6.166666666666667, 37.25, 2.141666666666667, 104.1666666666667, 118.5833333333333, 826.4166666666667, -1.333333333333333, 25.37613219192412, 14.0, 20.91995523892647, 22.7, 1.0, 8.15189923001929], 
processed observation next is [0.5, 0.4782608695652174, 0.1752136752136752, 0.3725, 0.19469696969696973, 0.28935185185185197, 0.3137125220458553, 0.8264166666666667, 0.4777777777777778, 0.2537613219192412, 0.2, 0.5459977619463234, 0.635, 1.0, 0.09590469682375634], 
reward next is -0.1748. 
=============================================
[2017-11-01 10:00:46,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.28647968e-01   4.45232123e-01   1.89712048e-01   1.82049409e-01
   5.43583892e-02   3.40377352e-19   1.01948708e-18   9.76820687e-20
   8.50229070e-19], sum to 1.0000
[2017-11-01 10:00:46,238] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.25, 26.75, 0.375, 12.5, 111.5, 821.0, 1.666666666666667, 28.84923482953299, 16.0, 20.14360462777828, 22.7, 1.0, 3.985183264368691], 
actual action is [1.75, 11.0], 
sim time next is 4024200.0000, 
raw observation next is [-3.166666666666667, 26.5, 0.2499999999999999, 8.333333333333332, 110.6666666666667, 818.0, 1.75, 28.57192111980819, 11.0, 20.16930255585644, 22.7, 1.0, 3.695939414504566], 
processed observation next is [0.5, 0.5652173913043478, 0.25213675213675213, 0.265, 0.022727272727272717, 0.023148148148148143, 0.2927689594356262, 0.818, 0.5291666666666667, 0.2857192111980819, 0.05, 0.508465127792822, 0.635, 1.0, 0.043481640170641954], 
reward next is -0.1646. 
=============================================
[2017-11-01 10:00:54,331] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13500, global step 214648: loss -73.3682
[2017-11-01 10:00:55,091] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13500, global step 214762: loss -2.6670
[2017-11-01 10:00:55,198] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13500, global step 214781: loss 1.3377
[2017-11-01 10:00:57,883] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13500, global step 215128: loss 3.7277
[2017-11-01 10:01:00,674] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13500, global step 215481: loss -12.3121
[2017-11-01 10:01:01,360] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13500, global step 215582: loss 24.8985
[2017-11-01 10:01:01,614] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13500, global step 215603: loss -0.7640
[2017-11-01 10:01:01,834] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.22456389e-17   1.27706095e-03   3.40999832e-04   1.64057955e-03
   4.12229099e-04   1.90391261e-02   1.22569561e-01   2.00694744e-02
   8.34650993e-01], sum to 1.0000
[2017-11-01 10:01:01,904] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.583333333333333, 25.16666666666667, 2.308333333333334, 61.66666666666667, 18.33333333333333, 176.9166666666667, -7.5, 28.21233385043775, 10.0, 20.75287586245065, 22.7, 1.0, 0.0], 
actual action is [2.416666666666667, 15.0], 
sim time next is 4038000.0000, 
raw observation next is [-2.666666666666667, 25.33333333333333, 2.266666666666667, 63.33333333333333, 16.66666666666667, 160.8333333333333, 2.416666666666667, 26.52719975676216, 15.0, 20.66997842956576, 22.7, 1.0, 40.83420875673235], 
processed observation next is [0.5, 0.7391304347826086, 0.2649572649572649, 0.2533333333333333, 0.20606060606060608, 0.1759259259259259, 0.044091710758377436, 0.16083333333333327, 0.5402777777777777, 0.2652719975676216, 0.25, 0.5334989214782879, 0.635, 1.0, 0.48040245596155706], 
reward next is -0.3728. 
=============================================
[2017-11-01 10:01:02,659] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13500, global step 215766: loss 7.3181
[2017-11-01 10:01:04,284] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13500, global step 216003: loss 167.3261
[2017-11-01 10:01:05,345] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13500, global step 216131: loss -9.2734
[2017-11-01 10:01:07,746] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13500, global step 216405: loss -21.9690
[2017-11-01 10:01:09,330] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13500, global step 216606: loss 33.5717
[2017-11-01 10:01:09,713] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13500, global step 216662: loss 9.0019
[2017-11-01 10:01:11,175] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13500, global step 216871: loss 14.0230
[2017-11-01 10:01:12,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  2.45584816e-01   3.23416650e-01   1.35852650e-01   1.98541045e-01
   9.66048092e-02   3.41345179e-28   9.14100567e-28   1.26234741e-28
   4.68202313e-27], sum to 1.0000
[2017-11-01 10:01:12,987] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-6.0, 37.0, 2.6, 106.6666666666667, 0.0, 0.0, -1.0, 27.01070036884966, 27.0, 20.01734045786477, 21.5, 0.0, 47.23091780534809], 
actual action is [-1.0, 25.0], 
sim time next is 4059000.0000, 
raw observation next is [-6.0, 37.0, 2.6, 110.0, 0.0, 0.0, -1.0, 26.21255197373084, 25.0, 20.12543929638285, 21.5, 0.0, 46.64132533198763], 
processed observation next is [0.5, 1.0, 0.1794871794871795, 0.37, 0.23636363636363636, 0.3055555555555556, 0.0, 0.0, 0.48333333333333334, 0.2621255197373084, 0.75, 0.5062719648191425, 0.575, 0.0, 0.5487214744939721], 
reward next is -0.6180. 
=============================================
[2017-11-01 10:01:15,877] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13500, global step 217481: loss 2.4980
[2017-11-01 10:01:21,477] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13500, global step 218197: loss 25.0410
[2017-11-01 10:01:21,564] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.80625373e-01   3.06649268e-01   6.36758432e-02   1.93817824e-01
   1.55231655e-01   1.10032348e-11   1.42866873e-11   5.53100057e-12
   2.69389979e-11], sum to 1.0000
[2017-11-01 10:01:21,642] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.666666666666667, 28.33333333333334, 2.766666666666667, 183.3333333333333, 120.1666666666667, 836.8333333333334, -3.5, 21.1756733970431, 10.0, 21.66277266955574, 22.7, 1.0, 0.0], 
actual action is [-3.333333333333333, 10], 
sim time next is 4105500.0000, 
raw observation next is [1.833333333333333, 28.41666666666666, 2.808333333333334, 194.1666666666667, 120.0833333333333, 838.9166666666666, -3.333333333333333, 21.27020902959759, 10.0, 21.61123071973975, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.3803418803418803, 0.2841666666666666, 0.25530303030303036, 0.539351851851852, 0.31768077601410927, 0.8389166666666666, 0.4444444444444445, 0.21270209029597592, 0.0, 0.5805615359869876, 0.635, 1.0, 0.0], 
reward next is -0.1064. 
=============================================
[2017-11-01 10:01:24,289] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.66330338e-01   3.67076874e-01   7.61539042e-02   2.35136747e-01
   1.55302107e-01   1.71100341e-24   6.78679677e-24   1.18102526e-24
   6.88124945e-23], sum to 1.0000
[2017-11-01 10:01:24,352] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 36.66666666666666, 2.6, 133.3333333333333, 0.0, 0.0, 1.0, 25.03641117268453, 30.0, 20.00309060355426, 21.5, 0.0, 46.5494978621315], 
actual action is [1.0, 29.5], 
sim time next is 4081500.0000, 
raw observation next is [-4.0, 37.0, 2.6, 132.5, 0.0, 0.0, 1.0, 24.29639271214675, 29.5, 20.10018549277738, 21.5, 0.0, 46.05040908071535], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.23076923076923078, 0.37, 0.23636363636363636, 0.3680555555555556, 0.0, 0.0, 0.5166666666666667, 0.24296392712146753, 0.975, 0.505009274638869, 0.575, 0.0, 0.5417695185966511], 
reward next is -0.6208. 
=============================================
[2017-11-01 10:01:28,525] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.26316437e-01   2.56358176e-01   8.67205113e-02   2.26107597e-01
   2.04497293e-01   3.67480890e-09   3.69378239e-09   1.72121850e-09
   2.59838506e-09], sum to 1.0000
[2017-11-01 10:01:28,536] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [4.0, 35.0, 3.35, 185.0, 93.66666666666666, 609.0, -1.0, 13.52125912709077, 10.0, 22.72213082534408, 22.7, 1.0, 0.0], 
actual action is [-1.0, 10], 
sim time next is 4118100.0000, 
raw observation next is [4.0, 35.0, 3.475, 182.5, 93.58333333333334, 587.5, -1.0, 13.44245833296326, 10.0, 22.74160471641882, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.4358974358974359, 0.35, 0.3159090909090909, 0.5069444444444444, 0.24757495590828926, 0.5875, 0.48333333333333334, 0.1344245833296326, 0.0, 0.637080235820941, 0.635, 1.0, 0.0], 
reward next is -0.0672. 
=============================================
[2017-11-01 10:01:41,517] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  6.32850155e-02   6.74035624e-02   4.35162127e-01   2.90748715e-01
   1.43400565e-01   2.09902156e-25   4.11093931e-25   1.82650216e-25
   7.00851559e-24], sum to 1.0000
[2017-11-01 10:01:41,575] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [0.08333333333333337, 42.75, 3.016666666666667, 336.6666666666666, 0.0, 0.0, 5.166666666666667, 22.44379088232587, 12.5, 20.67187877256562, 21.5, 0.0, 26.07831305994235], 
actual action is [5.083333333333333, 12.0], 
sim time next is 4143600.0000, 
raw observation next is [0.0, 43.0, 3.1, 340.0, 0.0, 0.0, 5.083333333333333, 22.67590351085169, 12.0, 20.69878298316407, 21.5, 0.0, 24.86114101296703], 
processed observation next is [0.6666666666666666, 1.0, 0.3333333333333333, 0.43, 0.2818181818181818, 0.9444444444444444, 0.0, 0.0, 0.5847222222222223, 0.2267590351085169, 0.1, 0.5349391491582034, 0.575, 0.0, 0.29248401191725915], 
reward next is -0.3465. 
=============================================
[2017-11-01 10:01:44,111] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.95796543e-01   2.10880771e-01   6.49659783e-02   2.75481403e-01
   1.52875289e-01   2.61029432e-17   3.19405437e-17   1.03551871e-17
   8.62095377e-17], sum to 1.0000
[2017-11-01 10:01:44,185] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [0.3333333333333333, 31.66666666666667, 2.1, 316.6666666666667, 118.8333333333333, 826.1666666666666, -4.833333333333333, 33.24084739261311, 10.0, 19.89396554249691, 22.7, 1.0, 0.0], 
actual action is [-4.666666666666667, 10], 
sim time next is 4189500.0000, 
raw observation next is [0.5, 31.25, 2.1, 315.0, 118.75, 828.25, -4.666666666666667, 33.58884198248401, 10.0, 19.92824954892822, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.34615384615384615, 0.3125, 0.19090909090909092, 0.875, 0.31415343915343913, 0.82825, 0.4222222222222222, 0.33588841982484013, 0.0, 0.49641247744641104, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:01:48,271] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.20920315e-10   2.75736637e-02   4.70577925e-02   8.85236859e-01
   4.01316881e-02   1.16485981e-17   7.39343693e-17   3.44435856e-17
   6.37894710e-15], sum to 1.0000
[2017-11-01 10:01:48,330] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-5.0, 50.66666666666667, 3.100000000000001, 343.3333333333334, 0.0, 0.0, 0.0, 27.66490904389173, 24.5, 19.61150520492142, 21.5, 0.0, 46.00196258629666], 
actual action is [0.0, 24.0], 
sim time next is 4173900.0000, 
raw observation next is [-5.0, 51.08333333333333, 2.975, 344.1666666666666, 0.0, 0.0, 0.0, 27.36861486316128, 24.0, 19.66646232474238, 21.5, 0.0, 45.87872759263323], 
processed observation next is [0.8333333333333334, 0.30434782608695654, 0.20512820512820512, 0.5108333333333333, 0.27045454545454545, 0.9560185185185183, 0.0, 0.0, 0.5, 0.2736861486316128, 0.7, 0.483323116237119, 0.575, 0.0, 0.5397497363839204], 
reward next is -0.7283. 
=============================================
[2017-11-01 10:01:48,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.73148252e-02   2.16475166e-02   1.13775030e-01   7.93935776e-01
   5.33269122e-02   3.87903295e-29   7.73960948e-29   5.06894891e-29
   3.72676342e-27], sum to 1.0000
[2017-11-01 10:01:48,506] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.0, 52.66666666666667, 2.433333333333334, 350.0, 0.0, 0.0, 1.0, 26.60177816477333, 27.0, 19.62806359976473, 21.5, 0.0, 45.04599653709005], 
actual action is [1.0, 26.5], 
sim time next is 4166700.0000, 
raw observation next is [-4.0, 52.33333333333333, 2.516666666666667, 347.5, 0.0, 0.0, 1.0, 26.24362841399958, 26.5, 19.68679450015282, 21.5, 0.0, 45.01342441781839], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.23076923076923078, 0.5233333333333333, 0.22878787878787882, 0.9652777777777778, 0.0, 0.0, 0.5166666666666667, 0.2624362841399958, 0.825, 0.48433972500764105, 0.575, 0.0, 0.5295696990331575], 
reward next is -0.7181. 
=============================================
[2017-11-01 10:01:48,553] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14000, global step 222193: loss 103.1074
[2017-11-01 10:01:50,015] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.94766641e-01   1.96584955e-01   1.65657371e-01   2.84953445e-01
   1.58037603e-01   3.89229399e-10   3.54654389e-10   1.55503097e-10
   2.35166359e-10], sum to 1.0000
[2017-11-01 10:01:50,035] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.0, 36.0, 1.0, 60.00000000000001, 34.66666666666666, 120.3333333333333, -2.0, 19.31649281991025, 10.0, 21.81962437354243, 22.7, 1.0, 0.0], 
actual action is [-2.0, 10], 
sim time next is 4123500.0000, 
raw observation next is [3.0, 35.75, 0.8749999999999999, 52.49999999999999, 28.83333333333334, 88.66666666666669, -2.0, 19.88761035656058, 10.0, 21.74088587416604, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.41025641025641024, 0.3575, 0.07954545454545453, 0.14583333333333331, 0.07627865961199295, 0.08866666666666669, 0.4666666666666667, 0.19887610356560578, 0.0, 0.587044293708302, 0.635, 1.0, 0.0], 
reward next is -0.0994. 
=============================================
[2017-11-01 10:01:53,706] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14000, global step 222757: loss -162.9438
[2017-11-01 10:01:54,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.31171376e-01   2.62038320e-01   7.51738176e-02   3.94267499e-01
   1.37349010e-01   3.06631329e-21   4.34927446e-21   2.23212911e-21
   2.63285256e-20], sum to 1.0000
[2017-11-01 10:01:54,453] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-0.6666666666666667, 34.16666666666667, 2.1, 326.6666666666667, 117.3333333333333, 806.0, 4.166666666666667, 24.451426824639, 19.0, 20.30179345305909, 22.7, 1.0, 37.26403781577212], 
actual action is [4.333333333333333, 18.5], 
sim time next is 4187700.0000, 
raw observation next is [-0.5, 33.75, 2.1, 325.0, 117.75, 810.0, 4.333333333333333, 23.35949943957029, 18.5, 20.597396058042, 22.7, 1.0, 27.51158237223808], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.32051282051282054, 0.3375, 0.19090909090909092, 0.9027777777777778, 0.3115079365079365, 0.81, 0.5722222222222223, 0.2335949943957029, 0.425, 0.5298698029021001, 0.635, 1.0, 0.3236656749675068], 
reward next is -0.2786. 
=============================================
[2017-11-01 10:01:55,517] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14000, global step 222939: loss 41.5507
[2017-11-01 10:01:57,288] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14000, global step 223103: loss -6.6959
[2017-11-01 10:01:59,606] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14000, global step 223352: loss 9.7097
[2017-11-01 10:02:00,612] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14000, global step 223452: loss -7.5421
[2017-11-01 10:02:01,189] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14000, global step 223499: loss -13.9896
[2017-11-01 10:02:04,603] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14000, global step 223901: loss 10.4053
[2017-11-01 10:02:08,412] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14000, global step 224225: loss 50.4279
[2017-11-01 10:02:09,526] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14000, global step 224340: loss 0.0376
[2017-11-01 10:02:09,764] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14000, global step 224369: loss -1.4096
[2017-11-01 10:02:09,781] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-41.09863281]
 [-40.54790115]
 [-40.79296494]
 [-40.69034958]
 [-40.46763229]], R is [[-40.13137817]
 [-39.84363556]
 [-39.56337357]
 [-39.29074478]
 [-39.02592468]].
[2017-11-01 10:02:13,117] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14000, global step 224783: loss 25.3650
[2017-11-01 10:02:14,285] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14000, global step 224921: loss -13.9154
[2017-11-01 10:02:14,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14000, global step 224928: loss 1.9445
[2017-11-01 10:02:16,634] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-24.18759537]
 [-24.99037933]
 [-24.25542068]
 [-23.99804688]
 [-23.9206295 ]], R is [[-24.42863464]
 [-24.25774574]
 [-24.092062  ]
 [-23.93270111]
 [-23.7870369 ]].
[2017-11-01 10:02:19,103] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14000, global step 225524: loss -29.3319
[2017-11-01 10:02:27,245] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14000, global step 226584: loss 18.4809
[2017-11-01 10:02:30,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-19.93163681]
 [-19.67835045]
 [-19.45516968]
 [-19.69187164]
 [-20.31521988]], R is [[-19.69611168]
 [-19.61179733]
 [-19.52842331]
 [-19.44593048]
 [-19.36433792]].
[2017-11-01 10:02:32,668] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.24692647e-17   1.04354799e-03   1.25186780e-04   3.97915574e-04
   1.73660892e-03   5.67657873e-02   6.35783374e-01   1.79358888e-02
   2.86211699e-01], sum to 1.0000
[2017-11-01 10:02:32,759] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.3, 42.25, 3.35, 247.5, 0.0, 0.0, -3.666666666666667, 29.60375035691078, 10.0, 20.62176092426517, 22.7, 1.0, 0.0], 
actual action is [6.3, 11.0], 
sim time next is 4216800.0000, 
raw observation next is [1.266666666666667, 42.33333333333334, 3.333333333333334, 246.6666666666667, 0.0, 0.0, 6.3, 27.76000095646447, 11.0, 20.52841726408938, 21.5, 0.0, 47.80426779761529], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.36581196581196584, 0.42333333333333345, 0.3030303030303031, 0.6851851851851853, 0.0, 0.0, 0.605, 0.2776000095646447, 0.05, 0.526420863204469, 0.575, 0.0, 0.5624031505601799], 
reward next is -0.5241. 
=============================================
[2017-11-01 10:02:44,530] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   3.35273890e-35   4.72263982e-35   1.26766385e-33
   5.04765310e-34   5.48045384e-03   8.76356423e-01   1.08603726e-03
   1.17077179e-01], sum to 1.0000
[2017-11-01 10:02:44,553] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [4.566666666666666, 75.41666666666666, 5.216666666666667, 220.0, 0.0, 0.0, 9.6, 40.3268194865332, 13.5, 18.82584521267393, 21.5, 0.0, 2.437039005893057], 
actual action is [9.566666666666666, 14.5], 
sim time next is 4315200.0000, 
raw observation next is [4.533333333333333, 75.33333333333334, 5.233333333333333, 220.0, 0.0, 0.0, 9.566666666666666, 40.56909192237551, 14.5, 18.80179371409473, 21.5, 0.0, 2.30268223193202], 
processed observation next is [1.0, 0.9565217391304348, 0.44957264957264953, 0.7533333333333334, 0.47575757575757577, 0.6111111111111112, 0.0, 0.0, 0.6594444444444444, 0.4056909192237551, 0.225, 0.4400896857047366, 0.575, 0.0, 0.027090379199200237], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:02:46,610] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  5.23480922e-02   2.70602107e-02   4.66658890e-01   3.06472301e-01
   1.47460446e-01   5.92098997e-31   9.47815652e-30   8.31360151e-32
   1.20126730e-30], sum to 1.0000
[2017-11-01 10:02:46,644] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [6.083333333333333, 66.91666666666666, 5.908333333333333, 234.1666666666667, 0.0, 0.0, 1.1, 30.26410225461144, 10.0, 20.4897942394899, 22.7, 1.0, 0.0], 
actual action is [1.083333333333333, 10], 
sim time next is 4300800.0000, 
raw observation next is [6.066666666666666, 67.33333333333334, 5.866666666666667, 233.3333333333333, 0.0, 0.0, 1.083333333333333, 30.56656197242173, 10.0, 20.44542379731994, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.4888888888888889, 0.6733333333333335, 0.5333333333333333, 0.648148148148148, 0.0, 0.0, 0.5180555555555555, 0.3056656197242173, 0.0, 0.522271189865997, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:02:47,074] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 229926: loss 0.5576
[2017-11-01 10:02:48,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  3.19215818e-04   4.05240618e-03   3.60382110e-01   5.24608970e-01
   1.10637240e-01   4.90735278e-36   3.12938935e-34   4.75101747e-37
   3.63626550e-35], sum to 1.0000
[2017-11-01 10:02:48,201] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [3.266666666666667, 71.33333333333333, 4.508333333333333, 208.3333333333333, 0.0, 0.0, -1.7, 37.84608542057018, 10.0, 19.18639307487663, 21.5, 0.0, 0.0], 
actual action is [-1.733333333333333, 10], 
sim time next is 4342200.0000, 
raw observation next is [3.233333333333333, 71.66666666666667, 4.416666666666666, 206.6666666666667, 0.0, 0.0, -1.733333333333333, 38.84799849998698, 10.0, 19.05953714740809, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.41623931623931626, 0.7166666666666667, 0.40151515151515144, 0.5740740740740742, 0.0, 0.0, 0.4711111111111111, 0.3884799849998698, 0.0, 0.4529768573704045, 0.575, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:02:50,002] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 230513: loss 367.5531
[2017-11-01 10:02:50,431] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 230602: loss 236.9229
[2017-11-01 10:02:53,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.36617213e-01   1.57327041e-01   2.93340921e-01   2.02487186e-01
   2.10227519e-01   4.02270217e-08   7.22054239e-08   1.15344703e-08
   8.87880613e-09], sum to 1.0000
[2017-11-01 10:02:53,519] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [14.4, 29.5, 3.6, 225.0, 119.5, 834.25, 9.2, 16.4703000344984, 10.0, 22.73829136223054, 22.7, 1.0, 0.0], 
actual action is [9.4, 10], 
sim time next is 4362600.0000, 
raw observation next is [14.6, 29.0, 3.6, 226.6666666666667, 119.3333333333333, 836.3333333333334, 9.4, 16.19185068732597, 10.0, 22.77742327746105, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.7076923076923077, 0.29, 0.32727272727272727, 0.6296296296296298, 0.3156966490299823, 0.8363333333333334, 0.6566666666666666, 0.1619185068732597, 0.0, 0.6388711638730525, 0.635, 1.0, 0.0], 
reward next is -0.0810. 
=============================================
[2017-11-01 10:02:53,654] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 231167: loss 106.5949
[2017-11-01 10:02:54,778] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14500, global step 231345: loss 209.2861
[2017-11-01 10:02:55,190] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 231406: loss 70.0686
[2017-11-01 10:02:55,633] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.43315925e-03   4.62017767e-03   7.71842420e-01   1.64776653e-01
   5.43276258e-02   4.11242526e-32   2.30550911e-30   7.03209594e-33
   1.78472751e-32], sum to 1.0000
[2017-11-01 10:02:55,657] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 231510: loss 65.4546
[2017-11-01 10:02:55,659] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [4.5, 72.0, 5.7, 210.0, 0.0, 0.0, 9.475000000000001, 28.18149732116795, 11.0, 19.97797868818003, 21.5, 0.0, 19.47925280578471], 
actual action is [-0.5, 10.0], 
sim time next is 4327500.0000, 
raw observation next is [4.458333333333333, 71.91666666666667, 5.691666666666666, 210.8333333333333, 0.0, 0.0, -0.5, 29.68647280194913, 10.0, 19.95620525230287, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.4476495726495726, 0.7191666666666667, 0.5174242424242425, 0.585648148148148, 0.0, 0.0, 0.49166666666666664, 0.2968647280194913, 0.0, 0.49781026261514344, 0.575, 0.0, 0.0], 
reward next is -0.3859. 
=============================================
[2017-11-01 10:02:55,810] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 231542: loss 103.2553
[2017-11-01 10:03:01,298] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 232532: loss 39.7968
[2017-11-01 10:03:02,144] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 232678: loss 84.0555
[2017-11-01 10:03:02,566] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 232754: loss 38.7614
[2017-11-01 10:03:02,668] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14500, global step 232773: loss 38.3865
[2017-11-01 10:03:03,058] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.02918364e-01   3.06921098e-02   6.06928587e-01   1.24511272e-01
   1.34949625e-01   4.89678463e-19   2.87155460e-18   6.44871686e-20
   1.67261891e-19], sum to 1.0000
[2017-11-01 10:03:03,070] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.5, 43.0, 5.7, 251.6666666666667, 6.000000000000001, 0.0, 7.550000000000001, 12.70621336073946, 10.0, 21.99270712462578, 22.7, 1.0, 0.0], 
actual action is [7.5, 10], 
sim time next is 4384500.0000, 
raw observation next is [12.45, 43.5, 5.649999999999999, 250.8333333333333, 0.0, 0.0, 7.5, 12.80297337184043, 10.0, 21.95293480334211, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.6525641025641026, 0.435, 0.5136363636363636, 0.6967592592592591, 0.0, 0.0, 0.625, 0.12802973371840431, 0.0, 0.5976467401671055, 0.635, 1.0, 0.0], 
reward next is -0.0640. 
=============================================
[2017-11-01 10:03:03,320] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 232903: loss 3.0839
[2017-11-01 10:03:03,800] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 233007: loss 106.1779
[2017-11-01 10:03:03,972] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.05537939e-01   8.92836899e-02   3.43253076e-01   1.39263585e-01
   1.22661747e-01   3.68856286e-13   7.96719678e-13   4.80684625e-14
   6.85759907e-14], sum to 1.0000
[2017-11-01 10:03:03,984] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.0, 36.0, 5.466666666666667, 260.0, 49.66666666666666, 0.0, 8.0, 9.145140780497002, 10.0, 23.58651281753271, 22.7, 1.0, 0.0], 
actual action is [8.0, 10], 
sim time next is 4379100.0000, 
raw observation next is [13.0, 36.25, 5.558333333333333, 260.0, 44.33333333333334, 0.0, 8.0, 9.173387111280038, 10.0, 23.53536020225622, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6956521739130435, 0.6666666666666666, 0.3625, 0.5053030303030303, 0.7222222222222222, 0.11728395061728397, 0.0, 0.6333333333333333, 0.09173387111280037, 0.0, 0.6767680101128111, 0.635, 1.0, 0.0], 
reward next is -0.0459. 
=============================================
[2017-11-01 10:03:07,247] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14500, global step 233675: loss -68.5812
[2017-11-01 10:03:08,854] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.95661536e-03   3.34174931e-03   8.81072938e-01   5.81860077e-03
   1.07810102e-01   5.08705245e-33   3.01874566e-31   1.57450650e-34
   2.34986923e-33], sum to 1.0000
[2017-11-01 10:03:08,861] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [4.666666666666667, 67.0, 6.866666666666666, 260.0, 0.0, 0.0, -0.291666666666667, 37.68135681832407, 10.0, 18.67612040284627, 21.5, 0.0, 0.0], 
actual action is [-0.33333333333333304, 10], 
sim time next is 4419900.0000, 
raw observation next is [4.625, 67.0, 6.9, 260.0, 0.0, 0.0, -0.333333333333333, 37.96191766353864, 10.0, 18.65551950778066, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.4519230769230769, 0.67, 0.6272727272727273, 0.7222222222222222, 0.0, 0.0, 0.49444444444444446, 0.3796191766353864, 0.0, 0.432775975389033, 0.575, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:03:14,493] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-29.7826519 ]
 [-30.9559021 ]
 [-30.86751175]
 [-28.81929207]
 [-29.17488861]], R is [[-31.17241287]
 [-30.92654419]
 [-30.68240356]
 [-30.4399128 ]
 [-30.19900703]].
[2017-11-01 10:03:15,606] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 235112: loss 22.1603
[2017-11-01 10:03:17,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  8.02666917e-35   3.24769542e-14   2.33758596e-14   2.54021471e-14
   5.43107090e-14   7.92672485e-02   3.65355462e-01   2.56152940e-03
   5.52815735e-01], sum to 1.0000
[2017-11-01 10:03:17,247] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.0, 86.0, 5.75, 267.5, 229.5, 117.25, -4.0, 36.64473082756307, 10.0, 19.1904181030005, 22.7, 1.0, 0.0], 
actual action is [6.0, 15.0], 
sim time next is 4443600.0000, 
raw observation next is [1.0, 86.0, 5.966666666666667, 266.6666666666667, 236.6666666666667, 126.8333333333333, 6.0, 36.07021629234266, 15.0, 19.25162112094773, 22.7, 1.0, 4.517709991283995], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.358974358974359, 0.86, 0.5424242424242425, 0.7407407407407408, 0.6261022927689596, 0.1268333333333333, 0.6, 0.36070216292342655, 0.25, 0.4625810560473864, 0.635, 1.0, 0.053149529309223474], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:03:18,750] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.10153161e-01   1.96789175e-01   3.69833678e-01   1.48281574e-01
   1.74942464e-01   3.56055241e-23   5.74970485e-23   9.32592052e-25
   1.93194371e-23], sum to 1.0000
[2017-11-01 10:03:18,764] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [1.708333333333333, 81.66666666666666, 7.158333333333333, 254.1666666666667, 110.0, 212.6666666666667, -3.233333333333333, 29.2130778299749, 10.0, 19.92630103144688, 22.7, 1.0, 0.0], 
actual action is [-3.291666666666667, 10], 
sim time next is 4437000.0000, 
raw observation next is [1.65, 82.0, 7.050000000000001, 255.0, 120.0, 232.0, -3.291666666666667, 29.79700154917719, 10.0, 19.91269196391373, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.37564102564102564, 0.82, 0.640909090909091, 0.7083333333333334, 0.31746031746031744, 0.232, 0.44513888888888886, 0.2979700154917719, 0.0, 0.4956345981956865, 0.635, 1.0, 0.0], 
reward next is -0.1490. 
=============================================
[2017-11-01 10:03:21,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.79922220e-03   4.52638984e-01   3.33124161e-01   1.20245248e-01
   9.21924114e-02   1.17573953e-18   3.68260726e-18   5.34627380e-20
   3.39941681e-18], sum to 1.0000
[2017-11-01 10:03:21,811] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 86.0, 6.4, 265.0, 251.0, 146.0, -4.0, 25.59879153651719, 10.0, 20.41225600209655, 22.7, 1.0, 0.0], 
actual action is [-4.0, 10], 
sim time next is 4444500.0000, 
raw observation next is [1.0, 86.0, 6.616666666666667, 264.1666666666667, 241.9166666666667, 133.8333333333333, -4.0, 25.45164151555728, 10.0, 20.45314775011676, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.358974358974359, 0.86, 0.6015151515151516, 0.7337962962962964, 0.6399911816578484, 0.13383333333333328, 0.43333333333333335, 0.25451641515557283, 0.0, 0.522657387505838, 0.635, 1.0, 0.0], 
reward next is -0.1273. 
=============================================
[2017-11-01 10:03:22,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.55601378e-04   3.50487116e-03   9.74833369e-01   1.35293547e-02
   7.57678412e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-01 10:03:22,868] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [5.183333333333334, 66.83333333333333, 6.55, 260.0, 0.0, 0.0, 10.275, 33.70096933002537, 15.0, 18.86937783746134, 21.5, 0.0, 17.48549746078771], 
actual action is [10.183333333333334, 14.0], 
sim time next is 4416900.0000, 
raw observation next is [5.091666666666667, 66.91666666666667, 6.575, 260.0, 0.0, 0.0, 10.18333333333333, 33.63533770465133, 14.0, 18.85558039757872, 21.5, 0.0, 8.075917531793753], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.46388888888888896, 0.6691666666666667, 0.5977272727272728, 0.7222222222222222, 0.0, 0.0, 0.6697222222222222, 0.33635337704651325, 0.2, 0.442779019878936, 0.575, 0.0, 0.09501079449169121], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:03:34,183] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 238218: loss 70.7696
[2017-11-01 10:03:36,649] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 238506: loss 21.0361
[2017-11-01 10:03:37,438] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.05973317  0.12160327  0.09063855  0.08743799  0.64058703  0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 10:03:37,449] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 92.0, 7.7, 290.0, 180.3333333333333, 5.0, -5.0, 25.0309457110482, 10.0, 20.57830325739057, 22.7, 1.0, 0.0], 
actual action is [-5.0, 10.0], 
sim time next is 4454700.0000, 
raw observation next is [0.0, 92.0, 7.699999999999999, 290.0, 188.1666666666667, 5.5, -5.0, 25.17959697755053, 10.0, 20.52712947486375, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.3333333333333333, 0.92, 0.7, 0.8055555555555556, 0.49779541446208125, 0.0055, 0.4166666666666667, 0.25179596977550533, 0.0, 0.5263564737431874, 0.635, 1.0, 0.0], 
reward next is -0.1259. 
=============================================
[2017-11-01 10:03:38,138] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 238679: loss -0.5048
[2017-11-01 10:03:38,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.002692    0.02810273  0.02974405  0.04796802  0.8914932   0.          0.
  0.          0.        ], sum to 1.0000
[2017-11-01 10:03:38,719] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 78.0, 10.0, 285.0, 49.0, 0.0, -5.0, 33.9863111551815, 10.0, 19.53977345759638, 22.7, 1.0, 0.0], 
actual action is [-5.0, 10.0], 
sim time next is 4466100.0000, 
raw observation next is [0.0, 78.0, 10.38333333333333, 285.8333333333334, 47.0, 4.583333333333336, -5.0, 34.26765635990512, 10.0, 19.48777322252264, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.3333333333333333, 0.78, 0.9439393939393935, 0.7939814814814817, 0.12433862433862433, 0.004583333333333336, 0.4166666666666667, 0.3426765635990512, 0.0, 0.47438866112613204, 0.635, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:03:42,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 239094: loss -11.7584
[2017-11-01 10:03:42,772] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 239154: loss 5.0959
[2017-11-01 10:03:42,828] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 239165: loss -199.2499
[2017-11-01 10:03:45,232] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 239386: loss 124.0887
[2017-11-01 10:03:45,931] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.81264873e-02   4.00941104e-01   6.41897991e-02   6.30366877e-02
   4.33705956e-01   1.89012145e-32   1.19660432e-32   4.55527709e-34
   1.54219640e-31], sum to 1.0000
[2017-11-01 10:03:45,994] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [0.0, 72.0, 6.491666666666665, 304.1666666666666, 0.0, 0.0, 5.0, 17.96764691866581, 26.0, 21.07659060042863, 21.5, 0.0, 46.99074993282255], 
actual action is [5.0, 26.0], 
sim time next is 4480200.0000, 
raw observation next is [0.0, 72.0, 6.149999999999999, 305.0, 0.0, 0.0, 5.0, 17.52576963668081, 26.0, 21.18125078543972, 21.5, 0.0, 46.71688128096989], 
processed observation next is [0.16666666666666666, 0.8695652173913043, 0.3333333333333333, 0.72, 0.559090909090909, 0.8472222222222222, 0.0, 0.0, 0.5833333333333334, 0.1752576963668081, 0.8, 0.5590625392719859, 0.575, 0.0, 0.5496103680114105], 
reward next is -0.3545. 
=============================================
[2017-11-01 10:03:46,425] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15000, global step 239506: loss 10.8753
[2017-11-01 10:03:53,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 240424: loss 23.7090
[2017-11-01 10:03:54,241] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15000, global step 240469: loss -18.0606
[2017-11-01 10:03:54,396] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 240495: loss 10.7383
[2017-11-01 10:03:54,506] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 240502: loss -79.5950
[2017-11-01 10:03:57,187] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 240853: loss -68.9827
[2017-11-01 10:03:57,417] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 240890: loss 3.2288
[2017-11-01 10:04:00,535] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15000, global step 241489: loss 4.3134
[2017-11-01 10:04:07,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.18548439e-02   1.55456707e-01   5.31406403e-02   4.58590463e-02
   7.23688900e-01   4.66078638e-18   2.24625569e-18   4.46707640e-18
   2.67662763e-18], sum to 1.0000
[2017-11-01 10:04:07,822] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 13.44151037973598, 25.5, 21.94651271020405, 21.5, 0.0, 42.80909180918329], 
actual action is [6.0, 23.5], 
sim time next is 4578000.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 13.01269928035745, 23.5, 22.06847039707255, 21.5, 0.0, 42.22013424388389], 
processed observation next is [0.3333333333333333, 1.0, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.6, 0.1301269928035745, 0.675, 0.6034235198536274, 0.575, 0.0, 0.49670746169275165], 
reward next is -0.2484. 
=============================================
[2017-11-01 10:04:09,868] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 242633: loss 27.8959
[2017-11-01 10:04:18,337] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.74748472e-03   9.71244872e-02   4.04185103e-03   1.41592035e-02
   8.81926954e-01   1.10113774e-20   2.67843506e-21   1.64194786e-21
   4.10749983e-21], sum to 1.0000
[2017-11-01 10:04:18,419] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [3.0, 49.0, 3.1, 310.0, 255.5, 80.5, 7.916666666666667, 6.995575001983283, 22.0, 24.25396291238784, 22.7, 1.0, 19.29694072931951], 
actual action is [8.0, 22.0], 
sim time next is 4543500.0000, 
raw observation next is [3.0, 48.66666666666666, 3.183333333333334, 309.9999999999999, 256.9166666666666, 85.91666666666667, 8.0, 7.034474415137207, 22.0, 24.23900539497496, 22.7, 1.0, 18.0399938466083], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.41025641025641024, 0.4866666666666666, 0.2893939393939395, 0.8611111111111108, 0.6796737213403877, 0.08591666666666667, 0.6333333333333333, 0.07034474415137207, 0.6, 0.711950269748748, 0.635, 1.0, 0.21223522172480352], 
reward next is -0.1413. 
=============================================
[2017-11-01 10:04:27,640] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.93317640e-02   4.82754976e-01   3.44473980e-02   3.26051861e-02
   4.10860747e-01   6.93679055e-14   1.02510079e-14   1.87163280e-14
   3.70847923e-15], sum to 1.0000
[2017-11-01 10:04:27,676] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.16711612593475, 16.5, 22.36438978437013, 21.5, 0.0, 21.09978976786024], 
actual action is [6.0, 16.5], 
sim time next is 4574400.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 12.56780567007536, 16.5, 22.28826858198136, 21.5, 0.0, 20.25315076189616], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.6, 0.1256780567007536, 0.325, 0.6144134290990679, 0.575, 0.0, 0.2382723619046607], 
reward next is -0.1191. 
=============================================
[2017-11-01 10:04:28,250] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 245653: loss -46.1815
[2017-11-01 10:04:29,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  3.30200568e-02   4.52646494e-01   2.79639605e-02   4.69460115e-02
   4.39423501e-01   3.10244541e-09   7.28299143e-10   1.05092535e-09
   4.31957525e-10], sum to 1.0000
[2017-11-01 10:04:30,029] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [4.85, 49.5, 0.55, 15.0, 203.0, 599.0, -0.1750000000000007, 8.75675024359737, 10.0, 23.63263009946397, 22.7, 1.0, 0.0], 
actual action is [-0.15000000000000036, 10.0], 
sim time next is 4631700.0000, 
raw observation next is [4.875, 49.58333333333333, 0.4583333333333333, 12.5, 202.3333333333333, 559.8333333333333, -0.1500000000000004, 8.667749770031596, 10.0, 23.69805096653726, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.4583333333333333, 0.4958333333333333, 0.041666666666666664, 0.034722222222222224, 0.5352733686067018, 0.5598333333333333, 0.49749999999999994, 0.08667749770031596, 0.0, 0.6849025483268629, 0.635, 1.0, 0.0], 
reward next is -0.0433. 
=============================================
[2017-11-01 10:04:30,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.44264545e-02   4.52194422e-01   2.77363993e-02   4.18627858e-02
   4.43779856e-01   2.23834484e-09   5.30632316e-10   7.79261489e-10
   2.49443466e-10], sum to 1.0000
[2017-11-01 10:04:30,176] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.666666666666667, 50.0, 2.6, 86.66666666666666, 121.6666666666667, 837.3333333333334, -2.416666666666667, 9.763787991942994, 10.0, 23.69517617307742, 22.7, 1.0, 0.0], 
actual action is [-2.333333333333333, 10], 
sim time next is 4621500.0000, 
raw observation next is [2.75, 49.75, 2.475, 85.0, 121.5, 839.5, -2.333333333333333, 9.787628518835072, 10.0, 23.66768785202705, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.40384615384615385, 0.4975, 0.225, 0.2361111111111111, 0.32142857142857145, 0.8395, 0.46111111111111114, 0.09787628518835073, 0.0, 0.6833843926013525, 0.635, 1.0, 0.0], 
reward next is -0.0489. 
=============================================
[2017-11-01 10:04:30,380] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 246069: loss 19.0010
[2017-11-01 10:04:32,110] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.30935891e-34   7.82676146e-11   1.73249016e-13   1.41526461e-12
   3.82552101e-10   9.65913355e-01   1.01698181e-02   2.02535074e-02
   3.66330985e-03], sum to 1.0000
[2017-11-01 10:04:32,149] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.366666666666667, 68.33333333333334, 0.0, 0.0, 0.0, 0.0, 3.666666666666667, 39.94960413842283, 17.5, 18.61415210552245, 21.5, 0.0, 3.44695000209506], 
actual action is [3.633333333333333, 18.0], 
sim time next is 4592700.0000, 
raw observation next is [-1.4, 68.5, 0.0, 0.0, 0.0, 0.0, 3.633333333333333, 40.42476281960698, 18.0, 18.57170092179486, 21.5, 0.0, 3.277509419277495], 
processed observation next is [0.5, 0.13043478260869565, 0.29743589743589743, 0.685, 0.0, 0.0, 0.0, 0.0, 0.5605555555555556, 0.40424762819606985, 0.4, 0.428585046089743, 0.575, 0.0, 0.03855893434444112], 
reward next is -1.0000. 
=============================================
[2017-11-01 10:04:32,454] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-15.79415035]
 [-24.42170715]
 [-24.30483818]
 [-23.85675049]
 [-24.77257729]], R is [[-14.54131889]
 [-14.6459465 ]
 [-14.93003178]
 [-15.19637489]
 [-15.44596004]].
[2017-11-01 10:04:33,389] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 246697: loss -1.5914
[2017-11-01 10:04:33,714] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.83204425e-16   7.03358045e-03   8.16786924e-05   3.13565426e-04
   7.49795372e-03   8.14014018e-01   6.05664700e-02   9.02079865e-02
   2.02847514e-02], sum to 1.0000
[2017-11-01 10:04:33,735] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 54.08333333333333, 2.1, 325.0, 0.0, 0.0, 7.0, 21.43154536423142, 12.5, 20.82199231833479, 21.5, 0.0, 3.528811556688633], 
actual action is [7.0, 13.0], 
sim time next is 4664400.0000, 
raw observation next is [2.0, 53.66666666666667, 2.1, 320.0, 0.0, 0.0, 7.0, 21.71293456513974, 13.0, 20.78917770770497, 21.5, 0.0, 3.41123136997358], 
processed observation next is [0.5, 1.0, 0.38461538461538464, 0.5366666666666667, 0.19090909090909092, 0.8888888888888888, 0.0, 0.0, 0.6166666666666667, 0.2171293456513974, 0.15, 0.5394588853852484, 0.575, 0.0, 0.04013213376439506], 
reward next is -0.1978. 
=============================================
[2017-11-01 10:04:33,745] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 246777: loss 8.6325
[2017-11-01 10:04:34,636] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 246999: loss 7.9705
[2017-11-01 10:04:35,604] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 247239: loss 3.9095
[2017-11-01 10:04:36,780] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 247517: loss 8.8887
[2017-11-01 10:04:37,632] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15500, global step 247741: loss 20.6699
[2017-11-01 10:04:39,019] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.86178452
  0.02053745  0.02132431  0.09635375], sum to 1.0000
[2017-11-01 10:04:39,042] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 52.83333333333333, 1.375, 36.66666666666666, 0.0, 0.0, 7.0, 31.93384134453818, 12.0, 19.61023648014382, 21.5, 0.0, 2.003438000460162], 
actual action is [7.0, 12.5], 
sim time next is 4669800.0000, 
raw observation next is [2.0, 53.66666666666667, 1.25, 33.33333333333334, 0.0, 0.0, 7.0, 32.16656675894804, 12.5, 19.59006341002792, 21.5, 0.0, 1.923922482952559], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.38461538461538464, 0.5366666666666667, 0.11363636363636363, 0.09259259259259262, 0.0, 0.0, 0.6166666666666667, 0.32166566758948045, 0.125, 0.479503170501396, 0.575, 0.0, 0.022634382152383045], 
reward next is -0.4888. 
=============================================
[2017-11-01 10:04:39,674] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 248243: loss -142.4834
[2017-11-01 10:04:40,224] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 248357: loss -2.6889
[2017-11-01 10:04:40,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.16036847e-01   5.53623080e-01   4.74372171e-02   6.43638596e-02
   2.18538985e-01   1.07399072e-12   4.96609969e-13   3.92479316e-13
   3.30530986e-13], sum to 1.0000
[2017-11-01 10:04:40,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.6, 44.5, 0.0, 0.0, 117.0, 147.0, 0.6666666666666661, 10.85508612708511, 10.0, 23.42946804846006, 22.7, 1.0, 0.0], 
actual action is [0.5999999999999996, 10], 
sim time next is 4638900.0000, 
raw observation next is [5.533333333333333, 44.75, 0.0, 0.0, 110.5833333333333, 146.8333333333333, 0.5999999999999996, 10.86989666828268, 10.0, 23.40249132906514, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.4752136752136752, 0.4475, 0.0, 0.0, 0.29254850088183415, 0.1468333333333333, 0.51, 0.1086989666828268, 0.0, 0.6701245664532569, 0.635, 1.0, 0.0], 
reward next is -0.0543. 
=============================================
[2017-11-01 10:04:40,952] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 248510: loss -6.0652
[2017-11-01 10:04:43,126] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15500, global step 248900: loss 147.6223
[2017-11-01 10:04:43,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 248938: loss 5.8084
[2017-11-01 10:04:43,581] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 248974: loss -104.5834
[2017-11-01 10:04:44,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  4.50121462e-02   3.47327232e-01   6.54962808e-02   4.84977476e-02
   4.93666589e-01   3.81214035e-24   6.34860022e-25   6.48152476e-25
   7.59153271e-24], sum to 1.0000
[2017-11-01 10:04:44,224] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-1.0, 100.0, 0.0, 0.0, 0.0, 0.0, 4.0, 17.3970432781292, 19.5, 21.07998731651605, 21.5, 0.0, 28.92673801872625], 
actual action is [4.0, 19.5], 
sim time next is 4689000.0000, 
raw observation next is [-1.0, 100.0, 0.0, 0.0, 0.0, 0.0, 4.0, 17.54633995395434, 19.5, 21.11507685746998, 21.5, 0.0, 27.51369238793818], 
processed observation next is [0.6666666666666666, 0.2608695652173913, 0.3076923076923077, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.1754633995395434, 0.475, 0.5557538428734989, 0.575, 0.0, 0.32369049868162564], 
reward next is -0.2581. 
=============================================
[2017-11-01 10:04:45,154] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  7.05824569e-02   5.05237222e-01   5.75400740e-02   1.07888468e-01
   2.58751750e-01   9.37536507e-11   6.37240608e-11   2.67434963e-11
   5.32556325e-11], sum to 1.0000
[2017-11-01 10:04:45,176] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [4.800000000000001, 47.0, 0.0, 0.0, 52.83333333333333, 145.3333333333333, -0.09999999999999964, 14.71534995330404, 10.0, 22.52686776395405, 22.7, 1.0, 0.0], 
actual action is [-0.1999999999999993, 10], 
sim time next is 4641900.0000, 
raw observation next is [4.7, 47.25, 0.0, 0.0, 46.41666666666667, 145.1666666666667, -0.1999999999999993, 14.99299129585731, 10.0, 22.47023311910977, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.45384615384615384, 0.4725, 0.0, 0.0, 0.12279541446208114, 0.14516666666666672, 0.4966666666666667, 0.1499299129585731, 0.0, 0.6235116559554885, 0.635, 1.0, 0.0], 
reward next is -0.0750. 
=============================================
[2017-11-01 10:04:47,255] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15500, global step 249671: loss -18.1365
[2017-11-01 10:04:47,497] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  5.60558165e-36   9.21939730e-14   1.32098917e-15   4.80404138e-15
   1.34699779e-14   1.80021286e-01   1.23455137e-01   3.66651788e-02
   6.59858406e-01], sum to 1.0000
[2017-11-01 10:04:47,577] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 53.66666666666667, 2.1, 320.0, 0.0, 0.0, 7.0, 17.71553556842251, 25.5, 20.52758148133861, 21.5, 0.0, 56.86618416289651], 
actual action is [7.0, 26.0], 
sim time next is 4664700.0000, 
raw observation next is [2.0, 53.25, 2.1, 315.0, 0.0, 0.0, 7.0, 15.65021982507093, 26.0, 20.8420288402756, 21.5, 0.0, 50.40422918151546], 
processed observation next is [0.5, 1.0, 0.38461538461538464, 0.5325, 0.19090909090909092, 0.875, 0.0, 0.0, 0.6166666666666667, 0.1565021982507093, 0.8, 0.54210144201378, 0.575, 0.0, 0.5929909315472407], 
reward next is -0.4610. 
=============================================
[2017-11-01 10:04:48,953] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2017-11-01 10:04:48,967] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-01 10:04:48,967] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.01 09:17

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-01 10:04:48,968] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-01 10:04:48,969] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-01 10:04:48,977] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-01 10:04:48,977] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-01 10:04:48,977] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-01 10:04:48,977] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-01 10:04:48,978] EPLUS_ENV_IW-v5702_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=00hr 46min 49.66sec

[2017-11-01 10:04:49,969] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-01 10:04:49,972] EPLUS_ENV_IW-v5702_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v5702-res2/Eplus-env-sub_run2
[2017-11-01 10:05:35,375] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.68168268e-09   8.18075120e-01   4.02906910e-02   2.69756969e-02
   1.14658467e-01   3.54935040e-11   1.96816938e-11   1.82481998e-11
   1.28364264e-10]
[2017-11-01 10:05:35,579] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.30085870e-15   5.19448638e-01   1.61513519e-02   1.73025075e-02
   6.97249770e-02   5.23476563e-02   3.14678177e-02   2.76569221e-02
   2.65900135e-01]
[2017-11-01 10:05:35,936] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.59487512e-14   7.91365445e-01   2.57092137e-02   2.59061102e-02
   1.07044108e-01   7.41158705e-03   4.35691373e-03   3.90968611e-03
   3.42969857e-02]
[2017-11-01 10:05:36,774] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.36191513e-12   7.33359531e-02   1.34549220e-03   3.80161381e-03
   1.05640786e-02   1.83743089e-01   1.82658464e-01   8.89771655e-02
   4.55574155e-01]
[2017-11-01 10:05:37,149] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.96088637e-16   1.02855731e-03   1.91160889e-05   5.17666522e-05
   1.42914883e-04   2.06439331e-01   1.89162090e-01   1.03607990e-01
   4.99548197e-01]
[2017-11-01 10:05:38,446] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.01248879e-03   7.36177087e-01   7.02681765e-02   3.36934403e-02
   1.52848795e-01   1.65463889e-16   8.75292613e-17   9.02967165e-17
   3.51271895e-16]
[2017-11-01 10:05:52,284] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.71966655e-05   5.87549448e-01   5.38411103e-02   4.52489145e-02
   3.13333392e-01   1.25096817e-11   1.31545183e-11   1.14340768e-11
   5.38460006e-11]
[2017-11-01 10:05:54,899] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.25799842e-28   4.85360883e-13   1.22614042e-14   5.10334810e-14
   9.07440965e-14   1.91167772e-01   2.62887031e-01   9.11206678e-02
   4.54824537e-01]
[2017-11-01 10:05:55,058] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.21657073e-02   6.37388408e-01   5.57266772e-02   7.00036511e-02
   1.74715549e-01   6.27814675e-11   6.32063221e-11   2.71685261e-11
   7.83548643e-11]
[2017-11-01 10:06:01,228] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.59773084e-12   7.19686091e-01   3.06806825e-02   3.30413692e-02
   1.59543216e-01   8.71085096e-03   7.95507617e-03   6.89779362e-03
   3.34849693e-02]
[2017-11-01 10:06:06,295] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.31072608e-02   5.90876341e-01   5.24104573e-02   6.84908032e-02
   1.95115119e-01   7.84163359e-12   7.92946871e-12   3.33492912e-12
   5.76057041e-12]
[2017-11-01 10:06:07,439] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.64861654e-04   7.64309764e-01   2.76418794e-02   4.52784784e-02
   1.61804914e-01   3.98178335e-09   5.06890041e-09   2.18910690e-09
   4.88230656e-09]
[2017-11-01 10:06:19,921] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.74404689e-05   6.63892508e-01   5.86028062e-02   1.00193016e-01
   1.77234203e-01   3.73079567e-09   4.05208889e-09   1.32232303e-09
   7.03329084e-09]
[2017-11-01 10:06:23,724] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.85407733e-19   1.54182771e-06   2.13534506e-08   7.41384198e-08
   2.70063879e-07   1.97693616e-01   2.84664690e-01   1.18470497e-01
   3.99169326e-01]
[2017-11-01 10:06:24,699] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.13208608e-22   2.39847679e-08   2.89437058e-10   1.10489651e-09
   4.16106483e-09   1.91750601e-01   2.80660689e-01   1.19541228e-01
   4.08047467e-01]
[2017-11-01 10:06:28,253] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.55544090e-02   6.73590958e-01   6.17501661e-02   3.32457051e-02
   1.95858717e-01   9.02926640e-16   6.89283331e-16   5.65813562e-16
   1.76256545e-15]
[2017-11-01 10:06:29,978] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.02262332e-06   7.19914019e-01   3.37273888e-02   2.96790563e-02
   2.16672540e-01   3.51448350e-11   3.91650427e-11   3.13119287e-11
   9.91786514e-11]
[2017-11-01 10:06:30,812] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.86945989e-14   2.46978968e-01   7.55732460e-03   1.07706664e-02
   6.73515350e-02   8.01113993e-02   1.06347591e-01   7.57900998e-02
   4.05092388e-01]
[2017-11-01 10:06:30,843] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.67733144e-21   6.52323115e-06   1.64000099e-07   3.00008253e-07
   1.68165604e-06   1.09673031e-01   1.54616565e-01   1.02338880e-01
   6.33362889e-01]
[2017-11-01 10:06:32,308] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.65115870e-15   2.09655464e-02   5.37243381e-04   9.72911133e-04
   5.79497823e-03   1.08003393e-01   1.63698390e-01   1.04977995e-01
   5.95049500e-01]
[2017-11-01 10:06:39,450] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.61027711e-25   3.61140146e-10   8.39809645e-12   2.60160053e-11
   5.75396397e-11   2.03244001e-01   2.18188778e-01   1.07853167e-01
   4.70714152e-01]
[2017-11-01 10:06:40,597] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.26889213e-21   3.57266504e-06   1.19221326e-07   1.52882464e-07
   5.62318348e-07   1.69687539e-01   1.23089746e-01   1.14281483e-01
   5.92936814e-01]
[2017-11-01 10:06:41,222] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.09908357e-10   7.94981182e-01   4.20156159e-02   3.30721661e-02
   1.29888058e-01   8.86771977e-06   5.76523098e-06   5.62377909e-06
   2.27109540e-05]
[2017-11-01 10:06:41,354] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.09926460e-18   7.42306933e-04   2.71377285e-05   3.05322610e-05
   1.20713215e-04   1.71639696e-01   1.19864039e-01   1.11011848e-01
   5.96563697e-01]
[2017-11-01 10:06:42,588] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.23884416e-11   8.05174530e-01   3.60141508e-02   2.99388934e-02
   1.28871292e-01   1.79810385e-07   1.17305177e-07   1.06021680e-07
   7.14470389e-07]
[2017-11-01 10:06:45,074] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.29006977e-09   2.28127033e-01   9.64598730e-03   2.14515608e-02
   4.49208766e-02   1.67447180e-01   1.71983987e-01   8.29657614e-02
   2.73457587e-01]
[2017-11-01 10:06:50,552] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.00839749e-01   5.04859865e-01   9.27647799e-02   4.08537537e-02
   2.60681838e-01   8.52056250e-18   4.35440158e-18   5.10715000e-18
   1.67891956e-17]
[2017-11-01 10:06:52,274] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.23259118e-02   5.20406842e-01   8.43985006e-02   4.05938290e-02
   3.02274942e-01   1.03696751e-16   6.75385691e-17   7.24516778e-17
   3.32852714e-16]
[2017-11-01 10:06:52,867] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.07238957e-05   6.80394053e-01   5.39339446e-02   3.85978222e-02
   2.27063462e-01   4.98367450e-12   4.27631324e-12   3.82695091e-12
   1.74564200e-11]
[2017-11-01 10:06:55,279] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.15497828e-02   6.63178146e-01   4.35960777e-02   5.75952530e-02
   1.74080744e-01   1.16218537e-12   1.05663286e-12   5.26177192e-13
   1.27504821e-12]
[2017-11-01 10:06:58,189] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.02649368e-01   5.53716183e-01   9.21463668e-02   4.08074297e-02
   2.10680678e-01   6.75508709e-17   3.63587602e-17   3.85163550e-17
   1.00157192e-16]
[2017-11-01 10:06:59,253] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.88122993e-05   7.24042714e-01   6.38675094e-02   3.52268890e-02
   1.76764116e-01   1.76237863e-13   1.19843168e-13   1.13541439e-13
   4.64806958e-13]
[2017-11-01 10:07:00,391] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.71085235e-02   4.71227437e-01   1.02084391e-01   6.18870854e-02
   3.17692608e-01   4.82130222e-15   2.90869208e-15   3.46217793e-15
   9.66763595e-15]
[2017-11-01 10:07:03,928] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.24103807e-02   6.70401692e-01   4.08436283e-02   5.66953793e-02
   1.69649005e-01   4.18211056e-11   4.58908710e-11   1.93657052e-11
   4.80609406e-11]
[2017-11-01 10:07:07,364] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.47638100e-02   5.10427356e-01   9.67796817e-02   4.27052453e-02
   2.65323907e-01   6.34803495e-16   3.59674806e-16   4.30724009e-16
   1.19654807e-15]
[2017-11-01 10:07:07,919] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.12737558e-33   6.77834633e-13   1.68603399e-14   3.57576653e-14
   1.43384247e-13   1.10557936e-01   1.22518465e-01   8.95707980e-02
   6.77352786e-01]
[2017-11-01 10:07:08,269] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.09834248e-02   5.02456069e-01   8.92807618e-02   4.49411608e-02
   2.92338610e-01   1.43353349e-15   9.37355353e-16   1.06700349e-15
   2.95455468e-15]
[2017-11-01 10:07:11,039] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.62510048e-02   4.79206741e-01   8.32126811e-02   5.52205406e-02
   3.46108973e-01   3.15005116e-14   2.66274734e-14   2.40786869e-14
   9.23988601e-14]
[2017-11-01 10:07:17,256] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.06273879e-11   7.57903159e-01   3.06960717e-02   3.23246978e-02
   1.23554491e-01   1.04546547e-02   8.93552043e-03   7.03071384e-03
   2.91006193e-02]
[2017-11-01 10:07:19,796] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.49113560e-02   5.06379187e-01   9.81121734e-02   4.56027351e-02
   2.74994493e-01   6.77026288e-16   4.39354481e-16   4.61381970e-16
   1.68612062e-15]
[2017-11-01 10:07:23,524] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.04311064e-07   7.75412023e-01   2.87680700e-02   5.84011152e-02
   1.35786667e-01   3.93107504e-04   4.46129387e-04   1.84955614e-04
   6.07724476e-04]
[2017-11-01 10:07:24,490] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.20671436e-02   6.66226625e-01   4.59193327e-02   6.04704469e-02
   1.65316463e-01   6.73240977e-12   6.14885139e-12   2.91463425e-12
   8.35461821e-12]
[2017-11-01 10:07:24,785] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.68264925e-02   6.62981331e-01   4.72426862e-02   5.92845455e-02
   1.63664907e-01   1.16663311e-11   1.05258302e-11   5.12737595e-12
   1.34225391e-11]
[2017-11-01 10:07:25,034] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.09334005e-07   7.77660489e-01   3.61007340e-02   5.28801009e-02
   1.33355021e-01   6.98765518e-07   6.28897681e-07   3.48244271e-07
   1.13047633e-06]
[2017-11-01 10:07:25,292] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.55873021e-06   7.76408136e-01   5.73941283e-02   3.43155526e-02
   1.31878585e-01   1.21340637e-11   7.55216636e-12   7.53030364e-12
   2.75421855e-11]
[2017-11-01 10:07:28,960] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.68962695e-07   8.31415892e-01   1.58388745e-02   3.14772576e-02
   1.21266395e-01   1.42510700e-07   1.31820968e-07   7.96976636e-08
   3.11747300e-07]
[2017-11-01 10:07:29,294] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.86988688e-07   8.04570973e-01   4.64998297e-02   2.98134610e-02
   1.19115300e-01   1.24152025e-11   6.30017219e-12   6.84733433e-12
   3.21574087e-11]
[2017-11-01 10:07:29,450] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.53206481e-09   8.09933245e-01   4.01130952e-02   3.03548165e-02
   1.19598538e-01   5.49447599e-08   2.89353039e-08   3.05226280e-08
   1.61358628e-07]
[2017-11-01 10:07:29,926] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.89448074e-09   7.49676526e-01   3.28521542e-02   5.50858863e-02
   1.28524885e-01   8.15039128e-03   6.56923978e-03   4.07482823e-03
   1.50660789e-02]
[2017-11-01 10:07:31,230] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.81121532e-11   7.95876324e-01   4.21786122e-02   3.71430665e-02
   1.24379113e-01   7.80826522e-05   4.72772153e-05   4.48733190e-05
   2.52654601e-04]
[2017-11-01 10:07:31,848] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.92187724e-02   7.78479874e-01   1.96273346e-02   3.14679369e-02
   1.41206071e-01   4.53562664e-14   4.09859761e-14   2.55218803e-14
   1.01095137e-13]
[2017-11-01 10:07:31,997] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.49398442e-02   7.70290315e-01   1.87048037e-02   3.07253413e-02
   1.45339653e-01   2.62281363e-14   2.46337933e-14   1.53206966e-14
   5.25747963e-14]
[2017-11-01 10:07:32,306] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.99516365e-02   6.50039732e-01   7.61554688e-02   3.65732610e-02
   1.57279909e-01   9.11376742e-20   3.92576849e-20   4.33827409e-20
   2.04026321e-19]
[2017-11-01 10:07:33,386] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.31006828e-02   7.25421429e-01   3.54916230e-02   3.24796140e-02
   1.53506622e-01   1.04787041e-17   6.70451600e-18   5.34742736e-18
   2.32522786e-17]
[2017-11-01 10:07:35,073] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.83099706e-11   7.16942728e-01   4.91427146e-02   4.80644256e-02
   1.85745880e-01   1.36199469e-05   1.15024450e-05   9.75782859e-06
   6.94067348e-05]
[2017-11-01 10:07:35,192] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.22234226e-14   5.07887363e-01   3.01769543e-02   3.39900069e-02
   1.29093796e-01   3.50721776e-02   3.04712355e-02   2.51262225e-02
   2.08182260e-01]
[2017-11-01 10:07:35,851] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.77577207e-15   5.59996180e-02   3.02880933e-03   3.83017608e-03
   1.42860925e-02   1.07688740e-01   9.92044881e-02   8.04363713e-02
   6.35525703e-01]
[2017-11-01 10:07:36,765] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.86914825e-09   5.35506427e-01   1.37634845e-02   3.41013558e-02
   8.43939409e-02   7.33025894e-02   8.74617249e-02   3.68150137e-02
   1.34655505e-01]
[2017-11-01 10:07:36,918] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.19086202e-09   5.51552534e-01   1.64603963e-02   3.96591350e-02
   8.97531658e-02   6.86839595e-02   7.96383172e-02   3.26924808e-02
   1.21560007e-01]
[2017-11-01 10:07:42,809] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.72753226e-11   7.41780341e-01   4.96537387e-02   4.43845317e-02
   1.35596275e-01   5.45358052e-03   4.04558983e-03   3.26783070e-03
   1.58180669e-02]
[2017-11-01 10:07:43,540] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.03014773e-12   7.04858124e-01   4.38205749e-02   3.92349847e-02
   1.43323034e-01   1.26027903e-02   9.28449351e-03   8.38707294e-03
   3.84890288e-02]
[2017-11-01 10:07:43,891] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.62192938e-02   4.99985516e-01   9.63838696e-02   4.27609459e-02
   2.64650404e-01   7.72828295e-17   4.15284174e-17   5.00683822e-17
   1.49869391e-16]
[2017-11-01 10:07:47,392] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.31801516e-01   4.78788942e-01   8.83928835e-02   1.10433906e-01
   1.90582797e-01   2.42326625e-09   1.96182226e-09   1.27952682e-09
   2.07355200e-09]
[2017-11-01 10:07:47,889] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.54549276e-08   7.76087463e-01   5.43785915e-02   3.75407189e-02
   1.31993189e-01   9.21201160e-09   5.56150948e-09   5.59231461e-09
   2.29822756e-08]
[2017-11-01 10:07:47,917] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.61477048e-10   7.84882665e-01   4.70582545e-02   3.71886715e-02
   1.30839229e-01   6.24304630e-06   3.85175008e-06   3.80722418e-06
   1.72181499e-05]
[2017-11-01 10:07:49,102] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.98915632e-13   5.70365489e-01   3.98946851e-02   4.23021093e-02
   1.33854508e-01   2.77957898e-02   2.26966497e-02   1.71443596e-02
   1.45946518e-01]
[2017-11-01 10:07:50,415] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.20570663e-02   5.97060680e-01   5.49939200e-02   7.63794631e-02
   1.89508855e-01   6.65644276e-11   5.65054288e-11   3.36540344e-11
   7.37442191e-11]
[2017-11-01 10:07:50,977] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.83869728e-03   7.27430403e-01   7.99440816e-02   3.91177051e-02
   1.50669098e-01   2.87358807e-15   1.44815328e-15   1.56243803e-15
   5.87341201e-15]
[2017-11-01 10:07:51,290] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.69811835e-06   7.74732590e-01   6.04341030e-02   3.36736180e-02
   1.31156981e-01   2.71800659e-12   1.51691290e-12   1.51030761e-12
   6.14178109e-12]
[2017-11-01 10:07:54,455] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.89525169e-02   5.88261664e-01   8.25241581e-02   3.81938629e-02
   1.92067742e-01   3.94322788e-17   2.21100530e-17   2.34507126e-17
   6.65302028e-17]
[2017-11-01 10:08:02,769] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.82064071e-02   6.65043056e-01   3.82977091e-02   5.22876866e-02
   1.76165089e-01   4.02243106e-14   3.55531204e-14   1.73934319e-14
   3.96333323e-14]
[2017-11-01 10:08:06,488] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.42094774e-14   1.80942819e-01   6.22258848e-03   7.04294397e-03
   3.42188179e-02   1.16086245e-01   9.87890661e-02   8.61916617e-02
   4.70505893e-01]
[2017-11-01 10:08:14,697] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.22218657e-02   6.35882974e-01   4.78514060e-02   5.95811196e-02
   1.74462542e-01   3.23568348e-13   2.75200327e-13   1.39307348e-13
   2.88249080e-13]
[2017-11-01 10:08:14,980] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.12671091e-06   7.87900805e-01   3.24293748e-02   4.59551960e-02
   1.33712307e-01   2.82289562e-07   2.58230472e-07   1.50339773e-07
   4.52407136e-07]
[2017-11-01 10:08:23,066] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.10859275e-01   5.95834732e-01   4.96626273e-02   6.52265251e-02
   1.78416789e-01   6.59132525e-13   6.16200450e-13   2.65757468e-13
   4.55009890e-13]
[2017-11-01 10:08:25,626] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.72074294e-14   1.74198896e-01   6.42783102e-03   8.36073328e-03
   3.93452086e-02   1.11272939e-01   1.15493871e-01   9.01996121e-02
   4.54700917e-01]
[2017-11-01 10:08:28,582] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.99636530e-12   4.74737212e-02   3.34877800e-03   6.74389862e-03
   1.05058951e-02   2.01679334e-01   1.87098697e-01   7.39879310e-02
   4.69161838e-01]
[2017-11-01 10:08:29,988] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.57997024e-16   6.00920212e-05   1.24378732e-06   3.78800314e-06
   9.31209524e-06   2.10978687e-01   2.82675207e-01   1.06563725e-01
   3.99707943e-01]
[2017-11-01 10:08:32,682] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.23133756e-01   5.14440954e-01   8.96231532e-02   4.19632457e-02
   2.30838820e-01   1.37133694e-16   7.75875298e-17   8.47334967e-17
   2.01707886e-16]
[2017-11-01 10:08:37,314] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.44903695e-06   6.30180717e-01   8.60897899e-02   1.17857665e-01
   1.65861398e-01   2.38734941e-07   2.05972029e-07   8.22619768e-08
   4.16659418e-07]
[2017-11-01 10:08:40,583] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.15309000e-01   5.40110886e-01   8.92018378e-02   4.19550464e-02
   2.13423222e-01   8.30631544e-17   4.88481915e-17   4.81937130e-17
   1.22875576e-16]
[2017-11-01 10:08:45,138] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.09013592e-02   4.83023763e-01   9.05002654e-02   4.96536531e-02
   3.35921049e-01   1.91025750e-15   1.37284517e-15   1.40823473e-15
   5.90938126e-15]
[2017-11-01 10:08:48,403] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.95165711e-07   8.15865159e-01   1.81606356e-02   3.95359546e-02
   1.26310110e-01   2.93218000e-05   3.55951524e-05   1.53471756e-05
   4.77715112e-05]
[2017-11-01 10:08:48,453] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.43564338e-09   7.97187209e-01   1.73380505e-02   4.11549583e-02
   1.23305492e-01   4.75836545e-03   5.83683606e-03   2.48721009e-03
   7.93188438e-03]
[2017-11-01 10:08:52,850] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.39380412e-32   1.66809166e-12   4.25042963e-14   1.05247320e-13
   4.33835015e-13   9.46247950e-02   1.28205001e-01   8.29574466e-02
   6.94212735e-01]
[2017-11-01 10:08:53,809] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.99891099e-07   6.71177149e-01   4.87759523e-02   4.52165119e-02
   2.34830081e-01   2.19132112e-09   2.39965492e-09   1.85363058e-09
   9.15010023e-09]
[2017-11-01 10:08:58,223] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.87557372e-11   5.50768003e-02   1.60175585e-03   3.96172283e-03
   9.45392437e-03   2.14331478e-01   2.41465226e-01   1.09229527e-01
   3.64879519e-01]
[2017-11-01 10:09:02,630] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.11559355e-02   4.93633777e-01   8.79812241e-02   4.78433222e-02
   2.99385756e-01   1.90380303e-16   1.21557169e-16   1.18260331e-16
   4.22944700e-16]
[2017-11-01 10:09:11,034] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.90034686e-22   4.71912927e-07   2.15432703e-08   3.99556406e-08
   1.36199219e-07   1.15849815e-01   1.50379017e-01   9.16615352e-02
   6.42108977e-01]
[2017-11-01 10:09:14,604] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.60974634e-09   1.32220834e-01   4.43629781e-03   1.04003595e-02
   2.82918252e-02   1.92732766e-01   2.23942667e-01   1.07343979e-01
   3.00631315e-01]
[2017-11-01 10:09:20,446] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.87188005e-02   6.68075085e-01   4.48895618e-02   6.33488744e-02
   1.64967656e-01   1.80627163e-11   1.90309279e-11   8.12313845e-12
   2.13970473e-11]
[2017-11-01 10:09:20,668] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.40663877e-02   5.93882024e-01   7.00289756e-02   9.47649181e-02
   1.77257732e-01   2.25146590e-09   2.07753681e-09   1.11374043e-09
   2.72637402e-09]
[2017-11-01 10:09:20,692] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.82732686e-02   5.78922093e-01   7.40794092e-02   9.95995998e-02
   1.79125652e-01   2.38955211e-09   2.14312501e-09   1.17736776e-09
   2.70858513e-09]
[2017-11-01 10:09:20,882] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.71191525e-02   5.14128387e-01   9.20895785e-02   1.19169123e-01
   1.77493766e-01   6.76807277e-09   5.82848170e-09   3.18236126e-09
   5.96724670e-09]
[2017-11-01 10:09:21,748] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.87374310e-09   7.64253795e-01   5.42187020e-02   4.13722210e-02
   1.40135646e-01   3.99362125e-06   2.92134996e-06   2.50800713e-06
   1.00940333e-05]
[2017-11-01 10:09:23,990] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.75379655e-02   4.77339834e-01   9.12744403e-02   5.59193827e-02
   3.17928374e-01   9.67189124e-16   6.19150909e-16   6.46078563e-16
   1.95622174e-15]
[2017-11-01 10:09:29,486] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.10517517e-01   4.97972637e-01   9.42943841e-02   4.24875431e-02
   2.54727930e-01   1.34075072e-16   6.93918573e-17   8.32567279e-17
   1.95519133e-16]
[2017-11-01 10:09:36,009] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.95685041e-04   6.91666603e-01   4.43762802e-02   6.72950670e-02
   1.95964724e-01   4.17972643e-07   4.72513420e-07   2.36433777e-07
   5.28931594e-07]
[2017-11-01 10:09:40,425] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.11591202e-21   3.31771867e-06   1.72510696e-07   2.67752995e-07
   9.83202995e-07   1.18396074e-01   1.37883589e-01   9.76280123e-02
   6.46087527e-01]
[2017-11-01 10:09:42,637] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.33521000e-30   9.82250652e-12   2.94090219e-13   7.35719049e-13
   2.49263002e-12   1.04860142e-01   1.48872659e-01   8.60741585e-02
   6.60193026e-01]
[2017-11-01 10:09:44,148] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.18279357e-03   6.64763808e-01   6.24194555e-02   8.85333642e-02
   1.82099953e-01   1.65284305e-07   1.94713863e-07   7.76020599e-08
   2.02717700e-07]
[2017-11-01 10:09:44,556] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.04668441e-02   5.59249938e-01   6.93328977e-02   8.64126682e-02
   2.04537705e-01   3.65606967e-09   3.35996742e-09   1.85702309e-09
   3.64164920e-09]
[2017-11-01 10:09:48,729] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.89293588e-12   7.41856277e-01   3.92426215e-02   4.09855880e-02
   1.75658673e-01   3.00014566e-04   2.59340042e-04   2.22510062e-04
   1.47510180e-03]
[2017-11-01 10:09:50,107] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.76940542e-02   4.85126793e-01   8.59939680e-02   4.24559340e-02
   2.88729250e-01   1.87832302e-17   9.44163142e-18   1.13433428e-17
   3.19650051e-17]
[2017-11-01 10:09:52,169] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.46421174e-11   7.99725950e-01   3.65639962e-02   3.27327736e-02
   1.24057315e-01   1.38942758e-03   8.92766868e-04   8.81908112e-04
   3.75593686e-03]
[2017-11-01 10:09:53,191] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.77566094e-18   8.32226418e-04   3.15791840e-05   3.52044044e-05
   1.38443793e-04   1.71958193e-01   1.21921740e-01   1.10939883e-01
   5.94142735e-01]
[2017-11-01 10:10:04,998] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.05980545e-01   4.71067071e-01   1.19749509e-01   1.36123240e-01
   1.67079702e-01   5.46071854e-10   4.37904879e-10   1.74902967e-10
   5.83806004e-10]
[2017-11-01 10:10:08,585] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.11170305e-34   8.21865701e-14   2.12462735e-15   3.70027063e-15
   1.30666572e-14   1.50210947e-01   1.12984501e-01   9.81476530e-02
   6.38656855e-01]
[2017-11-01 10:10:09,076] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.61065817e-08   8.04302275e-01   3.84710319e-02   2.80739497e-02
   1.29152730e-01   4.01023909e-10   2.80370199e-10   2.40142906e-10
   1.23931854e-09]
[2017-11-01 10:10:12,607] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.68750405e-01   4.77442861e-01   1.01763643e-01   6.06574565e-02
   1.91385642e-01   7.83333766e-14   4.58674846e-14   4.83261129e-14
   9.33972477e-14]
[2017-11-01 10:10:14,270] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.32297397e-02   5.00369966e-01   8.72756019e-02   4.87127602e-02
   3.00411999e-01   3.58152364e-17   2.34616993e-17   2.12905288e-17
   1.04693372e-16]
[2017-11-01 10:10:15,641] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.66883429e-03   6.83161616e-01   4.87907492e-02   7.30037019e-02
   1.92374364e-01   1.89667475e-07   1.88136923e-07   1.07385461e-07
   2.63668966e-07]
[2017-11-01 10:10:20,262] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.20212130e-05   5.83959162e-01   6.11369945e-02   4.73816171e-02
   3.07490170e-01   6.14626579e-12   5.93050045e-12   5.29162521e-12
   2.59407912e-11]
[2017-11-01 10:10:23,824] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.97029999e-06   7.15938985e-01   3.42006125e-02   6.48320764e-02
   1.79960176e-01   1.22502213e-03   1.36273785e-03   6.98465388e-04
   1.77788769e-03]
[2017-11-01 10:10:24,328] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.32030380e-04   7.19767809e-01   3.77007276e-02   6.20613284e-02
   1.80134773e-01   8.36249569e-07   9.02850275e-07   4.74978066e-07
   1.14289560e-06]
[2017-11-01 10:10:24,652] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.36901320e-14   6.82297861e-04   2.31511258e-05   5.00019960e-05
   1.24153317e-04   2.33266994e-01   2.44021937e-01   1.34872809e-01
   3.86958599e-01]
[2017-11-01 10:10:28,805] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.11234955e-03   4.81400967e-01   1.01872496e-01   6.25190437e-02
   3.46095204e-01   7.30237200e-14   5.77859226e-14   5.46055205e-14
   2.69673362e-13]
[2017-11-01 10:10:31,371] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.45407322e-02   5.94607651e-01   5.79251237e-02   7.63237625e-02
   1.86602652e-01   5.69251257e-10   5.08361742e-10   3.04080511e-10
   6.64416133e-10]
[2017-11-01 10:10:34,784] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.90181161e-07   7.21740901e-01   6.06379323e-02   3.94446105e-02
   1.78175837e-01   4.15299002e-12   2.98180773e-12   2.78954724e-12
   1.53138873e-11]
[2017-11-01 10:10:36,171] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.19701743e-02   6.11061096e-01   5.82938157e-02   7.73529485e-02
   1.91321909e-01   1.91806326e-09   1.73277304e-09   1.03410203e-09
   2.60763811e-09]
[2017-11-01 10:10:36,685] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.39925781e-02   6.09951377e-01   5.33091575e-02   7.07817450e-02
   1.81965128e-01   1.66271108e-10   1.48844451e-10   8.88397619e-11
   1.94565683e-10]
[2017-11-01 10:10:37,873] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04144390e-03   7.19664872e-01   7.99716786e-02   4.06478234e-02
   1.58674240e-01   6.72326371e-14   3.96702460e-14   3.86992853e-14
   1.26137206e-13]
[2017-11-01 10:10:38,166] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.74638711e-07   7.62726307e-01   6.01952001e-02   3.64134274e-02
   1.40664563e-01   4.05674355e-10   2.51251742e-10   2.45132081e-10
   8.90112539e-10]
[2017-11-01 10:10:40,458] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.58888949e-02   4.93155926e-01   1.08216338e-01   5.06071039e-02
   2.92131722e-01   2.32046608e-16   1.43971130e-16   1.45672673e-16
   7.48575743e-16]
[2017-11-01 10:10:40,482] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.35472501e-02   5.28607428e-01   1.08080268e-01   5.43179885e-02
   2.95447022e-01   1.81695047e-15   1.20887335e-15   1.15637001e-15
   6.34603945e-15]
[2017-11-01 10:10:42,095] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.20112383e-12   3.59147252e-03   2.42685899e-04   6.21348794e-04
   9.31077055e-04   2.18504846e-01   2.27313116e-01   8.41409117e-02
   4.64654565e-01]
[2017-11-01 10:10:43,434] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.26469829e-10   5.55105396e-02   1.99884176e-03   4.66435449e-03
   1.25830481e-02   2.08626926e-01   2.31189862e-01   1.18861154e-01
   3.66565317e-01]
[2017-11-01 10:10:43,888] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.73454867e-07   7.08159864e-01   3.13086845e-02   6.33573234e-02
   1.62288025e-01   8.16810597e-03   8.85638874e-03   4.48778830e-03
   1.33735510e-02]
[2017-11-01 10:10:43,897] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.19337700e-08   5.51207244e-01   2.33781543e-02   4.96519096e-02
   1.26802206e-01   5.76957427e-02   6.27678111e-02   3.19482982e-02
   9.65484977e-02]
[2017-11-01 10:10:48,222] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.30912143e-05   7.18364120e-01   3.68892923e-02   6.33627400e-02
   1.81282029e-01   6.77451771e-06   6.13223165e-06   3.97391386e-06
   1.18144162e-05]
[2017-11-01 10:10:52,767] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04417108e-01   4.70054716e-01   1.33067399e-01   1.25668883e-01
   1.66791886e-01   2.77194023e-12   1.89801603e-12   8.20071929e-13
   3.60532047e-12]
[2017-11-01 10:10:52,960] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.82329221e-07   5.43899000e-01   4.38673422e-02   8.74365419e-02
   1.45491019e-01   4.39772606e-02   4.86019403e-02   2.06914507e-02
   6.60348088e-02]
[2017-11-01 10:10:53,298] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04458752e-06   3.95995200e-01   3.78376022e-02   7.03531355e-02
   1.37153313e-01   8.46861526e-02   7.82287270e-02   4.82725985e-02
   1.47472188e-01]
[2017-11-01 10:10:53,529] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.50491996e-02   5.44974148e-01   9.08827484e-02   1.15200780e-01
   1.93892986e-01   5.89945941e-08   5.07921492e-08   3.22820064e-08
   6.72158080e-08]
[2017-11-01 10:10:58,937] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.01398849e-02   5.91898143e-01   6.78761825e-02   8.61498713e-02
   1.83935955e-01   1.39325440e-09   1.39866474e-09   6.13619544e-10
   1.53250401e-09]
[2017-11-01 10:11:01,590] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.37244626e-06   6.53489053e-01   7.15139732e-02   4.83341664e-02
   2.26661414e-01   6.05026029e-11   4.83459384e-11   4.63069166e-11
   2.19942523e-10]
[2017-11-01 10:11:02,896] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.72168870e-21   9.04160061e-06   3.18604123e-07   5.73284581e-07
   2.44953321e-06   1.08848274e-01   1.30744293e-01   9.29467231e-02
   6.67448342e-01]
[2017-11-01 10:11:05,528] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.92033333e-02   5.45365512e-01   6.84179589e-02   8.70843083e-02
   1.99928939e-01   2.66698841e-09   2.45972065e-09   1.37152900e-09
   2.50528909e-09]
[2017-11-01 10:11:05,551] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.74435732e-02   5.49182057e-01   6.77541345e-02   8.68349001e-02
   1.98785275e-01   2.66393951e-09   2.48522536e-09   1.36505729e-09
   2.57136312e-09]
[2017-11-01 10:11:07,893] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.49148035e-02   5.17569363e-01   1.03570946e-01   4.46937308e-02
   2.49251187e-01   4.65600353e-16   2.83566752e-16   2.82254407e-16
   9.54883535e-16]
[2017-11-01 10:11:12,286] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.87598799e-06   6.72729075e-01   5.45451529e-02   9.85547304e-02
   1.73940286e-01   5.51718222e-05   6.76433265e-05   2.32800867e-05
   7.57684975e-05]
[2017-11-01 10:11:18,892] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  6.15601266e-13   2.61462847e-04   1.70973090e-05   3.92132351e-05
   6.70488807e-05   2.34894171e-01   2.92036265e-01   1.12810135e-01
   3.59874576e-01]
[2017-11-01 10:11:23,595] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.18780632e-23   2.08404586e-07   8.57881499e-09   1.48885988e-08
   5.35129239e-08   1.12794757e-01   1.24582179e-01   8.76357928e-02
   6.74986959e-01]
[2017-11-01 10:11:25,213] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.89586139e-08   4.55199182e-01   1.84412282e-02   3.94906327e-02
   1.10747457e-01   8.53937715e-02   8.65719244e-02   5.12030236e-02
   1.52952641e-01]
[2017-11-01 10:11:30,654] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.17815298e-02   6.92589700e-01   4.12657857e-02   5.66088483e-02
   1.67754158e-01   8.39949638e-11   7.34094174e-11   4.76781219e-11
   1.26872998e-10]
[2017-11-01 10:11:32,057] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  2.24545027e-09   6.91418052e-01   5.77386096e-02   5.40536717e-02
   1.96787074e-01   3.28378235e-07   2.69894088e-07   2.46590275e-07
   1.75189257e-06]
[2017-11-01 10:11:32,796] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.16002430e-05   6.02234781e-01   1.07829861e-01   1.23852231e-01
   1.66001514e-01   1.46037693e-09   1.08185394e-09   4.71107764e-10
   3.13302895e-09]
[2017-11-01 10:11:34,197] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.24369048e-01   5.56516588e-01   9.83209908e-02   4.88182046e-02
   1.71975166e-01   1.65981638e-16   8.34124297e-17   9.02288877e-17
   3.15930875e-16]
[2017-11-01 10:11:36,347] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.68228468e-07   8.03096175e-01   2.07243431e-02   4.47578765e-02
   1.30698383e-01   1.66780155e-04   1.91191051e-04   8.69452706e-05
   2.78138876e-04]
[2017-11-01 10:11:38,932] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.28801831e-15   6.33918867e-02   2.83957249e-03   3.34440498e-03
   1.49908699e-02   1.19371429e-01   9.99640599e-02   9.12101790e-02
   6.04887605e-01]
[2017-11-01 10:11:39,863] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.09472808e-10   7.21855760e-01   4.23065461e-02   4.24967594e-02
   1.93320811e-01   2.75272373e-06   2.58649698e-06   2.19332355e-06
   1.25966944e-05]
[2017-11-01 10:11:40,641] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.00648203e-02   4.84021634e-01   1.02439582e-01   4.76155728e-02
   2.95858413e-01   5.65407992e-17   3.04252382e-17   3.62656362e-17
   1.32496388e-16]
[2017-11-01 10:11:41,560] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.55673055e-10   3.09814304e-01   7.32403295e-03   1.85972787e-02
   4.88912575e-02   1.38072103e-01   1.61575437e-01   7.03505203e-02
   2.45375156e-01]
[2017-11-01 10:11:41,894] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  9.55172013e-08   7.57825732e-01   2.33364198e-02   5.07231466e-02
   1.36377469e-01   7.28643034e-03   8.23496561e-03   3.98642523e-03
   1.22293159e-02]
[2017-11-01 10:11:42,573] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.10255189e-01   5.68045735e-01   9.42659900e-02   4.42328416e-02
   1.83200210e-01   5.57632494e-17   3.13845725e-17   2.91840868e-17
   8.63941710e-17]
[2017-11-01 10:11:43,417] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  4.35864367e-03   5.71532071e-01   1.02563910e-01   5.24693169e-02
   2.69076079e-01   8.55498127e-14   6.15402843e-14   6.33215675e-14
   2.60330711e-13]
[2017-11-01 10:11:44,594] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.62151651e-14   2.00008880e-02   1.47338340e-03   1.94442458e-03
   7.06783729e-03   1.11886717e-01   1.27369851e-01   1.00117229e-01
   6.30139649e-01]
[2017-11-01 10:11:46,599] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.04084939e-01   5.22372901e-01   7.71642774e-02   9.49267149e-02
   2.01451093e-01   2.94318481e-09   2.42839726e-09   1.65342240e-09
   2.72765543e-09]
[2017-11-01 10:11:46,854] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.40942022e-01   4.61461663e-01   9.09351557e-02   1.11911900e-01
   1.94749251e-01   6.48761989e-10   5.47338730e-10   3.48132662e-10
   5.17475007e-10]
[2017-11-01 10:11:47,501] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.34420795e-13   7.20265061e-02   5.88170160e-03   5.71153732e-03
   1.74441505e-02   1.56907991e-01   1.24420248e-01   1.01632558e-01
   5.15975237e-01]
[2017-11-01 10:11:47,547] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.76475479e-13   1.68716595e-01   1.22415731e-02   1.21270493e-02
   4.00455855e-02   1.23956628e-01   9.91742909e-02   8.20153877e-02
   4.61722821e-01]
[2017-11-01 10:11:48,323] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.65460506e-02   4.65082020e-01   1.31579340e-01   5.80096729e-02
   2.68783003e-01   1.64086428e-16   8.65308212e-17   9.49369615e-17
   3.88645424e-16]
[2017-11-01 10:11:51,127] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.61429337e-02   7.08347678e-01   2.83842105e-02   4.32411432e-02
   1.63884088e-01   8.93069256e-13   9.32905879e-13   4.81715958e-13
   1.34614943e-12]
[2017-11-01 10:11:51,461] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.69431405e-07   7.72534907e-01   5.72806038e-02   3.76918539e-02
   1.32492244e-01   1.67587466e-09   1.07580300e-09   1.02262998e-09
   3.66536512e-09]
[2017-11-01 10:11:54,688] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.46698235e-02   5.03778696e-01   8.15373883e-02   4.34657075e-02
   3.16548496e-01   1.11705898e-16   7.47923740e-17   7.48563117e-17
   3.13794076e-16]
[2017-11-01 10:12:08,530] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.28838226e-01   3.47191095e-01   1.64882183e-01   1.79692119e-01
   1.79392144e-01   1.30811407e-06   1.15683122e-06   6.97724658e-07
   9.80659479e-07]
[2017-11-01 10:12:09,020] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  5.67621905e-09   7.08146513e-01   6.78447857e-02   5.17413355e-02
   1.72225058e-01   8.55845701e-06   6.21561867e-06   5.65403298e-06
   2.18567893e-05]
[2017-11-01 10:12:12,056] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.00357018e-01   5.04094124e-01   9.42896456e-02   1.18980683e-01
   1.82278514e-01   6.56720234e-10   6.06144801e-10   2.32533617e-10
   6.02769112e-10]
[2017-11-01 10:12:12,821] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.37386784e-01   4.50583905e-01   1.01596780e-01   1.14910118e-01
   1.95522398e-01   2.64741242e-08   2.08929638e-08   1.60103948e-08
   2.04660466e-08]
[2017-11-01 10:12:13,479] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.64123386e-01   4.53173041e-01   1.10662386e-01   5.61271980e-02
   2.15913951e-01   1.94533038e-15   9.19427900e-16   1.17840918e-15
   2.95728107e-15]
[2017-11-01 10:12:13,519] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  1.59864292e-01   4.64010686e-01   1.10653691e-01   5.54875545e-02
   2.09983796e-01   1.36025455e-15   6.45920326e-16   8.00458099e-16
   2.09974280e-15]
[2017-11-01 10:12:14,020] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.70181723e-05   7.09190547e-01   8.25293362e-02   4.75331098e-02
   1.60669997e-01   2.40519410e-12   1.52450145e-12   1.47723684e-12
   6.28656936e-12]
[2017-11-01 10:12:15,362] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  3.23242952e-13   4.79587466e-01   2.17909701e-02   2.13310514e-02
   7.55167529e-02   7.44526908e-02   4.56121266e-02   4.47230861e-02
   2.36985922e-01]
[2017-11-01 10:12:20,033] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  7.65221220e-10   7.79029548e-01   4.93086874e-02   3.64690684e-02
   1.35176882e-01   3.26751365e-06   2.05664855e-06   1.94493873e-06
   8.50482229e-06]
[2017-11-01 10:12:21,993] A3C_AGENT_WORKER-Thread-17 INFO:Softmax [  8.27684328e-02   4.89025176e-01   9.75994840e-02   4.71053757e-02
   2.83501506e-01   2.21322347e-17   1.19354370e-17   1.31149155e-17
   4.78568520e-17]
