Using TensorFlow backend.
[2017-11-02 09:39:31,143] A3C_AGENT_MAIN INFO:Namespace(act_func='6', action_space='iw_af5_1', agent_num=5, clip_norm=5.0, decay_steps=1000000, dropout_prob=0.5, end_e=0.0, env='IW-v570202', err_penalty_scl=0.15, eval_epi_num=1, eval_freq=250000, gamma=0.99, h_regu_frac=0.01, init_e=0.0, is_warm_start=True, job_mode='Train', learning_rate=0.0001, max_interactions=15000000, model_dir='a3c-res-v0.1/IW-v5702-run1/model_data/model.ckpt-15000000', num_threads=16, output='a3c-res-v0.1/IW-v570202-run5', p_loss_frac=1.0, reward_func='10', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=0.9, rwd_p_para=0.1, save_freq=500000, save_scope='all', state_dim=13, test_env='IW-eval-v570202', test_mode='Multiple', train_freq=5, v_loss_frac=0.5, window_len=24)
[2017-11-02 09:39:31,143] A3C_AGENT_MAIN INFO:Start compiling...
2017-11-02 09:39:34.549882: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549898: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549912: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549914: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-02 09:39:34.549916: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[2017-11-02 09:39:36,110] A3C_AGENT_MAIN INFO:Start the learning...
[2017-11-02 09:39:36,112] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['IW-v570202'] ...
[2017-11-02 09:39:36,112] Making new env: IW-v570202
[2017-11-02 09:39:36,139] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:36,139] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2017-11-02 09:39:36,140] Making new env: IW-v570202
[2017-11-02 09:39:36,145] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:36,147] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res2/Eplus-env-sub_run1
[2017-11-02 09:39:37,141] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:37,141] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2017-11-02 09:39:37,142] Making new env: IW-v570202
[2017-11-02 09:39:37,154] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:37,157] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res3/Eplus-env-sub_run1
[2017-11-02 09:39:38,142] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:38,144] A3C_AGENT_WORKER-Thread-4 INFO:Local worker starts!
[2017-11-02 09:39:38,144] Making new env: IW-v570202
[2017-11-02 09:39:38,151] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:38,152] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res4/Eplus-env-sub_run1
[2017-11-02 09:39:39,145] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:39,145] A3C_AGENT_WORKER-Thread-5 INFO:Local worker starts!
[2017-11-02 09:39:39,145] Making new env: IW-v570202
[2017-11-02 09:39:39,152] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:39,155] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res5/Eplus-env-sub_run1
[2017-11-02 09:39:40,146] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:40,147] A3C_AGENT_WORKER-Thread-6 INFO:Local worker starts!
[2017-11-02 09:39:40,147] Making new env: IW-v570202
[2017-11-02 09:39:40,154] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:40,156] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res6/Eplus-env-sub_run1
[2017-11-02 09:39:41,148] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:41,149] A3C_AGENT_WORKER-Thread-7 INFO:Local worker starts!
[2017-11-02 09:39:41,149] Making new env: IW-v570202
[2017-11-02 09:39:41,160] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:41,162] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res7/Eplus-env-sub_run1
[2017-11-02 09:39:42,150] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:42,151] A3C_AGENT_WORKER-Thread-8 INFO:Local worker starts!
[2017-11-02 09:39:42,151] Making new env: IW-v570202
[2017-11-02 09:39:42,162] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:42,165] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res8/Eplus-env-sub_run1
[2017-11-02 09:39:43,152] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:43,153] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2017-11-02 09:39:43,153] Making new env: IW-v570202
[2017-11-02 09:39:43,165] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:43,168] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res9/Eplus-env-sub_run1
[2017-11-02 09:39:44,153] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:44,153] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2017-11-02 09:39:44,154] Making new env: IW-v570202
[2017-11-02 09:39:44,166] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:44,169] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res10/Eplus-env-sub_run1
[2017-11-02 09:39:45,154] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:45,155] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2017-11-02 09:39:45,155] Making new env: IW-v570202
[2017-11-02 09:39:45,167] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:45,170] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res11/Eplus-env-sub_run1
[2017-11-02 09:39:46,156] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:46,157] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2017-11-02 09:39:46,157] Making new env: IW-v570202
[2017-11-02 09:39:46,171] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:46,174] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res12/Eplus-env-sub_run1
[2017-11-02 09:39:47,158] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:47,159] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2017-11-02 09:39:47,159] Making new env: IW-v570202
[2017-11-02 09:39:47,175] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:47,185] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res13/Eplus-env-sub_run1
[2017-11-02 09:39:48,160] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:48,161] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2017-11-02 09:39:48,161] Making new env: IW-v570202
[2017-11-02 09:39:48,173] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:48,176] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res14/Eplus-env-sub_run1
[2017-11-02 09:39:49,161] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:49,162] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2017-11-02 09:39:49,162] Making new env: IW-v570202
[2017-11-02 09:39:49,174] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:49,176] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res15/Eplus-env-sub_run1
[2017-11-02 09:39:50,163] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:50,163] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2017-11-02 09:39:50,164] Making new env: IW-v570202
[2017-11-02 09:39:50,174] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:50,177] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res16/Eplus-env-sub_run1
[2017-11-02 09:39:51,164] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2017-11-02 09:39:51,165] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2017-11-02 09:39:51,165] Making new env: IW-v570202
[2017-11-02 09:39:51,181] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:39:51,192] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res17/Eplus-env-sub_run1
[2017-11-02 09:40:24,485] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 09:40:24,485] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 09:40:24,488] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run1
[2017-11-02 09:41:02,050] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.28252757e-05   3.18736166e-01   2.37650216e-01   3.63286793e-01
   8.02871883e-02   5.14919066e-06   2.95183736e-06   3.79793414e-06
   4.97814153e-06]
[2017-11-02 09:41:03,785] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10477369  0.12697582  0.15794802  0.13980746  0.09610155  0.12415372
  0.09362306  0.09706853  0.05954813]
[2017-11-02 09:41:08,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.19946255e-03   3.73847157e-01   1.90802649e-01   3.58670533e-01
   7.34801963e-02   5.82307466e-12   2.60209541e-12   3.66819856e-12
   3.45965205e-12]
[2017-11-02 09:41:10,688] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.63415781e-05   3.21877360e-01   2.00796604e-01   3.84426385e-01
   9.28533822e-02   6.33277697e-09   3.01964209e-09   3.36803696e-09
   3.68436281e-09]
[2017-11-02 09:41:18,505] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30946940e-14   1.85919041e-03   8.93111632e-04   3.05128703e-03
   5.08802070e-04   3.04039150e-01   1.66716695e-01   2.12791860e-01
   3.10139894e-01]
[2017-11-02 09:41:20,073] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.14060298e-14   3.07285669e-03   1.45701785e-03   4.84669069e-03
   8.31147016e-04   3.07508767e-01   1.72876224e-01   2.15792343e-01
   2.93615013e-01]
[2017-11-02 09:41:21,876] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.24947918e-10   1.82918295e-01   7.77010620e-02   2.24794313e-01
   4.74962592e-02   1.44899130e-01   9.26221311e-02   1.09322213e-01
   1.20246634e-01]
[2017-11-02 09:41:22,390] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.98328407e-22   1.01993525e-08   3.77982978e-09   1.29456277e-08
   2.45246201e-09   2.94950157e-01   2.03745633e-01   2.22952828e-01
   2.78351307e-01]
[2017-11-02 09:41:24,244] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.52805485e-11   1.41464859e-01   4.74064872e-02   1.54857516e-01
   2.67529860e-02   1.99254051e-01   1.14953972e-01   1.40629798e-01
   1.74680457e-01]
[2017-11-02 09:41:30,744] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.16412743e-20   6.53800925e-09   9.49592494e-09   1.55836783e-08
   3.30441563e-09   3.52797478e-01   1.99724674e-01   1.98806420e-01
   2.48671368e-01]
[2017-11-02 09:41:36,400] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.69405476e-30   1.12059355e-13   5.30705783e-14   1.88997486e-13
   3.51900922e-14   2.76442856e-01   2.02818558e-01   2.09953949e-01
   3.10784608e-01]
[2017-11-02 09:41:43,772] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28845245e-01   2.64631569e-01   2.40211919e-01   2.84537077e-01
   8.17741454e-02   4.41206880e-12   1.58224735e-12   1.61180574e-12
   1.06450981e-12]
[2017-11-02 09:42:06,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37029797e-01   2.47203037e-01   2.47622088e-01   2.81677902e-01
   8.64671469e-02   2.86249774e-11   9.51384110e-12   9.91655803e-12
   4.39675423e-12]
[2017-11-02 09:42:26,030] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.68557192e-04   3.28458339e-01   2.39902243e-01   3.52035016e-01
   7.94355422e-02   1.12680894e-07   6.07089206e-08   7.82234579e-08
   8.73698269e-08]
[2017-11-02 09:42:27,112] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28429225e-02   3.21096361e-01   2.39834085e-01   3.43719512e-01
   8.25071558e-02   3.75264403e-12   1.70422129e-12   2.25060660e-12
   2.06064527e-12]
[2017-11-02 09:42:30,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30113706e-01   2.35688180e-01   2.84806550e-01   2.57316977e-01
   9.20745656e-02   1.13392016e-08   4.27716440e-09   4.95270980e-09
   2.49469556e-09]
[2017-11-02 09:42:30,751] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.13363207e-16   6.68382345e-05   5.26704753e-05   1.16276504e-04
   2.48399429e-05   3.20855528e-01   1.74220011e-01   1.95501596e-01
   3.09162289e-01]
[2017-11-02 09:42:34,630] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.79499213e-27   3.50830281e-12   1.65488012e-12   4.90869845e-12
   8.38243049e-13   2.69474089e-01   2.03335240e-01   2.08303347e-01
   3.18887293e-01]
[2017-11-02 09:42:39,016] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.44381521e-36   1.10079062e-17   1.39601717e-17   3.33953261e-17
   6.07830843e-18   3.23084176e-01   1.95363343e-01   1.77403286e-01
   3.04149270e-01]
[2017-11-02 09:42:40,266] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00100232  0.22695528  0.26091322  0.26256865  0.09324251  0.05872258
  0.03448647  0.03833093  0.02377808]
[2017-11-02 09:42:41,193] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17244408e-05   2.47832239e-01   2.94002861e-01   3.66803646e-01
   9.12893191e-02   2.71662975e-05   1.11916370e-05   1.21569365e-05
   9.74633895e-06]
[2017-11-02 09:42:44,668] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.02014550e-04   3.81073356e-01   1.92339256e-01   3.43379229e-01
   8.31061751e-02   7.84525866e-09   4.37167680e-09   5.35343103e-09
   4.24837499e-09]
[2017-11-02 09:42:49,068] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.46419321e-09   1.16272151e-01   1.02272183e-01   1.88598782e-01
   4.02249098e-02   1.87273920e-01   1.12837650e-01   1.04895778e-01
   1.47624597e-01]
[2017-11-02 09:42:50,910] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12436826  0.15277146  0.18944806  0.16113153  0.10127898  0.08750349
  0.07136748  0.06769231  0.04443851]
[2017-11-02 09:42:51,205] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12544468  0.1663375   0.22207785  0.18517894  0.10670095  0.06533281
  0.05175926  0.04801964  0.02914828]
[2017-11-02 09:42:56,200] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.86623642e-14   2.86329276e-04   1.30771441e-04   3.14010860e-04
   7.07528816e-05   3.07793379e-01   2.10409924e-01   2.29074910e-01
   2.51919955e-01]
[2017-11-02 09:42:56,895] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.77811832e-05   3.87941331e-01   1.87630519e-01   3.55018556e-01
   6.93802088e-02   5.52161339e-07   3.13003170e-07   3.71326308e-07
   3.86165397e-07]
[2017-11-02 09:42:58,925] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.24996342e-08   3.69039237e-01   1.59450039e-01   3.89414549e-01
   7.30282813e-02   2.89770239e-03   1.76404743e-03   1.96853746e-03
   2.43750494e-03]
[2017-11-02 09:42:59,055] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.26172915e-27   5.72230718e-12   2.21816272e-12   7.28951881e-12
   1.19902157e-12   2.73796290e-01   2.02328816e-01   2.08159789e-01
   3.15715164e-01]
[2017-11-02 09:43:03,548] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.39305881e-17   2.93549931e-07   3.74037967e-07   5.69322481e-07
   1.32713680e-07   3.53763163e-01   2.25322366e-01   1.96472690e-01
   2.24440485e-01]
[2017-11-02 09:43:05,035] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.63810531e-05   2.94520736e-01   2.82198191e-01   3.30850691e-01
   9.23024863e-02   2.22926919e-05   1.07031710e-05   1.09024531e-05
   7.66650464e-06]
[2017-11-02 09:43:08,704] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.34519607e-01   3.12271506e-01   1.95128486e-01   2.78673947e-01
   7.94064626e-02   9.80829025e-13   4.10539549e-13   5.96967083e-13
   4.04557274e-13]
[2017-11-02 09:43:12,449] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.81501358e-10   8.15983629e-04   9.34509735e-04   1.30375917e-03
   3.89320950e-04   3.20529491e-01   2.41811782e-01   2.11005345e-01
   2.23209798e-01]
[2017-11-02 09:43:14,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11955263  0.18932657  0.28473157  0.23105283  0.11438119  0.02449842
  0.01372917  0.01502881  0.00769881]
[2017-11-02 09:43:17,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.74048994e-07   2.98020869e-01   2.22276062e-01   3.77228379e-01
   8.77018273e-02   4.37094970e-03   2.87030288e-03   3.19054420e-03
   4.34064213e-03]
[2017-11-02 09:43:17,440] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.69770941e-06   3.10015470e-01   2.40825832e-01   3.67439717e-01
   8.14768076e-02   6.79307850e-05   4.14063070e-05   5.13347768e-05
   7.38248564e-05]
[2017-11-02 09:43:18,552] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.33919157e-03   3.11336070e-01   2.56759346e-01   3.47362876e-01
   8.32025111e-02   5.90313975e-09   3.03085002e-09   3.90900734e-09
   4.42266446e-09]
[2017-11-02 09:43:22,312] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13270339  0.14357665  0.17587286  0.16245335  0.09667248  0.0961088
  0.07050433  0.07683697  0.04527113]
[2017-11-02 09:43:26,404] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14933728  0.12572701  0.14890297  0.14538623  0.10163717  0.10532612
  0.08203855  0.09143983  0.05020486]
[2017-11-02 09:43:29,292] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0947002   0.09773389  0.13491972  0.11923623  0.10525832  0.11764742
  0.12025119  0.1177215   0.09253152]
[2017-11-02 09:43:30,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12727849  0.12692334  0.14738874  0.1422388   0.09388508  0.1134325
  0.08830678  0.10033896  0.06020725]
[2017-11-02 09:43:32,611] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11672171  0.11223304  0.14357509  0.12911589  0.1088408   0.11105293
  0.10287127  0.10349435  0.07209488]
[2017-11-02 09:43:34,707] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06523711  0.21029095  0.34071928  0.26996952  0.09995704  0.00437722
  0.00263179  0.00358227  0.00323491]
[2017-11-02 09:43:35,258] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11334954  0.14780691  0.20882556  0.18339306  0.10446154  0.08606615
  0.05927387  0.06065799  0.03616531]
[2017-11-02 09:43:37,962] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.17086142e-14   1.13752023e-04   7.97821485e-05   1.79186580e-04
   3.82442813e-05   2.77234823e-01   1.95759743e-01   2.11505339e-01
   3.15089136e-01]
[2017-11-02 09:43:41,528] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.61287919e-01   2.20932648e-01   2.61097997e-01   2.55333930e-01
   1.01347312e-01   1.04349716e-07   4.32538805e-08   4.38008207e-08
   1.78836235e-08]
[2017-11-02 09:43:42,010] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14321859  0.15170468  0.17503284  0.14928551  0.10567389  0.09550665
  0.0727733   0.0689097   0.03789483]
[2017-11-02 09:43:45,032] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37543620e-03   3.14243287e-01   2.77737945e-01   3.17976594e-01
   8.86647925e-02   6.60935711e-07   3.66845939e-07   4.30794955e-07
   4.22385284e-07]
[2017-11-02 09:43:45,089] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.28071336e-07   3.12577218e-01   2.21403703e-01   3.35418075e-01
   8.40520337e-02   1.40606575e-02   9.38372687e-03   1.04257418e-02
   1.26779592e-02]
[2017-11-02 09:43:45,694] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.26778433e-01   2.49436304e-01   2.27596551e-01   2.23058239e-01
   7.31304139e-02   4.44955964e-12   1.66666680e-12   2.11514270e-12
   1.26041029e-12]
[2017-11-02 09:43:46,175] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86399204e-02   2.71391124e-01   2.74782985e-01   2.72083551e-01
   8.31024423e-02   5.72111247e-10   2.54808147e-10   3.22510962e-10
   2.93680941e-10]
[2017-11-02 09:43:47,888] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10161884  0.10732946  0.13339417  0.11567578  0.1111881   0.11251442
  0.12221994  0.1068032   0.08925614]
[2017-11-02 09:43:49,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12737598  0.21235171  0.28595328  0.24684024  0.11767058  0.00318967
  0.0021207   0.00257332  0.00192456]
[2017-11-02 09:43:50,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00840993e-01   2.33683690e-01   3.07087064e-01   2.66130984e-01
   9.22506973e-02   2.28676845e-06   1.20194795e-06   1.67267820e-06
   1.47718106e-06]
[2017-11-02 09:43:52,583] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12501822  0.11456114  0.15064983  0.13224165  0.11417045  0.09791965
  0.09797551  0.09753846  0.06992505]
[2017-11-02 09:43:52,900] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17742012  0.1336382   0.17601392  0.16235463  0.10554547  0.08954589
  0.05993908  0.06681728  0.02872532]
[2017-11-02 09:43:52,971] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14897069  0.13328607  0.16870902  0.15816645  0.10450377  0.10142288
  0.06952176  0.07670344  0.03871595]
[2017-11-02 09:43:54,061] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.13123648e-01   2.18031585e-01   3.09342057e-01   2.64112234e-01
   9.53854769e-02   1.71526005e-06   8.74066188e-07   1.27795454e-06
   1.12025293e-06]
[2017-11-02 09:43:54,228] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.76107953e-02   2.62985826e-01   3.10109526e-01   2.95863420e-01
   9.34291407e-02   3.97995962e-07   1.95024256e-07   3.06105420e-07
   3.32695379e-07]
[2017-11-02 09:43:54,313] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10880338  0.16886032  0.2431069   0.2163599   0.11866811  0.05181517
  0.03464351  0.0355081   0.02223456]
[2017-11-02 09:43:54,621] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11783111  0.16024955  0.24153499  0.22144467  0.11680805  0.05451405
  0.03275524  0.03577547  0.0190868 ]
[2017-11-02 09:43:54,727] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08962225  0.1218429   0.18112758  0.16440409  0.09485769  0.12301326
  0.07821257  0.09149733  0.05542231]
[2017-11-02 09:44:00,130] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.01943398e-13   1.04635218e-02   5.90111408e-03   1.72256529e-02
   3.15170619e-03   2.73122102e-01   1.80853546e-01   1.95447892e-01
   3.13834429e-01]
[2017-11-02 09:44:02,729] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30013481e-01   2.28752494e-01   2.83322006e-01   2.67982036e-01
   8.99299979e-02   1.62063185e-09   6.15958340e-10   7.19425408e-10
   4.51953169e-10]
[2017-11-02 09:44:02,767] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.20960444e-02   2.45969638e-01   3.05479586e-01   2.88970798e-01
   9.74838063e-02   4.68767034e-08   1.90834974e-08   2.23536318e-08
   1.44067362e-08]
[2017-11-02 09:44:10,407] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.36845764e-12   5.08163832e-02   2.31584702e-02   7.19672143e-02
   1.23501476e-02   2.51650631e-01   1.54957056e-01   1.74707413e-01
   2.60392725e-01]
[2017-11-02 09:44:11,514] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97845675e-33   8.83658737e-15   3.31714132e-15   1.50885299e-14
   2.31573789e-15   2.64905661e-01   1.89348429e-01   1.97161794e-01
   3.48584056e-01]
[2017-11-02 09:44:18,688] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.36718109e-01   3.12468946e-01   1.98341757e-01   2.74196237e-01
   7.82749578e-02   1.93097305e-14   7.01414728e-15   9.32419205e-15
   7.56260746e-15]
[2017-11-02 09:44:20,477] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.32623991e-05   3.72538060e-01   1.67006388e-01   3.67894590e-01
   9.24777091e-02   2.23316296e-10   1.07338159e-10   1.44051895e-10
   1.53670368e-10]
[2017-11-02 09:44:23,762] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.01941783e-12   5.53527176e-02   1.76772196e-02   6.47237524e-02
   1.10922074e-02   2.53012806e-01   1.57056093e-01   1.89081907e-01
   2.52003342e-01]
[2017-11-02 09:44:24,669] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.81549017e-24   4.56093696e-09   1.15837029e-09   5.74589132e-09
   9.39394673e-10   2.83239365e-01   1.87873706e-01   2.27610067e-01
   3.01276803e-01]
[2017-11-02 09:44:29,723] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.64300948e-01   2.72482485e-01   2.34726191e-01   2.53544062e-01
   7.49463364e-02   3.66148653e-13   1.35781943e-13   1.63061147e-13
   1.29421769e-13]
[2017-11-02 09:44:33,934] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.55008786e-04   3.86367261e-01   1.85008034e-01   3.48489612e-01
   7.97800720e-02   3.23116311e-09   1.76640258e-09   2.21722241e-09
   1.84345050e-09]
[2017-11-02 09:44:35,936] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.05764557e-07   3.55449021e-01   1.89290985e-01   3.79171103e-01
   7.60522187e-02   1.16321762e-05   7.14366752e-06   7.68746031e-06
   9.41599956e-06]
[2017-11-02 09:44:37,115] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.85948159e-02   3.38374645e-01   2.33499989e-01   3.10244799e-01
   7.92857260e-02   1.12608959e-11   4.87319950e-12   5.64800940e-12
   4.93606328e-12]
[2017-11-02 09:44:40,286] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.26949713e-01   2.27173820e-01   2.91999787e-01   2.57769525e-01
   9.61063579e-02   3.96589741e-07   1.73410641e-07   1.92370308e-07
   1.11612643e-07]
[2017-11-02 09:44:47,739] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09879687e-01   3.05459261e-01   2.08489552e-01   3.03656161e-01
   7.25153014e-02   4.82972020e-14   1.76134166e-14   2.56301074e-14
   2.12682163e-14]
[2017-11-02 09:44:49,733] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.54941022e-01   2.72669554e-01   2.22359717e-01   2.69443512e-01
   8.05862099e-02   9.85634317e-12   3.58304619e-12   3.48326251e-12
   1.90398717e-12]
[2017-11-02 09:44:55,511] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.53771508e-02   3.65136623e-01   2.07465276e-01   3.23601723e-01
   8.84192064e-02   1.47641500e-11   6.61968267e-12   8.89458212e-12
   6.50820934e-12]
[2017-11-02 09:44:57,478] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.59388510e-05   3.94076020e-01   1.74614206e-01   3.59577626e-01
   7.17162192e-02   1.95062473e-08   1.03698126e-08   1.22141515e-08
   1.25964865e-08]
[2017-11-02 09:45:00,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0944766   0.18399236  0.28187215  0.23781513  0.10917374  0.03539988
  0.02044088  0.02327655  0.01355267]
[2017-11-02 09:45:03,182] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.34991050e-01   3.25104028e-01   1.81722388e-01   2.75298208e-01
   8.28843266e-02   1.94664841e-14   7.70386884e-15   1.06938054e-14
   9.18171518e-15]
[2017-11-02 09:45:20,422] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.14809012e-02   2.67086565e-01   3.18402380e-01   2.85743058e-01
   1.06661201e-01   2.70462391e-04   1.34274247e-04   1.43157929e-04
   7.79679322e-05]
[2017-11-02 09:45:24,121] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.56111552e-26   2.38757417e-11   1.05168391e-11   3.63517584e-11
   7.13474982e-12   2.91141599e-01   1.98335424e-01   2.25960732e-01
   2.84562260e-01]
[2017-11-02 09:45:27,455] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.41341289e-07   4.09651011e-01   1.39725953e-01   3.83272707e-01
   6.73447251e-02   1.91569620e-06   9.69199505e-07   1.25186648e-06
   1.37025677e-06]
[2017-11-02 09:45:27,974] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.61328288e-15   3.01013119e-04   9.44783678e-05   3.08584305e-04
   4.83506446e-05   3.16651911e-01   1.87289685e-01   2.23166719e-01
   2.72139221e-01]
[2017-11-02 09:45:33,366] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.26964495e-01   3.15503746e-01   2.11809486e-01   2.61438102e-01
   8.42841417e-02   3.45960348e-12   1.42203003e-12   2.01994064e-12
   1.36197184e-12]
[2017-11-02 09:45:33,426] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.45760281e-08   3.37131262e-01   1.86045259e-01   3.76039714e-01
   9.49443579e-02   1.88552879e-03   1.18616165e-03   1.35701837e-03
   1.41060213e-03]
[2017-11-02 09:45:34,289] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.26621126e-08   3.49077821e-01   1.91998199e-01   3.60967487e-01
   9.03247893e-02   2.51371600e-03   1.57578185e-03   1.74766826e-03
   1.79447187e-03]
[2017-11-02 09:45:38,131] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10635757  0.21281873  0.29364476  0.24213786  0.11068892  0.01345722
  0.00831996  0.00816278  0.00441221]
[2017-11-02 09:45:39,309] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14344093  0.13001217  0.1580338   0.14460565  0.10847622  0.09805469
  0.08577576  0.08205116  0.04954964]
[2017-11-02 09:45:39,699] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13080829  0.12346284  0.14799526  0.13472167  0.11254077  0.09943192
  0.09756511  0.09020476  0.06326935]
[2017-11-02 09:45:42,149] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.13004743e-12   2.44842703e-03   1.44309457e-03   2.89531588e-03
   6.52879942e-04   3.08560342e-01   2.16351941e-01   2.18358442e-01
   2.49289483e-01]
[2017-11-02 09:45:42,293] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.91773579e-19   8.32958023e-08   4.50335591e-08   1.07091111e-07
   2.29143655e-08   2.95510769e-01   2.17417732e-01   2.17331484e-01
   2.69739777e-01]
[2017-11-02 09:45:42,973] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91909206e-02   2.92335689e-01   2.41734296e-01   2.93050259e-01
   7.36888051e-02   3.60097260e-12   1.44091716e-12   1.82310287e-12
   1.54083885e-12]
[2017-11-02 09:45:46,576] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.31908347e-15   3.16455589e-05   3.62989776e-05   6.30741051e-05
   1.42883864e-05   3.64761710e-01   2.09637687e-01   1.80393890e-01
   2.45061383e-01]
[2017-11-02 09:45:47,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0939234   0.12200885  0.15946466  0.14080869  0.09919078  0.11908071
  0.0985938   0.09765949  0.06926958]
[2017-11-02 09:45:47,843] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21027479  0.17940736  0.22806661  0.19209677  0.10403958  0.03364952
  0.02201408  0.02220884  0.00824255]
[2017-11-02 09:45:59,506] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.23661384e-01   2.96498895e-01   2.41486311e-01   2.58871496e-01
   7.94819817e-02   8.43914591e-11   3.41420052e-11   4.58394538e-11
   3.16364747e-11]
[2017-11-02 09:46:09,000] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10720898  0.10908499  0.13855045  0.12039194  0.1070004   0.1142303
  0.11412032  0.10777505  0.08163749]
[2017-11-02 09:46:12,761] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.53216104e-10   1.73111692e-01   1.01959854e-01   2.34967798e-01
   4.74027097e-02   1.31451502e-01   8.69186074e-02   9.13125798e-02
   1.32875234e-01]
[2017-11-02 09:46:16,895] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.77411482e-01   1.95831999e-01   2.67235994e-01   2.43888006e-01
   1.14080615e-01   6.94970018e-04   3.69862537e-04   3.51155322e-04
   1.35935639e-04]
[2017-11-02 09:46:18,466] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.40612755e-20   5.42260885e-08   3.15536326e-08   8.40639345e-08
   1.71858048e-08   2.89695948e-01   2.00795174e-01   2.14765355e-01
   2.94743329e-01]
[2017-11-02 09:46:21,257] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.73371707e-02   3.53943259e-01   2.18191251e-01   3.04467052e-01
   7.60612488e-02   4.07769277e-13   1.57192279e-13   2.04451934e-13
   1.71128614e-13]
[2017-11-02 09:46:34,136] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.73742421e-07   3.22848409e-01   2.10014164e-01   3.72834384e-01
   8.94208774e-02   1.55495049e-03   9.84999118e-04   1.09042774e-03
   1.25157495e-03]
[2017-11-02 09:46:36,211] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.08639982e-03   3.40062350e-01   2.40148887e-01   3.39885980e-01
   7.78163671e-02   2.41352827e-09   1.18349719e-09   1.47371781e-09
   1.46801715e-09]
[2017-11-02 09:46:37,208] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09975161  0.11195306  0.13620184  0.12084942  0.10097174  0.12548794
  0.12036358  0.10650572  0.07791515]
[2017-11-02 09:46:38,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10885359  0.11337045  0.13742992  0.12523834  0.10960548  0.11224066
  0.11606913  0.0998527   0.07733966]
[2017-11-02 09:46:39,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12349281  0.17410959  0.25152344  0.22373262  0.10228583  0.04677898
  0.02992741  0.0311355   0.01701379]
[2017-11-02 09:46:44,685] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.48880675e-01   2.59098172e-01   2.52536803e-01   2.57572681e-01
   8.19116756e-02   3.20579639e-11   1.32151104e-11   1.71633194e-11
   1.43735700e-11]
[2017-11-02 09:46:50,505] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   4.29051630e-19   1.33552355e-19   6.06705391e-19
   7.11763068e-20   2.73823053e-01   1.89949736e-01   2.03941852e-01
   3.32285345e-01]
[2017-11-02 09:46:53,619] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10174189  0.13277696  0.16166653  0.14448914  0.10600106  0.11278116
  0.09126105  0.08851568  0.06076653]
[2017-11-02 09:47:04,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10625781  0.19951327  0.29198489  0.25371763  0.11536068  0.01318335
  0.00797508  0.00773234  0.00427498]
[2017-11-02 09:47:10,151] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.85910627e-04   2.71293461e-01   2.83148497e-01   3.40766639e-01
   1.03989817e-01   1.68382205e-04   1.02044854e-04   1.38414471e-04
   2.06889410e-04]
[2017-11-02 09:47:14,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.98927268e-01   2.71781057e-01   2.01834977e-01   2.54218429e-01
   7.32382312e-02   1.83901356e-14   6.07062626e-15   9.18274263e-15
   5.81157818e-15]
[2017-11-02 09:47:15,802] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.68518201e-01   2.01503783e-01   2.53841937e-01   2.70182401e-01
   1.05950348e-01   1.69441500e-06   7.38463825e-07   6.81978122e-07
   2.29085060e-07]
[2017-11-02 09:47:16,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11830069  0.11504323  0.14737763  0.13282828  0.11237632  0.10474046
  0.10205726  0.09725007  0.07002603]
[2017-11-02 09:47:19,962] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11180989  0.10986732  0.14238919  0.12563261  0.11523267  0.10167153
  0.11001998  0.10134974  0.082027  ]
[2017-11-02 09:47:21,181] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.29448455e-02   2.53245920e-01   3.17510694e-01   3.08089614e-01
   1.08187579e-01   6.46765830e-06   3.65419578e-06   5.11532426e-06
   6.12149415e-06]
[2017-11-02 09:47:22,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.03724936e-01   2.64098644e-01   2.19035685e-01   2.40468219e-01
   7.26725087e-02   2.29514514e-13   8.13553326e-14   1.09083702e-13
   6.63435710e-14]
[2017-11-02 09:47:25,016] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.66682658e-19   2.40280087e-07   1.13016377e-07   2.94307483e-07
   5.38367146e-08   2.91059405e-01   2.05599919e-01   2.12022811e-01
   2.91317105e-01]
[2017-11-02 09:47:32,909] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07365023  0.16058484  0.2241182   0.20845295  0.1002923   0.07688005
  0.05783696  0.05764643  0.04053814]
[2017-11-02 09:47:38,093] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1598964   0.12718812  0.17111897  0.15019961  0.11867294  0.07800432
  0.07313055  0.07685387  0.04493522]
[2017-11-02 09:47:42,141] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.07887515e-05   3.18611592e-01   2.52647072e-01   3.31389606e-01
   9.68808681e-02   1.08429682e-04   6.54995383e-05   9.00959712e-05
   1.16074523e-04]
[2017-11-02 09:47:42,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.05513528e-03   3.40875149e-01   2.43575305e-01   3.27371538e-01
   8.71228725e-02   5.57036950e-09   2.88519941e-09   3.32454508e-09
   3.32439321e-09]
[2017-11-02 09:47:52,324] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.98601002e-09   5.32616228e-02   3.50911580e-02   6.46114871e-02
   1.47669911e-02   2.43986383e-01   1.63784713e-01   1.78169534e-01
   2.46328101e-01]
[2017-11-02 09:47:52,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.09954572e-04   3.55985284e-01   2.25107118e-01   3.34774613e-01
   8.38229731e-02   4.44992345e-08   2.65794124e-08   2.93633207e-08
   2.69658624e-08]
[2017-11-02 09:47:52,615] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.88054465e-17   1.61230764e-06   1.00895636e-06   2.13420140e-06
   4.45908142e-07   2.88738877e-01   2.09749132e-01   2.06006303e-01
   2.95500457e-01]
[2017-11-02 09:47:54,595] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.27624999e-21   1.63665153e-08   9.05805386e-09   2.40622438e-08
   4.31491287e-09   2.72837758e-01   2.04995632e-01   1.95024073e-01
   3.27142507e-01]
[2017-11-02 09:48:02,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11236882  0.20710251  0.26942927  0.25083122  0.10969882  0.01649207
  0.01222122  0.01289145  0.00896467]
[2017-11-02 09:48:03,128] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.11043968e-03   2.81141043e-01   3.03402096e-01   3.05893689e-01
   1.04227655e-01   3.71178525e-04   2.39243498e-04   3.04033048e-04
   3.10626201e-04]
[2017-11-02 09:48:05,582] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.45974443e-19   5.99428915e-07   3.20029727e-07   8.71286034e-07
   1.62425863e-07   2.85182446e-01   2.00565204e-01   1.98379830e-01
   3.15870553e-01]
[2017-11-02 09:48:14,407] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.96902031e-02   3.30917120e-01   2.16643557e-01   2.86927283e-01
   8.58218670e-02   1.06901875e-11   4.65532734e-12   6.10420438e-12
   4.27816550e-12]
[2017-11-02 09:48:37,848] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1669398   0.13647935  0.16910297  0.15743832  0.11700246  0.07693329
  0.06621852  0.07038298  0.03950229]
[2017-11-02 09:48:38,162] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09286996  0.09777176  0.12928489  0.1159559   0.11069782  0.11378123
  0.12316842  0.11436258  0.10210748]
[2017-11-02 09:48:39,366] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13645494  0.12217728  0.15485096  0.13846585  0.12010612  0.08736397
  0.09028535  0.08707318  0.06322234]
[2017-11-02 09:48:44,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.14092040e-26   1.40475027e-11   6.67599092e-12   1.83549755e-11
   3.31971451e-12   2.73947090e-01   2.07329512e-01   2.10453153e-01
   3.08270276e-01]
[2017-11-02 09:48:51,631] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.16292739e-01   2.53575057e-01   2.25496471e-01   2.23022446e-01
   8.16133544e-02   1.15784049e-11   4.29804282e-12   5.96960892e-12
   4.03646691e-12]
[2017-11-02 09:48:53,324] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.04328230e-07   3.19708765e-01   2.09526211e-01   3.75205964e-01
   7.99859762e-02   4.33321064e-03   2.64839386e-03   3.34813888e-03
   5.24330512e-03]
[2017-11-02 09:48:53,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19648449e-01   2.94254482e-01   2.29834482e-01   2.76291549e-01
   7.99710602e-02   4.03234249e-13   1.58463954e-13   2.22928487e-13
   1.77687970e-13]
[2017-11-02 09:48:57,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11533892  0.11778978  0.14690608  0.12871821  0.11070012  0.1065767
  0.10590839  0.09814242  0.06991937]
[2017-11-02 09:48:58,155] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10364059  0.1067481   0.13911986  0.12301194  0.11214559  0.10876822
  0.11559936  0.10598367  0.08498276]
[2017-11-02 09:49:06,444] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08602602  0.09465137  0.12048206  0.11024364  0.10465028  0.12609926
  0.13751954  0.11627449  0.10405338]
[2017-11-02 09:49:09,532] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18512577  0.16234103  0.23814094  0.20143795  0.09465332  0.04727025
  0.02631287  0.03212834  0.01258951]
[2017-11-02 09:49:10,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0971083   0.18440855  0.28083143  0.23508424  0.10308377  0.0324739
  0.02198233  0.02620223  0.01882523]
[2017-11-02 09:49:13,140] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13037175  0.12263888  0.15164837  0.13687125  0.11008324  0.1010142
  0.0951291   0.09137682  0.06086636]
[2017-11-02 09:49:18,318] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.73579348e-06   3.20395410e-01   2.15859517e-01   3.81269336e-01
   8.24603140e-02   3.30975081e-06   2.01424632e-06   2.27621445e-06
   2.99691669e-06]
[2017-11-02 09:49:25,816] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21578875  0.16686699  0.19770679  0.17288324  0.10814589  0.05360456
  0.03520572  0.03589639  0.01390165]
[2017-11-02 09:49:26,470] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.54822317e-06   2.26958886e-01   1.84902400e-01   2.56284952e-01
   7.43241459e-02   7.07293153e-02   4.61348295e-02   5.62287942e-02
   8.44351798e-02]
[2017-11-02 09:49:27,100] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.18252382e-01   3.00822914e-01   2.35506922e-01   2.56746650e-01
   8.86710733e-02   2.01421144e-10   9.30555355e-11   1.20134666e-10
   8.24917010e-11]
[2017-11-02 09:49:36,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.61983182e-03   3.12538087e-01   2.84625620e-01   3.04944307e-01
   9.51951817e-02   2.54064016e-05   1.50202141e-05   1.83515549e-05
   1.80951811e-05]
[2017-11-02 09:49:51,019] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19890429e-01   3.11199963e-01   1.99252710e-01   2.97302723e-01
   7.23541901e-02   2.20892183e-14   7.95805835e-15   1.18227851e-14
   9.08922087e-15]
[2017-11-02 09:49:52,478] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09214781  0.15513305  0.20457147  0.17800415  0.10677107  0.08850552
  0.06249916  0.06784685  0.04452086]
[2017-11-02 09:49:59,748] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.42513652e-05   3.66926879e-01   2.22790241e-01   3.26939642e-01
   8.32480937e-02   3.20553966e-07   1.86621165e-07   2.03092227e-07
   1.85267794e-07]
[2017-11-02 09:50:03,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08143034  0.14559008  0.19086201  0.1660542   0.10671119  0.09984478
  0.07425341  0.07993107  0.05532282]
[2017-11-02 09:50:08,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15702754  0.12577103  0.16799812  0.14917657  0.11824767  0.08034222
  0.07499653  0.07877518  0.04766506]
[2017-11-02 09:50:22,572] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.48311165e-02   2.35195041e-01   3.11442584e-01   2.57691175e-01
   9.97277498e-02   3.79941164e-04   2.34878185e-04   2.84187438e-04
   2.13334279e-04]
[2017-11-02 09:50:24,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.16474628  0.20475808  0.21951586  0.18627654  0.11517961  0.03763964
  0.03092128  0.02589805  0.01506465]
[2017-11-02 09:50:44,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1263593   0.11991466  0.15040037  0.13816053  0.10660407  0.10662095
  0.09328336  0.09653534  0.06212151]
[2017-11-02 09:50:54,367] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17812696  0.13473891  0.17902105  0.16216479  0.11519402  0.07041347
  0.05926446  0.06666181  0.03441451]
[2017-11-02 09:50:55,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08871988  0.093107    0.12850127  0.11325023  0.11131214  0.11111105
  0.12537929  0.11843941  0.11017974]
[2017-11-02 09:50:57,848] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.88894023e-02   2.60700852e-01   3.07980865e-01   2.75626093e-01
   1.06754132e-01   1.55430353e-05   9.32873354e-06   1.22957399e-05
   1.14636887e-05]
[2017-11-02 09:51:10,791] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09723308  0.09949675  0.13641967  0.11904365  0.11423755  0.10636621
  0.11824663  0.1119701   0.09698636]
[2017-11-02 09:51:12,766] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.16936392  0.12785795  0.15493788  0.14808461  0.1058634   0.0958968
  0.07339618  0.08229411  0.04230518]
[2017-11-02 09:51:12,956] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14590806  0.12437855  0.15482438  0.14224918  0.09154339  0.11572036
  0.0802445   0.09659342  0.04853809]
[2017-11-02 09:51:13,137] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10840995  0.11947292  0.16388611  0.14482525  0.08376712  0.12718433
  0.0859747   0.1047164   0.06176318]
[2017-11-02 09:51:13,868] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.64763890e-04   2.77166992e-01   2.74737418e-01   2.99698114e-01
   9.31998342e-02   1.72481276e-02   1.18964938e-02   1.26658771e-02
   1.31224860e-02]
[2017-11-02 09:51:24,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09749714  0.10408868  0.13854679  0.12302669  0.10912603  0.1146081
  0.11760041  0.10966916  0.08583701]
[2017-11-02 09:51:25,710] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.07933952  0.09840985  0.13510582  0.1221681   0.09717971  0.13804778
  0.12101109  0.12250621  0.08623187]
[2017-11-02 09:51:30,489] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.93322148e-08   3.19347950e-04   6.03257387e-04   6.02332992e-04
   1.90068269e-04   3.31855834e-01   1.82058543e-01   2.73460746e-01
   2.10909829e-01]
[2017-11-02 09:51:30,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   2.44850691e-25   6.09182057e-25   1.11970522e-24
   1.45410533e-25   2.38696769e-01   1.19943708e-01   2.38838837e-01
   4.02520657e-01]
[2017-11-02 09:51:31,857] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.33449343e-02   2.34146908e-01   3.04761380e-01   2.80074745e-01
   8.76720548e-02   2.33303528e-08   1.08339062e-08   1.93524663e-08
   2.29598900e-08]
[2017-11-02 09:51:32,334] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14294854  0.20559084  0.29245552  0.2430709   0.11275595  0.00103239
  0.00062328  0.00084361  0.000679  ]
[2017-11-02 09:51:33,828] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09892802  0.10281296  0.13599555  0.11792399  0.10919986  0.11323758
  0.11991841  0.11173511  0.0902485 ]
[2017-11-02 09:51:37,217] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12614277  0.16355376  0.20954385  0.19609351  0.10821631  0.06300342
  0.04643454  0.05106982  0.03594198]
[2017-11-02 09:51:37,669] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11302493  0.11360697  0.13582277  0.13187289  0.08720772  0.13114722
  0.10110023  0.11566132  0.07055592]
[2017-11-02 09:51:52,069] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47632605e-07   1.39143094e-01   1.40270799e-01   2.02866390e-01
   5.82553744e-02   1.16489261e-01   6.87380433e-02   9.49974582e-02
   1.79239422e-01]
[2017-11-02 09:51:52,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.23110414e-03   3.34948003e-01   2.38588884e-01   3.36264074e-01
   8.89679715e-02   4.19655910e-09   2.19107665e-09   2.87296142e-09
   2.85491319e-09]
[2017-11-02 09:51:58,570] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00260003  0.21182226  0.26580629  0.25986093  0.10316858  0.05785025
  0.03580786  0.03823056  0.0248532 ]
[2017-11-02 09:52:04,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.62112945e-01   2.63375849e-01   1.90817311e-01   2.09287405e-01
   7.44065493e-02   3.98983553e-13   1.38578968e-13   1.93767826e-13
   9.10933452e-14]
[2017-11-02 09:52:14,555] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11275283  0.11365255  0.13858813  0.12638128  0.10986773  0.11088435
  0.11001263  0.10044602  0.07741448]
[2017-11-02 09:52:19,650] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12660861  0.12082137  0.14649002  0.13028124  0.11309297  0.10118445
  0.10208936  0.09256402  0.06686787]
[2017-11-02 09:52:25,263] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.182567    0.13337463  0.15959321  0.1480033   0.09120932  0.10015301
  0.06610083  0.0822188   0.03677992]
[2017-11-02 09:52:27,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10748103  0.1084433   0.13706583  0.12108713  0.11446426  0.10366163
  0.11482835  0.10397886  0.08898959]
[2017-11-02 09:52:27,939] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11833749  0.1157427   0.14848198  0.1313131   0.11776871  0.09603847
  0.10278555  0.09548268  0.07404933]
[2017-11-02 09:52:28,388] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10080083  0.10422061  0.13975017  0.12407608  0.11358401  0.10767814
  0.11452357  0.10744508  0.08792156]
[2017-11-02 09:52:28,689] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09434751  0.09909417  0.13546814  0.11891776  0.11155023  0.11108397
  0.11968231  0.11366881  0.09618707]
[2017-11-02 09:52:29,922] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09831771  0.10379173  0.1344572   0.11907773  0.10838573  0.12271035
  0.11677701  0.11190031  0.08458221]
[2017-11-02 09:52:30,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13825639  0.10589794  0.14265165  0.12834162  0.10667774  0.10944587
  0.09955242  0.10178184  0.06739454]
[2017-11-02 09:52:31,912] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15370981  0.11284573  0.1427429   0.129795    0.10950523  0.10220988
  0.09284074  0.09471575  0.06163501]
[2017-11-02 09:52:33,288] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11181701  0.108433    0.13287935  0.11911091  0.10776456  0.10895637
  0.11653217  0.10683868  0.08766797]
[2017-11-02 09:52:35,632] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14751428  0.1223494   0.16458072  0.14531596  0.11406241  0.08756001
  0.08003205  0.08610687  0.05247819]
[2017-11-02 09:52:37,760] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15161015  0.12120961  0.14586325  0.13959311  0.09050207  0.1210615
  0.08229078  0.09919632  0.04867325]
[2017-11-02 09:52:38,696] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10209927  0.11334495  0.14957967  0.13628428  0.07787299  0.13934489
  0.0933254   0.1171798   0.07096884]
[2017-11-02 09:52:41,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08420759  0.09214693  0.12487518  0.11072744  0.10431245  0.12583587
  0.13197199  0.12115074  0.10477186]
[2017-11-02 09:52:43,328] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1052768   0.10541183  0.14019775  0.12524508  0.11290029  0.1063649
  0.11354081  0.106024    0.08503862]
[2017-11-02 09:52:44,450] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12550318  0.11829216  0.1541353   0.13879859  0.11441982  0.09749769
  0.09536495  0.09247549  0.06351282]
[2017-11-02 09:52:44,474] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12087892  0.11619138  0.15043281  0.13542679  0.11456861  0.09915276
  0.09989022  0.09498089  0.06847758]
[2017-11-02 09:52:44,866] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09460787  0.09791031  0.13300788  0.11752892  0.11229607  0.1100892
  0.12132794  0.11355825  0.09967361]
[2017-11-02 09:52:47,034] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.17790347e-10   6.73789019e-03   3.79794021e-03   6.70814048e-03
   1.62785035e-03   2.86122292e-01   2.21520290e-01   2.09539264e-01
   2.63946414e-01]
[2017-11-02 09:52:48,343] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.17414130e-14   1.29382577e-04   6.44224565e-05   1.44242018e-04
   2.67057148e-05   2.97333986e-01   2.17414722e-01   2.01868907e-01
   2.83017606e-01]
[2017-11-02 09:52:58,794] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.85736605e-04   3.36769670e-01   2.53656894e-01   3.23004574e-01
   8.56830701e-02   2.52153871e-08   1.35407605e-08   1.56050710e-08
   1.45402002e-08]
[2017-11-02 09:52:59,439] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.42424482e-06   3.10375601e-01   2.53611267e-01   3.48831594e-01
   8.67317393e-02   1.50761858e-04   9.89882756e-05   9.26396460e-05
   1.04017796e-04]
[2017-11-02 09:53:00,562] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09200741  0.1400566   0.18655193  0.16071111  0.10244884  0.10841742
  0.07818254  0.08112969  0.05049442]
[2017-11-02 09:53:09,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17684029  0.17864862  0.23763533  0.19915406  0.10803434  0.03909701
  0.02581228  0.02470167  0.01007644]
[2017-11-02 09:53:11,219] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.12032650e-09   4.23831912e-03   3.45715717e-03   5.06858062e-03
   1.15055242e-03   2.70073056e-01   1.99446529e-01   2.14033663e-01
   3.02532107e-01]
[2017-11-02 09:53:11,522] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.41877842e-02   2.64243215e-01   3.15881550e-01   2.88831651e-01
   8.68540853e-02   6.02466628e-07   3.08683298e-07   3.90236067e-07
   3.78738008e-07]
[2017-11-02 09:53:12,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.16961969e-08   1.37000293e-01   9.94121060e-02   1.67879328e-01
   3.40313725e-02   1.55284315e-01   1.17515609e-01   1.14312686e-01
   1.74564213e-01]
[2017-11-02 09:53:12,778] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47777304e-04   3.13266575e-01   2.65573978e-01   3.38489443e-01
   8.25136155e-02   2.87040393e-06   1.75293007e-06   1.81108715e-06
   2.11550218e-06]
[2017-11-02 09:53:17,963] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.15160145  0.13529412  0.1635405   0.14429232  0.1042507   0.09715954
  0.08182357  0.07845771  0.04358001]
[2017-11-02 09:53:18,861] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12078661  0.1154261   0.14447278  0.129173    0.11161692  0.1031164
  0.10309438  0.09870282  0.07361095]
[2017-11-02 09:53:19,772] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11985105  0.11639296  0.14482354  0.13013904  0.11000669  0.10523433
  0.10290938  0.09869554  0.07194751]
[2017-11-02 09:53:21,495] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10652402  0.22825493  0.29621884  0.25417095  0.1112621   0.00118319
  0.00076795  0.00091417  0.00070384]
[2017-11-02 09:53:24,495] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10823545  0.13257694  0.1622057   0.14447635  0.10037445  0.10762836
  0.09507105  0.08613645  0.06329523]
[2017-11-02 09:53:37,534] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.168304    0.1192512   0.14952174  0.13807811  0.11162259  0.09545911
  0.08151909  0.08531753  0.05092653]
[2017-11-02 09:53:43,993] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11039323  0.14556934  0.18256466  0.16638309  0.10310684  0.09719712
  0.07212957  0.07455773  0.04809844]
[2017-11-02 09:53:46,207] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09496918  0.09852637  0.13426486  0.11710141  0.11385829  0.10768563
  0.11991476  0.11334303  0.10033653]
[2017-11-02 09:53:46,258] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0991293   0.10154301  0.13710549  0.11933513  0.11522385  0.10501962
  0.11673494  0.11033644  0.09557223]
[2017-11-02 09:53:50,376] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.17867364  0.11150549  0.15927157  0.13349329  0.11761277  0.08319888
  0.07939771  0.08485115  0.05199555]
[2017-11-02 09:53:54,317] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.08922078  0.0942043   0.13346881  0.11694545  0.11143486  0.1127123
  0.12259987  0.11754769  0.10186593]
[2017-11-02 09:53:54,513] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09065732  0.09542067  0.13446772  0.11743257  0.11172117  0.11210154
  0.12170341  0.11662142  0.09987419]
[2017-11-02 09:53:54,877] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.10561687  0.1071905   0.14482032  0.12685294  0.11534064  0.10385019
  0.11026809  0.10422485  0.08183558]
[2017-11-02 09:53:55,604] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14065523  0.12120222  0.16296606  0.15004578  0.11328491  0.10197396
  0.07664334  0.08662378  0.0466047 ]
[2017-11-02 09:53:56,134] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18025023  0.11449187  0.1667182   0.14142324  0.11495336  0.08262867
  0.07448111  0.08012459  0.04492863]
[2017-11-02 09:53:57,198] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.1026042   0.11391006  0.15334065  0.1289717   0.07631198  0.14047971
  0.09566025  0.11896804  0.06975346]
[2017-11-02 09:54:00,758] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.11680639  0.11489135  0.14110895  0.12822875  0.11087435  0.10567887
  0.10713769  0.0991149   0.07615873]
[2017-11-02 09:54:01,033] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09609129  0.10307872  0.13022743  0.11829445  0.10416713  0.12356901
  0.12268107  0.1121997   0.08969122]
[2017-11-02 09:54:05,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.13081461  0.11653326  0.14408502  0.13240534  0.1123941   0.10017744
  0.09964006  0.09463214  0.069318  ]
[2017-11-02 09:54:20,765] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12015133  0.11275919  0.1437875   0.1254034   0.11493164  0.10025223
  0.10756233  0.09870964  0.07644279]
[2017-11-02 09:54:22,634] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.09572116  0.09890992  0.13488501  0.11857967  0.1143639   0.10761275
  0.11878476  0.11246637  0.09867646]
[2017-11-02 09:54:25,329] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.30219522  0.14322199  0.1838004   0.17595451  0.10251322  0.03559207
  0.02193345  0.02660298  0.00818622]
[2017-11-02 09:54:25,742] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.24128859  0.14083852  0.17262381  0.1600824   0.10519005  0.06409763
  0.04292302  0.05230129  0.02065476]
[2017-11-02 09:54:27,928] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.26040071  0.1518261   0.18839033  0.17908911  0.11083348  0.03623353
  0.02830857  0.03191377  0.01300439]
[2017-11-02 09:54:31,262] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0769811   0.08423863  0.12064395  0.10567867  0.10461416  0.11783688
  0.13503057  0.12887779  0.12609829]
[2017-11-02 09:54:33,160] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.12422385  0.10077479  0.14041239  0.13144086  0.10478859  0.11727442
  0.10336805  0.10633965  0.07137734]
[2017-11-02 09:54:34,035] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -14624.4167
[2017-11-02 09:54:34,035] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, -14624.416699102812]
[2017-11-02 09:54:38,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   8.51007998e-24   6.78068783e-24   3.02575299e-23
   3.12867777e-24   1.37776986e-01   1.16794288e-01   1.60709351e-01
   5.84719300e-01], sum to 1.0000
[2017-11-02 09:54:38,436] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [7.199999999999999, 96.0, 4.933333333333334, 215.0, 0.0, 0.0, 12.2, 17.25556046077312, 21.5, 21.04647348279439, 21.5, 0.0, 41.30177343424362], 
actual action is [12.2, 25], 
sim time next is 6900.0000, 
raw observation next is [7.2, 96.0, 5.016666666666667, 217.5, 0.0, 0.0, 12.2, 16.59538415846841, 25.0, 21.12718770476935, 21.5, 0.0, 39.09426395586159], 
processed observation next is [1.0, 0.043478260869565216, 0.5179487179487179, 0.96, 0.45606060606060606, 0.6041666666666666, 0.0, 0.0, 0.7033333333333334, 0.1659538415846841, 1.0, 0.44674110068133593, 0.5, 0.0, 0.45993251712778344], 
reward next is -0.4672. 
=============================================
[2017-11-02 09:54:41,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   5.51508094e-19   3.44872277e-19   6.67992134e-19
   1.43304220e-19   1.17968976e-01   9.54846442e-02   1.15099169e-01
   6.71447217e-01], sum to 1.0000
[2017-11-02 09:54:41,744] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [7.616666666666667, 93.5, 5.016666666666667, 236.6666666666667, 0.0, 0.0, 2.575, 19.65331921531847, 18.0, 21.13042472995032, 21.5, 0.0, 0.0], 
actual action is [12.616666666666667, 19.0], 
sim time next is 14100.0000, 
raw observation next is [7.658333333333334, 93.25, 5.058333333333334, 238.3333333333333, 0.0, 0.0, 12.61666666666667, 18.21858529515906, 19.0, 20.92760681007625, 21.5, 0.0, 56.20183591881556], 
processed observation next is [1.0, 0.13043478260869565, 0.5297008547008547, 0.9325, 0.4598484848484849, 0.6620370370370369, 0.0, 0.0, 0.7102777777777779, 0.1821858529515906, 0.14285714285714285, 0.41822954429660697, 0.5, 0.0, 0.6611980696331242], 
reward next is -0.6768. 
=============================================
[2017-11-02 09:54:45,713] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.99310738e-01   1.04858540e-01   2.05077633e-01   2.01019034e-01
   8.97340700e-02   5.71590820e-18   1.15528346e-18   2.33701519e-18
   2.63367814e-18], sum to 1.0000
[2017-11-02 09:54:45,737] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 6.1, 240.8333333333333, 0.0, 0.0, 12.7, 12.50737677887561, 22.5, 21.08714901357485, 21.5, 0.0, 56.50812795383061], 
actual action is [2.7, 18], 
sim time next is 25800.0000, 
raw observation next is [7.7, 93.0, 6.1, 241.6666666666667, 0.0, 0.0, 2.7, 13.30457226593987, 18.0, 21.30584865251162, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.5307692307692308, 0.93, 0.5545454545454546, 0.6712962962962964, 0.0, 0.0, 0.545, 0.1330457226593987, 0.0, 0.4722640932159458, 0.5, 0.0, 0.0], 
reward next is -0.0277. 
=============================================
[2017-11-02 09:54:51,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.27689570e-01   1.01440161e-01   3.23766321e-01   2.79197723e-01
   1.67906255e-01   2.28600544e-17   4.59951918e-18   6.18800705e-18
   2.55298791e-17], sum to 1.0000
[2017-11-02 09:54:51,646] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [7.699999999999999, 93.0, 6.949999999999999, 254.1666666666667, 36.58333333333333, 0.0, 12.7, 12.65552363160629, 25.0, 21.47420314181142, 22.7, 1.0, 53.09225036251046], 
actual action is [12.7, 24.5], 
sim time next is 34200.0000, 
raw observation next is [7.7, 93.0, 6.9, 255.0, 38.0, 0.0, 12.7, 11.32748075010561, 24.5, 21.57181294408172, 22.7, 1.0, 72.66964107053747], 
processed observation next is [1.0, 0.391304347826087, 0.5307692307692308, 0.93, 0.6272727272727273, 0.7083333333333334, 0.10052910052910052, 0.0, 0.7116666666666667, 0.11327480750105609, 0.9285714285714286, 0.5102589920116744, 0.6714285714285714, 1.0, 0.854936953771029], 
reward next is -0.7808. 
=============================================
[2017-11-02 09:54:53,762] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-39.76344681]
 [-40.16292572]
 [-38.65913773]
 [-40.25600052]
 [-39.63707352]], R is [[-40.95020294]
 [-41.54070282]
 [-42.12529755]
 [-42.70404434]
 [-43.27700424]].
[2017-11-02 09:55:04,159] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-35.67015839]
 [-34.45108414]
 [-33.99980927]
 [-35.05715942]
 [-34.49189758]], R is [[-34.50370407]
 [-34.17221069]
 [-34.2491684 ]
 [-34.66082764]
 [-34.32892609]].
[2017-11-02 09:55:06,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-35.58026123]
 [-35.50847626]
 [-35.31624985]
 [-36.68490982]
 [-35.42177963]], R is [[-36.28139877]
 [-35.91858673]
 [-35.55940247]
 [-35.34952545]
 [-35.15369034]].
[2017-11-02 09:55:09,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.80641580e-01   3.77088152e-02   3.39539424e-02   3.50895338e-02
   1.26062250e-02   4.15739758e-16   1.02985219e-17   3.06707355e-17
   7.03392041e-18], sum to 1.0000
[2017-11-02 09:55:09,257] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [0.4333333333333333, 95.66666666666666, 3.7, 273.3333333333334, 0.0, 0.0, 5.45, 12.79570995440225, 20.0, 21.68152120935058, 21.5, 0.0, 32.34597475328299], 
actual action is [5.433333333333334, 19.0], 
sim time next is 80700.0000, 
raw observation next is [0.4166666666666666, 95.58333333333333, 3.725, 274.1666666666666, 0.0, 0.0, 5.433333333333334, 12.60468652447269, 19.0, 21.84832039627514, 21.5, 0.0, 30.73864952118231], 
processed observation next is [1.0, 0.9565217391304348, 0.344017094017094, 0.9558333333333333, 0.3386363636363636, 0.7615740740740738, 0.0, 0.0, 0.5905555555555556, 0.1260468652447269, 0.14285714285714285, 0.5497600566107346, 0.5, 0.0, 0.36163117083743895], 
reward next is -0.3255. 
=============================================
[2017-11-02 09:55:15,178] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-55.65169907]
 [-52.78945923]
 [-52.78824234]
 [-55.04367447]
 [-53.87755203]], R is [[-55.34055328]
 [-55.78714752]
 [-56.22927475]
 [-56.66698074]
 [-57.10031128]].
[2017-11-02 09:55:24,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.92006123e-01   7.39569718e-04   8.57549370e-04
   6.39671134e-03], sum to 1.0000
[2017-11-02 09:55:24,721] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.199999999999999, 69.16666666666667, 6.449999999999999, 253.3333333333333, 0.0, 0.0, -2.149999999999999, 23.99965850929032, 19.0, 19.78991155129929, 21.5, 0.0, 33.09405688723532], 
actual action is [-2.1999999999999993, 19.5], 
sim time next is 111300.0000, 
raw observation next is [-7.25, 68.58333333333333, 6.274999999999999, 251.6666666666667, 0.0, 0.0, -2.199999999999999, 24.55769026019487, 19.5, 19.76658293066865, 21.5, 0.0, 31.40441052047416], 
processed observation next is [0.0, 0.2608695652173913, 0.14743589743589744, 0.6858333333333333, 0.5704545454545453, 0.6990740740740742, 0.0, 0.0, 0.4633333333333333, 0.2455769026019487, 0.21428571428571427, 0.2523689900955216, 0.5, 0.0, 0.36946365318204893], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:32,991] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.56813931
  0.0083206   0.00285245  0.42068765], sum to 1.0000
[2017-11-02 09:55:33,365] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.799999999999999, 69.66666666666666, 8.2, 253.3333333333333, 69.16666666666666, 5.999999999999998, -2.799999999999999, 18.13727853740484, 24.0, 21.27591257909248, 22.7, 1.0, 68.04341641467514], 
actual action is [-2.799999999999999, 24.5], 
sim time next is 121500.0000, 
raw observation next is [-7.8, 70.75, 8.075, 252.5, 81.25, 9.0, -2.799999999999999, 17.72520691622832, 24.5, 21.32114545224468, 22.7, 1.0, 68.15366088337741], 
processed observation next is [0.0, 0.391304347826087, 0.13333333333333333, 0.7075, 0.734090909090909, 0.7013888888888888, 0.21494708994708994, 0.009, 0.45333333333333337, 0.1772520691622832, 0.9285714285714286, 0.4744493503206684, 0.6714285714285714, 1.0, 0.8018077750985578], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:36,030] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-61.55015182]
 [-64.09460449]
 [-63.9481926 ]
 [-62.84288788]
 [-66.17499542]], R is [[-66.40373993]
 [-66.73970032]
 [-67.07230377]
 [-67.40158081]
 [-67.72756195]].
[2017-11-02 09:55:43,984] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.16178687e-02   3.28472927e-02   6.59352958e-01   2.61345685e-01
   1.48361912e-02   2.31065217e-27   6.10512006e-30   5.68469632e-30
   3.69762269e-29], sum to 1.0000
[2017-11-02 09:55:44,138] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-6.7, 63.75, 7.283333333333333, 260.8333333333333, 46.83333333333334, 27.5, -1.7, 18.53203464586498, 24.0, 21.33266042729337, 22.7, 1.0, 67.83752701970559], 
actual action is [-1.7000000000000002, 23.0], 
sim time next is 144000.0000, 
raw observation next is [-6.7, 64.0, 7.2, 260.0, 44.0, 24.0, -1.7, 17.81308768363918, 23.0, 21.53925160390362, 22.7, 1.0, 65.97998705364058], 
processed observation next is [0.0, 0.6956521739130435, 0.16153846153846155, 0.64, 0.6545454545454545, 0.7222222222222222, 0.1164021164021164, 0.024, 0.4716666666666667, 0.17813087683639178, 0.7142857142857143, 0.5056073719862313, 0.6714285714285714, 1.0, 0.7762351418075363], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:48,586] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7617: loss 41.8203
[2017-11-02 09:55:49,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   2.06830712e-37   1.57410435e-36   2.21415973e-36
   7.22992880e-38   5.74015081e-01   2.43693613e-03   2.33173626e-03
   4.21216279e-01], sum to 1.0000
[2017-11-02 09:55:49,345] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.149999999999999, 69.25, 7.2, 267.5, 20.25, 2.25, -2.1, 20.02347137473607, 24.5, 21.51662168454448, 22.7, 1.0, 69.84001405641477], 
actual action is [-2.1499999999999986, 25.0], 
sim time next is 147000.0000, 
raw observation next is [-7.199999999999999, 69.83333333333334, 7.199999999999999, 268.3333333333333, 18.0, 2.0, -2.149999999999999, 19.24499141300193, 25.0, 21.53989763869147, 22.7, 1.0, 70.30744181924908], 
processed observation next is [0.0, 0.6956521739130435, 0.14871794871794874, 0.6983333333333335, 0.6545454545454544, 0.7453703703703703, 0.047619047619047616, 0.002, 0.46416666666666667, 0.1924499141300193, 1.0, 0.5056996626702102, 0.6714285714285714, 1.0, 0.8271463743441068], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:50,671] A3C_AGENT_WORKER-Thread-8 INFO:Local step 500, global step 7762: loss 7.5547
[2017-11-02 09:55:50,893] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.73023772e-01   1.13049662e-03   7.66895711e-04
   2.50787847e-02], sum to 1.0000
[2017-11-02 09:55:51,001] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.3, 71.0, 7.2, 270.0, 0.0, 0.0, -2.25, 19.60864925557982, 23.5, 21.85754694678246, 22.7, 1.0, 51.10406294163386], 
actual action is [-2.3, 24.0], 
sim time next is 147900.0000, 
raw observation next is [-7.3, 70.16666666666666, 7.241666666666666, 270.0, 0.0, 0.0, -2.3, 18.88250195453481, 24.0, 21.76844691921568, 22.7, 1.0, 70.29431753237178], 
processed observation next is [0.0, 0.7391304347826086, 0.14615384615384616, 0.7016666666666665, 0.6583333333333333, 0.75, 0.0, 0.0, 0.46166666666666667, 0.1888250195453481, 0.8571428571428571, 0.5383495598879543, 0.6714285714285714, 1.0, 0.8269919709690797], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:51,549] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7832: loss -55.5274
[2017-11-02 09:55:52,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.71673846e-01   4.50621621e-04   3.61775368e-04
   2.75138393e-02], sum to 1.0000
[2017-11-02 09:55:52,136] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-7.149999999999999, 69.25, 7.2, 267.5, 20.25, 2.25, -2.1, 22.03188902529894, 21.5, 21.35424547289571, 22.7, 1.0, 50.45818429127437], 
actual action is [-2.1499999999999986, 22.0], 
sim time next is 147000.0000, 
raw observation next is [-7.199999999999999, 69.83333333333334, 7.199999999999999, 268.3333333333333, 18.0, 2.0, -2.149999999999999, 21.07625199830029, 22.0, 21.30040523720892, 22.7, 1.0, 67.51136465957978], 
processed observation next is [0.0, 0.6956521739130435, 0.14871794871794874, 0.6983333333333335, 0.6545454545454544, 0.7453703703703703, 0.047619047619047616, 0.002, 0.46416666666666667, 0.21076251998300288, 0.5714285714285714, 0.47148646245841724, 0.6714285714285714, 1.0, 0.7942513489362327], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:55:52,457] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7895: loss 72.4510
[2017-11-02 09:55:52,525] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7899: loss -90.4024
[2017-11-02 09:55:53,201] A3C_AGENT_WORKER-Thread-5 INFO:Local step 500, global step 7945: loss -69.9089
[2017-11-02 09:55:53,788] A3C_AGENT_WORKER-Thread-6 INFO:Local step 500, global step 7987: loss -47.7961
[2017-11-02 09:55:54,133] A3C_AGENT_WORKER-Thread-4 INFO:Local step 500, global step 8012: loss -11.4881
[2017-11-02 09:55:54,209] A3C_AGENT_WORKER-Thread-7 INFO:Local step 500, global step 8018: loss -49.0602
[2017-11-02 09:55:54,973] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8062: loss -161.6560
[2017-11-02 09:55:55,142] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8074: loss -3.0593
[2017-11-02 09:55:55,252] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 8080: loss -185.9503
[2017-11-02 09:55:55,309] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-121.54837036]
 [-130.43457031]
 [-123.27184296]
 [-119.70581818]
 [-122.94532013]], R is [[-123.39573669]
 [-123.16178131]
 [-122.93016815]
 [-122.7008667 ]
 [-122.47386169]].
[2017-11-02 09:55:55,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8096: loss 24.3210
[2017-11-02 09:55:55,947] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8119: loss 239.1296
[2017-11-02 09:55:57,135] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8187: loss 52.4126
[2017-11-02 09:55:57,313] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8200: loss 23.9263
[2017-11-02 09:56:00,871] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.84426141e-01   6.18549762e-04   1.31523702e-03
   1.36399930e-02], sum to 1.0000
[2017-11-02 09:56:00,923] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.4, 68.0, 5.016666666666667, 260.8333333333333, 0.0, 0.0, -3.4, 21.43653246392159, 22.0, 21.36711168510679, 21.5, 0.0, 52.89862220144429], 
actual action is [-3.4000000000000004, 22.5], 
sim time next is 162000.0000, 
raw observation next is [-8.4, 68.0, 5.1, 260.0, 0.0, 0.0, -3.4, 21.06027405083808, 22.5, 21.41007058279397, 21.5, 0.0, 42.03157657857578], 
processed observation next is [0.0, 0.9130434782608695, 0.11794871794871795, 0.68, 0.4636363636363636, 0.7222222222222222, 0.0, 0.0, 0.44333333333333336, 0.2106027405083808, 0.6428571428571429, 0.48715294039913865, 0.5, 0.0, 0.49448913621853857], 
reward next is -0.4579. 
=============================================
[2017-11-02 09:56:03,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-80.9090271 ]
 [-78.64864349]
 [-83.60351562]
 [-78.73403931]
 [-79.67655182]], R is [[-85.17233276]
 [-84.81245422]
 [-84.96433258]
 [-85.11469269]
 [-85.2635498 ]].
[2017-11-02 09:56:08,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   7.62808487e-19   1.66572017e-18   4.82803403e-19
   1.79433091e-19   9.90649760e-01   1.59261550e-03   1.25173794e-03
   6.50600949e-03], sum to 1.0000
[2017-11-02 09:56:08,385] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.816666666666666, 73.5, 4.016666666666667, 230.0, 0.0, 0.0, -3.775, 18.34310652978485, 25.0, 21.32591182796611, 21.5, 0.0, 46.45976553551743], 
actual action is [-3.8166666666666664, 25], 
sim time next is 176100.0000, 
raw observation next is [-8.858333333333334, 73.75, 4.058333333333333, 230.0, 0.0, 0.0, -3.816666666666666, 18.41896236339376, 25.0, 21.30435387980088, 21.5, 0.0, 46.50797430216021], 
processed observation next is [0.16666666666666666, 0.0, 0.10619658119658117, 0.7375, 0.3689393939393939, 0.6388888888888888, 0.0, 0.0, 0.4363888888888889, 0.1841896236339376, 1.0, 0.47205055425726833, 0.5, 0.0, 0.5471526388489436], 
reward next is -0.5204. 
=============================================
[2017-11-02 09:56:10,617] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.94837701e-01   1.26102555e-03   5.92077849e-04
   3.30920517e-03], sum to 1.0000
[2017-11-02 09:56:10,797] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-8.9, 74.0, 4.1, 230.0, 0.0, 0.0, -3.858333333333334, 16.21058711166711, 25.0, 21.59078785026939, 21.5, 0.0, 46.39070378495582], 
actual action is [-3.9000000000000004, 25], 
sim time next is 176700.0000, 
raw observation next is [-8.9, 74.0, 4.008333333333333, 227.5, 0.0, 0.0, -3.9, 16.28945881679537, 25.0, 21.56662943538568, 21.5, 0.0, 46.41965808552626], 
processed observation next is [0.16666666666666666, 0.043478260869565216, 0.10512820512820512, 0.74, 0.3643939393939393, 0.6319444444444444, 0.0, 0.0, 0.435, 0.1628945881679537, 1.0, 0.5095184907693826, 0.5, 0.0, 0.5461136245356031], 
reward next is -0.4915. 
=============================================
[2017-11-02 09:56:44,648] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.57481900e-03   8.53935373e-04   9.13824333e-05
   9.94479895e-01], sum to 1.0000
[2017-11-02 09:56:44,970] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.95, 59.75, 7.300000000000001, 230.0, 71.25, 0.0, 2.1, 11.24747529655541, 25.0, 23.53774025798595, 22.7, 1.0, 62.73678326366598], 
actual action is [2.05, 25], 
sim time next is 228000.0000, 
raw observation next is [-3.0, 60.0, 7.166666666666667, 230.0, 66.16666666666667, 0.0, 2.05, 11.20292280138263, 25.0, 23.55240867210624, 22.7, 1.0, 62.7029316741099], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2564102564102564, 0.6, 0.6515151515151515, 0.6388888888888888, 0.17504409171075838, 0.0, 0.5341666666666666, 0.11202922801382631, 1.0, 0.7932012388723199, 0.6714285714285714, 1.0, 0.7376815491071753], 
reward next is -0.6751. 
=============================================
[2017-11-02 09:56:46,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.07644992e-02   4.55797603e-03   7.29098800e-04
   9.83948410e-01], sum to 1.0000
[2017-11-02 09:56:47,032] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 65.0, 7.2, 210.0, 139.0, 0.0, 0.458333333333333, 11.896910324727, 25.0, 23.08735792542682, 22.7, 1.0, 63.3780748310615], 
actual action is [0.5, 25], 
sim time next is 219900.0000, 
raw observation next is [-4.408333333333333, 64.75, 7.149999999999999, 210.0, 140.6666666666667, 0.0, 0.5, 11.78241016225976, 25.0, 23.1255053233452, 22.7, 1.0, 63.16026895851718], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.2202991452991453, 0.6475, 0.6499999999999999, 0.5833333333333334, 0.3721340388007056, 0.0, 0.5083333333333333, 0.1178241016225976, 1.0, 0.7322150461921717, 0.6714285714285714, 1.0, 0.743061987747261], 
reward next is -0.6805. 
=============================================
[2017-11-02 09:56:52,173] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.99806357e-03   1.95970852e-03   6.95885028e-05
   9.94972587e-01], sum to 1.0000
[2017-11-02 09:56:52,520] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.15, 60.75, 6.766666666666667, 230.0, 52.83333333333333, 0.0, 1.9, 10.77465903589847, 25.0, 23.65292776184384, 22.7, 1.0, 62.43078681966943], 
actual action is [1.85, 25], 
sim time next is 229200.0000, 
raw observation next is [-3.2, 61.0, 6.633333333333333, 230.0, 49.66666666666667, 0.0, 1.85, 10.74176285423623, 25.0, 23.66174431175651, 22.7, 1.0, 62.36518566455568], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2512820512820513, 0.61, 0.603030303030303, 0.6388888888888888, 0.13139329805996475, 0.0, 0.5308333333333334, 0.1074176285423623, 1.0, 0.8088206159652158, 0.6714285714285714, 1.0, 0.7337080666418315], 
reward next is -0.6711. 
=============================================
[2017-11-02 09:56:55,471] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.17329781e-29   7.03045174e-28   1.38315790e-29
   3.78549994e-30   4.46707942e-02   4.79393937e-02   2.50849058e-03
   9.04881299e-01], sum to 1.0000
[2017-11-02 09:56:55,729] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 65.0, 6.016666666666666, 220.0, 0.0, 0.0, 1.6, 10.99094278695215, 25.0, 23.69561900054259, 22.7, 1.0, 41.44922420531673], 
actual action is [1.6, 25], 
sim time next is 240000.0000, 
raw observation next is [-3.4, 65.0, 5.933333333333334, 220.0, 0.0, 0.0, 1.6, 11.08114505057453, 25.0, 23.63016904617339, 22.7, 1.0, 53.55674539802196], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.24615384615384614, 0.65, 0.5393939393939394, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.11081145050574531, 1.0, 0.8043098637390556, 0.6714285714285714, 1.0, 0.6300793576237878], 
reward next is -0.5782. 
=============================================
[2017-11-02 09:57:09,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.21126324e-01   2.02095266e-02   8.34622264e-01   1.89249329e-02
   5.11694606e-03   3.71713183e-23   2.06020066e-23   2.50732852e-24
   8.57248361e-24], sum to 1.0000
[2017-11-02 09:57:09,616] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.399999999999999, 79.5, 6.283333333333333, 273.3333333333333, 0.0, 0.0, 0.6500000000000004, 24.05375877989568, 24.5, 20.60295631212622, 21.5, 0.0, 24.34077930717801], 
actual action is [0.6000000000000014, 23.5], 
sim time next is 258900.0000, 
raw observation next is [-4.45, 79.25, 6.191666666666666, 276.6666666666666, 0.0, 0.0, 0.6000000000000014, 23.30445261208829, 23.5, 20.60529102955788, 21.5, 0.0, 41.5286593499639], 
processed observation next is [0.16666666666666666, 1.0, 0.21923076923076926, 0.7925, 0.5628787878787879, 0.7685185185185183, 0.0, 0.0, 0.51, 0.23304452612088292, 0.7857142857142857, 0.3721844327939827, 0.5, 0.0, 0.4885724629407518], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:12,445] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.47967602e-03   3.69433919e-03   9.90764141e-01   9.65668994e-04
   9.61819314e-05   1.91396964e-31   4.73236775e-32   1.95107068e-32
   1.46016511e-31], sum to 1.0000
[2017-11-02 09:57:12,507] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.4, 69.5, 7.35, 296.6666666666666, 0.0, 0.0, -4.35, 25.75470244006913, 19.5, 19.86709631233584, 21.5, 0.0, 31.53038367650501], 
actual action is [-4.4, 18.5], 
sim time next is 273300.0000, 
raw observation next is [-9.45, 69.75, 7.525, 298.3333333333334, 0.0, 0.0, -4.4, 26.32262700316983, 18.5, 19.84039112634895, 21.5, 0.0, 29.84477599931757], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.09102564102564105, 0.6975, 0.6840909090909091, 0.8287037037037039, 0.0, 0.0, 0.4266666666666667, 0.2632262700316983, 0.07142857142857142, 0.2629130180498502, 0.5, 0.0, 0.3511150117566773], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:13,943] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   2.88618381e-21   2.62282677e-18   2.58337149e-21
   1.48936219e-22   8.33488554e-02   3.20574455e-02   1.28390389e-02
   8.71754646e-01], sum to 1.0000
[2017-11-02 09:57:14,053] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.633333333333333, 67.66666666666667, 5.683333333333334, 280.0, 0.0, 0.0, -13.5, 30.32990679467698, 18.0, 19.90610474305253, 21.5, 0.0, 0.0], 
actual action is [-3.633333333333333, 23.0], 
sim time next is 269700.0000, 
raw observation next is [-8.766666666666667, 67.33333333333333, 5.641666666666667, 280.0, 0.0, 0.0, -3.633333333333333, 28.72606967578081, 23.0, 19.74577880736191, 21.5, 0.0, 62.31076838504559], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.10854700854700852, 0.6733333333333333, 0.5128787878787878, 0.7777777777777778, 0.0, 0.0, 0.43944444444444447, 0.2872606967578081, 0.7142857142857143, 0.24939697248027265, 0.5, 0.0, 0.7330678633534775], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:15,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.13711685e-19   4.42354009e-03   9.93694723e-01   1.19348988e-03
   6.67388304e-05   8.76088088e-05   2.58245091e-05   2.88956107e-05
   4.79103794e-04], sum to 1.0000
[2017-11-02 09:57:15,252] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.1, 68.0, 5.766666666666667, 263.3333333333334, 0.0, 0.0, -7.050000000000001, 24.26687782432506, 25.0, 19.80996137578873, 21.5, 0.0, 48.91138745468631], 
actual action is [-7.1, 24.0], 
sim time next is 283500.0000, 
raw observation next is [-12.15, 67.75, 5.85, 265.0, 0.0, 0.0, -7.1, 24.34392587172935, 24.0, 19.80373810963576, 21.5, 0.0, 48.95236756454701], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.021794871794871787, 0.6775, 0.5318181818181817, 0.7361111111111112, 0.0, 0.0, 0.38166666666666665, 0.2434392587172935, 0.8571428571428571, 0.2576768728051085, 0.5, 0.0, 0.5759102066417295], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:15,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.34583598e-02   3.59416381e-03   9.72407758e-01   5.07030170e-04
   3.25759866e-05   5.49479441e-37   3.60193681e-38   9.23668629e-38
   4.14870127e-37], sum to 1.0000
[2017-11-02 09:57:15,572] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-9.866666666666667, 69.0, 7.533333333333333, 286.6666666666667, 0.0, 0.0, -14.775, 28.36350968365624, 18.0, 20.10882699305799, 21.5, 0.0, 0.0], 
actual action is [-14.866666666666667, 18], 
sim time next is 275100.0000, 
raw observation next is [-9.958333333333332, 68.75, 7.491666666666666, 283.3333333333333, 0.0, 0.0, -14.86666666666667, 31.71519340502054, 18.0, 19.93981644647124, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.07799145299145302, 0.6875, 0.681060606060606, 0.787037037037037, 0.0, 0.0, 0.2522222222222222, 0.31715193405020536, 0.0, 0.27711663521017726, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:20,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  2.04447377e-02   4.20909375e-02   9.34766114e-01   2.63005635e-03
   6.81481761e-05   2.00209812e-36   4.52712226e-37   9.55179919e-37
   8.45852416e-36], sum to 1.0000
[2017-11-02 09:57:20,248] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-10.05, 68.5, 7.45, 280.0, 0.0, 0.0, -4.958333333333332, 23.71504064452576, 24.0, 20.26177296962214, 21.5, 0.0, 44.92656476351554], 
actual action is [-5.050000000000001, 23.0], 
sim time next is 275700.0000, 
raw observation next is [-10.14166666666667, 68.25, 7.408333333333333, 276.6666666666667, 0.0, 0.0, -5.050000000000001, 23.62788745796977, 23.0, 20.22509985954559, 21.5, 0.0, 50.43287054990827], 
processed observation next is [0.3333333333333333, 0.17391304347826086, 0.07329059829059822, 0.6825, 0.6734848484848485, 0.7685185185185186, 0.0, 0.0, 0.41583333333333333, 0.2362788745796977, 0.7142857142857143, 0.3178714085065129, 0.5, 0.0, 0.5933278888224502], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:22,850] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-109.69056702]
 [-110.77324677]
 [-108.6726532 ]
 [-109.79374695]
 [-108.29410553]], R is [[-102.25848389]
 [-102.23590088]
 [-102.21353912]
 [-102.19140625]
 [-102.16949463]].
[2017-11-02 09:57:29,677] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.91922225e-10   6.20390959e-02   8.99608016e-01   3.69255915e-02
   1.42731087e-03   1.06001050e-13   1.44529029e-14   1.05192539e-14
   4.45262283e-14], sum to 1.0000
[2017-11-02 09:57:29,971] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-12.1, 65.66666666666667, 5.6, 246.6666666666667, 84.16666666666667, 383.5, -7.15, 18.41164577203844, 25.0, 21.41627216644314, 22.7, 1.0, 55.69411012250985], 
actual action is [-7.1, 24.0], 
sim time next is 293100.0000, 
raw observation next is [-12.05, 65.33333333333333, 5.6, 248.3333333333333, 89.58333333333333, 383.25, -7.1, 18.13924500238657, 24.0, 21.41258837402069, 22.7, 1.0, 64.65532818917816], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.024358974358974342, 0.6533333333333333, 0.509090909090909, 0.6898148148148147, 0.23699294532627865, 0.38325, 0.38166666666666665, 0.1813924500238657, 0.8571428571428571, 0.4875126248600985, 0.6714285714285714, 1.0, 0.7606509198726843], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:31,257] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15636: loss -65.8423
[2017-11-02 09:57:35,201] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1000, global step 15840: loss 49.1587
[2017-11-02 09:57:35,333] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15847: loss -381.0505
[2017-11-02 09:57:36,506] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1000, global step 15906: loss -40.2543
[2017-11-02 09:57:36,512] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15906: loss -133.7090
[2017-11-02 09:57:36,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15917: loss -20.5012
[2017-11-02 09:57:37,097] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1000, global step 15938: loss -0.6747
[2017-11-02 09:57:37,173] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15943: loss -110.4725
[2017-11-02 09:57:38,500] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16034: loss -10.8479
[2017-11-02 09:57:38,925] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16062: loss 117.6686
[2017-11-02 09:57:39,082] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16069: loss -30.6229
[2017-11-02 09:57:39,542] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1000, global step 16101: loss -44.3895
[2017-11-02 09:57:39,873] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1000, global step 16122: loss -42.3942
[2017-11-02 09:57:39,960] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16128: loss 10.2137
[2017-11-02 09:57:39,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  7.34712677e-20   7.02310801e-02   8.86636853e-01   4.27901335e-02
   3.25969711e-04   1.41397104e-05   1.15532572e-07   2.51132491e-07
   1.50448045e-06], sum to 1.0000
[2017-11-02 09:57:40,107] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-10.6, 56.33333333333334, 7.533333333333333, 263.3333333333334, 102.8333333333333, 633.6666666666667, -5.6, 16.41655889360368, 21.0, 22.19633746297017, 22.7, 1.0, 36.70958598424681], 
actual action is [-5.6, 20.0], 
sim time next is 300300.0000, 
raw observation next is [-10.6, 55.41666666666666, 7.616666666666665, 264.1666666666666, 104.4166666666667, 645.8333333333333, -5.6, 17.08478759673563, 20.0, 22.11729436439696, 22.7, 1.0, 34.23407703469626], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.06153846153846155, 0.5541666666666666, 0.6924242424242423, 0.7337962962962961, 0.27623456790123463, 0.6458333333333333, 0.4066666666666666, 0.1708478759673563, 0.2857142857142857, 0.588184909199566, 0.6714285714285714, 1.0, 0.40275384746701487], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:57:40,193] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16145: loss 16.6818
[2017-11-02 09:57:42,797] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16302: loss 236.9585
[2017-11-02 09:58:09,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.98212099e-01   5.32047998e-04   2.47788033e-04
   1.00817182e-03], sum to 1.0000
[2017-11-02 09:58:09,558] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-14.2, 67.5, 5.1, 265.0, 0.0, 0.0, -9.15, 28.13596833705003, 25.0, 20.07694671047135, 21.5, 0.0, 49.13839548566223], 
actual action is [-9.2, 25], 
sim time next is 347700.0000, 
raw observation next is [-14.25, 67.75, 5.1, 264.1666666666667, 0.0, 0.0, -9.2, 28.20927212372225, 25.0, 20.06500192556497, 21.5, 0.0, 49.09290888830639], 
processed observation next is [0.5, 0.0, -0.03205128205128205, 0.6775, 0.4636363636363636, 0.7337962962962964, 0.0, 0.0, 0.3466666666666667, 0.2820927212372225, 1.0, 0.29500027508071014, 0.5, 0.0, 0.5775636339800752], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:10,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-131.74899292]
 [-122.6782608 ]
 [-134.2338562 ]
 [-131.30363464]
 [-131.78701782]], R is [[-135.53079224]
 [-135.17549133]
 [-134.82373047]
 [-134.47549438]
 [-134.1307373 ]].
[2017-11-02 09:58:14,409] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99465644e-01   1.39494194e-04   1.82619515e-05
   3.76601267e-04], sum to 1.0000
[2017-11-02 09:58:14,518] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 69.0, 7.066666666666666, 260.0, 0.0, 0.0, -10.0, 43.37911741974797, 20.0, 18.5325238789464, 21.5, 0.0, 31.932774142297], 
actual action is [-10.0, 20.5], 
sim time next is 353400.0000, 
raw observation next is [-15.0, 69.0, 6.933333333333334, 260.0, 0.0, 0.0, -10.0, 43.34307038955045, 20.5, 18.47077353709398, 21.5, 0.0, 45.33605083980123], 
processed observation next is [0.5, 0.08695652173913043, -0.05128205128205128, 0.69, 0.6303030303030304, 0.7222222222222222, 0.0, 0.0, 0.3333333333333333, 0.4334307038955045, 0.35714285714285715, 0.06725336244199706, 0.5, 0.0, 0.5333653039976616], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:15,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99119461e-01   3.09979019e-04   6.70622176e-05
   5.03452786e-04], sum to 1.0000
[2017-11-02 09:58:15,743] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-14.875, 69.0, 6.675000000000001, 260.0, 0.0, 0.0, -9.83333333333333, 39.79987060649081, 20.0, 18.84309693348132, 21.5, 0.0, 37.54207628591882], 
actual action is [-9.875, 20.5], 
sim time next is 352200.0000, 
raw observation next is [-14.91666666666667, 69.0, 6.85, 260.0, 0.0, 0.0, -9.875, 39.94362113024903, 20.5, 18.83255837364007, 21.5, 0.0, 45.7969226643612], 
processed observation next is [0.5, 0.043478260869565216, -0.04914529914529922, 0.69, 0.6227272727272727, 0.7222222222222222, 0.0, 0.0, 0.33541666666666664, 0.3994362113024903, 0.35714285714285715, 0.11893691052000983, 0.5, 0.0, 0.538787325463073], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:16,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.99623537e-01   1.23017468e-04   9.55465657e-06
   2.43874223e-04], sum to 1.0000
[2017-11-02 09:58:16,781] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.0, 69.0, 6.933333333333334, 260.0, 0.0, 0.0, -10.0, 45.53278554534108, 18.5, 18.45053782809955, 21.5, 0.0, 51.4117909167413], 
actual action is [-10.0, 19.0], 
sim time next is 353700.0000, 
raw observation next is [-15.0, 69.0, 6.800000000000001, 260.0, 0.0, 0.0, -10.0, 45.95286298766304, 19.0, 18.35992228876924, 21.5, 0.0, 34.43069690291265], 
processed observation next is [0.5, 0.08695652173913043, -0.05128205128205128, 0.69, 0.6181818181818183, 0.7222222222222222, 0.0, 0.0, 0.3333333333333333, 0.4595286298766304, 0.14285714285714285, 0.05141746982417723, 0.5, 0.0, 0.40506702238720765], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:33,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.98913050e-01   5.81582950e-04   1.00737561e-04
   4.04624967e-04], sum to 1.0000
[2017-11-02 09:58:33,836] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.23333333333333, 82.0, 4.933333333333334, 233.3333333333334, 36.66666666666666, 694.5, -10.325, 35.41660044681006, 24.0, 19.68217701791811, 22.7, 1.0, 65.23320935744913], 
actual action is [-10.23333333333333, 24.5], 
sim time next is 379500.0000, 
raw observation next is [-15.14166666666667, 80.0, 4.766666666666666, 231.6666666666666, 37.83333333333334, 716.25, -10.23333333333333, 34.80053209969825, 24.5, 19.76730521808962, 22.7, 1.0, 64.97272665197228], 
processed observation next is [0.5, 0.391304347826087, -0.05491452991452998, 0.8, 0.43333333333333324, 0.6435185185185184, 0.10008818342151678, 0.71625, 0.3294444444444445, 0.3480053209969825, 0.9285714285714286, 0.25247217401280303, 0.6714285714285714, 1.0, 0.764385019434968], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:58:40,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-102.29763794]
 [-105.13561249]
 [-107.51331329]
 [-104.50480652]
 [-105.64883423]], R is [[-105.07196045]
 [-105.02124023]
 [-104.97103119]
 [-104.92132568]
 [-104.87211609]].
[2017-11-02 09:58:55,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0240059
  0.91589469  0.05622571  0.00387367], sum to 1.0000
[2017-11-02 09:58:56,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-9.625, 40.5, 5.475, 212.5, 0.0, 0.0, -4.583333333333334, 26.05475672187945, 25.0, 21.38451776711636, 22.7, 1.0, 65.02583447516237], 
actual action is [-4.625, 25], 
sim time next is 415200.0000, 
raw observation next is [-9.666666666666668, 40.66666666666667, 5.433333333333334, 210.0, 0.0, 0.0, -4.625, 26.00776134164615, 25.0, 21.39472164557236, 22.7, 1.0, 65.00028069393557], 
processed observation next is [0.5, 0.8260869565217391, 0.08547008547008544, 0.40666666666666673, 0.49393939393939396, 0.5833333333333334, 0.0, 0.0, 0.42291666666666666, 0.2600776134164615, 1.0, 0.4849602350817658, 0.6714285714285714, 1.0, 0.7647091846345361], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:59:06,783] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00524496
  0.94239974  0.0415023   0.01085299], sum to 1.0000
[2017-11-02 09:59:06,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00569485
  0.9508543   0.03590921  0.00754169], sum to 1.0000
[2017-11-02 09:59:06,934] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-11.7, 54.0, 4.058333333333333, 190.0, 0.0, 0.0, -6.699999999999999, 27.20294717290648, 25.0, 20.61745311865855, 21.5, 0.0, 47.70530206294728], 
actual action is [-6.699999999999999, 25], 
sim time next is 432000.0000, 
raw observation next is [-11.7, 54.0, 4.1, 190.0, 0.0, 0.0, -6.699999999999999, 27.31377944982188, 25.0, 20.59139987980152, 21.5, 0.0, 47.75611198001137], 
processed observation next is [0.6666666666666666, 0.0, 0.033333333333333354, 0.54, 0.3727272727272727, 0.5277777777777778, 0.0, 0.0, 0.38833333333333336, 0.2731377944982188, 1.0, 0.3701999828287888, 0.5, 0.0, 0.5618366115295456], 
reward next is -1.0000. 
=============================================
[2017-11-02 09:59:06,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-10.875, 50.25, 3.15, 197.5, 0.0, 0.0, -5.78333333333333, 23.66117932810939, 25.0, 21.31785376243794, 21.5, 0.0, 46.34235978532839], 
actual action is [-5.875, 25], 
sim time next is 426000.0000, 
raw observation next is [-10.96666666666667, 50.66666666666667, 3.2, 196.6666666666667, 0.0, 0.0, -5.875, 23.7546139506962, 25.0, 21.29324538808721, 21.5, 0.0, 46.40537170222341], 
processed observation next is [0.5, 0.9565217391304348, 0.05213675213675204, 0.5066666666666667, 0.29090909090909095, 0.5462962962962964, 0.0, 0.0, 0.40208333333333335, 0.237546139506962, 1.0, 0.4704636268696016, 0.5, 0.0, 0.5459455494379225], 
reward next is -0.5209. 
=============================================
[2017-11-02 09:59:14,619] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23284: loss 1.8325
[2017-11-02 09:59:15,486] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23379: loss 1.7083
[2017-11-02 09:59:15,827] A3C_AGENT_WORKER-Thread-5 INFO:Local step 1500, global step 23417: loss -25.1104
[2017-11-02 09:59:16,621] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23505: loss 1.5728
[2017-11-02 09:59:16,845] A3C_AGENT_WORKER-Thread-8 INFO:Local step 1500, global step 23531: loss 1.0905
[2017-11-02 09:59:18,738] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23737: loss -37.1460
[2017-11-02 09:59:19,965] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23859: loss 3.3842
[2017-11-02 09:59:20,050] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-110.92807007]
 [-110.32891083]
 [-109.79460144]
 [-108.89787292]
 [-108.1441803 ]], R is [[-107.69704437]
 [-107.62007141]
 [-107.54386902]
 [-107.46842957]
 [-107.39374542]].
[2017-11-02 09:59:20,142] A3C_AGENT_WORKER-Thread-4 INFO:Local step 1500, global step 23877: loss -1.1617
[2017-11-02 09:59:20,780] A3C_AGENT_WORKER-Thread-6 INFO:Local step 1500, global step 23932: loss -99.3314
[2017-11-02 09:59:22,307] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24058: loss 4.0297
[2017-11-02 09:59:24,194] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24208: loss 1.2998
[2017-11-02 09:59:25,130] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24268: loss 7.0242
[2017-11-02 09:59:25,686] A3C_AGENT_WORKER-Thread-7 INFO:Local step 1500, global step 24312: loss 10.0365
[2017-11-02 09:59:27,654] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24442: loss -3.0027
[2017-11-02 09:59:27,958] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24462: loss 153.2652
[2017-11-02 09:59:28,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24510: loss -45.3117
[2017-11-02 09:59:51,663] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00211412
  0.1146967   0.65170753  0.23148167], sum to 1.0000
[2017-11-02 09:59:51,865] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.2, 36.33333333333333, 4.1, 166.6666666666667, 87.66666666666667, 0.0, 4.75, 12.17941325310314, 25.0, 23.55931375241461, 22.7, 1.0, 60.22968929113744], 
actual action is [4.8, 25], 
sim time next is 485100.0000, 
raw observation next is [-0.15, 36.5, 4.1, 167.5, 84.5, 0.0, 4.8, 12.04678626591764, 25.0, 23.5917134714399, 22.7, 1.0, 60.05330579106197], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3294871794871795, 0.365, 0.3727272727272727, 0.4652777777777778, 0.22354497354497355, 0.0, 0.58, 0.1204678626591764, 1.0, 0.7988162102056998, 0.6714285714285714, 1.0, 0.7065094798948467], 
reward next is -0.6479. 
=============================================
[2017-11-02 10:00:01,983] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00256096
  0.06330116  0.92195141  0.0121864 ], sum to 1.0000
[2017-11-02 10:00:02,171] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.1, 96.0, 5.516666666666666, 138.3333333333333, 0.0, 0.0, 6.1, 10.35915192286125, 25.0, 23.9288250768365, 22.7, 1.0, 54.02623182420434], 
actual action is [6.1, 25], 
sim time next is 501000.0000, 
raw observation next is [1.1, 96.0, 5.433333333333334, 136.6666666666667, 0.0, 0.0, 6.1, 10.18275616908339, 25.0, 23.89496601344801, 22.7, 1.0, 63.23784236828355], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.96, 0.49393939393939396, 0.37962962962962976, 0.0, 0.0, 0.6016666666666667, 0.1018275616908339, 1.0, 0.8421380019211442, 0.6714285714285714, 1.0, 0.7439746160974535], 
reward next is -0.6798. 
=============================================
[2017-11-02 10:00:06,104] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01137498
  0.0400922   0.93950814  0.00902475], sum to 1.0000
[2017-11-02 10:00:06,293] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [1.1, 42.25, 6.016666666666666, 168.3333333333333, 11.66666666666667, 0.0, 6.1, 9.881416800901645, 25.0, 24.01752946232771, 22.7, 1.0, 60.1591838132925], 
actual action is [6.1, 25], 
sim time next is 493200.0000, 
raw observation next is [1.1, 43.0, 6.1, 170.0, 10.0, 0.0, 6.1, 9.92261027351146, 25.0, 24.04228046948427, 22.7, 1.0, 52.45399403044022], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.36153846153846153, 0.43, 0.5545454545454546, 0.4722222222222222, 0.026455026455026454, 0.0, 0.6016666666666667, 0.09922610273511459, 1.0, 0.8631829242120383, 0.6714285714285714, 1.0, 0.6171058121228261], 
reward next is -0.5653. 
=============================================
[2017-11-02 10:00:06,476] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-50.64907455]
 [-50.7475853 ]
 [-50.24901962]
 [-50.31851578]
 [-50.0163002 ]], R is [[-49.8299942 ]
 [-49.6546669 ]
 [-49.49523926]
 [-49.3515358 ]
 [-49.26465607]].
[2017-11-02 10:00:11,603] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0145164
  0.07528454  0.89067352  0.0195256 ], sum to 1.0000
[2017-11-02 10:00:11,794] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.9, 93.33333333333334, 5.1, 176.6666666666667, 0.0, 0.0, 7.850000000000001, 7.900872186855868, 25.0, 24.01800015414725, 21.5, 0.0, 44.41556937278173], 
actual action is [7.9, 25], 
sim time next is 512700.0000, 
raw observation next is [2.95, 93.66666666666666, 4.975, 175.8333333333333, 0.0, 0.0, 7.9, 7.829129362103664, 25.0, 24.06190264212612, 21.5, 0.0, 38.77294635666093], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.40897435897435896, 0.9366666666666665, 0.4522727272727272, 0.4884259259259258, 0.0, 0.0, 0.6316666666666666, 0.07829129362103665, 1.0, 0.865986091732303, 0.5, 0.0, 0.4561523100783639], 
reward next is -0.4105. 
=============================================
[2017-11-02 10:00:13,217] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01476518
  0.11928371  0.85214126  0.01380978], sum to 1.0000
[2017-11-02 10:00:13,325] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [3.466666666666667, 96.33333333333333, 4.433333333333334, 183.3333333333333, 0.0, 0.0, 8.425, 7.509404885953999, 25.0, 23.96627784594652, 21.5, 0.0, 44.26646785601054], 
actual action is [8.466666666666667, 25], 
sim time next is 516300.0000, 
raw observation next is [3.508333333333333, 96.41666666666666, 4.516666666666666, 186.6666666666667, 0.0, 0.0, 8.466666666666667, 7.373695139175005, 25.0, 24.01306129775191, 21.5, 0.0, 43.83134389221292], 
processed observation next is [0.6666666666666666, 1.0, 0.4232905982905983, 0.9641666666666666, 0.41060606060606053, 0.5185185185185186, 0.0, 0.0, 0.6411111111111112, 0.07373695139175006, 1.0, 0.8590087568217015, 0.5, 0.0, 0.515662869320152], 
reward next is -0.4641. 
=============================================
[2017-11-02 10:00:22,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-50.15872955]
 [-50.12380981]
 [-49.87891006]
 [-49.29667664]
 [-49.40091705]], R is [[-48.81895065]
 [-48.80189133]
 [-48.78826141]
 [-48.77630997]
 [-48.76715469]].
[2017-11-02 10:00:35,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01109801
  0.42938077  0.5063976   0.05312366], sum to 1.0000
[2017-11-02 10:00:35,229] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.35, 88.66666666666666, 6.6, 321.6666666666666, 138.4166666666667, 106.1666666666667, 4.7, 6.023303407299764, 25.0, 24.12746517775342, 22.7, 1.0, 46.04059243007238], 
actual action is [4.65, 25], 
sim time next is 553200.0000, 
raw observation next is [-0.4, 88.33333333333334, 6.6, 323.3333333333334, 132.8333333333333, 109.3333333333333, 4.65, 6.03496336321266, 25.0, 24.10344849264473, 22.7, 1.0, 46.62242125217819], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.3230769230769231, 0.8833333333333334, 0.6, 0.8981481481481484, 0.35141093474426793, 0.1093333333333333, 0.5775, 0.0603496336321266, 1.0, 0.8719212132349615, 0.6714285714285714, 1.0, 0.5484990735550376], 
reward next is -0.4997. 
=============================================
[2017-11-02 10:00:46,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   1.62794187e-35   1.31979248e-34   1.61788803e-35
   6.93216727e-36   2.20905840e-02   6.46251738e-01   2.91021913e-01
   4.06357683e-02], sum to 1.0000
[2017-11-02 10:00:46,401] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.8, 87.0, 5.1, 270.0, 0.0, 0.0, 2.2, 6.958020848060922, 25.0, 23.85330746687717, 21.5, 0.0, 48.35300052402713], 
actual action is [2.2, 25], 
sim time next is 590700.0000, 
raw observation next is [-2.8, 86.66666666666667, 5.183333333333334, 270.8333333333333, 0.0, 0.0, 2.2, 6.87463110415635, 25.0, 23.85947362063053, 21.5, 0.0, 48.15500873840708], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.2615384615384615, 0.8666666666666667, 0.47121212121212125, 0.7523148148148148, 0.0, 0.0, 0.5366666666666667, 0.06874631104156351, 1.0, 0.8370676600900759, 0.5, 0.0, 0.5665295145694951], 
reward next is -0.5099. 
=============================================
[2017-11-02 10:00:48,496] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.06090599
  0.59886557  0.29363269  0.04659575], sum to 1.0000
[2017-11-02 10:00:48,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.2, 83.0, 6.1, 296.6666666666667, 109.0, 204.3333333333333, 3.8, 6.955554369694564, 25.0, 24.25742727566611, 22.7, 1.0, 46.04320317780256], 
actual action is [3.8, 25], 
sim time next is 573300.0000, 
raw observation next is [-1.2, 83.0, 6.1, 295.0, 106.75, 171.5, 3.8, 6.953212965335538, 25.0, 24.36353203653827, 22.7, 1.0, 45.80988553262279], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.3025641025641026, 0.83, 0.5545454545454546, 0.8194444444444444, 0.2824074074074074, 0.1715, 0.5633333333333332, 0.06953212965335538, 1.0, 0.909076005219753, 0.6714285714285714, 1.0, 0.5389398297955623], 
reward next is -0.4920. 
=============================================
[2017-11-02 10:00:49,826] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2000, global step 31262: loss -0.0064
[2017-11-02 10:00:51,019] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31403: loss 0.6795
[2017-11-02 10:00:51,667] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2000, global step 31473: loss -0.0913
[2017-11-02 10:00:52,938] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31628: loss 0.0113
[2017-11-02 10:00:53,125] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31647: loss 1.6226
[2017-11-02 10:00:53,816] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2000, global step 31718: loss 0.4277
[2017-11-02 10:00:54,891] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31839: loss 0.0057
[2017-11-02 10:00:55,133] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2000, global step 31863: loss 0.6345
[2017-11-02 10:00:57,498] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32130: loss -3.2133
[2017-11-02 10:00:57,698] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32150: loss -1.0772
[2017-11-02 10:00:58,993] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32292: loss -4.3975
[2017-11-02 10:00:59,240] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32323: loss 0.5708
[2017-11-02 10:00:59,976] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2000, global step 32403: loss 0.0288
[2017-11-02 10:01:00,936] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32509: loss 0.6665
[2017-11-02 10:01:01,769] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32598: loss 0.0947
[2017-11-02 10:01:02,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32696: loss 0.1628
[2017-11-02 10:01:03,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02759528
  0.67926675  0.26151329  0.03162463], sum to 1.0000
[2017-11-02 10:01:03,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.5, 68.58333333333333, 5.4, 251.6666666666667, 0.0, 0.0, 0.5, 6.878021342716201, 25.0, 22.66967045899647, 21.5, 0.0, 46.01132673326361], 
actual action is [0.5, 25], 
sim time next is 622800.0000, 
raw observation next is [-4.5, 68.0, 5.1, 250.0, 0.0, 0.0, 0.5, 6.890696196857446, 25.0, 22.66049315206962, 21.5, 0.0, 45.8206764556968], 
processed observation next is [1.0, 0.21739130434782608, 0.21794871794871795, 0.68, 0.4636363636363636, 0.6944444444444444, 0.0, 0.0, 0.5083333333333333, 0.06890696196857446, 1.0, 0.6657847360099457, 0.5, 0.0, 0.5390667818317271], 
reward next is -0.4852. 
=============================================
[2017-11-02 10:01:12,434] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.18454775
  0.16031829  0.41154164  0.24359235], sum to 1.0000
[2017-11-02 10:01:13,097] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.9, 66.5, 9.075, 250.0, 126.25, 38.25, 1.100000000000001, 6.481548126827071, 25.0, 23.6175830558953, 22.7, 1.0, 63.52852442896431], 
actual action is [1.1, 25], 
sim time next is 640200.0000, 
raw observation next is [-3.9, 66.0, 9.116666666666665, 250.0, 123.3333333333333, 34.00000000000001, 1.1, 6.473936831049019, 25.0, 23.65622020256132, 22.7, 1.0, 63.54315468464075], 
processed observation next is [1.0, 0.391304347826087, 0.23333333333333334, 0.66, 0.8287878787878786, 0.6944444444444444, 0.32627865961199287, 0.03400000000000001, 0.5183333333333333, 0.0647393683104902, 1.0, 0.8080314575087603, 0.6714285714285714, 1.0, 0.7475665257016558], 
reward next is -0.6793. 
=============================================
[2017-11-02 10:01:19,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.01013222
  0.12121087  0.56832743  0.30032957], sum to 1.0000
[2017-11-02 10:01:19,577] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.483333333333333, 65.0, 8.783333333333333, 241.6666666666667, 96.33333333333333, 12.66666666666666, 1.475, 6.56547681959124, 25.0, 23.88549585715483, 22.7, 1.0, 63.36242707898575], 
actual action is [1.516666666666667, 25], 
sim time next is 644100.0000, 
raw observation next is [-3.441666666666666, 65.0, 8.741666666666665, 240.8333333333333, 95.41666666666666, 15.83333333333333, 1.516666666666667, 6.563228149226648, 25.0, 23.90500125499466, 22.7, 1.0, 63.27497252006172], 
processed observation next is [1.0, 0.43478260869565216, 0.2450854700854701, 0.65, 0.7946969696969696, 0.6689814814814814, 0.25242504409171074, 0.01583333333333333, 0.5252777777777777, 0.06563228149226648, 1.0, 0.8435716078563799, 0.6714285714285714, 1.0, 0.7444114414124908], 
reward next is -0.6765. 
=============================================
[2017-11-02 10:01:23,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.16357531e-05   1.01167761e-01   7.58240998e-01   1.28016889e-01
   1.24826832e-02   1.63602194e-12   9.83190872e-12   1.37133005e-11
   2.92151264e-12], sum to 1.0000
[2017-11-02 10:01:23,258] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.025, 59.25, 6.124999999999999, 252.5, 164.5, 94.75, 2.883333333333333, 7.304164547642478, 22.5, 23.81667441101903, 22.7, 1.0, 30.67328719990186], 
actual action is [2.975, 21.5], 
sim time next is 652800.0000, 
raw observation next is [-1.933333333333333, 59.33333333333334, 6.3, 253.3333333333333, 170.3333333333333, 94.16666666666666, 2.975, 7.468256303939195, 21.5, 23.76346082067571, 22.7, 1.0, 28.73055811288812], 
processed observation next is [1.0, 0.5652173913043478, 0.28376068376068375, 0.5933333333333334, 0.5727272727272728, 0.7037037037037036, 0.4506172839506172, 0.09416666666666666, 0.5495833333333333, 0.07468256303939196, 0.5, 0.8233515458108158, 0.6714285714285714, 1.0, 0.3380065660339779], 
reward next is -0.3117. 
=============================================
[2017-11-02 10:01:27,137] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  3.44756216e-07   2.57938448e-02   9.00070906e-01   3.84714417e-02
   3.56628858e-02   6.21651424e-08   1.62157036e-07   2.23305761e-07
   5.83292810e-08], sum to 1.0000
[2017-11-02 10:01:27,221] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-3.225, 64.0, 8.325, 242.5, 91.75, 28.5, 1.716666666666666, 12.63977804687659, 19.0, 21.54396982849111, 22.7, 1.0, 96.68815727713375], 
actual action is [-8.225, 18.0], 
sim time next is 645600.0000, 
raw observation next is [-3.166666666666667, 63.66666666666667, 8.2, 243.3333333333334, 90.83333333333334, 31.66666666666667, -8.225, 13.33905244159387, 18.0, 21.6360023903366, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.25213675213675213, 0.6366666666666667, 0.7454545454545454, 0.6759259259259262, 0.240299823633157, 0.03166666666666667, 0.36291666666666667, 0.13339052441593868, 0.0, 0.5194289129052285, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:01:39,832] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.94189024e-01   1.09158061e-03   4.12511779e-03   3.46143381e-04
   2.48209340e-04   8.61793145e-20   4.71545268e-19   5.29186574e-19
   4.06894615e-19], sum to 1.0000
[2017-11-02 10:01:39,929] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.399999999999999, 69.0, 4.058333333333333, 240.0, 0.0, 0.0, 1.6, 11.66294608519412, 19.0, 22.26946967600328, 21.5, 0.0, 47.34625489787017], 
actual action is [-8.399999999999999, 18], 
sim time next is 681000.0000, 
raw observation next is [-3.4, 69.0, 4.016666666666667, 240.0, 0.0, 0.0, -8.399999999999999, 12.85015628533594, 18.0, 22.3405587881581, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.24615384615384614, 0.69, 0.36515151515151517, 0.6666666666666666, 0.0, 0.0, 0.36000000000000004, 0.1285015628533594, 0.0, 0.6200798268797284, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:01:43,175] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  8.26798379e-01   5.60757741e-02   9.25097689e-02   1.12374453e-02
   1.33786416e-02   2.45159478e-15   1.32600729e-14   1.39265794e-14
   3.44182754e-15], sum to 1.0000
[2017-11-02 10:01:43,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 64.0, 4.1, 243.3333333333333, 0.0, 0.0, -7.591666666666666, 16.13905175976909, 18.0, 22.28008465080057, 21.5, 0.0, 0.0], 
actual action is [-7.633333333333333, 18], 
sim time next is 675900.0000, 
raw observation next is [-2.675, 64.25, 3.975, 242.5, 0.0, 0.0, -7.633333333333333, 18.10458418444485, 18.0, 22.03259207490789, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.26474358974358975, 0.6425, 0.3613636363636364, 0.6736111111111112, 0.0, 0.0, 0.37277777777777776, 0.1810458418444485, 0.0, 0.5760845821296984, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:01:55,936] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00099218
  0.01391067  0.78069383  0.20440334], sum to 1.0000
[2017-11-02 10:01:56,000] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.341666666666666, 75.91666666666666, 4.558333333333333, 259.1666666666666, 0.0, 0.0, -7.383333333333333, 26.69319167617289, 18.0, 20.07480710418132, 21.5, 0.0, 0.0], 
actual action is [2.658333333333334, 20.0], 
sim time next is 709200.0000, 
raw observation next is [-2.3, 76.0, 4.6, 260.0, 0.0, 0.0, 2.658333333333334, 25.46028055307579, 20.0, 19.95403951250999, 21.5, 0.0, 49.87187434686825], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.76, 0.41818181818181815, 0.7222222222222222, 0.0, 0.0, 0.5443055555555555, 0.2546028055307579, 0.2857142857142857, 0.2791485017871414, 0.5, 0.0, 0.5867279334925677], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:00,328] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.54611557e-21   1.53621951e-08   1.60708646e-06   1.62113576e-08
   7.50292202e-08   2.05108132e-02   5.23682088e-02   1.70175031e-01
   7.56944299e-01], sum to 1.0000
[2017-11-02 10:02:00,785] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 76.0, 4.391666666666666, 260.0, 26.58333333333333, 0.0, 2.7, 13.73599322051593, 19.0, 21.74872697286389, 22.7, 1.0, 63.21585779654628], 
actual action is [2.7, 24.0], 
sim time next is 721800.0000, 
raw observation next is [-2.3, 76.0, 4.35, 260.0, 29.0, 0.0, 2.7, 13.54877585241202, 24.0, 21.87927117937116, 22.7, 1.0, 53.52891438063176], 
processed observation next is [0.0, 0.34782608695652173, 0.27435897435897433, 0.76, 0.39545454545454545, 0.7222222222222222, 0.07671957671957672, 0.0, 0.545, 0.1354877585241202, 0.8571428571428571, 0.5541815970530227, 0.6714285714285714, 1.0, 0.6297519338897855], 
reward next is -0.5803. 
=============================================
[2017-11-02 10:02:01,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-67.52735138]
 [-66.35111237]
 [-65.90734863]
 [-66.64792633]
 [-65.44174957]], R is [[-65.76851654]
 [-66.11083221]
 [-66.44972229]
 [-66.78522491]
 [-67.11737061]].
[2017-11-02 10:02:07,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.27232027e-01   3.61298886e-03   6.32242188e-02   1.12459296e-03
   4.80619259e-03   7.40388949e-22   1.56110196e-21   4.71696634e-21
   2.53190898e-21], sum to 1.0000
[2017-11-02 10:02:07,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.95, 71.33333333333334, 4.683333333333334, 260.0, 104.1666666666667, 50.58333333333334, 3.0, 14.006881835989, 23.0, 22.17054202486536, 22.7, 1.0, 54.43250360719684], 
actual action is [-6.95, 18.0], 
sim time next is 726000.0000, 
raw observation next is [-1.9, 70.66666666666666, 4.766666666666666, 260.0, 107.3333333333333, 52.16666666666666, -6.95, 15.29414982695886, 18.0, 22.14003555267503, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.2846153846153846, 0.7066666666666666, 0.43333333333333324, 0.7222222222222222, 0.28395061728395055, 0.05216666666666666, 0.38416666666666666, 0.15294149826958858, 0.0, 0.5914336503821472, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:09,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.92418112e-03   2.92784460e-02   8.81860137e-01   8.04665219e-03
   7.88906366e-02   4.19567394e-16   1.02746928e-15   4.29791082e-15
   2.73684159e-15], sum to 1.0000
[2017-11-02 10:02:09,540] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-2.3, 76.0, 4.1, 260.0, 65.0, 24.5, 2.7, 15.06533513101496, 25.0, 21.54240757885562, 22.7, 1.0, 66.22319348242527], 
actual action is [2.7, 24.0], 
sim time next is 723900.0000, 
raw observation next is [-2.25, 75.33333333333333, 4.183333333333333, 260.0, 71.0, 28.58333333333334, 2.7, 14.21279443881499, 24.0, 21.76716644295997, 22.7, 1.0, 63.86322594916941], 
processed observation next is [0.0, 0.391304347826087, 0.27564102564102566, 0.7533333333333333, 0.38030303030303025, 0.7222222222222222, 0.18783068783068782, 0.02858333333333334, 0.545, 0.1421279443881499, 0.8571428571428571, 0.538166634708567, 0.6714285714285714, 1.0, 0.7513320699902284], 
reward next is -0.6904. 
=============================================
[2017-11-02 10:02:17,598] A3C_AGENT_WORKER-Thread-8 INFO:Local step 2500, global step 39269: loss -15.8088
[2017-11-02 10:02:19,482] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39468: loss 24.7323
[2017-11-02 10:02:19,750] A3C_AGENT_WORKER-Thread-5 INFO:Local step 2500, global step 39497: loss -105.0350
[2017-11-02 10:02:20,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.35468804e-20   4.30391278e-10   1.92311358e-08   5.95445748e-10
   1.94679850e-09   1.83982745e-01   1.84123173e-01   2.75761306e-01
   3.56132716e-01], sum to 1.0000
[2017-11-02 10:02:20,470] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39588: loss -7.7351
[2017-11-02 10:02:20,478] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.1416666666666666, 54.08333333333333, 6.766666666666666, 250.0, 127.0833333333333, 476.5, 4.766666666666667, 14.3920746551149, 19.0, 22.29743063050103, 22.7, 1.0, 44.41688904377412], 
actual action is [4.858333333333333, 20.0], 
sim time next is 736200.0000, 
raw observation next is [-0.04999999999999999, 53.5, 6.9, 250.0, 131.0, 449.0, 4.858333333333333, 14.19785204595059, 20.0, 22.30382499994462, 22.7, 1.0, 27.53089064479656], 
processed observation next is [0.0, 0.5217391304347826, 0.33205128205128204, 0.535, 0.6272727272727273, 0.6944444444444444, 0.34656084656084657, 0.449, 0.5809722222222222, 0.1419785204595059, 0.2857142857142857, 0.6148321428492315, 0.6714285714285714, 1.0, 0.32389283111525363], 
reward next is -0.3057. 
=============================================
[2017-11-02 10:02:20,793] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.86753012e-33   5.67938362e-18   1.13458581e-15   5.82756641e-18
   8.91011626e-17   1.21257916e-01   3.74093860e-01   3.25932175e-01
   1.78716049e-01], sum to 1.0000
[2017-11-02 10:02:20,852] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.9, 55.25, 4.35, 337.5, 0.0, 0.0, 1.1, 16.96693778349751, 19.0, 22.01689652962761, 22.7, 1.0, 30.76452730267448], 
actual action is [1.1, 20.0], 
sim time next is 757200.0000, 
raw observation next is [-3.9, 55.0, 4.433333333333334, 336.6666666666667, 0.0, 0.0, 1.1, 17.29489966336142, 20.0, 21.92254674018589, 22.7, 1.0, 21.50157255291366], 
processed observation next is [0.0, 0.782608695652174, 0.23333333333333334, 0.55, 0.40303030303030307, 0.9351851851851852, 0.0, 0.0, 0.5183333333333333, 0.1729489966336142, 0.2857142857142857, 0.5603638200265557, 0.6714285714285714, 1.0, 0.2529596770931019], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:21,199] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39685: loss -72.1951
[2017-11-02 10:02:21,541] A3C_AGENT_WORKER-Thread-6 INFO:Local step 2500, global step 39724: loss -17.8138
[2017-11-02 10:02:23,462] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39910: loss -24.4788
[2017-11-02 10:02:23,697] A3C_AGENT_WORKER-Thread-4 INFO:Local step 2500, global step 39937: loss 36.6499
[2017-11-02 10:02:24,322] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40011: loss -15.0695
[2017-11-02 10:02:25,687] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40173: loss 56.1740
[2017-11-02 10:02:26,577] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40272: loss -47.4739
[2017-11-02 10:02:26,825] A3C_AGENT_WORKER-Thread-7 INFO:Local step 2500, global step 40296: loss 61.5220
[2017-11-02 10:02:26,906] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40302: loss -78.6565
[2017-11-02 10:02:26,926] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40305: loss 4.0965
[2017-11-02 10:02:27,561] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40369: loss -37.9949
[2017-11-02 10:02:30,280] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40628: loss -19.9798
[2017-11-02 10:02:54,421] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   5.37232963e-25   3.42580913e-24   3.64675487e-24
   1.43656975e-24   5.67736244e-03   3.45317600e-03   5.43588936e-01
   4.47280556e-01], sum to 1.0000
[2017-11-02 10:02:54,641] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 75.0, 2.583333333333333, 78.33333333333334, 69.66666666666666, 0.0, -11.2, 23.0368708171291, 18.0, 20.98541047604237, 22.7, 1.0, 0.0], 
actual action is [-1.2000000000000002, 23.0], 
sim time next is 813300.0000, 
raw observation next is [-6.2, 75.0, 2.541666666666667, 79.16666666666666, 71.83333333333334, 0.0, -1.2, 20.73497061830174, 23.0, 20.84640489385628, 22.7, 1.0, 91.16019885197208], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.17435897435897435, 0.75, 0.23106060606060608, 0.21990740740740738, 0.19003527336860673, 0.0, 0.48000000000000004, 0.2073497061830174, 0.7142857142857143, 0.4066292705508973, 0.6714285714285714, 1.0, 1.0724729276702598], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:55,863] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  2.77051411e-04   3.64130363e-02   2.25328341e-01   5.94676554e-01
   1.34033322e-01   1.40051910e-04   4.22880039e-05   7.11088022e-03
   1.97848049e-03], sum to 1.0000
[2017-11-02 10:02:55,900] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-4.5, 71.0, 2.041666666666667, 60.0, 100.4166666666667, 0.0, -9.5, 24.50923480691247, 18.0, 20.72578984834011, 22.7, 1.0, 0.0], 
actual action is [-9.5, 18.0], 
sim time next is 817800.0000, 
raw observation next is [-4.5, 71.0, 2.083333333333333, 60.0, 102.3333333333333, 0.0, -9.5, 26.30770642650072, 18.0, 20.67264018350776, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.18939393939393936, 0.16666666666666666, 0.2707231040564373, 0.0, 0.3416666666666667, 0.2630770642650072, 0.0, 0.3818057405011085, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:02:57,191] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  3.26225385e-02   3.97607125e-02   2.68828392e-01   4.22642559e-01
   2.36084640e-01   6.54854375e-07   1.66211009e-07   4.71901149e-05
   1.30866374e-05], sum to 1.0000
[2017-11-02 10:02:57,464] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-4.5, 71.66666666666666, 2.5, 61.66666666666666, 103.5833333333333, 0.0, 0.5, 22.49715511183218, 20.0, 20.76378483372615, 22.7, 1.0, 73.60487480705288], 
actual action is [0.5, 19.5], 
sim time next is 821400.0000, 
raw observation next is [-4.5, 72.33333333333334, 2.5, 63.33333333333333, 102.6666666666667, 0.0, 0.5, 21.89329936140065, 19.5, 20.8845286719196, 22.7, 1.0, 39.46808235499877], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.21794871794871795, 0.7233333333333334, 0.22727272727272727, 0.1759259259259259, 0.27160493827160503, 0.0, 0.5083333333333333, 0.2189329936140065, 0.21428571428571427, 0.4120755245599429, 0.6714285714285714, 1.0, 0.46433038064704435], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:07,952] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.24428135e-03   4.43357101e-04   9.65273261e-01
   3.20390239e-02], sum to 1.0000
[2017-11-02 10:03:08,159] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 71.0, 2.041666666666667, 60.0, 100.4166666666667, 0.0, 0.5, 20.29958831126208, 20.0, 21.45539260180761, 22.7, 1.0, 69.33676900593129], 
actual action is [0.5, 22.0], 
sim time next is 817800.0000, 
raw observation next is [-4.5, 71.0, 2.083333333333333, 60.0, 102.3333333333333, 0.0, 0.5, 20.20220105989178, 22.0, 21.42427029844852, 22.7, 1.0, 44.26857851461377], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.18939393939393936, 0.16666666666666666, 0.2707231040564373, 0.0, 0.5083333333333333, 0.2020220105989178, 0.5714285714285714, 0.4891814712069313, 0.6714285714285714, 1.0, 0.5208068060542796], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:16,777] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.40209417e-26   9.58637082e-17   2.78799651e-16   3.00378868e-15
   4.86479662e-16   2.07050312e-02   3.08486237e-03   5.19269288e-01
   4.56940860e-01], sum to 1.0000
[2017-11-02 10:03:17,008] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.899999999999999, 79.58333333333333, 2.591666666666666, 89.16666666666667, 72.33333333333334, 0.0, 1.1, 15.95927114362849, 25.0, 22.18992171169524, 22.7, 1.0, 54.04217389767562], 
actual action is [1.100000000000001, 25], 
sim time next is 828600.0000, 
raw observation next is [-3.9, 80.16666666666667, 2.683333333333334, 88.33333333333333, 69.66666666666666, 0.0, 1.100000000000001, 15.52590741403991, 25.0, 22.2330478391369, 22.7, 1.0, 61.93863533226075], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.23333333333333334, 0.8016666666666667, 0.243939393939394, 0.24537037037037035, 0.1843033509700176, 0.0, 0.5183333333333333, 0.1552590741403991, 1.0, 0.6047211198767002, 0.6714285714285714, 1.0, 0.7286898274383617], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:03:20,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.35535812e-02   5.31464524e-04   1.81621835e-01
   8.04293096e-01], sum to 1.0000
[2017-11-02 10:03:20,316] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 82.66666666666667, 4.016666666666667, 80.0, 42.33333333333334, 0.0, 1.1, 14.05673622864064, 25.0, 22.70391828202103, 22.7, 1.0, 54.03518592656492], 
actual action is [1.1, 25], 
sim time next is 834900.0000, 
raw observation next is [-3.9, 82.33333333333333, 4.058333333333333, 80.0, 40.66666666666667, 0.0, 1.1, 13.74940867424879, 25.0, 22.70244440815494, 22.7, 1.0, 62.89744544911186], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.23333333333333334, 0.8233333333333333, 0.3689393939393939, 0.2222222222222222, 0.10758377425044093, 0.0, 0.5183333333333333, 0.13749408674248792, 1.0, 0.6717777725935627, 0.6714285714285714, 1.0, 0.7399699464601396], 
reward next is -0.6797. 
=============================================
[2017-11-02 10:03:23,605] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.19261344e-02   5.62050554e-04   3.55940759e-01
   6.01571023e-01], sum to 1.0000
[2017-11-02 10:03:23,861] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.483333333333333, 83.5, 3.6, 68.33333333333333, 0.0, 0.0, 1.475, 12.54693256424457, 25.0, 22.99705041008853, 22.7, 1.0, 61.09607865431297], 
actual action is [1.516666666666667, 25], 
sim time next is 849300.0000, 
raw observation next is [-3.441666666666666, 83.25, 3.6, 69.16666666666666, 0.0, 0.0, 1.516666666666667, 12.43404301692511, 25.0, 23.03478809769961, 22.7, 1.0, 61.04964095283258], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.2450854700854701, 0.8325, 0.32727272727272727, 0.1921296296296296, 0.0, 0.0, 0.5252777777777777, 0.12434043016925109, 1.0, 0.7192554425285158, 0.6714285714285714, 1.0, 0.7182310700333245], 
reward next is -0.6588. 
=============================================
[2017-11-02 10:03:28,247] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   2.37515286e-28   1.19411576e-27   4.53164575e-27
   1.55989396e-27   2.83862725e-02   1.10489572e-03   4.52517569e-01
   5.17991304e-01], sum to 1.0000
[2017-11-02 10:03:28,355] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 80.0, 1.75, 60.0, 0.0, 0.0, 2.7, 9.934157662536316, 25.0, 23.01038922265673, 21.5, 0.0, 42.54314720930232], 
actual action is [2.7, 25], 
sim time next is 865200.0000, 
raw observation next is [-2.3, 80.0, 1.833333333333333, 60.00000000000001, 0.0, 0.0, 2.7, 9.89338429559123, 25.0, 23.00938905914995, 21.5, 0.0, 42.57721619841639], 
processed observation next is [0.3333333333333333, 0.0, 0.27435897435897433, 0.8, 0.16666666666666663, 0.16666666666666669, 0.0, 0.0, 0.545, 0.0989338429559123, 1.0, 0.7156270084499928, 0.5, 0.0, 0.5009084258637222], 
reward next is -0.4508. 
=============================================
[2017-11-02 10:03:32,905] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.02305677e-34   3.45478446e-23   2.36437744e-22   7.56736419e-22
   2.41956085e-22   4.52279560e-02   1.66827242e-03   5.65434396e-01
   3.87669384e-01], sum to 1.0000
[2017-11-02 10:03:33,116] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.9, 82.33333333333333, 4.008333333333333, 60.83333333333334, 0.0, 0.0, 1.1, 10.54487062721634, 25.0, 23.61717631048806, 22.7, 1.0, 60.66482910385249], 
actual action is [1.1, 25], 
sim time next is 842400.0000, 
raw observation next is [-3.9, 82.0, 4.1, 60.0, 0.0, 0.0, 1.1, 10.51082871773744, 25.0, 23.62544298935807, 22.7, 1.0, 60.73549985983697], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.23333333333333334, 0.82, 0.3727272727272727, 0.16666666666666666, 0.0, 0.0, 0.5183333333333333, 0.10510828717737439, 1.0, 0.8036347127654386, 0.6714285714285714, 1.0, 0.7145352924686702], 
reward next is -0.6536. 
=============================================
[2017-11-02 10:03:50,664] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 46948: loss -1.9222
[2017-11-02 10:03:52,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.83293545
  0.00087845  0.1535987   0.01258739], sum to 1.0000
[2017-11-02 10:03:52,764] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.575, 78.25, 2.5, 60.0, 0.0, 0.0, 3.383333333333333, 7.43480259976026, 25.0, 23.26477502428266, 21.5, 0.0, 42.86298531051641], 
actual action is [3.425, 25], 
sim time next is 876000.0000, 
raw observation next is [-1.533333333333333, 78.0, 2.5, 60.00000000000001, 0.0, 0.0, 3.425, 7.420839006966644, 25.0, 23.25805727261642, 21.5, 0.0, 42.85062819145793], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.294017094017094, 0.78, 0.22727272727272727, 0.16666666666666669, 0.0, 0.0, 0.5570833333333333, 0.07420839006966644, 1.0, 0.7511510389452027, 0.5, 0.0, 0.5041250375465639], 
reward next is -0.4537. 
=============================================
[2017-11-02 10:03:53,472] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3000, global step 47143: loss -2.8558
[2017-11-02 10:03:55,730] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-51.04373932]
 [-50.89429855]
 [-50.70888138]
 [-50.80519867]
 [-51.2817421 ]], R is [[-50.82506943]
 [-50.77002716]
 [-50.71562195]
 [-50.66184998]
 [-50.60871124]].
[2017-11-02 10:03:57,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.70814962e-15   1.84360925e-12   5.57058002e-12   1.76687224e-11
   7.39785750e-12   6.27844393e-01   6.65816944e-03   2.82491177e-01
   8.30062479e-02], sum to 1.0000
[2017-11-02 10:03:57,395] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.45, 77.5, 2.5, 60.0, 0.0, 0.0, 3.508333333333334, 7.320610424820642, 25.0, 23.26962520385971, 21.5, 0.0, 42.81760879637938], 
actual action is [3.55, 25], 
sim time next is 876900.0000, 
raw observation next is [-1.408333333333333, 77.25, 2.5, 60.0, 0.0, 0.0, 3.55, 7.306501825816238, 25.0, 23.26371063583948, 21.5, 0.0, 42.80928732894533], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.2972222222222222, 0.7725, 0.22727272727272727, 0.16666666666666666, 0.0, 0.0, 0.5591666666666666, 0.07306501825816239, 1.0, 0.7519586622627829, 0.5, 0.0, 0.5036386744581803], 
reward next is -0.4533. 
=============================================
[2017-11-02 10:04:00,751] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47595: loss 1.8932
[2017-11-02 10:04:01,061] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3000, global step 47615: loss 1.1600
[2017-11-02 10:04:01,079] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47615: loss -2.4408
[2017-11-02 10:04:03,582] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3000, global step 47766: loss 0.0836
[2017-11-02 10:04:05,460] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3000, global step 47884: loss -0.0473
[2017-11-02 10:04:08,918] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48114: loss 0.5620
[2017-11-02 10:04:09,614] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48159: loss 0.0148
[2017-11-02 10:04:10,589] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48231: loss 0.0953
[2017-11-02 10:04:15,464] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48583: loss 0.3333
[2017-11-02 10:04:16,885] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3000, global step 48697: loss 0.0787
[2017-11-02 10:04:19,404] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48900: loss 0.0302
[2017-11-02 10:04:20,022] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48957: loss 0.6423
[2017-11-02 10:04:20,671] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 49020: loss 1.3003
[2017-11-02 10:04:22,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.83742476e-01   5.89850417e-04   9.13881883e-03
   6.52882829e-03], sum to 1.0000
[2017-11-02 10:04:22,761] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [4.5, 92.83333333333333, 3.683333333333333, 150.0, 30.0, 0.0, 9.45, 6.72132897078396, 25.0, 24.31914537342085, 22.7, 1.0, 39.99050763419502], 
actual action is [9.5, 25], 
sim time next is 922500.0000, 
raw observation next is [4.550000000000001, 92.75, 3.725, 150.0, 27.0, 0.0, 9.5, 6.719127050372341, 25.0, 24.31596581386489, 22.7, 1.0, 39.94651130026632], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.45, 0.9275, 0.3386363636363636, 0.4166666666666667, 0.07142857142857142, 0.0, 0.6583333333333333, 0.06719127050372341, 1.0, 0.9022808305521269, 0.6714285714285714, 1.0, 0.46995895647372143], 
reward next is -0.4297. 
=============================================
[2017-11-02 10:04:23,129] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 49241: loss 0.0557
[2017-11-02 10:04:33,858] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-29.97206306]
 [-30.23311424]
 [-30.11425972]
 [-29.80710411]
 [-30.24709129]], R is [[-30.72011185]
 [-30.64230537]
 [-30.55904198]
 [-30.47029305]
 [-30.38780212]].
[2017-11-02 10:04:33,961] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.44953004e-38   5.56068750e-38   9.90271729e-38
   4.66630595e-38   9.95938897e-01   4.19746793e-04   3.22291907e-03
   4.18493320e-04], sum to 1.0000
[2017-11-02 10:04:34,078] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [5.416666666666667, 90.16666666666667, 4.933333333333334, 153.3333333333333, 0.0, 0.0, 10.375, 5.806242957364423, 25.0, 24.21546681566614, 21.5, 0.0, 26.4292158277752], 
actual action is [10.416666666666668, 25], 
sim time next is 953700.0000, 
raw observation next is [5.458333333333333, 89.58333333333333, 5.016666666666667, 156.6666666666667, 0.0, 0.0, 10.41666666666667, 5.798859231095481, 25.0, 24.18607534839191, 21.5, 0.0, 25.23386047857811], 
processed observation next is [0.5, 0.0, 0.4732905982905983, 0.8958333333333333, 0.45606060606060606, 0.43518518518518534, 0.0, 0.0, 0.6736111111111112, 0.05798859231095481, 1.0, 0.8837250497702728, 0.5, 0.0, 0.29686894680680126], 
reward next is -0.2672. 
=============================================
[2017-11-02 10:04:40,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.08820676e-28   7.86953139e-21   1.86353275e-20   3.53086407e-20
   1.82609491e-20   9.49328780e-01   1.05097853e-02   3.47284116e-02
   5.43297129e-03], sum to 1.0000
[2017-11-02 10:04:40,773] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [5.0, 97.66666666666666, 4.516666666666666, 120.0, 0.0, 0.0, 10.0, 6.697301516323135, 25.0, 24.40212833027561, 21.5, 0.0, 30.01020511167724], 
actual action is [10.0, 25], 
sim time next is 942000.0000, 
raw observation next is [5.0, 97.33333333333334, 4.433333333333334, 120.0, 0.0, 0.0, 10.0, 6.684379457933986, 25.0, 24.45138666805604, 21.5, 0.0, 28.56309071105398], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.46153846153846156, 0.9733333333333334, 0.40303030303030307, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.06684379457933985, 1.0, 0.9216266668651484, 0.5, 0.0, 0.33603636130651743], 
reward next is -0.3024. 
=============================================
[2017-11-02 10:04:47,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.89484847e-01   1.23453152e-03   1.96196861e-03   3.18390899e-03
   2.15204083e-03   1.53101666e-03   2.24639705e-04   1.73651701e-04
   5.34821338e-05], sum to 1.0000
[2017-11-02 10:04:47,279] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.458333333333333, 89.58333333333333, 5.016666666666667, 156.6666666666667, 0.0, 0.0, 0.416666666666667, 8.773446615506263, 18.0, 23.05669815097734, 21.5, 0.0, 0.0], 
actual action is [0.45833333333333304, 18], 
sim time next is 954000.0000, 
raw observation next is [5.5, 89.0, 5.1, 160.0, 0.0, 0.0, 0.458333333333333, 9.144173633368837, 18.0, 22.91858322343597, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.47435897435897434, 0.89, 0.4636363636363636, 0.4444444444444444, 0.0, 0.0, 0.5076388888888889, 0.09144173633368836, 0.0, 0.7026547462051386, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:04:56,453] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [ 0.29501525  0.08374308  0.14924034  0.11906742  0.11837902  0.10468175
  0.05115793  0.05087496  0.0278402 ], sum to 1.0000
[2017-11-02 10:04:56,489] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.40833333333333, 86.0, 6.266666666666666, 201.6666666666667, 127.3333333333333, 0.0, 7.366666666666671, 16.54741103081171, 18.0, 20.7842890605369, 22.7, 1.0, 0.0], 
actual action is [7.40833333333333, 18], 
sim time next is 995400.0000, 
raw observation next is [12.45, 86.0, 6.4, 200.0, 128.0, 0.0, 7.40833333333333, 16.55467050562906, 18.0, 20.78621902867653, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.6525641025641026, 0.86, 0.5818181818181819, 0.5555555555555556, 0.3386243386243386, 0.0, 0.6234722222222222, 0.16554670505629057, 0.0, 0.39803128981093294, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:05:00,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  7.46844947e-01   3.78888324e-02   6.48545623e-02   5.66907190e-02
   8.62546116e-02   3.95959569e-03   1.48450036e-03   1.39179535e-03
   6.30411552e-04], sum to 1.0000
[2017-11-02 10:05:00,174] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 5.183333333333334, 210.0, 0.0, 0.0, 9.4, 9.737804989546001, 18.0, 22.85511411581488, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1048500.0000, 
raw observation next is [14.4, 77.0, 5.225, 210.0, 0.0, 0.0, 9.4, 9.749644567180273, 18.0, 22.85403231813427, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.7025641025641025, 0.77, 0.475, 0.5833333333333334, 0.0, 0.0, 0.6566666666666666, 0.09749644567180273, 0.0, 0.6934331883048956, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:00,912] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 54128: loss 0.2005
[2017-11-02 10:05:02,133] A3C_AGENT_WORKER-Thread-8 INFO:Local step 3500, global step 54356: loss 0.3266
[2017-11-02 10:05:02,673] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  7.95047343e-01   3.13022807e-02   5.51118515e-02   6.06033839e-02
   5.70951626e-02   4.26082202e-04   1.74301691e-04   1.73701657e-04
   6.59045618e-05], sum to 1.0000
[2017-11-02 10:05:02,695] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.5, 75.5, 7.016666666666667, 206.6666666666667, 35.66666666666666, 0.0, 10.5, 14.17085407669858, 18.0, 21.26975453670589, 22.7, 1.0, 0.0], 
actual action is [10.5, 18], 
sim time next is 1008900.0000, 
raw observation next is [15.5, 75.75, 6.925000000000001, 205.0, 33.0, 0.0, 10.5, 14.27374303241703, 18.0, 21.25636162214243, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.7307692307692307, 0.7575, 0.6295454545454546, 0.5694444444444444, 0.0873015873015873, 0.0, 0.675, 0.1427374303241703, 0.0, 0.4651945174489183, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0143. 
=============================================
[2017-11-02 10:05:04,735] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 54805: loss 1.9150
[2017-11-02 10:05:06,031] A3C_AGENT_WORKER-Thread-6 INFO:Local step 3500, global step 55066: loss -5.0668
[2017-11-02 10:05:06,546] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55182: loss 0.8124
[2017-11-02 10:05:06,625] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.83307242e-01   3.02919932e-03   4.47004009e-03   5.94329555e-03
   3.25015397e-03   5.15192156e-09   3.77659548e-09   1.98363792e-09
   4.69676686e-10], sum to 1.0000
[2017-11-02 10:05:06,648] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.65833333333333, 81.75, 3.891666666666667, 192.5, 0.0, 0.0, 7.75, 11.94607157539302, 18.0, 21.98182338201327, 21.5, 0.0, 0.0], 
actual action is [7.65833333333333, 18], 
sim time next is 1064400.0000, 
raw observation next is [12.56666666666667, 82.0, 3.933333333333333, 190.0, 0.0, 0.0, 7.65833333333333, 12.00772262766787, 18.0, 21.96839744926204, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.6555555555555557, 0.82, 0.35757575757575755, 0.5277777777777778, 0.0, 0.0, 0.6276388888888889, 0.1200772262766787, 0.0, 0.5669139213231483, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:06,912] A3C_AGENT_WORKER-Thread-5 INFO:Local step 3500, global step 55245: loss -55.1951
[2017-11-02 10:05:07,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-7.59549046]
 [-8.30506325]
 [-7.24756718]
 [-7.42828941]
 [-7.16037655]], R is [[-7.92598772]
 [-7.85814238]
 [-7.79081583]
 [-7.99645805]
 [-8.51396656]].
[2017-11-02 10:05:07,806] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.90970850e-01   2.00835289e-03   2.50466587e-03   2.94123730e-03
   1.57478743e-03   1.34042777e-08   6.58486421e-09   4.92687091e-09
   1.23788246e-09], sum to 1.0000
[2017-11-02 10:05:07,821] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.225, 180.0, 0.0, 0.0, 19.4, 12.28668763589601, 18.5, 21.22995689644403, 21.5, 0.0, 27.62993833311272], 
actual action is [9.4, 18], 
sim time next is 1033200.0000, 
raw observation next is [14.4, 75.0, 4.1, 180.0, 0.0, 0.0, 9.4, 12.48578317187626, 18.0, 21.24982312459501, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5, 0.0, 0.0, 0.6566666666666666, 0.12485783171876261, 0.0, 0.46426044637071584, 0.5, 0.0, 0.0], 
reward next is -0.0357. 
=============================================
[2017-11-02 10:05:09,092] A3C_AGENT_WORKER-Thread-4 INFO:Local step 3500, global step 55668: loss -35.9994
[2017-11-02 10:05:10,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55942: loss -5.8596
[2017-11-02 10:05:12,107] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56259: loss -142.4538
[2017-11-02 10:05:12,735] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56403: loss -106.9921
[2017-11-02 10:05:13,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.76869166e-01   4.75974940e-03   8.78409110e-03   7.91943353e-03
   1.66759442e-03   4.14443523e-12   2.39346000e-12   2.10170813e-12
   4.91670073e-13], sum to 1.0000
[2017-11-02 10:05:13,253] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.1, 185.8333333333333, 0.0, 0.0, 9.4, 10.89071158916104, 18.0, 22.54688018456707, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1035600.0000, 
raw observation next is [14.4, 75.0, 4.1, 186.6666666666667, 0.0, 0.0, 9.4, 11.04842239193426, 18.0, 22.52906442670126, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5185185185185186, 0.0, 0.0, 0.6566666666666666, 0.1104842239193426, 0.0, 0.6470092038144658, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:13,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.67359155e-01   1.37159690e-01   1.86570436e-01   1.48719683e-01
   5.78471161e-02   8.29993805e-04   6.66298263e-04   6.16667327e-04
   2.31012629e-04], sum to 1.0000
[2017-11-02 10:05:13,337] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.98333333333333, 49.83333333333334, 3.0, 186.6666666666667, 23.66666666666667, 0.9999999999999998, 13.125, 7.617163996444309, 18.0, 24.11134639113112, 22.7, 1.0, 0.0], 
actual action is [12.98333333333333, 18], 
sim time next is 1097700.0000, 
raw observation next is [17.84166666666667, 49.91666666666666, 3.0, 188.3333333333333, 20.83333333333334, 1.25, 12.98333333333333, 7.62555674323665, 18.0, 24.09274206267125, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.7908119658119659, 0.4991666666666666, 0.2727272727272727, 0.523148148148148, 0.0551146384479718, 0.00125, 0.7163888888888889, 0.0762555674323665, 0.0, 0.8703917232387498, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0076. 
=============================================
[2017-11-02 10:05:14,163] A3C_AGENT_WORKER-Thread-7 INFO:Local step 3500, global step 56680: loss -4.0450
[2017-11-02 10:05:14,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.82253492e-01   2.70517217e-03   8.05252604e-03   6.19484717e-03
   7.93933112e-04   6.23098198e-13   1.98356536e-13   3.15982890e-13
   5.29230014e-14], sum to 1.0000
[2017-11-02 10:05:14,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 77.0, 5.141666666666667, 210.0, 0.0, 0.0, 9.4, 11.54703823691087, 18.0, 21.97398569202984, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1048200.0000, 
raw observation next is [14.4, 77.0, 5.183333333333334, 210.0, 0.0, 0.0, 9.4, 11.79745928953115, 18.0, 21.97295424043522, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.7025641025641025, 0.77, 0.47121212121212125, 0.5833333333333334, 0.0, 0.0, 0.6566666666666666, 0.1179745928953115, 0.0, 0.567564891490746, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:05:15,060] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56837: loss 4.0941
[2017-11-02 10:05:15,243] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.40007641e-02   1.97725177e-01   4.35391545e-01   3.17917705e-01
   3.47454101e-02   8.39711356e-05   3.38508762e-05   9.67889209e-05
   4.73371438e-06], sum to 1.0000
[2017-11-02 10:05:15,283] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [14.05, 77.58333333333333, 4.725, 204.1666666666667, 0.0, 0.0, 19.1, 12.34416935861967, 20.5, 21.05083450964982, 21.5, 0.0, 13.8846457870114], 
actual action is [19.05, 20.0], 
sim time next is 1053600.0000, 
raw observation next is [14.0, 77.66666666666667, 4.6, 203.3333333333333, 0.0, 0.0, 19.05, 12.22464442730912, 20.0, 21.10201219910495, 21.5, 0.0, 12.63340225301782], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.6923076923076923, 0.7766666666666667, 0.41818181818181815, 0.5648148148148147, 0.0, 0.0, 0.8175, 0.1222464442730912, 0.2857142857142857, 0.4431445998721359, 0.5, 0.0, 0.14862826180020966], 
reward next is -0.1906. 
=============================================
[2017-11-02 10:05:17,096] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 57195: loss 1.1622
[2017-11-02 10:05:17,798] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 57316: loss 13.9201
[2017-11-02 10:05:18,635] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 57463: loss 2.4500
[2017-11-02 10:05:19,745] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 57648: loss 26.5772
[2017-11-02 10:05:24,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.38348186e-01   1.03201173e-01   8.49214122e-02   4.23268639e-02
   2.67335363e-02   1.97356124e-03   1.42033212e-03   8.27796408e-04
   2.47167191e-04], sum to 1.0000
[2017-11-02 10:05:24,826] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [19.25, 50.25, 4.574999999999999, 177.5, 128.0, 0.0, 14.2, 8.943185619707814, 18.0, 22.446869264253, 22.7, 1.0, 0.0], 
actual action is [14.25, 18], 
sim time next is 1090200.0000, 
raw observation next is [19.3, 49.83333333333334, 4.75, 178.3333333333333, 124.0, 0.0, 14.25, 8.945914668686703, 18.0, 22.44364877437902, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.8282051282051281, 0.4983333333333334, 0.4318181818181818, 0.49537037037037024, 0.328042328042328, 0.0, 0.7375, 0.08945914668686702, 0.0, 0.6348069677684316, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0089. 
=============================================
[2017-11-02 10:05:38,151] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-5.13791227]
 [-5.20321655]
 [-5.21851683]
 [-5.4217062 ]
 [-5.40038872]], R is [[-5.28682804]
 [-5.24785566]
 [-5.20918894]
 [-5.17082357]
 [-5.13275766]].
[2017-11-02 10:05:44,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 61884: loss 0.1223
[2017-11-02 10:05:48,052] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4000, global step 62539: loss 0.2611
[2017-11-02 10:05:48,254] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 62571: loss 0.2574
[2017-11-02 10:05:49,002] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4000, global step 62730: loss 0.4852
[2017-11-02 10:05:50,778] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.32163596e-01   4.28525805e-02   1.55471973e-02   7.50953518e-03
   1.92672538e-03   1.21039363e-07   2.05110965e-07   4.54262228e-08
   8.74614781e-09], sum to 1.0000
[2017-11-02 10:05:50,779] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63164: loss 0.4530
[2017-11-02 10:05:50,784] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [16.1, 79.33333333333333, 6.8, 130.0, 0.0, 0.0, 11.1, 10.66473568419419, 18.0, 21.88510440065297, 22.7, 1.0, 0.0], 
actual action is [11.100000000000001, 18], 
sim time next is 1212300.0000, 
raw observation next is [16.1, 79.5, 6.749999999999999, 130.0, 0.0, 0.0, 11.1, 10.67507417087126, 18.0, 21.87954401118588, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.0, 0.7461538461538462, 0.795, 0.6136363636363635, 0.3611111111111111, 0.0, 0.0, 0.685, 0.10675074170871261, 0.0, 0.5542205730265545, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:05:51,161] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4000, global step 63269: loss 1.6247
[2017-11-02 10:05:53,113] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63793: loss -0.0907
[2017-11-02 10:05:53,973] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4000, global step 63994: loss -1.3795
[2017-11-02 10:05:55,202] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64292: loss -0.3013
[2017-11-02 10:05:57,195] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4000, global step 64739: loss 1.0487
[2017-11-02 10:05:58,270] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64978: loss -0.0321
[2017-11-02 10:05:58,614] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 65065: loss -0.2031
[2017-11-02 10:05:59,225] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.76363242e-01   2.73041546e-01   1.26143783e-01   7.78270736e-02
   4.42654341e-02   9.06584493e-04   9.43698979e-04   3.82098428e-04
   1.26562940e-04], sum to 1.0000
[2017-11-02 10:05:59,270] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [16.6, 75.0, 8.325, 125.0, 0.0, 0.0, 11.6, 11.74326757324387, 18.0, 21.55496432891425, 22.7, 1.0, 0.0], 
actual action is [11.600000000000001, 18], 
sim time next is 1203600.0000, 
raw observation next is [16.6, 75.0, 8.2, 126.6666666666667, 0.0, 0.0, 11.6, 11.77316995317998, 18.0, 21.54570025213058, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.758974358974359, 0.75, 0.7454545454545454, 0.35185185185185197, 0.0, 0.0, 0.6933333333333334, 0.11773169953179981, 0.0, 0.5065286074472256, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0118. 
=============================================
[2017-11-02 10:05:59,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 65299: loss 0.2237
[2017-11-02 10:06:00,008] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 65301: loss -0.3805
[2017-11-02 10:06:00,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.34722099  0.26557034  0.1681833   0.11097299  0.07434249  0.01305946
  0.01230882  0.00602131  0.00232023], sum to 1.0000
[2017-11-02 10:06:00,232] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [14.4, 97.33333333333334, 3.933333333333334, 330.0, 96.0, 0.0, 9.4, 11.27480962003733, 18.0, 21.54672914601891, 22.7, 1.0, 0.0], 
actual action is [9.4, 18.0], 
sim time next is 1251900.0000, 
raw observation next is [14.4, 97.0, 3.85, 332.5, 96.5, 0.0, 9.4, 11.28987055158501, 18.0, 21.54334112864036, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.7025641025641025, 0.97, 0.35000000000000003, 0.9236111111111112, 0.2552910052910053, 0.0, 0.6566666666666666, 0.11289870551585009, 0.0, 0.5061915898057657, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0113. 
=============================================
[2017-11-02 10:06:00,878] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 65471: loss 1.3251
[2017-11-02 10:06:01,236] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 65544: loss -0.8281
[2017-11-02 10:06:21,257] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.66788593e-01   7.98428237e-01   2.03278270e-02   1.43076517e-02
   1.47713872e-04   4.32862326e-25   6.35271738e-24   2.41992648e-25
   1.38005324e-25], sum to 1.0000
[2017-11-02 10:06:21,266] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [5.5, 100.0, 6.991666666666666, 287.5, 0.0, 0.0, 0.5, 15.82048319109178, 18.0, 21.03403020660399, 21.5, 0.0, 0.0], 
actual action is [0.5, 18], 
sim time next is 1291200.0000, 
raw observation next is [5.5, 100.0, 7.333333333333332, 280.0, 0.0, 0.0, 0.5, 16.29728541516962, 18.0, 20.98086429845047, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.47435897435897434, 1.0, 0.6666666666666665, 0.7777777777777778, 0.0, 0.0, 0.5083333333333333, 0.16297285415169618, 0.0, 0.4258377569214957, 0.5, 0.0, 0.0], 
reward next is -0.0742. 
=============================================
[2017-11-02 10:06:22,847] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.35522805e-15   4.39473212e-01   4.14122753e-02   1.08297747e-02
   2.26382515e-04   2.06128545e-02   4.69719470e-01   8.65112897e-03
   9.07488633e-03], sum to 1.0000
[2017-11-02 10:06:22,946] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [2.1, 92.0, 6.1, 251.6666666666667, 0.0, 0.0, 7.15, 15.59509855497787, 21.0, 20.59512054868945, 21.5, 0.0, 21.05681014945818], 
actual action is [7.1, 19.0], 
sim time next is 1311300.0000, 
raw observation next is [2.05, 92.0, 6.1, 252.5, 0.0, 0.0, 7.1, 15.70718558226544, 19.0, 20.58680981583733, 21.5, 0.0, 19.40100816285095], 
processed observation next is [0.0, 0.17391304347826086, 0.3858974358974359, 0.92, 0.5545454545454546, 0.7013888888888888, 0.0, 0.0, 0.6183333333333334, 0.1570718558226544, 0.14285714285714285, 0.369544259405333, 0.5, 0.0, 0.22824715485707], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:06:26,932] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  4.20586502e-15   2.00968096e-03   6.83029473e-04   1.57597839e-04
   1.34780439e-05   1.69758588e-01   5.38077593e-01   5.03400601e-02
   2.38960013e-01], sum to 1.0000
[2017-11-02 10:06:26,962] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.1, 92.0, 5.933333333333334, 273.3333333333334, 115.3333333333333, 0.0, 6.1, 13.00616285593244, 19.0, 22.08014701569538, 22.7, 1.0, 12.21006806186959], 
actual action is [6.1, 20.0], 
sim time next is 1340700.0000, 
raw observation next is [1.1, 92.0, 5.766666666666666, 274.1666666666666, 114.1666666666667, 0.0, 6.1, 13.24237619599672, 20.0, 22.01026317133782, 22.7, 1.0, 11.58871062757622], 
processed observation next is [0.0, 0.5217391304347826, 0.36153846153846153, 0.92, 0.5242424242424242, 0.7615740740740738, 0.30202821869488544, 0.0, 0.6016666666666667, 0.1324237619599672, 0.2857142857142857, 0.5728947387625455, 0.6714285714285714, 1.0, 0.136337772089132], 
reward next is -0.1359. 
=============================================
[2017-11-02 10:06:31,625] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 70193: loss 78.4387
[2017-11-02 10:06:36,140] A3C_AGENT_WORKER-Thread-8 INFO:Local step 4500, global step 70820: loss -27.7244
[2017-11-02 10:06:37,223] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 70967: loss 184.9178
[2017-11-02 10:06:39,483] A3C_AGENT_WORKER-Thread-5 INFO:Local step 4500, global step 71312: loss 1.8601
[2017-11-02 10:06:39,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71331: loss -3.7140
[2017-11-02 10:06:39,987] A3C_AGENT_WORKER-Thread-6 INFO:Local step 4500, global step 71368: loss 27.2824
[2017-11-02 10:06:41,933] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.58454263e-01   3.81062508e-01   2.82198131e-01   7.32996985e-02
   4.98536741e-03   4.45943279e-20   2.04397699e-19   4.16034245e-21
   2.16250377e-20], sum to 1.0000
[2017-11-02 10:06:42,020] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 6.433333333333334, 298.3333333333333, 0.0, 0.0, 5.5, 9.490769864090149, 20.0, 21.93643259142665, 22.7, 1.0, 51.77537784672005], 
actual action is [-4.5, 18], 
sim time next is 1365300.0000, 
raw observation next is [0.5, 96.0, 6.35, 297.5, 0.0, 0.0, -4.5, 10.31537042506316, 18.0, 22.15216779162984, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.34615384615384615, 0.96, 0.5772727272727273, 0.8263888888888888, 0.0, 0.0, 0.425, 0.1031537042506316, 0.0, 0.5931668273756914, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0103. 
=============================================
[2017-11-02 10:06:42,139] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71664: loss 19.7060
[2017-11-02 10:06:43,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71861: loss -50.2697
[2017-11-02 10:06:46,337] A3C_AGENT_WORKER-Thread-4 INFO:Local step 4500, global step 72239: loss -26.7788
[2017-11-02 10:06:49,759] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72613: loss 77.6487
[2017-11-02 10:06:50,141] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72657: loss 50.2956
[2017-11-02 10:06:51,278] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72808: loss -17.3970
[2017-11-02 10:06:51,448] A3C_AGENT_WORKER-Thread-7 INFO:Local step 4500, global step 72835: loss 3.5689
[2017-11-02 10:06:51,818] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72875: loss 10.0734
[2017-11-02 10:06:51,873] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72879: loss -9.6450
[2017-11-02 10:06:52,888] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.44760977e-05   3.41622680e-01   5.90613425e-01   5.87505437e-02
   8.91886372e-03   3.69294179e-12   2.76208084e-11   2.94661702e-13
   5.29280179e-12], sum to 1.0000
[2017-11-02 10:06:52,954] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [1.1, 92.66666666666667, 6.466666666666667, 290.0, 39.66666666666667, 0.0, -3.9, 10.2833184456401, 18.0, 22.57869416654244, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1352700.0000, 
raw observation next is [1.1, 92.75, 6.374999999999999, 290.0, 37.5, 0.0, -3.9, 10.65436224362834, 18.0, 22.6409301003651, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.36153846153846153, 0.9275, 0.5795454545454545, 0.8055555555555556, 0.0992063492063492, 0.0, 0.435, 0.1065436224362834, 0.0, 0.6629900143378714, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:06:53,515] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 73057: loss 16.8124
[2017-11-02 10:06:56,382] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  4.03997861e-03   2.99281508e-01   6.49396122e-01   4.13097739e-02
   5.97270625e-03   9.20407812e-16   2.53892451e-15   2.99105598e-17
   6.17630908e-16], sum to 1.0000
[2017-11-02 10:06:56,496] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.35, 97.91666666666666, 2.875, 258.3333333333333, 0.0, 0.0, 4.7, 10.57418964500963, 23.0, 22.07860631183017, 21.5, 0.0, 62.63203812915793], 
actual action is [4.65, 22.0], 
sim time next is 1395600.0000, 
raw observation next is [-0.4, 98.33333333333333, 2.7, 266.6666666666667, 0.0, 0.0, 4.65, 10.46024017125626, 22.0, 21.96201518014223, 21.5, 0.0, 34.77026808022548], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.3230769230769231, 0.9833333333333333, 0.24545454545454548, 0.7407407407407408, 0.0, 0.0, 0.5775, 0.10460240171256259, 0.5714285714285714, 0.5660021685917472, 0.5, 0.0, 0.4090619774144174], 
reward next is -0.3682. 
=============================================
[2017-11-02 10:06:57,444] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99750316e-01   8.13273364e-05   1.51185552e-04   1.55405542e-05
   1.58321313e-06   6.71385679e-29   2.01039088e-28   2.43004794e-30
   5.64742664e-29], sum to 1.0000
[2017-11-02 10:06:57,538] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 5.683333333333333, 281.6666666666666, 0.0, 0.0, -4.5, 11.76359624645229, 18.0, 22.82617909451553, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 1361400.0000, 
raw observation next is [0.5, 96.0, 5.766666666666667, 283.3333333333334, 0.0, 0.0, -4.5, 13.11878897017948, 18.0, 22.50486796744199, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.34615384615384615, 0.96, 0.5242424242424243, 0.7870370370370373, 0.0, 0.0, 0.425, 0.1311878897017948, 0.0, 0.643552566777427, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0131. 
=============================================
[2017-11-02 10:06:58,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99713004e-01   1.03926526e-04   1.57567265e-04   2.22491199e-05
   3.21803100e-06   3.46240171e-28   6.03659582e-28   1.11925449e-29
   2.16671572e-28], sum to 1.0000
[2017-11-02 10:06:58,419] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 100.0, 2.5, 360.0, 9.0, 0.0, -5.6, 15.72117380217466, 18.0, 21.52914038105036, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1411500.0000, 
raw observation next is [-0.6, 99.99999999999999, 2.458333333333333, 331.6666666666667, 10.5, 0.0, -5.6, 16.18538512040792, 18.0, 21.38217238537975, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 0.9999999999999999, 0.22348484848484845, 0.9212962962962964, 0.027777777777777776, 0.0, 0.4066666666666666, 0.1618538512040792, 0.0, 0.4831674836256786, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:10,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.50274829e-35   4.11928864e-35   2.04594127e-37
   2.60071690e-37   4.50793445e-01   5.05111277e-01   5.64838992e-03
   3.84469070e-02], sum to 1.0000
[2017-11-02 10:07:10,197] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.3, 97.5, 3.05, 250.0, 0.0, 0.0, 4.75, 15.47079987462473, 18.5, 21.09560083957181, 21.5, 0.0, 59.23644793399168], 
actual action is [4.7, 19.5], 
sim time next is 1395300.0000, 
raw observation next is [-0.35, 97.91666666666666, 2.875, 258.3333333333333, 0.0, 0.0, 4.7, 15.18421301004311, 19.5, 21.01591816174631, 21.5, 0.0, 32.74285031756096], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.3243589743589744, 0.9791666666666665, 0.26136363636363635, 0.7175925925925926, 0.0, 0.0, 0.5783333333333334, 0.1518421301004311, 0.21428571428571427, 0.4308454516780443, 0.5, 0.0, 0.3852100037360113], 
reward next is -0.4158. 
=============================================
[2017-11-02 10:07:12,780] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.96046233e-02   1.36282548e-01   8.31095040e-01   1.10274432e-02
   1.99030875e-03   8.87651332e-22   2.73499293e-21   3.00721571e-23
   3.21221207e-22], sum to 1.0000
[2017-11-02 10:07:12,923] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.6, 100.0, 3.325, 345.0, 0.0, 0.0, -5.6, 11.31951987783393, 18.0, 22.09403036588319, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1408800.0000, 
raw observation next is [-0.6, 100.0, 3.233333333333333, 346.6666666666667, 0.0, 0.0, -5.6, 12.63216128532892, 18.0, 22.10497540740156, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.317948717948718, 1.0, 0.2939393939393939, 0.962962962962963, 0.0, 0.0, 0.4066666666666666, 0.1263216128532892, 0.0, 0.586425058200223, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0126. 
=============================================
[2017-11-02 10:07:17,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.99994993e-01   1.36194490e-06   3.48124604e-06   2.08593491e-07
   1.72083059e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:17,094] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 99.99999999999999, 3.508333333333333, 341.6666666666666, 0.0, 0.0, -5.6, 14.63190371187814, 18.0, 21.10547175278196, 21.5, 0.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1408200.0000, 
raw observation next is [-0.6, 100.0, 3.416666666666667, 343.3333333333334, 0.0, 0.0, -5.6, 16.19805421283907, 18.0, 21.07395269828924, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.317948717948718, 1.0, 0.3106060606060606, 0.9537037037037039, 0.0, 0.0, 0.4066666666666666, 0.16198054212839072, 0.0, 0.4391360997556057, 0.5, 0.0, 0.0], 
reward next is -0.0609. 
=============================================
[2017-11-02 10:07:18,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  7.48629682e-03   3.54262561e-01   5.88661253e-01   4.52019162e-02
   4.38795844e-03   2.50573894e-19   9.73206218e-19   1.76845609e-20
   5.04523046e-19], sum to 1.0000
[2017-11-02 10:07:18,275] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-0.3499999999999999, 97.91666666666666, 2.208333333333333, 157.5, 43.66666666666666, 0.0, -5.4, 14.93003354279095, 18.0, 21.78778218110059, 22.7, 1.0, 0.0], 
actual action is [-5.35, 18], 
sim time next is 1416600.0000, 
raw observation next is [-0.3, 97.5, 2.25, 185.0, 46.0, 0.0, -5.35, 15.51207908610062, 18.0, 21.73815633890147, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.32564102564102565, 0.975, 0.20454545454545456, 0.5138888888888888, 0.12169312169312169, 0.0, 0.41083333333333333, 0.1551207908610062, 0.0, 0.5340223341287812, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:19,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.14128881e-27   1.27432043e-09   2.31066721e-09   8.07689679e-11
   9.56732003e-12   7.01455101e-02   2.95233518e-01   7.05041504e-03
   6.27570510e-01], sum to 1.0000
[2017-11-02 10:07:20,071] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.3499999999999999, 97.91666666666666, 2.208333333333333, 157.5, 43.66666666666666, 0.0, -5.4, 14.74388653639469, 18.0, 21.19356399995094, 22.7, 1.0, 0.0], 
actual action is [4.65, 23.0], 
sim time next is 1416600.0000, 
raw observation next is [-0.3, 97.5, 2.25, 185.0, 46.0, 0.0, 4.65, 13.89754308146965, 23.0, 21.31858896823022, 22.7, 1.0, 37.72226710805126], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.32564102564102565, 0.975, 0.20454545454545456, 0.5138888888888888, 0.12169312169312169, 0.0, 0.5775, 0.1389754308146965, 0.7142857142857143, 0.4740841383186028, 0.6714285714285714, 1.0, 0.44379137774177957], 
reward next is -0.4133. 
=============================================
[2017-11-02 10:07:24,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-31.33129883]
 [-31.87112808]
 [-32.56492615]
 [-32.39326477]
 [-32.46318054]], R is [[-31.25654793]
 [-31.80643272]
 [-31.97783661]
 [-31.82945824]
 [-31.82286453]].
[2017-11-02 10:07:26,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  2.30221448e-27   1.46744839e-09   1.96823025e-09   1.02582401e-10
   1.46062225e-11   3.02585155e-01   5.33457458e-01   9.64294281e-03
   1.54314443e-01], sum to 1.0000
[2017-11-02 10:07:26,338] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.6, 92.0, 1.666666666666667, 186.6666666666667, 0.0, 0.0, -3.4, 17.34533881820777, 18.0, 21.17139254543813, 21.5, 0.0, 0.0], 
actual action is [6.6, 19.0], 
sim time next is 1471500.0000, 
raw observation next is [1.6, 92.0, 1.875, 210.0, 0.0, 0.0, 6.6, 17.0903949192039, 19.0, 21.12019727863653, 21.5, 0.0, 29.67225118435947], 
processed observation next is [0.3333333333333333, 0.0, 0.37435897435897436, 0.92, 0.17045454545454544, 0.5833333333333334, 0.0, 0.0, 0.61, 0.170903949192039, 0.14285714285714285, 0.4457424683766474, 0.5, 0.0, 0.3490853080512879], 
reward next is -0.3684. 
=============================================
[2017-11-02 10:07:31,127] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 78150: loss 38.9882
[2017-11-02 10:07:39,121] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5000, global step 79088: loss 23.6058
[2017-11-02 10:07:39,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79154: loss -5.9902
[2017-11-02 10:07:39,641] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79160: loss 8.1382
[2017-11-02 10:07:43,063] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5000, global step 79597: loss 62.6531
[2017-11-02 10:07:43,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-32.75443649]
 [-31.4433136 ]
 [-31.74973297]
 [-31.24187469]
 [-31.75724602]], R is [[-30.81072235]
 [-31.08518791]
 [-30.77433586]
 [-30.46659279]
 [-30.58859634]].
[2017-11-02 10:07:43,875] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79720: loss 11.9115
[2017-11-02 10:07:44,696] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79856: loss -11.1761
[2017-11-02 10:07:45,071] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5000, global step 79915: loss -83.8637
[2017-11-02 10:07:45,948] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80066: loss -19.5830
[2017-11-02 10:07:46,890] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5000, global step 80239: loss -183.5683
[2017-11-02 10:07:48,921] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80605: loss -138.0118
[2017-11-02 10:07:49,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.62607743e-19   1.12516144e-19   7.35450887e-21
   1.61744577e-21   2.02804029e-01   7.17468381e-01   1.29111297e-02
   6.68164641e-02], sum to 1.0000
[2017-11-02 10:07:49,312] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, -3.9, 23.84773499278872, 18.0, 20.16268537822132, 22.7, 1.0, 0.0], 
actual action is [6.1, 19.0], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, 6.1, 20.29957708189389, 19.0, 20.12797275834634, 22.7, 1.0, 75.85476451906435], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.6016666666666667, 0.2029957708189389, 0.14285714285714285, 0.3039961083351912, 0.6714285714285714, 1.0, 0.8924089943419334], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:50,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99988556e-01   7.45980924e-06   2.51478809e-06   1.44385695e-06
   5.47777290e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:50,338] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, 6.1, 21.62381185009116, 19.0, 20.31029892983119, 22.7, 1.0, 51.55877587939803], 
actual action is [-3.9, 18], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, -3.9, 22.46168837329514, 18.0, 20.31281585104623, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.435, 0.22461688373295138, 0.0, 0.3304022644351759, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:50,687] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80930: loss 12.0177
[2017-11-02 10:07:50,955] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80955: loss 85.3874
[2017-11-02 10:07:51,732] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-19.58183479]
 [-19.37526131]
 [-23.00914574]
 [-22.38502312]
 [-20.11676216]], R is [[-18.81581306]
 [-18.63809586]
 [-18.46231842]
 [-18.28847122]
 [-18.11653328]].
[2017-11-02 10:07:51,832] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99982834e-01   1.21758358e-05   3.49248330e-06   1.37764596e-06
   9.27143304e-08   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:07:51,845] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 81059: loss 119.9539
[2017-11-02 10:07:51,848] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 100.0, 1.0, 95.0, 0.0, 0.0, -3.9, 24.26988313766037, 18.0, 20.21615918874355, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1496100.0000, 
raw observation next is [1.1, 100.0, 0.8333333333333333, 79.16666666666666, 0.0, 0.0, -3.9, 25.51833789460747, 18.0, 20.11757292995636, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.36153846153846153, 1.0, 0.07575757575757575, 0.21990740740740738, 0.0, 0.0, 0.435, 0.2551833789460747, 0.0, 0.3025104185651943, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:07:52,857] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 81215: loss 4.4634
[2017-11-02 10:07:53,896] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5000, global step 81378: loss -3.2915
[2017-11-02 10:07:56,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99308109e-01   4.24094527e-04   1.16547606e-04   1.33426904e-04
   1.78780647e-05   3.88343799e-25   3.97892960e-25   4.44235494e-26
   3.34866339e-26], sum to 1.0000
[2017-11-02 10:07:56,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.033333333333333, 94.0, 1.0, 46.66666666666667, 90.0, 706.6666666666666, -1.058333333333334, 13.3692731280638, 18.0, 22.51500383403704, 22.7, 1.0, 0.0], 
actual action is [-0.9666666666666668, 18], 
sim time next is 1511100.0000, 
raw observation next is [4.125, 93.75, 0.75, 35.0, 91.0, 706.0, -0.9666666666666668, 13.26732298849205, 18.0, 22.54146722123, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.4391025641025641, 0.9375, 0.06818181818181818, 0.09722222222222222, 0.24074074074074073, 0.706, 0.48388888888888887, 0.1326732298849205, 0.0, 0.6487810316042858, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:08:04,547] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   7.44361280e-38   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.09357452e-02   9.68137562e-01   1.03499638e-02
   1.05766691e-02], sum to 1.0000
[2017-11-02 10:08:04,610] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [4.516666666666667, 85.41666666666666, 2.883333333333333, 90.0, 0.0, 0.0, -0.5, 16.93351668611997, 18.0, 20.93779165781799, 21.5, 0.0, 0.0], 
actual action is [9.516666666666666, 19.0], 
sim time next is 1568400.0000, 
raw observation next is [4.533333333333333, 85.33333333333334, 2.866666666666666, 90.0, 0.0, 0.0, 9.516666666666666, 16.35022278430492, 19.0, 20.84801632249611, 21.5, 0.0, 33.92535348093717], 
processed observation next is [0.5, 0.13043478260869565, 0.44957264957264953, 0.8533333333333334, 0.2606060606060605, 0.25, 0.0, 0.0, 0.6586111111111111, 0.16350222784304919, 0.14285714285714285, 0.4068594746423016, 0.5, 0.0, 0.39912180565808436], 
reward next is -0.4524. 
=============================================
[2017-11-02 10:08:05,464] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00554886
  0.98472679  0.00565312  0.00407129], sum to 1.0000
[2017-11-02 10:08:05,486] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [4.658333333333333, 84.41666666666666, 2.741666666666667, 90.0, 0.0, 0.0, 9.65, 18.91091381610538, 19.5, 20.49363354789363, 21.5, 0.0, 10.39650329903321], 
actual action is [9.658333333333333, 20.5], 
sim time next is 1572000.0000, 
raw observation next is [4.666666666666667, 84.33333333333334, 2.733333333333333, 90.0, 0.0, 0.0, 9.658333333333333, 19.25640310865533, 20.5, 20.44444092623161, 21.5, 0.0, 10.02532820134914], 
processed observation next is [0.5, 0.17391304347826086, 0.45299145299145305, 0.8433333333333334, 0.24848484848484845, 0.25, 0.0, 0.0, 0.6609722222222222, 0.19256403108655332, 0.35714285714285715, 0.3492058466045158, 0.5, 0.0, 0.11794503766293106], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:06,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.74814506e-35   8.18904542e-14   2.17180942e-15   7.17781649e-15
   8.20911722e-16   2.16014888e-02   9.67547178e-01   5.59055014e-03
   5.26081864e-03], sum to 1.0000
[2017-11-02 10:08:06,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [6.324999999999999, 77.5, 3.725, 105.0, 0.0, 0.0, 11.41666666666667, 15.45323454270451, 22.0, 20.89189706792796, 21.5, 0.0, 13.44109764701117], 
actual action is [11.325, 23.0], 
sim time next is 1549200.0000, 
raw observation next is [6.233333333333333, 78.0, 3.766666666666667, 106.6666666666667, 0.0, 0.0, 11.325, 14.69898646166163, 23.0, 20.87143964498544, 21.5, 0.0, 36.8501958923317], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.4931623931623932, 0.78, 0.34242424242424246, 0.2962962962962964, 0.0, 0.0, 0.6887500000000001, 0.14698986461661628, 0.7142857142857143, 0.41020566356934857, 0.5, 0.0, 0.4335317163803729], 
reward next is -0.4800. 
=============================================
[2017-11-02 10:08:09,238] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99994755e-01   3.13823602e-06   1.10509625e-07   1.81527412e-06
   1.23829125e-07   8.17030875e-33   8.19275305e-32   9.79922397e-34
   8.58101142e-34], sum to 1.0000
[2017-11-02 10:08:09,264] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 82.0, 3.933333333333334, 123.3333333333333, 0.0, 0.0, 0.375, 14.77510772274261, 18.0, 21.50894191072649, 21.5, 0.0, 0.0], 
actual action is [0.3333333333333339, 18], 
sim time next is 1553100.0000, 
raw observation next is [5.291666666666666, 82.0, 3.891666666666666, 124.1666666666667, 0.0, 0.0, 0.3333333333333339, 15.58957114990151, 18.0, 21.48580509705797, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 1.0, 0.46901709401709396, 0.82, 0.35378787878787876, 0.3449074074074075, 0.0, 0.0, 0.5055555555555556, 0.1558957114990151, 0.0, 0.4979721567225671, 0.5, 0.0, 0.0], 
reward next is -0.0020. 
=============================================
[2017-11-02 10:08:09,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.49978517e-07   7.78572023e-01   1.91995297e-02   1.64789036e-01
   3.42237316e-02   2.20616086e-04   2.87192781e-03   6.86949716e-05
   5.37861815e-05], sum to 1.0000
[2017-11-02 10:08:09,295] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [10.13333333333333, 62.66666666666667, 5.800000000000001, 156.6666666666667, 0.0, 0.0, 5.225, 14.12309078790137, 18.0, 21.48144663238067, 22.7, 1.0, 0.0], 
actual action is [5.133333333333329, 18], 
sim time next is 1621500.0000, 
raw observation next is [10.04166666666667, 63.08333333333333, 5.449999999999999, 158.3333333333333, 0.0, 0.0, 5.133333333333329, 14.42576572739794, 18.0, 21.39257944991812, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5908119658119659, 0.6308333333333332, 0.49545454545454537, 0.43981481481481466, 0.0, 0.0, 0.5855555555555554, 0.1442576572739794, 0.0, 0.48465420713116003, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0144. 
=============================================
[2017-11-02 10:08:17,300] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999046e-01   7.53426946e-07   4.01170404e-08   2.30956303e-07
   4.21836717e-08   2.01918617e-27   4.30878631e-26   4.15045462e-28
   3.55712087e-28], sum to 1.0000
[2017-11-02 10:08:17,316] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.975000000000001, 62.75, 5.1, 112.5, 204.0, 128.25, 3.833333333333334, 13.54236797358316, 18.0, 21.93198401331663, 22.7, 1.0, 0.0], 
actual action is [3.9750000000000014, 18], 
sim time next is 1594200.0000, 
raw observation next is [9.116666666666667, 62.16666666666666, 5.1, 111.6666666666667, 205.3333333333333, 141.6666666666667, 3.975000000000001, 13.37250253039468, 18.0, 21.96997159955009, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.5670940170940171, 0.6216666666666666, 0.4636363636363636, 0.3101851851851853, 0.5432098765432097, 0.14166666666666672, 0.56625, 0.1337250253039468, 0.0, 0.567138799935727, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 10:08:17,476] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 85572: loss -100.5131
[2017-11-02 10:08:19,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99996543e-01   2.71608747e-06   9.71414025e-08   4.80340532e-07
   9.12169256e-08   1.24743253e-25   2.51311659e-24   3.50675358e-26
   1.30554831e-26], sum to 1.0000
[2017-11-02 10:08:19,962] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.38333333333333, 53.5, 6.283333333333333, 143.3333333333333, 33.66666666666667, 24.66666666666667, 7.475, 8.951225404854945, 18.0, 22.91800752928814, 22.7, 1.0, 0.0], 
actual action is [7.383333333333329, 18], 
sim time next is 1616100.0000, 
raw observation next is [12.29166666666667, 53.75, 6.191666666666666, 141.6666666666667, 29.58333333333334, 21.58333333333334, 7.383333333333329, 8.978633044768287, 18.0, 22.89513748412397, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.6485042735042736, 0.5375, 0.5628787878787879, 0.39351851851851866, 0.07826278659611995, 0.02158333333333334, 0.6230555555555555, 0.08978633044768287, 0.0, 0.699305354874853, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0090. 
=============================================
[2017-11-02 10:08:22,234] A3C_AGENT_WORKER-Thread-8 INFO:Local step 5500, global step 86390: loss -50.6115
[2017-11-02 10:08:22,613] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   3.34626567e-22   2.00157737e-24   6.81936016e-24
   1.39111420e-24   1.09019084e-03   9.98362005e-01   1.98018111e-04
   3.49788344e-04], sum to 1.0000
[2017-11-02 10:08:22,638] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [7.325, 75.5, 7.575, 120.0, 0.0, 0.0, 2.366666666666667, 23.00069116317854, 18.0, 19.45549391348126, 21.5, 0.0, 0.0], 
actual action is [12.325, 19.0], 
sim time next is 1630200.0000, 
raw observation next is [7.283333333333333, 75.66666666666667, 7.616666666666667, 120.0, 0.0, 0.0, 12.325, 23.06152392729355, 19.0, 19.42384050946776, 21.5, 0.0, 7.619291502891101], 
processed observation next is [0.5, 0.8695652173913043, 0.52008547008547, 0.7566666666666667, 0.6924242424242425, 0.3333333333333333, 0.0, 0.0, 0.7054166666666667, 0.2306152392729355, 0.14285714285714285, 0.2034057870668227, 0.5, 0.0, 0.08963872356342471], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:24,871] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 86819: loss -12.5739
[2017-11-02 10:08:25,256] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99991655e-01   5.30161151e-06   3.32578395e-07   2.28332806e-06
   3.79364707e-07   1.58560820e-21   1.75092971e-20   4.12269589e-22
   2.87415576e-22], sum to 1.0000
[2017-11-02 10:08:25,325] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.61666666666667, 49.66666666666666, 7.024999999999999, 136.6666666666667, 160.25, 72.33333333333334, 8.43333333333334, 12.63087444895173, 18.0, 22.0707565388578, 22.7, 1.0, 0.0], 
actual action is [8.61666666666667, 18], 
sim time next is 1602000.0000, 
raw observation next is [13.8, 49.0, 7.2, 140.0, 162.5, 62.0, 8.61666666666667, 12.60467282238093, 18.0, 22.06519131654625, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5652173913043478, 0.6871794871794872, 0.49, 0.6545454545454545, 0.3888888888888889, 0.4298941798941799, 0.062, 0.6436111111111112, 0.1260467282238093, 0.0, 0.5807416166494644, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0126. 
=============================================
[2017-11-02 10:08:26,298] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87085: loss 87.3450
[2017-11-02 10:08:29,216] A3C_AGENT_WORKER-Thread-6 INFO:Local step 5500, global step 87560: loss 213.4645
[2017-11-02 10:08:29,550] A3C_AGENT_WORKER-Thread-5 INFO:Local step 5500, global step 87600: loss -364.2876
[2017-11-02 10:08:31,462] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87893: loss 159.8339
[2017-11-02 10:08:31,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87920: loss -4.4293
[2017-11-02 10:08:32,834] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88136: loss 43.7014
[2017-11-02 10:08:35,389] A3C_AGENT_WORKER-Thread-4 INFO:Local step 5500, global step 88488: loss -39.9499
[2017-11-02 10:08:36,019] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88549: loss -39.8894
[2017-11-02 10:08:37,875] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99945998e-01   2.45754509e-05   1.09891812e-06   2.52659593e-05
   3.13071746e-06   2.44233767e-29   1.62966460e-26   3.42716939e-30
   3.54525147e-30], sum to 1.0000
[2017-11-02 10:08:37,877] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88715: loss 417.8937
[2017-11-02 10:08:37,900] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.85, 231.6666666666666, 81.66666666666667, 0.0, 6.1, 11.78909812608369, 19.0, 22.49788075345614, 22.7, 1.0, 32.49226562577604], 
actual action is [-3.9, 18], 
sim time next is 1693800.0000, 
raw observation next is [1.1, 88.0, 6.9, 230.0, 80.0, 0.0, -3.9, 12.34354786760922, 18.0, 22.5279475694593, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.36153846153846153, 0.88, 0.6272727272727273, 0.6388888888888888, 0.21164021164021163, 0.0, 0.435, 0.1234354786760922, 0.0, 0.6468496527799, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0123. 
=============================================
[2017-11-02 10:08:38,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.85295484e-09   7.60268390e-01   2.52253339e-02   1.56145111e-01
   4.19951156e-02   2.95087993e-05   1.63245164e-02   6.22704829e-06
   5.77421270e-06], sum to 1.0000
[2017-11-02 10:08:39,099] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [4.575, 92.0, 7.7, 250.0, 0.0, 0.0, 9.716666666666667, 14.15467082973085, 19.0, 20.80097607913025, 22.7, 1.0, 25.25431331930719], 
actual action is [-0.4249999999999998, 18], 
sim time next is 1668000.0000, 
raw observation next is [4.433333333333334, 92.0, 7.7, 250.0, 0.0, 0.0, -0.4249999999999998, 15.4565170003669, 18.0, 20.72499606074639, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.44700854700854703, 0.92, 0.7000000000000001, 0.6944444444444444, 0.0, 0.0, 0.49291666666666667, 0.15456517000366898, 0.0, 0.3892851515351983, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:40,327] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 89016: loss 61.5063
[2017-11-02 10:08:41,101] A3C_AGENT_WORKER-Thread-7 INFO:Local step 5500, global step 89128: loss 54.2766
[2017-11-02 10:08:42,007] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 89263: loss -174.2468
[2017-11-02 10:08:43,186] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 89462: loss -16.3707
[2017-11-02 10:08:44,689] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   6.41745229e-13   3.99139408e-14   7.13040412e-13
   5.38052269e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:08:44,777] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 7.575, 237.5, 0.0, 0.0, -3.9, 23.01539115437125, 18.0, 20.74885326528489, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1713000.0000, 
raw observation next is [1.1, 88.0, 7.616666666666667, 238.3333333333333, 0.0, 0.0, -3.9, 23.95192519698118, 18.0, 20.64739458301725, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.36153846153846153, 0.88, 0.6924242424242425, 0.6620370370370369, 0.0, 0.0, 0.435, 0.2395192519698118, 0.0, 0.37819922614532125, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:48,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.61146999e-06   9.99854326e-01   3.63545369e-05
   1.05684441e-04], sum to 1.0000
[2017-11-02 10:08:49,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.5, 92.0, 8.7, 247.5, 0.0, 0.0, -4.5, 26.26024428155825, 18.0, 19.93502250429392, 21.5, 0.0, 0.0], 
actual action is [5.5, 19.0], 
sim time next is 1729200.0000, 
raw observation next is [0.5, 92.0, 8.7, 246.6666666666667, 0.0, 0.0, 5.5, 25.44248849184235, 19.0, 19.92311170298843, 21.5, 0.0, 37.58268286986797], 
processed observation next is [0.8333333333333334, 0.0, 0.34615384615384615, 0.92, 0.7909090909090909, 0.6851851851851853, 0.0, 0.0, 0.5916666666666667, 0.2544248849184235, 0.14285714285714285, 0.27473024328406126, 0.5, 0.0, 0.4421492102337409], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:08:49,986] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-91.06332397]
 [-94.24360657]
 [-97.46411133]
 [-92.98303223]
 [-90.82104492]], R is [[-91.34546661]
 [-91.43201447]
 [-91.51769257]
 [-91.60251617]
 [-91.68649292]].
[2017-11-02 10:08:50,417] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-118.73893738]
 [-119.08853149]
 [-107.63809204]
 [-111.34016418]
 [-111.03089905]], R is [[-114.94807434]
 [-114.79859161]
 [-114.65060425]
 [-114.50409698]
 [-114.35905457]].
[2017-11-02 10:09:01,124] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.52325473e-05   9.99630809e-01   2.05740536e-04
   1.08212706e-04], sum to 1.0000
[2017-11-02 10:09:01,343] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.6, 84.33333333333333, 9.533333333333333, 250.0, 0.0, 0.0, 4.4, 16.82125048551058, 20.0, 20.72812174979041, 21.5, 0.0, 48.51497538456263], 
actual action is [4.4, 21.0], 
sim time next is 1745100.0000, 
raw observation next is [-0.6, 84.0, 9.575, 250.0, 0.0, 0.0, 4.4, 16.54757770217177, 21.0, 20.83800494707392, 21.5, 0.0, 42.4641527821178], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.317948717948718, 0.84, 0.8704545454545454, 0.6944444444444444, 0.0, 0.0, 0.5733333333333334, 0.16547577702171767, 0.42857142857142855, 0.40542927815341706, 0.5, 0.0, 0.4995782680249153], 
reward next is -0.5442. 
=============================================
[2017-11-02 10:09:01,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   3.06066472e-35   3.63420950e-37   1.97015892e-36
   1.05740768e-33   1.44256672e-04   9.99589503e-01   2.13366773e-04
   5.29041245e-05], sum to 1.0000
[2017-11-02 10:09:01,730] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.5, 92.0, 8.2, 240.0, 0.0, 0.0, 5.5, 18.29134985947126, 20.0, 20.92217016256524, 21.5, 0.0, 23.53140773249872], 
actual action is [5.5, 21.0], 
sim time next is 1721100.0000, 
raw observation next is [0.4583333333333333, 92.25, 8.241666666666665, 240.0, 0.0, 0.0, 5.5, 18.9169297037435, 21.0, 20.87954639922356, 21.5, 0.0, 22.79105338562747], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.3450854700854701, 0.9225, 0.7492424242424242, 0.6666666666666666, 0.0, 0.0, 0.5916666666666667, 0.18916929703743499, 0.42857142857142855, 0.4113637713176515, 0.5, 0.0, 0.26813003983091144], 
reward next is -0.3300. 
=============================================
[2017-11-02 10:09:02,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-79.98878479]
 [-77.52418518]
 [-79.51000977]
 [-81.14012909]
 [-82.53195953]], R is [[-80.01891327]
 [-80.21872711]
 [-80.41654205]
 [-80.61238098]
 [-80.80625916]].
[2017-11-02 10:09:16,742] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.49247663e-14   2.39146539e-15   1.08223223e-14
   8.08523279e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:09:16,945] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.95, 84.66666666666666, 9.2, 250.0, 61.75, 0.0, 3.1, 15.240439012506, 25.0, 21.23800818959085, 22.7, 1.0, 45.83124497471122], 
actual action is [3.05, 20.0], 
sim time next is 1762200.0000, 
raw observation next is [-2.0, 85.0, 9.2, 250.0, 65.0, 0.0, 3.05, 14.89889465203885, 20.0, 21.38387356882702, 22.7, 1.0, 56.69881970313654], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.28205128205128205, 0.85, 0.8363636363636363, 0.6944444444444444, 0.17195767195767195, 0.0, 0.5508333333333333, 0.1489889465203885, 0.2857142857142857, 0.4834105098324315, 0.6714285714285714, 1.0, 0.6670449376839593], 
reward next is -0.6152. 
=============================================
[2017-11-02 10:09:20,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.83563184e-03   1.01141185e-02   1.63753575e-03   2.54914607e-03
   9.82863605e-01   1.03685650e-22   3.32067432e-23   8.16203534e-24
   8.34840061e-22], sum to 1.0000
[2017-11-02 10:09:20,502] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-2.3, 83.33333333333333, 9.241666666666665, 250.8333333333333, 121.9166666666667, 0.0, -7.3, 14.76352900093187, 18.0, 21.92908430649495, 22.7, 1.0, 0.0], 
actual action is [-7.3, 18.0], 
sim time next is 1771200.0000, 
raw observation next is [-2.3, 83.0, 9.2, 250.0, 122.5, 0.0, -7.3, 16.72198671290928, 18.0, 21.85455130824431, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.27435897435897433, 0.83, 0.8363636363636363, 0.6944444444444444, 0.32407407407407407, 0.0, 0.3783333333333333, 0.16721986712909281, 0.0, 0.5506501868920444, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:09:25,121] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 94651: loss 126.4120
[2017-11-02 10:09:30,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.06818106e-25   2.29187940e-08   9.58285113e-08   2.90651503e-09
   7.68053269e-07   7.38865435e-02   1.47989970e-02   5.68050379e-03
   9.05633032e-01], sum to 1.0000
[2017-11-02 10:09:30,594] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 84.0, 9.325, 252.5, 120.75, 0.0, -7.3, 15.7234709664621, 18.0, 22.08548941227658, 22.7, 1.0, 0.0], 
actual action is [2.7, 23.0], 
sim time next is 1770600.0000, 
raw observation next is [-2.3, 83.66666666666667, 9.283333333333331, 251.6666666666667, 121.3333333333333, 0.0, 2.7, 13.86337406162871, 23.0, 21.94656706582222, 22.7, 1.0, 97.16025729057873], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.27435897435897433, 0.8366666666666667, 0.8439393939393938, 0.6990740740740742, 0.3209876543209876, 0.0, 0.545, 0.13863374061628708, 0.7142857142857143, 0.5637952951174598, 0.6714285714285714, 1.0, 1.1430618504773968], 
reward next is -1.0426. 
=============================================
[2017-11-02 10:09:33,663] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6000, global step 95216: loss 39.6269
[2017-11-02 10:09:35,678] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95348: loss -49.0502
[2017-11-02 10:09:35,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95351: loss 58.5360
[2017-11-02 10:09:36,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.13086857e-20   4.49080659e-07   2.03691689e-05   6.56068124e-08
   1.32060213e-05   1.75977141e-01   1.57538541e-02   4.00489429e-03
   8.04230034e-01], sum to 1.0000
[2017-11-02 10:09:36,589] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-2.3, 85.66666666666667, 9.533333333333333, 256.6666666666667, 115.3333333333333, 0.0, 2.7, 10.68481808746183, 24.0, 22.42905015695743, 22.7, 1.0, 64.57125460665414], 
actual action is [2.7, 24.5], 
sim time next is 1769100.0000, 
raw observation next is [-2.3, 85.33333333333333, 9.491666666666665, 255.8333333333333, 117.1666666666667, 0.0, 2.7, 10.44824335977663, 24.5, 22.53019004453655, 22.7, 1.0, 64.37767300768142], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.27435897435897433, 0.8533333333333333, 0.8628787878787878, 0.710648148148148, 0.3099647266313934, 0.0, 0.545, 0.1044824335977663, 0.9285714285714286, 0.6471700063623642, 0.6714285714285714, 1.0, 0.7573843883256638], 
reward next is -0.6921. 
=============================================
[2017-11-02 10:09:36,773] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95421: loss 19.5737
[2017-11-02 10:09:37,010] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.14324976e-24   5.28996180e-10   1.79158679e-08   7.28436408e-11
   1.53673394e-08   1.67976871e-01   1.78445783e-02   4.64510312e-03
   8.09533417e-01], sum to 1.0000
[2017-11-02 10:09:37,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.483333333333333, 86.16666666666667, 9.533333333333333, 250.0, 40.66666666666666, 0.0, 1.558333333333334, 11.979467787068, 25.0, 22.75512082217267, 22.7, 1.0, 65.88410405527], 
actual action is [1.516666666666667, 25], 
sim time next is 1786500.0000, 
raw observation next is [-3.525, 85.75, 9.45, 250.0, 37.5, 0.0, 1.516666666666667, 11.72728020953634, 25.0, 22.77018468008044, 22.7, 1.0, 66.75866129613145], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.24294871794871795, 0.8575, 0.859090909090909, 0.6944444444444444, 0.0992063492063492, 0.0, 0.5252777777777777, 0.11727280209536341, 1.0, 0.6814549542972058, 0.6714285714285714, 1.0, 0.7853960152486053], 
reward next is -0.7186. 
=============================================
[2017-11-02 10:09:38,647] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6000, global step 95558: loss -8.2777
[2017-11-02 10:09:41,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.04707732
  0.00211451  0.00101233  0.94979578], sum to 1.0000
[2017-11-02 10:09:42,037] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.2, 82.5, 8.45, 245.0, 0.0, 0.0, 0.8500000000000014, 10.59853144631717, 25.0, 23.28868508031329, 22.7, 1.0, 63.97420939810313], 
actual action is [0.7999999999999998, 25], 
sim time next is 1794900.0000, 
raw observation next is [-4.25, 82.58333333333334, 8.408333333333333, 245.8333333333333, 0.0, 0.0, 0.7999999999999998, 10.56082923675282, 25.0, 23.30888469781329, 22.7, 1.0, 63.94417481107654], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.22435897435897437, 0.8258333333333334, 0.7643939393939394, 0.6828703703703702, 0.0, 0.0, 0.5133333333333333, 0.1056082923675282, 1.0, 0.7584120996876129, 0.6714285714285714, 1.0, 0.752284409542077], 
reward next is -0.6876. 
=============================================
[2017-11-02 10:09:46,302] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96074: loss 27.3964
[2017-11-02 10:09:48,258] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6000, global step 96221: loss 1.1511
[2017-11-02 10:09:49,320] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96303: loss 0.1748
[2017-11-02 10:09:52,345] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6000, global step 96532: loss 0.1457
[2017-11-02 10:09:55,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  0.00000000e+00   4.03830706e-29   9.04423154e-28   1.26811823e-30
   3.35778784e-28   5.39383441e-02   2.22182181e-03   9.45120584e-03
   9.34388578e-01], sum to 1.0000
[2017-11-02 10:09:55,054] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96740: loss 0.0366
[2017-11-02 10:09:55,164] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 83.0, 9.575, 250.0, 0.0, 0.0, 0.5, 8.917481597832978, 25.0, 23.67709416156361, 21.5, 0.0, 47.75294667719135], 
actual action is [0.5, 25], 
sim time next is 1800000.0000, 
raw observation next is [-4.5, 83.0, 9.7, 250.0, 0.0, 0.0, 0.5, 8.898467871913995, 25.0, 23.66608833694734, 21.5, 0.0, 47.8011292654365], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.21794871794871795, 0.83, 0.8818181818181817, 0.6944444444444444, 0.0, 0.0, 0.5083333333333333, 0.08898467871913995, 1.0, 0.8094411909924771, 0.5, 0.0, 0.5623662266521942], 
reward next is -0.5061. 
=============================================
[2017-11-02 10:09:55,210] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96749: loss 0.9530
[2017-11-02 10:09:57,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.27252901
  0.05606475  0.02205735  0.64934891], sum to 1.0000
[2017-11-02 10:09:57,486] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.958333333333333, 85.75, 8.783333333333333, 240.8333333333333, 0.0, 0.0, 0.08333333333333304, 8.697696328722593, 25.0, 23.46706126527901, 21.5, 0.0, 47.6910323371233], 
actual action is [0.04166666666666696, 25], 
sim time next is 1803600.0000, 
raw observation next is [-5.0, 86.0, 8.7, 240.0, 0.0, 0.0, 0.04166666666666696, 8.691384455857145, 25.0, 23.45008304505805, 21.5, 0.0, 47.66562975722849], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.20512820512820512, 0.86, 0.7909090909090909, 0.6666666666666666, 0.0, 0.0, 0.5006944444444444, 0.08691384455857146, 1.0, 0.7785832921511501, 0.5, 0.0, 0.5607721147909234], 
reward next is -0.5047. 
=============================================
[2017-11-02 10:10:00,065] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 97107: loss 5.6813
[2017-11-02 10:10:01,687] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 97225: loss -1.2364
[2017-11-02 10:10:04,183] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6000, global step 97433: loss 12.4033
[2017-11-02 10:10:05,419] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 97547: loss 9.5055
[2017-11-02 10:10:07,997] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.82605531e-14   6.39711699e-13   9.41663604e-14
   3.17686930e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:10:08,041] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 71.0, 7.783333333333333, 240.0, 175.3333333333333, 54.66666666666666, 0.5, 19.95838453923189, 19.0, 21.15144356506179, 22.7, 1.0, 79.5984808223297], 
actual action is [-9.5, 18], 
sim time next is 1864500.0000, 
raw observation next is [-4.5, 71.0, 7.741666666666667, 240.0, 176.6666666666667, 58.33333333333334, -9.5, 21.13247992617007, 18.0, 21.14335213558592, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.5652173913043478, 0.21794871794871795, 0.71, 0.7037878787878789, 0.6666666666666666, 0.46737213403880085, 0.05833333333333334, 0.3416666666666667, 0.2113247992617007, 0.0, 0.449050305083703, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:10:19,550] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-80.56426239]
 [-80.26311493]
 [-80.04972076]
 [-79.52565765]
 [-81.36893463]], R is [[-79.78635406]
 [-79.58970642]
 [-79.39836884]
 [-79.20790863]
 [-78.97956848]].
[2017-11-02 10:10:20,220] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-83.58181763]
 [-85.07683563]
 [-79.96875   ]
 [-83.02320099]
 [-80.43252563]], R is [[-80.57939911]
 [-80.77360535]
 [-80.96587372]
 [-81.15621948]
 [-81.3446579 ]].
[2017-11-02 10:10:35,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-62.93253708]
 [-62.23078537]
 [-63.04800797]
 [-62.38901901]
 [-62.95936203]], R is [[-62.6243515 ]
 [-62.49840927]
 [-62.37442017]
 [-62.25268936]
 [-62.13407516]].
[2017-11-02 10:10:37,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  4.46425553e-38   8.36787475e-20   6.63751540e-19   3.18490902e-19
   5.31923456e-18   1.63431335e-02   8.04066420e-01   4.78566326e-02
   1.31733775e-01], sum to 1.0000
[2017-11-02 10:10:37,813] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 77.0, 8.2, 243.3333333333334, 124.6666666666667, 58.16666666666666, -0.5999999999999996, 13.02195042140091, 25.0, 22.33689308833354, 22.7, 1.0, 45.61507425017853], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1851900.0000, 
raw observation next is [-5.6, 76.75, 8.2, 244.1666666666666, 122.3333333333333, 54.58333333333334, -0.5999999999999996, 13.1473346378016, 25.0, 22.32839856148775, 22.7, 1.0, 56.15590541041327], 
processed observation next is [1.0, 0.43478260869565216, 0.18974358974358976, 0.7675, 0.7454545454545454, 0.6782407407407406, 0.3236331569664902, 0.054583333333333345, 0.49, 0.131473346378016, 1.0, 0.6183426516411069, 0.6714285714285714, 1.0, 0.6606577107107443], 
reward next is -0.6077. 
=============================================
[2017-11-02 10:10:50,762] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-55.17500305]
 [-56.44522476]
 [-57.3824234 ]
 [-58.18151474]
 [-56.48182297]], R is [[-56.18557739]
 [-56.29700089]
 [-56.41321945]
 [-56.53894424]
 [-56.66769409]].
[2017-11-02 10:11:01,967] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 101996: loss 50.2543
[2017-11-02 10:11:06,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00113284
  0.98299003  0.00270827  0.01316886], sum to 1.0000
[2017-11-02 10:11:06,883] A3C_AGENT_WORKER-Thread-8 INFO:Local step 6500, global step 102575: loss 4.6315
[2017-11-02 10:11:06,942] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.9, 86.0, 3.6, 220.0, 59.0, 285.0, -3.949999999999999, 24.24542522491354, 21.0, 19.9576138770289, 22.7, 1.0, 20.58683604212832], 
actual action is [-3.9000000000000004, 22.0], 
sim time next is 1933500.0000, 
raw observation next is [-8.766666666666666, 85.41666666666666, 3.641666666666667, 219.1666666666667, 63.33333333333334, 329.0, -3.9, 22.18033493423093, 22.0, 19.97876361964382, 22.7, 1.0, 61.98270400396465], 
processed observation next is [0.0, 0.391304347826087, 0.10854700854700858, 0.8541666666666665, 0.3310606060606061, 0.6087962962962964, 0.16754850088183423, 0.329, 0.435, 0.2218033493423093, 0.5714285714285714, 0.2826805170919745, 0.6714285714285714, 1.0, 0.7292082823995841], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:11:07,281] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 102614: loss 82.4349
[2017-11-02 10:11:09,652] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99997973e-01   3.65771413e-08   1.00111708e-06   1.29108614e-07
   9.82053280e-07   8.15154844e-29   3.44903277e-27   1.14437217e-28
   2.75881159e-28], sum to 1.0000
[2017-11-02 10:11:09,729] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.5, 73.33333333333333, 5.183333333333334, 220.0, 211.6666666666667, 85.33333333333331, -0.5499999999999998, 14.27770926634545, 19.0, 22.31965542772326, 22.7, 1.0, 23.24510348119224], 
actual action is [-10.5, 18], 
sim time next is 1941300.0000, 
raw observation next is [-5.449999999999999, 72.5, 5.225, 220.0, 216.75, 66.5, -10.5, 14.99485971074225, 18.0, 22.26613144333724, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.1935897435897436, 0.725, 0.475, 0.6111111111111112, 0.5734126984126984, 0.0665, 0.325, 0.1499485971074225, 0.0, 0.6094473490481772, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0150. 
=============================================
[2017-11-02 10:11:12,899] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103148: loss -16.8911
[2017-11-02 10:11:14,682] A3C_AGENT_WORKER-Thread-6 INFO:Local step 6500, global step 103312: loss 45.3296
[2017-11-02 10:11:17,893] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103565: loss -17.8354
[2017-11-02 10:11:22,099] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  8.78025744e-29   7.85511674e-16   7.63691766e-15   4.62992021e-16
   1.05969878e-14   1.03973215e-02   9.79119003e-01   6.32325280e-03
   4.16032691e-03], sum to 1.0000
[2017-11-02 10:11:22,415] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.05, 77.0, 4.35, 260.0, 0.0, 0.0, 0.04166666666666696, 9.018239998007536, 25.0, 23.35935337850861, 22.7, 1.0, 61.6609383019284], 
actual action is [-0.04999999999999982, 25], 
sim time next is 1971300.0000, 
raw observation next is [-5.141666666666667, 78.0, 4.308333333333333, 260.0, 0.0, 0.0, -0.04999999999999982, 9.028475861122242, 25.0, 23.36475056353182, 22.7, 1.0, 61.63683211010908], 
processed observation next is [0.0, 0.8260869565217391, 0.2014957264957265, 0.78, 0.3916666666666666, 0.7222222222222222, 0.0, 0.0, 0.49916666666666665, 0.09028475861122243, 1.0, 0.766392937647403, 0.6714285714285714, 1.0, 0.725139201295401], 
reward next is -0.6617. 
=============================================
[2017-11-02 10:11:23,615] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103971: loss 10.3158
[2017-11-02 10:11:26,137] A3C_AGENT_WORKER-Thread-5 INFO:Local step 6500, global step 104204: loss 25.4254
[2017-11-02 10:11:28,986] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.31498806e-03   9.96292412e-01   8.93324905e-04
   4.99339076e-04], sum to 1.0000
[2017-11-02 10:11:29,093] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 84.33333333333334, 2.833333333333333, 246.6666666666667, 0.0, 0.0, -0.7499999999999991, 10.76652413538454, 25.0, 21.90201940492178, 21.5, 0.0, 44.47044319514609], 
actual action is [-0.7999999999999998, 25], 
sim time next is 2003100.0000, 
raw observation next is [-5.85, 84.66666666666666, 2.791666666666667, 248.3333333333333, 0.0, 0.0, -0.7999999999999998, 10.75386307672991, 25.0, 21.9054770539437, 21.5, 0.0, 44.44620586743118], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.18333333333333335, 0.8466666666666666, 0.25378787878787884, 0.6898148148148147, 0.0, 0.0, 0.48666666666666664, 0.10753863076729911, 1.0, 0.5579252934205284, 0.5, 0.0, 0.5228965396168375], 
reward next is -0.4706. 
=============================================
[2017-11-02 10:11:29,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.38230359e-03   9.96999264e-01   4.44626377e-04
   1.73873937e-04], sum to 1.0000
[2017-11-02 10:11:29,264] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 83.0, 4.199999999999999, 257.5, 0.0, 0.0, -0.6000000000000014, 10.03163280587909, 25.0, 22.68413260025964, 21.5, 0.0, 45.43772966752734], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1984800.0000, 
raw observation next is [-5.6, 83.0, 4.066666666666666, 256.6666666666667, 0.0, 0.0, -0.5999999999999996, 10.01934695515278, 25.0, 22.67942590895108, 21.5, 0.0, 45.35895210004082], 
processed observation next is [0.0, 1.0, 0.18974358974358976, 0.83, 0.3696969696969697, 0.712962962962963, 0.0, 0.0, 0.49, 0.1001934695515278, 1.0, 0.6684894155644402, 0.5, 0.0, 0.5336347305887155], 
reward next is -0.4803. 
=============================================
[2017-11-02 10:11:29,532] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104449: loss -2.2982
[2017-11-02 10:11:31,017] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104578: loss -48.2519
[2017-11-02 10:11:32,290] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104716: loss -31.0212
[2017-11-02 10:11:32,592] A3C_AGENT_WORKER-Thread-4 INFO:Local step 6500, global step 104758: loss 2.8968
[2017-11-02 10:11:34,101] A3C_AGENT_WORKER-Thread-7 INFO:Local step 6500, global step 104950: loss 1.8761
[2017-11-02 10:11:35,965] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 105126: loss 54.9883
[2017-11-02 10:11:36,296] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 105161: loss 35.4915
[2017-11-02 10:11:38,371] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 105348: loss 50.6937
[2017-11-02 10:11:44,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.88571234e-35   7.28557031e-20   3.41759719e-20   3.29340891e-21
   3.04375808e-20   1.51766296e-02   9.76646125e-01   2.82630604e-03
   5.35096135e-03], sum to 1.0000
[2017-11-02 10:11:44,731] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 79.66666666666667, 4.433333333333334, 256.6666666666667, 0.0, 0.0, -0.7499999999999991, 10.8169771870228, 25.0, 22.33978264106647, 21.5, 0.0, 46.44318058675461], 
actual action is [-0.7999999999999998, 25], 
sim time next is 1977900.0000, 
raw observation next is [-5.85, 80.08333333333333, 4.391666666666666, 258.3333333333333, 0.0, 0.0, -0.7999999999999998, 10.58134967847273, 25.0, 22.40682411801815, 21.5, 0.0, 46.02622152535623], 
processed observation next is [0.0, 0.9130434782608695, 0.18333333333333335, 0.8008333333333333, 0.3992424242424242, 0.7175925925925926, 0.0, 0.0, 0.48666666666666664, 0.1058134967847273, 1.0, 0.6295463025740214, 0.5, 0.0, 0.5414849591218379], 
reward next is -0.4873. 
=============================================
[2017-11-02 10:11:54,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02943116
  0.92151934  0.01578706  0.03326247], sum to 1.0000
[2017-11-02 10:11:55,048] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.8, 83.0, 4.433333333333334, 263.3333333333333, 0.0, 0.0, -10.85, 12.94072315911324, 18.0, 22.3846070843145, 21.5, 0.0, 0.0], 
actual action is [-0.7999999999999998, 19.0], 
sim time next is 1982700.0000, 
raw observation next is [-5.749999999999999, 83.0, 4.475, 262.5, 0.0, 0.0, -0.7999999999999998, 12.64814447382977, 19.0, 22.23357468200294, 21.5, 0.0, 49.4286479795695], 
processed observation next is [0.0, 0.9565217391304348, 0.18589743589743593, 0.83, 0.4068181818181818, 0.7291666666666666, 0.0, 0.0, 0.48666666666666664, 0.1264814447382977, 0.14285714285714285, 0.6047963831432769, 0.5, 0.0, 0.5815135056419941], 
reward next is -0.5234. 
=============================================
[2017-11-02 10:11:58,273] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  5.35629551e-14   7.50472609e-08   3.70944448e-08   1.34429197e-08
   3.16338102e-08   2.90715843e-01   2.17443928e-01   4.36271168e-02
   4.48213041e-01], sum to 1.0000
[2017-11-02 10:11:58,382] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.2, 87.0, 2.666666666666667, 256.6666666666667, 0.0, 0.0, -1.2, 15.18802868652859, 25.0, 20.88616897557592, 21.5, 0.0, 48.33964856719816], 
actual action is [-1.2000000000000002, 25], 
sim time next is 2010300.0000, 
raw observation next is [-6.199999999999999, 87.0, 2.583333333333333, 255.8333333333333, 0.0, 0.0, -1.2, 14.7480521499335, 25.0, 20.89654380846903, 21.5, 0.0, 48.09932529834153], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.17435897435897438, 0.87, 0.23484848484848483, 0.710648148148148, 0.0, 0.0, 0.48000000000000004, 0.147480521499335, 1.0, 0.4137919726384328, 0.5, 0.0, 0.5658744152746062], 
reward next is -0.5955. 
=============================================
[2017-11-02 10:12:02,156] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   3.69912625e-26   2.32760513e-26   5.32942179e-27
   1.97565391e-26   2.34058976e-01   8.90831053e-02   4.05419916e-02
   6.36315942e-01], sum to 1.0000
[2017-11-02 10:12:02,243] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 87.0, 2.75, 257.5, 0.0, 0.0, -1.2, 12.59508642533536, 20.0, 21.40110884520712, 21.5, 0.0, 46.92532008688205], 
actual action is [-1.2000000000000002, 25.0], 
sim time next is 2010000.0000, 
raw observation next is [-6.2, 87.0, 2.666666666666667, 256.6666666666667, 0.0, 0.0, -1.2, 12.5856750337788, 25.0, 21.40704323403346, 21.5, 0.0, 39.29239231099469], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.17435897435897435, 0.87, 0.24242424242424246, 0.712962962962963, 0.0, 0.0, 0.48000000000000004, 0.125856750337788, 1.0, 0.48672046200477986, 0.5, 0.0, 0.46226343895287875], 
reward next is -0.4293. 
=============================================
[2017-11-02 10:12:05,509] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99987841e-01   2.87425587e-06   4.96232997e-06   2.39027077e-06
   1.96258611e-06   5.62717191e-15   5.01318197e-16   7.73996314e-16
   5.83476899e-16], sum to 1.0000
[2017-11-02 10:12:05,574] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.116666666666666, 86.58333333333333, 4.808333333333333, 240.0, 26.66666666666666, 0.0, -1.133333333333334, 17.64636688064407, 24.0, 20.93352577765266, 22.7, 1.0, 23.62384264836788], 
actual action is [-1.1166666666666663, 19.0], 
sim time next is 2017800.0000, 
raw observation next is [-6.1, 86.5, 4.85, 240.0, 29.0, 0.0, -1.116666666666666, 17.01156697215022, 19.0, 20.89372431535621, 22.7, 1.0, 49.86989488495328], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.17692307692307693, 0.865, 0.44090909090909086, 0.6666666666666666, 0.07671957671957672, 0.0, 0.48138888888888887, 0.1701156697215022, 0.14285714285714285, 0.4133891879080299, 0.6714285714285714, 1.0, 0.5867046457053328], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:11,975] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 109830: loss -10.9369
[2017-11-02 10:12:13,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   2.32630565e-29   7.95769818e-29   3.74305162e-30
   7.18065376e-30   3.06150943e-01   2.73137782e-02   5.40106475e-01
   1.26428738e-01], sum to 1.0000
[2017-11-02 10:12:14,046] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.9, 83.0, 3.6, 260.0, 0.0, 0.0, 1.100000000000001, 10.43175767794187, 25.0, 22.52836052555977, 21.5, 0.0, 44.65692749552393], 
actual action is [1.1, 25], 
sim time next is 2065800.0000, 
raw observation next is [-3.9, 82.66666666666667, 3.6, 260.0, 0.0, 0.0, 1.1, 10.30691085170349, 25.0, 22.56258304805082, 21.5, 0.0, 44.60363945732264], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.23333333333333334, 0.8266666666666667, 0.32727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5183333333333333, 0.10306910851703491, 1.0, 0.651797578292974, 0.5, 0.0, 0.5247486994979135], 
reward next is -0.4723. 
=============================================
[2017-11-02 10:12:16,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 110409: loss -3.3555
[2017-11-02 10:12:17,893] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7000, global step 110683: loss 2.2676
[2017-11-02 10:12:17,930] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.19869228
  0.01500683  0.76511329  0.02118758], sum to 1.0000
[2017-11-02 10:12:17,930] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7000, global step 110692: loss -10.0156
[2017-11-02 10:12:17,993] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.3, 84.66666666666666, 5.266666666666667, 246.6666666666667, 0.0, 0.0, 0.75, 10.10787569152676, 25.0, 22.68001396852133, 21.5, 0.0, 45.54896517580958], 
actual action is [0.7000000000000002, 25], 
sim time next is 2069100.0000, 
raw observation next is [-4.35, 85.0, 5.475, 245.0, 0.0, 0.0, 0.7000000000000002, 10.10881615036791, 25.0, 22.67528423746553, 21.5, 0.0, 45.68704109485509], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.2217948717948718, 0.85, 0.4977272727272727, 0.6805555555555556, 0.0, 0.0, 0.5116666666666666, 0.1010881615036791, 1.0, 0.6678977482093613, 0.5, 0.0, 0.5374946011159423], 
reward next is -0.4837. 
=============================================
[2017-11-02 10:12:19,026] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 110817: loss 2.7347
[2017-11-02 10:12:19,937] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-51.87228012]
 [-51.60419846]
 [-51.95064163]
 [-51.83728027]
 [-51.66189194]], R is [[-53.6178894 ]
 [-53.56760788]
 [-53.51712036]
 [-53.46664429]
 [-53.41647339]].
[2017-11-02 10:12:23,574] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111530: loss 4.7542
[2017-11-02 10:12:26,033] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111959: loss 1.2393
[2017-11-02 10:12:27,366] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7000, global step 112249: loss -25.7469
[2017-11-02 10:12:28,533] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.91832313e-26   1.91043543e-16   2.02429143e-15   2.56747889e-16
   2.10410197e-16   4.32279170e-01   1.01957142e-01   3.56626421e-01
   1.09137312e-01], sum to 1.0000
[2017-11-02 10:12:28,609] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.699999999999999, 80.91666666666666, 4.225, 245.8333333333333, 0.0, 0.0, -1.700000000000001, 22.47127097891705, 25.0, 19.73168611989851, 21.5, 0.0, 47.08063331930657], 
actual action is [-1.6999999999999993, 25], 
sim time next is 2097000.0000, 
raw observation next is [-6.7, 80.5, 4.05, 245.0, 0.0, 0.0, -1.699999999999999, 21.24685594343595, 25.0, 19.72443185392168, 21.5, 0.0, 54.25411735724764], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.16153846153846155, 0.805, 0.36818181818181817, 0.6805555555555556, 0.0, 0.0, 0.4716666666666667, 0.2124685594343595, 1.0, 0.24634740770309702, 0.5, 0.0, 0.638283733614678], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:28,963] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112592: loss -24.6178
[2017-11-02 10:12:28,998] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7000, global step 112601: loss -51.5588
[2017-11-02 10:12:30,142] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112794: loss -67.6392
[2017-11-02 10:12:30,256] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112811: loss -14.8253
[2017-11-02 10:12:32,073] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 113093: loss -108.4868
[2017-11-02 10:12:32,923] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 113212: loss 38.8291
[2017-11-02 10:12:33,668] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7000, global step 113296: loss 79.4063
[2017-11-02 10:12:34,141] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 113358: loss 120.3798
[2017-11-02 10:12:36,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   7.95335342e-14   6.58489322e-13   5.43579396e-13
   3.79271186e-13   1.61714056e-30   1.03395768e-30   1.46901209e-30
   8.95331804e-30], sum to 1.0000
[2017-11-02 10:12:36,884] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.8, 82.0, 2.625, 232.5, 148.5, 97.75, -2.8, 9.478383209526328, 25.0, 22.46330819035477, 22.7, 1.0, 64.08305555389978], 
actual action is [-2.8, 20.0], 
sim time next is 2107200.0000, 
raw observation next is [-7.8, 82.0, 2.666666666666667, 233.3333333333333, 157.0, 104.5, -2.8, 8.94329077948975, 20.0, 22.74691071021029, 22.7, 1.0, 62.0376136101712], 
processed observation next is [0.3333333333333333, 0.391304347826087, 0.13333333333333333, 0.82, 0.24242424242424246, 0.648148148148148, 0.41534391534391535, 0.1045, 0.4533333333333333, 0.0894329077948975, 0.2857142857142857, 0.6781301014586129, 0.6714285714285714, 1.0, 0.72985427776672], 
reward next is -0.6658. 
=============================================
[2017-11-02 10:12:47,261] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.13911866e-11   1.21003083e-10   5.75533891e-11
   3.92192667e-11   4.99570859e-27   3.03023526e-27   1.90671802e-27
   3.65147011e-26], sum to 1.0000
[2017-11-02 10:12:47,360] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.6, 75.0, 2.591666666666667, 259.1666666666666, 18.25, 109.1666666666667, -10.6, 20.33368631490176, 18.0, 20.79690411380507, 22.7, 1.0, 0.0], 
actual action is [-10.6, 18], 
sim time next is 2188800.0000, 
raw observation next is [-5.6, 75.0, 2.5, 260.0, 21.5, 131.0, -10.6, 22.17659986459895, 18.0, 20.74388772695224, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.34782608695652173, 0.18974358974358976, 0.75, 0.22727272727272727, 0.7222222222222222, 0.056878306878306875, 0.131, 0.3233333333333333, 0.22176599864598948, 0.0, 0.39198396099317734, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:50,679] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  3.39731701e-14   6.64346486e-12   2.05195947e-11   1.64407273e-11
   2.87436359e-11   9.98033676e-03   1.07217263e-02   5.84121309e-02
   9.20885861e-01], sum to 1.0000
[2017-11-02 10:12:50,728] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.35, 70.25, 6.925000000000001, 265.0, 136.5, 0.0, -9.4, 14.87646244917394, 18.0, 22.12988922644314, 22.7, 1.0, 0.0], 
actual action is [0.6500000000000004, 23.0], 
sim time next is 2200800.0000, 
raw observation next is [-4.300000000000001, 70.0, 6.833333333333334, 266.6666666666667, 138.6666666666667, 0.0, 0.6500000000000004, 14.00173942903718, 23.0, 22.10694840996847, 22.7, 1.0, 53.57036509952856], 
processed observation next is [0.5, 0.4782608695652174, 0.22307692307692306, 0.7, 0.6212121212121212, 0.7407407407407408, 0.3668430335097003, 0.0, 0.5108333333333334, 0.1400173942903718, 0.7142857142857143, 0.5867069157097815, 0.6714285714285714, 1.0, 0.6302395894062184], 
reward next is -0.5812. 
=============================================
[2017-11-02 10:12:51,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   1.20699089e-27   4.06852007e-27   1.65965857e-27
   3.59923296e-27   2.69687697e-02   1.76930279e-02   4.96849678e-02
   9.05653298e-01], sum to 1.0000
[2017-11-02 10:12:51,988] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 78.66666666666666, 3.0, 270.0, 0.0, 0.0, -1.2, 18.33569055981301, 25.0, 20.61801027350589, 21.5, 0.0, 46.9976499345468], 
actual action is [-1.2000000000000002, 25], 
sim time next is 2181600.0000, 
raw observation next is [-6.2, 79.0, 3.0, 270.0, 0.0, 0.0, -1.2, 17.99822874060989, 25.0, 20.64375300032563, 21.5, 0.0, 46.59504882796637], 
processed observation next is [0.5, 0.2608695652173913, 0.17435897435897435, 0.79, 0.2727272727272727, 0.75, 0.0, 0.0, 0.48000000000000004, 0.1799822874060989, 1.0, 0.3776790000465188, 0.5, 0.0, 0.5481770450348985], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:12:54,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99997139e-01   2.12695085e-07   1.23282291e-06   4.42834903e-07
   1.02736215e-06   2.49884377e-18   7.62616116e-19   9.01657990e-19
   3.10028022e-17], sum to 1.0000
[2017-11-02 10:12:54,965] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.3, 80.0, 3.6, 273.3333333333334, 0.0, 0.0, -12.3, 21.12135453860202, 18.0, 20.60616588168019, 21.5, 0.0, 0.0], 
actual action is [-12.3, 18], 
sim time next is 2162700.0000, 
raw observation next is [-7.3, 79.75, 3.6, 272.5, 0.0, 0.0, -12.3, 23.47472482524247, 18.0, 20.56041260337907, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.0, 0.14615384615384616, 0.7975, 0.32727272727272727, 0.7569444444444444, 0.0, 0.0, 0.295, 0.23474724825242468, 0.0, 0.36577322905415294, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:13:00,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-68.5300827 ]
 [-68.5275116 ]
 [-67.82234955]
 [-67.68682861]
 [-67.38568878]], R is [[-68.63578033]
 [-68.94942474]
 [-69.25993347]
 [-69.56733704]
 [-68.88570404]].
[2017-11-02 10:13:00,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02684219
  0.02035576  0.22885817  0.72394383], sum to 1.0000
[2017-11-02 10:13:00,691] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.616666666666667, 77.5, 5.85, 261.6666666666667, 0.0, 0.0, -11.575, 18.01979132306944, 18.0, 21.46581455932414, 21.5, 0.0, 0.0], 
actual action is [-1.6166666666666671, 20.0], 
sim time next is 2246100.0000, 
raw observation next is [-6.658333333333333, 77.75, 5.975, 260.8333333333333, 0.0, 0.0, -1.616666666666667, 17.26958870833159, 20.0, 21.31721046568787, 21.5, 0.0, 58.28116841246906], 
processed observation next is [0.5, 1.0, 0.1626068376068376, 0.7775, 0.5431818181818181, 0.724537037037037, 0.0, 0.0, 0.47305555555555556, 0.1726958870833159, 0.2857142857142857, 0.47388720938398166, 0.5, 0.0, 0.6856608048525772], 
reward next is -0.6432. 
=============================================
[2017-11-02 10:13:01,841] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 117714: loss -5.5621
[2017-11-02 10:13:04,611] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.57048713e-11   3.69422315e-09   3.07160430e-09   2.46810328e-09
   5.95328498e-09   4.22515087e-02   4.85659316e-02   6.46797776e-01
   2.62384772e-01], sum to 1.0000
[2017-11-02 10:13:04,670] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 69.75, 6.949999999999999, 262.5, 0.0, 0.0, 0.0, 11.51583748343992, 20.0, 22.52380562579543, 21.5, 0.0, 47.21886346146639], 
actual action is [0.0, 22.0], 
sim time next is 2233800.0000, 
raw observation next is [-5.0, 69.5, 6.9, 265.0, 0.0, 0.0, 0.0, 11.53719823676332, 22.0, 22.55124004103997, 21.5, 0.0, 41.55074263599816], 
processed observation next is [0.5, 0.8695652173913043, 0.20512820512820512, 0.695, 0.6272727272727273, 0.7361111111111112, 0.0, 0.0, 0.5, 0.1153719823676332, 0.5714285714285714, 0.6501771487199959, 0.5, 0.0, 0.48883226630586074], 
reward next is -0.4399. 
=============================================
[2017-11-02 10:13:04,717] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   3.71013498e-10   4.65184780e-10   6.95432711e-10
   8.46205550e-10   1.47836272e-20   1.15931835e-20   1.51216965e-19
   7.76168449e-20], sum to 1.0000
[2017-11-02 10:13:04,868] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.775, 67.25, 5.975, 277.5, 131.75, 0.0, 1.183333333333334, 10.31932658922165, 20.0, 22.89137439158586, 22.7, 1.0, 51.49235614495576], 
actual action is [-8.775, 18], 
sim time next is 2204400.0000, 
raw observation next is [-3.733333333333333, 67.0, 5.933333333333334, 276.6666666666667, 130.5, 0.0, -8.775, 11.36481933667319, 18.0, 22.94329781333767, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.5217391304347826, 0.23760683760683762, 0.67, 0.5393939393939394, 0.7685185185185186, 0.34523809523809523, 0.0, 0.35375, 0.11364819336673189, 0.0, 0.7061854019053813, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0114. 
=============================================
[2017-11-02 10:13:05,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02277047
  0.02984731  0.91462934  0.03275285], sum to 1.0000
[2017-11-02 10:13:05,528] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 76.25, 4.933333333333333, 265.8333333333333, 0.0, 0.0, -1.7, 14.318038732052, 25.0, 21.58271150837266, 21.5, 0.0, 46.94711318370394], 
actual action is [-1.7000000000000002, 25], 
sim time next is 2248800.0000, 
raw observation next is [-6.700000000000001, 76.0, 4.766666666666667, 266.6666666666667, 0.0, 0.0, -1.7, 14.21912835617539, 25.0, 21.59456967918205, 21.5, 0.0, 46.80233178535507], 
processed observation next is [0.6666666666666666, 0.0, 0.16153846153846152, 0.76, 0.43333333333333335, 0.7407407407407408, 0.0, 0.0, 0.4716666666666667, 0.1421912835617539, 1.0, 0.5135099541688645, 0.5, 0.0, 0.5506156680630009], 
reward next is -0.4956. 
=============================================
[2017-11-02 10:13:06,081] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 118239: loss -0.2898
[2017-11-02 10:13:07,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-54.37002182]
 [-54.61729813]
 [-54.28763962]
 [-55.08122635]
 [-53.79742813]], R is [[-55.32396317]
 [-55.77072525]
 [-56.21302032]
 [-56.65089035]
 [-57.0843811 ]].
[2017-11-02 10:13:08,134] A3C_AGENT_WORKER-Thread-8 INFO:Local step 7500, global step 118479: loss 0.8331
[2017-11-02 10:13:09,380] A3C_AGENT_WORKER-Thread-6 INFO:Local step 7500, global step 118651: loss 1.0003
[2017-11-02 10:13:09,446] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 118658: loss 0.1050
[2017-11-02 10:13:13,010] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-43.04409409]
 [-42.77671432]
 [-43.44225693]
 [-42.56076813]
 [-42.47411346]], R is [[-43.4826889 ]
 [-43.57704163]
 [-43.67392731]
 [-43.76473236]
 [-43.85768127]].
[2017-11-02 10:13:16,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  4.68541079e-29   4.10819865e-20   2.96372383e-20   1.76594385e-20
   6.27496951e-20   4.46501235e-03   2.93446898e-01   6.34524524e-01
   6.75635636e-02], sum to 1.0000
[2017-11-02 10:13:16,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.5, 68.5, 6.016666666666666, 276.6666666666667, 0.0, 0.0, 0.5, 11.37840066692846, 20.0, 22.52115562996395, 22.7, 1.0, 63.26064616455421], 
actual action is [0.5, 22.0], 
sim time next is 2224500.0000, 
raw observation next is [-4.5, 68.25, 6.058333333333333, 278.3333333333333, 0.0, 0.0, 0.5, 11.3731759819051, 22.0, 22.51931903036435, 22.7, 1.0, 37.39638565980915], 
processed observation next is [0.5, 0.7391304347826086, 0.21794871794871795, 0.6825, 0.5507575757575757, 0.7731481481481481, 0.0, 0.0, 0.5083333333333333, 0.113731759819051, 0.5714285714285714, 0.6456170043377644, 0.6714285714285714, 1.0, 0.4399574783506959], 
reward next is -0.4073. 
=============================================
[2017-11-02 10:13:17,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119868: loss 38.7036
[2017-11-02 10:13:18,997] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00357645
  0.0656624   0.81223136  0.11852971], sum to 1.0000
[2017-11-02 10:13:19,050] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.7, 77.25, 5.6, 262.5, 0.0, 0.0, -1.700000000000001, 12.26149619239217, 20.0, 21.97741322084285, 21.5, 0.0, 59.35233586359587], 
actual action is [-1.7000000000000002, 22.0], 
sim time next is 2247600.0000, 
raw observation next is [-6.700000000000001, 77.0, 5.433333333333334, 263.3333333333334, 0.0, 0.0, -1.7, 12.29318797178467, 22.0, 21.91730286094128, 21.5, 0.0, 38.54353905425925], 
processed observation next is [0.6666666666666666, 0.0, 0.16153846153846152, 0.77, 0.49393939393939396, 0.7314814814814817, 0.0, 0.0, 0.4716666666666667, 0.1229318797178467, 0.5714285714285714, 0.5596146944201829, 0.5, 0.0, 0.4534534006383441], 
reward next is -0.4081. 
=============================================
[2017-11-02 10:13:19,831] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120208: loss -16.8166
[2017-11-02 10:13:20,034] A3C_AGENT_WORKER-Thread-5 INFO:Local step 7500, global step 120235: loss -21.2964
[2017-11-02 10:13:21,782] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120534: loss -30.2445
[2017-11-02 10:13:22,389] A3C_AGENT_WORKER-Thread-4 INFO:Local step 7500, global step 120669: loss -15.5582
[2017-11-02 10:13:23,568] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120883: loss 8.8352
[2017-11-02 10:13:23,613] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120890: loss 2.8783
[2017-11-02 10:13:23,684] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120905: loss 39.1846
[2017-11-02 10:13:25,192] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 121171: loss -0.5272
[2017-11-02 10:13:25,889] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 121283: loss 0.1227
[2017-11-02 10:13:26,263] A3C_AGENT_WORKER-Thread-7 INFO:Local step 7500, global step 121333: loss 0.7055
[2017-11-02 10:13:30,511] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00199777
  0.9115994   0.07232747  0.01407534], sum to 1.0000
[2017-11-02 10:13:30,637] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.2, 53.0, 2.0, 235.0, 0.0, 0.0, 3.8, 7.854263864564979, 18.5, 23.71838728139478, 22.7, 1.0, 52.16737927454468], 
actual action is [3.8, 19.5], 
sim time next is 2313300.0000, 
raw observation next is [-1.2, 53.16666666666667, 2.0, 237.5, 0.0, 0.0, 3.8, 7.943225388870391, 19.5, 23.62743522241846, 22.7, 1.0, 37.1639682000123], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3025641025641026, 0.5316666666666667, 0.18181818181818182, 0.6597222222222222, 0.0, 0.0, 0.5633333333333332, 0.07943225388870391, 0.21428571428571427, 0.8039193174883513, 0.6714285714285714, 1.0, 0.43722315529426237], 
reward next is -0.4014. 
=============================================
[2017-11-02 10:13:34,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  0.00000000e+00   7.82349384e-32   6.44722446e-32   3.62872608e-32
   1.76412797e-31   3.54530080e-03   9.75006640e-01   1.23343505e-02
   9.11367312e-03], sum to 1.0000
[2017-11-02 10:13:34,484] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.116666666666667, 85.5, 2.916666666666667, 271.6666666666667, 82.33333333333334, 31.33333333333334, -3.258333333333333, 10.64155928377467, 19.0, 22.50043111604463, 22.7, 1.0, 70.20794034401523], 
actual action is [-3.116666666666667, 20.0], 
sim time next is 2279700.0000, 
raw observation next is [-7.975000000000001, 84.75, 2.875, 267.5, 87.0, 33.25, -3.116666666666667, 10.41760063453642, 20.0, 22.58245626928778, 22.7, 1.0, 46.04425789518248], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.1288461538461538, 0.8475, 0.26136363636363635, 0.7430555555555556, 0.23015873015873015, 0.03325, 0.44805555555555554, 0.1041760063453642, 0.2857142857142857, 0.654636609898254, 0.6714285714285714, 1.0, 0.5416971517080292], 
reward next is -0.4979. 
=============================================
[2017-11-02 10:13:34,824] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00400975
  0.98169345  0.01152638  0.00277036], sum to 1.0000
[2017-11-02 10:13:34,895] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.7, 54.5, 1.125, 202.5, 0.0, 0.0, 3.3, 8.02001849718301, 23.0, 23.5324261013015, 21.5, 0.0, 27.57537286797765], 
actual action is [3.3, 24.0], 
sim time next is 2323200.0000, 
raw observation next is [-1.7, 54.66666666666667, 1.0, 180.0, 0.0, 0.0, 3.3, 8.115657715678186, 24.0, 23.51143329880083, 21.5, 0.0, 26.48056335098547], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.28974358974358977, 0.5466666666666667, 0.09090909090909091, 0.5, 0.0, 0.0, 0.5549999999999999, 0.08115657715678186, 0.8571428571428571, 0.7873476141144045, 0.5, 0.0, 0.31153603942335845], 
reward next is -0.2804. 
=============================================
[2017-11-02 10:13:41,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  3.00447063e-08   3.10893782e-08   7.36097494e-09   9.16479603e-09
   1.78820265e-08   1.14274956e-02   9.56138015e-01   1.69921387e-02
   1.54422736e-02], sum to 1.0000
[2017-11-02 10:13:41,215] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.7833333333333332, 46.0, 2.083333333333333, 211.6666666666667, 187.6666666666667, 66.0, -5.875, 13.30956264939642, 18.0, 22.26779280632314, 22.7, 1.0, 0.0], 
actual action is [4.216666666666667, 19.0], 
sim time next is 2296500.0000, 
raw observation next is [-0.6916666666666667, 45.5, 2.041666666666667, 210.8333333333333, 179.3333333333333, 65.25, 4.216666666666667, 12.85400032315918, 19.0, 22.22642824221891, 22.7, 1.0, 25.83199271648226], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.3155982905982906, 0.455, 0.18560606060606064, 0.585648148148148, 0.47442680776014096, 0.06525, 0.5702777777777778, 0.12854000323159182, 0.14285714285714285, 0.6037754631741298, 0.6714285714285714, 1.0, 0.3039057966644972], 
reward next is -0.2864. 
=============================================
[2017-11-02 10:13:47,304] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.13473054e-12   1.24936433e-12   2.09190846e-12
   3.91823076e-12   1.48449540e-26   9.05710850e-27   7.98309302e-26
   9.32296387e-27], sum to 1.0000
[2017-11-02 10:13:47,384] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.633333333333333, 64.0, 5.433333333333334, 60.0, 136.0, 435.0, -7.675, 14.64421244081161, 18.0, 21.54530664623903, 22.7, 1.0, 0.0], 
actual action is [-7.633333333333333, 18], 
sim time next is 2370300.0000, 
raw observation next is [-2.591666666666666, 63.75, 5.516666666666666, 57.5, 137.5, 442.5, -7.633333333333333, 15.64290214537621, 18.0, 21.65899807068274, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.43478260869565216, 0.26688034188034193, 0.6375, 0.5015151515151515, 0.1597222222222222, 0.3637566137566138, 0.4425, 0.37277777777777776, 0.1564290214537621, 0.0, 0.522714010097534, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:13:48,069] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 125042: loss 11.8795
[2017-11-02 10:13:52,213] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 126023: loss -193.5075
[2017-11-02 10:13:52,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.04198989
  0.06501935  0.7370556   0.15593523], sum to 1.0000
[2017-11-02 10:13:52,457] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.3, 62.5, 2.416666666666667, 26.66666666666667, 0.0, 0.0, 2.7, 16.00393357088811, 20.0, 21.366304811437, 21.5, 0.0, 54.32382725332126], 
actual action is [2.7, 21.0], 
sim time next is 2336100.0000, 
raw observation next is [-2.3, 62.25, 2.458333333333333, 28.33333333333333, 0.0, 0.0, 2.7, 15.72456069819457, 21.0, 21.40541964826252, 21.5, 0.0, 34.22440473121391], 
processed observation next is [0.8333333333333334, 0.0, 0.27435897435897433, 0.6225, 0.22348484848484845, 0.07870370370370369, 0.0, 0.0, 0.545, 0.1572456069819457, 0.42857142857142855, 0.4864885211803599, 0.5, 0.0, 0.4026400556613401], 
reward next is -0.3759. 
=============================================
[2017-11-02 10:13:55,055] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8000, global step 126529: loss 38.3153
[2017-11-02 10:13:56,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 126727: loss 77.6087
[2017-11-02 10:13:56,973] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8000, global step 126827: loss 62.5713
[2017-11-02 10:14:01,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   6.38675744e-12   6.27185424e-13   6.00163452e-12
   5.37064403e-12   4.40603630e-29   4.81668940e-29   9.46521924e-29
   5.29781805e-27], sum to 1.0000
[2017-11-02 10:14:01,496] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.3, 68.33333333333333, 5.516666666666667, 70.0, 93.0, 240.0, 1.65, 13.85627087923801, 23.0, 21.88723846689305, 22.7, 1.0, 59.94440781473313], 
actual action is [-8.3, 18.0], 
sim time next is 2366100.0000, 
raw observation next is [-3.25, 68.0, 5.475, 70.0, 100.0, 270.0, -8.3, 15.17075063045326, 18.0, 21.90133597320378, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.25, 0.68, 0.4977272727272727, 0.19444444444444445, 0.26455026455026454, 0.27, 0.36166666666666664, 0.15170750630453259, 0.0, 0.5573337104576827, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:04,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-56.5346756 ]
 [-57.08356476]
 [-56.95478439]
 [-55.81662369]
 [-56.57408905]], R is [[-57.79166412]
 [-58.21374893]
 [-58.63161087]
 [-59.04529572]
 [-59.45484161]].
[2017-11-02 10:14:06,361] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8000, global step 128188: loss 38.7763
[2017-11-02 10:14:06,625] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128239: loss -8.9891
[2017-11-02 10:14:08,596] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128566: loss 28.8767
[2017-11-02 10:14:08,855] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8000, global step 128605: loss 39.3974
[2017-11-02 10:14:09,874] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128774: loss 24.4987
[2017-11-02 10:14:11,194] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 129000: loss 0.1817
[2017-11-02 10:14:11,797] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 129094: loss 12.4191
[2017-11-02 10:14:11,875] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 129110: loss -42.0748
[2017-11-02 10:14:12,622] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 129220: loss 47.5465
[2017-11-02 10:14:13,114] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8000, global step 129296: loss -71.6911
[2017-11-02 10:14:13,477] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 129353: loss -23.1916
[2017-11-02 10:14:19,555] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.76625957e-24   1.64217679e-16   2.35037994e-17   7.50926074e-17
   1.07676873e-16   4.77205038e-01   9.15530045e-03   1.60910636e-01
   3.52729023e-01], sum to 1.0000
[2017-11-02 10:14:19,614] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-9.5, 59.75, 3.808333333333333, 64.16666666666666, 0.0, 0.0, -4.5, 21.57339486896891, 25.0, 20.06971504895785, 21.5, 0.0, 46.78024637499787], 
actual action is [-4.5, 25], 
sim time next is 2446200.0000, 
raw observation next is [-9.5, 59.5, 3.85, 65.0, 0.0, 0.0, -4.5, 21.56363100135659, 25.0, 20.08133967537539, 21.5, 0.0, 46.80345165396488], 
processed observation next is [1.0, 0.30434782608695654, 0.08974358974358974, 0.595, 0.35000000000000003, 0.18055555555555555, 0.0, 0.0, 0.425, 0.2156363100135659, 1.0, 0.29733423933934133, 0.5, 0.0, 0.5506288429878221], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:26,127] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.08849599e-15   3.26805799e-16   5.02333355e-15
   1.34896212e-15   0.00000000e+00   0.00000000e+00   6.28290944e-38
   2.21069729e-38], sum to 1.0000
[2017-11-02 10:14:26,178] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.666666666666666, 51.33333333333334, 4.516666666666666, 70.0, 47.0, 499.0, -2.85, 19.23282871678771, 20.5, 20.90384738173395, 22.7, 1.0, 51.89392208206362], 
actual action is [-12.666666666666666, 18], 
sim time next is 2451300.0000, 
raw observation next is [-7.483333333333333, 50.66666666666666, 4.558333333333333, 70.0, 48.75, 519.75, -12.66666666666667, 20.80626696114292, 18.0, 20.93683000824683, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.34782608695652173, 0.14145299145299145, 0.5066666666666666, 0.4143939393939393, 0.19444444444444445, 0.12896825396825398, 0.51975, 0.2888888888888888, 0.20806266961142922, 0.0, 0.41954714403526133, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:33,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 132776: loss 58.8766
[2017-11-02 10:14:33,047] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   9.36503477e-29   5.72772054e-30   1.97600051e-29
   3.07500054e-29   1.87592596e-01   3.06189768e-02   5.81700623e-01
   2.00087786e-01], sum to 1.0000
[2017-11-02 10:14:33,118] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 57.0, 2.25, 75.0, 0.0, 0.0, 2.7, 12.33433412285879, 20.0, 21.74201609633239, 21.5, 0.0, 47.30412609198257], 
actual action is [2.7, 25.0], 
sim time next is 2524800.0000, 
raw observation next is [-2.3, 57.00000000000001, 2.333333333333333, 76.66666666666667, 0.0, 0.0, 2.7, 12.31503145199308, 25.0, 21.72013125989242, 21.5, 0.0, 32.50538961650875], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.5700000000000001, 0.2121212121212121, 0.21296296296296297, 0.0, 0.0, 0.545, 0.1231503145199308, 1.0, 0.5314473228417741, 0.5, 0.0, 0.3824163484295147], 
reward next is -0.3442. 
=============================================
[2017-11-02 10:14:37,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  2.50685407e-04   5.93941841e-05   7.73137253e-06   3.93855589e-05
   2.22238068e-05   3.55282485e-01   6.99101835e-02   3.94873351e-01
   1.79554567e-01], sum to 1.0000
[2017-11-02 10:14:37,815] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.05, 33.5, 4.449999999999999, 60.0, 0.0, 0.0, 3.9, 15.20854187862816, 18.5, 21.8952739575291, 21.5, 0.0, 53.48148797101806], 
actual action is [3.95, 20.5], 
sim time next is 2499600.0000, 
raw observation next is [-1.0, 33.66666666666667, 4.233333333333333, 60.00000000000001, 0.0, 0.0, 3.95, 14.91465065230513, 20.5, 21.93558335301122, 21.5, 0.0, 33.3956454561098], 
processed observation next is [1.0, 0.9565217391304348, 0.3076923076923077, 0.3366666666666667, 0.38484848484848483, 0.16666666666666669, 0.0, 0.0, 0.5658333333333334, 0.1491465065230513, 0.35714285714285715, 0.5622261932873174, 0.5, 0.0, 0.3928899465424682], 
reward next is -0.3536. 
=============================================
[2017-11-02 10:14:38,217] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 134073: loss 8.2070
[2017-11-02 10:14:38,541] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-36.10106277]
 [-35.07095718]
 [-35.2112236 ]
 [-35.52928162]
 [-35.37573242]], R is [[-35.19832993]
 [-34.84634781]
 [-34.84957123]
 [-35.08029556]
 [-34.72949219]].
[2017-11-02 10:14:39,009] A3C_AGENT_WORKER-Thread-6 INFO:Local step 8500, global step 134299: loss 19.4001
[2017-11-02 10:14:39,671] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 134497: loss 72.2554
[2017-11-02 10:14:40,517] A3C_AGENT_WORKER-Thread-8 INFO:Local step 8500, global step 134758: loss -114.5018
[2017-11-02 10:14:41,846] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.75739043e-10   9.75437370e-11   4.93210917e-10
   1.66979000e-10   2.22457446e-20   4.43940676e-22   1.23797737e-21
   3.48474294e-22], sum to 1.0000
[2017-11-02 10:14:41,860] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.05, 33.5, 4.725, 92.5, 0.0, 0.0, -3.766666666666667, 16.25261135066221, 18.0, 21.78686307036512, 22.7, 1.0, 0.0], 
actual action is [-3.95, 18], 
sim time next is 2569800.0000, 
raw observation next is [0.8666666666666667, 34.0, 4.683333333333333, 64.99999999999999, 0.0, 0.0, -3.95, 16.83881383771971, 18.0, 21.72356693192492, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.35555555555555557, 0.34, 0.4257575757575757, 0.18055555555555552, 0.0, 0.0, 0.4341666666666667, 0.1683881383771971, 0.0, 0.5319381331321316, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:44,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135944: loss -37.2024
[2017-11-02 10:14:45,117] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.08707062
  0.01209635  0.3809281   0.51990485], sum to 1.0000
[2017-11-02 10:14:45,185] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.883333333333333, 46.0, 3.683333333333333, 325.0, 0.0, 0.0, 3.208333333333333, 21.35594597039704, 20.0, 20.05627115101867, 21.5, 0.0, 38.43173903428384], 
actual action is [3.116666666666667, 22.0], 
sim time next is 2578500.0000, 
raw observation next is [-1.975, 47.0, 3.725, 322.5, 0.0, 0.0, 3.116666666666667, 19.73614506969369, 22.0, 20.34017021248508, 21.5, 0.0, 45.93025333080698], 
processed observation next is [0.0, 0.8695652173913043, 0.2826923076923077, 0.47, 0.3386363636363636, 0.8958333333333334, 0.0, 0.0, 0.5519444444444445, 0.19736145069693692, 0.5714285714285714, 0.33431003035501156, 0.5, 0.0, 0.5403559215389057], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:46,179] A3C_AGENT_WORKER-Thread-5 INFO:Local step 8500, global step 136217: loss -55.6473
[2017-11-02 10:14:48,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136538: loss 40.5303
[2017-11-02 10:14:49,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   1.30200822e-16   2.92867366e-17   5.80677349e-16
   1.53170794e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:14:49,377] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.9, 80.5, 5.1, 240.0, 0.0, 0.0, -0.8499999999999996, 19.6417807137577, 25.0, 20.44529213759629, 21.5, 0.0, 43.43348027403177], 
actual action is [-0.9000000000000004, 20.0], 
sim time next is 2608500.0000, 
raw observation next is [-5.95, 80.91666666666667, 5.1, 240.0, 0.0, 0.0, -0.9000000000000004, 19.30509746045245, 20.0, 20.48376237533266, 21.5, 0.0, 47.18838621166054], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.18076923076923077, 0.8091666666666667, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.48500000000000004, 0.1930509746045245, 0.2857142857142857, 0.3548231964760942, 0.5, 0.0, 0.5551574848430653], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:14:49,883] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  5.09804421e-10   3.19415037e-08   3.76214793e-09   4.11126955e-08
   3.29594556e-08   1.55050486e-01   1.01325596e-02   6.15507253e-02
   7.73266196e-01], sum to 1.0000
[2017-11-02 10:14:50,046] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 54.66666666666667, 2.0, 26.66666666666667, 43.5, 15.0, 2.2, 16.24874293676829, 25.0, 21.22909827305193, 22.7, 1.0, 76.85943367621735], 
actual action is [2.2, 25], 
sim time next is 2535900.0000, 
raw observation next is [-2.8, 54.83333333333333, 2.0, 25.83333333333333, 47.25, 16.5, 2.2, 14.29775740871445, 25.0, 21.45949315681691, 22.7, 1.0, 68.2429474049493], 
processed observation next is [0.0, 0.34782608695652173, 0.2615384615384615, 0.5483333333333333, 0.18181818181818182, 0.07175925925925924, 0.125, 0.0165, 0.5366666666666667, 0.1429775740871445, 1.0, 0.49421330811670167, 0.6714285714285714, 1.0, 0.8028582047641095], 
reward next is -0.7369. 
=============================================
[2017-11-02 10:14:51,062] A3C_AGENT_WORKER-Thread-4 INFO:Local step 8500, global step 137074: loss 44.3058
[2017-11-02 10:14:51,301] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 137124: loss 12.8031
[2017-11-02 10:14:51,815] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 137226: loss -10.1945
[2017-11-02 10:14:51,905] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 137241: loss 30.3580
[2017-11-02 10:14:52,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 137288: loss 1.0658
[2017-11-02 10:14:52,951] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 137500: loss 29.1609
[2017-11-02 10:14:53,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.95749167e-10   5.95163988e-11   4.74229434e-10
   2.14169849e-10   1.36435349e-22   2.87401371e-23   5.51787188e-23
   4.11066961e-22], sum to 1.0000
[2017-11-02 10:14:53,585] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.3, 29.0, 4.199999999999999, 347.5, 103.0, 303.75, -1.7, 12.61566035932446, 18.0, 23.04839848689596, 22.7, 1.0, 0.0], 
actual action is [-1.7000000000000002, 18], 
sim time next is 2562600.0000, 
raw observation next is [3.3, 29.0, 4.333333333333333, 348.3333333333334, 99.33333333333334, 288.0, -1.7, 12.69689162516293, 18.0, 23.03381910891022, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.41794871794871796, 0.29, 0.3939393939393939, 0.9675925925925929, 0.2627865961199295, 0.288, 0.4716666666666667, 0.12696891625162932, 0.0, 0.7191170155586027, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0127. 
=============================================
[2017-11-02 10:14:53,873] A3C_AGENT_WORKER-Thread-7 INFO:Local step 8500, global step 137756: loss -10.8240
[2017-11-02 10:14:54,797] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 138003: loss 6.8281
[2017-11-02 10:15:05,813] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   4.44445514e-15   1.93986173e-15   4.98407298e-14
   1.45159933e-14   3.08321679e-36   6.30420772e-37   1.08089159e-36
   4.17442197e-34], sum to 1.0000
[2017-11-02 10:15:05,862] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.149999999999999, 78.75, 6.374999999999999, 237.5, 0.0, 0.0, -2.1, 19.13698287769955, 25.0, 20.53063859614546, 21.5, 0.0, 36.34618297367916], 
actual action is [-2.1499999999999986, 20.0], 
sim time next is 2616600.0000, 
raw observation next is [-7.199999999999999, 78.83333333333334, 6.283333333333333, 235.0, 0.0, 0.0, -2.149999999999999, 19.24049442980801, 20.0, 20.52261298654609, 21.5, 0.0, 43.4727631424124], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.14871794871794874, 0.7883333333333334, 0.5712121212121212, 0.6527777777777778, 0.0, 0.0, 0.46416666666666667, 0.19240494429808008, 0.2857142857142857, 0.36037328379229855, 0.5, 0.0, 0.5114442722636753], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:08,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[-88.58201599]
 [-88.64775085]
 [-89.62199402]
 [-87.08802032]
 [-86.20114899]], R is [[-86.6653595 ]
 [-86.79870605]
 [-86.93071747]
 [-87.061409  ]
 [-87.1907959 ]].
[2017-11-02 10:15:08,465] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.88825210e-03   1.93510292e-04   6.09109586e-04
   9.97309089e-01], sum to 1.0000
[2017-11-02 10:15:08,562] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.658333333333333, 78.41666666666667, 7.024999999999999, 258.3333333333333, 0.0, 0.0, -11.61666666666667, 21.06587223915611, 18.0, 20.73578838293596, 21.5, 0.0, 0.0], 
actual action is [-1.6583333333333332, 23.0], 
sim time next is 2613600.0000, 
raw observation next is [-6.7, 78.0, 7.2, 260.0, 0.0, 0.0, -1.658333333333333, 20.0011976594241, 23.0, 20.58574292554865, 21.5, 0.0, 64.94043206426804], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.16153846153846155, 0.78, 0.6545454545454545, 0.7222222222222222, 0.0, 0.0, 0.4723611111111111, 0.200011976594241, 0.7142857142857143, 0.3693918465069501, 0.5, 0.0, 0.7640050831090357], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:09,157] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 140654: loss -19.2774
[2017-11-02 10:15:09,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  3.45307899e-26   2.91785990e-20   2.89224852e-21   7.15071790e-20
   8.99532485e-20   2.48477049e-03   6.38102822e-04   1.52141473e-03
   9.95355725e-01], sum to 1.0000
[2017-11-02 10:15:10,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.816666666666666, 64.5, 7.449999999999999, 223.3333333333333, 132.3333333333333, 213.6666666666667, -9.908333333333333, 13.5144562708643, 18.0, 22.73072546874164, 22.7, 1.0, 0.0], 
actual action is [0.18333333333333357, 23.0], 
sim time next is 2628900.0000, 
raw observation next is [-4.725, 64.25, 7.575, 225.0, 137.25, 229.0, 0.1833333333333336, 11.92994697930802, 23.0, 22.62974136952487, 22.7, 1.0, 78.86241533319823], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.21217948717948718, 0.6425, 0.6886363636363636, 0.625, 0.3630952380952381, 0.229, 0.5030555555555556, 0.1192994697930802, 0.7142857142857143, 0.6613916242178384, 0.6714285714285714, 1.0, 0.927793121567038], 
reward next is -0.8469. 
=============================================
[2017-11-02 10:15:14,662] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.94216149e-13   9.21648283e-14   2.29498929e-12
   8.72436455e-13   5.67329387e-25   2.12701872e-25   8.33206721e-26
   6.92375427e-25], sum to 1.0000
[2017-11-02 10:15:14,673] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.991666666666667, 62.25, 8.575, 238.3333333333333, 182.0, 231.6666666666667, -9.083333333333332, 15.09605561933375, 18.0, 22.59456913128522, 22.7, 1.0, 0.0], 
actual action is [-8.991666666666667, 18], 
sim time next is 2631600.0000, 
raw observation next is [-3.9, 62.0, 8.7, 240.0, 188.0, 223.0, -8.991666666666667, 15.66365322171692, 18.0, 22.49370439216415, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.23333333333333334, 0.62, 0.7909090909090909, 0.6666666666666666, 0.4973544973544973, 0.223, 0.3501388888888889, 0.1566365322171692, 0.0, 0.6419577703091645, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:18,208] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9000, global step 142251: loss -77.0778
[2017-11-02 10:15:18,809] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 142409: loss -5.3044
[2017-11-02 10:15:18,970] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   7.64197493e-17   9.70264330e-18   4.41001722e-16
   1.14087701e-16   3.26379968e-37   9.39614005e-38   5.49847769e-38
   1.17591732e-37], sum to 1.0000
[2017-11-02 10:15:18,991] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 7.475, 231.6666666666667, 69.33333333333333, 120.5, -4.5, 14.28583469930246, 18.0, 22.50366248037079, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 2652000.0000, 
raw observation next is [0.5, 50.0, 7.299999999999999, 233.3333333333333, 63.66666666666666, 117.0, -4.5, 14.66753549449563, 18.0, 22.43890349881494, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.34615384615384615, 0.5, 0.6636363636363636, 0.648148148148148, 0.16843033509700173, 0.117, 0.425, 0.1466753549449563, 0.0, 0.6341290712592773, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 10:15:19,388] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 142565: loss -123.1611
[2017-11-02 10:15:19,891] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   6.23089930e-16   2.05485799e-16   5.01812388e-15
   1.78414192e-15   3.29218832e-35   2.78009494e-35   1.45298535e-35
   2.89427441e-34], sum to 1.0000
[2017-11-02 10:15:19,917] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 6.6, 240.0, 41.0, 103.0, 5.5, 15.55527165242131, 23.0, 21.8031480790496, 22.7, 1.0, 43.64367414695609], 
actual action is [-4.5, 18.0], 
sim time next is 2653500.0000, 
raw observation next is [0.4083333333333333, 50.33333333333333, 6.475, 239.1666666666667, 35.33333333333333, 99.5, -4.5, 16.61131094023747, 18.0, 21.83655335557303, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.3438034188034188, 0.5033333333333333, 0.5886363636363636, 0.664351851851852, 0.09347442680776012, 0.0995, 0.425, 0.1661131094023747, 0.0, 0.5480790507961473, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:20,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.29399836e-04   7.11958055e-05   1.34378515e-05   1.95095767e-04
   1.54710709e-04   2.33882628e-02   3.48622352e-02   2.72486843e-02
   9.13936973e-01], sum to 1.0000
[2017-11-02 10:15:20,816] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 62.0, 7.999999999999999, 240.0, 0.0, 0.0, 3.8, 17.07933577831741, 25.0, 21.23473805302113, 22.7, 1.0, 71.74523364036565], 
actual action is [3.8, 25], 
sim time next is 2663100.0000, 
raw observation next is [-1.2, 62.25, 8.174999999999999, 240.0, 0.0, 0.0, 3.8, 15.38827693681567, 25.0, 21.35253771407197, 22.7, 1.0, 74.3636399517622], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3025641025641026, 0.6225, 0.743181818181818, 0.6666666666666666, 0.0, 0.0, 0.5633333333333332, 0.1538827693681567, 1.0, 0.47893395915313874, 0.6714285714285714, 1.0, 0.8748663523736729], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:22,137] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9000, global step 142992: loss -6.5401
[2017-11-02 10:15:23,027] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-63.64768982]
 [-62.55807877]
 [-64.06117249]
 [-64.06697083]
 [-63.32047653]], R is [[-64.88238525]
 [-64.74172974]
 [-64.6129303 ]
 [-64.48628998]
 [-64.29928589]].
[2017-11-02 10:15:26,344] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143548: loss -161.1622
[2017-11-02 10:15:26,909] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9000, global step 143657: loss -49.0784
[2017-11-02 10:15:29,087] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144035: loss -121.9077
[2017-11-02 10:15:31,741] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144550: loss 18.6129
[2017-11-02 10:15:32,246] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144642: loss -392.1910
[2017-11-02 10:15:32,247] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144642: loss 30.3848
[2017-11-02 10:15:32,493] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9000, global step 144682: loss 206.2199
[2017-11-02 10:15:34,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144990: loss -159.1192
[2017-11-02 10:15:34,637] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9000, global step 145029: loss 21.7805
[2017-11-02 10:15:34,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  6.85134941e-27   4.46491845e-17   1.01994579e-17   5.98258907e-17
   7.17052350e-18   1.01301225e-03   1.14736408e-02   2.77794302e-01
   7.09719062e-01], sum to 1.0000
[2017-11-02 10:15:34,747] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.0, 59.0, 1.5, 70.0, 0.0, 0.0, -1.0, 17.04108788829262, 25.0, 20.97161896711858, 21.5, 0.0, 45.62846441951908], 
actual action is [-1.0, 25], 
sim time next is 2775900.0000, 
raw observation next is [-6.0, 58.99999999999999, 1.591666666666667, 69.16666666666666, 0.0, 0.0, -1.0, 16.60981096899501, 25.0, 21.04643154128109, 21.5, 0.0, 44.84292601364908], 
processed observation next is [0.5, 0.13043478260869565, 0.1794871794871795, 0.59, 0.14469696969696974, 0.1921296296296296, 0.0, 0.0, 0.48333333333333334, 0.1660981096899501, 1.0, 0.43520450589729875, 0.5, 0.0, 0.527563835454695], 
reward next is -0.5396. 
=============================================
[2017-11-02 10:15:35,694] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 145179: loss 23.2849
[2017-11-02 10:15:37,106] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 145378: loss 3.5588
[2017-11-02 10:15:37,187] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.13466178e-16   5.55866364e-17   6.26369112e-16
   2.28545189e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:15:37,222] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.166666666666667, 54.83333333333333, 1.5, 288.3333333333334, 0.0, 0.0, 0.916666666666667, 15.59213581684534, 22.0, 21.86137430912395, 22.7, 1.0, 37.23041236376295], 
actual action is [-9.166666666666668, 18], 
sim time next is 2744100.0000, 
raw observation next is [-4.25, 55.25, 1.5, 262.5, 0.0, 0.0, -9.166666666666668, 17.814880836805, 18.0, 21.84001651648783, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.22435897435897437, 0.5525, 0.13636363636363635, 0.7291666666666666, 0.0, 0.0, 0.3472222222222222, 0.17814880836805, 0.0, 0.5485737880696898, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:15:44,480] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   9.76966446e-14   1.27016670e-13   2.09082339e-12
   5.80106709e-14   7.10227818e-36   4.01169877e-35   3.21404997e-34
   7.11763712e-34], sum to 1.0000
[2017-11-02 10:15:44,497] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 60.66666666666666, 1.9, 53.33333333333333, 0.0, 0.0, -11.0, 18.40002830260794, 18.0, 21.6019111175323, 21.5, 0.0, 0.0], 
actual action is [-11.0, 18], 
sim time next is 2756700.0000, 
raw observation next is [-6.0, 60.25, 1.95, 52.5, 0.0, 0.0, -11.0, 20.70578488126224, 18.0, 21.48712956315092, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.1794871794871795, 0.6025, 0.17727272727272728, 0.14583333333333334, 0.0, 0.0, 0.31666666666666665, 0.2070578488126224, 0.0, 0.49816136616441703, 0.5, 0.0, 0.0], 
reward next is -0.0018. 
=============================================
[2017-11-02 10:15:45,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-64.04896545]
 [-63.79737473]
 [-64.96237183]
 [-64.12556458]
 [-63.58773422]], R is [[-64.88051605]
 [-65.23171234]
 [-65.57939911]
 [-65.92360687]
 [-66.26437378]].
[2017-11-02 10:15:55,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.05774264e-12   1.93620009e-09   1.77415638e-09   1.59325282e-08
   1.26256527e-09   6.78493921e-03   3.36791240e-02   2.14338318e-01
   7.45197594e-01], sum to 1.0000
[2017-11-02 10:15:55,360] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.0, 59.0, 2.933333333333334, 58.33333333333333, 0.0, 0.0, -11.0, 17.22513423840248, 18.0, 21.83516533053916, 21.5, 0.0, 0.0], 
actual action is [-1.0, 23.0], 
sim time next is 2760900.0000, 
raw observation next is [-6.0, 59.0, 3.016666666666667, 59.16666666666667, 0.0, 0.0, -1.0, 16.55667530772543, 23.0, 21.69058871479021, 21.5, 0.0, 55.36340437747886], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.1794871794871795, 0.59, 0.2742424242424243, 0.16435185185185186, 0.0, 0.0, 0.48333333333333334, 0.16556675307725432, 0.7142857142857143, 0.5272269592557441, 0.5, 0.0, 0.6513341691468101], 
reward next is -0.5862. 
=============================================
[2017-11-02 10:15:55,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 148628: loss 20.7884
[2017-11-02 10:16:02,444] A3C_AGENT_WORKER-Thread-6 INFO:Local step 9500, global step 149967: loss -11.1491
[2017-11-02 10:16:04,089] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 150214: loss -8.4477
[2017-11-02 10:16:04,854] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 150322: loss 46.9565
[2017-11-02 10:16:06,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  6.39434997e-14   2.16027798e-13   7.96664438e-14   3.40283812e-12
   2.59025277e-13   5.89575246e-03   1.26716709e-02   1.92471862e-01
   7.88960755e-01], sum to 1.0000
[2017-11-02 10:16:07,106] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.9999999999999999, 46.0, 3.1, 93.33333333333333, 133.8333333333333, 750.0, -4.25, 18.1567031301714, 18.0, 22.12960039381179, 22.7, 1.0, 0.0], 
actual action is [6.0, 23.0], 
sim time next is 2807100.0000, 
raw observation next is [1.25, 45.5, 3.225, 97.5, 138.25, 743.5, 6.0, 14.90646657377569, 23.0, 22.04115402463906, 22.7, 1.0, 87.4545135077831], 
processed observation next is [0.5, 0.4782608695652174, 0.36538461538461536, 0.455, 0.2931818181818182, 0.2708333333333333, 0.36574074074074076, 0.7435, 0.6, 0.1490646657377569, 0.7142857142857143, 0.5773077178055799, 0.6714285714285714, 1.0, 1.0288766295033307], 
reward next is -0.9409. 
=============================================
[2017-11-02 10:16:07,131] A3C_AGENT_WORKER-Thread-8 INFO:Local step 9500, global step 150732: loss 37.4820
[2017-11-02 10:16:08,528] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-40.22081375]
 [-39.52638626]
 [-41.00276566]
 [-39.41436386]
 [-39.86009598]], R is [[-40.27880096]
 [-40.69565582]
 [-40.30205536]
 [-39.9115715 ]
 [-39.52410507]].
[2017-11-02 10:16:09,384] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151276: loss 47.9178
[2017-11-02 10:16:11,082] A3C_AGENT_WORKER-Thread-5 INFO:Local step 9500, global step 151813: loss 20.2707
[2017-11-02 10:16:13,898] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152319: loss 87.6107
[2017-11-02 10:16:16,191] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152887: loss 49.6738
[2017-11-02 10:16:16,262] A3C_AGENT_WORKER-Thread-4 INFO:Local step 9500, global step 152907: loss 61.4812
[2017-11-02 10:16:16,338] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152927: loss -131.6525
[2017-11-02 10:16:16,497] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152976: loss 22.5899
[2017-11-02 10:16:16,927] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 153100: loss 30.2854
[2017-11-02 10:16:17,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  2.28501800e-02   5.80982378e-05   4.60591800e-05   5.54476981e-04
   7.60523908e-05   5.01217041e-03   7.19295740e-02   3.27802449e-01
   5.71670890e-01], sum to 1.0000
[2017-11-02 10:16:17,924] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.0, 76.66666666666667, 7.033333333333333, 130.0, 0.0, 0.0, 6.0, 19.03038406256741, 21.0, 21.19577123720885, 21.5, 0.0, 38.7733677933517], 
actual action is [6.0, 22.0], 
sim time next is 2857500.0000, 
raw observation next is [1.0, 77.25, 6.95, 130.0, 0.0, 0.0, 6.0, 19.27709312534489, 22.0, 21.15882186789271, 21.5, 0.0, 32.78071853005051], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.358974358974359, 0.7725, 0.6318181818181818, 0.3611111111111111, 0.0, 0.0, 0.6, 0.1927709312534489, 0.5714285714285714, 0.45126026684181547, 0.5, 0.0, 0.3856555121182413], 
reward next is -0.3958. 
=============================================
[2017-11-02 10:16:18,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 153537: loss 82.4999
[2017-11-02 10:16:18,955] A3C_AGENT_WORKER-Thread-7 INFO:Local step 9500, global step 153634: loss 40.0425
[2017-11-02 10:16:21,332] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 154117: loss 53.7023
[2017-11-02 10:16:21,727] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   2.72998137e-16   3.09290798e-16   5.12741484e-15
   7.21694888e-16   0.00000000e+00   7.47800796e-38   3.76431199e-38
   2.53217188e-37], sum to 1.0000
[2017-11-02 10:16:21,833] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.1666666666666666, 98.83333333333334, 4.683333333333333, 121.6666666666667, 58.66666666666666, 0.0, 5.25, 10.28827883086326, 23.0, 22.84154319713204, 22.7, 1.0, 68.60974787030946], 
actual action is [-4.833333333333333, 18.0], 
sim time next is 2886900.0000, 
raw observation next is [0.08333333333333337, 99.41666666666666, 4.641666666666666, 120.8333333333333, 61.08333333333334, 0.0, -4.833333333333333, 11.00287935691483, 18.0, 22.88908573825536, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.3354700854700855, 0.9941666666666665, 0.4219696969696969, 0.33564814814814803, 0.16159611992945327, 0.0, 0.41944444444444445, 0.1100287935691483, 0.0, 0.6984408197507658, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0110. 
=============================================
[2017-11-02 10:16:22,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   1.70499644e-30   7.57280544e-31   4.38158542e-30
   1.17612489e-30   2.97587551e-02   6.36891901e-01   1.91603482e-01
   1.41745955e-01], sum to 1.0000
[2017-11-02 10:16:23,017] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [1.0, 93.0, 4.1, 110.0, 0.0, 0.0, -4.0, 20.61674367085944, 18.0, 20.7182073596513, 21.5, 0.0, 0.0], 
actual action is [6.0, 19.0], 
sim time next is 2869500.0000, 
raw observation next is [1.0, 93.58333333333333, 4.183333333333333, 111.6666666666667, 0.0, 0.0, 6.0, 19.31138701584262, 19.0, 20.6261955072965, 21.5, 0.0, 62.66273883629937], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.358974358974359, 0.9358333333333333, 0.38030303030303025, 0.3101851851851853, 0.0, 0.0, 0.6, 0.19311387015842618, 0.14285714285714285, 0.375170786756643, 0.5, 0.0, 0.7372086921917573], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:25,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.28965118e-34   8.05652598e-24   3.69914273e-24   2.32242796e-23
   6.06433508e-24   2.58056730e-01   4.18152183e-01   7.95722753e-02
   2.44218841e-01], sum to 1.0000
[2017-11-02 10:16:25,205] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.166666666666667, 79.16666666666667, 7.949999999999999, 260.0, 0.0, 0.0, 3.916666666666667, 12.22956806287975, 18.5, 22.04143048133505, 21.5, 0.0, 42.74846086451987], 
actual action is [3.833333333333333, 19.0], 
sim time next is 2931300.0000, 
raw observation next is [-1.25, 79.75, 7.824999999999999, 260.0, 0.0, 0.0, 3.833333333333333, 12.16473809106789, 19.0, 22.06586214501749, 21.5, 0.0, 40.98295697799279], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.30128205128205127, 0.7975, 0.7113636363636363, 0.7222222222222222, 0.0, 0.0, 0.5638888888888889, 0.1216473809106789, 0.14285714285714285, 0.5808374492882129, 0.5, 0.0, 0.4821524350352093], 
reward next is -0.4339. 
=============================================
[2017-11-02 10:16:34,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   3.58843099e-20   3.91068892e-20   8.00242183e-19
   4.32636108e-20   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:34,433] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666667, 92.41666666666667, 9.341666666666667, 250.0, 0.0, 0.0, 5.0, 24.64727353234836, 19.0, 20.14747149624781, 22.7, 1.0, 4.932446279271009], 
actual action is [-5.166666666666667, 18], 
sim time next is 2918400.0000, 
raw observation next is [-0.3333333333333333, 92.33333333333333, 9.433333333333334, 250.0, 0.0, 0.0, -5.166666666666667, 25.26739046123922, 18.0, 20.07030849914685, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.3247863247863248, 0.9233333333333333, 0.8575757575757575, 0.6944444444444444, 0.0, 0.0, 0.41388888888888886, 0.2526739046123922, 0.0, 0.2957583570209787, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:34,582] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 156999: loss -116.2296
[2017-11-02 10:16:34,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.9601965
  0.01015787  0.01741677  0.01222882], sum to 1.0000
[2017-11-02 10:16:34,928] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 85.0, 8.75, 255.0, 0.0, 0.0, -6.0, 30.64981916743956, 18.0, 19.39766716054579, 22.7, 1.0, 0.0], 
actual action is [4.0, 18.5], 
sim time next is 2921700.0000, 
raw observation next is [-1.0, 83.83333333333333, 8.575, 255.8333333333333, 0.0, 0.0, 4.0, 30.65481924221704, 18.5, 19.34470526916179, 22.7, 1.0, 14.75509289567445], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.3076923076923077, 0.8383333333333333, 0.7795454545454544, 0.710648148148148, 0.0, 0.0, 0.5666666666666667, 0.3065481924221704, 0.07142857142857142, 0.19210075273739843, 0.6714285714285714, 1.0, 0.17358932818440528], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:35,132] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-67.14446259]
 [-67.71973419]
 [-65.50917053]
 [-64.87150574]
 [-67.91646576]], R is [[-62.51775742]
 [-62.89258194]
 [-63.26365662]
 [-63.63101959]
 [-63.99470901]].
[2017-11-02 10:16:38,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   3.91578534e-17   7.11311138e-17   1.00166845e-15
   6.71035052e-17   0.00000000e+00   0.00000000e+00   1.04349147e-37
   1.37348673e-37], sum to 1.0000
[2017-11-02 10:16:38,536] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 84.0, 6.175000000000001, 280.0, 0.0, 0.0, 2.0, 18.03969275947576, 25.0, 20.73415764496262, 21.5, 0.0, 42.87751269501418], 
actual action is [2.0, 20.0], 
sim time next is 2951400.0000, 
raw observation next is [-3.0, 84.0, 6.350000000000001, 280.0, 0.0, 0.0, 2.0, 17.52090770190568, 20.0, 20.78368885420486, 21.5, 0.0, 48.35054372621657], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.5772727272727274, 0.7777777777777778, 0.0, 0.0, 0.5333333333333333, 0.1752090770190568, 0.2857142857142857, 0.39766983631498015, 0.5, 0.0, 0.5688299261907832], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:39,404] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03257681
  0.02209376  0.86614937  0.07917997], sum to 1.0000
[2017-11-02 10:16:39,458] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10000, global step 158080: loss -171.2275
[2017-11-02 10:16:39,476] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 77.0, 4.6, 280.0, 0.0, 0.0, -9.0, 28.43739378761464, 18.0, 19.90891356564573, 21.5, 0.0, 0.0], 
actual action is [1.0, 20.0], 
sim time next is 2961300.0000, 
raw observation next is [-4.0, 77.0, 4.6, 280.0, 0.0, 0.0, 1.0, 27.02543604459577, 20.0, 19.75826959637991, 21.5, 0.0, 71.64345934893032], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.23076923076923078, 0.77, 0.41818181818181815, 0.7777777777777778, 0.0, 0.0, 0.5166666666666667, 0.27025436044595774, 0.2857142857142857, 0.25118137091141585, 0.5, 0.0, 0.8428642276344743], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:39,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.31068948e-23   2.57577758e-23   9.10156865e-22
   2.81756534e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:39,670] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.916666666666667, 84.08333333333334, 4.733333333333333, 278.3333333333333, 0.0, 0.0, -7.833333333333333, 26.96449006413749, 18.0, 20.10252993926642, 21.5, 0.0, 0.0], 
actual action is [-7.916666666666667, 18], 
sim time next is 2948400.0000, 
raw observation next is [-3.0, 84.0, 4.6, 280.0, 0.0, 0.0, -7.916666666666667, 29.08933340166707, 18.0, 19.97460409954481, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.2564102564102564, 0.84, 0.41818181818181815, 0.7777777777777778, 0.0, 0.0, 0.3680555555555555, 0.29089333401667067, 0.0, 0.28208629993497275, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:42,106] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 158684: loss -13.1159
[2017-11-02 10:16:42,541] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 158756: loss -105.4648
[2017-11-02 10:16:44,237] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10000, global step 159049: loss -44.7792
[2017-11-02 10:16:45,600] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159262: loss -4.2496
[2017-11-02 10:16:47,564] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  7.07347333e-01   1.67853625e-06   1.14578063e-06   8.55372855e-05
   3.15030638e-06   2.60776747e-03   9.43542719e-02   2.89172810e-02
   1.66681916e-01], sum to 1.0000
[2017-11-02 10:16:47,578] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 5.908333333333333, 274.1666666666666, 249.75, 317.9166666666667, -8.0, 19.1081637586208, 18.0, 21.65811671273072, 22.7, 1.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 2979600.0000, 
raw observation next is [-3.0, 65.0, 5.866666666666667, 273.3333333333334, 243.5, 351.8333333333333, -8.0, 20.24430739582207, 18.0, 21.58969978775577, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.2564102564102564, 0.65, 0.5333333333333333, 0.7592592592592595, 0.6441798941798942, 0.35183333333333333, 0.36666666666666664, 0.2024430739582207, 0.0, 0.5128142553936813, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:50,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   1.85609385e-36   5.94657079e-37   8.49182672e-36
   1.73440464e-36   2.54988912e-02   7.60466829e-02   1.61364645e-01
   7.37089753e-01], sum to 1.0000
[2017-11-02 10:16:50,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.0, 71.0, 1.75, 24.16666666666666, 0.0, 0.0, 0.0, 17.01860968294936, 25.0, 21.36820953578478, 21.5, 0.0, 39.32482674550968], 
actual action is [0.0, 25], 
sim time next is 3029400.0000, 
raw observation next is [-5.0, 71.0, 1.8, 25.0, 0.0, 0.0, 0.0, 16.74866205357864, 25.0, 21.3586106750835, 21.5, 0.0, 45.21450821351471], 
processed observation next is [1.0, 0.043478260869565216, 0.20512820512820512, 0.71, 0.16363636363636364, 0.06944444444444445, 0.0, 0.0, 0.5, 0.16748662053578642, 1.0, 0.4798015250119287, 0.5, 0.0, 0.531935390747232], 
reward next is -0.4989. 
=============================================
[2017-11-02 10:16:52,713] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10000, global step 160338: loss -8.0861
[2017-11-02 10:16:52,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.49196960e-22   1.67123275e-22   1.32802983e-20
   2.34662466e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:16:52,788] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.333333333333333, 56.66666666666667, 4.833333333333333, 253.3333333333333, 78.5, 634.8333333333334, -6.416666666666667, 15.71493164548411, 18.0, 22.30966007086439, 22.7, 1.0, 0.0], 
actual action is [-6.333333333333333, 18], 
sim time next is 2994300.0000, 
raw observation next is [-1.25, 56.25, 5.050000000000001, 257.5, 76.25, 618.75, -6.333333333333333, 16.38173213193927, 18.0, 22.25061298499855, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6521739130434783, 0.30128205128205127, 0.5625, 0.45909090909090916, 0.7152777777777778, 0.20171957671957672, 0.61875, 0.3944444444444445, 0.1638173213193927, 0.0, 0.6072304264283643, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:53,054] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160406: loss 60.2198
[2017-11-02 10:16:54,043] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-78.95678711]
 [-78.17741394]
 [-76.5462265 ]
 [-78.76947784]
 [-76.53187561]], R is [[-76.67449951]
 [-76.90775299]
 [-76.15271759]
 [-75.40439606]
 [-75.19260406]].
[2017-11-02 10:16:54,579] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160713: loss -30.6148
[2017-11-02 10:16:55,159] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160829: loss 44.6703
[2017-11-02 10:16:56,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.17979624e-17   5.12995281e-17   1.27452402e-15
   5.36401713e-17   1.03029292e-36   2.70924651e-36   2.45628007e-36
   8.44807500e-36], sum to 1.0000
[2017-11-02 10:16:56,082] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 73.75, 3.1, 30.0, 0.0, 0.0, -1.0, 21.52933494848502, 22.0, 20.20982783362064, 21.5, 0.0, 40.49985004254074], 
actual action is [-11.0, 18], 
sim time next is 3050400.0000, 
raw observation next is [-6.0, 72.66666666666667, 3.1, 33.33333333333334, 0.0, 0.0, -11.0, 24.10944723237614, 18.0, 20.24252135560981, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.30434782608695654, 0.1794871794871795, 0.7266666666666667, 0.2818181818181818, 0.09259259259259262, 0.0, 0.0, 0.31666666666666665, 0.2410944723237614, 0.0, 0.3203601936585443, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:16:56,403] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10000, global step 161073: loss 11.3743
[2017-11-02 10:16:56,596] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 161120: loss -7.3748
[2017-11-02 10:16:56,921] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 161188: loss -10.8377
[2017-11-02 10:16:57,987] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 161404: loss -66.0719
[2017-11-02 10:16:59,459] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10000, global step 161696: loss 6.6296
[2017-11-02 10:17:00,689] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 161941: loss 4.4507
[2017-11-02 10:17:06,122] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-48.99343109]
 [-48.96157074]
 [-49.19911194]
 [-49.78742981]
 [-48.62319946]], R is [[-49.44449615]
 [-49.35947418]
 [-49.3528595 ]
 [-49.3599968 ]
 [-49.28119659]].
[2017-11-02 10:17:06,415] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.52160549
  0.20395221  0.12136247  0.15307981], sum to 1.0000
[2017-11-02 10:17:06,460] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.0, 96.0, 4.6, 95.0, 0.0, 0.0, 4.0, 11.57028719908616, 19.5, 22.69730091091073, 21.5, 0.0, 36.3300336272559], 
actual action is [4.0, 24.5], 
sim time next is 3098100.0000, 
raw observation next is [-1.0, 96.66666666666666, 4.6, 95.83333333333334, 0.0, 0.0, 4.0, 11.5404220058684, 24.5, 22.75958509583112, 21.5, 0.0, 32.05939367128691], 
processed observation next is [1.0, 0.8695652173913043, 0.3076923076923077, 0.9666666666666666, 0.41818181818181815, 0.2662037037037037, 0.0, 0.0, 0.5666666666666667, 0.115404220058684, 0.9285714285714286, 0.6799407279758743, 0.5, 0.0, 0.3771693373092578], 
reward next is -0.3395. 
=============================================
[2017-11-02 10:17:11,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.16888538e-11   5.47137405e-11   6.96645797e-11
   3.40805301e-11   1.63302222e-23   4.31270849e-24   4.28202061e-24
   1.90861393e-23], sum to 1.0000
[2017-11-02 10:17:11,722] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 92.0, 4.808333333333333, 90.0, 0.0, 0.0, 4.0, 11.03231203137435, 20.0, 22.90820110570951, 21.5, 0.0, 46.20626405396297], 
actual action is [-6.0, 18], 
sim time next is 3094800.0000, 
raw observation next is [-1.0, 92.0, 4.766666666666667, 90.0, 0.0, 0.0, -6.0, 11.99782007964585, 18.0, 23.00760046235158, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.8260869565217391, 0.3076923076923077, 0.92, 0.43333333333333335, 0.25, 0.0, 0.0, 0.4, 0.1199782007964585, 0.0, 0.7153714946216542, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:12,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-49.95063019]
 [-48.98101044]
 [-49.24435425]
 [-48.68025208]
 [-49.44340515]], R is [[-50.35266876]
 [-50.84914398]
 [-51.34065247]
 [-51.82724762]
 [-52.30897522]].
[2017-11-02 10:17:13,060] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 164401: loss 3.3417
[2017-11-02 10:17:14,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-42.81797791]
 [-42.06270599]
 [-41.54441071]
 [-41.8454628 ]
 [-39.98720932]], R is [[-40.99336243]
 [-41.08478928]
 [-41.20298767]
 [-41.33148575]
 [-41.33478546]].
[2017-11-02 10:17:15,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.96414441
  0.00830187  0.02462195  0.00293171], sum to 1.0000
[2017-11-02 10:17:15,720] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 55.0, 3.1, 100.0, 112.5, 811.0, 1.916666666666667, 18.39757241045611, 22.0, 21.61800637917242, 22.7, 1.0, 10.64414713621141], 
actual action is [2.0, 22.5], 
sim time next is 3067500.0000, 
raw observation next is [-2.916666666666667, 54.58333333333333, 3.1, 97.49999999999999, 112.75, 812.0, 2.0, 18.72488386007567, 22.5, 21.56638299473848, 22.7, 1.0, 10.23906705274581], 
processed observation next is [1.0, 0.5217391304347826, 0.2585470085470085, 0.5458333333333333, 0.2818181818181818, 0.2708333333333333, 0.29828042328042326, 0.812, 0.5333333333333333, 0.18724883860075672, 0.6428571428571429, 0.5094832849626398, 0.6714285714285714, 1.0, 0.12045961238524482], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:16,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.33186476e-15   3.35659167e-15   8.17136157e-15
   2.14664153e-15   5.41999108e-37   1.70703814e-37   1.40520013e-37
   1.25355430e-37], sum to 1.0000
[2017-11-02 10:17:16,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.083333333333333, 99.99999999999999, 1.375, 45.83333333333333, 0.0, 0.0, 6.0, 15.71019229933153, 20.0, 21.49960698190861, 21.5, 0.0, 34.62931940761788], 
actual action is [-3.916666666666667, 18], 
sim time next is 3118200.0000, 
raw observation next is [1.166666666666667, 100.0, 1.25, 41.66666666666667, 0.0, 0.0, -3.916666666666667, 16.56498882855075, 18.0, 21.45658651129359, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.3632478632478633, 1.0, 0.11363636363636363, 0.11574074074074076, 0.0, 0.0, 0.4347222222222222, 0.1656498882855075, 0.0, 0.49379807304194145, 0.5, 0.0, 0.0], 
reward next is -0.0062. 
=============================================
[2017-11-02 10:17:17,241] A3C_AGENT_WORKER-Thread-6 INFO:Local step 10500, global step 165512: loss 1.1583
[2017-11-02 10:17:19,735] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 166260: loss 3.3344
[2017-11-02 10:17:20,245] A3C_AGENT_WORKER-Thread-8 INFO:Local step 10500, global step 166406: loss 20.7939
[2017-11-02 10:17:20,369] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 166442: loss 6.4352
[2017-11-02 10:17:21,886] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   2.78699130e-09   4.33214886e-09   9.57645163e-09
   4.34910419e-09   2.24199245e-16   3.96775114e-17   4.15423570e-17
   4.73286177e-17], sum to 1.0000
[2017-11-02 10:17:21,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 100.0, 3.6, 200.0, 98.16666666666667, 749.0, 2.0, 7.005212107159457, 18.0, 23.89308447882935, 22.7, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 3163500.0000, 
raw observation next is [7.0, 100.0, 3.6, 200.0, 96.75, 742.0, 2.0, 6.988365437584465, 18.0, 23.93845043498519, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 1.0, 0.32727272727272727, 0.5555555555555556, 0.25595238095238093, 0.742, 0.5333333333333333, 0.06988365437584465, 0.0, 0.8483500621407413, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0070. 
=============================================
[2017-11-02 10:17:22,537] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167153: loss 0.6916
[2017-11-02 10:17:24,138] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.38254231
  0.01869439  0.44786558  0.15089776], sum to 1.0000
[2017-11-02 10:17:24,197] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 100.0, 3.35, 95.0, 0.0, 0.0, 5.0, 25.5396795197376, 22.0, 20.46522150224672, 21.5, 0.0, 16.07714325770068], 
actual action is [5.0, 22.5], 
sim time next is 3108900.0000, 
raw observation next is [0.0, 100.0, 3.308333333333334, 92.5, 0.0, 0.0, 5.0, 24.53867623230494, 22.5, 20.42380256321822, 21.5, 0.0, 38.45155023064413], 
processed observation next is [1.0, 1.0, 0.3333333333333333, 1.0, 0.30075757575757583, 0.2569444444444444, 0.0, 0.0, 0.5833333333333334, 0.2453867623230494, 0.6428571428571429, 0.3462575090311744, 0.5, 0.0, 0.4523711791840486], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:24,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99999523e-01   6.71178597e-08   1.42723010e-07   1.70853568e-07
   8.94365115e-08   1.82482298e-13   2.62682163e-14   1.69485953e-13
   9.96082896e-14], sum to 1.0000
[2017-11-02 10:17:24,521] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 100.0, 2.325, 340.0, 0.0, 0.0, -2.0, 13.88212850917279, 18.0, 20.87926907308897, 21.5, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 3185400.0000, 
raw observation next is [3.0, 100.0, 2.416666666666667, 340.0, 0.0, 0.0, -2.0, 14.24417241446212, 18.0, 20.86266633498365, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.8695652173913043, 0.41025641025641024, 1.0, 0.21969696969696972, 0.9444444444444444, 0.0, 0.0, 0.4666666666666667, 0.1424417241446212, 0.0, 0.40895233356909294, 0.5, 0.0, 0.0], 
reward next is -0.0910. 
=============================================
[2017-11-02 10:17:25,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   4.26663201e-15   5.30488815e-15   1.58805447e-14
   4.75933583e-15   5.84235329e-36   2.23803893e-36   7.03282830e-36
   5.98528268e-36], sum to 1.0000
[2017-11-02 10:17:25,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 14.13151332608232, 25.0, 20.33450250826686, 22.0, 1.0, 70.8081818498045], 
actual action is [2.0, 20.0], 
sim time next is 3222900.0000, 
raw observation next is [-3.0, 92.0, 5.1, 267.5, 0.0, 0.0, 2.0, 13.09649095235479, 20.0, 20.65587076873092, 22.0, 1.0, 52.2441600835602], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.92, 0.4636363636363636, 0.7430555555555556, 0.0, 0.0, 0.5333333333333333, 0.1309649095235479, 0.2857142857142857, 0.379410109818703, 0.5714285714285714, 1.0, 0.6146371774536494], 
reward next is -0.5663. 
=============================================
[2017-11-02 10:17:26,534] A3C_AGENT_WORKER-Thread-5 INFO:Local step 10500, global step 168396: loss 0.5406
[2017-11-02 10:17:27,143] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168587: loss 2.0356
[2017-11-02 10:17:27,212] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.01885145e-09   1.20126997e-09   1.47668577e-09
   1.02209030e-09   4.75175428e-22   1.73468090e-22   6.90237793e-22
   1.20329503e-20], sum to 1.0000
[2017-11-02 10:17:27,222] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.416666666666667, 97.08333333333334, 3.6, 307.5, 0.0, 0.0, -3.5, 14.94524441417865, 18.0, 21.5034471457281, 20.8, 0.0, 0.0], 
actual action is [-3.583333333333333, 18], 
sim time next is 3199200.0000, 
raw observation next is [1.333333333333333, 97.66666666666666, 3.6, 310.0, 0.0, 0.0, -3.583333333333333, 15.61143431794352, 18.0, 21.405185067443, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.3675213675213675, 0.9766666666666666, 0.32727272727272727, 0.8611111111111112, 0.0, 0.0, 0.4402777777777778, 0.1561143431794352, 0.0, 0.4864550096347143, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:27,413] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168664: loss 0.2490
[2017-11-02 10:17:29,389] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 169243: loss 1.3115
[2017-11-02 10:17:29,560] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99991417e-01   1.26355417e-06   2.22336644e-06   3.26862028e-06
   1.75753985e-06   5.09944864e-11   1.55614601e-11   2.08112260e-11
   1.07810469e-10], sum to 1.0000
[2017-11-02 10:17:29,572] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.833333333333334, 100.0, 5.616666666666666, 160.0, 88.33333333333334, 477.0, 1.75, 14.01995407727281, 18.0, 22.06763351519534, 22.7, 1.0, 0.0], 
actual action is [1.833333333333334, 18], 
sim time next is 3142500.0000, 
raw observation next is [6.916666666666666, 100.0, 5.358333333333333, 160.0, 89.66666666666666, 498.25, 1.833333333333334, 13.98551240332193, 18.0, 22.082456083505, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.5106837606837606, 1.0, 0.4871212121212121, 0.4444444444444444, 0.23721340388007053, 0.49825, 0.5305555555555556, 0.1398551240332193, 0.0, 0.5832080119292858, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0140. 
=============================================
[2017-11-02 10:17:30,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 169554: loss 0.8239
[2017-11-02 10:17:30,841] A3C_AGENT_WORKER-Thread-4 INFO:Local step 10500, global step 169722: loss 2.0476
[2017-11-02 10:17:31,134] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 169829: loss 1.3761
[2017-11-02 10:17:31,617] A3C_AGENT_WORKER-Thread-7 INFO:Local step 10500, global step 169992: loss 1.6063
[2017-11-02 10:17:31,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 170041: loss 0.4262
[2017-11-02 10:17:34,071] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   5.58206740e-14   1.07738457e-13   1.35949168e-13
   3.33737791e-14   1.46939021e-34   1.96578885e-34   5.35123829e-34
   3.05070888e-33], sum to 1.0000
[2017-11-02 10:17:34,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   5.78386297e-11   8.61267169e-11   9.90647148e-11
   3.72341810e-11   3.33936608e-28   4.72437549e-28   9.01714911e-28
   3.50592089e-27], sum to 1.0000
[2017-11-02 10:17:34,097] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5, 100.0, 4.35, 295.0, 0.0, 0.0, 4.583333333333333, 14.79285703331917, 23.0, 20.58456322805168, 20.8, 0.0, 101.3921528121153], 
actual action is [-5.5, 18.0], 
sim time next is 3206100.0000, 
raw observation next is [-0.5833333333333334, 100.0, 4.225, 295.8333333333333, 0.0, 0.0, -5.5, 15.59803297055206, 18.0, 20.76000102118353, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.31837606837606836, 1.0, 0.38409090909090904, 0.8217592592592592, 0.0, 0.0, 0.4083333333333333, 0.1559803297055206, 0.0, 0.3942858601690758, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0057. 
=============================================
[2017-11-02 10:17:34,100] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 100.0, 3.016666666666667, 323.3333333333334, 0.0, 0.0, -2.75, 12.61720196644569, 18.0, 21.72409020879828, 21.5, 0.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 3189300.0000, 
raw observation next is [2.083333333333333, 100.0, 3.058333333333334, 321.6666666666667, 0.0, 0.0, -2.833333333333333, 13.15839168028734, 18.0, 21.64946593098716, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.3867521367521367, 1.0, 0.27803030303030307, 0.8935185185185186, 0.0, 0.0, 0.4527777777777778, 0.1315839168028734, 0.0, 0.5213522758553084, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:34,371] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 171018: loss 0.5385
[2017-11-02 10:17:35,557] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.98035371e-01   2.50024368e-06   2.30586443e-06   2.86234763e-06
   1.61595460e-06   1.16349453e-04   8.08047043e-05   7.93940388e-04
   9.64126259e-04], sum to 1.0000
[2017-11-02 10:17:35,584] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 77.0, 5.1, 310.0, 34.0, 307.5, -8.916666666666668, 14.51198060033711, 18.0, 21.88129812478289, 22.0, 1.0, 0.0], 
actual action is [-9.0, 18], 
sim time next is 3258300.0000, 
raw observation next is [-4.0, 76.0, 5.016666666666667, 310.8333333333333, 29.83333333333333, 273.5833333333333, -9.0, 15.4283237831425, 18.0, 21.82760194582755, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.23076923076923078, 0.76, 0.45606060606060606, 0.8634259259259258, 0.07892416225749557, 0.2735833333333333, 0.35, 0.154283237831425, 0.0, 0.5468002779753641, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:37,577] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  2.09614896e-17   4.02571986e-12   3.98501631e-12   2.88566957e-12
   2.23423211e-12   1.01636551e-01   6.89430460e-02   1.84602529e-01
   6.44817889e-01], sum to 1.0000
[2017-11-02 10:17:37,659] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.75, 100.0, 3.975, 297.5, 0.0, 0.0, -5.666666666666667, 17.27151845595328, 18.0, 20.91256812943881, 20.8, 0.0, 0.0], 
actual action is [4.25, 23.0], 
sim time next is 3207000.0000, 
raw observation next is [-0.8333333333333334, 100.0, 3.85, 298.3333333333333, 0.0, 0.0, 4.25, 15.82761006792991, 23.0, 20.88029647885863, 20.8, 0.0, 55.42856349241761], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.31196581196581197, 1.0, 0.35000000000000003, 0.8287037037037036, 0.0, 0.0, 0.5708333333333333, 0.1582761006792991, 0.7142857142857143, 0.41147092555123266, 0.4000000000000001, 0.0, 0.652100746969619], 
reward next is -0.5869. 
=============================================
[2017-11-02 10:17:38,729] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   2.25948519e-13   3.12885758e-13   8.15312390e-13
   1.54290534e-13   1.86755000e-35   1.34699441e-35   1.74921509e-35
   2.20151926e-35], sum to 1.0000
[2017-11-02 10:17:38,753] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666667, 100.0, 4.85, 291.6666666666667, 0.0, 0.0, -5.083333333333333, 18.79075802529865, 18.0, 20.22986909803039, 20.8, 0.0, 0.0], 
actual action is [-5.166666666666667, 18], 
sim time next is 3204900.0000, 
raw observation next is [-0.25, 100.0, 4.725, 292.5, 0.0, 0.0, -5.166666666666667, 19.74708570925601, 18.0, 20.234321202887, 20.8, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.3269230769230769, 1.0, 0.4295454545454545, 0.8125, 0.0, 0.0, 0.41388888888888886, 0.1974708570925601, 0.0, 0.3191887432695713, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0808. 
=============================================
[2017-11-02 10:17:39,706] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 172718: loss -78.7692
[2017-11-02 10:17:40,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   5.89204141e-13   7.58170978e-13   2.20767588e-12
   4.23210891e-13   5.06875368e-33   1.73299789e-33   7.45828390e-33
   3.12639180e-33], sum to 1.0000
[2017-11-02 10:17:40,731] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 92.0, 5.1, 269.1666666666667, 0.0, 0.0, 2.0, 17.91704713064209, 23.5, 20.45608088608346, 22.0, 1.0, 70.47810737683746], 
actual action is [2.0, 18.5], 
sim time next is 3222600.0000, 
raw observation next is [-3.0, 92.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 16.86762990679978, 18.5, 20.55003182807358, 22.0, 1.0, 49.76715697650502], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.92, 0.4636363636363636, 0.7453703703703703, 0.0, 0.0, 0.5333333333333333, 0.1686762990679978, 0.07142857142857142, 0.3642902611533683, 0.5714285714285714, 1.0, 0.5854959644294708], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:41,895] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   2.25804499e-14   3.35996252e-14   7.27639045e-14
   1.35999407e-14   7.39083750e-36   2.41399628e-36   1.46214852e-35
   1.03979715e-35], sum to 1.0000
[2017-11-02 10:17:41,915] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.0, 71.16666666666666, 5.741666666666666, 331.6666666666667, 0.0, 0.0, -12.0, 18.70345888672108, 18.0, 21.11280780556271, 20.8, 0.0, 0.0], 
actual action is [-12.0, 18], 
sim time next is 3286800.0000, 
raw observation next is [-7.0, 70.0, 5.7, 330.0, 0.0, 0.0, -12.0, 21.15648421012687, 18.0, 21.02900513590782, 20.8, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.15384615384615385, 0.7, 0.5181818181818182, 0.9166666666666666, 0.0, 0.0, 0.3, 0.2115648421012687, 0.0, 0.43271501941540286, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:17:44,111] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11000, global step 173808: loss -12.8133
[2017-11-02 10:17:44,738] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 174002: loss -267.8194
[2017-11-02 10:17:44,995] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   5.00235873e-14   3.35965488e-14   9.89750409e-14
   2.97050016e-14   5.72432602e-29   2.17928317e-29   1.14314901e-27
   6.82670244e-29], sum to 1.0000
[2017-11-02 10:17:45,072] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 82.0, 6.783333333333333, 258.3333333333334, 110.3333333333333, 771.6666666666666, -7.55, 14.16619716490613, 18.0, 22.30043816836623, 22.0, 1.0, 0.0], 
actual action is [-7.5, 18], 
sim time next is 3236100.0000, 
raw observation next is [-2.45, 81.0, 6.741666666666667, 259.1666666666666, 110.6666666666667, 776.5833333333333, -7.5, 14.23520180471849, 18.0, 22.28616695667752, 22.0, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.27051282051282055, 0.81, 0.6128787878787879, 0.7199074074074071, 0.2927689594356262, 0.7765833333333333, 0.375, 0.1423520180471849, 0.0, 0.6123095652396456, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:17:45,574] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11000, global step 174250: loss 0.5454
[2017-11-02 10:17:46,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.45471154e-03   9.10501927e-04   5.04764088e-04   3.42626212e-04
   3.62814259e-04   1.55881615e-02   4.95528476e-03   9.13303614e-01
   6.25774115e-02], sum to 1.0000
[2017-11-02 10:17:46,768] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.0, 67.0, 4.266666666666667, 318.3333333333334, 0.0, 0.0, 1.0, 16.31275513054737, 19.0, 21.24833995205496, 22.0, 1.0, 48.25888433561532], 
actual action is [1.0, 21.0], 
sim time next is 3261300.0000, 
raw observation next is [-4.0, 66.0, 4.183333333333333, 319.1666666666667, 0.0, 0.0, 1.0, 15.36229875510024, 21.0, 21.30828074309249, 22.0, 1.0, 50.96140654074158], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.23076923076923078, 0.66, 0.38030303030303025, 0.8865740740740742, 0.0, 0.0, 0.5166666666666667, 0.1536229875510024, 0.42857142857142855, 0.4726115347274984, 0.5714285714285714, 1.0, 0.599545959302842], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:17:46,913] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 174621: loss -207.5890
[2017-11-02 10:17:49,233] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175218: loss 127.6579
[2017-11-02 10:17:53,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176271: loss 3.1795
[2017-11-02 10:17:53,986] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11000, global step 176273: loss -3.7691
[2017-11-02 10:17:54,120] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176301: loss 1.1357
[2017-11-02 10:17:54,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.33156148e-27   4.68364811e-19   3.97641670e-19   2.09785579e-19
   2.33405062e-19   5.60066141e-02   1.52051887e-02   8.83716881e-01
   4.50713001e-02], sum to 1.0000
[2017-11-02 10:17:54,581] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-4.166666666666667, 66.0, 3.1, 168.3333333333333, 0.0, 0.0, 0.916666666666667, 22.90575852670105, 20.0, 20.50225617524146, 20.8, 0.0, 56.25624311723973], 
actual action is [0.833333333333333, 22.0], 
sim time next is 3363300.0000, 
raw observation next is [-4.25, 66.5, 3.1, 167.5, 0.0, 0.0, 0.833333333333333, 22.72013993443753, 22.0, 20.50252607101654, 20.8, 0.0, 31.52312728943306], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.22435897435897437, 0.665, 0.2818181818181818, 0.4652777777777778, 0.0, 0.0, 0.5138888888888888, 0.2272013993443753, 0.5714285714285714, 0.35750372443093426, 0.4000000000000001, 0.0, 0.37086032105215366], 
reward next is -0.3763. 
=============================================
[2017-11-02 10:17:55,306] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176596: loss -15.4023
[2017-11-02 10:17:55,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   2.11662476e-11   3.72796585e-11   3.74324217e-11
   1.27217559e-11   5.62589960e-26   6.64310615e-26   2.44653219e-24
   3.54224825e-25], sum to 1.0000
[2017-11-02 10:17:55,476] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.416666666666666, 73.5, 3.1, 164.1666666666667, 0.0, 0.0, -10.33333333333333, 22.68098828490216, 18.0, 20.64901490989127, 20.8, 0.0, 0.0], 
actual action is [-10.416666666666666, 18], 
sim time next is 3367800.0000, 
raw observation next is [-5.5, 74.0, 3.1, 165.0, 0.0, 0.0, -10.41666666666667, 25.17416100534252, 18.0, 20.59003643229631, 20.8, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 1.0, 0.19230769230769232, 0.74, 0.2818181818181818, 0.4583333333333333, 0.0, 0.0, 0.3263888888888888, 0.2517416100534252, 0.0, 0.37000520461375835, 0.4000000000000001, 0.0, 0.0], 
reward next is -0.0300. 
=============================================
[2017-11-02 10:17:55,675] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176685: loss -87.7080
[2017-11-02 10:17:57,048] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176966: loss 87.3385
[2017-11-02 10:17:57,745] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11000, global step 177113: loss 29.2170
[2017-11-02 10:17:57,859] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 177134: loss 13.5767
[2017-11-02 10:17:58,828] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11000, global step 177294: loss -4.8506
[2017-11-02 10:18:02,036] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 177773: loss 0.7356
[2017-11-02 10:18:08,037] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999523e-01   8.06267408e-08   9.37057791e-08   1.25633989e-07
   6.06192785e-08   1.48243912e-13   4.75348060e-12   8.48509457e-11
   4.70211717e-12], sum to 1.0000
[2017-11-02 10:18:08,075] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.166666666666667, 46.66666666666667, 5.1, 223.3333333333333, 78.0, 616.3333333333334, -7.25, 15.74239794504046, 18.0, 22.16279026193547, 22.0, 1.0, 0.0], 
actual action is [-7.166666666666667, 18], 
sim time next is 3340500.0000, 
raw observation next is [-2.083333333333333, 46.33333333333334, 5.1, 221.6666666666667, 75.75, 601.9166666666666, -7.166666666666667, 15.97203572696861, 18.0, 22.14796751004039, 22.0, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6521739130434783, 0.2799145299145299, 0.46333333333333343, 0.4636363636363636, 0.6157407407407409, 0.2003968253968254, 0.6019166666666667, 0.38055555555555554, 0.1597203572696861, 0.0, 0.5925667871486274, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:09,133] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-68.38537598]
 [-67.89758301]
 [-67.60417175]
 [-68.86851501]
 [-68.94946289]], R is [[-69.29692841]
 [-69.10499573]
 [-68.91425323]
 [-68.72302246]
 [-68.52742767]].
[2017-11-02 10:18:14,102] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 180594: loss -20.1167
[2017-11-02 10:18:18,844] A3C_AGENT_WORKER-Thread-6 INFO:Local step 11500, global step 181789: loss 12.9678
[2017-11-02 10:18:19,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.30264375e-13   2.21301208e-13   5.29498700e-13
   1.41567666e-13   8.66603088e-33   1.43013919e-32   3.36827327e-32
   1.12792040e-32], sum to 1.0000
[2017-11-02 10:18:19,398] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.583333333333333, 62.91666666666666, 4.6, 184.1666666666667, 0.0, 0.0, 2.333333333333333, 17.7501572050836, 22.0, 21.13835311662675, 22.0, 1.0, 45.69035383544946], 
actual action is [-7.583333333333333, 18], 
sim time next is 3396600.0000, 
raw observation next is [-2.5, 62.5, 4.6, 185.0, 2.0, 107.0, -7.583333333333333, 19.77878718256328, 18.0, 21.19833163696351, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.30434782608695654, 0.2692307692307692, 0.625, 0.41818181818181815, 0.5138888888888888, 0.005291005291005291, 0.107, 0.3736111111111111, 0.19778787182563282, 0.0, 0.4569045195662156, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:20,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   8.39944552e-16   2.86702680e-16   1.39373787e-15
   4.52231949e-16   1.63560917e-31   1.32982195e-31   3.26792084e-31
   3.42884150e-32], sum to 1.0000
[2017-11-02 10:18:20,129] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 67.0, 8.2, 216.6666666666667, 52.83333333333334, 447.6666666666667, -3.0, 12.26693396223711, 18.0, 22.35944074046187, 22.0, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 3429900.0000, 
raw observation next is [2.0, 67.0, 8.2, 217.5, 48.75, 415.0, -3.0, 12.47407302557438, 18.0, 22.32980959931749, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.38461538461538464, 0.67, 0.7454545454545454, 0.6041666666666666, 0.12896825396825398, 0.415, 0.45, 0.12474073025574381, 0.0, 0.618544228473927, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 10:18:20,360] A3C_AGENT_WORKER-Thread-8 INFO:Local step 11500, global step 182097: loss 37.1075
[2017-11-02 10:18:21,209] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 182260: loss -26.7464
[2017-11-02 10:18:22,259] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 182483: loss 2.0839
[2017-11-02 10:18:23,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.19179503e-16   5.97596369e-17   3.73223945e-16
   6.42419963e-17   2.49021190e-32   7.90615166e-32   5.64770485e-33
   5.80975850e-33], sum to 1.0000
[2017-11-02 10:18:23,399] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 46.0, 9.65, 227.5, 116.5, 813.75, 8.0, 11.55930564432577, 24.5, 22.58056188536528, 22.0, 1.0, 47.38691304132805], 
actual action is [8.0, 19.5], 
sim time next is 3414000.0000, 
raw observation next is [3.0, 46.33333333333334, 9.433333333333334, 226.6666666666667, 116.6666666666667, 814.8333333333334, 8.0, 10.49933210142428, 19.5, 22.6348467392647, 22.0, 1.0, 43.32834436558334], 
processed observation next is [0.5, 0.5217391304347826, 0.41025641025641024, 0.46333333333333343, 0.8575757575757575, 0.6296296296296298, 0.30864197530864207, 0.8148333333333334, 0.6333333333333333, 0.1049933210142428, 0.21428571428571427, 0.6621209627520999, 0.5714285714285714, 1.0, 0.5097452278303922], 
reward next is -0.4693. 
=============================================
[2017-11-02 10:18:24,090] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 182904: loss -0.0472
[2017-11-02 10:18:26,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.07826552e-11   1.33722183e-11   3.13218063e-11
   7.34304111e-12   7.71448107e-21   1.09869304e-20   2.24209789e-21
   1.62863189e-21], sum to 1.0000
[2017-11-02 10:18:26,288] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 67.0, 7.2, 260.0, 0.0, 0.0, 6.0, 13.25850371631552, 19.0, 21.26914893165371, 20.8, 0.0, 58.62089824663666], 
actual action is [-4.0, 18], 
sim time next is 3470700.0000, 
raw observation next is [0.9166666666666666, 67.41666666666666, 7.283333333333333, 260.0, 0.0, 0.0, -4.0, 14.61954602976623, 18.0, 21.316461212252, 20.8, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.35683760683760685, 0.6741666666666666, 0.6621212121212121, 0.7222222222222222, 0.0, 0.0, 0.43333333333333335, 0.1461954602976623, 0.0, 0.4737801731788573, 0.4000000000000001, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:18:27,030] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99947906e-01   9.76412866e-06   7.68338941e-06   1.19577844e-05
   4.43948238e-06   4.25639882e-06   6.70054851e-06   2.30373553e-06
   5.05861135e-06], sum to 1.0000
[2017-11-02 10:18:27,056] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-37.3752861 ]
 [-36.811409  ]
 [-36.87651825]
 [-36.90394592]
 [-36.74664307]], R is [[-38.04278564]
 [-37.67791748]
 [-37.30113983]
 [-36.92812729]
 [-37.21723557]].
[2017-11-02 10:18:27,059] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 78.99999999999999, 6.566666666666666, 210.0, 0.0, 0.0, -4.0, 21.43016237893999, 18.0, 20.795836922548, 22.0, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 3442200.0000, 
raw observation next is [1.0, 79.00000000000001, 6.433333333333334, 210.0, 0.0, 0.0, -4.0, 22.60733380472081, 18.0, 20.72177668581648, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.358974358974359, 0.7900000000000001, 0.5848484848484848, 0.5833333333333334, 0.0, 0.0, 0.43333333333333335, 0.22607333804720808, 0.0, 0.3888252408309256, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:28,333] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.15675834e-16   4.03403544e-16   1.28577526e-15
   2.06958445e-16   3.16731236e-34   5.00452210e-34   2.73890643e-34
   1.98647387e-34], sum to 1.0000
[2017-11-02 10:18:28,351] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.583333333333333, 72.0, 5.908333333333333, 215.8333333333333, 0.0, 0.0, -3.333333333333333, 24.33655953096037, 18.0, 20.3554271864397, 22.0, 1.0, 0.0], 
actual action is [-3.416666666666667, 18], 
sim time next is 3436200.0000, 
raw observation next is [1.5, 73.0, 5.95, 215.0, 0.0, 0.0, -3.416666666666667, 24.96169989415359, 18.0, 20.26954398424778, 22.0, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.3717948717948718, 0.73, 0.5409090909090909, 0.5972222222222222, 0.0, 0.0, 0.44305555555555554, 0.24961699894153588, 0.0, 0.32422056917825415, 0.5714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:28,491] A3C_AGENT_WORKER-Thread-5 INFO:Local step 11500, global step 184380: loss 42.7501
[2017-11-02 10:18:28,653] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184426: loss 20.9203
[2017-11-02 10:18:28,973] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184512: loss -0.4024
[2017-11-02 10:18:29,418] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184625: loss -123.3545
[2017-11-02 10:18:29,655] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184686: loss -14.8867
[2017-11-02 10:18:30,151] A3C_AGENT_WORKER-Thread-4 INFO:Local step 11500, global step 184823: loss 46.0384
[2017-11-02 10:18:30,776] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184967: loss -5.7895
[2017-11-02 10:18:31,148] A3C_AGENT_WORKER-Thread-7 INFO:Local step 11500, global step 185051: loss -61.0266
[2017-11-02 10:18:31,934] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 185250: loss 0.2851
[2017-11-02 10:18:32,369] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-19.66341209]
 [-18.76362038]
 [-19.36914253]
 [-19.55253983]
 [-19.19919777]], R is [[-19.14858055]
 [-18.97017479]
 [-19.39599991]
 [-20.20203972]
 [-21.00001907]].
[2017-11-02 10:18:34,699] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 186108: loss 39.2160
[2017-11-02 10:18:41,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.74602997e-01   3.24418390e-04   1.43555226e-02
   1.07170651e-02], sum to 1.0000
[2017-11-02 10:18:41,514] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-3.0, 69.5, 3.375, 310.0, 0.0, 0.0, -8.0, 27.8014242046544, 18.0, 19.97721140734435, 21.5, 0.0, 0.0], 
actual action is [2.0, 18.5], 
sim time next is 3550800.0000, 
raw observation next is [-3.0, 69.0, 3.633333333333334, 306.6666666666667, 0.0, 0.0, 2.0, 27.62006880177538, 18.5, 19.88638892076835, 21.5, 0.0, 33.0218207076156], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.2564102564102564, 0.69, 0.3303030303030304, 0.8518518518518519, 0.0, 0.0, 0.5333333333333333, 0.27620068801775377, 0.07142857142857142, 0.2694841315383358, 0.5, 0.0, 0.38849200832488945], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:42,897] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.82083797e-01   7.20537500e-05   9.40957107e-03
   8.43468588e-03], sum to 1.0000
[2017-11-02 10:18:42,935] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.0, 70.0, 3.1, 276.6666666666667, 0.0, 0.0, -11.0, 32.3902770247611, 18.0, 19.45523761531435, 21.5, 0.0, 0.0], 
actual action is [-1.0, 18.5], 
sim time next is 3565500.0000, 
raw observation next is [-6.0, 70.0, 3.225, 275.8333333333333, 0.0, 0.0, -1.0, 32.50787407892199, 18.5, 19.33031008754481, 21.5, 0.0, 33.17444956622243], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.1794871794871795, 0.7, 0.2931818181818182, 0.7662037037037036, 0.0, 0.0, 0.48333333333333334, 0.32507874078921994, 0.07142857142857142, 0.19004429822068708, 0.5, 0.0, 0.390287641955558], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:44,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.03214786e-17   1.34449565e-18   6.43187148e-18
   2.61398255e-18   7.43049427e-30   6.03177772e-32   4.19609354e-31
   3.98578866e-32], sum to 1.0000
[2017-11-02 10:18:44,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 49.0, 8.783333333333335, 260.0, 57.91666666666666, 493.8333333333333, -2.0, 10.45665403880816, 18.0, 22.9078548753442, 22.0, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 3516000.0000, 
raw observation next is [3.0, 49.0, 8.566666666666666, 260.0, 53.83333333333334, 462.6666666666667, -2.0, 10.5968220002458, 18.0, 22.92469532039456, 22.0, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.41025641025641024, 0.49, 0.7787878787878788, 0.7222222222222222, 0.14241622574955912, 0.46266666666666667, 0.4666666666666667, 0.105968220002458, 0.0, 0.7035279029135084, 0.5714285714285714, 1.0, 0.0], 
reward next is -0.0106. 
=============================================
[2017-11-02 10:18:44,737] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 189107: loss -2.7557
[2017-11-02 10:18:47,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  2.28857044e-09   6.21570781e-11   3.14574027e-11   4.01365226e-11
   2.76494556e-11   9.40317988e-01   3.62947932e-03   1.24953464e-02
   4.35571782e-02], sum to 1.0000
[2017-11-02 10:18:48,021] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-6.25, 70.0, 4.85, 290.0, 91.0, 487.75, -1.333333333333334, 22.13500228350535, 18.5, 20.48040040331338, 22.7, 1.0, 81.59638298223582], 
actual action is [-1.25, 19.0], 
sim time next is 3574200.0000, 
raw observation next is [-6.166666666666666, 70.0, 4.933333333333334, 290.0, 92.0, 508.6666666666666, -1.25, 21.1966646190759, 19.0, 20.61390208840924, 22.7, 1.0, 55.26106999846727], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.17521367521367523, 0.7, 0.4484848484848485, 0.8055555555555556, 0.24338624338624337, 0.5086666666666666, 0.4791666666666667, 0.211966646190759, 0.14285714285714285, 0.3734145840584629, 0.6714285714285714, 1.0, 0.6501302352760855], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:49,011] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12000, global step 190107: loss 31.3040
[2017-11-02 10:18:50,470] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-34.31914139]
 [-33.46832275]
 [-33.01854706]
 [-32.9153595 ]
 [-34.06440353]], R is [[-37.6366539 ]
 [-38.26028824]
 [-38.87768555]
 [-38.85598755]
 [-38.89196014]].
[2017-11-02 10:18:51,231] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 190577: loss -139.6836
[2017-11-02 10:18:52,613] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12000, global step 190907: loss -152.8328
[2017-11-02 10:18:53,502] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.18004718e-30   9.24341518e-23   2.41423433e-23   1.94974404e-23
   2.73668754e-23   7.98066631e-02   2.82802968e-03   4.16922420e-02
   8.75673056e-01], sum to 1.0000
[2017-11-02 10:18:53,617] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.916666666666667, 69.58333333333333, 5.149999999999999, 287.5, 95.0, 571.4166666666667, -11.0, 23.6682594346008, 18.0, 20.53795143941004, 22.7, 1.0, 0.0], 
actual action is [-0.916666666666667, 23.0], 
sim time next is 3575400.0000, 
raw observation next is [-5.833333333333333, 69.16666666666667, 5.2, 285.0, 96.0, 592.3333333333334, -0.916666666666667, 22.27336326044233, 23.0, 20.52744736102201, 22.7, 1.0, 55.92082418369589], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.18376068376068377, 0.6916666666666668, 0.4727272727272727, 0.7916666666666666, 0.25396825396825395, 0.5923333333333334, 0.4847222222222222, 0.2227336326044233, 0.7142857142857143, 0.3610639087174299, 0.6714285714285714, 1.0, 0.6578920492199517], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:18:53,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-69.16181183]
 [-79.00823212]
 [-77.23888397]
 [-84.58675385]
 [-85.03212738]], R is [[-74.50461578]
 [-74.75956726]
 [-75.01197052]
 [-75.26184845]
 [-75.50923157]].
[2017-11-02 10:18:53,854] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191146: loss 102.1235
[2017-11-02 10:18:54,161] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191209: loss 274.2633
[2017-11-02 10:18:59,844] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12000, global step 192335: loss -0.8086
[2017-11-02 10:19:00,113] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192407: loss 65.1106
[2017-11-02 10:19:00,524] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192520: loss -61.8584
[2017-11-02 10:19:01,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192890: loss 328.2422
[2017-11-02 10:19:02,336] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12000, global step 193077: loss 192.7205
[2017-11-02 10:19:02,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 193118: loss 67.3276
[2017-11-02 10:19:03,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.75415550e-11   9.34067046e-10   2.47623189e-09   4.25447177e-10
   3.51719182e-10   8.13416541e-01   2.15896703e-02   1.10393465e-01
   5.46003841e-02], sum to 1.0000
[2017-11-02 10:19:03,060] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12000, global step 193336: loss -274.9456
[2017-11-02 10:19:03,143] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 23.83687374407866, 25.0, 20.93077262714274, 21.5, 0.0, 36.08902688271026], 
actual action is [4.0, 25], 
sim time next is 3616500.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 20.91563094943416, 25.0, 20.96214941623058, 21.5, 0.0, 63.87714839076795], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.2091563094943416, 1.0, 0.4231642023186544, 0.5, 0.0, 0.7514958634207994], 
reward next is -0.7532. 
=============================================
[2017-11-02 10:19:03,422] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 193474: loss 13.0786
[2017-11-02 10:19:03,817] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 193610: loss -52.5225
[2017-11-02 10:19:04,852] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   5.68258027e-12   3.20215555e-11   1.07226051e-11
   3.27760323e-12   1.51063141e-25   1.25934094e-27   4.27369401e-26
   1.63229111e-26], sum to 1.0000
[2017-11-02 10:19:04,867] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 25.0, 3.1, 170.0, 0.0, 0.0, 13.0, 23.31101903955321, 18.5, 21.01533047344739, 21.5, 0.0, 19.96877094321941], 
actual action is [4.0, 18], 
sim time next is 3629100.0000, 
raw observation next is [9.0, 25.0, 3.141666666666667, 170.0, 0.0, 0.0, 4.0, 23.82727983119417, 18.0, 21.0434451238341, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.5641025641025641, 0.25, 0.28560606060606064, 0.4722222222222222, 0.0, 0.0, 0.5666666666666667, 0.23827279831194167, 0.0, 0.43477787483344293, 0.5, 0.0, 0.0], 
reward next is -0.0652. 
=============================================
[2017-11-02 10:19:05,211] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  6.10665871e-35   6.34114795e-23   1.21336867e-22   1.44562847e-23
   1.80858227e-23   6.78556204e-01   2.29253853e-03   2.77935535e-01
   4.12157252e-02], sum to 1.0000
[2017-11-02 10:19:05,303] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 25.9558715691657, 24.0, 20.14904482750162, 21.5, 0.0, 70.05464863039268], 
actual action is [4.0, 25], 
sim time next is 3615000.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 22.68909036986441, 25.0, 20.32934346413455, 21.5, 0.0, 59.8865763644295], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.2268909036986441, 1.0, 0.3327633520192213, 0.5, 0.0, 0.7045479572285823], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:05,735] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.85363397e-14   1.19810073e-13   7.12129466e-14
   2.02904608e-14   6.31880445e-35   2.09309615e-36   4.28688354e-35
   1.40905555e-35], sum to 1.0000
[2017-11-02 10:19:05,752] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, 4.0, 18.59056431143464, 20.5, 21.38182416908902, 21.5, 0.0, 39.91153771004537], 
actual action is [-6.0, 18], 
sim time next is 3617100.0000, 
raw observation next is [-1.0, 42.0, 0.0, 0.0, 0.0, 0.0, -6.0, 19.81732571851081, 18.0, 21.48618015161107, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.3076923076923077, 0.42, 0.0, 0.0, 0.0, 0.0, 0.4, 0.1981732571851081, 0.0, 0.4980257359444385, 0.5, 0.0, 0.0], 
reward next is -0.0020. 
=============================================
[2017-11-02 10:19:06,794] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.55623233
  0.0013791   0.43126836  0.01112029], sum to 1.0000
[2017-11-02 10:19:06,848] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [9.0, 25.0, 3.1, 170.0, 0.0, 0.0, 13.0, 23.74276388045526, 20.0, 20.78994885324058, 21.5, 0.0, 64.37295503958161], 
actual action is [14.0, 20.5], 
sim time next is 3629100.0000, 
raw observation next is [9.0, 25.0, 3.141666666666667, 170.0, 0.0, 0.0, 14.0, 22.28876381331322, 20.5, 20.95372202938983, 21.5, 0.0, 29.76415672637739], 
processed observation next is [1.0, 0.0, 0.5641025641025641, 0.25, 0.28560606060606064, 0.4722222222222222, 0.0, 0.0, 0.7333333333333333, 0.2228876381331322, 0.35714285714285715, 0.42196028991283285, 0.5, 0.0, 0.35016654972208694], 
reward next is -0.3932. 
=============================================
[2017-11-02 10:19:07,412] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 194832: loss 1.0698
[2017-11-02 10:19:09,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.98345985e-20   1.04604375e-19   6.52045410e-20
   9.14525069e-21   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:09,520] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 58.99999999999999, 5.016666666666667, 251.6666666666667, 35.41666666666666, 313.75, -1.0, 15.98010650472652, 18.0, 21.98952827873061, 22.7, 1.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 3690600.0000, 
raw observation next is [4.0, 59.0, 4.933333333333334, 253.3333333333333, 31.33333333333333, 284.0, -1.0, 16.36083904732616, 18.0, 21.94300560163686, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4358974358974359, 0.59, 0.4484848484848485, 0.7037037037037036, 0.08289241622574954, 0.284, 0.48333333333333334, 0.1636083904732616, 0.0, 0.5632865145195513, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:11,532] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-56.61439133]
 [-58.12146759]
 [-56.86539078]
 [-59.28170395]
 [-56.03392792]], R is [[-55.79149246]
 [-55.24613571]
 [-55.16177368]
 [-54.62306976]
 [-54.08916855]].
[2017-11-02 10:19:13,619] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 196891: loss -13.9996
[2017-11-02 10:19:14,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-64.3821106 ]
 [-65.17749023]
 [-65.5340271 ]
 [-67.04013824]
 [-63.82969666]], R is [[-66.77072144]
 [-67.10301208]
 [-67.43198395]
 [-67.75766754]
 [-68.08009338]].
[2017-11-02 10:19:15,126] A3C_AGENT_WORKER-Thread-6 INFO:Local step 12500, global step 197450: loss -209.5737
[2017-11-02 10:19:15,903] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   1.56717030e-16   3.35455461e-16   3.43788042e-16
   6.00851424e-17   1.66329406e-31   7.12415606e-34   5.15641999e-32
   1.99709805e-32], sum to 1.0000
[2017-11-02 10:19:15,924] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 71.0, 6.2, 240.0, 113.0, 795.5, 2.0, 12.40014652029015, 20.5, 22.51681272156744, 22.7, 1.0, 19.80352560320729], 
actual action is [-8.0, 18], 
sim time next is 3755100.0000, 
raw observation next is [-2.916666666666667, 70.5, 6.241666666666667, 240.8333333333333, 113.3333333333333, 799.9166666666667, -8.0, 12.72561870504081, 18.0, 22.57260414091619, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.4782608695652174, 0.2585470085470085, 0.705, 0.5674242424242425, 0.6689814814814814, 0.2998236331569664, 0.7999166666666667, 0.36666666666666664, 0.12725618705040811, 0.0, 0.6532291629880272, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0127. 
=============================================
[2017-11-02 10:19:19,600] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   9.95472368e-13   2.21807577e-12   1.47247037e-12
   3.92231169e-13   1.32283823e-26   3.92957501e-28   2.86930990e-26
   2.65004494e-27], sum to 1.0000
[2017-11-02 10:19:19,799] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 72.0, 5.783333333333333, 276.6666666666667, 32.99999999999999, 233.6666666666666, 1.0, 18.95232262656082, 25.0, 20.6798452575063, 22.7, 1.0, 73.59752460476399], 
actual action is [1.0, 20.0], 
sim time next is 3743700.0000, 
raw observation next is [-4.0, 71.5, 5.741666666666666, 278.3333333333333, 39.99999999999999, 258.0833333333333, 1.0, 17.77447151532182, 20.0, 20.8339063984327, 22.7, 1.0, 51.23312349174719], 
processed observation next is [0.0, 0.30434782608695654, 0.23076923076923078, 0.715, 0.521969696969697, 0.7731481481481481, 0.1058201058201058, 0.25808333333333333, 0.5166666666666667, 0.1777447151532182, 0.2857142857142857, 0.4048437712046713, 0.6714285714285714, 1.0, 0.6027426293146728], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:20,569] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 198989: loss 73.6182
[2017-11-02 10:19:21,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.63517871e-16   8.60283190e-16   6.86547732e-16
   5.49859974e-17   0.00000000e+00   0.00000000e+00   1.45264036e-37
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:21,869] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 5.1, 268.3333333333333, 0.0, 0.0, 2.0, 23.53683661021357, 22.0, 20.11504506345579, 21.5, 0.0, 33.32675108801453], 
actual action is [-8.0, 18], 
sim time next is 3729300.0000, 
raw observation next is [-3.0, 65.0, 5.1, 269.1666666666667, 0.0, 0.0, -8.0, 25.00433355852069, 18.0, 20.17227832331261, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.2564102564102564, 0.65, 0.4636363636363636, 0.7476851851851852, 0.0, 0.0, 0.36666666666666664, 0.25004333558520686, 0.0, 0.3103254747589444, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:21,913] A3C_AGENT_WORKER-Thread-8 INFO:Local step 12500, global step 199358: loss 111.3865
[2017-11-02 10:19:21,972] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199378: loss 4.8288
[2017-11-02 10:19:22,198] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199436: loss 62.2199
[2017-11-02 10:19:22,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.55269835e-16   8.28943712e-16   7.08730255e-16
   5.36041724e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:22,438] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 65.0, 4.725, 277.5, 0.0, 0.0, -8.0, 27.32375903454413, 18.0, 20.07199055436642, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 3732600.0000, 
raw observation next is [-3.0, 65.0, 4.683333333333333, 278.3333333333333, 0.0, 0.0, -8.0, 29.4271570713551, 18.0, 19.94811002385915, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.17391304347826086, 0.2564102564102564, 0.65, 0.4257575757575757, 0.7731481481481481, 0.0, 0.0, 0.36666666666666664, 0.29427157071355103, 0.0, 0.2783014319798787, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,008] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.65671238e-02   1.74296423e-04   9.69382644e-01
   3.87601997e-03], sum to 1.0000
[2017-11-02 10:19:25,042] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 65.0, 6.7, 270.0, 0.0, 0.0, 2.0, 31.54844889289715, 20.0, 19.05929846838925, 21.5, 0.0, 36.79251077979669], 
actual action is [2.0, 22.0], 
sim time next is 3737100.0000, 
raw observation next is [-3.083333333333333, 66.0, 6.658333333333333, 269.1666666666667, 0.0, 0.0, 2.0, 31.44936522957344, 22.0, 19.05746247281106, 21.5, 0.0, 23.99762552011929], 
processed observation next is [0.0, 0.2608695652173913, 0.2542735042735043, 0.66, 0.6053030303030303, 0.7476851851851852, 0.0, 0.0, 0.5333333333333333, 0.3144936522957344, 0.5714285714285714, 0.15106606754443724, 0.5, 0.0, 0.2823250061190505], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,279] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.99405228e-19   3.24522124e-18   3.03282814e-18
   1.00076498e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:25,309] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.416666666666667, 70.0, 6.491666666666666, 265.8333333333333, 0.0, 0.0, 1.666666666666667, 29.22112305348767, 22.0, 18.93384805284882, 21.5, 0.0, 66.76207094929062], 
actual action is [-8.416666666666668, 18], 
sim time next is 3738600.0000, 
raw observation next is [-3.5, 71.0, 6.45, 265.0, 0.0, 0.0, -8.416666666666668, 30.65163307987584, 18.0, 19.084816138229, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.2608695652173913, 0.24358974358974358, 0.71, 0.5863636363636364, 0.7361111111111112, 0.0, 0.0, 0.3597222222222222, 0.3065163307987584, 0.0, 0.1549737340327145, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,628] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200437: loss -10.9413
[2017-11-02 10:19:25,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.16071382e-16   1.07463335e-15   8.09543587e-16
   4.86554618e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:25,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.25, 66.75, 4.475, 305.0, 0.0, 0.0, -7.0, 24.79982712919686, 18.0, 20.68481041806573, 21.5, 0.0, 0.0], 
actual action is [-7.25, 18], 
sim time next is 3711000.0000, 
raw observation next is [-2.5, 66.16666666666667, 4.516666666666666, 306.6666666666667, 0.0, 0.0, -7.25, 26.10855629088771, 18.0, 20.67095049766957, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.2692307692307692, 0.6616666666666667, 0.41060606060606053, 0.8518518518518519, 0.0, 0.0, 0.37916666666666665, 0.2610855629088771, 0.0, 0.38156435680993844, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:25,917] A3C_AGENT_WORKER-Thread-5 INFO:Local step 12500, global step 200515: loss 5.1275
[2017-11-02 10:19:26,667] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200695: loss 53.6359
[2017-11-02 10:19:27,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200788: loss -1.1842
[2017-11-02 10:19:27,462] A3C_AGENT_WORKER-Thread-4 INFO:Local step 12500, global step 200882: loss 38.1482
[2017-11-02 10:19:28,262] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 201073: loss 60.7558
[2017-11-02 10:19:28,777] A3C_AGENT_WORKER-Thread-7 INFO:Local step 12500, global step 201204: loss 19.2769
[2017-11-02 10:19:28,847] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 201220: loss -141.8388
[2017-11-02 10:19:30,090] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 201575: loss -147.5149
[2017-11-02 10:19:36,324] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.05512127e-11   2.13797632e-10   3.07009938e-11
   1.16290202e-12   7.41976991e-27   1.83938944e-27   5.87645286e-24
   9.63679816e-26], sum to 1.0000
[2017-11-02 10:19:36,395] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 76.5, 4.558333333333333, 220.0, 0.0, 0.0, 2.0, 17.75491872267448, 25.0, 20.7973287348411, 21.5, 0.0, 58.01731820808845], 
actual action is [2.0, 20.0], 
sim time next is 3794400.0000, 
raw observation next is [-3.0, 77.0, 4.6, 220.0, 0.0, 0.0, 2.0, 16.65805846548043, 20.0, 20.9300407140658, 21.5, 0.0, 39.07899924935622], 
processed observation next is [0.0, 0.9565217391304348, 0.2564102564102564, 0.77, 0.41818181818181815, 0.6111111111111112, 0.0, 0.0, 0.5333333333333333, 0.1665805846548043, 0.2857142857142857, 0.4185772448665429, 0.5, 0.0, 0.45975293234536735], 
reward next is -0.4952. 
=============================================
[2017-11-02 10:19:36,556] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 203047: loss 34.4911
[2017-11-02 10:19:47,969] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 204648: loss 86.5549
[2017-11-02 10:19:52,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.23256621e-16   1.50662216e-15   2.67726045e-16
   2.05856783e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:19:52,753] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.583333333333334, 61.91666666666667, 5.35, 155.8333333333333, 0.0, 0.0, -11.5, 23.20506433043878, 18.0, 20.17161335357242, 21.5, 0.0, 0.0], 
actual action is [-11.583333333333334, 18], 
sim time next is 3912000.0000, 
raw observation next is [-6.666666666666666, 62.33333333333333, 5.3, 126.6666666666667, 0.0, 0.0, -11.58333333333333, 26.1528836332415, 18.0, 20.05920712734814, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.1623931623931624, 0.6233333333333333, 0.4818181818181818, 0.35185185185185197, 0.0, 0.0, 0.3069444444444445, 0.261528836332415, 0.0, 0.2941724467640202, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:19:54,871] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13000, global step 205609: loss -28.2170
[2017-11-02 10:20:02,621] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 206800: loss 80.0694
[2017-11-02 10:20:03,016] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 206847: loss 21.2342
[2017-11-02 10:20:03,242] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13000, global step 206881: loss -51.5897
[2017-11-02 10:20:06,954] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207470: loss -77.9760
[2017-11-02 10:20:10,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   9.23825748e-17   5.14765692e-16   2.07502320e-16
   2.33636767e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:20:10,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.0, 65.0, 2.725, 347.5, 0.0, 0.0, 3.0, 25.99831607109887, 22.0, 19.9787413965511, 21.5, 0.0, 22.41757541662042], 
actual action is [-7.0, 18], 
sim time next is 3896400.0000, 
raw observation next is [-2.0, 65.0, 2.933333333333334, 346.6666666666667, 0.0, 0.0, -7.0, 27.04576328129081, 18.0, 19.99664144766506, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.28205128205128205, 0.65, 0.2666666666666667, 0.962962962962963, 0.0, 0.0, 0.38333333333333336, 0.2704576328129081, 0.0, 0.28523449252357985, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:10,798] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-35.5450592 ]
 [-35.81684875]
 [-37.83666611]
 [-40.91237259]
 [-46.11975479]], R is [[-41.48830032]
 [-42.07341766]
 [-42.65268326]
 [-43.22615814]
 [-43.79389572]].
[2017-11-02 10:20:11,249] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208102: loss -74.9472
[2017-11-02 10:20:11,739] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13000, global step 208169: loss -30.8742
[2017-11-02 10:20:12,206] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.44066392e-02   1.78122864e-05   9.45497096e-01
   7.84860313e-05], sum to 1.0000
[2017-11-02 10:20:12,304] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-2.833333333333333, 70.0, 5.016666666666667, 340.0, 0.0, 0.0, 2.25, 26.08262454340635, 20.0, 20.01016447113307, 21.5, 0.0, 56.35246528581182], 
actual action is [2.166666666666667, 22.0], 
sim time next is 3902100.0000, 
raw observation next is [-2.916666666666667, 70.5, 5.058333333333334, 340.0, 0.0, 0.0, 2.166666666666667, 25.44851257068176, 22.0, 20.052155435504, 21.5, 0.0, 28.96146985160053], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.2585470085470085, 0.705, 0.4598484848484849, 0.9444444444444444, 0.0, 0.0, 0.5361111111111111, 0.2544851257068176, 0.5714285714285714, 0.2931650622148574, 0.5, 0.0, 0.34072317472471214], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:12,766] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208312: loss -46.5830
[2017-11-02 10:20:13,505] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208437: loss -119.6547
[2017-11-02 10:20:14,777] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13000, global step 208612: loss -34.4206
[2017-11-02 10:20:15,316] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208691: loss -39.1819
[2017-11-02 10:20:15,732] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13000, global step 208756: loss -21.2937
[2017-11-02 10:20:16,303] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.80728073e-08   1.23200703e-08   6.87769042e-09
   4.58236871e-09   7.19174220e-10   7.43050500e-12   7.88557775e-10
   2.03461336e-12], sum to 1.0000
[2017-11-02 10:20:16,316] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 49.0, 3.183333333333334, 296.6666666666667, 117.6666666666667, 798.3333333333334, -1.0, 11.08704572168418, 18.5, 22.88830536915185, 22.7, 1.0, 40.30642731206357], 
actual action is [-11.0, 18], 
sim time next is 3928500.0000, 
raw observation next is [-6.0, 49.0, 3.225, 270.0, 118.25, 801.25, -11.0, 11.5391536648214, 18.0, 22.90074740915466, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.1794871794871795, 0.49, 0.2931818181818182, 0.75, 0.31283068783068785, 0.80125, 0.31666666666666665, 0.115391536648214, 0.0, 0.7001067727363802, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0115. 
=============================================
[2017-11-02 10:20:16,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208845: loss 1.6252
[2017-11-02 10:20:17,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208941: loss -48.1817
[2017-11-02 10:20:28,438] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.58311881e-14   8.86046014e-15   9.62381047e-15
   4.38651343e-15   7.07229010e-30   8.48957302e-32   1.28050914e-29
   3.59306629e-32], sum to 1.0000
[2017-11-02 10:20:28,462] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 49.0, 3.475, 110.0, 119.75, 816.25, -11.0, 10.05557353353115, 18.0, 23.51865541345956, 22.7, 1.0, 0.0], 
actual action is [-11.0, 18], 
sim time next is 3930600.0000, 
raw observation next is [-6.0, 49.0, 3.516666666666667, 83.33333333333331, 119.6666666666667, 818.3333333333334, -11.0, 10.49513580065516, 18.0, 23.43991280931138, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.1794871794871795, 0.49, 0.31969696969696976, 0.23148148148148143, 0.31657848324515, 0.8183333333333334, 0.31666666666666665, 0.10495135800655159, 0.0, 0.7771304013301972, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0105. 
=============================================
[2017-11-02 10:20:28,589] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 210342: loss 106.8551
[2017-11-02 10:20:34,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   3.17327371e-12   2.58111327e-12   1.84576464e-12
   1.24921178e-12   7.47558956e-14   1.37998740e-16   3.82048858e-14
   1.49107032e-15], sum to 1.0000
[2017-11-02 10:20:34,896] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.833333333333334, 43.33333333333334, 2.600000000000001, 116.6666666666667, 108.3333333333333, 753.3333333333334, -3.916666666666666, 14.36034073773626, 19.0, 22.46291278889231, 22.7, 1.0, 27.0171742352784], 
actual action is [-13.833333333333334, 18], 
sim time next is 4011300.0000, 
raw observation next is [-8.75, 43.0, 2.6, 120.0, 109.25, 760.25, -13.83333333333333, 15.01507826655605, 18.0, 22.50316843153049, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.43478260869565216, 0.10897435897435898, 0.43, 0.23636363636363636, 0.3333333333333333, 0.289021164021164, 0.76025, 0.26944444444444454, 0.15015078266556048, 0.0, 0.6433097759329272, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:40,870] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.14415072e-15   1.99936410e-15   1.88178576e-15
   6.37788228e-16   5.41099519e-33   4.81149582e-35   1.58022029e-32
   1.00549193e-32], sum to 1.0000
[2017-11-02 10:20:40,897] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.75, 20.5, 1.9, 60.0, 92.75, 732.5, -6.833333333333333, 14.15254130347458, 18.0, 22.39039714836531, 22.7, 1.0, 0.0], 
actual action is [-6.75, 18], 
sim time next is 4029600.0000, 
raw observation next is [-1.666666666666667, 20.66666666666667, 2.033333333333333, 63.33333333333334, 91.5, 725.6666666666667, -6.75, 14.12336578392713, 18.0, 22.44431612800078, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.29059829059829057, 0.20666666666666672, 0.18484848484848485, 0.17592592592592596, 0.24206349206349206, 0.7256666666666668, 0.3875, 0.1412336578392713, 0.0, 0.6349023040001113, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0141. 
=============================================
[2017-11-02 10:20:46,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[ -75.50553894]
 [ -76.90077209]
 [ -96.42882538]
 [ -94.76527405]
 [-100.073349  ]], R is [[-74.73484802]
 [-74.98750305]
 [-75.23762512]
 [-75.48525238]
 [-75.73040009]].
[2017-11-02 10:20:48,381] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13500, global step 212915: loss 108.2698
[2017-11-02 10:20:50,916] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-74.17179108]
 [-73.54226685]
 [-75.65028381]
 [-75.73925781]
 [-76.5715332 ]], R is [[-72.71204376]
 [-72.98492432]
 [-73.25507355]
 [-73.52252197]
 [-73.78730011]].
[2017-11-02 10:20:51,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-88.24212646]
 [-86.34049225]
 [-90.82637787]
 [-87.74214935]
 [-86.67502594]], R is [[-87.89809418]
 [-88.01911163]
 [-88.13892365]
 [-88.25753784]
 [-88.37496185]].
[2017-11-02 10:20:55,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.93079126e-01   6.76325783e-07   5.64945955e-03
   1.27076171e-03], sum to 1.0000
[2017-11-02 10:20:55,215] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-13.08333333333333, 63.5, 1.375, 9.166666666666666, 0.0, 0.0, -18.0, 34.45104716754836, 18.0, 19.11111993596538, 21.5, 0.0, 0.0], 
actual action is [-8.08333333333333, 18.5], 
sim time next is 3996600.0000, 
raw observation next is [-13.16666666666667, 64.0, 1.25, 8.333333333333334, 0.0, 0.0, -8.08333333333333, 34.05991327924379, 18.5, 18.95152402744102, 21.5, 0.0, 48.43734841781303], 
processed observation next is [0.5, 0.2608695652173913, -0.004273504273504349, 0.64, 0.11363636363636363, 0.02314814814814815, 0.0, 0.0, 0.36527777777777787, 0.34059913279243786, 0.07142857142857142, 0.13593200392014587, 0.5, 0.0, 0.5698511578566239], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:20:57,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-54.94434738]
 [-54.04138184]
 [-76.44363403]
 [-75.1916275 ]
 [-77.27340698]], R is [[-57.90265656]
 [-58.32363129]
 [-58.74039459]
 [-59.15299225]
 [-59.5614624 ]].
[2017-11-02 10:20:59,696] A3C_AGENT_WORKER-Thread-6 INFO:Local step 13500, global step 214078: loss -12.2846
[2017-11-02 10:21:07,786] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   3.73072206e-13   2.39034703e-12   4.83145045e-13
   9.16263864e-14   6.49520500e-28   7.73713485e-31   6.36491295e-28
   1.93738830e-26], sum to 1.0000
[2017-11-02 10:21:07,888] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 41.0, 3.141666666666667, 139.1666666666667, 0.0, 0.0, -1.0, 20.24956605877135, 25.0, 20.78711685376989, 21.5, 0.0, 42.0662801539339], 
actual action is [-1.0, 20.0], 
sim time next is 4068000.0000, 
raw observation next is [-6.0, 41.0, 3.1, 140.0, 0.0, 0.0, -1.0, 19.78670809973074, 20.0, 20.83809440057635, 21.5, 0.0, 46.04721850571779], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.1794871794871795, 0.41, 0.2818181818181818, 0.3888888888888889, 0.0, 0.0, 0.48333333333333334, 0.19786708099730738, 0.2857142857142857, 0.4054420572251927, 0.5, 0.0, 0.5417319824202093], 
reward next is -0.5821. 
=============================================
[2017-11-02 10:21:09,690] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13500, global step 215208: loss 192.7398
[2017-11-02 10:21:11,149] A3C_AGENT_WORKER-Thread-8 INFO:Local step 13500, global step 215372: loss -25.5084
[2017-11-02 10:21:11,566] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13500, global step 215428: loss 17.7826
[2017-11-02 10:21:13,770] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13500, global step 215759: loss -13.7333
[2017-11-02 10:21:13,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   9.10861221e-16   3.48074134e-16   4.39470127e-16
   3.25253664e-16   2.58219539e-28   4.99896069e-30   4.04295969e-29
   4.08125115e-28], sum to 1.0000
[2017-11-02 10:21:14,052] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.583333333333333, 23.16666666666666, 2.808333333333334, 66.66666666666667, 63.08333333333333, 518.4166666666666, -6.5, 10.16112057707003, 18.0, 23.63566590640768, 22.7, 1.0, 0.0], 
actual action is [-6.583333333333333, 18], 
sim time next is 4034400.0000, 
raw observation next is [-1.666666666666667, 23.33333333333334, 2.766666666666667, 63.33333333333333, 59.16666666666667, 488.8333333333334, -6.583333333333333, 10.43937916669188, 18.0, 23.55667142282114, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.29059829059829057, 0.2333333333333334, 0.2515151515151515, 0.1759259259259259, 0.15652557319223986, 0.48883333333333345, 0.3902777777777778, 0.10439379166691881, 0.0, 0.7938102032601628, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0104. 
=============================================
[2017-11-02 10:21:15,513] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   1.65896008e-08   4.50031017e-08   1.55336828e-08
   5.42776579e-09   9.42785008e-14   3.10519250e-15   3.56892013e-14
   1.35724862e-12], sum to 1.0000
[2017-11-02 10:21:15,606] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 38.33333333333334, 2.933333333333334, 130.0, 0.0, 0.0, -1.0, 15.22406859686022, 25.0, 21.56243594207152, 21.5, 0.0, 46.67537084857686], 
actual action is [-1.0, 20.0], 
sim time next is 4062300.0000, 
raw observation next is [-6.0, 38.66666666666667, 3.016666666666667, 130.0, 0.0, 0.0, -1.0, 14.78231481950856, 20.0, 21.61720829875223, 21.5, 0.0, 46.28257483096814], 
processed observation next is [0.6666666666666666, 0.0, 0.1794871794871795, 0.3866666666666667, 0.2742424242424243, 0.3611111111111111, 0.0, 0.0, 0.48333333333333334, 0.1478231481950856, 0.2857142857142857, 0.5167440426788902, 0.5, 0.0, 0.544500880364331], 
reward next is -0.4901. 
=============================================
[2017-11-02 10:21:15,996] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13500, global step 216093: loss 147.6115
[2017-11-02 10:21:19,108] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13500, global step 216450: loss 48.6470
[2017-11-02 10:21:19,144] A3C_AGENT_WORKER-Thread-4 INFO:Local step 13500, global step 216452: loss 8.2971
[2017-11-02 10:21:19,257] A3C_AGENT_WORKER-Thread-5 INFO:Local step 13500, global step 216465: loss 39.4643
[2017-11-02 10:21:20,007] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13500, global step 216555: loss 15.4179
[2017-11-02 10:21:21,269] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13500, global step 216718: loss -23.6226
[2017-11-02 10:21:21,621] A3C_AGENT_WORKER-Thread-7 INFO:Local step 13500, global step 216760: loss -22.4234
[2017-11-02 10:21:22,123] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13500, global step 216828: loss 69.6214
[2017-11-02 10:21:23,206] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13500, global step 216965: loss 19.5934
[2017-11-02 10:21:35,064] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   2.02534090e-15   9.37826832e-16   1.15150678e-15
   8.20011643e-16   1.57837317e-29   1.42720860e-30   1.07331004e-30
   4.98553718e-29], sum to 1.0000
[2017-11-02 10:21:35,075] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.416666666666667, 32.66666666666666, 2.1, 227.5, 106.8333333333333, 797.0, -1.666666666666667, 10.88436426110661, 18.0, 23.04593480424446, 22.7, 1.0, 0.0], 
actual action is [-1.583333333333333, 18], 
sim time next is 4113000.0000, 
raw observation next is [3.5, 33.0, 2.1, 225.0, 106.0, 794.0, -1.583333333333333, 10.78411850412194, 18.0, 23.0958886336876, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.4230769230769231, 0.33, 0.19090909090909092, 0.625, 0.2804232804232804, 0.794, 0.47361111111111115, 0.1078411850412194, 0.0, 0.7279840905268001, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0108. 
=============================================
[2017-11-02 10:21:38,024] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13500, global step 218811: loss 12.3704
[2017-11-02 10:21:41,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.80721997e-14   1.41343659e-14   1.53141744e-14
   1.33385226e-14   7.58270506e-25   9.18203649e-26   1.32105877e-25
   2.05309452e-24], sum to 1.0000
[2017-11-02 10:21:41,497] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.833333333333333, 34.33333333333334, 2.1, 215.0, 102.0, 761.0, -1.25, 10.18527914175437, 18.0, 23.45598159601039, 22.7, 1.0, 0.0], 
actual action is [-1.166666666666667, 18], 
sim time next is 4114500.0000, 
raw observation next is [3.916666666666667, 34.66666666666666, 2.1, 212.5, 101.0, 752.75, -1.166666666666667, 10.07193098297971, 18.0, 23.49865764314284, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.4337606837606838, 0.34666666666666657, 0.19090909090909092, 0.5902777777777778, 0.2671957671957672, 0.75275, 0.4805555555555555, 0.1007193098297971, 0.0, 0.7855225204489769, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0101. 
=============================================
[2017-11-02 10:21:43,401] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-4.52988386]
 [-5.9500556 ]
 [-4.84054804]
 [-5.27604532]
 [-5.59875154]], R is [[-4.65907955]
 [-4.62635183]
 [-4.59395981]
 [-4.56189632]
 [-4.53015184]].
[2017-11-02 10:21:48,553] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14000, global step 220473: loss -233.5378
[2017-11-02 10:21:49,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   3.82479232e-13   6.83384447e-13   3.11694464e-13
   1.31320844e-13   5.31547035e-27   7.76141631e-28   2.38056477e-27
   1.72477411e-25], sum to 1.0000
[2017-11-02 10:21:49,340] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.833333333333333, 37.5, 1.925, 284.1666666666666, 0.0, 0.0, 8.0, 15.50963149194227, 23.0, 21.34991351710735, 22.7, 1.0, 66.12440764827359], 
actual action is [-2.166666666666667, 18.0], 
sim time next is 4129800.0000, 
raw observation next is [2.666666666666667, 38.0, 1.75, 258.3333333333334, 0.0, 0.0, -2.166666666666667, 16.09870915292382, 18.0, 21.4346751191923, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8260869565217391, 0.4017094017094017, 0.38, 0.1590909090909091, 0.7175925925925929, 0.0, 0.0, 0.46388888888888885, 0.1609870915292382, 0.0, 0.4906678741703284, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:00,385] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14000, global step 222246: loss -79.0669
[2017-11-02 10:22:06,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00613892
  0.00144175  0.00602533  0.98639399], sum to 1.0000
[2017-11-02 10:22:07,065] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666666, 49.33333333333333, 3.433333333333334, 336.6666666666667, 0.0, 0.0, 0.4166666666666661, 23.42791320001479, 23.0, 19.94956015195887, 21.5, 0.0, 61.77320937448273], 
actual action is [0.3333333333333339, 25], 
sim time next is 4171500.0000, 
raw observation next is [-4.75, 49.25, 3.475, 337.5, 0.0, 0.0, 0.3333333333333339, 22.47378263887184, 25.0, 19.96477231457709, 21.5, 0.0, 52.20718638971506], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.21153846153846154, 0.4925, 0.3159090909090909, 0.9375, 0.0, 0.0, 0.5055555555555556, 0.2247378263887184, 1.0, 0.28068175922529853, 0.5, 0.0, 0.6142021928201772], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:07,368] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14000, global step 223167: loss -62.9907
[2017-11-02 10:22:08,333] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14000, global step 223286: loss -17.0109
[2017-11-02 10:22:08,613] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14000, global step 223323: loss 38.6578
[2017-11-02 10:22:08,840] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-47.6086731 ]
 [-48.42660904]
 [-48.9163475 ]
 [-48.41316223]
 [-49.8308754 ]], R is [[-48.37583923]
 [-48.89208221]
 [-49.4031601 ]
 [-49.9091301 ]
 [-50.41003799]].
[2017-11-02 10:22:09,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   1.35959707e-18   1.26280556e-18   1.19757214e-18
   9.05631663e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.57033003e-38], sum to 1.0000
[2017-11-02 10:22:09,802] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 39.5, 3.683333333333333, 275.0, 53.33333333333334, 421.0, -2.75, 16.83833714889381, 18.0, 22.58309853873734, 22.7, 1.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 4208100.0000, 
raw observation next is [2.083333333333333, 39.75, 3.641666666666667, 272.5, 49.66666666666667, 388.75, -2.833333333333333, 17.42321975187698, 18.0, 22.47714183422746, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6956521739130435, 0.3867521367521367, 0.3975, 0.3310606060606061, 0.7569444444444444, 0.13139329805996475, 0.38875, 0.4527777777777778, 0.1742321975187698, 0.0, 0.6395916906039228, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:12,443] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14000, global step 223767: loss 16.6856
[2017-11-02 10:22:14,087] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14000, global step 223978: loss -75.3432
[2017-11-02 10:22:15,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14000, global step 224170: loss 105.4971
[2017-11-02 10:22:17,038] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14000, global step 224395: loss -15.2181
[2017-11-02 10:22:18,741] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14000, global step 224650: loss -3.4962
[2017-11-02 10:22:19,021] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   5.96573987e-16   6.21836215e-16   9.10027740e-16
   6.29857829e-16   3.41592459e-35   6.14086457e-35   1.47307680e-35
   5.13337327e-34], sum to 1.0000
[2017-11-02 10:22:19,054] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 42.33333333333333, 4.475, 254.1666666666667, 184.75, 126.4166666666667, -3.0, 15.28659870743857, 18.0, 22.43447797713293, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4200000.0000, 
raw observation next is [2.0, 42.66666666666667, 4.6, 253.3333333333333, 182.5, 163.8333333333333, -3.0, 15.8541298961656, 18.0, 22.41634679023441, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.38461538461538464, 0.4266666666666667, 0.41818181818181815, 0.7037037037037036, 0.4828042328042328, 0.16383333333333328, 0.45, 0.158541298961656, 0.0, 0.6309066843192015, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:19,433] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14000, global step 224757: loss -85.9502
[2017-11-02 10:22:19,683] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14000, global step 224790: loss -63.2741
[2017-11-02 10:22:19,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14000, global step 224807: loss 0.9164
[2017-11-02 10:22:20,019] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14000, global step 224841: loss -21.6549
[2017-11-02 10:22:20,770] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-39.50560379]
 [-40.29600906]
 [-39.89154816]
 [-39.5532341 ]
 [-40.84485245]], R is [[-40.29840088]
 [-39.90842438]
 [-39.52207565]
 [-39.89686584]
 [-39.51252747]].
[2017-11-02 10:22:23,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14000, global step 225270: loss 4.7795
[2017-11-02 10:22:24,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   6.28607545e-15   1.30056996e-14   1.24624999e-14
   6.52611950e-15   7.24516017e-33   2.57774156e-32   2.41537236e-33
   4.64794434e-33], sum to 1.0000
[2017-11-02 10:22:24,861] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.5, 41.66666666666667, 3.433333333333334, 253.3333333333333, 0.0, 0.0, 6.525, 18.09935369105467, 19.0, 21.95823538066601, 22.7, 1.0, 24.8056347440748], 
actual action is [-3.5, 18], 
sim time next is 4214700.0000, 
raw observation next is [1.475, 41.75, 3.425, 252.5, 0.0, 0.0, -3.5, 18.76292393871377, 18.0, 21.94132398170643, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.37115384615384617, 0.4175, 0.31136363636363634, 0.7013888888888888, 0.0, 0.0, 0.44166666666666665, 0.1876292393871377, 0.0, 0.5630462831009184, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:36,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.15112413e-16   5.49036539e-16   1.88806212e-16
   8.44290546e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.04762048e-38], sum to 1.0000
[2017-11-02 10:22:36,254] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 5.7, 241.6666666666667, 0.0, 0.0, -2.0, 23.76779950737041, 18.0, 20.73107713918876, 21.5, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4243200.0000, 
raw observation next is [3.0, 45.0, 5.7, 243.3333333333333, 0.0, 0.0, -2.0, 24.99913868269318, 18.0, 20.72597322004734, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.08695652173913043, 0.41025641025641024, 0.45, 0.5181818181818182, 0.6759259259259258, 0.0, 0.0, 0.4666666666666667, 0.24999138682693178, 0.0, 0.38942474572104857, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:39,357] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14000, global step 227450: loss 4.8208
[2017-11-02 10:22:40,309] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.10834683
  0.05139541  0.38015783  0.46009982], sum to 1.0000
[2017-11-02 10:22:40,585] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [3.0, 49.0, 5.1, 220.0, 18.33333333333333, 8.833333333333332, -2.0, 24.77850009493559, 18.0, 20.33262434942724, 21.5, 0.0, 0.0], 
actual action is [8.0, 20.0], 
sim time next is 4261500.0000, 
raw observation next is [3.0, 49.0, 5.1, 220.0, 27.5, 13.25, 8.0, 23.44015343607195, 20.0, 20.36358745495042, 21.5, 0.0, 43.16855513995353], 
processed observation next is [1.0, 0.30434782608695654, 0.41025641025641024, 0.49, 0.4636363636363636, 0.6111111111111112, 0.07275132275132275, 0.01325, 0.6333333333333333, 0.23440153436071948, 0.2857142857142857, 0.33765535070720276, 0.5, 0.0, 0.5078653545876887], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:41,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   2.95313253e-35   6.69654795e-35   5.05560756e-36
   2.26881057e-35   4.52467501e-02   3.68910283e-02   3.96615893e-01
   5.21246314e-01], sum to 1.0000
[2017-11-02 10:22:41,868] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.0, 49.0, 5.1, 220.0, 0.0, 0.0, -2.0, 25.8138769986254, 18.0, 20.59961593900387, 21.5, 0.0, 0.0], 
actual action is [8.0, 23.0], 
sim time next is 4259400.0000, 
raw observation next is [3.0, 49.0, 5.1, 220.0, 0.0, 0.0, 8.0, 23.35551273996565, 23.0, 20.50264492272004, 21.5, 0.0, 65.12650554581636], 
processed observation next is [1.0, 0.30434782608695654, 0.41025641025641024, 0.49, 0.4636363636363636, 0.6111111111111112, 0.0, 0.0, 0.6333333333333333, 0.2335551273996565, 0.7142857142857143, 0.3575207032457201, 0.5, 0.0, 0.7661941828919572], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:44,051] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99999523e-01   9.44701761e-10   2.79721490e-09   8.04404821e-10
   9.18378817e-10   2.65994116e-10   5.27960287e-10   1.50130841e-08
   4.56920986e-07], sum to 1.0000
[2017-11-02 10:22:44,061] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.95, 57.0, 6.925, 265.0, 104.5, 630.25, 1.933333333333334, 16.32336509972252, 18.0, 22.345019820004, 22.7, 1.0, 0.0], 
actual action is [1.9500000000000002, 18], 
sim time next is 4290600.0000, 
raw observation next is [6.966666666666667, 56.66666666666667, 6.883333333333333, 266.6666666666666, 100.6666666666667, 622.0, 1.95, 16.24938964196572, 18.0, 22.36267131876036, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.6521739130434783, 0.511965811965812, 0.5666666666666668, 0.6257575757575757, 0.7407407407407405, 0.26631393298059974, 0.622, 0.5325, 0.1624938964196572, 0.0, 0.6232387598229084, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:22:44,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 14500, global step 228144: loss 133.2294
[2017-11-02 10:22:54,532] A3C_AGENT_WORKER-Thread-6 INFO:Local step 14500, global step 229720: loss 3.7617
[2017-11-02 10:22:59,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   4.88142801e-15   3.23292113e-14   2.14899408e-14
   1.02201361e-14   2.18472909e-27   8.57224870e-28   1.35760593e-27
   1.16316878e-26], sum to 1.0000
[2017-11-02 10:22:59,181] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 5.7, 240.0, 0.0, 0.0, 8.0, 32.40558287568238, 23.0, 19.76417243547051, 21.5, 0.0, 23.80517088746772], 
actual action is [-2.0, 18.0], 
sim time next is 4251900.0000, 
raw observation next is [3.0, 45.33333333333334, 5.566666666666666, 239.1666666666667, 0.0, 0.0, -2.0, 33.23019819600501, 18.0, 19.73122134892293, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.41025641025641024, 0.4533333333333334, 0.506060606060606, 0.664351851851852, 0.0, 0.0, 0.4666666666666667, 0.3323019819600501, 0.0, 0.2473173355604185, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:01,348] A3C_AGENT_WORKER-Thread-10 INFO:Local step 14500, global step 230762: loss -141.5170
[2017-11-02 10:23:03,190] A3C_AGENT_WORKER-Thread-3 INFO:Local step 14500, global step 231057: loss 6.4171
[2017-11-02 10:23:05,734] A3C_AGENT_WORKER-Thread-8 INFO:Local step 14500, global step 231350: loss 40.7207
[2017-11-02 10:23:06,340] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   3.23614642e-11   7.17839052e-11   8.60610333e-11
   2.94339934e-11   6.43994044e-28   7.39989518e-28   4.43949482e-28
   5.52502231e-27], sum to 1.0000
[2017-11-02 10:23:06,382] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.3, 57.0, 4.1, 190.0, 99.5, 584.0, 1.024999999999999, 15.61416588836284, 18.0, 21.99662111904254, 22.7, 1.0, 0.0], 
actual action is [1.2999999999999998, 18], 
sim time next is 4352700.0000, 
raw observation next is [6.608333333333333, 55.75, 4.058333333333333, 190.0, 100.75, 599.5, 1.3, 15.02717884180738, 18.0, 22.05421421961504, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.5027777777777778, 0.5575, 0.3689393939393939, 0.5277777777777778, 0.2665343915343915, 0.5995, 0.5216666666666667, 0.15027178841807382, 0.0, 0.5791734599450058, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:08,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.18216429e-15   1.93708134e-15   2.16374206e-15
   1.14481437e-15   8.19910248e-34   7.61028634e-34   9.46855373e-34
   1.58640515e-32], sum to 1.0000
[2017-11-02 10:23:08,659] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.416666666666667, 75.0, 6.183333333333334, 258.3333333333333, 0.0, 0.0, -2.5, 22.20698661288348, 18.0, 20.61580560860954, 21.5, 0.0, 0.0], 
actual action is [-2.583333333333333, 18], 
sim time next is 4430400.0000, 
raw observation next is [2.333333333333333, 76.0, 5.966666666666667, 256.6666666666667, 0.0, 0.0, -2.583333333333333, 22.90281242266921, 18.0, 20.5318950470505, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.39316239316239315, 0.76, 0.5424242424242425, 0.712962962962963, 0.0, 0.0, 0.4569444444444445, 0.2290281242266921, 0.0, 0.36169929243578586, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:09,485] A3C_AGENT_WORKER-Thread-13 INFO:Local step 14500, global step 231792: loss 32.6189
[2017-11-02 10:23:11,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.05576201e-10   2.84136215e-10   3.61402852e-10
   1.13498558e-10   1.62139694e-22   2.64547597e-22   3.35769393e-22
   3.28781918e-21], sum to 1.0000
[2017-11-02 10:23:11,620] A3C_AGENT_WORKER-Thread-12 INFO:Local step 14500, global step 232058: loss 2.7790
[2017-11-02 10:23:11,649] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 7.050000000000001, 250.0, 30.0, 58.0, -3.0, 15.69056281465175, 18.0, 21.76606549207226, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4434600.0000, 
raw observation next is [2.0, 80.0, 7.266666666666667, 250.0, 39.99999999999999, 77.33333333333331, -3.0, 16.80704087029855, 18.0, 21.70627749905407, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.38461538461538464, 0.8, 0.6606060606060606, 0.6944444444444444, 0.1058201058201058, 0.07733333333333331, 0.45, 0.1680704087029855, 0.0, 0.5294682141505815, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:12,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99993682e-01   1.23968493e-06   1.68797112e-06   2.05186325e-06
   1.33187655e-06   3.21066958e-13   2.71688867e-13   8.90632579e-14
   1.35071601e-13], sum to 1.0000
[2017-11-02 10:23:12,359] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [13.525, 33.25, 4.866666666666666, 254.1666666666667, 110.6666666666667, 52.41666666666669, 8.6, 7.266616360469384, 18.0, 25.32438934517166, 22.7, 1.0, 0.0], 
actual action is [8.525, 18], 
sim time next is 4375800.0000, 
raw observation next is [13.45, 33.5, 4.9, 255.0, 103.0, 0.0, 8.525, 7.272426278212295, 18.0, 25.28531589007869, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.6521739130434783, 0.6782051282051282, 0.335, 0.4454545454545455, 0.7083333333333334, 0.2724867724867725, 0.0, 0.6420833333333333, 0.07272426278212295, 0.0, 1.0407594128683841, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0073. 
=============================================
[2017-11-02 10:23:13,752] A3C_AGENT_WORKER-Thread-17 INFO:Local step 14500, global step 232353: loss 33.5899
[2017-11-02 10:23:16,421] A3C_AGENT_WORKER-Thread-15 INFO:Local step 14500, global step 232737: loss 63.5197
[2017-11-02 10:23:16,555] A3C_AGENT_WORKER-Thread-5 INFO:Local step 14500, global step 232751: loss -101.2873
[2017-11-02 10:23:16,563] A3C_AGENT_WORKER-Thread-4 INFO:Local step 14500, global step 232756: loss -18.5484
[2017-11-02 10:23:17,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   1.25830985e-10   2.54496035e-10   4.47090864e-10
   1.50067778e-10   2.88868873e-22   6.85807449e-22   1.24032600e-22
   1.18580107e-21], sum to 1.0000
[2017-11-02 10:23:17,633] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.991666666666667, 74.08333333333333, 4.508333333333333, 190.0, 38.33333333333333, 204.5833333333333, 7.983333333333333, 16.33991704253587, 23.0, 21.09402336049426, 22.7, 1.0, 88.76090630895483], 
actual action is [-2.008333333333333, 18.0], 
sim time next is 4348800.0000, 
raw observation next is [3.0, 74.0, 4.6, 190.0, 46.0, 245.5, -2.008333333333333, 16.98403759821364, 18.0, 21.27537336546413, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.41025641025641024, 0.74, 0.41818181818181815, 0.5277777777777778, 0.12169312169312169, 0.2455, 0.46652777777777776, 0.1698403759821364, 0.0, 0.46791048078059, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:18,174] A3C_AGENT_WORKER-Thread-2 INFO:Local step 14500, global step 232963: loss 1.4405
[2017-11-02 10:23:20,176] A3C_AGENT_WORKER-Thread-7 INFO:Local step 14500, global step 233255: loss 19.8326
[2017-11-02 10:23:21,129] A3C_AGENT_WORKER-Thread-14 INFO:Local step 14500, global step 233425: loss 44.5044
[2017-11-02 10:23:21,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-17.12337112]
 [-18.59667397]
 [-18.14731026]
 [-17.92577553]
 [-17.02705002]], R is [[-18.71695709]
 [-19.52978706]
 [-20.33448982]
 [-21.13114548]
 [-21.91983414]].
[2017-11-02 10:23:21,854] A3C_AGENT_WORKER-Thread-11 INFO:Local step 14500, global step 233546: loss 28.8628
[2017-11-02 10:23:22,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99994755e-01   9.52387779e-07   1.29522130e-06   1.94759400e-06
   1.05466370e-06   6.21976559e-12   6.19079180e-12   1.69994823e-12
   2.45907244e-12], sum to 1.0000
[2017-11-02 10:23:22,101] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.575, 29.5, 4.1, 242.5, 115.75, 844.75, 9.58333333333333, 7.226962516467014, 18.0, 24.35702834446646, 22.7, 1.0, 0.0], 
actual action is [9.575, 18], 
sim time next is 4368000.0000, 
raw observation next is [14.56666666666667, 29.66666666666667, 4.133333333333334, 243.3333333333334, 115.5, 843.8333333333334, 9.575, 7.179839072257007, 18.0, 24.36782205672187, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.7068376068376069, 0.2966666666666667, 0.3757575757575758, 0.6759259259259262, 0.3055555555555556, 0.8438333333333333, 0.6595833333333334, 0.07179839072257006, 0.0, 0.9096888652459815, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0072. 
=============================================
[2017-11-02 10:23:34,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   9.38100726e-12   6.76307491e-12   8.96016508e-12
   6.31851689e-12   1.24559862e-22   3.59722618e-22   2.10825652e-22
   2.93748436e-21], sum to 1.0000
[2017-11-02 10:23:34,676] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 85.33333333333333, 5.533333333333333, 266.6666666666667, 179.3333333333333, 50.16666666666666, -3.875, 14.98373201719036, 18.0, 22.15032465505664, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 4441500.0000, 
raw observation next is [1.075, 85.5, 5.425, 267.5, 186.5, 59.75, -3.9, 15.02831877094141, 18.0, 22.14033673583714, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.3608974358974359, 0.855, 0.49318181818181817, 0.7430555555555556, 0.4933862433862434, 0.05975, 0.435, 0.1502831877094141, 0.0, 0.5914766765481626, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:35,812] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-27.36604691]
 [-28.34878159]
 [-26.57177353]
 [-25.50333405]
 [-29.47651291]], R is [[-28.14083672]
 [-28.85942841]
 [-29.57083511]
 [-30.27512741]
 [-30.97237587]].
[2017-11-02 10:23:39,514] A3C_AGENT_WORKER-Thread-9 INFO:Local step 14500, global step 236213: loss 64.2007
[2017-11-02 10:23:39,794] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15000, global step 236255: loss -43.4250
[2017-11-02 10:23:41,005] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   9.56275725e-10   2.00176631e-09   1.56641677e-09
   1.01129305e-09   1.98920685e-16   2.72856550e-16   7.99895034e-17
   1.72066898e-15], sum to 1.0000
[2017-11-02 10:23:41,048] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.533333333333334, 68.0, 7.433333333333334, 270.0, 0.0, 0.0, -1.4, 15.24696827012183, 18.0, 21.47074126456013, 21.5, 0.0, 0.0], 
actual action is [-1.466666666666666, 18], 
sim time next is 4425900.0000, 
raw observation next is [3.466666666666666, 68.0, 7.466666666666667, 270.0, 0.0, 0.0, -1.466666666666666, 16.03784187161616, 18.0, 21.33770668860909, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.42222222222222217, 0.68, 0.6787878787878788, 0.75, 0.0, 0.0, 0.47555555555555556, 0.1603784187161616, 0.0, 0.4768152412298698, 0.5, 0.0, 0.0], 
reward next is -0.0232. 
=============================================
[2017-11-02 10:23:41,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-25.95946503]
 [-23.13039398]
 [-22.83390045]
 [-22.88772202]
 [-25.14754486]], R is [[-21.09643936]
 [-20.89772415]
 [-20.70054817]
 [-20.50486565]
 [-20.3106308 ]].
[2017-11-02 10:23:46,839] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   6.59571009e-11   4.85714177e-11   6.24069199e-11
   4.17984085e-11   2.39473407e-22   3.09381882e-22   2.01527632e-22
   1.08908243e-21], sum to 1.0000
[2017-11-02 10:23:46,916] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.766666666666667, 81.33333333333334, 7.266666666666667, 253.3333333333333, 100.0, 193.3333333333333, -3.175, 11.21020171596969, 18.0, 22.27609054738331, 22.7, 1.0, 0.0], 
actual action is [-3.233333333333333, 18], 
sim time next is 4436700.0000, 
raw observation next is [1.708333333333333, 81.66666666666666, 7.158333333333333, 254.1666666666667, 110.0, 212.6666666666667, -3.233333333333333, 11.50470963711606, 18.0, 22.27664510702243, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.37713675213675213, 0.8166666666666665, 0.6507575757575758, 0.7060185185185186, 0.291005291005291, 0.21266666666666673, 0.44611111111111107, 0.11504709637116059, 0.0, 0.6109493010032041, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0115. 
=============================================
[2017-11-02 10:23:48,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-6.86431551]
 [-5.71595144]
 [-5.33683062]
 [-5.41535664]
 [-6.13524055]], R is [[-6.53781891]
 [-6.47984743]
 [-6.42247963]
 [-6.36573792]
 [-6.30961895]].
[2017-11-02 10:23:49,948] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   2.42590774e-11   2.78564914e-11   2.91541791e-11
   1.86711688e-11   3.88598246e-23   5.85566780e-23   1.85622568e-23
   2.19084265e-23], sum to 1.0000
[2017-11-02 10:23:50,046] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 7.533333333333333, 290.0, 0.0, 0.0, 5.0, 13.33429680332284, 24.0, 21.95784378508159, 22.7, 1.0, 34.32415997785604], 
actual action is [5.0, 19.0], 
sim time next is 4472700.0000, 
raw observation next is [0.0, 72.0, 7.616666666666665, 290.0, 0.0, 0.0, 5.0, 12.74542688154981, 19.0, 21.96800880106043, 22.7, 1.0, 52.28012985363664], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.3333333333333333, 0.72, 0.6924242424242423, 0.8055555555555556, 0.0, 0.0, 0.5833333333333334, 0.1274542688154981, 0.14285714285714285, 0.5668584001514902, 0.6714285714285714, 1.0, 0.6150603512192545], 
reward next is -0.5663. 
=============================================
[2017-11-02 10:23:51,208] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15000, global step 237899: loss -158.4002
[2017-11-02 10:23:52,399] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.45770175e-11   2.77780188e-10   2.14940316e-10   1.13203384e-10
   1.73888764e-10   3.68055403e-01   2.49639884e-01   1.53152317e-01
   2.29152352e-01], sum to 1.0000
[2017-11-02 10:23:52,457] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [0.0, 72.0, 8.2, 296.6666666666667, 0.0, 0.0, -5.0, 15.00785105463581, 18.0, 21.94973249320342, 22.7, 1.0, 0.0], 
actual action is [5.0, 18.5], 
sim time next is 4477500.0000, 
raw observation next is [0.0, 72.0, 8.2, 297.5, 0.0, 0.0, 5.0, 14.01099902711674, 18.5, 21.86779517203215, 22.7, 1.0, 64.84653148457573], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3333333333333333, 0.72, 0.7454545454545454, 0.8263888888888888, 0.0, 0.0, 0.5833333333333334, 0.1401099902711674, 0.07142857142857142, 0.5525421674331642, 0.6714285714285714, 1.0, 0.7629003704067734], 
reward next is -0.7006. 
=============================================
[2017-11-02 10:23:57,378] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15000, global step 238749: loss 51.2979
[2017-11-02 10:23:57,463] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15000, global step 238762: loss -263.0826
[2017-11-02 10:23:59,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.37668124e-23   1.41481263e-16   1.42360470e-16   2.83542228e-17
   5.73978377e-17   2.80892793e-02   4.83152121e-02   3.40270966e-01
   5.83324552e-01], sum to 1.0000
[2017-11-02 10:23:59,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.46983198e-11   3.24752378e-11   2.11094822e-11
   8.31694782e-12   8.96282729e-28   1.62538704e-27   5.98400878e-27
   1.49335591e-26], sum to 1.0000
[2017-11-02 10:23:59,182] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.225, 72.0, 8.85, 310.0, 0.0, 0.0, 4.8, 20.84732204141083, 23.0, 20.36326794820507, 21.5, 0.0, 86.5191677954709], 
actual action is [4.775, 25], 
sim time next is 4488600.0000, 
raw observation next is [-0.25, 72.0, 8.8, 310.0, 0.0, 0.0, 4.775, 18.24221708395179, 25.0, 20.52293816378511, 21.5, 0.0, 62.64713765360523], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.3269230769230769, 0.72, 0.8, 0.8611111111111112, 0.0, 0.0, 0.5795833333333333, 0.1824221708395179, 1.0, 0.3604197376835871, 0.5, 0.0, 0.7370251488659438], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:23:59,185] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.266666666666666, 63.83333333333333, 5.666666666666666, 254.1666666666667, 0.0, 0.0, 2.333333333333334, 15.11839409697999, 18.0, 21.57289207540845, 22.7, 1.0, 0.0], 
actual action is [2.2666666666666657, 18], 
sim time next is 4408200.0000, 
raw observation next is [7.199999999999999, 64.0, 5.7, 255.0, 0.0, 0.0, 2.266666666666666, 15.20481130160057, 18.0, 21.55619479480943, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.5179487179487179, 0.64, 0.5181818181818182, 0.7083333333333334, 0.0, 0.0, 0.5377777777777778, 0.1520481130160057, 0.0, 0.5080278278299184, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:00,057] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15000, global step 239136: loss 197.4989
[2017-11-02 10:24:01,227] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.67902643e-17   1.14255323e-17   9.09089939e-18
   5.41617889e-18   7.58094846e-38   3.12691031e-37   1.99785593e-36
   2.32867641e-35], sum to 1.0000
[2017-11-02 10:24:01,281] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 49.66666666666666, 4.1, 340.0, 112.6666666666667, 63.33333333333333, -3.0, 15.99954147208659, 18.0, 22.17381789996055, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4552200.0000, 
raw observation next is [2.0, 50.0, 4.1, 340.0, 109.0, 68.0, -3.0, 16.07287648350622, 18.0, 22.13502653636358, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6956521739130435, 0.38461538461538464, 0.5, 0.3727272727272727, 0.9444444444444444, 0.28835978835978837, 0.068, 0.45, 0.1607287648350622, 0.0, 0.5907180766233685, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:01,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   2.08745815e-14   3.37156925e-14   1.46352013e-14
   6.09490477e-15   9.67001620e-33   2.58459469e-32   1.12009589e-31
   1.15026429e-30], sum to 1.0000
[2017-11-02 10:24:02,033] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 72.0, 7.366666666666666, 290.0, 0.0, 0.0, -5.0, 16.83102605293441, 18.0, 21.41829450902957, 22.7, 1.0, 0.0], 
actual action is [-5.0, 18], 
sim time next is 4472100.0000, 
raw observation next is [0.0, 72.0, 7.45, 290.0, 0.0, 0.0, -5.0, 17.84457311339185, 18.0, 21.34533746435216, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.3333333333333333, 0.72, 0.6772727272727272, 0.8055555555555556, 0.0, 0.0, 0.4166666666666667, 0.17844573113391848, 0.0, 0.47790535205030843, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:24:03,002] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15000, global step 239510: loss -105.8458
[2017-11-02 10:24:04,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15000, global step 239702: loss 56.3158
[2017-11-02 10:24:07,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.28217711e-04   1.73756962e-05   1.46653319e-05   6.28519092e-06
   8.49567550e-06   3.59450467e-02   8.64463672e-02   1.47036776e-01
   7.30396807e-01], sum to 1.0000
[2017-11-02 10:24:07,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.4, 72.5, 8.35, 310.0, 0.0, 0.0, -5.383333333333333, 17.76558332146903, 18.0, 21.47769484301103, 21.5, 0.0, 0.0], 
actual action is [4.6, 23.0], 
sim time next is 4491300.0000, 
raw observation next is [-0.4166666666666667, 72.58333333333333, 8.291666666666666, 310.0, 0.0, 0.0, 4.6, 16.04951946964498, 23.0, 21.35640513272742, 21.5, 0.0, 65.95301559206743], 
processed observation next is [0.16666666666666666, 1.0, 0.32264957264957267, 0.7258333333333333, 0.7537878787878788, 0.8611111111111112, 0.0, 0.0, 0.5766666666666667, 0.1604951946964498, 0.7142857142857143, 0.47948644753248865, 0.5, 0.0, 0.7759178304949109], 
reward next is -0.7188. 
=============================================
[2017-11-02 10:24:07,551] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15000, global step 239972: loss 21.6854
[2017-11-02 10:24:09,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  5.91902052e-22   2.12999736e-17   8.24929689e-18   4.29289078e-18
   8.83185786e-18   2.17601359e-02   7.58854672e-02   2.05248266e-01
   6.97106063e-01], sum to 1.0000
[2017-11-02 10:24:09,639] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.0, 80.0, 7.7, 250.0, 60.0, 116.0, -3.0, 13.71133929184643, 18.0, 21.97727299160401, 22.7, 1.0, 0.0], 
actual action is [7.0, 20.0], 
sim time next is 4435500.0000, 
raw observation next is [1.941666666666667, 80.33333333333333, 7.591666666666667, 250.8333333333333, 70.0, 135.3333333333333, 7.0, 11.22849548036331, 20.0, 21.9866005335753, 22.7, 1.0, 67.56080797156538], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.3831196581196581, 0.8033333333333332, 0.6901515151515152, 0.6967592592592591, 0.18518518518518517, 0.13533333333333328, 0.6166666666666667, 0.11228495480363311, 0.2857142857142857, 0.5695143619393284, 0.6714285714285714, 1.0, 0.7948330349595927], 
reward next is -0.7266. 
=============================================
[2017-11-02 10:24:11,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   8.35011909e-16   1.39526994e-15   1.98229194e-15
   1.32999525e-15   0.00000000e+00   6.67812829e-38   3.34100551e-38
   9.11428007e-38], sum to 1.0000
[2017-11-02 10:24:11,088] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 73.0, 6.758333333333334, 310.0, 0.0, 0.0, 4.4, 15.54744077361133, 20.0, 20.88877773837025, 21.5, 0.0, 42.41720577632081], 
actual action is [-5.6, 18], 
sim time next is 4500000.0000, 
raw observation next is [-0.6, 73.0, 6.7, 310.0, 0.0, 0.0, -5.6, 16.53187451396033, 18.0, 21.12270683219156, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.08695652173913043, 0.317948717948718, 0.73, 0.6090909090909091, 0.8611111111111112, 0.0, 0.0, 0.4066666666666666, 0.1653187451396033, 0.0, 0.44610097602736587, 0.5, 0.0, 0.0], 
reward next is -0.0539. 
=============================================
[2017-11-02 10:24:11,182] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15000, global step 240373: loss 0.0442
[2017-11-02 10:24:11,230] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15000, global step 240375: loss 13.2009
[2017-11-02 10:24:14,633] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15000, global step 240846: loss 5.2832
[2017-11-02 10:24:15,677] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15000, global step 240974: loss -14.0298
[2017-11-02 10:24:15,846] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15000, global step 240986: loss -53.3233
[2017-11-02 10:24:16,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  3.10933031e-27   2.38046166e-20   1.09890549e-20   5.17646679e-21
   2.00289862e-20   4.91775125e-02   2.23595977e-01   5.32107294e-01
   1.95119128e-01], sum to 1.0000
[2017-11-02 10:24:16,573] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-0.6, 73.0, 7.050000000000001, 310.0, 0.0, 0.0, 4.4, 15.94102945896927, 20.0, 21.27515379839002, 21.5, 0.0, 48.20871456300182], 
actual action is [4.4, 22.0], 
sim time next is 4498500.0000, 
raw observation next is [-0.6, 73.0, 6.991666666666667, 310.0, 0.0, 0.0, 4.4, 15.72633963708961, 22.0, 21.3074007949973, 21.5, 0.0, 33.01955901401758], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.317948717948718, 0.73, 0.6356060606060606, 0.8611111111111112, 0.0, 0.0, 0.5733333333333334, 0.15726339637089612, 0.5714285714285714, 0.4724858278567571, 0.5, 0.0, 0.3884654001649127], 
reward next is -0.3771. 
=============================================
[2017-11-02 10:24:16,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.06691907e-29   1.36487915e-24   2.10695281e-25   1.64420504e-25
   9.16560229e-25   1.11580621e-02   1.86593920e-01   6.12565219e-01
   1.89682797e-01], sum to 1.0000
[2017-11-02 10:24:16,858] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.583333333333333, 50.25, 3.516666666666667, 310.0, 248.4166666666667, 53.41666666666667, -2.5, 12.76752391055759, 18.0, 22.53077001540478, 22.7, 1.0, 0.0], 
actual action is [7.583333333333333, 20.0], 
sim time next is 4542000.0000, 
raw observation next is [2.666666666666667, 50.0, 3.433333333333333, 310.0, 249.8333333333333, 58.83333333333333, 7.583333333333333, 11.23465851966474, 20.0, 22.51280008257293, 22.7, 1.0, 57.86096083133543], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.4017094017094017, 0.5, 0.3121212121212121, 0.8611111111111112, 0.6609347442680775, 0.05883333333333333, 0.6263888888888889, 0.11234658519664739, 0.2857142857142857, 0.6446857260818472, 0.6714285714285714, 1.0, 0.6807171862510051], 
reward next is -0.6239. 
=============================================
[2017-11-02 10:24:17,181] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15000, global step 241147: loss -10.1588
[2017-11-02 10:24:18,080] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15000, global step 241270: loss 2.5777
[2017-11-02 10:24:21,362] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   9.59259424e-36   4.93513230e-36   1.87236488e-36
   1.07271429e-35   8.15488398e-02   1.03333063e-01   5.98646522e-01
   2.16471612e-01], sum to 1.0000
[2017-11-02 10:24:21,444] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.9166666666666666, 73.0, 5.516666666666667, 300.0, 0.0, 0.0, 4.075, 15.44429270571075, 19.5, 21.04591595000127, 21.5, 0.0, 50.66292178467585], 
actual action is [4.083333333333333, 24.5], 
sim time next is 4506900.0000, 
raw observation next is [-0.9083333333333333, 73.0, 5.458333333333334, 300.0, 0.0, 0.0, 4.083333333333333, 14.79122374809873, 24.5, 21.18452499022106, 21.5, 0.0, 40.83807903852489], 
processed observation next is [0.3333333333333333, 0.13043478260869565, 0.31004273504273505, 0.73, 0.49621212121212127, 0.8333333333333334, 0.0, 0.0, 0.5680555555555556, 0.1479122374809873, 0.9285714285714286, 0.4549321414601515, 0.5, 0.0, 0.4804479886885281], 
reward next is -0.4775. 
=============================================
[2017-11-02 10:24:30,004] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.26588477e-27   6.20876194e-21   4.16772932e-21   2.48593240e-21
   6.86220393e-21   1.83697820e-01   8.84733424e-02   1.65734455e-01
   5.62094390e-01], sum to 1.0000
[2017-11-02 10:24:30,082] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.583333333333333, 69.33333333333333, 0.0, 0.0, 0.0, 0.0, -6.541666666666667, 13.53606075976493, 18.0, 21.73931354097247, 21.5, 0.0, 0.0], 
actual action is [3.416666666666667, 20.0], 
sim time next is 4594500.0000, 
raw observation next is [-1.625, 69.5, 0.0, 0.0, 0.0, 0.0, 3.416666666666667, 12.66631858348471, 20.0, 21.72286064967324, 21.5, 0.0, 54.22748885501018], 
processed observation next is [0.5, 0.17391304347826086, 0.2916666666666667, 0.695, 0.0, 0.0, 0.0, 0.0, 0.5569444444444444, 0.1266631858348471, 0.2857142857142857, 0.5318372356676058, 0.5, 0.0, 0.6379704571177668], 
reward next is -0.5742. 
=============================================
[2017-11-02 10:24:34,503] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15000, global step 243378: loss 19.8869
[2017-11-02 10:24:37,723] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.66791112e-11   1.86455469e-11   2.46313282e-11
   1.70876768e-11   4.05314603e-24   3.12524958e-24   3.32620164e-24
   7.92938054e-24], sum to 1.0000
[2017-11-02 10:24:37,809] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, -3.0, 12.28977202174517, 18.0, 22.11776107921671, 22.7, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 4561200.0000, 
raw observation next is [2.0, 52.0, 3.1, 340.0, 0.0, 0.0, -3.0, 13.11620819471204, 18.0, 22.17061281422675, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.38461538461538464, 0.52, 0.2818181818181818, 0.9444444444444444, 0.0, 0.0, 0.45, 0.1311620819471204, 0.0, 0.5958018306038214, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0131. 
=============================================
[2017-11-02 10:24:38,181] A3C_AGENT_WORKER-Thread-16 INFO:Local step 15500, global step 243906: loss 8.2314
[2017-11-02 10:24:44,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.18153560e-11   2.07733310e-11   2.39398935e-11
   1.40340795e-11   1.77776829e-31   1.83213078e-31   2.87189774e-31
   1.81825541e-30], sum to 1.0000
[2017-11-02 10:24:44,201] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, 6.0, 15.08585381268332, 23.0, 21.37308279072636, 21.5, 0.0, 77.62178810194092], 
actual action is [-4.0, 18.0], 
sim time next is 4572600.0000, 
raw observation next is [1.0, 61.0, 0.0, 0.0, 0.0, 0.0, -4.0, 16.19200569590109, 18.0, 21.53710171027454, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.358974358974359, 0.61, 0.0, 0.0, 0.0, 0.0, 0.43333333333333335, 0.1619200569590109, 0.0, 0.5053002443249345, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:24:50,187] A3C_AGENT_WORKER-Thread-6 INFO:Local step 15500, global step 245603: loss 14.0486
[2017-11-02 10:24:53,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-14.16205788]
 [-14.4144001 ]
 [-12.63282681]
 [-17.56111145]
 [-16.70965958]], R is [[-15.91987419]
 [-15.77509308]
 [-15.63165665]
 [-15.48953438]
 [-15.34864998]].
[2017-11-02 10:24:56,265] A3C_AGENT_WORKER-Thread-10 INFO:Local step 15500, global step 246352: loss 6.0725
[2017-11-02 10:24:59,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-25.19816017]
 [-19.79620552]
 [-18.14678574]
 [-18.9941082 ]
 [-23.20381927]], R is [[-26.05017281]
 [-25.80323029]
 [-25.55829048]
 [-25.31523895]
 [-25.07388115]].
[2017-11-02 10:24:59,711] A3C_AGENT_WORKER-Thread-8 INFO:Local step 15500, global step 246836: loss 3.5976
[2017-11-02 10:25:01,442] A3C_AGENT_WORKER-Thread-3 INFO:Local step 15500, global step 247042: loss 3.9954
[2017-11-02 10:25:03,629] A3C_AGENT_WORKER-Thread-13 INFO:Local step 15500, global step 247320: loss 10.4327
[2017-11-02 10:25:07,718] A3C_AGENT_WORKER-Thread-17 INFO:Local step 15500, global step 247902: loss 4.8518
[2017-11-02 10:25:07,788] A3C_AGENT_WORKER-Thread-12 INFO:Local step 15500, global step 247913: loss 5.3775
[2017-11-02 10:25:13,820] A3C_AGENT_WORKER-Thread-2 INFO:Local step 15500, global step 248667: loss 8.9818
[2017-11-02 10:25:14,814] A3C_AGENT_WORKER-Thread-4 INFO:Local step 15500, global step 248774: loss 11.8283
[2017-11-02 10:25:15,377] A3C_AGENT_WORKER-Thread-5 INFO:Local step 15500, global step 248849: loss 14.7130
[2017-11-02 10:25:17,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 15500, global step 249133: loss -20.4331
[2017-11-02 10:25:17,945] A3C_AGENT_WORKER-Thread-15 INFO:Local step 15500, global step 249211: loss 5.7030
[2017-11-02 10:25:18,019] A3C_AGENT_WORKER-Thread-11 INFO:Local step 15500, global step 249216: loss 4.6915
[2017-11-02 10:25:18,154] A3C_AGENT_WORKER-Thread-7 INFO:Local step 15500, global step 249234: loss 1.2115
[2017-11-02 10:25:24,561] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:40

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:25:24,565] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:25:24,566] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=00hr 44min 59.97sec

[2017-11-02 10:25:24,567] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:25:24,567] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:25:25,562] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:25:25,565] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run2
[2017-11-02 10:26:13,069] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.96460605  0.00234091  0.00601579  0.00213038  0.00397401  0.00118907
  0.01464587  0.00180407  0.00329377]
[2017-11-02 10:26:15,515] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20474905e-01   2.55968844e-05   1.64240246e-05   1.11483769e-05
   2.72860198e-05   6.44619614e-02   6.58918083e-01   8.72900859e-02
   6.87745363e-02]
[2017-11-02 10:26:16,343] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.90608387e-09   1.69411693e-10   7.27297597e-11   5.40745677e-11
   1.64821976e-10   7.41642863e-02   7.79584229e-01   9.53102335e-02
   5.09412140e-02]
[2017-11-02 10:26:21,073] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.09211642e-09   6.82501593e-08   1.10824907e-07   3.34191625e-08
   8.13836678e-08   6.47963658e-02   6.78539991e-01   1.07544251e-01
   1.49119154e-01]
[2017-11-02 10:26:28,146] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   5.48352084e-08   4.54169999e-08   4.70478305e-08
   6.48625686e-08   2.90608065e-10   2.06467865e-09   2.41364095e-10
   1.44592061e-10]
[2017-11-02 10:26:34,943] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.66166990e-14   5.19064128e-14   4.70052904e-14   3.82080333e-14
   7.46298436e-14   8.96006078e-02   8.11970234e-01   7.55480528e-02
   2.28810906e-02]
[2017-11-02 10:26:37,460] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.84971370e-15   3.78631751e-13   3.51215259e-13   1.85960649e-13
   4.61973829e-13   8.51849914e-02   7.44287789e-01   9.54434350e-02
   7.50837773e-02]
[2017-11-02 10:26:42,368] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.51895530e-15   4.63035079e-12   4.19621499e-12   1.64376293e-12
   3.61074603e-12   7.20517337e-02   6.92468524e-01   1.15652494e-01
   1.19827285e-01]
[2017-11-02 10:26:43,034] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.60821457e-07   3.10673357e-07   2.20058482e-07   8.34585308e-08
   1.93745123e-07   8.25173110e-02   6.63913667e-01   1.48329169e-01
   1.05238914e-01]
[2017-11-02 10:27:11,761] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.06570690e-10   2.38123832e-09   1.79066384e-09   6.04501560e-10
   1.80437776e-09   6.57004416e-02   7.09630430e-01   1.24108106e-01
   1.00561030e-01]
[2017-11-02 10:27:41,422] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.03428736
  0.68674916  0.20050296  0.0784606 ]
[2017-11-02 10:27:50,260] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.04912213
  0.86025149  0.07814797  0.01247853]
[2017-11-02 10:28:13,996] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.04598191
  0.68722022  0.17106263  0.09573515]
[2017-11-02 10:28:17,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.21776373e-34   2.14425509e-25   7.36840336e-26   3.17588806e-26
   1.92327136e-25   6.80455938e-02   7.57504165e-01   1.12524241e-01
   6.19259737e-02]
[2017-11-02 10:28:26,125] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99310732e-01   4.23220655e-07   1.48800382e-07   1.50407431e-07
   3.83867899e-07   5.46049087e-05   5.42973110e-04   6.49796420e-05
   2.56225012e-05]
[2017-11-02 10:28:27,710] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.42873604e-12   7.01728714e-13   8.74382218e-13
   1.43327776e-12   1.00812172e-19   8.89308494e-19   1.05540685e-19
   4.91679290e-20]
[2017-11-02 10:28:30,657] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.27357156e-05   2.26594566e-05   3.40688566e-05   1.08026725e-05
   2.56131352e-05   7.32923672e-02   6.71602368e-01   1.22158661e-01
   1.32820681e-01]
[2017-11-02 10:28:31,410] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99958158e-01   7.71754276e-06   1.72600940e-05   6.70900681e-06
   1.01358546e-05   2.21350549e-10   2.12467643e-09   3.25551364e-10
   4.73717843e-10]
[2017-11-02 10:28:33,965] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993086e-01   1.25085694e-06   2.75556840e-06   1.10286715e-06
   1.74514332e-06   4.72351628e-12   5.35259094e-11   7.19481332e-12
   1.01466223e-11]
[2017-11-02 10:28:35,345] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.43140696e-09   6.76662069e-08   1.08189710e-07   3.35463071e-08
   8.60565237e-08   6.21648207e-02   6.94958210e-01   1.03782915e-01
   1.39093742e-01]
[2017-11-02 10:28:44,035] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97553647e-01   4.28301049e-04   6.76016032e-04   2.42228154e-04
   4.87421552e-04   4.42505516e-05   4.23401623e-04   7.32401386e-05
   7.14475318e-05]
[2017-11-02 10:28:44,928] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.72218132e-08   1.73366544e-07   2.64481542e-07   8.10225060e-08
   1.98341567e-07   6.82847649e-02   6.86376214e-01   1.13458611e-01
   1.31879643e-01]
[2017-11-02 10:28:49,926] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.98794999e-23   7.54827455e-17   6.66987227e-17   1.73093681e-17
   6.70374697e-17   6.31170496e-02   6.95300400e-01   1.21653870e-01
   1.19928740e-01]
[2017-11-02 10:28:54,681] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.53636584e-08   1.04464021e-10   4.90779813e-11   4.09311716e-11
   1.20207982e-10   6.58083186e-02   8.31410110e-01   7.33070225e-02
   2.94744428e-02]
[2017-11-02 10:28:56,714] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.47992710e-16   1.71931923e-15   7.45269668e-16   5.24618803e-16
   1.92061629e-15   6.33477420e-02   8.27292442e-01   7.88760409e-02
   3.04837562e-02]
[2017-11-02 10:29:02,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.20611201e-05   2.74886588e-05   3.45627814e-05   1.12017315e-05
   2.10056514e-05   5.90029806e-02   6.47880435e-01   1.26682892e-01
   1.66247338e-01]
[2017-11-02 10:29:03,122] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.77826953e-10   1.49264778e-08   2.04844284e-08   6.10938500e-09
   1.65549103e-08   7.21780583e-02   6.82844698e-01   1.23094164e-01
   1.21883035e-01]
[2017-11-02 10:29:07,297] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94433224e-01   1.05245900e-03   9.35077027e-04   4.04732593e-04
   6.81200356e-04   1.89070153e-04   1.72254886e-03   2.95837701e-04
   2.85853312e-04]
[2017-11-02 10:29:08,902] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99927282e-01   2.25622935e-05   2.37159038e-05   1.06154748e-05
   1.58576095e-05   6.81576307e-09   6.20012344e-08   1.03582849e-08
   1.04443059e-08]
[2017-11-02 10:29:09,145] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.05480581e-17   5.79504272e-13   4.94452515e-13   1.52061089e-13
   4.25101523e-13   6.99907988e-02   6.79843307e-01   1.21488124e-01
   1.28677800e-01]
[2017-11-02 10:29:12,414] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.69162042e-04   1.42375791e-06   1.70469116e-06   1.38802056e-06
   1.92566472e-06   1.20333977e-01   7.25839674e-01   9.32426453e-02
   6.04080968e-02]
[2017-11-02 10:29:12,475] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.23349351e-02   2.83127993e-05   3.52358475e-05   2.95865630e-05
   3.86812972e-05   1.18398935e-01   7.10667372e-01   9.05610174e-02
   5.79058938e-02]
[2017-11-02 10:29:13,896] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.10683435e-10   1.61240160e-10   1.98916744e-10
   1.87567739e-10   2.09896353e-15   1.28431997e-14   1.19968188e-15
   4.36556122e-16]
[2017-11-02 10:29:14,435] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.36026821e-07   1.72650427e-09   2.37560371e-09   2.09166995e-09
   3.02863024e-09   1.20111324e-01   7.77152836e-01   7.64663219e-02
   2.62692608e-02]
[2017-11-02 10:29:17,614] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.23741493e-16   2.52307138e-12   2.40246755e-12   8.77101018e-13
   1.65255114e-12   7.43337423e-02   6.50528371e-01   1.27154097e-01
   1.47983760e-01]
[2017-11-02 10:29:34,808] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.44198299e-05   1.33101096e-07   5.92944147e-08   5.25014912e-08
   1.23083367e-07   9.48544815e-02   7.52812445e-01   1.00517049e-01
   5.17512187e-02]
[2017-11-02 10:29:43,235] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.40873371e-05   3.83260849e-05   4.02709484e-05   1.44121695e-05
   2.47943153e-05   8.72238651e-02   6.13151670e-01   1.42041385e-01
   1.57451153e-01]
[2017-11-02 10:29:44,442] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.15232910e-12   1.23276434e-09   1.14241938e-09   3.83445747e-10
   8.84573081e-10   7.81828314e-02   6.47345781e-01   1.30015805e-01
   1.44455597e-01]
[2017-11-02 10:29:45,374] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.42785567e-17   1.29358091e-12   1.12838460e-12   3.49941484e-13
   9.08732399e-13   7.98188746e-02   6.34624004e-01   1.35929868e-01
   1.49627283e-01]
[2017-11-02 10:29:48,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.57136698e-09   3.22291838e-09   2.46492116e-09
   2.63127231e-09   2.54493325e-16   1.72019644e-15   3.33617796e-16
   3.07005636e-16]
[2017-11-02 10:29:51,570] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.38112058e-10   5.17789978e-11   2.09563894e-11   1.61730993e-11
   4.54694546e-11   8.63122642e-02   7.53125191e-01   1.03157341e-01
   5.74051924e-02]
[2017-11-02 10:29:51,878] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.19226999e-04   2.29853413e-07   9.78561729e-08   8.28368414e-08
   1.98581873e-07   9.32649449e-02   7.35064685e-01   1.08778536e-01
   6.27720132e-02]
[2017-11-02 10:29:58,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.92895352e-09   1.02015818e-09   1.16733501e-09
   2.41695042e-09   5.77292970e-11   5.25420984e-10   6.69140438e-11
   3.36814222e-11]
[2017-11-02 10:30:00,507] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.20135362e-13   6.20787167e-13   4.17311341e-13
   2.36005659e-13   6.77839942e-32   5.89059403e-31   1.24795664e-31
   2.15023025e-31]
[2017-11-02 10:30:00,610] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.15070425e-13   4.72111445e-13   3.14436465e-13
   1.78282383e-13   2.74826553e-32   2.46442367e-31   5.03635676e-32
   8.66018544e-32]
[2017-11-02 10:30:00,684] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.85288186e-13   2.79273241e-13   1.88252002e-13
   1.03292192e-13   3.60604051e-33   3.35872708e-32   6.67414689e-33
   1.15883378e-32]
[2017-11-02 10:30:00,857] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.86450711e-13   1.27497817e-12   7.82237935e-13
   4.53083941e-13   3.40484760e-31   3.01394118e-30   6.31370899e-31
   1.12688079e-30]
[2017-11-02 10:30:04,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99298453e-01   1.87667087e-04   2.74331949e-04   1.00001336e-04
   1.37358846e-04   1.41698877e-07   1.33605784e-06   2.87018082e-07
   4.67100648e-07]
[2017-11-02 10:30:04,549] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.40560675e-01   9.61194310e-05   5.16756154e-05   3.70641283e-05
   8.65826441e-05   1.35474782e-02   1.13611810e-01   1.84405148e-02
   1.35681676e-02]
[2017-11-02 10:30:06,154] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.03903328e-13   4.77457971e-13   3.54091864e-13
   1.41671397e-13   1.10073129e-36   1.04364383e-35   2.19455034e-36
   3.63435891e-36]
[2017-11-02 10:30:06,708] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.49657657e-13   2.77336802e-13   2.21105442e-13
   9.95749029e-14   5.31660189e-36   4.96938285e-35   1.02677401e-35
   1.66478871e-35]
[2017-11-02 10:30:06,951] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.07260553e-14   1.03166180e-13   8.47327918e-14
   4.02048966e-14   1.47564629e-36   1.46027565e-35   2.71214183e-36
   4.36771557e-36]
[2017-11-02 10:30:06,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.33187757e-14   1.08209652e-13   8.85826785e-14
   4.19061114e-14   1.53424200e-36   1.51585363e-35   2.82336736e-36
   4.56365736e-36]
[2017-11-02 10:30:07,076] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.91169298e-14   1.01908262e-13   8.27093588e-14
   3.91013414e-14   1.34975579e-36   1.34489956e-35   2.47116711e-36
   4.08210646e-36]
[2017-11-02 10:30:07,169] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.14831401e-14   1.07830554e-13   8.65306633e-14
   4.05128066e-14   1.20240430e-36   1.20556014e-35   2.21899634e-36
   3.65683242e-36]
[2017-11-02 10:30:08,045] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.64899803e-15   1.56405947e-15   2.30279946e-15
   3.34626168e-15   6.53692116e-26   5.92527428e-25   7.11484251e-26
   4.07525020e-26]
[2017-11-02 10:30:08,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.40220983e-14   4.28724032e-14   3.20825181e-14
   1.53146420e-14   4.66548535e-37   5.20121453e-36   8.68149823e-37
   1.49149240e-36]
[2017-11-02 10:30:09,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99976873e-01   5.23609151e-06   1.01181195e-05   3.54594545e-06
   4.21502864e-06   3.00092555e-11   3.16495885e-10   5.96350122e-11
   1.03156476e-10]
[2017-11-02 10:30:12,430] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.29642153e-15   3.06437896e-11   3.88249606e-11   1.18923673e-11
   2.70744295e-11   6.88065663e-02   6.69238508e-01   1.09310210e-01
   1.52644724e-01]
[2017-11-02 10:30:12,510] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.72787179e-03   8.93292890e-04   1.29261345e-03   4.74960281e-04
   7.58058450e-04   7.23958015e-02   6.61890388e-01   1.06365725e-01
   1.50201276e-01]
[2017-11-02 10:30:13,494] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.58818709e-08   1.00225691e-07   1.54372785e-07   7.61035537e-08
   1.23709341e-07   9.46960747e-02   6.58083737e-01   1.02216028e-01
   1.45003647e-01]
[2017-11-02 10:30:17,131] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.70516941e-12   9.84081653e-12   6.66208495e-12
   3.66939725e-12   2.58297481e-27   2.29467527e-26   3.55082202e-27
   5.20661833e-27]
[2017-11-02 10:30:18,559] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.77036655e-01   3.21801566e-03   5.38045261e-03   2.02154112e-03
   2.78904289e-03   7.34929519e-04   6.24810392e-03   1.07668375e-03
   1.49455376e-03]
[2017-11-02 10:30:28,709] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98992145e-01   2.80974287e-04   3.78970173e-04   1.52404522e-04
   1.93795451e-04   1.60355071e-07   1.08836252e-06   2.45911650e-07
   2.97650729e-07]
[2017-11-02 10:30:34,747] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.06348473e-14   9.27124148e-15   1.98731277e-14
   2.05791940e-14   5.26701041e-26   3.93109530e-25   5.00606970e-26
   2.19146623e-26]
[2017-11-02 10:30:35,239] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.15691005e-12   2.52009112e-12   5.06840186e-12
   5.28205778e-12   1.44766089e-23   7.37407358e-23   1.45239579e-23
   5.35285788e-24]
[2017-11-02 10:30:40,867] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.97725328e-16   2.26413230e-16   5.71814367e-16
   6.56669651e-16   6.79844995e-30   6.23725533e-29   6.73710908e-30
   1.93599537e-30]
[2017-11-02 10:30:40,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.19905963e-15   3.19683840e-16   7.79576567e-16
   9.02670306e-16   1.08185661e-29   9.49704704e-29   1.10947415e-29
   3.35163983e-30]
[2017-11-02 10:30:41,059] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.95064649e-16   1.87096939e-16   4.50523854e-16
   5.21501616e-16   3.48728210e-30   3.15597145e-29   3.69625302e-30
   1.21044330e-30]
[2017-11-02 10:30:41,519] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.21792075e-15   3.92688879e-15   7.78147823e-15
   7.61375724e-15   1.06384955e-29   8.10814641e-29   1.31749286e-29
   5.82870284e-30]
[2017-11-02 10:30:41,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.01127959e-12   6.24490390e-12   5.03894452e-12
   2.08432533e-12   1.13347586e-32   8.53763839e-32   2.45752229e-32
   3.35473216e-32]
[2017-11-02 10:30:43,022] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96928871e-01   5.53341175e-04   1.25944137e-03   4.79857001e-04
   7.43875105e-04   2.22089079e-06   2.27549372e-05   3.24313328e-06
   6.42930263e-06]
[2017-11-02 10:30:49,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.70506722e-07   1.35214805e-06   2.31169224e-06   7.02706416e-07
   1.73275203e-06   6.97545707e-02   6.83092058e-01   1.15741715e-01
   1.31404936e-01]
[2017-11-02 10:30:51,998] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.94161188e-13   8.95487781e-11   1.55170904e-10   4.24161851e-11
   1.23140498e-10   6.29516691e-02   6.89258754e-01   1.07510068e-01
   1.40279487e-01]
[2017-11-02 10:30:58,571] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.48573331e-10   5.78119663e-10   6.00929195e-10
   1.07710729e-09   9.00652654e-13   8.55402554e-12   9.10490867e-13
   5.52678996e-13]
[2017-11-02 10:30:59,667] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.82142983e-13   1.15925620e-13   1.42269294e-13
   2.14185047e-13   3.26781296e-21   3.44170498e-20   3.09428072e-21
   1.50932118e-21]
[2017-11-02 10:31:34,774] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.29222083e-04   7.30382671e-05   7.21873439e-05   2.55653995e-05
   5.73511388e-05   6.97950721e-02   6.90554261e-01   1.22958586e-01
   1.15734726e-01]
[2017-11-02 10:31:42,856] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.22144697e-10   5.66830784e-11   6.06101141e-11   4.97820153e-11
   7.95441560e-11   1.13743797e-01   7.59338081e-01   8.87244493e-02
   3.81936990e-02]
[2017-11-02 10:31:45,961] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.19525146  0.00299493  0.00374549  0.00173397  0.00214273  0.06254911
  0.51997483  0.09279774  0.11880971]
[2017-11-02 10:31:54,592] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.27861118  0.00389101  0.00343936  0.00137055  0.00254176  0.05426733
  0.47807363  0.09246974  0.08533543]
[2017-11-02 10:31:58,670] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99952197e-01   1.08473091e-06   6.78620779e-07   6.68630094e-07
   1.16058982e-06   4.28522162e-06   3.36442172e-05   3.97335452e-06
   2.32308980e-06]
[2017-11-02 10:31:58,782] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.75713125e-11   1.09162705e-11   5.01800598e-12   3.92308321e-12
   1.04119283e-11   8.98740664e-02   7.62958288e-01   9.62209105e-02
   5.09468243e-02]
[2017-11-02 10:32:14,885] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99572217e-01   5.29390888e-07   2.30808411e-07   2.48211421e-07
   5.09545487e-07   3.72538780e-05   3.35974677e-04   3.74979682e-05
   1.55060479e-05]
[2017-11-02 10:32:15,724] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.30100458e-03   5.47052323e-08   2.08005488e-08   2.13771614e-08
   5.47286092e-08   6.91187680e-02   8.30655694e-01   7.42759109e-02
   2.16485299e-02]
[2017-11-02 10:32:15,847] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.46082764e-05   2.70338596e-09   9.63451430e-10   9.54379686e-10
   2.61989164e-09   7.09216073e-02   8.28320205e-01   7.81445205e-02
   2.25891806e-02]
[2017-11-02 10:32:17,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.64227709e-17   1.95154646e-14   9.88754180e-15   4.86728044e-15
   1.60941867e-14   7.50773251e-02   7.22869039e-01   1.19541965e-01
   8.25116858e-02]
[2017-11-02 10:32:29,406] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.04388874e-07   3.94467392e-09   2.17878826e-09   1.63557623e-09
   4.13032542e-09   8.95159394e-02   7.32995033e-01   1.05494879e-01
   7.19939619e-02]
[2017-11-02 10:32:31,682] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.95994277e-02   5.16312184e-07   2.18153801e-07   2.07175162e-07
   5.44104182e-07   6.89966157e-02   7.75865614e-01   7.59214759e-02
   2.96153650e-02]
[2017-11-02 10:32:39,329] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.48475169e-06   3.75288187e-06   4.06291292e-06   1.35854009e-06
   3.12142424e-06   7.34813735e-02   6.70831978e-01   1.28003180e-01
   1.27667680e-01]
[2017-11-02 10:32:50,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999642e-01   1.07963736e-08   4.57091387e-09   5.11044007e-09
   1.10733342e-08   2.53656864e-08   2.68970950e-07   2.63439635e-08
   1.01863016e-08]
[2017-11-02 10:32:53,179] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.68548003e-21   3.79284159e-15   3.57491695e-15   9.42328283e-16
   2.29528543e-15   6.29000887e-02   5.93256652e-01   1.49505198e-01
   1.94338068e-01]
[2017-11-02 10:32:59,193] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.60538710e-10   1.70315690e-08   1.72071086e-08   5.61658675e-09
   1.42221595e-08   7.11157620e-02   6.72548473e-01   1.22047357e-01
   1.34288460e-01]
[2017-11-02 10:33:05,308] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.70172381e-04   4.81525442e-09   1.62883584e-09   1.57247093e-09
   4.81290430e-09   6.28223941e-02   8.39426398e-01   7.46763274e-02
   2.29046382e-02]
[2017-11-02 10:33:10,908] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.89863325e-10   3.08255181e-08   3.30729719e-08   1.05707558e-08
   2.46859901e-08   7.74441585e-02   6.47739768e-01   1.31620422e-01
   1.43195629e-01]
[2017-11-02 10:33:14,037] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.09722051e-19   1.95289324e-14   1.21502379e-14   3.73353700e-15
   1.40807649e-14   6.65079355e-02   7.03641534e-01   1.30829632e-01
   9.90209654e-02]
[2017-11-02 10:33:21,914] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.30686806e-11   1.43875103e-11   2.04338040e-11
   3.99074523e-11   1.46097178e-13   1.57597427e-12   1.42590936e-13
   4.64254896e-14]
[2017-11-02 10:33:32,507] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.17524621e-12   6.52488155e-13   1.30760550e-12
   8.22735706e-13   9.41787200e-26   5.72931827e-25   6.35380867e-26
   1.72462189e-26]
[2017-11-02 10:33:35,661] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.47218529e-09   1.56839008e-07   1.66720042e-07   5.70291228e-08
   1.02738312e-07   8.34908709e-02   6.28664136e-01   1.37884423e-01
   1.49960145e-01]
[2017-11-02 10:33:38,294] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.70130687e-14   9.06877698e-11   7.13338694e-11   2.34074028e-11
   6.10672485e-11   7.09063560e-02   6.71796978e-01   1.29932076e-01
   1.27364531e-01]
[2017-11-02 10:33:46,364] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999285e-01   6.01165251e-09   2.03217154e-09   2.57911736e-09
   5.61100544e-09   5.35976312e-08   6.08433197e-07   5.54984965e-08
   1.72746777e-08]
[2017-11-02 10:34:09,444] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.09373730e-18   6.87335551e-13   5.51010138e-13   1.74167918e-13
   4.10063720e-13   9.19838920e-02   5.97180247e-01   1.62330955e-01
   1.48504823e-01]
[2017-11-02 10:34:17,665] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.64837705e-15   1.15784957e-15   2.65909392e-15
   3.21885416e-15   1.70395727e-26   1.50989407e-25   1.67431783e-26
   5.89285375e-27]
[2017-11-02 10:34:23,021] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.72144485e-08   3.31846479e-07   4.67393392e-07   1.45136781e-07
   3.38618833e-07   7.35076442e-02   6.46526575e-01   1.22326940e-01
   1.57637537e-01]
[2017-11-02 10:34:31,899] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97541218e-03   2.37011482e-04   3.58586898e-04   1.11812878e-04
   2.02986659e-04   5.46609275e-02   6.46246433e-01   1.16624773e-01
   1.78582028e-01]
[2017-11-02 10:34:43,090] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.20499067e-01   4.03826483e-08   1.39882745e-08   1.59634155e-08
   4.54200588e-08   4.95161451e-02   7.65585601e-01   5.19844033e-02
   1.24146342e-02]
[2017-11-02 10:34:53,304] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.79886492e-18   1.83566405e-14   1.04960706e-14   4.31942588e-15
   1.30100559e-14   7.56571144e-02   6.80609584e-01   1.32321224e-01
   1.11412048e-01]
[2017-11-02 10:34:58,090] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.37202088e-12   1.75962001e-13   4.26319712e-14   3.73639921e-14
   1.37307253e-13   6.69523254e-02   8.17989469e-01   8.66586119e-02
   2.83996221e-02]
[2017-11-02 10:34:58,912] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.04162417e-08   3.39254541e-07   4.43498720e-07   1.26129578e-07
   2.58959091e-07   5.43824919e-02   6.50255620e-01   1.22522928e-01
   1.72837749e-01]
[2017-11-02 10:35:01,655] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.27022449e-12   7.56605611e-10   1.03554676e-09   3.11449838e-10
   7.86481269e-10   6.91005662e-02   6.58013165e-01   1.13497257e-01
   1.59389004e-01]
[2017-11-02 10:35:06,272] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.07876760e-11   5.68394880e-11   1.06015294e-10
   7.66377656e-11   1.90499988e-22   7.44391516e-22   1.00108039e-22
   2.66411896e-23]
[2017-11-02 10:35:07,265] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.08861250e-10   2.86574542e-10   5.02677788e-10
   3.64559882e-10   6.65438025e-22   2.38903251e-21   3.36960131e-22
   1.01861544e-22]
[2017-11-02 10:35:08,001] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.22758664e-10   2.33795400e-10   1.50269422e-10
   6.76821446e-11   5.10182971e-25   3.44542889e-24   6.77369369e-25
   1.18516165e-24]
[2017-11-02 10:35:11,323] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99504924e-01   1.37975469e-04   1.75844340e-04   7.21972028e-05
   1.06440370e-04   2.11658218e-07   1.86815612e-06   3.30777169e-07
   4.03265688e-07]
[2017-11-02 10:35:13,904] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.95330199e-11   6.12484369e-11   7.68579297e-11
   9.81618883e-11   1.90659043e-16   1.42114023e-15   1.60575517e-16
   9.44320505e-17]
[2017-11-02 10:35:21,693] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.43317459e-07   5.92066385e-07   5.10907341e-07   1.81481582e-07
   4.15935574e-07   7.34155327e-02   6.79996490e-01   1.30223945e-01
   1.16362087e-01]
[2017-11-02 10:35:24,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.86128036e-20   2.33734591e-15   1.29934187e-15   4.60166425e-16
   1.42879085e-15   7.13818595e-02   6.71162009e-01   1.47650868e-01
   1.09805197e-01]
[2017-11-02 10:35:29,389] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.17247811e-10   1.01206821e-10   1.33513783e-10
   2.48858739e-10   1.33625167e-13   1.20164859e-12   1.44544993e-13
   5.59895758e-14]
[2017-11-02 10:35:29,804] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.31231933e-07   4.00651106e-06   4.15557270e-06   1.44809815e-06
   1.90738501e-06   7.03971088e-02   5.37237287e-01   1.68652445e-01
   2.23701090e-01]
[2017-11-02 10:35:35,773] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00654431e-20   4.43247852e-15   3.37380169e-15   9.81472746e-16
   3.05915817e-15   7.23460391e-02   6.61112547e-01   1.35523662e-01
   1.31017745e-01]
[2017-11-02 10:35:39,302] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.42048184e-09   2.37585107e-09   2.79653345e-09
   5.33774847e-09   4.23193786e-10   3.77073439e-09   4.13895446e-10
   1.86773763e-10]
[2017-11-02 10:35:39,572] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.45377579e-15   1.62388487e-15   3.32833677e-15
   4.66343815e-15   3.24766343e-24   2.97140458e-23   2.91438666e-24
   1.08729990e-24]
[2017-11-02 10:35:39,617] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.70514381e-15   4.40625030e-16   1.01261010e-15
   1.29277874e-15   3.57167683e-26   3.42677479e-25   3.26956283e-26
   1.14527527e-26]
[2017-11-02 10:35:39,676] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.06796392e-15   2.41089188e-16   5.91263408e-16
   7.20418621e-16   3.28026738e-27   3.19948147e-26   3.07607643e-27
   1.00085254e-27]
[2017-11-02 10:35:40,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.25670172e-16   1.84646512e-16   4.35385311e-16
   5.00819665e-16   2.98145541e-29   3.01392123e-28   2.99011156e-29
   1.04247714e-29]
[2017-11-02 10:35:41,026] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996781e-01   9.22890592e-07   1.25598717e-06   5.37627784e-07
   4.93686287e-07   2.63901883e-13   2.20652359e-12   5.59123765e-13
   8.20501490e-13]
[2017-11-02 10:35:44,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.65598946e-15   1.64824075e-11   2.41226917e-11   7.00982761e-12
   2.08688067e-11   6.06518909e-02   6.90026760e-01   1.03576146e-01
   1.45745188e-01]
[2017-11-02 10:35:49,640] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.94997854e-16   7.92605257e-17   2.08900149e-16
   2.58556225e-16   3.76648558e-28   3.83947115e-27   3.51632630e-28
   9.61016774e-29]
[2017-11-02 10:35:50,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.18191187e-15   2.85741853e-16   7.42471018e-16
   8.74097397e-16   1.48777077e-28   1.43632639e-27   1.33440259e-28
   3.42702923e-29]
[2017-11-02 10:35:50,907] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.0149697   0.00289149  0.00385652  0.00127653  0.00157866  0.06623106
  0.54743332  0.14551206  0.21625066]
[2017-11-02 10:35:56,233] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.30892687e-14   2.03932340e-11   1.76822983e-11   5.42332889e-12
   1.54855000e-11   7.03136921e-02   6.78450942e-01   1.27702981e-01
   1.23532467e-01]
[2017-11-02 10:36:04,941] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.03116209  0.00387087  0.00769156  0.00260592  0.00479801  0.0611261
  0.61284667  0.09599772  0.17990102]
[2017-11-02 10:36:05,299] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.87172961  0.00965689  0.01976875  0.00699968  0.01222572  0.00516171
  0.05206465  0.00796247  0.0144305 ]
[2017-11-02 10:36:11,736] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99966025e-01   7.13456802e-06   1.34677393e-05   5.20989443e-06
   8.15390194e-06   4.75154915e-10   4.62026639e-09   7.28826999e-10
   9.10339804e-10]
[2017-11-02 10:36:17,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.18138483e-12   5.21876813e-12   8.90319762e-12
   6.77443605e-12   1.77977239e-21   1.06436997e-20   1.16784453e-21
   3.70349445e-22]
[2017-11-02 10:36:17,746] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.67849759e-12   9.57771536e-12   1.49186982e-11
   1.28650398e-11   2.41614520e-19   1.41487951e-18   1.59643842e-19
   4.97626881e-20]
[2017-11-02 10:36:20,315] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.78811424e-09   1.26492372e-08   6.37851327e-09
   5.74564885e-09   1.29456816e-18   8.97347862e-18   1.85240357e-18
   2.02289025e-18]
[2017-11-02 10:36:22,598] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.19084176e-07   1.57515615e-06   1.58339742e-06   5.39678240e-07
   1.22456333e-06   6.86508268e-02   6.81018054e-01   1.20096825e-01
   1.30228683e-01]
[2017-11-02 10:36:28,441] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.10755860e-14   3.05677102e-15   6.56567298e-15
   8.29067463e-15   1.55996394e-25   1.36548707e-24   1.51853530e-25
   5.81086529e-26]
[2017-11-02 10:36:29,521] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.47049452e-12   2.11928175e-12   1.82481764e-12
   8.62667088e-13   4.47993092e-29   3.36011797e-28   8.92709696e-29
   1.34568950e-28]
[2017-11-02 10:36:32,926] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.27744818  0.0064811   0.007321    0.00278179  0.00488443  0.05315591
  0.46281266  0.08629636  0.09881856]
[2017-11-02 10:36:55,713] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.21300971e-14   1.69207520e-14   3.99407476e-14
   4.87798651e-14   8.62253861e-25   6.22232301e-24   8.05304809e-25
   2.60997761e-25]
[2017-11-02 10:36:55,843] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.31467233e-14   1.18190793e-14   2.78916447e-14
   3.33401858e-14   4.43430548e-25   3.30424744e-24   4.07598291e-25
   1.31622970e-25]
[2017-11-02 10:37:19,173] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99894381e-01   2.51139882e-05   4.07578082e-05   1.58493476e-05
   2.38581270e-05   1.54809843e-09   1.26039756e-08   2.36042408e-09
   2.77312329e-09]
[2017-11-02 10:37:19,359] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98791158e-01   2.88828480e-04   4.51543339e-04   1.68297425e-04
   2.78408581e-04   1.72063687e-06   1.43356683e-05   2.70504256e-06
   3.10902237e-06]
[2017-11-02 10:37:30,053] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.22504726  0.00906976  0.01345013  0.00486507  0.00785258  0.05069369
  0.49036476  0.07865261  0.12000414]
[2017-11-02 10:37:30,110] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   1.11457632e-06   1.99941655e-06   9.15343719e-07
   9.79895049e-07   2.43860433e-13   2.24263576e-12   3.27389889e-13
   5.15087972e-13]
[2017-11-02 10:37:34,805] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.12615306e-10   8.04113373e-11   1.38498060e-10
   1.04263438e-10   5.74821366e-24   2.27519776e-23   3.20131608e-24
   1.05674574e-24]
[2017-11-02 10:37:39,154] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.79824610e-16   2.67219969e-16   5.82238907e-16
   6.79585333e-16   3.86971543e-28   3.96885127e-27   3.72237745e-28
   1.50370110e-28]
[2017-11-02 10:37:43,108] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.06882853  0.00275668  0.00428347  0.00143395  0.00262451  0.0661554
  0.6083352   0.10788337  0.13769887]
[2017-11-02 10:37:43,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995828e-01   8.92831736e-07   1.61626542e-06   6.54866312e-07
   8.95943288e-07   5.90641956e-13   5.53366858e-12   8.95441707e-13
   1.15924750e-12]
[2017-11-02 10:37:44,177] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.18303423e-04   1.14934883e-04   1.75527748e-04   5.79182451e-05
   1.18768025e-04   6.64515868e-02   6.77951038e-01   1.09570190e-01
   1.45041779e-01]
[2017-11-02 10:37:47,619] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.20922323e-17   2.78043728e-13   2.20798084e-13   8.67988881e-14
   1.96399849e-13   7.99645856e-02   6.20675743e-01   1.39581949e-01
   1.59777716e-01]
[2017-11-02 10:37:51,264] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999642e-01   1.08230587e-07   1.58656391e-07   7.18094526e-08
   5.63071545e-08   2.85506404e-16   2.24376360e-15   5.81563822e-16
   8.60860654e-16]
[2017-11-02 10:37:52,142] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97534156e-01   6.79000746e-04   9.27517714e-04   4.16155613e-04
   4.39333351e-04   3.05977949e-07   1.97360737e-06   5.43205488e-07
   8.95922426e-07]
[2017-11-02 10:37:58,995] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.00733493e-13   2.30390875e-13   5.07352515e-13
   5.55316427e-13   1.00875724e-25   6.18901218e-25   9.74622857e-26
   2.93618867e-26]
[2017-11-02 10:37:59,104] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.74309534e-13   2.30693421e-13   5.15467985e-13
   5.39793850e-13   1.23591750e-25   7.44876141e-25   1.20706639e-25
   3.62825480e-26]
[2017-11-02 10:37:59,971] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98228371e-01   4.91771789e-04   7.23803416e-04   3.00880201e-04
   2.53761158e-04   1.04887576e-07   7.19823561e-07   2.32518701e-07
   4.14699173e-07]
[2017-11-02 10:38:01,840] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.84721345e-14   3.16712184e-10   3.30456135e-10   1.07329250e-10
   2.44474940e-10   7.86149278e-02   6.17543399e-01   1.26041025e-01
   1.77800596e-01]
[2017-11-02 10:38:05,222] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999523e-01   5.86109543e-08   3.00527105e-08   3.06753911e-08
   5.98984187e-08   1.71894872e-08   1.59847076e-07   1.76186195e-08
   1.08744098e-08]
[2017-11-02 10:38:14,434] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.18864622e-05   7.27999895e-06   7.59684735e-06   2.62475919e-06
   6.45523505e-06   6.55880496e-02   7.12405622e-01   1.15054429e-01
   1.06896155e-01]
[2017-11-02 10:38:17,393] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   7.23621107e-10   2.55960309e-10   3.37894018e-10
   7.79894094e-10   1.35532634e-08   1.82740635e-07   1.31860780e-08
   3.36565309e-09]
[2017-11-02 10:38:18,635] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.16748580e-11   9.87872978e-12   1.53023427e-11
   3.84372291e-11   5.62647914e-11   7.24372506e-10   5.66334445e-11
   1.50697007e-11]
[2017-11-02 10:38:29,322] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.83783336e-11   5.93642193e-12   8.68131001e-12
   1.82330869e-11   3.81639734e-13   4.71217466e-12   3.78069375e-13
   1.13794485e-13]
[2017-11-02 10:38:33,330] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.14524609  0.01269185  0.01305762  0.00541539  0.00725104  0.07106651
  0.48907223  0.11377556  0.14242373]
[2017-11-02 10:38:37,956] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.95860150e-11   2.49528766e-11   4.49267047e-11
   3.19181383e-11   1.60284409e-21   7.72531843e-21   1.04276779e-21
   3.00587029e-22]
[2017-11-02 10:38:45,103] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.88783781e-06   2.90714333e-08   1.35264884e-08   1.24573818e-08
   2.69096656e-08   1.07899323e-01   7.19705880e-01   1.09384641e-01
   6.30082190e-02]
[2017-11-02 10:38:45,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.75185135e-11   1.12385656e-11   2.09746300e-11
   2.23826374e-11   6.10658918e-22   2.79425569e-21   6.17480179e-22
   2.01952443e-22]
[2017-11-02 10:38:47,989] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.43095341e-12   1.86700291e-11   1.24875032e-11
   5.09087911e-12   7.49057591e-29   5.14173799e-28   1.52003395e-28
   3.24800381e-28]
[2017-11-02 10:38:53,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984622e-01   3.49718221e-06   6.23364031e-06   2.51931033e-06
   3.24989878e-06   2.28314828e-12   1.73930887e-11   3.41082089e-12
   4.65763105e-12]
[2017-11-02 10:38:54,314] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.00431997  0.001267    0.00186732  0.00066395  0.00118908  0.07126535
  0.62739801  0.11051276  0.18151654]
[2017-11-02 10:38:58,254] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98333275e-01   1.01872763e-06   4.80684434e-07   4.53328596e-07
   1.01978515e-06   1.29385022e-04   1.31675031e-03   1.43803030e-04
   7.38384406e-05]
[2017-11-02 10:38:58,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.46683248e-03   7.93165896e-07   3.55571103e-07   3.03042839e-07
   7.70171710e-07   7.81452134e-02   7.75060654e-01   9.11326632e-02
   4.91923988e-02]
[2017-11-02 10:38:59,265] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   4.26848565e-08   2.32953408e-08   2.19133529e-08
   4.34020571e-08   4.89400831e-09   4.40962999e-08   5.53447954e-09
   3.17159587e-09]
[2017-11-02 10:39:04,139] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.12661311e-10   3.05703338e-08   3.24042055e-08   1.05822506e-08
   2.42785170e-08   7.26003647e-02   6.58695757e-01   1.23795487e-01
   1.44908369e-01]
[2017-11-02 10:39:08,224] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.91890128e-16   1.56458976e-16   4.09356280e-16
   4.94200050e-16   1.45930625e-28   1.44966952e-27   1.32778124e-28
   3.39838885e-29]
[2017-11-02 10:39:08,799] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.45858323e-15   1.19179981e-15   2.99271182e-15
   3.60538558e-15   4.03850682e-28   3.44861869e-27   3.59872505e-28
   7.99829136e-29]
[2017-11-02 10:39:16,357] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.15472916e-16   8.10015821e-17   2.06176753e-16
   2.78799148e-16   2.30809723e-27   2.25152859e-26   2.27064983e-27
   6.38358773e-28]
[2017-11-02 10:39:28,591] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.43636058e-10   6.40349884e-10   1.05408449e-09
   8.67913408e-10   2.23035245e-20   6.99222493e-20   1.09953161e-20
   2.83185646e-21]
[2017-11-02 10:39:30,176] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.32709893e-10   1.47366952e-09   1.15814469e-09
   3.94267424e-10   2.25613695e-26   1.20662451e-25   3.34679169e-26
   5.14971265e-26]
[2017-11-02 10:39:31,138] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99973297e-01   6.64553090e-06   1.05946028e-05   4.84301927e-06
   4.67728432e-06   1.32124899e-12   9.14278115e-12   1.95017808e-12
   3.39758863e-12]
[2017-11-02 10:39:32,538] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.27505325e-13   7.88351657e-14   1.72897422e-13
   1.80835883e-13   1.73745875e-26   1.11203565e-25   1.56368687e-26
   5.05783678e-27]
[2017-11-02 10:39:34,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.94120458e-12   4.21816922e-12   3.34949776e-12
   1.23896097e-12   2.49486003e-33   1.89856238e-32   5.96207135e-33
   9.02555730e-33]
[2017-11-02 10:39:34,636] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.94274544e-12   4.22396623e-12   3.35451025e-12
   1.24013354e-12   2.48429931e-33   1.89104524e-32   5.93447919e-33
   8.98680419e-33]
[2017-11-02 10:39:36,147] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.57106341e-14   2.68075848e-14   5.93283899e-14
   5.34272571e-14   6.31172021e-28   4.09558594e-27   7.54607567e-28
   3.24463536e-28]
[2017-11-02 10:39:36,732] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.60403036e-14   4.16321903e-15   1.00638373e-14
   1.19836061e-14   5.18333037e-28   3.69159478e-27   5.17763877e-28
   1.31251235e-28]
[2017-11-02 10:39:37,583] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.38909149e-02   1.13407765e-07   1.36001281e-08   1.67468315e-08
   6.15121394e-08   5.33373356e-02   7.58096993e-01   8.29844400e-02
   2.16901079e-02]
[2017-11-02 10:39:37,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.52731035e-14   3.60328358e-14   2.36157732e-14
   8.98188232e-15   0.00000000e+00   1.10366121e-37   2.27586621e-38
   3.41418692e-38]
[2017-11-02 10:39:39,010] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.41218629e-14   4.17161312e-15   9.93748710e-15
   1.17636630e-14   2.20731370e-27   1.51086693e-26   2.47743616e-27
   7.94838318e-28]
[2017-11-02 10:39:39,421] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.21569142e-19   3.35234750e-20   1.07013125e-19
   1.33668600e-19   3.97685007e-36   6.13000445e-35   4.41893108e-36
   9.86177359e-37]
[2017-11-02 10:39:39,884] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   9.60913647e-15   2.00730512e-14   1.51510088e-14
   6.29183315e-15   0.00000000e+00   3.05075932e-38   0.00000000e+00
   0.00000000e+00]
[2017-11-02 10:39:46,075] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.66767351e-08   1.98679656e-10   7.26542784e-11   6.06901057e-11
   1.90555918e-10   6.69404864e-02   8.15253198e-01   8.26856941e-02
   3.51204760e-02]
[2017-11-02 10:39:46,186] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999762e-01   9.74478542e-09   4.32369518e-09   4.55726479e-09
   1.00228705e-08   1.64063341e-08   1.94348374e-07   1.79672170e-08
   7.76590259e-09]
[2017-11-02 10:39:56,690] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.60099059e-12   2.12555085e-09   2.46884446e-09   7.53828666e-10
   1.75254378e-09   7.56320432e-02   6.40919566e-01   1.26690760e-01
   1.56757623e-01]
[2017-11-02 10:40:00,575] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.60698867e-11   2.55844061e-11   4.27322136e-11
   2.77021999e-11   4.15255749e-24   1.97883865e-23   2.83690139e-24
   1.16803429e-24]
[2017-11-02 10:40:01,749] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.77189064e-01   5.56551432e-03   8.69427528e-03   3.67073016e-03
   3.51162557e-03   1.23998252e-04   7.81376613e-04   1.77879672e-04
   2.85624817e-04]
[2017-11-02 10:40:03,196] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.49080474e-19   1.87148176e-13   1.66229687e-13   4.85427060e-14
   1.25561020e-13   7.58358613e-02   6.16877913e-01   1.37707099e-01
   1.69579163e-01]
[2017-11-02 10:40:05,427] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.64935664e-15   4.69816512e-16   1.19118169e-15
   1.25545381e-15   4.81275411e-31   4.33774154e-30   4.47709029e-31
   1.10549331e-31]
[2017-11-02 10:40:05,783] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.53021665e-11   1.51827467e-10   1.10700324e-10
   4.02941638e-11   5.61960659e-29   3.33712502e-28   1.22406823e-28
   1.96221374e-28]
[2017-11-02 10:40:08,363] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.28284115e-15   8.37640728e-16   2.11336097e-15
   2.43915377e-15   7.62739126e-30   6.23078661e-29   7.43117436e-30
   1.67505538e-30]
[2017-11-02 10:40:08,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.07828442e-11   5.05139923e-11   3.92264485e-11
   1.46860614e-11   3.59502848e-31   2.45061608e-30   8.51185522e-31
   1.33058889e-30]
[2017-11-02 10:40:09,817] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.04804765e-16   1.85731614e-16   4.36396271e-16
   4.76342054e-16   5.09850691e-31   4.68435214e-30   5.38246732e-31
   2.13453905e-31]
[2017-11-02 10:40:11,339] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91724889e-08   6.03845422e-07   8.80280652e-07   2.90595978e-07
   6.64977904e-07   6.55997396e-02   6.74447656e-01   1.05759948e-01
   1.54190063e-01]
[2017-11-02 10:40:11,609] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.41680276e-08   1.60907220e-07   2.32147869e-07   7.54041878e-08
   1.79007159e-07   6.54570386e-02   6.77348554e-01   1.06839024e-01
   1.50354832e-01]
[2017-11-02 10:40:14,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.61775140e-15   4.19831907e-16   1.00387179e-15
   1.18711720e-15   1.26999721e-28   1.21364921e-27   1.22268686e-28
   3.71773512e-29]
[2017-11-02 10:40:19,465] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.81183403e-02   4.98571524e-07   1.61704477e-07   1.81233133e-07
   4.60540747e-07   8.60572979e-02   7.71810412e-01   8.35165754e-02
   3.04960981e-02]
[2017-11-02 10:40:20,958] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99690056e-01   8.09090416e-05   1.21811492e-04   4.62866628e-05
   6.09765048e-05   5.00866770e-09   3.80364256e-08   8.21817459e-09
   1.05594324e-08]
[2017-11-02 10:40:22,948] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99882221e-01   2.85636779e-05   4.43646786e-05   1.82155618e-05
   2.66421575e-05   1.12928600e-09   9.95433069e-09   1.71409098e-09
   2.42619835e-09]
[2017-11-02 10:40:26,850] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.78062546  0.01994445  0.03191591  0.0118012   0.0182474   0.0100529
  0.08500833  0.01519425  0.02721012]
[2017-11-02 10:40:29,667] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99540210e-01   1.08881948e-04   1.80378163e-04   8.98403378e-05
   7.99739573e-05   7.24145153e-08   5.36399227e-07   9.68189369e-08
   1.47248784e-07]
[2017-11-02 10:40:32,927] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.87415033e-17   3.38773085e-12   2.78616128e-12   9.58181451e-13
   2.08393806e-12   8.42187852e-02   5.88783801e-01   1.46180198e-01
   1.80817187e-01]
[2017-11-02 10:40:33,789] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.46133466e-09   4.63228256e-09   5.41651346e-09
   7.09601178e-09   4.02391336e-13   2.44792901e-12   3.53875810e-13
   2.53599225e-13]
[2017-11-02 10:40:33,929] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.27393495e-12   1.20955893e-12   1.64180746e-12
   2.03486165e-12   5.33535453e-21   3.67072641e-20   4.77951663e-21
   2.81385175e-21]
[2017-11-02 10:40:34,080] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   7.71357045e-13   2.22975636e-13   3.58714360e-13
   5.68520057e-13   8.13119705e-20   6.79115283e-19   8.20498092e-20
   3.62320359e-20]
[2017-11-02 10:40:36,871] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99991655e-01   1.99514329e-06   3.29465934e-06   1.51819552e-06
   1.56629267e-06   8.59850385e-14   5.89361079e-13   1.19849294e-13
   1.93835345e-13]
[2017-11-02 10:40:37,624] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.82877123  0.01192906  0.0168083   0.00632813  0.01075729  0.00916113
  0.08068869  0.01429291  0.02126325]
[2017-11-02 10:40:38,937] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.69282944e-16   6.82060046e-17   1.80501345e-16
   2.15979081e-16   1.33079632e-31   1.37735852e-30   1.45900913e-31
   4.69611991e-32]
[2017-11-02 10:40:39,252] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.17186485e-13   7.95044098e-14   1.76609080e-13
   1.86553450e-13   4.15272520e-27   2.60600693e-26   3.97661046e-27
   1.17473070e-27]
[2017-11-02 10:40:40,001] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.77050907e-12   1.55371549e-11   1.07363580e-11
   4.17577474e-12   6.85576752e-31   5.05325837e-30   1.39742721e-30
   2.81281937e-30]
[2017-11-02 10:40:40,610] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99894738e-01   3.10779651e-05   3.59982987e-05   2.04137959e-05
   1.77932779e-05   8.84290363e-10   4.54179228e-09   1.49088364e-09
   2.12700701e-09]
[2017-11-02 10:40:41,565] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.05072328e-16   4.82620911e-17   1.33459398e-16
   1.56163229e-16   2.56643830e-32   2.67910985e-31   2.49378599e-32
   5.08067834e-33]
[2017-11-02 10:40:43,865] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.60910735e-15   2.38563399e-15   6.02463238e-15
   6.94320318e-15   1.26477148e-27   9.89974214e-27   1.16370523e-27
   3.21075127e-28]
[2017-11-02 10:40:46,544] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   4.85796318e-16   1.19500877e-16   3.20308818e-16
   3.82798303e-16   3.01044799e-30   2.78989881e-29   3.19523063e-30
   8.95553380e-31]
[2017-11-02 10:40:46,854] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.40677975e-18   5.92624141e-19   1.84613933e-18
   2.38879008e-18   4.07983783e-34   5.32028229e-33   4.24546820e-34
   7.64756249e-35]
[2017-11-02 10:40:48,460] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.25302023e-14   1.17045774e-14   2.00008975e-14
   1.72050586e-14   3.38803337e-29   2.59594340e-28   3.94412517e-29
   2.28575189e-29]
[2017-11-02 10:40:50,282] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.45652700e-11   5.14019383e-11   3.87233301e-11
   1.57323009e-11   1.96233995e-29   1.27902079e-28   4.10775489e-29
   7.46684002e-29]
[2017-11-02 10:40:51,202] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.57553466e-11   2.52169830e-11   4.45539612e-11
   2.86689197e-11   5.27213887e-25   2.42586403e-24   3.53544433e-25
   1.56870032e-25]
[2017-11-02 10:40:51,275] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   5.06544702e-11   3.70629950e-11   6.34458111e-11
   4.01223776e-11   1.51829850e-24   6.78153112e-24   1.00154540e-24
   4.56154233e-25]
[2017-11-02 10:40:51,562] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.51489002e-11   4.94855892e-11   8.50609860e-11
   5.38227587e-11   1.16846215e-24   5.16904500e-24   7.53863486e-25
   3.52553204e-25]
[2017-11-02 10:40:56,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99886394e-01   2.63664533e-05   4.60294978e-05   1.80413699e-05
   2.31302565e-05   6.07758177e-10   4.89076646e-09   9.20182541e-10
   1.37517464e-09]
[2017-11-02 10:40:57,427] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.59698391  0.0126205   0.01978588  0.00721579  0.01259742  0.02462994
  0.22785851  0.03848554  0.0598226 ]
[2017-11-02 10:40:57,791] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94900823e-01   1.15697307e-03   1.76223612e-03   6.83812308e-04
   1.11680035e-03   2.73392434e-05   2.49359204e-04   4.19233911e-05
   6.07807597e-05]
[2017-11-02 10:40:58,397] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.92990335e-09   3.87006294e-09   1.85732985e-09
   2.01463624e-09   1.83833686e-20   1.65537917e-19   2.61200631e-20
   3.95944444e-20]
[2017-11-02 10:40:59,634] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.49281037e-17   3.12604602e-18   8.37288429e-18
   9.13874269e-18   2.61665748e-32   3.42099137e-31   2.64863328e-32
   8.37202211e-33]
[2017-11-02 10:40:59,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.04654112e-17   4.49647771e-18   1.26615858e-17
   1.35392013e-17   2.76906906e-33   3.55326552e-32   2.70393327e-33
   7.06354050e-34]
[2017-11-02 10:41:00,581] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.49965434e-12   7.46801492e-12   5.08622051e-12
   2.05564602e-12   4.78405277e-31   3.64750894e-30   9.66464184e-31
   1.88153463e-30]
[2017-11-02 10:41:03,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.78804888e-16   2.13932398e-16   5.55779715e-16
   6.22101919e-16   1.75190502e-29   1.73238747e-28   1.62316714e-29
   4.52570441e-30]
[2017-11-02 10:41:04,687] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   3.06822623e-11   7.66003511e-11   5.73482581e-11
   2.18088325e-11   1.02628716e-30   6.78187266e-30   2.15910006e-30
   3.12893801e-30]
[2017-11-02 10:41:04,898] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   2.03355128e-11   4.82419937e-11   3.44307326e-11
   1.30385555e-11   3.31957498e-30   2.23621200e-29   6.70040733e-30
   1.14528667e-29]
[2017-11-02 10:41:05,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   1.81154453e-10   3.05541481e-10   1.84930460e-10
   1.33864655e-10   2.14795051e-24   1.32670627e-23   2.74987090e-24
   4.34480960e-24]
[2017-11-02 10:41:07,468] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   6.34602039e-15   1.69171940e-15   4.14306684e-15
   5.15156883e-15   3.50240375e-28   2.77866432e-27   3.26350346e-28
   6.46181395e-29]
[2017-11-02 10:41:08,137] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.00000000e+00   8.87606915e-12   2.14347116e-11   1.67535916e-11
   6.55859872e-12   2.29458070e-32   1.69134430e-31   5.02745004e-32
   7.26373283e-32]
[2017-11-02 10:41:08,518] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -19458.2734
[2017-11-02 10:41:08,518] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 250000, evaluation results [250000.0, -19458.27338010617]
[2017-11-02 10:41:09,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   3.39607669e-17   8.30288297e-17   7.82463162e-17
   5.33756389e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:09,220] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.333333333333333, 72.0, 1.0, 213.3333333333334, 0.0, 0.0, -3.5, 15.58978534464604, 18.0, 21.53928805392152, 21.5, 0.0, 0.0], 
actual action is [-3.666666666666667, 18], 
sim time next is 4677900.0000, 
raw observation next is [1.166666666666667, 74.5, 0.8749999999999999, 186.6666666666666, 0.0, 0.0, -3.666666666666667, 17.12736973852981, 18.0, 21.51754772940013, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.3632478632478633, 0.745, 0.07954545454545453, 0.5185185185185184, 0.0, 0.0, 0.4388888888888889, 0.1712736973852981, 0.0, 0.5025068184857326, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:41:12,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-32.81018448]
 [-34.79334641]
 [-33.36060715]
 [-33.24949646]
 [-33.59140778]], R is [[-33.10428619]
 [-33.77324295]
 [-34.43551254]
 [-34.10598755]
 [-33.77925873]].
[2017-11-02 10:41:12,751] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-48.21146774]
 [-45.64338303]
 [-47.88190842]
 [-48.63516998]
 [-48.43313599]], R is [[-47.53513718]
 [-47.13495636]
 [-47.3481102 ]
 [-46.93582153]
 [-46.53562164]].
[2017-11-02 10:41:14,599] A3C_AGENT_WORKER-Thread-9 INFO:Local step 15500, global step 251545: loss 4.0550
[2017-11-02 10:41:14,714] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   1.08405384e-15   1.67338855e-15   1.79123413e-15
   9.72362483e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:14,742] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.0, 78.16666666666667, 3.6, 331.6666666666666, 0.0, 0.0, -8.0, 18.29825208568497, 18.0, 21.45181506516306, 21.5, 0.0, 0.0], 
actual action is [-8.0, 18], 
sim time next is 4748100.0000, 
raw observation next is [-3.0, 77.58333333333333, 3.6, 330.8333333333334, 0.0, 0.0, -8.0, 20.56819680322801, 18.0, 21.31244214656013, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.2564102564102564, 0.7758333333333333, 0.32727272727272727, 0.9189814814814817, 0.0, 0.0, 0.36666666666666664, 0.2056819680322801, 0.0, 0.47320602093716146, 0.5, 0.0, 0.0], 
reward next is -0.0268. 
=============================================
[2017-11-02 10:41:15,072] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99981165e-01   3.31914771e-06   7.45656780e-06   2.88795286e-06
   4.99420048e-06   1.62669878e-09   2.56689141e-08   6.28604502e-10
   1.05740838e-07], sum to 1.0000
[2017-11-02 10:41:15,120] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 3.1, 325.0, 0.0, 0.0, -1.0, 18.57707281302084, 25.0, 20.68441788599006, 21.5, 0.0, 46.49179453357443], 
actual action is [-1.0, 20.0], 
sim time next is 4764900.0000, 
raw observation next is [-6.0, 92.0, 3.183333333333334, 327.5, 0.0, 0.0, -1.0, 18.3354158140849, 20.0, 20.70847586850539, 21.5, 0.0, 45.97411364677654], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.2893939393939395, 0.9097222222222222, 0.0, 0.0, 0.48333333333333334, 0.183354158140849, 0.2857142857142857, 0.38692512407219837, 0.5, 0.0, 0.5408719252561945], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:19,886] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16000, global step 252838: loss 18.2121
[2017-11-02 10:41:20,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.74954981e-19   5.76728999e-20   1.73149026e-19
   1.02493526e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:20,268] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 72.66666666666667, 4.633333333333333, 333.3333333333334, 185.8333333333333, 5.0, -3.25, 13.17227446765718, 18.0, 22.50631297423135, 22.7, 1.0, 0.0], 
actual action is [-3.333333333333333, 18], 
sim time next is 4717500.0000, 
raw observation next is [1.583333333333333, 72.58333333333333, 4.766666666666666, 334.1666666666666, 190.9166666666667, 5.5, -3.333333333333333, 13.32738112438291, 18.0, 22.57041503363374, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.3739316239316239, 0.7258333333333333, 0.43333333333333324, 0.9282407407407405, 0.5050705467372135, 0.0055, 0.4444444444444445, 0.1332738112438291, 0.0, 0.6529164333762486, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:41:21,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.29945374e-16   4.22273320e-16   6.22405739e-16
   3.33292165e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.19973653e-38], sum to 1.0000
[2017-11-02 10:41:21,680] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.0, 92.0, 3.1, 325.0, 0.0, 0.0, -1.0, 18.87469199407235, 25.0, 20.55381651569731, 21.5, 0.0, 41.05366515035939], 
actual action is [-1.0, 20.0], 
sim time next is 4764900.0000, 
raw observation next is [-6.0, 92.0, 3.183333333333334, 327.5, 0.0, 0.0, -1.0, 18.63195421803354, 20.0, 20.64323750776511, 21.5, 0.0, 42.04889871333257], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.1794871794871795, 0.92, 0.2893939393939395, 0.9097222222222222, 0.0, 0.0, 0.48333333333333334, 0.1863195421803354, 0.2857142857142857, 0.3776053582521587, 0.5, 0.0, 0.49469292603920667], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:25,064] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16000, global step 253967: loss -55.0230
[2017-11-02 10:41:28,034] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16000, global step 254614: loss -18.6516
[2017-11-02 10:41:28,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   6.21342977e-16   3.37509172e-16   8.07865403e-16
   3.55915489e-16   9.83405947e-35   3.60913500e-34   5.81316682e-35
   2.17419692e-33], sum to 1.0000
[2017-11-02 10:41:28,354] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 3.6, 332.5, 134.25, 1.5, -4.0, 16.20294478694687, 18.0, 22.0979301218842, 22.7, 1.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 4710000.0000, 
raw observation next is [1.0, 86.0, 3.766666666666667, 333.3333333333334, 125.5, 0.9999999999999998, -4.0, 16.91395039437538, 18.0, 21.87544055403739, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5217391304347826, 0.358974358974359, 0.86, 0.34242424242424246, 0.9259259259259262, 0.33201058201058203, 0.0009999999999999998, 0.43333333333333335, 0.1691395039437538, 0.0, 0.5536343648624842, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:30,772] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16000, global step 255254: loss 89.8877
[2017-11-02 10:41:30,886] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16000, global step 255281: loss 3.2323
[2017-11-02 10:41:31,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.26887514e-13   4.62040614e-11   4.43662641e-11   1.72346633e-11
   2.01789020e-11   4.16161399e-03   1.56035302e-02   7.12900748e-03
   9.73105788e-01], sum to 1.0000
[2017-11-02 10:41:31,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-5.5, 84.5, 3.35, 355.0, 124.0, 419.0, -0.583333333333333, 13.20658131080951, 25.0, 21.6956474079579, 22.7, 1.0, 56.40129194956656], 
actual action is [-0.5, 25], 
sim time next is 4782900.0000, 
raw observation next is [-5.416666666666667, 83.25, 3.391666666666667, 355.8333333333333, 128.1666666666667, 419.1666666666667, -0.5, 12.54777643214309, 25.0, 21.83221482788007, 22.7, 1.0, 62.72932091736577], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.19444444444444445, 0.8325, 0.30833333333333335, 0.9884259259259258, 0.33906525573192253, 0.4191666666666667, 0.49166666666666664, 0.1254777643214309, 1.0, 0.5474592611257242, 0.6714285714285714, 1.0, 0.7379920107925384], 
reward next is -0.6767. 
=============================================
[2017-11-02 10:41:32,513] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16000, global step 255595: loss 190.7143
[2017-11-02 10:41:36,925] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16000, global step 256388: loss 0.6549
[2017-11-02 10:41:37,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16000, global step 256416: loss 62.2842
[2017-11-02 10:41:37,608] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16000, global step 256556: loss -105.7261
[2017-11-02 10:41:38,435] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   4.27784461e-15   1.92582321e-15   3.80293611e-15
   1.98647035e-15   3.94197235e-30   8.96726373e-30   1.50338985e-30
   7.23735434e-30], sum to 1.0000
[2017-11-02 10:41:38,457] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 5.0, 346.6666666666667, 139.5, 739.5, -2.0, 13.03033908691043, 18.0, 22.90683902435446, 22.7, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4805100.0000, 
raw observation next is [3.0, 37.0, 5.175000000000001, 345.0, 135.25, 738.25, -2.0, 13.41010675606702, 18.0, 22.85543923701719, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.41025641025641024, 0.37, 0.4704545454545455, 0.9583333333333334, 0.3578042328042328, 0.73825, 0.4666666666666667, 0.1341010675606702, 0.0, 0.6936341767167414, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0134. 
=============================================
[2017-11-02 10:41:38,589] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  8.60306609e-05   3.52588074e-08   1.49231418e-08   1.34162654e-08
   1.94337684e-08   2.17198297e-01   2.37804294e-01   7.14323074e-02
   4.73479033e-01], sum to 1.0000
[2017-11-02 10:41:38,605] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16000, global step 256851: loss -8.7268
[2017-11-02 10:41:38,628] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.25, 45.25, 3.1, 360.0, 129.75, 811.75, 3.5, 14.6018687518582, 19.0, 22.15652760199194, 22.7, 1.0, 54.29167341173808], 
actual action is [3.75, 21.0], 
sim time next is 4792800.0000, 
raw observation next is [-1.0, 45.0, 3.1, 360.0, 127.1666666666667, 820.8333333333334, 3.75, 14.08808651125764, 21.0, 22.18300088066937, 22.7, 1.0, 28.85002540160166], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.3076923076923077, 0.45, 0.2818181818181818, 1.0, 0.33641975308641986, 0.8208333333333334, 0.5625, 0.1408808651125764, 0.42857142857142855, 0.5975715543813384, 0.6714285714285714, 1.0, 0.3394120635482548], 
reward next is -0.3196. 
=============================================
[2017-11-02 10:41:39,008] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16000, global step 256982: loss -0.1890
[2017-11-02 10:41:39,336] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0490889
  0.0752961   0.05124728  0.82436776], sum to 1.0000
[2017-11-02 10:41:39,405] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.0, 71.0, 2.6, 315.0, 0.0, 0.0, 1.0, 17.65529924859822, 25.0, 20.70826601500326, 21.5, 0.0, 58.10333265461524], 
actual action is [1.0, 25], 
sim time next is 4758600.0000, 
raw observation next is [-4.0, 71.0, 2.6, 313.3333333333334, 0.0, 0.0, 1.0, 16.33545560873921, 25.0, 20.83527399036212, 21.5, 0.0, 51.05090380839776], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.23076923076923078, 0.71, 0.23636363636363636, 0.8703703703703707, 0.0, 0.0, 0.5166666666666667, 0.1633545560873921, 1.0, 0.4050391414803026, 0.5, 0.0, 0.6005988683340914], 
reward next is -0.6355. 
=============================================
[2017-11-02 10:41:39,615] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16000, global step 257144: loss 72.7707
[2017-11-02 10:41:39,939] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16000, global step 257234: loss 9.3336
[2017-11-02 10:41:40,576] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16000, global step 257435: loss -4.9472
[2017-11-02 10:41:41,277] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16000, global step 257636: loss 0.5874
[2017-11-02 10:41:41,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.80082242e-11   4.81375773e-11   4.83038679e-11
   1.90214216e-11   6.33294395e-28   1.87326578e-27   2.33616747e-28
   1.29729601e-27], sum to 1.0000
[2017-11-02 10:41:41,937] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 3.516666666666667, 21.66666666666666, 0.0, 0.0, 4.0, 15.74511831458977, 19.0, 21.87078761166754, 21.5, 0.0, 45.04940587997285], 
actual action is [-6.0, 18], 
sim time next is 4831800.0000, 
raw observation next is [-1.0, 55.0, 3.433333333333334, 23.33333333333334, 0.0, 0.0, -6.0, 16.93857862972861, 18.0, 21.8938330729217, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9565217391304348, 0.3076923076923077, 0.55, 0.3121212121212122, 0.06481481481481483, 0.0, 0.0, 0.4, 0.1693857862972861, 0.0, 0.5562618675602431, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:41:48,803] A3C_AGENT_WORKER-Thread-9 INFO:Local step 16000, global step 259699: loss 17.1572
[2017-11-02 10:41:49,311] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.65307465e-13   3.35841381e-13   3.65700065e-13
   1.02538420e-13   4.17098411e-34   2.95748024e-33   2.74602024e-34
   4.14736154e-33], sum to 1.0000
[2017-11-02 10:41:49,327] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.333333333333333, 61.66666666666667, 2.266666666666667, 26.66666666666667, 0.0, 0.0, -8.25, 25.74279246093091, 18.0, 20.09029482259164, 21.0, 0.0, 0.0], 
actual action is [-8.333333333333332, 18], 
sim time next is 4861500.0000, 
raw observation next is [-3.416666666666667, 62.08333333333333, 2.308333333333334, 25.83333333333333, 0.0, 0.0, -8.333333333333332, 28.04180546768505, 18.0, 20.07290559932125, 21.0, 0.0, 0.0], 
processed observation next is [1.0, 0.2608695652173913, 0.2457264957264957, 0.6208333333333332, 0.20984848484848492, 0.07175925925925924, 0.0, 0.0, 0.3611111111111111, 0.2804180546768505, 0.0, 0.296129371331607, 0.42857142857142855, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:49,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99999046e-01   1.80374656e-07   4.21861074e-07   2.35763181e-07
   1.48154967e-07   6.82071207e-13   4.59178875e-12   5.40799068e-13
   1.99866460e-11], sum to 1.0000
[2017-11-02 10:41:49,497] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.0, 68.0, 2.35, 35.0, 0.0, 0.0, 1.0, 23.45092666115535, 25.0, 19.96974989879535, 21.0, 0.0, 57.09545857070881], 
actual action is [1.0, 20.0], 
sim time next is 4865700.0000, 
raw observation next is [-4.0, 68.5, 2.308333333333334, 37.5, 11.75000000000001, 26.08333333333335, 1.0, 22.03342424751334, 20.0, 20.13190337271288, 21.0, 0.0, 41.02138509482258], 
processed observation next is [1.0, 0.30434782608695654, 0.23076923076923078, 0.685, 0.20984848484848492, 0.10416666666666667, 0.031084656084656114, 0.02608333333333335, 0.5166666666666667, 0.22033424247513342, 0.2857142857142857, 0.30455762467326863, 0.42857142857142855, 0.0, 0.48260453052732444], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:49,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   1.10285127e-18   1.67550024e-18   2.39462935e-18
   4.03001490e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.52036259e-38], sum to 1.0000
[2017-11-02 10:41:49,769] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 37.0, 5.175000000000001, 345.0, 135.25, 738.25, -2.0, 18.35784069235899, 18.0, 22.04776892220992, 22.7, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4805400.0000, 
raw observation next is [3.0, 37.0, 5.35, 343.3333333333334, 131.0, 737.0, -2.0, 18.42805772441384, 18.0, 22.03181900957651, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.41025641025641024, 0.37, 0.48636363636363633, 0.9537037037037039, 0.34656084656084657, 0.737, 0.4666666666666667, 0.1842805772441384, 0.0, 0.5759741442252155, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:50,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 16500, global step 260206: loss 217.6163
[2017-11-02 10:41:55,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.62662886e-18   7.54306331e-18   9.68371161e-18
   1.20035301e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:55,127] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 62.5, 2.6, 75.0, 207.0, 179.0, -7.583333333333333, 22.62023256882917, 18.0, 21.24466979269362, 22.2, 1.0, 0.0], 
actual action is [-7.5, 18], 
sim time next is 4872900.0000, 
raw observation next is [-2.416666666666667, 62.08333333333333, 2.683333333333334, 75.83333333333334, 214.75, 177.75, -7.5, 23.76730918002605, 18.0, 21.23124208563598, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.391304347826087, 0.27136752136752135, 0.6208333333333332, 0.243939393939394, 0.21064814814814817, 0.5681216931216931, 0.17775, 0.375, 0.2376730918002605, 0.0, 0.46160601223371145, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:55,201] A3C_AGENT_WORKER-Thread-6 INFO:Local step 16500, global step 261272: loss -327.2401
[2017-11-02 10:41:56,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   7.46084884e-17   5.74578182e-16   7.57161163e-16
   8.09175802e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   3.45495938e-38], sum to 1.0000
[2017-11-02 10:41:56,781] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.75, 44.75, 2.475, 57.5, 50.25, 219.5, -2.166666666666667, 23.44474259883561, 18.0, 21.83068276957082, 22.2, 1.0, 0.0], 
actual action is [-2.25, 18], 
sim time next is 4900800.0000, 
raw observation next is [2.666666666666667, 44.66666666666667, 2.433333333333334, 56.66666666666667, 44.5, 208.6666666666667, -2.25, 23.75479819430605, 18.0, 21.79111741742513, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.7391304347826086, 0.4017094017094017, 0.4466666666666667, 0.22121212121212128, 0.1574074074074074, 0.11772486772486772, 0.20866666666666672, 0.4625, 0.2375479819430605, 0.0, 0.5415882024893044, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:57,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.27306366e-19   4.42016627e-19   8.10268388e-19
   1.14116687e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:41:57,721] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 44.16666666666667, 3.433333333333334, 70.0, 248.0, 378.6666666666667, -2.916666666666667, 22.04902520211808, 18.0, 21.84124242777696, 22.2, 1.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 4889700.0000, 
raw observation next is [2.25, 44.25, 3.35, 70.0, 245.0, 377.5, -2.833333333333333, 22.36763887610409, 18.0, 21.80410523219345, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.6086956521739131, 0.391025641025641, 0.4425, 0.30454545454545456, 0.19444444444444445, 0.6481481481481481, 0.3775, 0.4527777777777778, 0.22367638876104087, 0.0, 0.5434436045990643, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:41:58,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 16500, global step 262210: loss 211.9012
[2017-11-02 10:41:58,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 16500, global step 262329: loss 119.1459
[2017-11-02 10:41:59,478] A3C_AGENT_WORKER-Thread-8 INFO:Local step 16500, global step 262634: loss -80.8140
[2017-11-02 10:42:01,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.69491767e-14   9.17383032e-14   8.56008786e-14
   3.49967722e-14   2.07823146e-31   4.08552842e-31   7.56947009e-32
   1.12478123e-29], sum to 1.0000
[2017-11-02 10:42:01,114] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.3333333333333333, 45.33333333333334, 1.7, 63.33333333333334, 0.0, 0.0, 4.75, 27.85111058607846, 23.0, 20.2449593978358, 21.0, 0.0, 92.36980529433565], 
actual action is [-5.333333333333333, 18.0], 
sim time next is 4929900.0000, 
raw observation next is [-0.4166666666666667, 45.91666666666666, 1.75, 61.66666666666666, 0.0, 0.0, -5.333333333333333, 28.86373401425579, 18.0, 20.4413125849644, 21.0, 0.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.32264957264957267, 0.45916666666666656, 0.1590909090909091, 0.17129629629629628, 0.0, 0.0, 0.41111111111111115, 0.28863734014255793, 0.0, 0.34875894070920005, 0.42857142857142855, 0.0, 0.0], 
reward next is -0.0798. 
=============================================
[2017-11-02 10:42:01,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   3.95759336e-17   1.19910021e-16   1.58825877e-16
   2.92260215e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   5.23325169e-38], sum to 1.0000
[2017-11-02 10:42:01,596] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 45.0, 2.6, 60.0, 79.00000000000001, 273.6666666666667, -2.0, 23.40424541932743, 18.0, 21.88163717842523, 22.2, 1.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 4899300.0000, 
raw observation next is [3.0, 45.0, 2.6, 60.0, 73.25, 262.8333333333334, -2.0, 23.6884651610672, 18.0, 21.84592968359832, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.41025641025641024, 0.45, 0.23636363636363636, 0.16666666666666666, 0.19378306878306878, 0.2628333333333334, 0.4666666666666667, 0.236884651610672, 0.0, 0.5494185262283315, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:02,077] A3C_AGENT_WORKER-Thread-13 INFO:Local step 16500, global step 263426: loss -94.0540
[2017-11-02 10:42:04,485] A3C_AGENT_WORKER-Thread-4 INFO:Local step 16500, global step 264181: loss -10.5037
[2017-11-02 10:42:04,880] A3C_AGENT_WORKER-Thread-17 INFO:Local step 16500, global step 264307: loss -113.4729
[2017-11-02 10:42:05,996] A3C_AGENT_WORKER-Thread-5 INFO:Local step 16500, global step 264630: loss -57.0101
[2017-11-02 10:42:06,206] A3C_AGENT_WORKER-Thread-2 INFO:Local step 16500, global step 264687: loss 3.0326
[2017-11-02 10:42:06,696] A3C_AGENT_WORKER-Thread-12 INFO:Local step 16500, global step 264814: loss 67.8316
[2017-11-02 10:42:07,216] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  2.75505638e-12   7.71703368e-10   1.86181481e-09   5.74269354e-10
   9.20765519e-10   5.23969997e-04   2.01989268e-03   8.06503987e-04
   9.96649683e-01], sum to 1.0000
[2017-11-02 10:42:07,283] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.416666666666667, 47.66666666666666, 2.391666666666667, 15.83333333333333, 0.0, 0.0, -7.333333333333333, 25.69462597870145, 18.0, 20.83495595428035, 21.0, 0.0, 0.0], 
actual action is [2.583333333333333, 23.0], 
sim time next is 4944600.0000, 
raw observation next is [-2.5, 48.0, 2.35, 15.0, 0.0, 0.0, 2.583333333333333, 23.59218746145441, 23.0, 20.69572049694522, 21.0, 0.0, 68.2376101004262], 
processed observation next is [0.0, 0.21739130434782608, 0.2692307692307692, 0.48, 0.21363636363636365, 0.041666666666666664, 0.0, 0.0, 0.5430555555555556, 0.2359218746145441, 0.7142857142857143, 0.3851029281350315, 0.42857142857142855, 0.0, 0.8027954129461905], 
reward next is -0.7660. 
=============================================
[2017-11-02 10:42:08,431] A3C_AGENT_WORKER-Thread-7 INFO:Local step 16500, global step 265252: loss -38.5576
[2017-11-02 10:42:08,721] A3C_AGENT_WORKER-Thread-14 INFO:Local step 16500, global step 265349: loss 0.0344
[2017-11-02 10:42:09,650] A3C_AGENT_WORKER-Thread-15 INFO:Local step 16500, global step 265630: loss -113.5760
[2017-11-02 10:42:11,183] A3C_AGENT_WORKER-Thread-11 INFO:Local step 16500, global step 266142: loss -118.6126
[2017-11-02 10:42:12,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99983191e-01   3.38678865e-06   5.30739408e-06   3.23120321e-06
   4.73708951e-06   2.47357853e-13   4.54530456e-13   1.83652518e-13
   2.08791213e-11], sum to 1.0000
[2017-11-02 10:42:12,187] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.833333333333333, 63.41666666666666, 0.0, 0.0, 0.0, 0.0, -7.666666666666667, 25.52712664126232, 18.0, 20.08602226956767, 21.0, 0.0, 0.0], 
actual action is [-7.833333333333333, 18], 
sim time next is 5036400.0000, 
raw observation next is [-3.0, 65.0, 0.0, 0.0, 0.0, 0.0, -7.833333333333333, 27.55576059669545, 18.0, 20.05132064492007, 21.0, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.2564102564102564, 0.65, 0.0, 0.0, 0.0, 0.0, 0.36944444444444446, 0.2755576059669545, 0.0, 0.2930458064171531, 0.42857142857142855, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:14,626] A3C_AGENT_WORKER-Thread-16 INFO:Local step 17000, global step 267396: loss 21.6701
[2017-11-02 10:42:15,959] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-46.83808136]
 [-46.53705978]
 [-46.94546509]
 [-46.70332336]
 [-46.15302658]], R is [[-46.39778137]
 [-46.93380356]
 [-47.46446609]
 [-47.98982239]
 [-48.50992584]].
[2017-11-02 10:42:16,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   4.91709659e-11   1.70683936e-11   3.47866597e-11
   4.12157392e-11   1.01896756e-25   1.22230176e-25   4.98062154e-26
   8.79773180e-26], sum to 1.0000
[2017-11-02 10:42:16,323] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99985933e-01   3.28921556e-06   3.18150501e-06   2.97600536e-06
   4.47351613e-06   9.90267313e-10   6.43259224e-10   1.82433457e-10
   9.03438879e-10], sum to 1.0000
[2017-11-02 10:42:16,326] A3C_AGENT_WORKER-Thread-9 INFO:Local step 16500, global step 268074: loss 5.9250
[2017-11-02 10:42:16,336] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 40.0, 1.5, 360.0, 0.0, 0.0, -4.0, 20.33333295934334, 18.0, 21.27841569391629, 21.0, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 5018700.0000, 
raw observation next is [0.8333333333333333, 41.25, 1.5, 357.5, 0.0, 0.0, -4.0, 21.73025350889932, 18.0, 21.16726086928023, 21.0, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.3547008547008547, 0.4125, 0.13636363636363635, 0.9930555555555556, 0.0, 0.0, 0.43333333333333335, 0.2173025350889932, 0.0, 0.4524658384686044, 0.42857142857142855, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:42:16,337] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.75, 24.25, 2.85, 32.5, 121.5, 863.75, 1.666666666666666, 14.81289097982695, 18.0, 22.82094486542907, 22.2, 1.0, 0.0], 
actual action is [1.75, 18], 
sim time next is 4971000.0000, 
raw observation next is [6.833333333333334, 24.16666666666666, 2.933333333333334, 31.66666666666666, 121.0, 863.3333333333334, 1.75, 14.80053363459749, 18.0, 22.80281204802021, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.5085470085470086, 0.2416666666666666, 0.2666666666666667, 0.08796296296296295, 0.3201058201058201, 0.8633333333333334, 0.5291666666666667, 0.1480053363459749, 0.0, 0.6861160068600302, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0148. 
=============================================
[2017-11-02 10:42:17,829] A3C_AGENT_WORKER-Thread-6 INFO:Local step 17000, global step 268679: loss 6.9999
[2017-11-02 10:42:18,508] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   7.89598508e-12   4.74044502e-12   1.00113563e-11
   7.52222503e-12   1.63360839e-30   8.44378319e-30   1.34725984e-30
   4.34171453e-30], sum to 1.0000
[2017-11-02 10:42:18,528] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.1666666666666666, 35.25, 4.016666666666666, 64.16666666666666, 106.75, 703.9166666666667, -5.333333333333333, 20.97644745617905, 18.0, 21.78024575689199, 22.2, 1.0, 0.0], 
actual action is [-5.166666666666667, 18], 
sim time next is 4959000.0000, 
raw observation next is [0.0, 34.5, 4.1, 65.0, 108.0, 717.0, -5.166666666666667, 20.78322295291042, 18.0, 21.82176944232372, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.391304347826087, 0.3333333333333333, 0.345, 0.3727272727272727, 0.18055555555555555, 0.2857142857142857, 0.717, 0.41388888888888886, 0.2078322295291042, 0.0, 0.5459670631891029, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:20,082] A3C_AGENT_WORKER-Thread-10 INFO:Local step 17000, global step 269592: loss 37.1041
[2017-11-02 10:42:20,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 17000, global step 269661: loss 3.3468
[2017-11-02 10:42:21,554] A3C_AGENT_WORKER-Thread-8 INFO:Local step 17000, global step 270176: loss 4.0015
[2017-11-02 10:42:23,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-58.3647728 ]
 [-57.20541382]
 [-59.23365021]
 [-55.32365417]
 [-60.60853577]], R is [[-55.77090836]
 [-56.21319962]
 [-56.65106964]
 [-57.08456039]
 [-57.51371384]].
[2017-11-02 10:42:24,220] A3C_AGENT_WORKER-Thread-13 INFO:Local step 17000, global step 271314: loss 4.9201
[2017-11-02 10:42:24,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.03770472
  0.1297837   0.09223849  0.74027306], sum to 1.0000
[2017-11-02 10:42:24,685] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.0, 65.0, 1.5, 350.0, 78.0, 317.0, -7.083333333333333, 21.80442095233744, 18.0, 21.21903587020166, 22.2, 1.0, 0.0], 
actual action is [3.0, 23.0], 
sim time next is 5040300.0000, 
raw observation next is [-1.75, 63.49999999999999, 1.375, 320.8333333333333, 81.16666666666667, 353.0, 3.0, 17.77610631373075, 23.0, 21.28196056746762, 22.2, 1.0, 85.38840933340549], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.28846153846153844, 0.6349999999999999, 0.125, 0.8912037037037036, 0.21472663139329806, 0.353, 0.55, 0.1777610631373075, 0.7142857142857143, 0.4688515096382316, 0.5999999999999999, 1.0, 1.0045695215694763], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:24,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   2.90989732e-10   4.69765754e-11   1.33831973e-10
   2.37317777e-10   4.83420118e-19   1.23645469e-18   4.89208056e-19
   3.15471150e-19], sum to 1.0000
[2017-11-02 10:42:24,772] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.833333333333332, 25.16666666666667, 1.25, 175.0, 122.0, 863.3333333333334, 3.75, 11.98149838635897, 18.0, 23.16142368661448, 22.2, 1.0, 0.0], 
actual action is [3.833333333333332, 18], 
sim time next is 5057700.0000, 
raw observation next is [8.916666666666668, 25.08333333333333, 1.375, 192.5, 121.5, 862.9166666666667, 3.833333333333332, 11.95053578517352, 18.0, 23.14480616757162, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.561965811965812, 0.2508333333333333, 0.125, 0.5347222222222222, 0.32142857142857145, 0.8629166666666668, 0.5638888888888888, 0.11950535785173519, 0.0, 0.7349723096530886, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0120. 
=============================================
[2017-11-02 10:42:25,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   3.53116003e-09   7.41256390e-10   1.86938509e-09
   3.02645087e-09   7.73606837e-17   2.52651585e-16   7.77156236e-17
   5.08475268e-17], sum to 1.0000
[2017-11-02 10:42:25,100] A3C_AGENT_WORKER-Thread-4 INFO:Local step 17000, global step 271705: loss 3.1679
[2017-11-02 10:42:25,106] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 17.83333333333334, 2.683333333333334, 251.6666666666667, 72.66666666666666, 560.5833333333334, 7.0, 7.705069459904957, 18.0, 25.12947289395769, 22.2, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5071200.0000, 
raw observation next is [12.0, 17.66666666666666, 2.766666666666667, 253.3333333333333, 69.33333333333333, 536.1666666666666, 7.0, 7.694031148837698, 18.0, 25.1272999475104, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.6410256410256411, 0.1766666666666666, 0.2515151515151515, 0.7037037037037036, 0.18342151675485008, 0.5361666666666667, 0.6166666666666667, 0.07694031148837698, 0.0, 1.0181857067872002, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0077. 
=============================================
[2017-11-02 10:42:25,969] A3C_AGENT_WORKER-Thread-17 INFO:Local step 17000, global step 272145: loss 11.6508
[2017-11-02 10:42:26,426] A3C_AGENT_WORKER-Thread-5 INFO:Local step 17000, global step 272383: loss 10.7263
[2017-11-02 10:42:27,344] A3C_AGENT_WORKER-Thread-2 INFO:Local step 17000, global step 272830: loss 12.3311
[2017-11-02 10:42:27,751] A3C_AGENT_WORKER-Thread-12 INFO:Local step 17000, global step 273026: loss 4.0067
[2017-11-02 10:42:28,541] A3C_AGENT_WORKER-Thread-14 INFO:Local step 17000, global step 273424: loss 6.1754
[2017-11-02 10:42:28,656] A3C_AGENT_WORKER-Thread-7 INFO:Local step 17000, global step 273477: loss 46.9661
[2017-11-02 10:42:29,791] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   2.51074254e-14   2.58696601e-14   6.44632798e-14
   8.34369601e-14   1.81887943e-23   2.70541204e-23   1.59038648e-24
   7.01561534e-24], sum to 1.0000
[2017-11-02 10:42:29,800] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.0, 40.0, 4.1, 175.0, 0.0, 0.0, 4.833333333333332, 28.93491460701209, 18.0, 20.16554347038843, 19.4, 0.0, 0.0], 
actual action is [5.0, 18], 
sim time next is 5121300.0000, 
raw observation next is [10.16666666666667, 39.83333333333333, 4.1, 175.8333333333333, 0.0, 0.0, 5.0, 29.04081257558595, 18.0, 20.15123015081072, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.5940170940170941, 0.39833333333333326, 0.3727272727272727, 0.4884259259259258, 0.0, 0.0, 0.5833333333333334, 0.2904081257558595, 0.0, 0.30731859297295977, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:42:31,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 17000, global step 274656: loss 6.8181
[2017-11-02 10:42:32,382] A3C_AGENT_WORKER-Thread-11 INFO:Local step 17000, global step 275295: loss 2.9481
[2017-11-02 10:42:32,492] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.06920554e-16   8.04890411e-17   3.68808230e-16
   2.97814455e-16   6.04193076e-33   6.54423684e-32   6.46426604e-33
   2.33313471e-32], sum to 1.0000
[2017-11-02 10:42:32,506] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 70.5, 6.991666666666666, 288.3333333333333, 104.25, 0.0, -3.0, 21.87713676937356, 18.0, 21.41359341529395, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5225400.0000, 
raw observation next is [2.0, 70.0, 6.95, 290.0, 105.0, 0.0, -3.0, 22.36244001342981, 18.0, 21.43145629952613, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.38461538461538464, 0.7, 0.6318181818181818, 0.8055555555555556, 0.2777777777777778, 0.0, 0.45, 0.2236244001342981, 0.0, 0.490208042789447, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:33,640] A3C_AGENT_WORKER-Thread-16 INFO:Local step 17500, global step 275953: loss 24.5980
[2017-11-02 10:42:35,116] A3C_AGENT_WORKER-Thread-6 INFO:Local step 17500, global step 276639: loss 21.0175
[2017-11-02 10:42:35,452] A3C_AGENT_WORKER-Thread-9 INFO:Local step 17000, global step 276810: loss 10.8200
[2017-11-02 10:42:37,879] A3C_AGENT_WORKER-Thread-10 INFO:Local step 17500, global step 277892: loss 7.8097
[2017-11-02 10:42:37,923] A3C_AGENT_WORKER-Thread-3 INFO:Local step 17500, global step 277911: loss 5.5195
[2017-11-02 10:42:38,427] A3C_AGENT_WORKER-Thread-8 INFO:Local step 17500, global step 278225: loss 5.8399
[2017-11-02 10:42:39,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   3.99103862e-24   8.49943036e-23   4.47069121e-23
   1.20224248e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:39,100] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 79.16666666666666, 6.516666666666667, 320.0, 0.0, 0.0, -5.0, 48.67874047838885, 18.0, 18.57720788832951, 22.2, 1.0, 0.0], 
actual action is [-5.0, 18], 
sim time next is 5259300.0000, 
raw observation next is [0.0, 78.58333333333334, 6.608333333333333, 320.0, 0.0, 0.0, -5.0, 49.17126319654234, 18.0, 18.52603813278372, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.3333333333333333, 0.7858333333333334, 0.6007575757575757, 0.8888888888888888, 0.0, 0.0, 0.4166666666666667, 0.4917126319654234, 0.0, 0.0751483046833888, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:40,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 17500, global step 279398: loss 12.3049
[2017-11-02 10:42:40,950] A3C_AGENT_WORKER-Thread-4 INFO:Local step 17500, global step 279443: loss 10.2652
[2017-11-02 10:42:42,120] A3C_AGENT_WORKER-Thread-17 INFO:Local step 17500, global step 279858: loss 57.3684
[2017-11-02 10:42:42,654] A3C_AGENT_WORKER-Thread-5 INFO:Local step 17500, global step 280033: loss -29.5691
[2017-11-02 10:42:42,898] A3C_AGENT_WORKER-Thread-2 INFO:Local step 17500, global step 280120: loss -11.2803
[2017-11-02 10:42:44,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 17500, global step 280831: loss -57.3898
[2017-11-02 10:42:45,596] A3C_AGENT_WORKER-Thread-7 INFO:Local step 17500, global step 281027: loss 71.5376
[2017-11-02 10:42:46,587] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   6.55508369e-16   1.21690185e-15   1.98489487e-15
   1.84753005e-15   2.14526305e-33   3.40880960e-32   2.46940066e-32
   1.21629788e-31], sum to 1.0000
[2017-11-02 10:42:46,605] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.666666666666667, 32.66666666666667, 3.6, 315.0, 57.33333333333333, 407.3333333333333, 2.833333333333333, 15.40269030145219, 18.0, 22.97200599548598, 22.2, 1.0, 0.0], 
actual action is [2.666666666666667, 18], 
sim time next is 5332500.0000, 
raw observation next is [7.5, 33.0, 3.6, 312.5, 53.75, 385.5, 2.666666666666667, 15.87406643522186, 18.0, 22.90975649946934, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.5256410256410257, 0.33, 0.32727272727272727, 0.8680555555555556, 0.1421957671957672, 0.3855, 0.5444444444444444, 0.1587406643522186, 0.0, 0.701393785638477, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:46,700] A3C_AGENT_WORKER-Thread-14 INFO:Local step 17500, global step 281410: loss 6.3167
[2017-11-02 10:42:46,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-94.90412903]
 [-97.07363129]
 [-93.92081451]
 [-93.9551239 ]
 [-95.07939911]], R is [[-95.04515839]
 [-95.0947113 ]
 [-95.14376831]
 [-95.19232941]
 [-95.24040985]].
[2017-11-02 10:42:47,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.82728910e-22   4.06536976e-21   1.83610024e-21
   5.21080690e-21   1.35149590e-38   1.44998294e-37   1.30043510e-38
   5.66260288e-36], sum to 1.0000
[2017-11-02 10:42:47,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.75, 69.75, 4.35, 322.5, 0.0, 0.0, -6.666666666666667, 61.22117149790597, 18.0, 17.59469464430443, 19.4, 0.0, 0.0], 
actual action is [-6.75, 18], 
sim time next is 5280600.0000, 
raw observation next is [-1.833333333333333, 70.16666666666667, 4.266666666666667, 321.6666666666667, 0.0, 0.0, -6.75, 62.04393842396089, 18.0, 17.50713429602139, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.28632478632478636, 0.7016666666666667, 0.3878787878787879, 0.8935185185185186, 0.0, 0.0, 0.3875, 0.6204393842396089, 0.0, -0.0704093862826584, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:47,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-105.73895264]
 [-105.82648468]
 [-102.43011475]
 [-102.39738464]
 [-102.82751465]], R is [[-107.33450317]
 [-107.2611618 ]
 [-107.18855286]
 [-107.1166687 ]
 [-107.04550171]].
[2017-11-02 10:42:47,980] A3C_AGENT_WORKER-Thread-15 INFO:Local step 17500, global step 281953: loss 31.3729
[2017-11-02 10:42:49,107] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-93.67996216]
 [-92.72927094]
 [-95.04138184]
 [-94.01973724]
 [-92.01680756]], R is [[-91.80930328]
 [-91.89121246]
 [-91.97229767]
 [-92.05257416]
 [-92.13204956]].
[2017-11-02 10:42:49,870] A3C_AGENT_WORKER-Thread-11 INFO:Local step 17500, global step 282722: loss 3.3868
[2017-11-02 10:42:50,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   9.93427599e-28   1.98255209e-27   4.59552538e-27
   4.03208995e-27   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:50,644] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.25, 73.5, 3.85, 337.5, 213.25, 377.0, -5.333333333333333, 34.86748080481158, 18.0, 20.37044141987571, 22.2, 1.0, 0.0], 
actual action is [-5.25, 18], 
sim time next is 5305800.0000, 
raw observation next is [-0.1666666666666666, 73.0, 3.766666666666667, 338.3333333333334, 211.6666666666667, 408.0, -5.25, 35.11415422686532, 18.0, 20.38583025901663, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.32905982905982906, 0.73, 0.34242424242424246, 0.9398148148148151, 0.5599647266313934, 0.408, 0.4125, 0.3511415422686532, 0.0, 0.3408328941452327, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:51,537] A3C_AGENT_WORKER-Thread-9 INFO:Local step 17500, global step 283402: loss 4.3218
[2017-11-02 10:42:53,742] A3C_AGENT_WORKER-Thread-16 INFO:Local step 18000, global step 284360: loss 4.6015
[2017-11-02 10:42:54,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   2.68434761e-31   3.33034171e-31   8.38782270e-31
   8.03994784e-31   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:54,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.33333333333333, 29.33333333333333, 3.433333333333334, 240.0, 138.0, 819.1666666666666, 5.16666666666667, 39.26644909468003, 18.0, 19.91704806977517, 20.56, 1.0, 0.0], 
actual action is [5.33333333333333, 18], 
sim time next is 5406300.0000, 
raw observation next is [10.5, 29.0, 3.475, 240.0, 137.0, 816.25, 5.33333333333333, 38.85958416929172, 18.0, 19.95254843424566, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.6025641025641025, 0.29, 0.3159090909090909, 0.6666666666666666, 0.36243386243386244, 0.81625, 0.5888888888888888, 0.3885958416929172, 0.0, 0.27893549060652284, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:54,525] A3C_AGENT_WORKER-Thread-6 INFO:Local step 18000, global step 284668: loss 6.1618
[2017-11-02 10:42:55,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   9.59975012e-24   3.84598721e-23   7.01751918e-23
   3.99968225e-23   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:42:55,637] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.66666666666667, 30.66666666666667, 4.433333333333334, 270.0, 60.0, 304.3333333333333, 5.75, 28.38801997038327, 18.0, 21.20155937442999, 20.56, 1.0, 0.0], 
actual action is [5.66666666666667, 18], 
sim time next is 5419500.0000, 
raw observation next is [10.58333333333333, 30.58333333333333, 4.391666666666666, 270.0, 53.5, 297.6666666666667, 5.66666666666667, 28.5427675535633, 18.0, 21.17694421441969, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.7391304347826086, 0.6047008547008546, 0.3058333333333333, 0.3992424242424242, 0.75, 0.14153439153439154, 0.2976666666666667, 0.5944444444444446, 0.28542767553563303, 0.0, 0.4538491734885274, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:42:57,424] A3C_AGENT_WORKER-Thread-10 INFO:Local step 18000, global step 285880: loss 6.9096
[2017-11-02 10:42:58,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 18000, global step 286201: loss 7.0160
[2017-11-02 10:42:59,196] A3C_AGENT_WORKER-Thread-8 INFO:Local step 18000, global step 286634: loss 5.7799
[2017-11-02 10:43:01,835] A3C_AGENT_WORKER-Thread-4 INFO:Local step 18000, global step 287694: loss -16.1597
[2017-11-02 10:43:02,072] A3C_AGENT_WORKER-Thread-13 INFO:Local step 18000, global step 287789: loss 7.0729
[2017-11-02 10:43:04,023] A3C_AGENT_WORKER-Thread-17 INFO:Local step 18000, global step 288561: loss 1.3799
[2017-11-02 10:43:04,036] A3C_AGENT_WORKER-Thread-5 INFO:Local step 18000, global step 288562: loss 1.2719
[2017-11-02 10:43:04,587] A3C_AGENT_WORKER-Thread-2 INFO:Local step 18000, global step 288829: loss 1.3297
[2017-11-02 10:43:05,121] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-89.83005524]
 [-91.86005402]
 [-92.42162323]
 [-90.41402435]
 [-89.54827118]], R is [[-90.10388947]
 [-90.20285034]
 [-90.3008194 ]
 [-90.39781189]
 [-90.49383545]].
[2017-11-02 10:43:06,633] A3C_AGENT_WORKER-Thread-12 INFO:Local step 18000, global step 289758: loss 1.0079
[2017-11-02 10:43:06,958] A3C_AGENT_WORKER-Thread-7 INFO:Local step 18000, global step 289919: loss 3.9015
[2017-11-02 10:43:07,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   7.63559927e-23   2.84650878e-22   4.43223204e-22
   3.11029099e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,181] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.66666666666667, 40.0, 4.433333333333334, 316.6666666666666, 142.1666666666667, 834.3333333333334, 7.58333333333333, 28.6585392453169, 18.0, 21.22115449483727, 20.56, 1.0, 0.0], 
actual action is [7.66666666666667, 18], 
sim time next is 5489100.0000, 
raw observation next is [12.75, 39.5, 4.35, 317.5, 141.75, 834.0, 7.66666666666667, 28.5132771717114, 18.0, 21.23485050001734, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6602564102564102, 0.395, 0.39545454545454545, 0.8819444444444444, 0.375, 0.834, 0.6277777777777779, 0.285132771717114, 0.0, 0.4621215000024773, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,503] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.46903758e-26   7.53314093e-26   9.80709351e-26
   4.27291132e-26   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,514] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.583333333333333, 58.75, 4.391666666666666, 284.1666666666666, 0.0, 0.0, 0.6666666666666661, 50.48903940143433, 18.0, 18.91327869325331, 20.56, 1.0, 0.0], 
actual action is [0.583333333333333, 18], 
sim time next is 5455800.0000, 
raw observation next is [5.5, 59.5, 4.35, 285.0, 0.0, 0.0, 0.583333333333333, 50.65994208653741, 18.0, 18.89351862302565, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.47435897435897434, 0.595, 0.39545454545454545, 0.7916666666666666, 0.0, 0.0, 0.5097222222222222, 0.5065994208653741, 0.0, 0.12764551757509274, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,517] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   1.30328902e-18   2.19655661e-17   1.13872421e-17
   7.69841197e-18   7.68004642e-34   1.64132017e-33   3.69506134e-34
   1.82131588e-31], sum to 1.0000
[2017-11-02 10:43:07,523] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.5, 59.5, 4.35, 285.0, 0.0, 0.0, 0.583333333333333, 50.65994208653741, 18.0, 18.89351862302565, 20.56, 1.0, 0.0], 
actual action is [0.5, 18], 
sim time next is 5456100.0000, 
raw observation next is [5.416666666666667, 60.25, 4.308333333333333, 285.8333333333334, 0.0, 0.0, 0.5, 50.86051622120635, 18.0, 18.87315088594841, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.13043478260869565, 0.47222222222222227, 0.6025, 0.3916666666666666, 0.7939814814814817, 0.0, 0.0, 0.5083333333333333, 0.5086051622120635, 0.0, 0.12473584084977267, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:07,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   9.21184811e-28   7.50036238e-27   9.04385117e-27
   4.29030400e-27   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:07,577] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 55.0, 1.091666666666667, 327.5, 0.0, 0.0, -6.0, 59.93994309355896, 18.0, 17.71948387166684, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 5369400.0000, 
raw observation next is [-1.0, 55.0, 1.15, 325.0, 0.0, 0.0, -6.0, 61.02411194457157, 18.0, 17.62757369689492, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.3076923076923077, 0.55, 0.10454545454545454, 0.9027777777777778, 0.0, 0.0, 0.4, 0.6102411194457157, 0.0, -0.05320375758643995, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:08,830] A3C_AGENT_WORKER-Thread-14 INFO:Local step 18000, global step 290848: loss 1.9727
[2017-11-02 10:43:08,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 18000, global step 290861: loss 22.7264
[2017-11-02 10:43:09,298] A3C_AGENT_WORKER-Thread-16 INFO:Local step 18500, global step 291098: loss 8.8417
[2017-11-02 10:43:09,804] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   2.82807733e-14   7.61233795e-14   1.21681948e-13
   6.34677383e-14   2.21063159e-29   4.71833968e-29   4.30489037e-29
   2.33759386e-28], sum to 1.0000
[2017-11-02 10:43:09,815] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 37.0, 4.6, 330.0, 22.5, 164.0, 7.08333333333333, 23.59827766399136, 18.0, 21.1870534581019, 19.4, 0.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5508300.0000, 
raw observation next is [11.91666666666667, 37.16666666666666, 4.558333333333333, 330.8333333333333, 18.75, 136.6666666666667, 7.0, 24.00962413074539, 18.0, 21.13599280565469, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.782608695652174, 0.6388888888888891, 0.3716666666666666, 0.4143939393939393, 0.9189814814814814, 0.0496031746031746, 0.13666666666666671, 0.6166666666666667, 0.2400962413074539, 0.0, 0.44799897223638446, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:10,953] A3C_AGENT_WORKER-Thread-6 INFO:Local step 18500, global step 291823: loss 4.0716
[2017-11-02 10:43:11,633] A3C_AGENT_WORKER-Thread-11 INFO:Local step 18000, global step 292148: loss 4.5346
[2017-11-02 10:43:12,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   3.99382764e-23   2.12038693e-22   4.47736700e-22
   1.47945574e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:12,404] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.416666666666667, 66.33333333333334, 0.625, 99.99999999999999, 0.0, 0.0, -1.5, 46.33107177889953, 18.0, 18.77586655196176, 19.4, 0.0, 0.0], 
actual action is [-1.583333333333333, 18], 
sim time next is 5542800.0000, 
raw observation next is [3.333333333333333, 66.66666666666666, 0.5, 80.00000000000001, 0.0, 0.0, -1.583333333333333, 46.61574599844152, 18.0, 18.747240228015, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.13043478260869565, 0.41880341880341876, 0.6666666666666665, 0.045454545454545456, 0.22222222222222227, 0.0, 0.0, 0.47361111111111115, 0.46615745998441516, 0.0, 0.10674860400214266, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0933. 
=============================================
[2017-11-02 10:43:12,769] A3C_AGENT_WORKER-Thread-9 INFO:Local step 18000, global step 292730: loss 1.2422
[2017-11-02 10:43:12,960] A3C_AGENT_WORKER-Thread-10 INFO:Local step 18500, global step 292836: loss -1.8183
[2017-11-02 10:43:13,826] A3C_AGENT_WORKER-Thread-3 INFO:Local step 18500, global step 293285: loss 135.5925
[2017-11-02 10:43:14,428] A3C_AGENT_WORKER-Thread-8 INFO:Local step 18500, global step 293604: loss 2.3302
[2017-11-02 10:43:14,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   1.42893879e-18   1.01595977e-17   1.27827190e-17
   4.22817713e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:14,948] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.5, 31.0, 3.85, 270.0, 0.0, 0.0, 4.583333333333332, 29.5975513282859, 18.0, 21.37879435054493, 20.56, 1.0, 0.0], 
actual action is [4.5, 18], 
sim time next is 5423700.0000, 
raw observation next is [9.416666666666666, 31.16666666666666, 3.808333333333333, 270.0, 0.0, 0.0, 4.5, 30.02913793209569, 18.0, 21.32024368782974, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.782608695652174, 0.5747863247863247, 0.3116666666666666, 0.3462121212121212, 0.75, 0.0, 0.0, 0.575, 0.3002913793209569, 0.0, 0.47432052683282017, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:16,173] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   2.51092888e-18   2.34637110e-17   2.81527480e-17
   7.71299186e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:16,196] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.916666666666667, 64.33333333333333, 3.1, 350.0, 0.0, 0.0, -1.0, 40.20820913519096, 18.0, 19.51071547653932, 20.56, 1.0, 0.0], 
actual action is [-1.083333333333333, 18], 
sim time next is 5533800.0000, 
raw observation next is [3.833333333333333, 64.66666666666667, 3.1, 350.0, 0.0, 0.0, -1.083333333333333, 40.50097857387089, 18.0, 19.47711785614235, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.4316239316239316, 0.6466666666666667, 0.2818181818181818, 0.9722222222222222, 0.0, 0.0, 0.48194444444444445, 0.4050097857387089, 0.0, 0.21101683659176423, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:17,123] A3C_AGENT_WORKER-Thread-4 INFO:Local step 18500, global step 295044: loss 9.3694
[2017-11-02 10:43:17,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-90.01504517]
 [-89.34649658]
 [-89.15139771]
 [-88.42768097]
 [-89.51269531]], R is [[-89.67198181]
 [-89.77526093]
 [-89.87751007]
 [-89.97873688]
 [-90.07894897]].
[2017-11-02 10:43:17,893] A3C_AGENT_WORKER-Thread-13 INFO:Local step 18500, global step 295473: loss 13.0244
[2017-11-02 10:43:18,494] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   7.93250127e-23   4.14797024e-22   4.84355244e-22
   1.58548142e-22   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:18,508] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.583333333333333, 71.08333333333333, 3.808333333333333, 170.0, 0.0, 0.0, -1.333333333333333, 41.45021958414252, 18.0, 18.64953474316433, 22.2, 1.0, 0.0], 
actual action is [-1.416666666666667, 18], 
sim time next is 5639400.0000, 
raw observation next is [3.5, 71.5, 3.85, 170.0, 0.0, 0.0, -1.416666666666667, 41.72353886354691, 18.0, 18.62713155605537, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.4230769230769231, 0.715, 0.35000000000000003, 0.4722222222222222, 0.0, 0.0, 0.47638888888888886, 0.41723538863546916, 0.0, 0.08959022229362443, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:19,012] A3C_AGENT_WORKER-Thread-5 INFO:Local step 18500, global step 296109: loss 5.2403
[2017-11-02 10:43:19,338] A3C_AGENT_WORKER-Thread-17 INFO:Local step 18500, global step 296292: loss 10.5591
[2017-11-02 10:43:19,506] A3C_AGENT_WORKER-Thread-2 INFO:Local step 18500, global step 296389: loss 1.9044
[2017-11-02 10:43:20,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   3.37868758e-15   2.34298478e-14   2.63244016e-14
   7.36555710e-15   1.79305992e-37   2.63641907e-37   4.31302538e-37
   1.59750828e-37], sum to 1.0000
[2017-11-02 10:43:20,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 50.33333333333334, 2.6, 157.5, 0.0, 0.0, 3.0, 23.34013093039983, 18.0, 20.48150977678855, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5614800.0000, 
raw observation next is [8.0, 50.66666666666666, 2.6, 160.0, 0.0, 0.0, 3.0, 23.55781735919475, 18.0, 20.45037864342168, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5384615384615384, 0.5066666666666666, 0.23636363636363636, 0.4444444444444444, 0.0, 0.0, 0.55, 0.2355781735919475, 0.0, 0.35005409191738274, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:21,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.03359090e-15   1.05703325e-14   1.04344396e-14
   2.49022393e-15   3.15296370e-36   2.03334694e-36   1.29574762e-35
   7.16781931e-36], sum to 1.0000
[2017-11-02 10:43:21,035] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.5, 58.0, 2.975, 162.5, 0.0, 0.0, 1.666666666666667, 25.68857551710643, 18.0, 20.14497116207397, 22.2, 1.0, 0.0], 
actual action is [1.5, 18], 
sim time next is 5619000.0000, 
raw observation next is [6.333333333333333, 58.66666666666666, 3.016666666666667, 161.6666666666667, 0.0, 0.0, 1.5, 25.92196792222624, 18.0, 20.1156380042813, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.4957264957264957, 0.5866666666666666, 0.2742424242424243, 0.4490740740740742, 0.0, 0.0, 0.525, 0.2592196792222624, 0.0, 0.3022340006116145, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:21,332] A3C_AGENT_WORKER-Thread-7 INFO:Local step 18500, global step 297375: loss -51.1337
[2017-11-02 10:43:21,674] A3C_AGENT_WORKER-Thread-12 INFO:Local step 18500, global step 297567: loss 8.9389
[2017-11-02 10:43:22,449] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   7.78773259e-18   4.27135025e-17   7.82988654e-17
   2.22217754e-17   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:22,474] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 73.0, 0.0, 0.0, 75.08333333333334, 230.8333333333333, -3.0, 49.41690020878165, 18.0, 18.30607765273188, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5557200.0000, 
raw observation next is [2.0, 73.0, 0.0, 0.0, 78.16666666666666, 261.6666666666667, -3.0, 49.91623660894226, 18.0, 18.30621289111858, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.38461538461538464, 0.73, 0.0, 0.0, 0.2067901234567901, 0.26166666666666666, 0.45, 0.49916236608942266, 0.0, 0.04374469873122574, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:23,665] A3C_AGENT_WORKER-Thread-14 INFO:Local step 18500, global step 298654: loss 1.8962
[2017-11-02 10:43:24,088] A3C_AGENT_WORKER-Thread-15 INFO:Local step 18500, global step 298888: loss 4.3348
[2017-11-02 10:43:24,542] A3C_AGENT_WORKER-Thread-16 INFO:Local step 19000, global step 299141: loss 27.7761
[2017-11-02 10:43:24,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   2.63505773e-10   1.36458622e-09   9.63099600e-10
   4.14021789e-10   4.10558375e-26   1.76460435e-26   4.99874193e-26
   7.76636643e-27], sum to 1.0000
[2017-11-02 10:43:24,831] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.0, 37.0, 2.1, 350.0, 0.0, 0.0, 7.16666666666667, 10.43330075023683, 18.0, 23.21577079395722, 22.2, 1.0, 0.0], 
actual action is [7.0, 18], 
sim time next is 5598300.0000, 
raw observation next is [12.0, 36.75, 2.1, 327.5, 0.0, 0.0, 7.0, 10.67845436213906, 18.0, 23.14276018815308, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.6410256410256411, 0.3675, 0.19090909090909092, 0.9097222222222222, 0.0, 0.0, 0.6166666666666667, 0.1067845436213906, 0.0, 0.7346800268790113, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0107. 
=============================================
[2017-11-02 10:43:25,148] A3C_AGENT_WORKER-Thread-6 INFO:Local step 19000, global step 299500: loss 8.6782
[2017-11-02 10:43:25,644] A3C_AGENT_WORKER-Thread-11 INFO:Local step 18500, global step 299792: loss 20.1701
[2017-11-02 10:43:26,210] A3C_AGENT_WORKER-Thread-9 INFO:Local step 18500, global step 300102: loss 15.5553
[2017-11-02 10:43:26,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-33.41356659]
 [-31.75720215]
 [-34.39923477]
 [-31.38718414]
 [-31.86919785]], R is [[-32.03498459]
 [-31.71463585]
 [-31.39748955]
 [-31.08351517]
 [-30.77268028]].
[2017-11-02 10:43:27,383] A3C_AGENT_WORKER-Thread-10 INFO:Local step 19000, global step 300748: loss 4.9754
[2017-11-02 10:43:27,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-36.76369858]
 [-38.74815369]
 [-38.30179977]
 [-37.74213409]
 [-38.22413254]], R is [[-38.91717148]
 [-38.52799988]
 [-38.14271927]
 [-37.7612915 ]
 [-37.38367844]].
[2017-11-02 10:43:28,916] A3C_AGENT_WORKER-Thread-3 INFO:Local step 19000, global step 301583: loss 2.2623
[2017-11-02 10:43:29,159] A3C_AGENT_WORKER-Thread-8 INFO:Local step 19000, global step 301715: loss 5.5815
[2017-11-02 10:43:30,469] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-29.63217926]
 [-32.07052231]
 [-29.93665886]
 [-29.02351761]
 [-34.2812233 ]], R is [[-29.93619537]
 [-29.64441299]
 [-29.35559082]
 [-29.0696888 ]
 [-28.78668213]].
[2017-11-02 10:43:31,840] A3C_AGENT_WORKER-Thread-4 INFO:Local step 19000, global step 303266: loss 2.5803
[2017-11-02 10:43:32,736] A3C_AGENT_WORKER-Thread-13 INFO:Local step 19000, global step 303779: loss 3.1461
[2017-11-02 10:43:33,196] A3C_AGENT_WORKER-Thread-2 INFO:Local step 19000, global step 304053: loss 1.7418
[2017-11-02 10:43:33,211] A3C_AGENT_WORKER-Thread-5 INFO:Local step 19000, global step 304053: loss 6.8971
[2017-11-02 10:43:34,006] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.96766925e-01   7.63620017e-04   5.94272453e-04   1.05754787e-03
   8.15453299e-04   1.18608193e-06   4.84558655e-07   4.58868982e-07
   6.07005575e-08], sum to 1.0000
[2017-11-02 10:43:34,049] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [24.08333333333333, 43.33333333333333, 5.149999999999999, 239.1666666666667, 139.0833333333333, 797.0833333333333, 19.0, 15.77603701499973, 18.0, 26.65075357633275, 19.4, 0.0, 0.0], 
actual action is [19.08333333333333, 18], 
sim time next is 5753400.0000, 
raw observation next is [24.16666666666666, 42.66666666666667, 5.2, 238.3333333333333, 137.6666666666667, 795.6666666666667, 19.08333333333333, 16.35628039903921, 18.0, 26.76090050589405, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.9529914529914527, 0.4266666666666667, 0.4727272727272727, 0.6620370370370369, 0.36419753086419765, 0.7956666666666667, 0.8180555555555554, 0.1635628039903921, 0.0, 1.2515572151277214, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:34,118] A3C_AGENT_WORKER-Thread-17 INFO:Local step 19000, global step 304593: loss 6.6027
[2017-11-02 10:43:36,484] A3C_AGENT_WORKER-Thread-12 INFO:Local step 19000, global step 305905: loss -1.1190
[2017-11-02 10:43:36,910] A3C_AGENT_WORKER-Thread-7 INFO:Local step 19000, global step 306140: loss -1.4944
[2017-11-02 10:43:38,163] A3C_AGENT_WORKER-Thread-14 INFO:Local step 19000, global step 306845: loss -0.1669
[2017-11-02 10:43:38,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99960661e-01   9.36229208e-06   8.86620364e-06   1.14180075e-05
   9.78722437e-06   5.98514023e-13   2.57135025e-13   3.01287180e-13
   3.75371324e-14], sum to 1.0000
[2017-11-02 10:43:38,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 19500, global step 306916: loss 24.4047
[2017-11-02 10:43:38,276] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [22.41666666666666, 35.41666666666666, 6.324999999999999, 230.0, 138.0, 772.8333333333333, 17.33333333333334, 6.734837153573365, 18.0, 25.30043138898715, 22.2, 1.0, 0.0], 
actual action is [17.41666666666666, 18], 
sim time next is 5668200.0000, 
raw observation next is [22.5, 35.5, 6.45, 230.0, 138.0, 767.0, 17.41666666666666, 6.785469239473829, 18.0, 25.37761761038848, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.9102564102564102, 0.355, 0.5863636363636364, 0.6388888888888888, 0.36507936507936506, 0.767, 0.7902777777777776, 0.06785469239473829, 0.0, 1.05394537291264, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0068. 
=============================================
[2017-11-02 10:43:38,421] A3C_AGENT_WORKER-Thread-6 INFO:Local step 19500, global step 306993: loss 15.0586
[2017-11-02 10:43:38,786] A3C_AGENT_WORKER-Thread-15 INFO:Local step 19000, global step 307201: loss -5.8405
[2017-11-02 10:43:39,291] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.46550485  0.0678421   0.19685392  0.11589962  0.05317903  0.02683856
  0.02235003  0.03542852  0.01610337], sum to 1.0000
[2017-11-02 10:43:39,314] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.0, 55.0, 5.016666666666667, 200.0, 0.0, 0.0, 22.0, 7.400507268503524, 20.0, 24.4382435089357, 19.4, 0.0, 39.31509248219977], 
actual action is [12.0, 18], 
sim time next is 5811300.0000, 
raw observation next is [17.0, 55.0, 4.975, 200.0, 0.0, 0.0, 12.0, 7.351779074859953, 18.0, 24.49695334668942, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.2608695652173913, 0.7692307692307693, 0.55, 0.4522727272727272, 0.5555555555555556, 0.0, 0.0, 0.7, 0.07351779074859953, 0.0, 0.9281361923842029, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:40,643] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-3.53125262]
 [-3.63840723]
 [-3.2014451 ]
 [-3.57755709]
 [-3.33466911]], R is [[-3.66966915]
 [-3.63297248]
 [-3.59664273]
 [-3.56067634]
 [-3.52506971]].
[2017-11-02 10:43:40,730] A3C_AGENT_WORKER-Thread-11 INFO:Local step 19000, global step 308308: loss 1.4757
[2017-11-02 10:43:41,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 19500, global step 308537: loss 17.3191
[2017-11-02 10:43:41,248] A3C_AGENT_WORKER-Thread-9 INFO:Local step 19000, global step 308602: loss -0.8031
[2017-11-02 10:43:42,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 19500, global step 309269: loss 41.0426
[2017-11-02 10:43:42,744] A3C_AGENT_WORKER-Thread-8 INFO:Local step 19500, global step 309503: loss 48.7446
[2017-11-02 10:43:43,782] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.98429716e-01   6.02838809e-05   1.03512837e-03   4.06278559e-04
   6.85392442e-05   2.05697767e-14   7.39850584e-15   1.12988596e-14
   2.71586715e-15], sum to 1.0000
[2017-11-02 10:43:43,812] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [22.08333333333333, 40.75, 3.558333333333333, 220.8333333333333, 0.0, 0.0, 17.16666666666667, 25.87387039032333, 18.0, 27.45247714890319, 19.4, 0.0, 0.0], 
actual action is [17.08333333333333, 18], 
sim time next is 5770800.0000, 
raw observation next is [22.0, 41.0, 3.6, 220.0, 0.0, 0.0, 17.08333333333333, 25.51043049891827, 18.0, 27.38693606057092, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.8974358974358975, 0.41, 0.32727272727272727, 0.6111111111111112, 0.0, 0.0, 0.7847222222222221, 0.25510430498918274, 0.0, 1.3409908657958458, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:44,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   9.93560269e-13   4.81052698e-11   2.44851847e-11
   9.88811246e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:43:44,207] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [23.0, 38.0, 3.1, 230.0, 24.5, 177.0, 18.16666666666667, 34.65459815178401, 18.0, 28.6150255044909, 22.2, 1.0, 0.0], 
actual action is [18.0, 18], 
sim time next is 5767500.0000, 
raw observation next is [22.91666666666666, 38.24999999999999, 3.141666666666667, 229.1666666666667, 20.41666666666666, 147.5, 18.0, 33.78163385018523, 18.0, 28.5389827324267, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.9209401709401707, 0.38249999999999995, 0.28560606060606064, 0.6365740740740742, 0.05401234567901233, 0.1475, 0.8, 0.3378163385018523, 0.0, 1.5055689617752428, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:45,089] A3C_AGENT_WORKER-Thread-4 INFO:Local step 19500, global step 310885: loss 3.7797
[2017-11-02 10:43:46,408] A3C_AGENT_WORKER-Thread-13 INFO:Local step 19500, global step 311685: loss 10.9276
[2017-11-02 10:43:46,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.26396084e-01   1.94467641e-02   1.55191138e-01   8.00667703e-02
   1.86426491e-02   9.62393533e-05   4.93748812e-05   8.79749277e-05
   2.30399801e-05], sum to 1.0000
[2017-11-02 10:43:46,534] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [17.5, 50.5, 4.35, 185.0, 0.0, 0.0, 12.58333333333333, 9.891866484810475, 18.0, 25.07056797439325, 22.2, 1.0, 0.0], 
actual action is [12.5, 18], 
sim time next is 5794500.0000, 
raw observation next is [17.41666666666667, 50.75, 4.308333333333333, 185.8333333333333, 0.0, 0.0, 12.5, 9.786948950409533, 18.0, 25.05016778524015, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.77991452991453, 0.5075, 0.3916666666666666, 0.5162037037037036, 0.0, 0.0, 0.7083333333333334, 0.09786948950409532, 0.0, 1.0071668264628784, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0098. 
=============================================
[2017-11-02 10:43:46,849] A3C_AGENT_WORKER-Thread-5 INFO:Local step 19500, global step 311968: loss 8.5061
[2017-11-02 10:43:47,691] A3C_AGENT_WORKER-Thread-2 INFO:Local step 19500, global step 312475: loss 5.9884
[2017-11-02 10:43:48,038] A3C_AGENT_WORKER-Thread-17 INFO:Local step 19500, global step 312672: loss 2.1797
[2017-11-02 10:43:50,301] A3C_AGENT_WORKER-Thread-7 INFO:Local step 19500, global step 314080: loss 36.1558
[2017-11-02 10:43:50,563] A3C_AGENT_WORKER-Thread-12 INFO:Local step 19500, global step 314239: loss 1.9275
[2017-11-02 10:43:51,440] A3C_AGENT_WORKER-Thread-14 INFO:Local step 19500, global step 314734: loss 2.0990
[2017-11-02 10:43:52,418] A3C_AGENT_WORKER-Thread-15 INFO:Local step 19500, global step 315266: loss 32.9408
[2017-11-02 10:43:53,083] A3C_AGENT_WORKER-Thread-6 INFO:Local step 20000, global step 315608: loss -313.3749
[2017-11-02 10:43:53,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.25822982  0.06652871  0.36361411  0.17358105  0.06414181  0.01958268
  0.01607675  0.0286018   0.00964334], sum to 1.0000
[2017-11-02 10:43:53,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.583333333333332, 68.91666666666666, 4.391666666666666, 298.3333333333334, 0.0, 0.0, 3.666666666666668, 5.242886947853994, 18.0, 22.53617793366424, 19.4, 0.0, 0.0], 
actual action is [3.583333333333332, 18], 
sim time next is 5880600.0000, 
raw observation next is [8.5, 68.5, 4.35, 300.0, 0.0, 0.0, 3.583333333333332, 5.257055923988847, 18.0, 22.51002308045716, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.043478260869565216, 0.5512820512820513, 0.685, 0.39545454545454545, 0.8333333333333334, 0.0, 0.0, 0.5597222222222221, 0.052570559239888466, 0.0, 0.64428901149388, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:53,656] A3C_AGENT_WORKER-Thread-16 INFO:Local step 20000, global step 315920: loss -19.0895
[2017-11-02 10:43:53,947] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-1.20235372]
 [-0.9604876 ]
 [-1.15086043]
 [-1.30399823]
 [-1.10359466]], R is [[-1.42167282]
 [-1.41841805]
 [-1.41536868]
 [-1.41253173]
 [-1.40991688]].
[2017-11-02 10:43:54,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.96363103e-01   8.86625261e-04   1.11958582e-03   8.66588962e-04
   7.63561053e-04   1.96532014e-07   1.43765050e-07   1.52247523e-07
   3.41933379e-08], sum to 1.0000
[2017-11-02 10:43:54,098] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 57.0, 4.183333333333334, 347.5, 128.1666666666667, 423.0, 3.0, 5.957573312809279, 18.0, 23.16221340119987, 19.4, 0.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 5935200.0000, 
raw observation next is [8.0, 57.0, 4.266666666666667, 350.0, 121.3333333333333, 416.0, 3.0, 5.94764980295469, 18.0, 23.1680053531277, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6956521739130435, 0.5384615384615384, 0.57, 0.3878787878787879, 0.9722222222222222, 0.3209876543209876, 0.416, 0.55, 0.059476498029546895, 0.0, 0.738286479018243, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:54,255] A3C_AGENT_WORKER-Thread-11 INFO:Local step 19500, global step 316208: loss 2.6638
[2017-11-02 10:43:54,479] A3C_AGENT_WORKER-Thread-9 INFO:Local step 19500, global step 316314: loss 1.0245
[2017-11-02 10:43:55,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.63380735e-07   2.96763801e-07   7.08278094e-06   3.97404983e-06
   1.94639620e-06   9.07906830e-01   3.29636969e-02   5.59329949e-02
   3.18279723e-03], sum to 1.0000
[2017-11-02 10:43:55,461] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [3.333333333333333, 100.0, 2.766666666666667, 353.3333333333334, 177.8333333333333, 0.0, -1.75, 46.34907891137051, 18.0, 18.77812352964702, 20.56, 1.0, 0.0], 
actual action is [8.333333333333332, 18.5], 
sim time next is 6009900.0000, 
raw observation next is [3.416666666666667, 100.0, 2.933333333333333, 354.1666666666666, 176.9166666666667, 0.0, 8.333333333333332, 41.32665673342515, 18.5, 18.7528790770214, 20.56, 1.0, 73.41086338029436], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.42094017094017094, 1.0, 0.26666666666666666, 0.9837962962962961, 0.4680335097001765, 0.0, 0.6388888888888888, 0.41326656733425154, 0.07142857142857142, 0.10755415386020013, 0.36571428571428555, 1.0, 0.8636572162387571], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:43:56,423] A3C_AGENT_WORKER-Thread-10 INFO:Local step 20000, global step 317255: loss 87.4977
[2017-11-02 10:43:56,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  6.97635114e-01   4.15180661e-02   1.34980902e-01   8.63553211e-02
   3.93325128e-02   6.79777586e-05   4.89989761e-05   4.68065446e-05
   1.42775862e-05], sum to 1.0000
[2017-11-02 10:43:56,458] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 64.0, 2.1, 316.6666666666667, 90.00000000000001, 0.0, 0.0, 12.27944982338872, 18.0, 20.5665766525945, 19.4, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 5904900.0000, 
raw observation next is [5.0, 64.0, 2.1, 315.0, 93.0, 0.0, 0.0, 11.96177051258663, 18.0, 20.64680283638245, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.46153846153846156, 0.64, 0.19090909090909092, 0.875, 0.24603174603174602, 0.0, 0.5, 0.11961770512586631, 0.0, 0.3781146909117784, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:57,959] A3C_AGENT_WORKER-Thread-3 INFO:Local step 20000, global step 317995: loss 11.4473
[2017-11-02 10:43:58,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.19901748  0.08707508  0.39650604  0.18688725  0.07087949  0.01582462
  0.01345666  0.02170283  0.00865054], sum to 1.0000
[2017-11-02 10:43:58,614] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [6.333333333333334, 62.0, 2.766666666666667, 326.6666666666667, 0.0, 0.0, 1.416666666666666, 7.125141222051801, 18.0, 21.60605022724224, 19.4, 0.0, 0.0], 
actual action is [1.333333333333334, 18], 
sim time next is 5892300.0000, 
raw observation next is [6.25, 61.5, 2.725, 330.0, 0.0, 0.0, 1.333333333333334, 7.232927452039942, 18.0, 21.5736645201882, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.4935897435897436, 0.615, 0.24772727272727274, 0.9166666666666666, 0.0, 0.0, 0.5222222222222223, 0.07232927452039942, 0.0, 0.5105235028840285, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:43:59,243] A3C_AGENT_WORKER-Thread-8 INFO:Local step 20000, global step 318559: loss 292.3623
[2017-11-02 10:44:01,486] A3C_AGENT_WORKER-Thread-4 INFO:Local step 20000, global step 319278: loss 1785.5681
[2017-11-02 10:44:04,036] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99924064e-01   1.14865138e-07   4.41991051e-06   7.03930273e-05
   9.25220377e-07   6.53744909e-18   5.10426620e-17   3.69784409e-17
   2.49180777e-18], sum to 1.0000
[2017-11-02 10:44:04,041] A3C_AGENT_WORKER-Thread-13 INFO:Local step 20000, global step 319979: loss -33.5396
[2017-11-02 10:44:04,061] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 86.0, 3.766666666666667, 246.6666666666667, 0.0, 0.0, -4.0, 31.080137465217, 18.0, 19.12881552411473, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 5978700.0000, 
raw observation next is [1.0, 86.0, 3.725, 275.0, 0.0, 0.0, -4.0, 32.71627668516479, 18.0, 18.96659404374463, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.358974358974359, 0.86, 0.3386363636363636, 0.7638888888888888, 0.0, 0.0, 0.43333333333333335, 0.3271627668516479, 0.0, 0.13808486339209022, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0619. 
=============================================
[2017-11-02 10:44:05,083] A3C_AGENT_WORKER-Thread-5 INFO:Local step 20000, global step 320265: loss -24.8212
[2017-11-02 10:44:06,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999166e-01   1.01126468e-10   1.60723115e-08   8.92970945e-07
   1.09293374e-09   3.90818995e-30   1.47299648e-28   1.21657769e-27
   1.15889201e-29], sum to 1.0000
[2017-11-02 10:44:06,251] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 80.0, 3.066666666666666, 14.16666666666667, 0.0, 0.0, -3.0, 24.12991640426555, 18.0, 19.1342178071912, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 5952600.0000, 
raw observation next is [2.0, 80.0, 3.0, 15.0, 0.0, 0.0, -3.0, 24.43586347082307, 18.0, 19.10395018635953, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9130434782608695, 0.38461538461538464, 0.8, 0.2727272727272727, 0.041666666666666664, 0.0, 0.0, 0.45, 0.2443586347082307, 0.0, 0.15770716947993282, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:06,638] A3C_AGENT_WORKER-Thread-2 INFO:Local step 20000, global step 320647: loss -54.3584
[2017-11-02 10:44:07,033] A3C_AGENT_WORKER-Thread-17 INFO:Local step 20000, global step 320757: loss 87.1473
[2017-11-02 10:44:08,464] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-90.34597778]
 [-85.7006073 ]
 [-87.05731201]
 [-85.13450623]
 [-85.66706848]], R is [[-89.9066391 ]
 [-90.00757599]
 [-90.10749817]
 [-90.2064209 ]
 [-90.30435944]].
[2017-11-02 10:44:09,716] A3C_AGENT_WORKER-Thread-7 INFO:Local step 20000, global step 321429: loss -37.2831
[2017-11-02 10:44:11,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 20000, global step 321796: loss -115.8394
[2017-11-02 10:44:12,340] A3C_AGENT_WORKER-Thread-12 INFO:Local step 20000, global step 322037: loss 54.6901
[2017-11-02 10:44:12,568] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-78.82019806]
 [-76.72580719]
 [-75.18088531]
 [-85.3200531 ]
 [-84.83330536]], R is [[-78.69782257]
 [-78.22932434]
 [-77.44702911]
 [-76.67256165]
 [-75.90583801]].
[2017-11-02 10:44:12,750] A3C_AGENT_WORKER-Thread-14 INFO:Local step 20000, global step 322133: loss 112.6670
[2017-11-02 10:44:13,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99915719e-01   4.24319140e-08   5.02904913e-06   7.87492318e-05
   4.82446524e-07   1.71654390e-16   1.63848211e-15   8.78915606e-15
   1.53719804e-16], sum to 1.0000
[2017-11-02 10:44:13,693] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.25, 100.0, 2.6, 352.5, 178.75, 0.0, -1.833333333333333, 29.06234032078585, 18.0, 20.2278169161327, 20.56, 1.0, 0.0], 
actual action is [-1.75, 18], 
sim time next is 6009600.0000, 
raw observation next is [3.333333333333333, 100.0, 2.766666666666667, 353.3333333333334, 177.8333333333333, 0.0, -1.75, 29.56552844260617, 18.0, 20.18381631009061, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5652173913043478, 0.41880341880341876, 1.0, 0.2515151515151515, 0.9814814814814817, 0.470458553791887, 0.0, 0.4708333333333333, 0.2956552844260617, 0.0, 0.31197375858437276, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:14,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 20000, global step 322788: loss 134.4304
[2017-11-02 10:44:14,999] A3C_AGENT_WORKER-Thread-9 INFO:Local step 20000, global step 322805: loss 115.8343
[2017-11-02 10:44:16,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   2.86943971e-12   5.97856209e-10   1.46179495e-08
   2.50146362e-11   2.84444121e-33   2.68256370e-33   2.09416155e-33
   1.08501561e-34], sum to 1.0000
[2017-11-02 10:44:16,741] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.416666666666666, 97.08333333333333, 1.75, 159.1666666666667, 0.0, 0.0, 1.333333333333333, 36.14707554619915, 18.0, 19.48290419790056, 19.4, 0.0, 0.0], 
actual action is [1.416666666666666, 18], 
sim time next is 6031800.0000, 
raw observation next is [6.5, 96.5, 1.8, 185.0, 0.0, 0.0, 1.416666666666666, 36.45893012905155, 18.0, 19.4848531772341, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.5, 0.965, 0.16363636363636364, 0.5138888888888888, 0.0, 0.0, 0.523611111111111, 0.36458930129051553, 0.0, 0.21212188246201436, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:44:18,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-39.02795792]
 [-40.60638046]
 [-40.52429962]
 [-39.77461624]
 [-42.64696121]], R is [[-40.96496201]
 [-40.59728241]
 [-40.2313118 ]
 [-39.86688232]
 [-39.50378036]].
[2017-11-02 10:44:18,742] A3C_AGENT_WORKER-Thread-6 INFO:Local step 20500, global step 323994: loss -8.1551
[2017-11-02 10:44:20,622] A3C_AGENT_WORKER-Thread-16 INFO:Local step 20500, global step 324498: loss 0.6851
[2017-11-02 10:44:25,092] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99641538e-01   2.98573255e-08   2.24727842e-06   3.55947530e-04
   2.93611635e-07   4.40314885e-13   1.03586559e-13   5.92612973e-11
   1.62279668e-13], sum to 1.0000
[2017-11-02 10:44:25,131] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 78.0, 6.2, 330.0, 130.5, 0.0, 4.0, 28.10529589767519, 19.0, 20.33073497790326, 20.56, 1.0, 70.3339422042077], 
actual action is [-6.0, 18], 
sim time next is 6091500.0000, 
raw observation next is [-1.0, 78.0, 6.241666666666667, 329.1666666666667, 129.75, 0.0, -6.0, 29.57693929851997, 18.0, 20.4676827529192, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.3076923076923077, 0.78, 0.5674242424242425, 0.9143518518518519, 0.34325396825396826, 0.0, 0.4, 0.2957693929851997, 0.0, 0.35252610755988556, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:25,657] A3C_AGENT_WORKER-Thread-10 INFO:Local step 20500, global step 325435: loss 94.3796
[2017-11-02 10:44:29,576] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  6.63624807e-32   2.19463115e-24   8.08143127e-23   1.79369818e-20
   1.84001112e-23   1.12669449e-03   5.36241423e-05   9.98277426e-01
   5.42179972e-04], sum to 1.0000
[2017-11-02 10:44:29,609] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [2.0, 52.0, 5.833333333333334, 310.0, 171.1666666666667, 227.3333333333333, -3.0, 30.2698684470441, 18.0, 20.77884831985458, 20.56, 1.0, 0.0], 
actual action is [7.0, 20.0], 
sim time next is 6107100.0000, 
raw observation next is [2.0, 52.0, 5.741666666666666, 310.0, 161.5833333333333, 234.1666666666667, 7.0, 28.87249001795874, 20.0, 20.72777818120061, 20.56, 1.0, 33.13414716773921], 
processed observation next is [1.0, 0.6956521739130435, 0.38461538461538464, 0.52, 0.521969696969697, 0.8611111111111112, 0.42746913580246904, 0.23416666666666672, 0.6166666666666667, 0.2887249001795874, 0.2857142857142857, 0.3896825973143727, 0.36571428571428555, 1.0, 0.3898134960910495], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:29,795] A3C_AGENT_WORKER-Thread-8 INFO:Local step 20500, global step 326500: loss 238.1097
[2017-11-02 10:44:29,929] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-75.03417969]
 [-74.38314819]
 [-72.48001099]
 [-71.90705872]
 [-70.90908813]], R is [[-68.68501282]
 [-68.99816132]
 [-69.30818176]
 [-69.61509705]
 [-69.91894531]].
[2017-11-02 10:44:30,187] A3C_AGENT_WORKER-Thread-3 INFO:Local step 20500, global step 326593: loss 46.2362
[2017-11-02 10:44:31,491] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   4.62062517e-13   3.11350182e-11   2.20052399e-09
   1.92656828e-12   2.77619508e-35   1.08472120e-35   1.05243231e-33
   4.01465149e-36], sum to 1.0000
[2017-11-02 10:44:31,504] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 47.0, 2.266666666666667, 183.3333333333333, 0.0, 0.0, 1.0, 26.74026007335554, 18.0, 20.53585442276168, 22.2, 1.0, 0.0], 
actual action is [1.0, 18], 
sim time next is 6200700.0000, 
raw observation next is [6.0, 47.0, 2.308333333333334, 184.1666666666667, 0.0, 0.0, 1.0, 27.13886405691137, 18.0, 20.48343359941861, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.782608695652174, 0.48717948717948717, 0.47, 0.20984848484848492, 0.5115740740740742, 0.0, 0.0, 0.5166666666666667, 0.2713886405691137, 0.0, 0.3547762284883729, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:33,536] A3C_AGENT_WORKER-Thread-4 INFO:Local step 20500, global step 327515: loss 58.3958
[2017-11-02 10:44:35,833] A3C_AGENT_WORKER-Thread-13 INFO:Local step 20500, global step 328079: loss 148.6582
[2017-11-02 10:44:36,193] A3C_AGENT_WORKER-Thread-5 INFO:Local step 20500, global step 328181: loss 6.0240
[2017-11-02 10:44:37,302] A3C_AGENT_WORKER-Thread-7 INFO:Local step 20500, global step 328473: loss 42.4434
[2017-11-02 10:44:37,515] A3C_AGENT_WORKER-Thread-17 INFO:Local step 20500, global step 328523: loss -1.6202
[2017-11-02 10:44:39,031] A3C_AGENT_WORKER-Thread-2 INFO:Local step 20500, global step 328919: loss 23.0672
[2017-11-02 10:44:40,157] A3C_AGENT_WORKER-Thread-15 INFO:Local step 20500, global step 329278: loss 147.5588
[2017-11-02 10:44:41,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 20500, global step 329672: loss -23.3509
[2017-11-02 10:44:43,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.72979313e-02   4.65172570e-06   1.45961705e-04   4.88191564e-03
   2.20140682e-05   8.30847491e-03   2.55974545e-03   8.96765649e-01
   1.36989129e-05], sum to 1.0000
[2017-11-02 10:44:43,474] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 43.29821987718269, 20.0, 18.5400780465721, 19.4, 0.0, 100.497156416691], 
actual action is [2.0, 22.0], 
sim time next is 6143400.0000, 
raw observation next is [-3.0, 71.0, 4.1, 260.0, 0.0, 0.0, 2.0, 38.91420801202413, 22.0, 18.73928374471598, 19.4, 0.0, 63.13818523730034], 
processed observation next is [0.0, 0.08695652173913043, 0.2564102564102564, 0.71, 0.3727272727272727, 0.7222222222222222, 0.0, 0.0, 0.5333333333333333, 0.3891420801202413, 0.5714285714285714, 0.10561196353085427, 0.1999999999999998, 0.0, 0.7428021792623569], 
reward next is -0.7629. 
=============================================
[2017-11-02 10:44:44,271] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.41481296e-13   1.30493468e-12   1.93941530e-10
   5.50625138e-13   2.49762915e-27   2.09392142e-26   4.93744159e-23
   1.07588656e-26], sum to 1.0000
[2017-11-02 10:44:44,338] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 44.0, 4.1, 210.0, 263.5, 468.5, 1.916666666666666, 14.53786224720442, 18.0, 22.28536686185976, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6185100.0000, 
raw observation next is [6.999999999999999, 43.99999999999999, 4.058333333333333, 210.0, 270.4166666666667, 428.0833333333334, 2.0, 14.44736806782693, 18.0, 22.30381824355852, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 0.43999999999999995, 0.3689393939393939, 0.5833333333333334, 0.7153880070546738, 0.4280833333333334, 0.5333333333333333, 0.1444736806782693, 0.0, 0.6148311776512172, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0144. 
=============================================
[2017-11-02 10:44:44,463] A3C_AGENT_WORKER-Thread-11 INFO:Local step 20500, global step 330694: loss 4.0147
[2017-11-02 10:44:44,725] A3C_AGENT_WORKER-Thread-12 INFO:Local step 20500, global step 330789: loss 9.1967
[2017-11-02 10:44:44,779] A3C_AGENT_WORKER-Thread-9 INFO:Local step 20500, global step 330809: loss 116.8342
[2017-11-02 10:44:45,406] A3C_AGENT_WORKER-Thread-6 INFO:Local step 21000, global step 331060: loss 56.2546
[2017-11-02 10:44:45,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   5.54296886e-11   6.13267881e-10   3.49597862e-08
   2.39617409e-10   4.93905020e-20   6.11585343e-19   3.74481414e-18
   5.86220574e-19], sum to 1.0000
[2017-11-02 10:44:45,908] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 44.0, 3.891666666666666, 210.0, 298.0833333333333, 266.4166666666667, 2.0, 15.29946383024414, 18.0, 22.16141840735889, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6186600.0000, 
raw observation next is [7.0, 44.0, 3.85, 210.0, 305.0, 226.0, 2.0, 15.22398937156119, 18.0, 22.18424871516814, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5128205128205128, 0.44, 0.35000000000000003, 0.5833333333333334, 0.8068783068783069, 0.226, 0.5333333333333333, 0.1522398937156119, 0.0, 0.5977498164525912, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:45,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99999881e-01   1.15476032e-10   8.36653191e-10   6.44659295e-08
   5.37454303e-10   3.48296073e-15   4.66214117e-14   5.09089570e-13
   5.71775632e-14], sum to 1.0000
[2017-11-02 10:44:45,959] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 50.33333333333334, 6.0, 210.0, 143.8333333333333, 846.3333333333334, 5.75, 14.15009630654616, 18.0, 22.5246097790595, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6263100.0000, 
raw observation next is [11.25, 49.5, 6.300000000000001, 212.5, 143.75, 847.5, 6.0, 14.0934828621868, 18.0, 22.52494395005282, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.6217948717948718, 0.495, 0.5727272727272728, 0.5902777777777778, 0.3802910052910053, 0.8475, 0.6, 0.140934828621868, 0.0, 0.6464205642932599, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0141. 
=============================================
[2017-11-02 10:44:47,682] A3C_AGENT_WORKER-Thread-16 INFO:Local step 21000, global step 331961: loss 84.4276
[2017-11-02 10:44:49,187] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   4.36902638e-16   9.78431644e-15   2.51234363e-13
   1.27779536e-15   9.28037723e-36   9.13643801e-34   3.70321401e-36
   3.25990685e-36], sum to 1.0000
[2017-11-02 10:44:49,198] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 67.0, 4.308333333333333, 184.1666666666667, 0.0, 0.0, -4.0, 44.96751863819478, 18.0, 18.59782395020427, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 6237000.0000, 
raw observation next is [1.0, 67.0, 4.35, 185.0, 0.0, 0.0, -4.0, 46.1815732458164, 18.0, 18.52432895925332, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.17391304347826086, 0.358974358974359, 0.67, 0.39545454545454545, 0.5138888888888888, 0.0, 0.0, 0.43333333333333335, 0.46181573245816404, 0.0, 0.0749041370361887, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:50,027] A3C_AGENT_WORKER-Thread-10 INFO:Local step 21000, global step 332936: loss 34.8099
[2017-11-02 10:44:51,795] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.75132721e-18   7.46221534e-17   2.28870962e-14
   6.41579647e-18   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:44:51,837] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.666666666666667, 72.66666666666667, 2.533333333333333, 190.0, 71.83333333333333, 69.49999999999999, -3.416666666666667, 36.23163380341082, 18.0, 19.47794184822978, 22.2, 1.0, 0.0], 
actual action is [-3.333333333333333, 18], 
sim time next is 6248700.0000, 
raw observation next is [1.75, 72.75, 2.275, 190.0, 82.75, 104.25, -3.333333333333333, 36.9302385958561, 18.0, 19.45733109001452, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.3782051282051282, 0.7275, 0.20681818181818182, 0.5277777777777778, 0.21891534391534392, 0.10425, 0.4444444444444445, 0.369302385958561, 0.0, 0.20819015571636004, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:52,978] A3C_AGENT_WORKER-Thread-8 INFO:Local step 21000, global step 334145: loss 32.1887
[2017-11-02 10:44:53,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 21000, global step 334320: loss 4.9139
[2017-11-02 10:44:53,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   1.03598411e-13   7.87531498e-13   3.96052191e-10
   1.49279054e-13   2.31911162e-27   7.98452862e-25   2.28035677e-25
   7.33840381e-24], sum to 1.0000
[2017-11-02 10:44:53,732] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.333333333333334, 63.0, 4.1, 163.3333333333333, 198.3333333333333, 172.8333333333333, 0.1666666666666661, 23.80990618305795, 18.0, 21.35581643552604, 22.2, 1.0, 0.0], 
actual action is [0.3333333333333339, 18], 
sim time next is 6255900.0000, 
raw observation next is [5.5, 62.25, 4.225, 165.0, 202.5, 219.25, 0.3333333333333339, 23.83292083616794, 18.0, 21.30794441671967, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.47435897435897434, 0.6225, 0.38409090909090904, 0.4583333333333333, 0.5357142857142857, 0.21925, 0.5055555555555556, 0.2383292083616794, 0.0, 0.4725634881028102, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:53,913] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   5.45792015e-14   4.52143184e-12   6.71326772e-10
   1.66167305e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:44:53,924] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.666666666666667, 57.33333333333334, 3.1, 190.0, 0.0, 0.0, 1.75, 27.75966675803836, 18.0, 20.19012428094384, 22.2, 1.0, 0.0], 
actual action is [1.666666666666667, 18], 
sim time next is 6308700.0000, 
raw observation next is [6.583333333333333, 57.66666666666666, 3.1, 190.0, 0.0, 0.0, 1.666666666666667, 27.97430749519495, 18.0, 20.16640405917906, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.0, 0.5021367521367521, 0.5766666666666665, 0.2818181818181818, 0.5277777777777778, 0.0, 0.0, 0.5277777777777778, 0.2797430749519495, 0.0, 0.30948629416843737, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:44:55,670] A3C_AGENT_WORKER-Thread-4 INFO:Local step 21000, global step 335275: loss 81.3218
[2017-11-02 10:44:58,148] A3C_AGENT_WORKER-Thread-7 INFO:Local step 21000, global step 336462: loss 6.3155
[2017-11-02 10:44:58,321] A3C_AGENT_WORKER-Thread-5 INFO:Local step 21000, global step 336548: loss 14.0552
[2017-11-02 10:44:58,360] A3C_AGENT_WORKER-Thread-13 INFO:Local step 21000, global step 336565: loss 35.0302
[2017-11-02 10:44:59,335] A3C_AGENT_WORKER-Thread-17 INFO:Local step 21000, global step 337046: loss 4.0863
[2017-11-02 10:45:00,724] A3C_AGENT_WORKER-Thread-6 INFO:Local step 21500, global step 337792: loss 10.3640
[2017-11-02 10:45:00,889] A3C_AGENT_WORKER-Thread-2 INFO:Local step 21000, global step 337883: loss 48.0289
[2017-11-02 10:45:00,891] A3C_AGENT_WORKER-Thread-15 INFO:Local step 21000, global step 337883: loss 34.7769
[2017-11-02 10:45:01,530] A3C_AGENT_WORKER-Thread-14 INFO:Local step 21000, global step 338265: loss 8.0511
[2017-11-02 10:45:02,063] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   1.87707028e-13   2.49636227e-12   1.34573706e-11
   5.53218983e-13   1.01444682e-37   4.77742026e-36   3.25019352e-38
   4.47050392e-38], sum to 1.0000
[2017-11-02 10:45:02,077] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.083333333333334, 59.66666666666667, 3.1, 190.0, 0.0, 0.0, 1.166666666666666, 31.91439608221798, 18.0, 19.83518845952506, 22.2, 1.0, 0.0], 
actual action is [1.083333333333334, 18], 
sim time next is 6310800.0000, 
raw observation next is [6.0, 60.0, 3.1, 190.0, 0.0, 0.0, 1.083333333333334, 32.15043457346499, 18.0, 19.80895768096151, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.48717948717948717, 0.6, 0.2818181818181818, 0.5277777777777778, 0.0, 0.0, 0.5180555555555556, 0.3215043457346499, 0.0, 0.2584225258516441, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:03,158] A3C_AGENT_WORKER-Thread-16 INFO:Local step 21500, global step 339202: loss 0.2817
[2017-11-02 10:45:03,616] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99226928e-01   4.98448135e-05   3.04801157e-04   3.70035472e-04
   4.83473850e-05   4.09377006e-16   1.23911158e-15   2.27449655e-16
   7.54664335e-17], sum to 1.0000
[2017-11-02 10:45:03,629] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.0, 47.0, 4.85, 192.5, 0.0, 0.0, 9.0, 12.42971568388056, 18.0, 21.61670796873378, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 6405600.0000, 
raw observation next is [14.0, 47.0, 4.766666666666667, 193.3333333333333, 0.0, 0.0, 9.0, 12.4805063396959, 18.0, 21.60708680207852, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.13043478260869565, 0.6923076923076923, 0.47, 0.43333333333333335, 0.5370370370370369, 0.0, 0.0, 0.65, 0.124805063396959, 0.0, 0.5152981145826457, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 10:45:03,824] A3C_AGENT_WORKER-Thread-12 INFO:Local step 21000, global step 339613: loss 9.2390
[2017-11-02 10:45:03,992] A3C_AGENT_WORKER-Thread-11 INFO:Local step 21000, global step 339717: loss 7.4480
[2017-11-02 10:45:04,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 21000, global step 339924: loss 14.6752
[2017-11-02 10:45:04,716] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   3.64385524e-13   1.31380540e-12   2.71872152e-12
   1.35746029e-13   5.68586730e-30   2.01667645e-29   1.09358132e-31
   4.81703126e-32], sum to 1.0000
[2017-11-02 10:45:04,724] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.0, 95.33333333333334, 6.783333333333333, 341.6666666666667, 0.0, 0.0, -6.0, 43.24253484876867, 18.0, 17.53542721035662, 19.4, 0.0, 0.0], 
actual action is [-6.0, 18], 
sim time next is 6496800.0000, 
raw observation next is [-1.0, 94.66666666666666, 6.866666666666667, 343.3333333333333, 0.0, 0.0, -6.0, 44.50735602729551, 18.0, 17.50593997736037, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.3076923076923077, 0.9466666666666665, 0.6242424242424243, 0.9537037037037036, 0.0, 0.0, 0.4, 0.4450735602729551, 0.0, -0.07058000323423284, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:04,773] A3C_AGENT_WORKER-Thread-10 INFO:Local step 21500, global step 340174: loss 4.2069
[2017-11-02 10:45:05,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   3.33040440e-09   6.61342481e-10   1.83899940e-09
   1.14730980e-09   9.78309027e-14   2.80725882e-13   2.90585359e-14
   3.88754030e-15], sum to 1.0000
[2017-11-02 10:45:05,636] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.25, 40.66666666666666, 6.533333333333333, 224.1666666666667, 152.25, 782.9166666666666, 9.0, 14.23728934559373, 18.0, 22.39396858231016, 22.2, 1.0, 0.0], 
actual action is [9.25, 18], 
sim time next is 6345000.0000, 
raw observation next is [14.5, 40.0, 6.7, 225.0, 150.0, 800.0, 9.25, 13.90422245305797, 18.0, 22.45211076859963, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.43478260869565216, 0.7051282051282052, 0.4, 0.6090909090909091, 0.625, 0.3968253968253968, 0.8, 0.6541666666666667, 0.1390422245305797, 0.0, 0.6360158240856616, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 10:45:07,462] A3C_AGENT_WORKER-Thread-3 INFO:Local step 21500, global step 341679: loss 0.0242
[2017-11-02 10:45:07,534] A3C_AGENT_WORKER-Thread-8 INFO:Local step 21500, global step 341723: loss 9.2584
[2017-11-02 10:45:07,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99993563e-01   2.09057703e-06   1.24839778e-06   1.91698769e-06
   1.13461704e-06   2.44997653e-13   3.80857780e-13   6.02935602e-14
   2.42085032e-14], sum to 1.0000
[2017-11-02 10:45:07,846] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [18.08333333333334, 33.83333333333333, 5.95, 220.8333333333333, 37.91666666666667, 141.1666666666667, 13.16666666666666, 6.451452520318807, 18.0, 24.44801497381961, 22.2, 1.0, 0.0], 
actual action is [13.08333333333334, 18], 
sim time next is 6372000.0000, 
raw observation next is [18.0, 34.0, 5.7, 220.0, 32.5, 121.0, 13.08333333333334, 6.437091237137609, 18.0, 24.39358690897077, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.782608695652174, 0.7948717948717948, 0.34, 0.5181818181818182, 0.6111111111111112, 0.08597883597883597, 0.121, 0.7180555555555557, 0.06437091237137609, 0.0, 0.9133695584243959, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0064. 
=============================================
[2017-11-02 10:45:09,606] A3C_AGENT_WORKER-Thread-4 INFO:Local step 21500, global step 342875: loss 1.1422
[2017-11-02 10:45:11,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-8.48625278]
 [-8.36796856]
 [-8.2950964 ]
 [-9.1328516 ]
 [-9.44636726]], R is [[-8.28521729]
 [-8.21064281]
 [-8.13674927]
 [-8.06353092]
 [-7.99098206]].
[2017-11-02 10:45:11,979] A3C_AGENT_WORKER-Thread-13 INFO:Local step 21500, global step 344262: loss 0.9091
[2017-11-02 10:45:12,074] A3C_AGENT_WORKER-Thread-5 INFO:Local step 21500, global step 344328: loss 3.0390
[2017-11-02 10:45:12,574] A3C_AGENT_WORKER-Thread-7 INFO:Local step 21500, global step 344629: loss -1.5070
[2017-11-02 10:45:13,254] A3C_AGENT_WORKER-Thread-17 INFO:Local step 21500, global step 344990: loss 0.3783
[2017-11-02 10:45:14,013] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.00000000e+00   2.80854414e-13   1.81033452e-11   7.83498960e-11
   1.17811122e-10   1.96095510e-37   4.72349130e-36   0.00000000e+00
   8.55946117e-38], sum to 1.0000
[2017-11-02 10:45:14,046] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.875, 63.5, 2.55, 65.0, 0.0, 0.0, -10.83333333333333, 63.12124601114687, 18.0, 16.90693054995764, 19.4, 0.0, 0.0], 
actual action is [-10.875, 18], 
sim time next is 6576600.0000, 
raw observation next is [-5.916666666666666, 63.66666666666666, 2.566666666666667, 66.66666666666667, 0.0, 0.0, -10.875, 64.83928823001439, 18.0, 16.94041181070921, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.18162393162393164, 0.6366666666666666, 0.23333333333333336, 0.1851851851851852, 0.0, 0.0, 0.31875, 0.6483928823001439, 0.0, -0.15136974132725559, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:14,164] A3C_AGENT_WORKER-Thread-2 INFO:Local step 21500, global step 345510: loss 0.4249
[2017-11-02 10:45:14,723] A3C_AGENT_WORKER-Thread-14 INFO:Local step 21500, global step 345829: loss 9.9662
[2017-11-02 10:45:14,780] A3C_AGENT_WORKER-Thread-15 INFO:Local step 21500, global step 345862: loss 6.5301
[2017-11-02 10:45:16,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   3.30808400e-15   8.16585027e-14   2.83575951e-13
   3.89132560e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:16,079] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.916666666666667, 54.08333333333334, 2.808333333333334, 39.16666666666668, 0.0, 0.0, -8.833333333333332, 56.11833422419326, 18.0, 17.671733365795, 19.4, 0.0, 0.0], 
actual action is [-8.916666666666668, 18], 
sim time next is 6562800.0000, 
raw observation next is [-4.0, 54.0, 2.6, 10.0, 0.0, 0.0, -8.916666666666668, 57.61714367643913, 18.0, 17.58724748144612, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.23076923076923078, 0.54, 0.23636363636363636, 0.027777777777777776, 0.0, 0.0, 0.35138888888888886, 0.5761714367643913, 0.0, -0.05896464550769715, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:17,293] A3C_AGENT_WORKER-Thread-11 INFO:Local step 21500, global step 347141: loss 67.8563
[2017-11-02 10:45:17,376] A3C_AGENT_WORKER-Thread-12 INFO:Local step 21500, global step 347181: loss 23.7765
[2017-11-02 10:45:17,454] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  8.38550389e-01   3.07938568e-02   5.51895276e-02   4.35979292e-02
   3.16168480e-02   8.18211847e-05   1.10520712e-04   4.43667741e-05
   1.47338878e-05], sum to 1.0000
[2017-11-02 10:45:17,463] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 100.0, 4.6, 180.0, 119.5, 0.0, 6.0, 8.848896431230049, 18.0, 21.80559502593556, 19.4, 0.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 6444300.0000, 
raw observation next is [11.0, 99.99999999999999, 4.216666666666666, 165.0, 118.75, 0.0, 6.0, 8.889922056366505, 18.0, 21.78265604711057, 19.4, 0.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.6153846153846154, 0.9999999999999999, 0.38333333333333325, 0.4583333333333333, 0.31415343915343913, 0.0, 0.6, 0.08889922056366505, 0.0, 0.5403794353015101, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:45:18,003] A3C_AGENT_WORKER-Thread-9 INFO:Local step 21500, global step 347471: loss 2.2970
[2017-11-02 10:45:18,485] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.92871456e-12   1.73562965e-12   2.57127739e-11
   9.20124654e-12   1.00255709e-34   8.93975576e-33   8.78672385e-35
   1.00598967e-34], sum to 1.0000
[2017-11-02 10:45:18,508] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 51.66666666666666, 5.649999999999999, 339.9999999999999, 126.6666666666667, 767.4166666666667, -3.0, 22.80831616608955, 18.0, 21.34643983229221, 22.2, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 6534600.0000, 
raw observation next is [2.0, 51.33333333333334, 5.6, 340.0000000000001, 125.3333333333333, 762.3333333333334, -3.0, 22.61471366517574, 18.0, 21.34389913068911, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.38461538461538464, 0.5133333333333334, 0.509090909090909, 0.9444444444444448, 0.33156966490299816, 0.7623333333333334, 0.45, 0.2261471366517574, 0.0, 0.47769987581272993, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:19,360] A3C_AGENT_WORKER-Thread-6 INFO:Local step 22000, global step 348014: loss 58.2301
[2017-11-02 10:45:22,844] A3C_AGENT_WORKER-Thread-16 INFO:Local step 22000, global step 349262: loss 48.6075
[2017-11-02 10:45:23,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   4.60579713e-10   1.85320287e-10   2.27231700e-09
   9.64511471e-10   2.00150578e-25   2.11579068e-21   2.02397348e-23
   3.40486124e-23], sum to 1.0000
[2017-11-02 10:45:23,490] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6666666666666667, 60.00000000000001, 7.9, 336.6666666666667, 274.5, 552.6666666666666, -5.75, 30.03927667070831, 18.0, 20.14022459882145, 22.2, 1.0, 0.0], 
actual action is [-5.666666666666667, 18], 
sim time next is 6521100.0000, 
raw observation next is [-0.5833333333333333, 59.99999999999999, 8.075, 338.3333333333333, 270.75, 595.8333333333334, -5.666666666666667, 30.12255548569571, 18.0, 20.08368304935159, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.4782608695652174, 0.31837606837606836, 0.6, 0.734090909090909, 0.9398148148148148, 0.7162698412698413, 0.5958333333333333, 0.40555555555555556, 0.3012255548569571, 0.0, 0.2976690070502269, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:24,455] A3C_AGENT_WORKER-Thread-10 INFO:Local step 22000, global step 349873: loss -185.0105
[2017-11-02 10:45:25,892] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.58640568e-05   9.99647021e-01   2.59133929e-04
   3.80030797e-05], sum to 1.0000
[2017-11-02 10:45:25,953] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.166666666666667, 54.83333333333334, 3.558333333333333, 105.8333333333333, 101.6666666666667, 467.75, -10.33333333333333, 38.67986744326045, 18.0, 19.2714816821913, 19.4, 0.0, 0.0], 
actual action is [-0.16666666666666696, 19.0], 
sim time next is 6595200.0000, 
raw observation next is [-5.0, 54.0, 3.6, 110.0, 104.0, 492.5, -0.166666666666667, 36.87875169073572, 19.0, 19.23249509714838, 19.4, 0.0, 62.06141320540256], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.20512820512820512, 0.54, 0.32727272727272727, 0.3055555555555556, 0.2751322751322751, 0.4925, 0.4972222222222222, 0.36878751690735717, 0.14285714285714285, 0.1760707281640543, 0.1999999999999998, 0.0, 0.730134273004736], 
reward next is -0.6811. 
=============================================
[2017-11-02 10:45:26,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   8.01252619e-13   2.82677365e-13   4.08402565e-12
   4.51138530e-13   4.74400842e-27   5.08423283e-23   1.48848266e-25
   4.43472610e-26], sum to 1.0000
[2017-11-02 10:45:26,346] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.25, 51.0, 5.1, 357.5, 41.25, 310.5, -4.666666666666667, 21.25849144285257, 18.0, 21.16764764166647, 22.2, 1.0, 0.0], 
actual action is [-4.75, 18], 
sim time next is 6544200.0000, 
raw observation next is [0.1666666666666666, 51.0, 5.1, 358.3333333333333, 36.66666666666667, 276.0000000000001, -4.75, 22.06084486616657, 18.0, 21.06732104762575, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.7391304347826086, 0.3376068376068376, 0.51, 0.4636363636363636, 0.9953703703703703, 0.09700176366843034, 0.27600000000000013, 0.42083333333333334, 0.22060844866166568, 0.0, 0.4381887210893929, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:27,974] A3C_AGENT_WORKER-Thread-3 INFO:Local step 22000, global step 350983: loss 127.3375
[2017-11-02 10:45:28,066] A3C_AGENT_WORKER-Thread-8 INFO:Local step 22000, global step 351019: loss -70.9133
[2017-11-02 10:45:29,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.82997846e-05   9.99948025e-01   3.21288862e-05
   1.54377847e-06], sum to 1.0000
[2017-11-02 10:45:29,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   1.99212289e-16   1.23852363e-16   8.88784154e-16
   1.72762005e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:29,147] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.166666666666667, 47.5, 5.1, 120.0, 0.0, 0.0, -2.916666666666667, 49.09181935211235, 18.0, 18.87118930728144, 19.4, 0.0, 0.0], 
actual action is [-2.833333333333333, 18], 
sim time next is 6650100.0000, 
raw observation next is [2.25, 47.25, 5.1, 120.0, 0.0, 0.0, -2.833333333333333, 49.49648973397463, 18.0, 18.88011504200668, 19.4, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.391025641025641, 0.4725, 0.4636363636363636, 0.3333333333333333, 0.0, 0.0, 0.4527777777777778, 0.49496489733974625, 0.0, 0.12573072028666843, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0743. 
=============================================
[2017-11-02 10:45:29,222] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.833333333333334, 63.33333333333333, 2.533333333333333, 63.33333333333333, 0.0, 0.0, -10.79166666666667, 56.51736836123947, 18.0, 17.60672354386774, 19.4, 0.0, 0.0], 
actual action is [-0.8333333333333339, 19.0], 
sim time next is 6576300.0000, 
raw observation next is [-5.875, 63.5, 2.55, 65.0, 0.0, 0.0, -0.8333333333333339, 51.75884979262435, 19.0, 17.63040471101596, 19.4, 0.0, 80.18537810063958], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.18269230769230768, 0.635, 0.2318181818181818, 0.18055555555555555, 0.0, 0.0, 0.48611111111111105, 0.5175884979262435, 0.14285714285714285, -0.05279932699772009, 0.1999999999999998, 0.0, 0.9433573894192891], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:29,482] A3C_AGENT_WORKER-Thread-4 INFO:Local step 22000, global step 351536: loss -99.3698
[2017-11-02 10:45:30,939] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-84.18602753]
 [-84.43808746]
 [-83.18393707]
 [-82.02167511]
 [-85.4812851 ]], R is [[-84.54214478]
 [-84.69672394]
 [-84.84975433]
 [-85.00125885]
 [-85.15124512]].
[2017-11-02 10:45:31,265] A3C_AGENT_WORKER-Thread-5 INFO:Local step 22000, global step 352106: loss 46.5493
[2017-11-02 10:45:33,223] A3C_AGENT_WORKER-Thread-7 INFO:Local step 22000, global step 352701: loss -30.1450
[2017-11-02 10:45:33,815] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99997735e-01   3.65870591e-07   1.05710320e-07   8.48911100e-07
   9.35938431e-07   1.23194532e-12   3.81900556e-08   8.14686079e-12
   2.05721052e-12], sum to 1.0000
[2017-11-02 10:45:33,827] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.999999999999999, 55.99999999999999, 4.975, 130.0, 167.1666666666667, 2.5, 2.0, 30.9918989356306, 18.0, 20.74932850930116, 20.56, 1.0, 0.0], 
actual action is [1.9999999999999991, 18], 
sim time next is 6693000.0000, 
raw observation next is [7.0, 56.0, 4.85, 130.0, 158.3333333333333, 2.0, 1.999999999999999, 32.26749741555542, 18.0, 20.69813273215413, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.5128205128205128, 0.56, 0.44090909090909086, 0.3611111111111111, 0.41887125220458543, 0.002, 0.5333333333333333, 0.3226749741555542, 0.0, 0.3854475331648755, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:33,981] A3C_AGENT_WORKER-Thread-13 INFO:Local step 22000, global step 352894: loss -71.4567
[2017-11-02 10:45:34,706] A3C_AGENT_WORKER-Thread-17 INFO:Local step 22000, global step 353078: loss 63.0657
[2017-11-02 10:45:35,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 22000, global step 353189: loss 87.4913
[2017-11-02 10:45:37,229] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-49.78839874]
 [-49.7041626 ]
 [-52.48843002]
 [-49.13278961]
 [-50.55735779]], R is [[-49.10279465]
 [-48.75006866]
 [-48.50049973]
 [-48.0154953 ]
 [-47.92034149]].
[2017-11-02 10:45:37,993] A3C_AGENT_WORKER-Thread-14 INFO:Local step 22000, global step 353773: loss -21.0365
[2017-11-02 10:45:38,065] A3C_AGENT_WORKER-Thread-15 INFO:Local step 22000, global step 353794: loss 16.7722
[2017-11-02 10:45:40,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.14809695e-05   9.99961495e-01   6.92643380e-06
   1.38145225e-07], sum to 1.0000
[2017-11-02 10:45:40,540] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-3.833333333333333, 49.33333333333333, 4.825, 98.33333333333333, 119.0, 649.8333333333333, 1.0, 24.51648398576416, 20.0, 20.84389267667028, 20.56, 1.0, 39.69300934883285], 
actual action is [1.166666666666667, 21.0], 
sim time next is 6597600.0000, 
raw observation next is [-3.666666666666667, 48.66666666666667, 5.0, 96.66666666666667, 120.0, 658.6666666666667, 1.166666666666667, 24.65795276734935, 21.0, 20.88124700341271, 20.56, 1.0, 34.29163260650049], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.2393162393162393, 0.4866666666666667, 0.45454545454545453, 0.26851851851851855, 0.31746031746031744, 0.6586666666666667, 0.5194444444444445, 0.2465795276734935, 0.42857142857142855, 0.41160671477324434, 0.36571428571428555, 1.0, 0.40343097184118226], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:41,568] A3C_AGENT_WORKER-Thread-11 INFO:Local step 22000, global step 354805: loss 7.7806
[2017-11-02 10:45:41,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   5.88858684e-11   7.27389980e-12   2.78453510e-10
   9.41338257e-11   3.76689867e-15   1.46847170e-11   1.33035613e-14
   1.47486859e-15], sum to 1.0000
[2017-11-02 10:45:42,024] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.5, 44.25, 5.425000000000001, 90.0, 127.0, 720.5, 2.333333333333333, 16.51200989242831, 25.0, 22.14115650245325, 20.56, 1.0, 62.72969118289375], 
actual action is [2.5, 20.0], 
sim time next is 6600000.0000, 
raw observation next is [-2.333333333333333, 43.66666666666667, 5.333333333333334, 90.0, 128.0, 729.3333333333333, 2.5, 16.06583842107203, 20.0, 22.29298897464108, 20.56, 1.0, 50.14453236068061], 
processed observation next is [0.8333333333333334, 0.391304347826087, 0.27350427350427353, 0.4366666666666667, 0.4848484848484849, 0.25, 0.3386243386243386, 0.7293333333333333, 0.5416666666666666, 0.1606583842107203, 0.2857142857142857, 0.61328413923444, 0.36571428571428555, 1.0, 0.5899356748315365], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:42,066] A3C_AGENT_WORKER-Thread-12 INFO:Local step 22000, global step 354988: loss -35.6634
[2017-11-02 10:45:42,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 22000, global step 355039: loss -37.4909
[2017-11-02 10:45:42,811] A3C_AGENT_WORKER-Thread-6 INFO:Local step 22500, global step 355307: loss 12.2194
[2017-11-02 10:45:44,416] A3C_AGENT_WORKER-Thread-16 INFO:Local step 22500, global step 356005: loss 5.2013
[2017-11-02 10:45:46,216] A3C_AGENT_WORKER-Thread-10 INFO:Local step 22500, global step 356925: loss 1.8160
[2017-11-02 10:45:46,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   8.44388002e-15   8.00280456e-15   2.87068512e-14
   2.10049433e-14   0.00000000e+00   2.60022297e-37   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:46,778] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 45.66666666666666, 4.6, 125.8333333333333, 0.0, 0.0, -3.0, 42.25792489869571, 18.0, 19.62378145508422, 20.56, 1.0, 0.0], 
actual action is [-3.0, 18], 
sim time next is 6643800.0000, 
raw observation next is [2.0, 46.0, 4.6, 125.0, 0.0, 0.0, -3.0, 42.53719177182855, 18.0, 19.59658665320232, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.38461538461538464, 0.46, 0.41818181818181815, 0.3472222222222222, 0.0, 0.0, 0.45, 0.42537191771828553, 0.0, 0.2280838076003313, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:48,817] A3C_AGENT_WORKER-Thread-3 INFO:Local step 22500, global step 358095: loss 1.0625
[2017-11-02 10:45:49,262] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   5.11831354e-13   1.39670922e-13   7.11755351e-12
   6.05868220e-12   2.46119177e-31   5.80184778e-27   7.92857059e-30
   1.01043433e-29], sum to 1.0000
[2017-11-02 10:45:49,273] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.16666666666667, 53.5, 6.433333333333334, 118.3333333333333, 117.0, 15.33333333333334, 7.25, 23.36129173911206, 18.0, 21.81221016795316, 20.56, 1.0, 0.0], 
actual action is [7.16666666666667, 18], 
sim time next is 6713700.0000, 
raw observation next is [12.08333333333333, 53.75, 6.566666666666666, 119.1666666666667, 108.25, 13.41666666666667, 7.16666666666667, 23.59066224478273, 18.0, 21.77426664466512, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.6956521739130435, 0.643162393162393, 0.5375, 0.5969696969696969, 0.3310185185185186, 0.2863756613756614, 0.01341666666666667, 0.6194444444444446, 0.2359066224478273, 0.0, 0.5391809492378741, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:49,883] A3C_AGENT_WORKER-Thread-8 INFO:Local step 22500, global step 358562: loss 18.0588
[2017-11-02 10:45:50,181] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.16336904e-09   2.02895079e-09   3.31205907e-09
   2.70626881e-08   4.07826615e-19   1.31977024e-16   1.23423862e-20
   1.03984075e-20], sum to 1.0000
[2017-11-02 10:45:50,195] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.0, 52.0, 4.1, 110.0, 0.0, 0.0, 7.0, 54.69188104027315, 19.0, 17.66088019414582, 19.4, 0.0, 92.84863611226233], 
actual action is [-3.0, 18], 
sim time next is 6670200.0000, 
raw observation next is [2.0, 52.0, 4.1, 110.0, 0.0, 0.0, -3.0, 55.29925169356282, 18.0, 17.8110833307087, 19.4, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.38461538461538464, 0.52, 0.3727272727272727, 0.3055555555555556, 0.0, 0.0, 0.45, 0.5529925169356282, 0.0, -0.02698809561304267, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:50,819] A3C_AGENT_WORKER-Thread-4 INFO:Local step 22500, global step 359037: loss 0.6236
[2017-11-02 10:45:51,287] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.22978583e-16   3.94997854e-16   2.84757230e-15
   1.59656351e-15   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,302] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.5, 72.5, 7.2, 130.0, 0.0, 0.0, 1.583333333333333, 38.38673215239356, 18.0, 19.61467044429538, 20.56, 1.0, 0.0], 
actual action is [1.5, 18], 
sim time next is 6734100.0000, 
raw observation next is [6.416666666666666, 72.91666666666666, 7.283333333333333, 130.0, 0.0, 0.0, 1.5, 38.618682358692, 18.0, 19.58763021955292, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4978632478632478, 0.7291666666666665, 0.6621212121212121, 0.3611111111111111, 0.0, 0.0, 0.525, 0.38618682358691997, 0.0, 0.22680431707898865, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:51,406] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   4.86610814e-15   2.64008328e-14   1.92005957e-13
   6.09804769e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,416] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.25, 73.75, 7.45, 130.0, 0.0, 0.0, 1.333333333333334, 39.08960559755273, 18.0, 19.53282473323548, 20.56, 1.0, 0.0], 
actual action is [1.25, 18], 
sim time next is 6735000.0000, 
raw observation next is [6.166666666666666, 74.16666666666666, 7.533333333333333, 130.0, 0.0, 0.0, 1.25, 39.32846480099948, 18.0, 19.50509812579623, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.4914529914529914, 0.7416666666666666, 0.6848484848484848, 0.3611111111111111, 0.0, 0.0, 0.5208333333333334, 0.39328464800999474, 0.0, 0.2150140179708901, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:51,585] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   9.14451095e-15   1.61079985e-14   1.86212184e-13
   5.25748743e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:51,595] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.266666666666667, 65.5, 5.425, 120.0, 73.08333333333333, 0.0, 0.2000000000000002, 44.46714551862868, 18.0, 18.86535001343576, 19.4, 0.0, 0.0], 
actual action is [0.2666666666666666, 18], 
sim time next is 6768600.0000, 
raw observation next is [5.333333333333334, 65.0, 5.450000000000001, 120.0, 79.66666666666667, 0.0, 0.2666666666666666, 43.34936924451858, 18.0, 18.97664981173094, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.47008547008547014, 0.65, 0.49545454545454554, 0.3333333333333333, 0.2107583774250441, 0.0, 0.5044444444444445, 0.43349369244518576, 0.0, 0.13952140167584862, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0605. 
=============================================
[2017-11-02 10:45:52,320] A3C_AGENT_WORKER-Thread-5 INFO:Local step 22500, global step 359798: loss 4.9170
[2017-11-02 10:45:52,663] A3C_AGENT_WORKER-Thread-7 INFO:Local step 22500, global step 359970: loss 132.0398
[2017-11-02 10:45:53,189] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   3.50749419e-15   3.88623544e-15   2.86158833e-14
   1.91871868e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:53,197] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 70.0, 6.7, 130.0, 0.0, 0.0, 2.083333333333333, 38.69604836525768, 18.0, 19.73422192701759, 20.56, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 6732300.0000, 
raw observation next is [6.916666666666666, 70.41666666666666, 6.783333333333333, 130.0, 0.0, 0.0, 2.0, 38.90199564135857, 18.0, 19.70949486591163, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9565217391304348, 0.5106837606837606, 0.7041666666666666, 0.6166666666666667, 0.3611111111111111, 0.0, 0.0, 0.5333333333333333, 0.38901995641358567, 0.0, 0.24421355227308997, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:53,479] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-86.34331512]
 [-87.48840332]
 [-89.50649261]
 [-85.97711182]
 [-86.87807465]], R is [[-88.03953552]
 [-88.15914154]
 [-88.27754974]
 [-88.39477539]
 [-88.51082611]].
[2017-11-02 10:45:54,915] A3C_AGENT_WORKER-Thread-17 INFO:Local step 22500, global step 361099: loss 11.1426
[2017-11-02 10:45:54,990] A3C_AGENT_WORKER-Thread-13 INFO:Local step 22500, global step 361135: loss 15.1187
[2017-11-02 10:45:55,631] A3C_AGENT_WORKER-Thread-2 INFO:Local step 22500, global step 361458: loss 11.7649
[2017-11-02 10:45:56,079] A3C_AGENT_WORKER-Thread-15 INFO:Local step 22500, global step 361733: loss 1.7384
[2017-11-02 10:45:56,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  1.00000000e+00   4.65105757e-14   1.76033328e-13   1.90063980e-12
   3.19631881e-13   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:56,220] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 70.0, 5.1, 110.0, 14.0, 0.0, 0.08333333333333304, 52.40038230970158, 18.0, 18.28191506293974, 19.4, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 6764700.0000, 
raw observation next is [5.016666666666667, 69.66666666666666, 5.125, 110.8333333333333, 16.16666666666667, 0.0, 0.0, 51.79740596124874, 18.0, 18.26655681795721, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.30434782608695654, 0.46196581196581193, 0.6966666666666665, 0.4659090909090909, 0.3078703703703703, 0.042768959435626114, 0.0, 0.5, 0.5179740596124874, 0.0, 0.03807954542245844, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:56,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   4.07127577e-17   5.16041456e-17   5.07682802e-16
   2.45394497e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:56,427] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.833333333333333, 76.0, 5.1, 120.0, 0.0, 0.0, 0.75, 49.34981340404683, 18.0, 18.46241327669179, 19.4, 0.0, 0.0], 
actual action is [0.833333333333333, 18], 
sim time next is 6749700.0000, 
raw observation next is [5.916666666666667, 75.5, 5.1, 120.0, 0.0, 0.0, 0.833333333333333, 49.44752810129558, 18.0, 18.45263323217292, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.08695652173913043, 0.4850427350427351, 0.755, 0.4636363636363636, 0.3333333333333333, 0.0, 0.0, 0.5138888888888888, 0.4944752810129558, 0.0, 0.06466189031041734, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:56,467] A3C_AGENT_WORKER-Thread-14 INFO:Local step 22500, global step 361958: loss 6.4571
[2017-11-02 10:45:57,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.55757066e-20   4.44807125e-21   3.45252883e-19
   2.07320813e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:57,121] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.7, 87.75, 1.875, 55.0, 60.5, 33.25, -2.333333333333333, 37.36436417101884, 18.0, 18.68231288329707, 22.2, 1.0, 0.0], 
actual action is [-2.3, 18], 
sim time next is 6852000.0000, 
raw observation next is [2.733333333333333, 87.66666666666667, 1.9, 56.66666666666667, 67.0, 35.83333333333334, -2.3, 37.79439507463839, 18.0, 19.11202397397822, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.30434782608695654, 0.4034188034188034, 0.8766666666666667, 0.17272727272727273, 0.1574074074074074, 0.17724867724867724, 0.03583333333333334, 0.46166666666666667, 0.37794395074638387, 0.0, 0.1588605677111745, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:57,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-43.02247238]
 [-43.21686554]
 [-41.91981125]
 [-41.05225754]
 [-41.75622177]], R is [[-39.72795486]
 [-39.33067703]
 [-38.9373703 ]
 [-38.54799652]
 [-38.16251755]].
[2017-11-02 10:45:57,807] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  1.00000000e+00   1.59870883e-15   1.18068611e-15   1.21404165e-14
   3.97111704e-15   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:45:57,818] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 74.0, 4.6, 99.16666666666666, 0.0, 0.0, -2.0, 53.21178462607729, 18.0, 17.73198486244781, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6808200.0000, 
raw observation next is [3.0, 74.0, 4.6, 98.33333333333334, 0.0, 0.0, -2.0, 53.37742439954534, 18.0, 17.71925266306165, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.41025641025641024, 0.74, 0.41818181818181815, 0.2731481481481482, 0.0, 0.0, 0.4666666666666667, 0.5337742439954534, 0.0, -0.04010676241976441, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:45:58,199] A3C_AGENT_WORKER-Thread-11 INFO:Local step 22500, global step 362914: loss 2.1169
[2017-11-02 10:45:58,490] A3C_AGENT_WORKER-Thread-6 INFO:Local step 23000, global step 363074: loss 90.8179
[2017-11-02 10:45:59,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 22500, global step 363428: loss 1.3622
[2017-11-02 10:45:59,662] A3C_AGENT_WORKER-Thread-9 INFO:Local step 22500, global step 363719: loss 16.3311
[2017-11-02 10:46:00,043] A3C_AGENT_WORKER-Thread-16 INFO:Local step 23000, global step 363888: loss 1.4877
[2017-11-02 10:46:00,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   6.52355236e-16   1.90361909e-15   1.38242308e-14
   1.27931291e-14   5.57122219e-35   2.86966751e-36   7.28138627e-37
   4.09747160e-37], sum to 1.0000
[2017-11-02 10:46:00,410] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 81.0, 0.75, 10.0, 0.0, 0.0, -1.0, 45.19611328663204, 18.0, 18.30837989682106, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 6903300.0000, 
raw observation next is [4.0, 81.0, 0.875, 11.66666666666667, 0.0, 0.0, -1.0, 45.7234792653293, 18.0, 18.3372342534063, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9130434782608695, 0.4358974358974359, 0.81, 0.07954545454545454, 0.03240740740740741, 0.0, 0.0, 0.48333333333333334, 0.45723479265329303, 0.0, 0.04817632191518584, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:00,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[ -98.24332428]
 [ -99.2071228 ]
 [ -99.61338806]
 [-100.86457825]
 [-100.74329376]], R is [[-101.00154877]
 [-100.99153137]
 [-100.98162079]
 [-100.97180176]
 [-100.96208191]].
[2017-11-02 10:46:02,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 23000, global step 364811: loss -19.6543
[2017-11-02 10:46:04,715] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.98434484e-01   1.08633564e-08   8.44674553e-10   4.55247751e-08
   1.05874122e-07   6.18002610e-04   6.34574535e-05   8.48222582e-04
   3.56899509e-05], sum to 1.0000
[2017-11-02 10:46:04,729] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.0, 75.0, 3.6, 80.0, 102.0, 0.0, 11.0, 21.23908090474331, 20.0, 21.6194731687406, 22.2, 1.0, 32.91565410796977], 
actual action is [1.0, 18], 
sim time next is 6879900.0000, 
raw observation next is [6.0, 76.0, 3.683333333333333, 80.83333333333333, 99.83333333333334, 0.0, 1.0, 21.61968448907701, 18.0, 21.63456069230265, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.48717948717948717, 0.76, 0.33484848484848484, 0.22453703703703703, 0.2641093474426808, 0.0, 0.5166666666666667, 0.2161968448907701, 0.0, 0.5192229560432357, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:05,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-110.20001984]
 [-111.65457916]
 [-111.20436859]
 [-111.76131439]
 [-112.61479187]], R is [[-109.35295105]
 [-109.2594223 ]
 [-109.16683197]
 [-109.07516479]
 [-108.98441315]].
[2017-11-02 10:46:05,184] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-113.85440063]
 [-118.3008728 ]
 [-111.47615051]
 [-111.21341705]
 [-110.50746155]], R is [[-115.27780914]
 [-115.12503052]
 [-114.97377777]
 [-114.82404327]
 [-114.67580414]].
[2017-11-02 10:46:07,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 23000, global step 366360: loss 699.8016
[2017-11-02 10:46:07,736] A3C_AGENT_WORKER-Thread-8 INFO:Local step 23000, global step 366543: loss 370.3983
[2017-11-02 10:46:07,809] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.00000000e+00   1.49205197e-11   2.34990742e-11   1.40246148e-10
   1.56064842e-10   3.21119873e-24   5.95338781e-26   6.39563494e-26
   1.45965306e-26], sum to 1.0000
[2017-11-02 10:46:07,820] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 79.5, 1.65, 20.0, 0.0, 0.0, -1.0, 37.61591158640623, 18.0, 19.44401395288551, 19.4, 0.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 6906000.0000, 
raw observation next is [4.0, 79.0, 1.7, 20.0, 0.0, 0.0, -1.0, 38.32964537233143, 18.0, 19.38471796406289, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.4358974358974359, 0.79, 0.15454545454545454, 0.05555555555555555, 0.0, 0.0, 0.48333333333333334, 0.3832964537233143, 0.0, 0.1978168520089843, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0022. 
=============================================
[2017-11-02 10:46:08,644] A3C_AGENT_WORKER-Thread-4 INFO:Local step 23000, global step 366843: loss 15.3593
[2017-11-02 10:46:10,620] A3C_AGENT_WORKER-Thread-7 INFO:Local step 23000, global step 367466: loss 269.5137
[2017-11-02 10:46:11,447] A3C_AGENT_WORKER-Thread-5 INFO:Local step 23000, global step 367778: loss 101.7625
[2017-11-02 10:46:11,626] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   2.43521168e-15   1.77718608e-15   1.40239442e-14
   1.55686350e-14   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:46:11,634] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.5, 78.0, 1.8, 40.0, 0.0, 0.0, -1.416666666666667, 43.70668497114338, 18.0, 18.69059709231362, 19.4, 0.0, 0.0], 
actual action is [-1.5, 18], 
sim time next is 6910500.0000, 
raw observation next is [3.416666666666667, 78.5, 1.75, 43.33333333333333, 0.0, 0.0, -1.5, 43.91179499054409, 18.0, 18.67496331862622, 19.4, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 1.0, 0.42094017094017094, 0.785, 0.1590909090909091, 0.12037037037037036, 0.0, 0.0, 0.475, 0.4391179499054409, 0.0, 0.09642333123231696, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:13,833] A3C_AGENT_WORKER-Thread-17 INFO:Local step 23000, global step 368602: loss 0.4207
[2017-11-02 10:46:14,999] A3C_AGENT_WORKER-Thread-13 INFO:Local step 23000, global step 369064: loss 30.5083
[2017-11-02 10:46:15,767] A3C_AGENT_WORKER-Thread-2 INFO:Local step 23000, global step 369279: loss 68.6805
[2017-11-02 10:46:16,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99858618e-01   3.34569989e-07   9.38642870e-08   2.12269401e-06
   3.22961796e-06   9.24084452e-06   5.90563322e-05   3.03653883e-06
   6.42421292e-05], sum to 1.0000
[2017-11-02 10:46:16,747] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.083333333333333, 86.5, 4.1, 80.83333333333333, 170.75, 0.0, 9.0, 21.68346664930505, 19.5, 21.08541157236147, 22.2, 1.0, 18.76256973413335], 
actual action is [-0.916666666666667, 18], 
sim time next is 6869400.0000, 
raw observation next is [4.166666666666667, 86.0, 4.1, 81.66666666666667, 175.0, 0.0, -0.916666666666667, 21.79565900134057, 18.0, 21.13614115050435, 22.2, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5217391304347826, 0.4401709401709402, 0.86, 0.3727272727272727, 0.22685185185185186, 0.46296296296296297, 0.0, 0.4847222222222222, 0.2179565900134057, 0.0, 0.44802016435776437, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:17,243] A3C_AGENT_WORKER-Thread-14 INFO:Local step 23000, global step 369918: loss 61.2455
[2017-11-02 10:46:18,025] A3C_AGENT_WORKER-Thread-15 INFO:Local step 23000, global step 370271: loss 40.2186
[2017-11-02 10:46:18,668] A3C_AGENT_WORKER-Thread-9 INFO:Local step 23000, global step 370596: loss 402.0614
[2017-11-02 10:46:18,870] A3C_AGENT_WORKER-Thread-6 INFO:Local step 23500, global step 370682: loss 3.3802
[2017-11-02 10:46:19,413] A3C_AGENT_WORKER-Thread-11 INFO:Local step 23000, global step 370917: loss -54.6825
[2017-11-02 10:46:20,231] A3C_AGENT_WORKER-Thread-12 INFO:Local step 23000, global step 371273: loss 55.4817
[2017-11-02 10:46:20,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 23500, global step 371556: loss 30.0115
[2017-11-02 10:46:22,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.00000000e+00   1.32995899e-16   5.80236429e-17   2.70221404e-16
   4.23641517e-16   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:46:22,057] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 2.516666666666667, 341.6666666666667, 0.0, 0.0, -2.0, 48.81060911976659, 18.0, 18.40812455281237, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 6933300.0000, 
raw observation next is [3.0, 87.0, 2.558333333333334, 340.8333333333333, 0.0, 0.0, -2.0, 49.34324424594212, 18.0, 18.36848004619216, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.41025641025641024, 0.87, 0.23257575757575763, 0.9467592592592592, 0.0, 0.0, 0.4666666666666667, 0.4934324424594212, 0.0, 0.052640006598880164, 0.1999999999999998, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:22,542] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   4.53909826e-10   1.23551269e-09   6.95536562e-09
   2.84386847e-09   6.43989805e-26   9.70230813e-26   1.72805201e-27
   9.17618412e-27], sum to 1.0000
[2017-11-02 10:46:22,550] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.0, 87.0, 2.166666666666667, 250.0, 0.0, 0.0, 3.0, 24.62482312844694, 18.0, 20.3488870456795, 22.2, 1.0, 0.0], 
actual action is [3.0, 18], 
sim time next is 7004400.0000, 
raw observation next is [8.0, 87.0, 2.033333333333333, 250.0, 0.0, 0.0, 3.0, 24.75069932269134, 18.0, 20.33135504356242, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.5384615384615384, 0.87, 0.18484848484848485, 0.6944444444444444, 0.0, 0.0, 0.55, 0.24750699322691339, 0.0, 0.3330507205089174, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:22,702] A3C_AGENT_WORKER-Thread-10 INFO:Local step 23500, global step 372290: loss 10.4236
[2017-11-02 10:46:26,778] A3C_AGENT_WORKER-Thread-3 INFO:Local step 23500, global step 373887: loss 8.8891
[2017-11-02 10:46:27,385] A3C_AGENT_WORKER-Thread-8 INFO:Local step 23500, global step 374116: loss 4.0659
[2017-11-02 10:46:28,690] A3C_AGENT_WORKER-Thread-4 INFO:Local step 23500, global step 374551: loss 5.3379
[2017-11-02 10:46:28,924] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   9.94446754e-01   2.75123492e-03   2.74251658e-03
   5.95561396e-05], sum to 1.0000
[2017-11-02 10:46:28,949] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [13.0, 67.0, 2.1, 100.8333333333333, 264.0833333333334, 445.75, 18.0, 9.02736208385367, 25.0, 25.91868153676583, 22.2, 1.0, 3.624872640941602], 
actual action is [18.0, 25], 
sim time next is 7052400.0000, 
raw observation next is [13.0, 67.0, 2.1, 80.0, 252.5, 476.5, 18.0, 9.229462845695009, 25.0, 25.96289130377827, 22.2, 1.0, 3.434849068178862], 
processed observation next is [0.5, 0.6521739130434783, 0.6666666666666666, 0.67, 0.19090909090909092, 0.2222222222222222, 0.667989417989418, 0.4765, 0.8, 0.09229462845695009, 1.0, 1.137555900539753, 0.5999999999999999, 1.0, 0.040409989037398376], 
reward next is -0.0456. 
=============================================
[2017-11-02 10:46:29,715] A3C_AGENT_WORKER-Thread-7 INFO:Local step 23500, global step 374929: loss 0.3496
[2017-11-02 10:46:32,061] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99943495e-01   8.80202333e-06   1.90676883e-06   2.82931001e-06
   5.40047449e-06   3.59484584e-05   1.01918806e-06   4.79524147e-07
   1.21446362e-07], sum to 1.0000
[2017-11-02 10:46:32,073] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 87.0, 2.1, 90.0, 0.0, 0.0, 2.083333333333333, 15.8831535460001, 18.0, 20.85275814271414, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7095900.0000, 
raw observation next is [6.999999999999999, 87.0, 2.1, 87.5, 0.0, 0.0, 2.0, 16.07157658516075, 18.0, 20.82274357121727, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5128205128205128, 0.87, 0.19090909090909092, 0.24305555555555555, 0.0, 0.0, 0.5333333333333333, 0.1607157658516075, 0.0, 0.40324908160246714, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:46:32,669] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99939919e-01   2.49059976e-05   1.18874677e-05   1.32962787e-05
   1.00224779e-05   1.95068872e-09   1.17080068e-10   4.56300622e-11
   4.76307101e-12], sum to 1.0000
[2017-11-02 10:46:32,683] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.666666666666668, 83.0, 0.7, 23.33333333333333, 0.0, 0.0, 3.75, 10.50238091150198, 18.0, 22.02384311725401, 22.2, 1.0, 0.0], 
actual action is [3.666666666666668, 18], 
sim time next is 7086300.0000, 
raw observation next is [8.583333333333332, 83.5, 0.8750000000000001, 29.16666666666667, 0.0, 0.0, 3.666666666666668, 10.61602184596839, 18.0, 21.99388361528633, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.0, 0.5534188034188033, 0.835, 0.07954545454545456, 0.08101851851851853, 0.0, 0.0, 0.5611111111111112, 0.1061602184596839, 0.0, 0.5705548021837613, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0106. 
=============================================
[2017-11-02 10:46:33,067] A3C_AGENT_WORKER-Thread-5 INFO:Local step 23500, global step 376467: loss 0.6631
[2017-11-02 10:46:33,182] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.38400052e-25   4.82177877e-21   1.09838089e-22   2.85961018e-22
   1.27846327e-21   9.50268269e-01   2.83803493e-02   1.92535706e-02
   2.09788606e-03], sum to 1.0000
[2017-11-02 10:46:33,206] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [11.0, 71.0, 0.0, 0.0, 48.33333333333334, 201.0, 16.0, 7.884319953577074, 25.0, 24.79650222003436, 22.2, 1.0, 3.287610408569517], 
actual action is [16.0, 25], 
sim time next is 6976500.0000, 
raw observation next is [11.0, 71.0, 0.0, 0.0, 42.41666666666666, 178.75, 16.0, 7.808708594612864, 25.0, 24.73164145073931, 22.2, 1.0, 3.068237000782201], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.6153846153846154, 0.71, 0.0, 0.0, 0.11221340388007052, 0.17875, 0.7666666666666667, 0.07808708594612863, 1.0, 0.9616630643913301, 0.5999999999999999, 1.0, 0.03609690589155531], 
reward next is -0.0403. 
=============================================
[2017-11-02 10:46:33,480] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99954343e-01   1.77319998e-05   2.93326320e-06   4.98143299e-06
   9.71040663e-06   9.56365329e-06   4.95098618e-07   1.77380713e-07
   6.35081463e-08], sum to 1.0000
[2017-11-02 10:46:33,504] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.083333333333333, 87.0, 3.1, 110.8333333333333, 63.33333333333334, 287.25, 2.0, 20.94877794008844, 18.0, 20.18930181937206, 19.4, 0.0, 0.0], 
actual action is [2.083333333333333, 18], 
sim time next is 7110600.0000, 
raw observation next is [7.166666666666667, 87.0, 3.1, 111.6666666666667, 71.66666666666669, 310.0, 2.083333333333333, 19.75693569880101, 18.0, 20.29515902218029, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.5170940170940171, 0.87, 0.2818181818181818, 0.3101851851851853, 0.18959435626102297, 0.31, 0.5347222222222222, 0.1975693569880101, 0.0, 0.32787986031146993, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:46:33,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 23500, global step 376929: loss 1.6836
[2017-11-02 10:46:34,895] A3C_AGENT_WORKER-Thread-6 INFO:Local step 24000, global step 377324: loss 0.9788
[2017-11-02 10:46:35,766] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-24.79932404]
 [-24.39108276]
 [-25.12760735]
 [-24.14592743]
 [-23.2800312 ]], R is [[-23.55336189]
 [-23.36631203]
 [-23.16399193]
 [-22.96359253]
 [-22.76524734]].
[2017-11-02 10:46:36,575] A3C_AGENT_WORKER-Thread-2 INFO:Local step 23500, global step 378081: loss -3.7486
[2017-11-02 10:46:37,640] A3C_AGENT_WORKER-Thread-13 INFO:Local step 23500, global step 378594: loss -2.1890
[2017-11-02 10:46:37,782] A3C_AGENT_WORKER-Thread-14 INFO:Local step 23500, global step 378661: loss -13.3876
[2017-11-02 10:46:38,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 23500, global step 378947: loss 0.6639
[2017-11-02 10:46:38,961] A3C_AGENT_WORKER-Thread-9 INFO:Local step 23500, global step 379289: loss 0.0816
[2017-11-02 10:46:38,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 24000, global step 379310: loss 0.4413
[2017-11-02 10:46:39,456] A3C_AGENT_WORKER-Thread-11 INFO:Local step 23500, global step 379563: loss 0.2753
[2017-11-02 10:46:39,975] A3C_AGENT_WORKER-Thread-10 INFO:Local step 24000, global step 379845: loss 0.1760
[2017-11-02 10:46:40,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.94254053e-01   2.70137028e-03   1.56689610e-03   1.45641781e-04
   1.33212260e-03   2.05413839e-10   3.12965515e-10   7.12006634e-11
   1.25519482e-11], sum to 1.0000
[2017-11-02 10:46:40,084] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.0, 72.66666666666666, 0.5, 3.333333333333334, 0.0, 0.0, 6.0, 7.147132948537422, 18.0, 23.45075359461401, 22.2, 1.0, 0.0], 
actual action is [6.0, 18], 
sim time next is 7073100.0000, 
raw observation next is [11.0, 72.25, 0.375, 2.5, 0.0, 0.0, 6.0, 7.146587102195141, 18.0, 23.42089793552109, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.6153846153846154, 0.7225, 0.03409090909090909, 0.006944444444444444, 0.0, 0.0, 0.6, 0.0714658710219514, 0.0, 0.7744139907887272, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0071. 
=============================================
[2017-11-02 10:46:40,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 23500, global step 380036: loss 0.4176
[2017-11-02 10:46:41,107] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.82212007e-01   1.10378200e-02   2.31502997e-03   1.33749199e-04
   4.30135243e-03   5.78196879e-10   6.28211205e-10   1.45867970e-10
   1.84330294e-11], sum to 1.0000
[2017-11-02 10:46:41,119] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.0, 67.0, 3.600000000000001, 160.0, 0.0, 0.0, 9.0, 9.95916810274243, 18.0, 25.26014000049365, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7169100.0000, 
raw observation next is [14.0, 67.0, 3.6, 160.0, 0.0, 0.0, 9.0, 9.881454110916634, 18.0, 25.23977094107637, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.6923076923076923, 0.67, 0.32727272727272727, 0.4444444444444444, 0.0, 0.0, 0.65, 0.09881454110916633, 0.0, 1.0342529915823384, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0099. 
=============================================
[2017-11-02 10:46:41,828] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.71375346e-01   1.66586936e-02   3.85188102e-03   3.40369559e-04
   7.77365547e-03   2.72316525e-09   3.28907768e-09   6.33060382e-10
   1.21187269e-10], sum to 1.0000
[2017-11-02 10:46:41,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.0, 87.0, 2.1, 85.0, 0.0, 0.0, 1.999999999999999, 13.14183225619153, 18.0, 21.48271885142575, 22.2, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7096500.0000, 
raw observation next is [7.0, 87.0, 2.1, 82.5, 0.0, 0.0, 2.0, 13.29233242545056, 18.0, 21.45422622067127, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.5128205128205128, 0.87, 0.19090909090909092, 0.22916666666666666, 0.0, 0.0, 0.5333333333333333, 0.1329233242545056, 0.0, 0.4934608886673243, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0133. 
=============================================
[2017-11-02 10:46:43,088] A3C_AGENT_WORKER-Thread-3 INFO:Local step 24000, global step 381679: loss 0.0109
[2017-11-02 10:46:43,870] A3C_AGENT_WORKER-Thread-8 INFO:Local step 24000, global step 382128: loss 0.3686
[2017-11-02 10:46:44,730] A3C_AGENT_WORKER-Thread-7 INFO:Local step 24000, global step 382624: loss 0.1480
[2017-11-02 10:46:44,751] A3C_AGENT_WORKER-Thread-4 INFO:Local step 24000, global step 382632: loss 0.4165
[2017-11-02 10:46:46,226] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.97319758e-01   2.43913545e-03   3.54592521e-06   1.16554554e-06
   2.36344989e-04   5.34253674e-12   4.83719662e-12   4.42331024e-12
   2.37508906e-13], sum to 1.0000
[2017-11-02 10:46:46,245] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333333, 60.66666666666667, 7.483333333333333, 231.6666666666667, 356.5833333333333, 360.6666666666667, 16.66666666666667, 12.19511760912652, 18.0, 26.43547760398531, 22.2, 1.0, 0.0], 
actual action is [16.83333333333333, 18], 
sim time next is 7214400.0000, 
raw observation next is [22.0, 60.0, 7.7, 230.0, 359.5, 352.0, 16.83333333333333, 12.32406685444405, 18.0, 26.4559634610458, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.8974358974358975, 0.6, 0.7000000000000001, 0.6388888888888888, 0.951058201058201, 0.352, 0.7805555555555554, 0.1232406685444405, 0.0, 1.2079947801494002, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0123. 
=============================================
[2017-11-02 10:46:47,427] A3C_AGENT_WORKER-Thread-5 INFO:Local step 24000, global step 384114: loss 0.4807
[2017-11-02 10:46:47,960] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-6.10933113]
 [-6.31583118]
 [-5.99641705]
 [-6.42991543]
 [-6.84621906]], R is [[-6.24689579]
 [-6.19202042]
 [-6.13762426]
 [-6.08370972]
 [-6.03026867]].
[2017-11-02 10:46:48,233] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  5.99755824e-01   2.22181767e-01   3.88558544e-02   2.12461427e-02
   1.17960252e-01   7.00987854e-08   4.00753919e-08   2.99647418e-08
   6.18140428e-09], sum to 1.0000
[2017-11-02 10:46:48,248] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.83333333333333, 43.5, 2.600000000000001, 193.3333333333333, 0.0, 0.0, 5.91666666666667, 8.602955215292472, 18.0, 22.24382580983583, 20.56, 1.0, 0.0], 
actual action is [5.83333333333333, 18], 
sim time next is 7334100.0000, 
raw observation next is [10.75, 43.75, 2.6, 195.0, 0.0, 0.0, 5.83333333333333, 8.70536811595947, 18.0, 22.21323758842093, 20.56, 1.0, 0.0], 
processed observation next is [1.0, 0.9130434782608695, 0.6089743589743589, 0.4375, 0.23636363636363636, 0.5416666666666666, 0.0, 0.0, 0.5972222222222221, 0.08705368115959469, 0.0, 0.601891084060133, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0087. 
=============================================
[2017-11-02 10:46:48,669] A3C_AGENT_WORKER-Thread-17 INFO:Local step 24000, global step 384810: loss 1.4890
[2017-11-02 10:46:49,602] A3C_AGENT_WORKER-Thread-6 INFO:Local step 24500, global step 385362: loss 22.2722
[2017-11-02 10:46:50,127] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.43050471e-01   3.83897901e-01   9.77259204e-02   5.35955727e-02
   2.21729219e-01   4.16563410e-07   2.82940334e-07   2.04063426e-07
   4.39433236e-08], sum to 1.0000
[2017-11-02 10:46:50,170] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [13.58333333333333, 47.0, 5.475, 298.3333333333334, 0.0, 0.0, 8.66666666666667, 7.101332433113134, 18.0, 24.48597039509069, 20.56, 1.0, 0.0], 
actual action is [8.58333333333333, 18], 
sim time next is 7255800.0000, 
raw observation next is [13.5, 47.0, 5.65, 300.0, 0.0, 0.0, 8.58333333333333, 7.031825326503093, 18.0, 24.45730771971202, 20.56, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.6794871794871795, 0.47, 0.5136363636363637, 0.8333333333333334, 0.0, 0.0, 0.6430555555555555, 0.07031825326503094, 0.0, 0.9224725313874315, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0070. 
=============================================
[2017-11-02 10:46:50,603] A3C_AGENT_WORKER-Thread-2 INFO:Local step 24000, global step 385970: loss -0.0141
[2017-11-02 10:46:50,645] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-1.05650461]
 [-1.16961372]
 [-1.15774143]
 [-0.87389672]
 [-1.02047813]], R is [[-1.1796819 ]
 [-1.1747303 ]
 [-1.16977668]
 [-1.16481721]
 [-1.1598562 ]].
[2017-11-02 10:46:50,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  3.35742921e-01   3.51378053e-01   9.12646949e-02   5.09128459e-02
   1.70700133e-01   5.94533276e-07   3.75904108e-07   2.67044442e-07
   5.82666821e-08], sum to 1.0000
[2017-11-02 10:46:50,804] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [14.0, 67.0, 4.6, 184.1666666666667, 0.0, 0.0, 9.0, 6.226587474624503, 18.0, 22.79792314518868, 22.2, 1.0, 0.0], 
actual action is [9.0, 18], 
sim time next is 7188000.0000, 
raw observation next is [14.0, 67.0, 4.6, 183.3333333333333, 0.0, 0.0, 9.0, 6.247527790996812, 18.0, 22.78444205473844, 22.2, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.17391304347826086, 0.6923076923076923, 0.67, 0.41818181818181815, 0.5092592592592591, 0.0, 0.0, 0.65, 0.06247527790996812, 0.0, 0.6834917221054917, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0062. 
=============================================
[2017-11-02 10:46:51,855] A3C_AGENT_WORKER-Thread-13 INFO:Local step 24000, global step 386754: loss 0.2582
[2017-11-02 10:46:51,902] A3C_AGENT_WORKER-Thread-14 INFO:Local step 24000, global step 386784: loss -0.3379
[2017-11-02 10:46:51,942] A3C_AGENT_WORKER-Thread-15 INFO:Local step 24000, global step 386813: loss -1.0728
[2017-11-02 10:46:52,957] A3C_AGENT_WORKER-Thread-11 INFO:Local step 24000, global step 387413: loss 0.3419
[2017-11-02 10:46:53,028] A3C_AGENT_WORKER-Thread-9 INFO:Local step 24000, global step 387450: loss -0.3087
[2017-11-02 10:46:53,227] A3C_AGENT_WORKER-Thread-16 INFO:Local step 24500, global step 387568: loss -5.4232
[2017-11-02 10:46:53,669] A3C_AGENT_WORKER-Thread-12 INFO:Local step 24000, global step 387815: loss 0.3443
[2017-11-02 10:46:53,786] A3C_AGENT_WORKER-Thread-10 INFO:Local step 24500, global step 387880: loss -7.1923
[2017-11-02 10:46:56,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[-12.3452177 ]
 [ -4.64176846]
 [ -5.31040573]
 [ -3.6302166 ]
 [ -3.52752447]], R is [[-7.67579556]
 [-7.61211729]
 [-7.5488863 ]
 [-7.48610258]
 [-7.42377377]].
[2017-11-02 10:46:56,646] A3C_AGENT_WORKER-Thread-3 INFO:Local step 24500, global step 389559: loss 0.8556
[2017-11-02 10:46:57,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.95933744e-01   6.76548302e-01   2.91251708e-02   1.33907516e-02
   8.49750713e-02   1.17397713e-05   7.50015170e-06   6.46149147e-06
   1.14479280e-06], sum to 1.0000
[2017-11-02 10:46:57,742] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [11.91666666666667, 43.91666666666666, 7.533333333333334, 300.0, 148.4166666666667, 867.25, 6.83333333333333, 7.295784744100931, 18.0, 22.84088683850992, 22.2, 1.0, 0.0], 
actual action is [6.91666666666667, 18], 
sim time next is 7300800.0000, 
raw observation next is [12.0, 44.0, 7.7, 300.0, 148.5, 868.5, 6.91666666666667, 7.29262101580319, 18.0, 22.83588519347917, 22.2, 1.0, 0.0], 
processed observation next is [1.0, 0.5217391304347826, 0.6410256410256411, 0.44, 0.7000000000000001, 0.8333333333333334, 0.39285714285714285, 0.8685, 0.6152777777777778, 0.0729262101580319, 0.0, 0.690840741925596, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0073. 
=============================================
[2017-11-02 10:46:57,774] A3C_AGENT_WORKER-Thread-8 INFO:Local step 24500, global step 390215: loss -3.6875
[2017-11-02 10:46:58,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.86134785e-01   4.84043479e-01   1.21027835e-01   8.77938047e-02
   1.21000133e-01   4.16413952e-11   3.15401941e-11   2.45088672e-11
   6.09004297e-12], sum to 1.0000
[2017-11-02 10:46:58,675] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [9.25, 84.25, 4.05, 287.5, 99.25, 11.0, 4.166666666666666, 13.56919302240943, 18.0, 21.33169837093581, 20.56, 1.0, 0.0], 
actual action is [4.25, 18], 
sim time next is 7406400.0000, 
raw observation next is [9.333333333333334, 83.33333333333334, 4.033333333333333, 290.0, 91.16666666666666, 9.0, 4.25, 13.86003123871515, 18.0, 21.2394085762173, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 0.7391304347826086, 0.5726495726495727, 0.8333333333333335, 0.36666666666666664, 0.8055555555555556, 0.2411816578483245, 0.009, 0.5708333333333333, 0.1386003123871515, 0.0, 0.46277265374532867, 0.36571428571428555, 1.0, 0.0], 
reward next is -0.0139. 
=============================================
[2017-11-02 10:46:58,745] A3C_AGENT_WORKER-Thread-7 INFO:Local step 24500, global step 390785: loss 18.0435
[2017-11-02 10:46:58,837] A3C_AGENT_WORKER-Thread-4 INFO:Local step 24500, global step 390847: loss 91.8811
[2017-11-02 10:47:01,391] A3C_AGENT_WORKER-Thread-5 INFO:Local step 24500, global step 392281: loss 302.1888
[2017-11-02 10:47:02,371] A3C_AGENT_WORKER-Thread-17 INFO:Local step 24500, global step 392860: loss 161.0727
[2017-11-02 10:47:03,811] A3C_AGENT_WORKER-Thread-2 INFO:Local step 24500, global step 393671: loss 81.3211
[2017-11-02 10:47:04,824] A3C_AGENT_WORKER-Thread-6 INFO:Local step 25000, global step 394200: loss -2.3943
[2017-11-02 10:47:05,336] A3C_AGENT_WORKER-Thread-15 INFO:Local step 24500, global step 394469: loss 33.8532
[2017-11-02 10:47:05,356] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-34.24597931]
 [-34.58935928]
 [-25.6813755 ]
 [-32.46544647]
 [-33.18928909]], R is [[-34.82800293]
 [-35.47972488]
 [-36.12492752]
 [-36.7636795 ]
 [-37.39604187]].
[2017-11-02 10:47:05,400] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  2.86279432e-03   4.50145677e-02   6.52183533e-01   1.77900884e-02
   2.82149047e-01   2.28861172e-38   1.00039039e-35   1.26084374e-37
   4.64884088e-36], sum to 1.0000
[2017-11-02 10:47:05,413] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.0, 56.0, 2.6, 290.0, 0.0, 0.0, 2.0, 30.68832568278067, 18.0, 19.0054951556784, 20.56, 1.0, 0.0], 
actual action is [2.0, 18], 
sim time next is 7427100.0000, 
raw observation next is [6.916666666666666, 56.33333333333333, 2.558333333333333, 285.0, 0.0, 0.0, 2.0, 30.77032637752347, 18.0, 18.98511523055393, 20.56, 1.0, 0.0], 
processed observation next is [0.0, 1.0, 0.5106837606837606, 0.5633333333333332, 0.23257575757575755, 0.7916666666666666, 0.0, 0.0, 0.5333333333333333, 0.3077032637752347, 0.0, 0.14073074722199003, 0.36571428571428555, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:05,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.72665886e-04   8.72779191e-02   6.36571646e-01   5.90876415e-02
   2.16490075e-01   1.24597695e-21   9.20066468e-20   5.51279649e-21
   7.41734794e-20], sum to 1.0000
[2017-11-02 10:47:05,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [5.333333333333333, 66.33333333333334, 3.433333333333334, 160.0, 0.0, 0.0, 0.5, 15.59633529334751, 18.0, 20.74627493269815, 22.2, 1.0, 0.0], 
actual action is [0.33333333333333304, 18], 
sim time next is 7349100.0000, 
raw observation next is [5.166666666666666, 66.66666666666666, 3.391666666666667, 160.0, 0.0, 0.0, 0.333333333333333, 15.80738645941847, 18.0, 20.71498515511003, 22.2, 1.0, 0.0], 
processed observation next is [0.0, 0.043478260869565216, 0.46581196581196577, 0.6666666666666665, 0.30833333333333335, 0.4444444444444444, 0.0, 0.0, 0.5055555555555555, 0.1580738645941847, 0.0, 0.3878550221585755, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:06,033] A3C_AGENT_WORKER-Thread-14 INFO:Local step 24500, global step 394834: loss -0.5254
[2017-11-02 10:47:06,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 24500, global step 394853: loss 91.2759
[2017-11-02 10:47:06,712] A3C_AGENT_WORKER-Thread-11 INFO:Local step 24500, global step 395169: loss 20.5301
[2017-11-02 10:47:06,955] A3C_AGENT_WORKER-Thread-9 INFO:Local step 24500, global step 395301: loss 39.2570
[2017-11-02 10:47:07,814] A3C_AGENT_WORKER-Thread-12 INFO:Local step 24500, global step 395765: loss -11.7198
[2017-11-02 10:47:08,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  4.58855629e-01   5.18525422e-01   5.63442055e-03   6.37005956e-04
   1.63475815e-02   6.31876260e-23   3.00367739e-22   1.05339626e-23
   1.97908525e-23], sum to 1.0000
[2017-11-02 10:47:08,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 57.0, 5.1, 150.0, 99.5, 13.5, 3.75, 17.35202221094697, 18.0, 20.90182666704645, 19.4, 0.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 7373100.0000, 
raw observation next is [9.166666666666666, 56.41666666666666, 4.975, 149.1666666666667, 99.08333333333333, 11.25, 4.0, 17.21897239910939, 18.0, 20.88336761764325, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.34782608695652173, 0.5683760683760684, 0.5641666666666666, 0.4522727272727272, 0.41435185185185197, 0.2621252204585538, 0.01125, 0.5666666666666667, 0.1721897239910939, 0.0, 0.4119096596633212, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:08,832] A3C_AGENT_WORKER-Thread-10 INFO:Local step 25000, global step 396215: loss -22.8499
[2017-11-02 10:47:10,531] A3C_AGENT_WORKER-Thread-16 INFO:Local step 25000, global step 396810: loss -0.0477
[2017-11-02 10:47:10,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  7.09453940e-01   1.78853288e-01   5.47823943e-02   1.42158074e-02
   4.26945277e-02   2.44959913e-10   3.55947161e-10   3.84807325e-11
   2.04519370e-11], sum to 1.0000
[2017-11-02 10:47:10,847] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.0, 59.5, 3.775, 225.8333333333333, 175.1666666666667, 5.0, 4.0, 13.12598601403285, 18.0, 21.74460457208507, 19.4, 0.0, 0.0], 
actual action is [4.0, 18], 
sim time next is 7395000.0000, 
raw observation next is [9.0, 62.0, 3.95, 231.6666666666667, 165.3333333333333, 3.999999999999999, 4.0, 13.3130415535141, 18.0, 21.6910248296874, 19.4, 0.0, 0.0], 
processed observation next is [0.0, 0.6086956521739131, 0.5641025641025641, 0.62, 0.3590909090909091, 0.6435185185185186, 0.4373897707231039, 0.003999999999999999, 0.5666666666666667, 0.13313041553514102, 0.0, 0.5272892613839143, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:14,134] A3C_AGENT_WORKER-Thread-3 INFO:Local step 25000, global step 398381: loss -149.9581
[2017-11-02 10:47:15,808] A3C_AGENT_WORKER-Thread-8 INFO:Local step 25000, global step 398827: loss -23.8512
[2017-11-02 10:47:16,142] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.26968827e-23   5.42671796e-10   7.21805601e-11   3.57026583e-12
   1.27799146e-10   9.06699598e-01   6.52097538e-02   6.48943149e-03
   2.16012392e-02], sum to 1.0000
[2017-11-02 10:47:16,162] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [2.0, 87.0, 5.191666666666666, 269.1666666666667, 0.0, 0.0, 7.0, 22.82908239569132, 18.5, 20.2721863977687, 19.4, 0.0, 18.61982264252296], 
actual action is [7.0, 19.0], 
sim time next is 7513200.0000, 
raw observation next is [2.0, 87.0, 5.1, 270.0, 0.0, 0.0, 7.0, 22.92873182488995, 19.0, 20.25018918217951, 19.4, 0.0, 10.66233997136737], 
processed observation next is [0.16666666666666666, 1.0, 0.38461538461538464, 0.87, 0.4636363636363636, 0.75, 0.0, 0.0, 0.6166666666666667, 0.2292873182488995, 0.14285714285714285, 0.32145559745421587, 0.1999999999999998, 0.0, 0.12543929378079258], 
reward next is -0.1129. 
=============================================
[2017-11-02 10:47:16,374] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.24589251e-28   3.50501335e-31   2.78041354e-32
   6.52446836e-30   9.18914914e-01   6.34014979e-02   1.34086311e-02
   4.27494477e-03], sum to 1.0000
[2017-11-02 10:47:16,449] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [6.0, 70.0, 3.1, 210.0, 201.3333333333333, 0.0, 11.0, 6.638302629620981, 25.0, 24.38177569174166, 22.2, 1.0, 35.35151078587441], 
actual action is [11.0, 25], 
sim time next is 7467900.0000, 
raw observation next is [6.0, 70.0, 3.1, 210.0, 207.1666666666667, 0.0, 11.0, 6.636479154592812, 25.0, 24.44025763673696, 22.2, 1.0, 34.59141018244124], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.48717948717948717, 0.7, 0.2818181818181818, 0.5833333333333334, 0.5480599647266315, 0.0, 0.6833333333333333, 0.06636479154592811, 1.0, 0.920036805248137, 0.5999999999999999, 1.0, 0.4069577668522498], 
reward next is -0.3729. 
=============================================
[2017-11-02 10:47:17,465] A3C_AGENT_WORKER-Thread-4 INFO:Local step 25000, global step 399299: loss 1.9157
[2017-11-02 10:47:18,387] A3C_AGENT_WORKER-Thread-7 INFO:Local step 25000, global step 399538: loss 0.2925
[2017-11-02 10:47:22,217] A3C_AGENT_WORKER-Thread-5 INFO:Local step 25000, global step 400489: loss 1.6295
[2017-11-02 10:47:22,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.29166050e-21   4.63655503e-11   1.44324093e-12   2.83671090e-13
   6.24109184e-12   2.88919300e-01   5.33646584e-01   4.85640317e-02
   1.28870085e-01], sum to 1.0000
[2017-11-02 10:47:22,494] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [8.0, 87.0, 4.449999999999999, 233.3333333333333, 67.33333333333333, 0.0, 13.0, 6.617090919489502, 20.0, 24.35806808832734, 22.2, 1.0, 33.51615419261191], 
actual action is [13.0, 20.5], 
sim time next is 7492500.0000, 
raw observation next is [8.0, 87.0, 4.625, 235.0, 64.0, 0.0, 13.0, 6.611362411320669, 20.5, 24.3333447849402, 22.2, 1.0, 27.47805170772794], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.5384615384615384, 0.87, 0.42045454545454547, 0.6527777777777778, 0.1693121693121693, 0.0, 0.7166666666666667, 0.06611362411320669, 0.35714285714285715, 0.9047635407057426, 0.5999999999999999, 1.0, 0.32327119656150516], 
reward next is -0.2976. 
=============================================
[2017-11-02 10:47:23,451] A3C_AGENT_WORKER-Thread-17 INFO:Local step 25000, global step 400977: loss -1.9576
[2017-11-02 10:47:23,565] A3C_AGENT_WORKER-Thread-2 INFO:Local step 25000, global step 401040: loss 14.4863
[2017-11-02 10:47:25,731] A3C_AGENT_WORKER-Thread-13 INFO:Local step 25000, global step 402260: loss -5.3570
[2017-11-02 10:47:25,815] A3C_AGENT_WORKER-Thread-9 INFO:Local step 25000, global step 402314: loss -3.4844
[2017-11-02 10:47:26,283] A3C_AGENT_WORKER-Thread-14 INFO:Local step 25000, global step 402593: loss 0.2932
[2017-11-02 10:47:26,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 25000, global step 402627: loss 5.8060
[2017-11-02 10:47:26,711] A3C_AGENT_WORKER-Thread-6 INFO:Local step 25500, global step 402841: loss 4.0379
[2017-11-02 10:47:26,856] A3C_AGENT_WORKER-Thread-12 INFO:Local step 25000, global step 402932: loss 8.0644
[2017-11-02 10:47:26,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  3.31439137e-01   6.14953816e-01   4.18802118e-03   3.31178424e-03
   4.61072885e-02   2.59107577e-24   2.72280942e-24   7.52232799e-26
   2.89480077e-25], sum to 1.0000
[2017-11-02 10:47:26,917] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.0, 87.0, 7.825, 240.0, 0.0, 0.0, -2.0, 39.07683540357812, 18.0, 18.7472430729463, 19.4, 0.0, 0.0], 
actual action is [-2.0, 18], 
sim time next is 7539600.0000, 
raw observation next is [3.0, 87.0, 7.866666666666667, 240.0, 0.0, 0.0, -2.0, 39.26668372808896, 18.0, 18.74021533578814, 19.4, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.41025641025641024, 0.87, 0.7151515151515152, 0.6666666666666666, 0.0, 0.0, 0.4666666666666667, 0.3926668372808896, 0.0, 0.10574504796973423, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0943. 
=============================================
[2017-11-02 10:47:26,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 25000, global step 403002: loss 7.3788
[2017-11-02 10:47:29,501] A3C_AGENT_WORKER-Thread-10 INFO:Local step 25500, global step 404385: loss 5.2155
[2017-11-02 10:47:30,301] A3C_AGENT_WORKER-Thread-16 INFO:Local step 25500, global step 404812: loss -1.4542
[2017-11-02 10:47:32,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.86172736e-01   1.14423232e-02   2.63555685e-05   3.97677613e-05
   2.31883908e-03   4.68087421e-20   1.19118816e-19   1.97663095e-20
   8.66426908e-20], sum to 1.0000
[2017-11-02 10:47:32,913] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.75, 67.0, 9.15, 260.0, 261.75, 12.0, 2.666666666666666, 17.64764763567465, 18.0, 22.21943775457174, 22.2, 1.0, 0.0], 
actual action is [2.75, 18], 
sim time next is 7559400.0000, 
raw observation next is [7.833333333333334, 66.66666666666666, 9.200000000000001, 260.0, 262.3333333333333, 12.0, 2.75, 17.73210382030184, 18.0, 22.17624778873603, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.5341880341880343, 0.6666666666666665, 0.8363636363636364, 0.7222222222222222, 0.6940035273368607, 0.012, 0.5458333333333333, 0.17732103820301842, 0.0, 0.5966068269622902, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:33,085] A3C_AGENT_WORKER-Thread-8 INFO:Local step 25500, global step 405897: loss 3.5334
[2017-11-02 10:47:33,530] A3C_AGENT_WORKER-Thread-3 INFO:Local step 25500, global step 406090: loss 5.3241
[2017-11-02 10:47:34,647] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-13.36867237]
 [-15.3968544 ]
 [-15.86459732]
 [-16.4753952 ]
 [-17.50876427]], R is [[-14.98627949]
 [-14.84989643]
 [-14.71471405]
 [-14.58068657]
 [-14.44784832]].
[2017-11-02 10:47:34,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.55467796e-01   9.27301943e-02   6.86658360e-03   7.44496798e-03
   3.74904051e-02   2.29959454e-12   4.87017371e-12   8.07825107e-13
   1.01565447e-12], sum to 1.0000
[2017-11-02 10:47:34,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.83333333333333, 43.5, 5.016666666666667, 320.8333333333333, 82.16666666666666, 561.5833333333333, 6.0, 7.495216944191146, 18.0, 24.56462795118853, 22.2, 1.0, 0.0], 
actual action is [5.83333333333333, 18], 
sim time next is 7665000.0000, 
raw observation next is [10.66666666666667, 44.0, 4.933333333333334, 321.6666666666667, 79.33333333333333, 545.6666666666666, 5.83333333333333, 7.520566372485709, 18.0, 24.45106730257907, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.606837606837607, 0.44, 0.4484848484848485, 0.8935185185185186, 0.20987654320987653, 0.5456666666666666, 0.5972222222222221, 0.07520566372485708, 0.0, 0.9215810432255813, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0075. 
=============================================
[2017-11-02 10:47:35,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.05681729e-01   6.90587386e-02   2.17648805e-03   3.09653021e-03
   1.99865345e-02   7.83926396e-12   1.63878650e-11   2.07517055e-12
   2.48266902e-12], sum to 1.0000
[2017-11-02 10:47:35,191] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.916666666666666, 54.25, 8.075, 270.8333333333334, 147.1666666666667, 193.0, 4.833333333333334, 11.38502538514715, 18.0, 23.28573110867293, 22.2, 1.0, 0.0], 
actual action is [4.916666666666666, 18], 
sim time next is 7578000.0000, 
raw observation next is [10.0, 54.0, 8.2, 270.0, 140.0, 213.0, 4.916666666666666, 11.36488090832387, 18.0, 23.26653284731316, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.5897435897435898, 0.54, 0.7454545454545454, 0.75, 0.37037037037037035, 0.213, 0.5819444444444444, 0.11364880908323871, 0.0, 0.7523618353304516, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0114. 
=============================================
[2017-11-02 10:47:35,223] A3C_AGENT_WORKER-Thread-7 INFO:Local step 25500, global step 406964: loss -0.0107
[2017-11-02 10:47:35,425] A3C_AGENT_WORKER-Thread-4 INFO:Local step 25500, global step 407065: loss 0.3578
[2017-11-02 10:47:35,893] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.10509944e-01   5.85597306e-02   3.81010212e-03   5.22673922e-03
   2.18935292e-02   6.16147133e-10   8.98090768e-10   1.27288929e-10
   8.61595378e-11], sum to 1.0000
[2017-11-02 10:47:35,921] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.33333333333333, 49.0, 4.533333333333334, 343.3333333333334, 137.0, 845.6666666666667, 6.25, 8.70526844488137, 18.0, 24.37439412156285, 22.2, 1.0, 0.0], 
actual action is [6.33333333333333, 18], 
sim time next is 7655100.0000, 
raw observation next is [11.41666666666667, 48.75, 4.566666666666666, 344.1666666666666, 136.5, 842.3333333333333, 6.33333333333333, 8.631063946732688, 18.0, 24.43837406665928, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.6086956521739131, 0.6260683760683762, 0.4875, 0.4151515151515151, 0.9560185185185183, 0.3611111111111111, 0.8423333333333333, 0.6055555555555555, 0.08631063946732688, 0.0, 0.9197677238084684, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0086. 
=============================================
[2017-11-02 10:47:36,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.89736784e-01   9.70560461e-02   4.61323373e-02   1.10733293e-01
   5.56341529e-01   3.03852457e-25   1.20671713e-23   6.65378289e-25
   5.38803295e-23], sum to 1.0000
[2017-11-02 10:47:36,761] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [7.5, 63.5, 4.6, 330.0, 0.0, 0.0, 2.583333333333333, 17.4885472999993, 18.0, 21.75510618078709, 22.2, 1.0, 0.0], 
actual action is [2.5, 18.0], 
sim time next is 7587300.0000, 
raw observation next is [7.416666666666667, 63.91666666666666, 4.516666666666666, 331.6666666666666, 0.0, 0.0, 2.5, 17.71412875378697, 18.0, 21.70469278456229, 22.2, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.5235042735042735, 0.6391666666666665, 0.41060606060606053, 0.9212962962962961, 0.0, 0.0, 0.5416666666666666, 0.1771412875378697, 0.0, 0.5292418263660414, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:37,471] A3C_AGENT_WORKER-Thread-5 INFO:Local step 25500, global step 408133: loss 3.5480
[2017-11-02 10:47:39,091] A3C_AGENT_WORKER-Thread-2 INFO:Local step 25500, global step 408982: loss 0.0120
[2017-11-02 10:47:39,207] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:39,208] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:39,209] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:39,207] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:39,209] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:39,211] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:39,212] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:39,216] EPLUS_ENV_IW-v570202_Thread-6-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 59.01sec

[2017-11-02 10:47:39,423] A3C_AGENT_WORKER-Thread-17 INFO:Local step 25500, global step 409168: loss 0.0389
[2017-11-02 10:47:40,210] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:40,214] EPLUS_ENV_IW-v570202_Thread-6_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res6/Eplus-env-sub_run2
[2017-11-02 10:47:40,375] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.87684071e-01   5.48341917e-03   1.99075649e-03   4.42857825e-04
   4.39893035e-03   2.13518747e-22   5.40996063e-22   3.87839110e-23
   1.06109542e-21], sum to 1.0000
[2017-11-02 10:47:40,409] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.166666666666666, 58.75, 3.433333333333333, 354.1666666666666, 0.0, 0.0, 0.333333333333333, 18.40379791510049, 18.0, 21.14332861556534, 22.2, 1.0, 0.0], 
actual action is [0.16666666666666607, 18], 
sim time next is 7680600.0000, 
raw observation next is [5.0, 59.5, 3.6, 355.0, 0.0, 0.0, 0.1666666666666661, 18.70984715784653, 18.0, 21.10403782348874, 22.2, 1.0, 0.0], 
processed observation next is [0.5, 0.9130434782608695, 0.46153846153846156, 0.595, 0.32727272727272727, 0.9861111111111112, 0.0, 0.0, 0.5027777777777778, 0.1870984715784653, 0.0, 0.4434339747841055, 0.5999999999999999, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:47:41,113] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.86658037e-01   8.88661016e-03   1.48347078e-03   3.60161095e-04
   2.61176913e-03   1.20361776e-10   1.08747754e-10   2.10206817e-11
   4.07416115e-11], sum to 1.0000
[2017-11-02 10:47:41,215] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.0, 63.5, 0.45, 5.0, 121.0, 696.0, -1.166666666666667, 14.52120955866973, 18.0, 22.00516039873677, 22.2, 1.0, 0.0], 
actual action is [-1.0, 18], 
sim time next is 7720500.0000, 
raw observation next is [4.166666666666667, 62.75, 0.525, 5.833333333333334, 123.1666666666667, 701.0, -1.0, 14.51468005129901, 18.0, 22.26780575872885, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.4401709401709402, 0.6275, 0.04772727272727273, 0.016203703703703706, 0.3258377425044093, 0.701, 0.48333333333333334, 0.1451468005129901, 0.0, 0.6096865369612645, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0145. 
=============================================
[2017-11-02 10:47:41,348] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99966383e-01   2.17438701e-05   6.41258566e-06   2.49235484e-07
   5.26423582e-06   4.71507645e-33   1.85175497e-33   1.05564926e-34
   6.99101021e-33], sum to 1.0000
[2017-11-02 10:47:41,358] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 72.0, 2.1, 240.0, 0.0, 0.0, -4.0, 40.12779798074394, 18.0, 18.85154883035874, 19.4, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 7709100.0000, 
raw observation next is [1.0, 72.0, 2.1, 240.0, 0.0, 0.0, -4.0, 40.46352902111111, 18.0, 18.82203539737491, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.21739130434782608, 0.358974358974359, 0.72, 0.19090909090909092, 0.6666666666666666, 0.0, 0.0, 0.43333333333333335, 0.40463529021111105, 0.0, 0.1174336281964159, 0.1999999999999998, 0.0, 0.0], 
reward next is -0.0826. 
=============================================
[2017-11-02 10:47:41,556] A3C_AGENT_WORKER-Thread-9 INFO:Local step 25500, global step 410099: loss 0.0544
[2017-11-02 10:47:42,534] A3C_AGENT_WORKER-Thread-15 INFO:Local step 25500, global step 410513: loss 0.6262
[2017-11-02 10:47:42,566] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:42,566] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:42,567] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:42,568] EPLUS_ENV_IW-v570202_Thread-10-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 58.35sec

[2017-11-02 10:47:43,207] A3C_AGENT_WORKER-Thread-13 INFO:Local step 25500, global step 410841: loss -0.6838
[2017-11-02 10:47:43,209] A3C_AGENT_WORKER-Thread-14 INFO:Local step 25500, global step 410842: loss 0.1133
[2017-11-02 10:47:43,485] A3C_AGENT_WORKER-Thread-12 INFO:Local step 25500, global step 410967: loss -0.0054
[2017-11-02 10:47:43,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 25500, global step 410970: loss 0.0982
[2017-11-02 10:47:43,569] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:43,597] EPLUS_ENV_IW-v570202_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res10/Eplus-env-sub_run2
[2017-11-02 10:47:45,101] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:45,103] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 07min 54.81sec

[2017-11-02 10:47:45,102] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:45,104] EPLUS_ENV_IW-v570202_Thread-16-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,101] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:46,106] EPLUS_ENV_IW-v570202_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res16/Eplus-env-sub_run2
[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,152] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,153] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  8.96sec

[2017-11-02 10:47:46,154] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,154] EPLUS_ENV_IW-v570202_Thread-3-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,782] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,783] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,784] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,785] EPLUS_ENV_IW-v570202_Thread-8-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  4.58sec

[2017-11-02 10:47:46,880] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:46,881] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:46,882] EPLUS_ENV_IW-v570202_Thread-7-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  5.68sec

[2017-11-02 10:47:47,151] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,169] EPLUS_ENV_IW-v570202_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res3/Eplus-env-sub_run2
[2017-11-02 10:47:47,777] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,782] EPLUS_ENV_IW-v570202_Thread-8_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res8/Eplus-env-sub_run2
[2017-11-02 10:47:47,894] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:47,898] EPLUS_ENV_IW-v570202_Thread-7_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res7/Eplus-env-sub_run2
[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:48,479] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:48,480] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:48,481] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:48,482] EPLUS_ENV_IW-v570202_Thread-4-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 10.30sec

[2017-11-02 10:47:49,479] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:49,484] EPLUS_ENV_IW-v570202_Thread-4_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res4/Eplus-env-sub_run2
[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:51,185] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:51,186] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:51,187] EPLUS_ENV_IW-v570202_Thread-5-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 12.00sec

[2017-11-02 10:47:51,948] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.42153633e-01   2.52273586e-02   2.76173502e-02   8.27002048e-04
   4.17468930e-03   3.00099459e-16   2.23826339e-16   3.64317573e-17
   1.28207502e-16], sum to 1.0000
[2017-11-02 10:47:51,994] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.166666666666667, 67.25, 0.075, 0.8333333333333333, 114.75, 604.3333333333333, -2.0, 29.24924965891172, 18.0, 20.10304638166767, 19.4, 0.0, 0.0], 
actual action is [-1.833333333333333, 18], 
sim time next is 7719000.0000, 
raw observation next is [3.333333333333333, 66.5, 0.15, 1.666666666666667, 116.0, 622.6666666666667, -1.833333333333333, 27.98636803815777, 18.0, 20.24356715164483, 19.4, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.34782608695652173, 0.41880341880341876, 0.665, 0.013636363636363636, 0.00462962962962963, 0.30687830687830686, 0.6226666666666667, 0.46944444444444444, 0.2798636803815777, 0.0, 0.3205095930921184, 0.1999999999999998, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:47:52,191] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:52,196] EPLUS_ENV_IW-v570202_Thread-5_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res5/Eplus-env-sub_run2
[2017-11-02 10:47:52,997] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:52,997] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:53,006] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:53,007] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:53,033] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:53,034] EPLUS_ENV_IW-v570202_Thread-2-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 16.78sec

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:53,612] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:53,613] EPLUS_ENV_IW-v570202_Thread-17-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min  2.33sec

[2017-11-02 10:47:53,957] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:53,963] EPLUS_ENV_IW-v570202_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res2/Eplus-env-sub_run2
[2017-11-02 10:47:54,617] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:54,624] EPLUS_ENV_IW-v570202_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res17/Eplus-env-sub_run2
[2017-11-02 10:47:54,794] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  7.20817566e-01   1.93742141e-01   5.11052087e-02   8.74613971e-03
   2.55889278e-02   1.51462078e-08   1.15797354e-08   5.61550939e-09
   3.43956041e-09], sum to 1.0000
[2017-11-02 10:47:54,825] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [13.5, 42.5, 3.85, 327.5, 134.25, 819.75, 8.33333333333333, 7.769911574493515, 18.0, 24.55181620747214, 22.2, 1.0, 0.0], 
actual action is [8.5, 18], 
sim time next is 7743000.0000, 
raw observation next is [13.66666666666667, 42.0, 3.933333333333333, 335.0, 133.3333333333333, 815.3333333333333, 8.5, 7.729952506651559, 18.0, 24.62804160640146, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.6837606837606839, 0.42, 0.35757575757575755, 0.9305555555555556, 0.35273368606701927, 0.8153333333333332, 0.6416666666666667, 0.07729952506651559, 0.0, 0.94686308662878, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0077. 
=============================================
[2017-11-02 10:47:57,843] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:47:57,844] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:47:57,847] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:47:57,848] EPLUS_ENV_IW-v570202_Thread-9-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.64sec

[2017-11-02 10:47:58,843] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:47:58,846] EPLUS_ENV_IW-v570202_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res9/Eplus-env-sub_run2
[2017-11-02 10:48:02,069] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,070] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  6.40270650e-01   1.75377116e-01   1.67637348e-01   4.11755731e-03
   1.25973346e-02   9.62091322e-17   1.18032678e-16   2.53811007e-17
   1.68847137e-16], sum to 1.0000
[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,088] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,089] EPLUS_ENV_IW-v570202_Thread-13-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.80sec

[2017-11-02 10:48:02,106] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [9.075000000000001, 47.5, 3.475, 357.5, 0.0, 0.0, 4.166666666666668, 14.06317066033746, 18.0, 21.80856313993659, 22.2, 1.0, 0.0], 
actual action is [4.075000000000001, 18], 
sim time next is 7771800.0000, 
raw observation next is [8.983333333333334, 47.33333333333334, 3.516666666666667, 358.3333333333333, 0.0, 0.0, 4.075000000000001, 14.22739718979765, 18.0, 21.77375945549792, 22.2, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.5636752136752137, 0.47333333333333344, 0.31969696969696976, 0.9953703703703703, 0.0, 0.0, 0.5679166666666667, 0.1422739718979765, 0.0, 0.5391084936425601, 0.5999999999999999, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:48:02,295] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,295] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,301] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,302] EPLUS_ENV_IW-v570202_Thread-12-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 16.07sec

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,313] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,314] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,315] EPLUS_ENV_IW-v570202_Thread-14-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 14.05sec

[2017-11-02 10:48:02,547] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,547] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:02,548] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:02,549] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:02,550] EPLUS_ENV_IW-v570202_Thread-15-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 13.28sec

[2017-11-02 10:48:03,073] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,076] EPLUS_ENV_IW-v570202_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res13/Eplus-env-sub_run2
[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Starting

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 09:39

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Processing Data Dictionary

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Processing Input File

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Initializing Simulation

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Reporting Surfaces

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Beginning Primary Simulation

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Initializing New Environment Parameters

[2017-11-02 10:48:03,238] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {1}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:ExternalInterface initializes.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {2}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {3}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {4}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {5}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Warming up {6}

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:48:03,239] EPLUS_ENV_IW-v570202_Thread-11-EPLUSPROCESS_EPI_0 INFO:EnergyPlus Run Time=01hr 08min 18.02sec

[2017-11-02 10:48:03,293] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,296] EPLUS_ENV_IW-v570202_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res12/Eplus-env-sub_run2
[2017-11-02 10:48:03,334] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,361] EPLUS_ENV_IW-v570202_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res14/Eplus-env-sub_run2
[2017-11-02 10:48:03,548] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:03,551] EPLUS_ENV_IW-v570202_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res15/Eplus-env-sub_run2
[2017-11-02 10:48:04,238] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:48:04,241] EPLUS_ENV_IW-v570202_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res11/Eplus-env-sub_run2
[2017-11-02 10:48:38,517] A3C_AGENT_WORKER-Thread-6 INFO:Local step 26000, global step 414823: loss 86.0878
[2017-11-02 10:48:41,129] A3C_AGENT_WORKER-Thread-10 INFO:Local step 26000, global step 414910: loss -3.0324
[2017-11-02 10:48:43,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99193847e-01   5.11294289e-04   2.71629222e-04   3.39260538e-07
   2.30438036e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:48:43,544] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 2.7, 41.84081935629116, 18.0, 18.42791951267186, 21.5, 0.0, 0.0], 
actual action is [2.7, 18], 
sim time next is 15600.0000, 
raw observation next is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 2.7, 42.0865450271405, 18.0, 18.39946014218834, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.17391304347826086, 0.5307692307692308, 0.93, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.545, 0.42086545027140504, 0.0, 0.05706573459833412, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:48:44,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 26000, global step 415054: loss -32.6907
[2017-11-02 10:48:49,962] A3C_AGENT_WORKER-Thread-7 INFO:Local step 26000, global step 415393: loss -16.0129
[2017-11-02 10:48:50,025] A3C_AGENT_WORKER-Thread-8 INFO:Local step 26000, global step 415395: loss 34.7165
[2017-11-02 10:48:51,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99762475e-01   1.94294407e-04   3.69484442e-05   2.12489496e-07
   6.02136788e-06   0.00000000e+00   2.38139380e-38   0.00000000e+00
   3.82522500e-36], sum to 1.0000
[2017-11-02 10:48:51,300] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.2, 96.0, 4.85, 212.5, 0.0, 0.0, 12.2, 19.00058029978402, 19.0, 20.52122900664196, 21.5, 0.0, 33.17066896904028], 
actual action is [2.2, 18], 
sim time next is 6600.0000, 
raw observation next is [7.199999999999999, 96.0, 4.933333333333334, 215.0, 0.0, 0.0, 2.2, 20.07448087299838, 18.0, 20.74390187517663, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.043478260869565216, 0.5179487179487179, 0.96, 0.4484848484848485, 0.5972222222222222, 0.0, 0.0, 0.5366666666666667, 0.2007448087299838, 0.0, 0.3919859821680899, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:48:52,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 26000, global step 415591: loss 93.9479
[2017-11-02 10:48:53,464] A3C_AGENT_WORKER-Thread-4 INFO:Local step 26000, global step 415636: loss 24.7058
[2017-11-02 10:48:56,415] A3C_AGENT_WORKER-Thread-17 INFO:Local step 26000, global step 415801: loss -16.0502
[2017-11-02 10:48:57,068] A3C_AGENT_WORKER-Thread-5 INFO:Local step 26000, global step 415847: loss 151.5591
[2017-11-02 10:48:59,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.05447721e-01   1.79555155e-02   7.23984167e-02   5.38877386e-04
   3.65948025e-03   4.69548056e-25   6.04422218e-25   2.28329439e-24
   4.56920050e-22], sum to 1.0000
[2017-11-02 10:48:59,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [7.658333333333334, 93.25, 5.058333333333334, 238.3333333333333, 0.0, 0.0, 12.61666666666667, 14.33568326892011, 23.0, 20.94236837450102, 21.5, 0.0, 49.86025545458869], 
actual action is [12.658333333333335, 22.0], 
sim time next is 14400.0000, 
raw observation next is [7.7, 93.0, 5.1, 240.0, 0.0, 0.0, 12.65833333333333, 13.33449833736156, 22.0, 21.14045700274188, 21.5, 0.0, 39.21959922720863], 
processed observation next is [1.0, 0.17391304347826086, 0.5307692307692308, 0.93, 0.4636363636363636, 0.6666666666666666, 0.0, 0.0, 0.7109722222222222, 0.1333449833736156, 0.5714285714285714, 0.44863671467741134, 0.5, 0.0, 0.46140704973186625], 
reward next is -0.4666. 
=============================================
[2017-11-02 10:49:02,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 26000, global step 416205: loss -22.7740
[2017-11-02 10:49:02,743] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-48.73719406]
 [-50.66049576]
 [-51.27514267]
 [-56.15449142]
 [-54.11884689]], R is [[-49.7937088 ]
 [-50.29577255]
 [-50.79281616]
 [-51.28488922]
 [-51.77204132]].
[2017-11-02 10:49:02,956] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   2.30422224e-08   8.19225417e-12   4.03351635e-14
   1.86272844e-10   4.90868911e-38   1.13608444e-35   1.22711811e-33
   7.08075949e-32], sum to 1.0000
[2017-11-02 10:49:02,972] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 4.1, 290.0, 0.0, 0.0, 10.0, 0.0, 20.0, 19.65446279971044, 21.5, 0.0, 25.89083793705264], 
actual action is [-5.0, 18], 
sim time next is 300.0000, 
raw observation next is [0.6, 95.08333333333333, 4.1, 281.6666666666666, 0.0, 0.0, -5.0, 29.19992417020309, 18.0, 19.65446279971044, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.0, 0.3487179487179487, 0.9508333333333333, 0.3727272727272727, 0.7824074074074071, 0.0, 0.0, 0.4166666666666667, 0.2919992417020309, 0.0, 0.23635182853006295, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:06,925] A3C_AGENT_WORKER-Thread-12 INFO:Local step 26000, global step 417270: loss 7.9490
[2017-11-02 10:49:06,935] A3C_AGENT_WORKER-Thread-11 INFO:Local step 26000, global step 417271: loss 221.0453
[2017-11-02 10:49:06,936] A3C_AGENT_WORKER-Thread-14 INFO:Local step 26000, global step 417271: loss 520.7566
[2017-11-02 10:49:07,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 26000, global step 417383: loss 72.2693
[2017-11-02 10:49:09,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 26000, global step 417966: loss -22.3410
[2017-11-02 10:49:13,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 26000, global step 418865: loss 1049.3673
[2017-11-02 10:49:17,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  1.00000000e+00   1.15387599e-09   1.34873404e-10   2.00557071e-11
   5.54601469e-11   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00], sum to 1.0000
[2017-11-02 10:49:17,493] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.866666666666666, 74.41666666666667, 6.6, 260.8333333333333, 0.0, 0.0, 0.2666666666666666, 23.12819443067566, 20.0, 20.24373912272766, 21.5, 0.0, 50.87386791623217], 
actual action is [-9.866666666666667, 18], 
sim time next is 104400.0000, 
raw observation next is [-5.0, 74.0, 6.6, 260.0, 0.0, 0.0, -9.866666666666667, 25.66155755334948, 18.0, 20.36328118283569, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.21739130434782608, 0.20512820512820512, 0.74, 0.6, 0.7222222222222222, 0.0, 0.0, 0.33555555555555555, 0.2566155755334948, 0.0, 0.3376115975479555, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:27,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   3.90761805e-08   1.96487377e-08   1.33807544e-05
   9.99986529e-01], sum to 1.0000
[2017-11-02 10:49:28,034] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.341666666666667, 88.66666666666666, 7.491666666666667, 264.1666666666667, 0.0, 0.0, -7.25, 28.29100257359498, 18.0, 20.04913450817269, 21.5, 0.0, 0.0], 
actual action is [2.658333333333333, 23.0], 
sim time next is 96000.0000, 
raw observation next is [-2.433333333333333, 88.33333333333334, 7.533333333333333, 263.3333333333333, 0.0, 0.0, 2.658333333333333, 23.6801575280695, 23.0, 19.92283391393866, 21.5, 0.0, 94.98125950314184], 
processed observation next is [0.0, 0.08695652173913043, 0.2709401709401709, 0.8833333333333334, 0.6848484848484848, 0.7314814814814814, 0.0, 0.0, 0.5443055555555555, 0.236801575280695, 0.7142857142857143, 0.27469055913409435, 0.5, 0.0, 1.117426582389904], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:42,194] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   6.72192643e-28   1.74513212e-27   2.86349310e-28
   2.71929521e-27   4.34979164e-08   1.88508636e-07   1.12999638e-04
   9.99886751e-01], sum to 1.0000
[2017-11-02 10:49:42,349] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.591666666666667, 62.75, 7.408333333333333, 264.1666666666667, 0.0, 0.0, -2.55, 19.2644479554929, 24.0, 21.97602495638325, 22.7, 1.0, 58.37676977186145], 
actual action is [-2.591666666666667, 25], 
sim time next is 153600.0000, 
raw observation next is [-7.633333333333333, 63.0, 7.366666666666667, 263.3333333333333, 0.0, 0.0, -2.591666666666667, 18.99769110547826, 25.0, 21.96946002388026, 22.7, 1.0, 66.5938152895416], 
processed observation next is [0.0, 0.782608695652174, 0.13760683760683762, 0.63, 0.6696969696969698, 0.7314814814814814, 0.0, 0.0, 0.4568055555555555, 0.1899769110547826, 1.0, 0.56706571769718, 0.6714285714285714, 1.0, 0.7834566504651952], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:42,643] A3C_AGENT_WORKER-Thread-3 INFO:Local step 26500, global step 422388: loss -51.3774
[2017-11-02 10:49:42,805] A3C_AGENT_WORKER-Thread-6 INFO:Local step 26500, global step 422411: loss 166.6928
[2017-11-02 10:49:43,816] A3C_AGENT_WORKER-Thread-10 INFO:Local step 26500, global step 422521: loss 99.4379
[2017-11-02 10:49:44,486] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.00000000e+00   3.62364860e-11   2.69895512e-11   9.21304786e-12
   8.20576593e-12   0.00000000e+00   0.00000000e+00   0.00000000e+00
   1.69996797e-37], sum to 1.0000
[2017-11-02 10:49:44,578] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.15, 66.33333333333334, 5.391666666666667, 265.8333333333333, 0.0, 0.0, -3.1, 19.65541061869074, 23.0, 22.02325753624048, 22.7, 1.0, 73.48795612549677], 
actual action is [-13.15, 18.0], 
sim time next is 157200.0000, 
raw observation next is [-8.2, 66.66666666666666, 5.133333333333333, 266.6666666666667, 0.0, 0.0, -13.15, 21.8729341361406, 18.0, 21.97315522432627, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.8260869565217391, 0.1230769230769231, 0.6666666666666665, 0.4666666666666666, 0.7407407407407408, 0.0, 0.0, 0.2808333333333334, 0.218729341361406, 0.0, 0.5675936034751814, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:46,177] A3C_AGENT_WORKER-Thread-7 INFO:Local step 26500, global step 422790: loss 145.9757
[2017-11-02 10:49:49,489] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.00000000e+00   1.69546998e-11   8.01002875e-11   1.03086819e-11
   1.09597768e-10   0.00000000e+00   0.00000000e+00   0.00000000e+00
   2.10207185e-38], sum to 1.0000
[2017-11-02 10:49:49,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.52294461e-07   7.23969080e-08   2.25678901e-03
   9.97743011e-01], sum to 1.0000
[2017-11-02 10:49:49,525] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 78.0, 3.6, 203.3333333333333, 0.0, 0.0, -3.9, 24.11359999922345, 20.0, 20.41910519581861, 21.5, 0.0, 47.19479145166197], 
actual action is [-13.9, 18], 
sim time next is 186300.0000, 
raw observation next is [-8.9, 78.0, 3.6, 202.5, 0.0, 0.0, -13.9, 27.19312650927852, 18.0, 20.40984088227815, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.13043478260869565, 0.10512820512820512, 0.78, 0.32727272727272727, 0.5625, 0.0, 0.0, 0.26833333333333337, 0.2719312650927852, 0.0, 0.34426298318259285, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:49,571] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 4.6, 200.0, 0.0, 0.0, -3.9, 24.86746545177719, 25.0, 20.32392944796966, 21.5, 0.0, 43.64123758466133], 
actual action is [-3.9000000000000004, 25], 
sim time next is 191100.0000, 
raw observation next is [-8.9, 78.0, 4.516666666666666, 199.1666666666667, 0.0, 0.0, -3.9, 24.89642617276728, 25.0, 20.29438979398038, 21.5, 0.0, 47.61463899149982], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.10512820512820512, 0.78, 0.41060606060606053, 0.5532407407407409, 0.0, 0.0, 0.435, 0.2489642617276728, 1.0, 0.32776997056862556, 0.5, 0.0, 0.5601722234294096], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:50,015] A3C_AGENT_WORKER-Thread-8 INFO:Local step 26500, global step 423309: loss 191.1449
[2017-11-02 10:49:50,289] A3C_AGENT_WORKER-Thread-4 INFO:Local step 26500, global step 423347: loss 123.2746
[2017-11-02 10:49:52,329] A3C_AGENT_WORKER-Thread-16 INFO:Local step 26500, global step 423586: loss -0.6069
[2017-11-02 10:49:52,668] A3C_AGENT_WORKER-Thread-17 INFO:Local step 26500, global step 423625: loss 23.0608
[2017-11-02 10:49:54,993] A3C_AGENT_WORKER-Thread-5 INFO:Local step 26500, global step 423869: loss -72.4912
[2017-11-02 10:49:55,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.93267179e-01   2.64843926e-04   2.44857580e-03   4.39300260e-04
   3.58009501e-03   4.61870674e-20   8.85618144e-20   2.00166816e-16
   7.50087180e-14], sum to 1.0000
[2017-11-02 10:49:55,146] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.9, 76.33333333333333, 3.35, 205.8333333333333, 0.0, 0.0, -3.9, 21.40572018592975, 25.0, 20.77369079496346, 21.5, 0.0, 47.42806736284741], 
actual action is [-3.9000000000000004, 20.0], 
sim time next is 182400.0000, 
raw observation next is [-8.9, 76.66666666666667, 3.4, 206.6666666666667, 0.0, 0.0, -3.9, 21.22727129143222, 20.0, 20.77331276201971, 21.5, 0.0, 47.21193398840865], 
processed observation next is [0.16666666666666666, 0.08695652173913043, 0.10512820512820512, 0.7666666666666667, 0.3090909090909091, 0.5740740740740742, 0.0, 0.0, 0.435, 0.2122727129143222, 0.2857142857142857, 0.3961875374313872, 0.5, 0.0, 0.5554345175106901], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:57,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   5.32702216e-10   1.85410054e-09   2.75262544e-04
   9.99724686e-01], sum to 1.0000
[2017-11-02 10:49:57,976] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  8.55762810e-02   2.28128880e-02   2.97380865e-01   3.95303704e-02
   5.54699600e-01   8.92940545e-16   3.25847519e-15   2.35801656e-11
   3.16499964e-08], sum to 1.0000
[2017-11-02 10:49:57,986] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.391666666666667, 75.25, 5.141666666666667, 199.1666666666667, 97.75, 0.0, -12.48333333333333, 24.9288846800076, 18.0, 21.44826040828915, 22.7, 1.0, 0.0], 
actual action is [-2.3916666666666666, 23.0], 
sim time next is 208800.0000, 
raw observation next is [-7.3, 75.0, 5.1, 200.0, 101.5, 0.0, -2.391666666666667, 22.88648809289679, 23.0, 21.17221925175753, 22.7, 1.0, 96.86521486525085], 
processed observation next is [0.16666666666666666, 0.43478260869565216, 0.14615384615384616, 0.75, 0.4636363636363636, 0.5555555555555556, 0.26851851851851855, 0.0, 0.46013888888888893, 0.2288648809289679, 0.7142857142857143, 0.4531741788225041, 0.6714285714285714, 1.0, 1.1395907631205981], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:49:58,031] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-8.9, 78.0, 3.85, 185.0, 0.0, 0.0, -3.9, 27.03977118614745, 25.0, 19.80446326255588, 21.5, 0.0, 47.33039370868946], 
actual action is [-3.9000000000000004, 25.0], 
sim time next is 196500.0000, 
raw observation next is [-8.9, 78.0, 3.891666666666667, 184.1666666666667, 0.0, 0.0, -3.9, 26.88690527467702, 25.0, 19.79941166538428, 21.5, 0.0, 47.73108682117344], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.10512820512820512, 0.78, 0.3537878787878788, 0.5115740740740742, 0.0, 0.0, 0.435, 0.2688690527467702, 1.0, 0.2570588093406115, 0.5, 0.0, 0.5615421978961581], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:03,125] A3C_AGENT_WORKER-Thread-2 INFO:Local step 26500, global step 424665: loss 257.4252
[2017-11-02 10:50:03,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   1.81605445e-37   7.43212689e-36   3.30515099e-37
   8.89943570e-36   7.18372339e-09   1.68995431e-08   4.71356761e-04
   9.99528646e-01], sum to 1.0000
[2017-11-02 10:50:03,413] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.15, 66.33333333333334, 5.391666666666667, 265.8333333333333, 0.0, 0.0, -3.1, 19.69485013738373, 25.0, 21.49223060917167, 22.7, 1.0, 66.72386791921596], 
actual action is [-3.1500000000000004, 25], 
sim time next is 157200.0000, 
raw observation next is [-8.2, 66.66666666666666, 5.133333333333333, 266.6666666666667, 0.0, 0.0, -3.15, 19.06262537909176, 25.0, 21.65491211408975, 22.7, 1.0, 65.44712287496725], 
processed observation next is [0.0, 0.8260869565217391, 0.1230769230769231, 0.6666666666666665, 0.4666666666666666, 0.7407407407407408, 0.0, 0.0, 0.4475, 0.1906262537909176, 1.0, 0.5221303020128215, 0.6714285714285714, 1.0, 0.769966151470203], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:06,805] A3C_AGENT_WORKER-Thread-9 INFO:Local step 26500, global step 425053: loss -6.9708
[2017-11-02 10:50:06,932] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   5.19796714e-34   2.94700677e-33   2.96913320e-34
   1.53004872e-32   1.78125816e-08   3.45237723e-08   8.31159006e-04
   9.99168754e-01], sum to 1.0000
[2017-11-02 10:50:07,130] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.733333333333334, 78.0, 5.266666666666667, 196.6666666666667, 28.33333333333334, 249.6666666666667, -3.775, 22.13398029821787, 25.0, 20.75031360731368, 22.7, 1.0, 66.9483274515794], 
actual action is [-3.7333333333333343, 25], 
sim time next is 203100.0000, 
raw observation next is [-8.691666666666666, 78.0, 5.308333333333333, 195.8333333333333, 31.16666666666666, 272.8333333333333, -3.733333333333334, 21.48646366680258, 25.0, 20.81983479567774, 22.7, 1.0, 66.981765909265], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.11047008547008548, 0.78, 0.4825757575757575, 0.5439814814814814, 0.08245149911816577, 0.2728333333333333, 0.43777777777777777, 0.21486463666802583, 1.0, 0.402833542239677, 0.6714285714285714, 1.0, 0.7880207754031175], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:07,486] A3C_AGENT_WORKER-Thread-12 INFO:Local step 26500, global step 425126: loss -3.0030
[2017-11-02 10:50:08,585] A3C_AGENT_WORKER-Thread-13 INFO:Local step 26500, global step 425252: loss 6.3849
[2017-11-02 10:50:09,010] A3C_AGENT_WORKER-Thread-11 INFO:Local step 26500, global step 425298: loss -119.0730
[2017-11-02 10:50:09,845] A3C_AGENT_WORKER-Thread-14 INFO:Local step 26500, global step 425395: loss -31.9919
[2017-11-02 10:50:14,735] A3C_AGENT_WORKER-Thread-15 INFO:Local step 26500, global step 425998: loss 33.2485
[2017-11-02 10:50:17,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   2.54446178e-38   2.20230219e-36   1.78800808e-37
   1.46494204e-35   2.33286140e-10   1.35002864e-09   4.43679346e-05
   9.99955654e-01], sum to 1.0000
[2017-11-02 10:50:17,565] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.9, 78.0, 4.016666666666667, 181.6666666666667, 0.0, 0.0, -3.9, 24.2639486776736, 25.0, 20.09674008238567, 21.5, 0.0, 42.8883572569722], 
actual action is [-3.9000000000000004, 25], 
sim time next is 197700.0000, 
raw observation next is [-8.9, 78.0, 4.058333333333333, 180.8333333333333, 0.0, 0.0, -3.9, 24.34268231132097, 25.0, 20.0681660901451, 21.5, 0.0, 46.79991850777193], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.10512820512820512, 0.78, 0.3689393939393939, 0.5023148148148147, 0.0, 0.0, 0.435, 0.2434268231132097, 1.0, 0.2954522985921569, 0.5, 0.0, 0.5505872765620227], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:25,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.58845944e-07   2.73462547e-07   7.72221363e-04
   9.99227285e-01], sum to 1.0000
[2017-11-02 10:50:25,216] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.4, 65.0, 6.433333333333334, 220.0, 0.0, 0.0, 1.600000000000001, 12.97953109863169, 25.0, 23.03939933436567, 22.7, 1.0, 52.54728663007107], 
actual action is [1.6, 25], 
sim time next is 238500.0000, 
raw observation next is [-3.4, 65.0, 6.35, 220.0, 0.0, 0.0, 1.6, 12.99243579264335, 25.0, 23.0293864213539, 22.7, 1.0, 56.23606789162845], 
processed observation next is [0.16666666666666666, 0.782608695652174, 0.24615384615384614, 0.65, 0.5772727272727273, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.1299243579264335, 1.0, 0.7184837744791288, 0.6714285714285714, 1.0, 0.6616007987250406], 
reward next is -0.6084. 
=============================================
[2017-11-02 10:50:33,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.91735045e-32   9.27101963e-20   9.55565351e-19   1.01007934e-18
   7.19407974e-19   5.06273601e-09   7.32141414e-09   1.01429527e-04
   9.99898553e-01], sum to 1.0000
[2017-11-02 10:50:33,438] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-10.96666666666667, 68.0, 6.5, 256.6666666666667, 0.0, 0.0, -5.875, 22.33842110792085, 25.0, 20.33265316750819, 21.5, 0.0, 49.2583993117176], 
actual action is [-5.96666666666667, 25], 
sim time next is 278700.0000, 
raw observation next is [-11.05833333333333, 68.25, 6.324999999999999, 255.8333333333333, 0.0, 0.0, -5.96666666666667, 22.45563345023814, 25.0, 20.31246118997922, 21.5, 0.0, 49.18106152170523], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.04978632478632487, 0.6825, 0.575, 0.710648148148148, 0.0, 0.0, 0.4005555555555555, 0.22455633450238138, 1.0, 0.3303515985684601, 0.5, 0.0, 0.5786007237847675], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:50:45,059] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.49711248e-08   1.05257900e-08   1.13622031e-04
   9.99886394e-01], sum to 1.0000
[2017-11-02 10:50:45,209] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.399999999999999, 65.0, 5.683333333333334, 220.0, 0.0, 0.0, 1.6, 10.57693321161322, 25.0, 23.6921042804631, 22.7, 1.0, 61.8156038893245], 
actual action is [1.600000000000001, 25], 
sim time next is 241200.0000, 
raw observation next is [-3.4, 65.0, 5.6, 220.0, 0.0, 0.0, 1.600000000000001, 10.53790855385405, 25.0, 23.7015860605452, 22.7, 1.0, 61.73862788593065], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.24615384615384614, 0.65, 0.509090909090909, 0.6111111111111112, 0.0, 0.0, 0.5266666666666667, 0.1053790855385405, 1.0, 0.8145122943636, 0.6714285714285714, 1.0, 0.7263367986580076], 
reward next is -0.6642. 
=============================================
[2017-11-02 10:51:01,909] A3C_AGENT_WORKER-Thread-3 INFO:Local step 27000, global step 430689: loss -4.2361
[2017-11-02 10:51:02,712] A3C_AGENT_WORKER-Thread-6 INFO:Local step 27000, global step 430774: loss -14.9536
[2017-11-02 10:51:03,285] A3C_AGENT_WORKER-Thread-7 INFO:Local step 27000, global step 430827: loss -94.5083
[2017-11-02 10:51:04,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   1.09045114e-02   1.95299042e-04   1.41845003e-03
   9.87481713e-01], sum to 1.0000
[2017-11-02 10:51:04,170] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-11.51666666666667, 55.66666666666666, 5.183333333333333, 271.6666666666666, 0.0, 0.0, -6.425000000000001, 13.69537130814438, 25.0, 22.70101084067651, 22.7, 1.0, 65.06468721519252], 
actual action is [-6.516666666666669, 25], 
sim time next is 323700.0000, 
raw observation next is [-11.60833333333333, 56.33333333333334, 5.141666666666667, 270.8333333333334, 0.0, 0.0, -6.516666666666669, 13.66718724893696, 25.0, 22.70523143556236, 22.7, 1.0, 64.6475721168983], 
processed observation next is [0.3333333333333333, 0.7391304347826086, 0.03568376068376075, 0.5633333333333335, 0.4674242424242424, 0.7523148148148151, 0.0, 0.0, 0.39138888888888884, 0.1366718724893696, 1.0, 0.6721759193660516, 0.6714285714285714, 1.0, 0.7605596719635095], 
reward next is -0.6982. 
=============================================
[2017-11-02 10:51:04,477] A3C_AGENT_WORKER-Thread-10 INFO:Local step 27000, global step 430933: loss 0.3962
[2017-11-02 10:51:09,645] A3C_AGENT_WORKER-Thread-4 INFO:Local step 27000, global step 431359: loss 60.7586
[2017-11-02 10:51:10,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 27000, global step 431454: loss -24.5629
[2017-11-02 10:51:10,869] A3C_AGENT_WORKER-Thread-17 INFO:Local step 27000, global step 431475: loss -1.6861
[2017-11-02 10:51:13,437] A3C_AGENT_WORKER-Thread-8 INFO:Local step 27000, global step 431716: loss -4.9963
[2017-11-02 10:51:14,040] A3C_AGENT_WORKER-Thread-5 INFO:Local step 27000, global step 431772: loss 11.6073
[2017-11-02 10:51:23,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.92320760e-21   9.79803304e-12   1.56243291e-12   9.73068934e-12
   1.15791686e-12   2.30926881e-03   9.05672926e-03   3.19887022e-03
   9.85435128e-01], sum to 1.0000
[2017-11-02 10:51:23,940] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-9.958333333333332, 46.08333333333333, 7.908333333333333, 275.8333333333333, 84.0, 747.4166666666666, -5.050000000000001, 9.828924362747635, 25.0, 23.30810238216409, 22.7, 1.0, 63.47449804740609], 
actual action is [-4.958333333333332, 25], 
sim time next is 304800.0000, 
raw observation next is [-9.866666666666667, 45.66666666666667, 7.866666666666666, 276.6666666666667, 85.0, 736.8333333333334, -4.958333333333332, 9.822511617124762, 25.0, 23.31767146961392, 22.7, 1.0, 63.49464923151642], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.08034188034188033, 0.4566666666666667, 0.7151515151515151, 0.7685185185185186, 0.22486772486772486, 0.7368333333333333, 0.4173611111111111, 0.09822511617124763, 1.0, 0.7596673528019886, 0.6714285714285714, 1.0, 0.7469958733119578], 
reward next is -0.6821. 
=============================================
[2017-11-02 10:51:25,980] A3C_AGENT_WORKER-Thread-2 INFO:Local step 27000, global step 433012: loss 1.2686
[2017-11-02 10:51:28,040] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   8.13363306e-03   5.92170749e-03   9.47763212e-04
   9.84996915e-01], sum to 1.0000
[2017-11-02 10:51:28,149] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 5, 
current raw observation is [-15.1, 69.66666666666667, 5.516666666666667, 256.6666666666667, 0.0, 0.0, -10.05, 27.19584518187707, 25.0, 19.79302024664793, 21.5, 0.0, 49.63373202428961], 
actual action is [-10.1, 25], 
sim time next is 357300.0000, 
raw observation next is [-15.15, 70.0, 5.475, 255.0, 0.0, 0.0, -10.1, 27.39483627440861, 25.0, 19.76465203399081, 21.5, 0.0, 49.60053728502444], 
processed observation next is [0.5, 0.13043478260869565, -0.05512820512820514, 0.7, 0.4977272727272727, 0.7083333333333334, 0.0, 0.0, 0.33166666666666667, 0.2739483627440861, 1.0, 0.25209314771297286, 0.5, 0.0, 0.5835357327649934], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:28,579] A3C_AGENT_WORKER-Thread-12 INFO:Local step 27000, global step 433270: loss 0.2784
[2017-11-02 10:51:28,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 27000, global step 433280: loss 0.6589
[2017-11-02 10:51:30,930] A3C_AGENT_WORKER-Thread-11 INFO:Local step 27000, global step 433493: loss 1.8725
[2017-11-02 10:51:31,535] A3C_AGENT_WORKER-Thread-14 INFO:Local step 27000, global step 433548: loss 0.5941
[2017-11-02 10:51:32,815] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   2.78167892e-03   5.63685491e-04   9.74793744e-04
   9.95679855e-01], sum to 1.0000
[2017-11-02 10:51:32,918] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-16.2, 78.0, 5.475, 260.0, 0.0, 0.0, -11.2, 36.8870088735915, 25.0, 18.57541701587479, 21.5, 0.0, 50.16252839253289], 
actual action is [-11.2, 25], 
sim time next is 370200.0000, 
raw observation next is [-16.2, 78.0, 5.516666666666667, 260.0, 0.0, 0.0, -11.2, 37.13069695608661, 25.0, 18.54759149551651, 21.5, 0.0, 50.20789531327404], 
processed observation next is [0.5, 0.2608695652173913, -0.08205128205128204, 0.78, 0.5015151515151515, 0.7222222222222222, 0.0, 0.0, 0.31333333333333335, 0.3713069695608661, 1.0, 0.0782273565023586, 0.5, 0.0, 0.5906811213326357], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:33,981] A3C_AGENT_WORKER-Thread-13 INFO:Local step 27000, global step 433740: loss 0.6261
[2017-11-02 10:51:35,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00497956
  0.01331706  0.30666757  0.67503583], sum to 1.0000
[2017-11-02 10:51:36,165] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-12.675, 68.25, 5.85, 287.5, 0.0, 0.0, -7.633333333333329, 12.36054669106726, 25.0, 22.90243233823855, 22.7, 1.0, 64.45576733363862], 
actual action is [-7.675000000000001, 25], 
sim time next is 330600.0000, 
raw observation next is [-12.71666666666667, 68.83333333333333, 5.933333333333333, 288.3333333333334, 0.0, 0.0, -7.675000000000001, 12.42629222059024, 25.0, 22.88715289354367, 22.7, 1.0, 64.54539591344543], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.007264957264957171, 0.6883333333333332, 0.5393939393939393, 0.8009259259259262, 0.0, 0.0, 0.3720833333333333, 0.12426292220590239, 1.0, 0.6981646990776673, 0.6714285714285714, 1.0, 0.759357598981711], 
reward next is -0.6958. 
=============================================
[2017-11-02 10:51:36,978] A3C_AGENT_WORKER-Thread-15 INFO:Local step 27000, global step 433984: loss -0.9243
[2017-11-02 10:51:39,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.0168792
  0.0055526   0.87583572  0.10173247], sum to 1.0000
[2017-11-02 10:51:39,967] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-14.775, 72.0, 4.1, 225.0, 47.0, 735.75, -9.86666666666667, 24.14799996920584, 25.0, 20.72221936348177, 22.7, 1.0, 63.38608958662753], 
actual action is [-9.775, 25], 
sim time next is 381000.0000, 
raw observation next is [-14.68333333333333, 70.0, 3.933333333333333, 223.3333333333333, 49.66666666666666, 735.0, -9.775, 23.74548394623149, 25.0, 20.79636698138441, 22.7, 1.0, 63.13067701146036], 
processed observation next is [0.5, 0.391304347826087, -0.04316239316239308, 0.7, 0.35757575757575755, 0.6203703703703702, 0.1313932980599647, 0.735, 0.33708333333333335, 0.2374548394623149, 1.0, 0.39948099734062986, 0.6714285714285714, 1.0, 0.7427138471936513], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:44,024] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-103.43919373]
 [-104.46818542]
 [-106.00250244]
 [-107.5440979 ]
 [-102.97489166]], R is [[-105.55390167]
 [-105.49836731]
 [-105.44338226]
 [-105.38894653]
 [-105.33506012]].
[2017-11-02 10:51:47,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   6.53707514e-32   1.36502377e-31   4.77284185e-31
   1.81494785e-32   4.70832980e-04   6.22020522e-03   8.67546499e-01
   1.25762433e-01], sum to 1.0000
[2017-11-02 10:51:47,411] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-11.6, 50.58333333333334, 6.583333333333333, 220.8333333333333, 56.25, 894.5, -6.699999999999999, 22.01397496462673, 25.0, 21.114063741199, 22.7, 1.0, 65.97383253856853], 
actual action is [-6.6, 25], 
sim time next is 393000.0000, 
raw observation next is [-11.5, 50.16666666666666, 6.566666666666666, 221.6666666666667, 56.0, 893.0, -6.6, 21.50989136993854, 25.0, 21.1909422994022, 22.7, 1.0, 65.63638085693593], 
processed observation next is [0.5, 0.5652173913043478, 0.038461538461538464, 0.5016666666666666, 0.5969696969696969, 0.6157407407407409, 0.14814814814814814, 0.893, 0.38999999999999996, 0.21509891369938539, 1.0, 0.4558488999145998, 0.6714285714285714, 1.0, 0.7721927159639521], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:51:49,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-118.1299057 ]
 [-116.3433609 ]
 [-117.6599884 ]
 [-117.08818054]
 [-118.29971313]], R is [[-117.65307617]
 [-117.47654724]
 [-117.3017807 ]
 [-117.12876129]
 [-116.95747375]].
[2017-11-02 10:52:07,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  3.54856014e-01   5.71106672e-02   3.97565454e-01   1.86927512e-01
   3.39622423e-03   3.01933198e-08   6.74705461e-06   4.41969814e-06
   1.32929505e-04], sum to 1.0000
[2017-11-02 10:52:07,371] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 3, 
current raw observation is [-10.41666666666667, 45.5, 6.375, 230.8333333333333, 50.91666666666666, 854.9166666666667, -5.5, 15.97220416122228, 25.0, 22.3329142591903, 22.7, 1.0, 56.29794533030373], 
actual action is [-5.41666666666667, 24.5], 
sim time next is 396600.0000, 
raw observation next is [-10.33333333333333, 45.0, 6.350000000000001, 231.6666666666667, 50.33333333333333, 850.3333333333334, -5.41666666666667, 15.77351642829887, 24.5, 22.3425139386093, 22.7, 1.0, 62.84415063287059], 
processed observation next is [0.5, 0.6086956521739131, 0.06837606837606845, 0.45, 0.5772727272727274, 0.6435185185185186, 0.13315696649029982, 0.8503333333333334, 0.40972222222222215, 0.1577351642829887, 0.9285714285714286, 0.620359134087043, 0.6714285714285714, 1.0, 0.7393429486220069], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:17,811] A3C_AGENT_WORKER-Thread-6 INFO:Local step 27500, global step 438185: loss -25.7576
[2017-11-02 10:52:18,628] A3C_AGENT_WORKER-Thread-3 INFO:Local step 27500, global step 438264: loss 127.9223
[2017-11-02 10:52:20,084] A3C_AGENT_WORKER-Thread-7 INFO:Local step 27500, global step 438384: loss 1.0497
[2017-11-02 10:52:22,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00111346
  0.01116488  0.00752968  0.98019195], sum to 1.0000
[2017-11-02 10:52:22,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.783333333333333, 32.16666666666666, 3.933333333333333, 178.3333333333333, 74.0, 0.0, 0.07500000000000018, 20.28939787861349, 25.0, 21.54221320587467, 22.7, 1.0, 63.11850308415741], 
actual action is [0.21666666666666679, 25], 
sim time next is 467700.0000, 
raw observation next is [-4.641666666666667, 32.08333333333334, 3.766666666666667, 179.1666666666667, 77.0, 0.0, 0.2166666666666668, 20.00361336393121, 25.0, 21.59958865998311, 22.7, 1.0, 62.88468980476539], 
processed observation next is [0.6666666666666666, 0.391304347826087, 0.21431623931623933, 0.3208333333333334, 0.34242424242424246, 0.49768518518518534, 0.2037037037037037, 0.0, 0.5036111111111111, 0.20003613363931208, 1.0, 0.5142269514261584, 0.6714285714285714, 1.0, 0.7398198800560634], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:23,605] A3C_AGENT_WORKER-Thread-10 INFO:Local step 27500, global step 438689: loss -16.6537
[2017-11-02 10:52:25,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  1.00000000e+00   1.02503327e-11   1.08320915e-10   2.42139607e-11
   8.77054722e-13   0.00000000e+00   4.58322745e-38   0.00000000e+00
   8.46306966e-37], sum to 1.0000
[2017-11-02 10:52:25,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-11.15, 51.5, 3.3, 195.0, 0.0, 0.0, -6.05833333333333, 21.02802700990436, 20.0, 21.36272131817135, 21.5, 0.0, 48.24846911344121], 
actual action is [-16.15, 18], 
sim time next is 426900.0000, 
raw observation next is [-11.24166666666667, 51.91666666666667, 3.35, 194.1666666666667, 0.0, 0.0, -16.15, 23.8169492368133, 18.0, 21.35401418031176, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.9565217391304348, 0.04508547008546998, 0.5191666666666667, 0.30454545454545456, 0.539351851851852, 0.0, 0.0, 0.23083333333333336, 0.238169492368133, 0.0, 0.47914488290168017, 0.5, 0.0, 0.0], 
reward next is -0.0209. 
=============================================
[2017-11-02 10:52:27,111] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  6.87055290e-04   2.53232196e-04   4.83180955e-03   9.07316164e-04
   8.93443284e-05   9.33208095e-04   1.94123033e-02   2.30520521e-03
   9.70580518e-01], sum to 1.0000
[2017-11-02 10:52:27,356] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 32.0, 3.6, 180.0, 80.0, 0.0, 0.3583333333333334, 19.189688850604, 25.0, 21.72109248519095, 22.7, 1.0, 62.62247543516149], 
actual action is [0.5, 25], 
sim time next is 468300.0000, 
raw observation next is [-4.316666666666666, 31.66666666666666, 3.683333333333333, 183.3333333333333, 83.0, 0.0, 0.5, 18.91715867326695, 25.0, 21.77695799951753, 22.7, 1.0, 62.43573121462858], 
processed observation next is [0.6666666666666666, 0.43478260869565216, 0.22264957264957266, 0.3166666666666666, 0.33484848484848484, 0.5092592592592591, 0.21957671957671956, 0.0, 0.5083333333333333, 0.1891715867326695, 1.0, 0.5395654285025044, 0.6714285714285714, 1.0, 0.7345380142897481], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:52:27,455] A3C_AGENT_WORKER-Thread-16 INFO:Local step 27500, global step 439113: loss -20.7978
[2017-11-02 10:52:30,437] A3C_AGENT_WORKER-Thread-4 INFO:Local step 27500, global step 439463: loss -30.6880
[2017-11-02 10:52:30,581] A3C_AGENT_WORKER-Thread-17 INFO:Local step 27500, global step 439480: loss 2.2636
[2017-11-02 10:52:30,751] A3C_AGENT_WORKER-Thread-8 INFO:Local step 27500, global step 439499: loss -14.3424
[2017-11-02 10:52:31,505] A3C_AGENT_WORKER-Thread-5 INFO:Local step 27500, global step 439584: loss 14.7415
[2017-11-02 10:52:42,578] A3C_AGENT_WORKER-Thread-2 INFO:Local step 27500, global step 440666: loss 0.6022
[2017-11-02 10:52:46,782] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   1.22293195e-38   0.00000000e+00
   0.00000000e+00   7.25076534e-04   6.29628589e-03   5.27778920e-03
   9.87700820e-01], sum to 1.0000
[2017-11-02 10:52:46,834] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [3.925, 86.5, 6.1, 275.0, 0.0, 0.0, 8.966666666666667, 6.204506645741499, 25.0, 23.9660422358322, 21.5, 0.0, 43.94006456422461], 
actual action is [8.925, 25], 
sim time next is 528600.0000, 
raw observation next is [3.883333333333333, 86.33333333333334, 6.1, 276.6666666666667, 0.0, 0.0, 8.925, 6.155671363865855, 25.0, 23.97144022542276, 21.5, 0.0, 44.4285133580196], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.43290598290598287, 0.8633333333333334, 0.5545454545454546, 0.7685185185185186, 0.0, 0.0, 0.6487499999999999, 0.06155671363865855, 1.0, 0.8530628893461086, 0.5, 0.0, 0.5226883924472894], 
reward next is -0.4704. 
=============================================
[2017-11-02 10:52:47,103] A3C_AGENT_WORKER-Thread-9 INFO:Local step 27500, global step 441142: loss 0.6605
[2017-11-02 10:52:47,489] A3C_AGENT_WORKER-Thread-14 INFO:Local step 27500, global step 441187: loss -2.1193
[2017-11-02 10:52:47,903] A3C_AGENT_WORKER-Thread-11 INFO:Local step 27500, global step 441235: loss 1.2103
[2017-11-02 10:52:47,970] A3C_AGENT_WORKER-Thread-12 INFO:Local step 27500, global step 441240: loss 1.0865
[2017-11-02 10:52:50,697] A3C_AGENT_WORKER-Thread-13 INFO:Local step 27500, global step 441580: loss 4.4363
[2017-11-02 10:52:54,526] A3C_AGENT_WORKER-Thread-15 INFO:Local step 27500, global step 442041: loss 0.7236
[2017-11-02 10:53:04,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   2.22925803e-10   9.21073773e-10   5.12654752e-10
   3.73069770e-11   9.00788656e-31   1.91325883e-29   3.48717565e-30
   1.80630336e-29], sum to 1.0000
[2017-11-02 10:53:04,426] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [3.341666666666667, 84.33333333333333, 6.1, 288.3333333333333, 0.0, 0.0, -1.566666666666666, 14.52073427000118, 18.0, 21.83758971865599, 21.5, 0.0, 0.0], 
actual action is [-1.6583333333333332, 18], 
sim time next is 531000.0000, 
raw observation next is [3.25, 84.0, 6.1, 290.0, 0.0, 0.0, -1.658333333333333, 15.96604436045766, 18.0, 21.87865704737865, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.4166666666666667, 0.84, 0.5545454545454546, 0.8055555555555556, 0.0, 0.0, 0.4723611111111111, 0.1596604436045766, 0.0, 0.5540938639112356, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:53:08,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  8.12273085e-01   3.11635877e-03   1.56766281e-01   2.58788336e-02
   1.96330459e-03   8.42953085e-09   8.98080089e-07   1.74468333e-08
   1.17017396e-06], sum to 1.0000
[2017-11-02 10:53:08,485] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.6, 85.0, 6.1, 280.0, 0.0, 0.0, -3.308333333333333, 20.62230990679152, 18.0, 21.00328896648827, 21.5, 0.0, 0.0], 
actual action is [-3.4, 18], 
sim time next is 536700.0000, 
raw observation next is [1.558333333333334, 85.24999999999999, 6.016666666666666, 279.9999999999999, 0.0, 0.0, -3.4, 22.53537884264912, 18.0, 20.94821557303171, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.3732905982905983, 0.8524999999999998, 0.5469696969696969, 0.7777777777777775, 0.0, 0.0, 0.44333333333333336, 0.2253537884264912, 0.0, 0.4211736532902443, 0.5, 0.0, 0.0], 
reward next is -0.0788. 
=============================================
[2017-11-02 10:53:08,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00878882
  0.43894276  0.01143623  0.54083228], sum to 1.0000
[2017-11-02 10:53:08,883] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.75, 90.33333333333334, 5.391666666666666, 285.8333333333334, 0.0, 0.0, -4.2, 27.00149231780817, 18.0, 20.59103765117712, 21.5, 0.0, 0.0], 
actual action is [5.75, 19.0], 
sim time next is 542400.0000, 
raw observation next is [0.7000000000000001, 90.66666666666666, 5.433333333333334, 286.6666666666666, 0.0, 0.0, 5.75, 23.31336416761033, 19.0, 20.30882267303637, 21.5, 0.0, 84.96132622695693], 
processed observation next is [0.8333333333333334, 0.2608695652173913, 0.35128205128205126, 0.9066666666666666, 0.49393939393939396, 0.7962962962962961, 0.0, 0.0, 0.5958333333333333, 0.23313364167610331, 0.14285714285714285, 0.32983181043376725, 0.5, 0.0, 0.9995450144347874], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:53:11,360] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28000, global step 445296: loss 5.6584
[2017-11-02 10:53:11,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.99309301e-01   7.75522931e-05   3.59782018e-04   2.11530758e-04
   4.09745808e-05   2.00508321e-08   4.61987923e-07   2.37891644e-08
   3.58700220e-07], sum to 1.0000
[2017-11-02 10:53:11,777] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.4166666666666667, 91.83333333333334, 5.35, 293.3333333333334, 23.0, 71.00000000000001, 5.458333333333333, 12.41885857591736, 25.0, 21.79402646714256, 22.7, 1.0, 69.44134718093409], 
actual action is [5.416666666666667, 20.0], 
sim time next is 548100.0000, 
raw observation next is [0.375, 91.75, 5.475, 295.0, 25.75, 79.25, 5.416666666666667, 12.12224356791404, 20.0, 21.92843289406641, 22.7, 1.0, 50.05863693728469], 
processed observation next is [0.8333333333333334, 0.34782608695652173, 0.34294871794871795, 0.9175, 0.4977272727272727, 0.8194444444444444, 0.06812169312169312, 0.07925, 0.5902777777777778, 0.1212224356791404, 0.2857142857142857, 0.5612046991523444, 0.6714285714285714, 1.0, 0.5889251404386434], 
reward next is -0.5422. 
=============================================
[2017-11-02 10:53:12,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02440093
  0.80799866  0.02833496  0.13926543], sum to 1.0000
[2017-11-02 10:53:12,497] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-2.8, 87.0, 5.558333333333333, 270.0, 0.0, 0.0, 2.2, 10.49742883123564, 25.0, 23.22134621642398, 21.5, 0.0, 45.59027526395683], 
actual action is [2.2, 25], 
sim time next is 587400.0000, 
raw observation next is [-2.8, 87.0, 5.516666666666667, 270.0, 0.0, 0.0, 2.2, 10.37343165226697, 25.0, 23.26085081777558, 21.5, 0.0, 45.57250808388185], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.2615384615384615, 0.87, 0.5015151515151515, 0.75, 0.0, 0.0, 0.5366666666666667, 0.10373431652266969, 1.0, 0.7515501168250829, 0.5, 0.0, 0.5361471539280218], 
reward next is -0.4825. 
=============================================
[2017-11-02 10:53:13,205] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28000, global step 445536: loss 51.7797
[2017-11-02 10:53:13,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.00000000e+00   7.02214509e-10   3.68248609e-09   5.78664938e-09
   7.66960051e-10   2.53563684e-26   3.64120878e-24   8.97262042e-26
   1.03081815e-24], sum to 1.0000
[2017-11-02 10:53:13,258] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-2.8, 87.0, 5.308333333333334, 270.0, 0.0, 0.0, 2.2, 10.22545128654459, 21.5, 23.35063434583619, 21.5, 0.0, 34.48886997475696], 
actual action is [-7.8, 18], 
sim time next is 589200.0000, 
raw observation next is [-2.8, 87.0, 5.266666666666666, 270.0, 0.0, 0.0, -7.8, 11.65757802021534, 18.0, 23.32753699624895, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.8260869565217391, 0.2615384615384615, 0.87, 0.4787878787878787, 0.75, 0.0, 0.0, 0.37, 0.1165757802021534, 0.0, 0.7610767137498498, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:53:14,703] A3C_AGENT_WORKER-Thread-7 INFO:Local step 28000, global step 445838: loss 8.7254
[2017-11-02 10:53:15,631] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28000, global step 446019: loss -269.5849
[2017-11-02 10:53:17,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   7.00539808e-31   4.84523010e-30   3.18204365e-30
   2.02615824e-31   8.87840346e-04   7.33056784e-01   1.98066365e-02
   2.46248662e-01], sum to 1.0000
[2017-11-02 10:53:17,967] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-0.7833333333333334, 81.16666666666667, 6.1, 329.1666666666667, 106.0833333333333, 243.75, 4.233333333333333, 12.68825435593955, 21.0, 22.45461467044509, 22.7, 1.0, 32.48718600017236], 
actual action is [4.216666666666667, 22.0], 
sim time next is 561600.0000, 
raw observation next is [-0.8, 81.0, 6.1, 330.0, 109.5, 265.5, 4.216666666666667, 12.82545552211372, 22.0, 22.45758485540058, 22.7, 1.0, 29.43141189194389], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.3128205128205128, 0.81, 0.5545454545454546, 0.9166666666666666, 0.2896825396825397, 0.2655, 0.5702777777777778, 0.12825455522113718, 0.5714285714285714, 0.636797836485797, 0.6714285714285714, 1.0, 0.34625190461110456], 
reward next is -0.3245. 
=============================================
[2017-11-02 10:53:21,660] A3C_AGENT_WORKER-Thread-8 INFO:Local step 28000, global step 446889: loss -22.0088
[2017-11-02 10:53:22,612] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28000, global step 447015: loss -44.5008
[2017-11-02 10:53:22,677] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28000, global step 447026: loss -72.0066
[2017-11-02 10:53:25,197] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28000, global step 447356: loss -46.0092
[2017-11-02 10:53:25,560] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28000, global step 447401: loss -45.4295
[2017-11-02 10:53:30,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.99996781e-01   5.83446933e-07   3.53123312e-07   2.26736893e-06
   2.56333053e-08   1.16963656e-15   9.44942299e-14   5.52343663e-15
   1.58093590e-13], sum to 1.0000
[2017-11-02 10:53:30,174] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.6, 54.0, 8.2, 250.0, 55.0, 26.5, 4.4, 13.05423696720178, 25.0, 22.73053306619569, 22.7, 1.0, 53.28897927127805], 
actual action is [4.4, 20.0], 
sim time next is 662700.0000, 
raw observation next is [-0.6499999999999999, 54.25, 8.2, 250.8333333333333, 50.33333333333333, 24.58333333333333, 4.4, 12.47491739109999, 20.0, 22.74035507491993, 22.7, 1.0, 67.21349502759621], 
processed observation next is [1.0, 0.6956521739130435, 0.31666666666666665, 0.5425, 0.7454545454545454, 0.6967592592592591, 0.13315696649029982, 0.02458333333333333, 0.5733333333333334, 0.12474917391099989, 0.2857142857142857, 0.6771935821314184, 0.6714285714285714, 1.0, 0.7907470003246613], 
reward next is -0.7241. 
=============================================
[2017-11-02 10:53:30,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  1.00000000e+00   7.45589701e-10   7.80084664e-10   4.85414597e-09
   2.93398292e-11   3.20373580e-31   1.42624607e-29   5.02666634e-31
   9.55842943e-30], sum to 1.0000
[2017-11-02 10:53:30,810] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.4, 83.0, 4.1, 260.0, 0.0, 0.0, 1.65, 19.55709849896449, 19.0, 20.9182036846031, 21.5, 0.0, 38.43289958269197], 
actual action is [-8.4, 18], 
sim time next is 601500.0000, 
raw observation next is [-3.399999999999999, 83.33333333333333, 4.141666666666666, 260.0, 0.0, 0.0, -8.4, 20.78241758187729, 18.0, 21.00166285781104, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 1.0, 0.2461538461538462, 0.8333333333333333, 0.3765151515151514, 0.7222222222222222, 0.0, 0.0, 0.36000000000000004, 0.2078241758187729, 0.0, 0.42880897968729165, 0.5, 0.0, 0.0], 
reward next is -0.0712. 
=============================================
[2017-11-02 10:53:33,367] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28000, global step 448543: loss 47.6337
[2017-11-02 10:53:36,960] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28000, global step 449076: loss -26.9941
[2017-11-02 10:53:37,420] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28000, global step 449147: loss 67.9303
[2017-11-02 10:53:37,855] A3C_AGENT_WORKER-Thread-9 INFO:Local step 28000, global step 449216: loss 10.7482
[2017-11-02 10:53:38,161] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28000, global step 449270: loss -127.9715
[2017-11-02 10:53:40,490] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   4.01375801e-05   1.47548818e-03   9.86526429e-05
   9.98385787e-01], sum to 1.0000
[2017-11-02 10:53:40,619] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.05, 58.5, 7.825, 260.0, 106.25, 65.25, -6.1, 23.13498284975023, 18.0, 21.5083729655905, 22.7, 1.0, 0.0], 
actual action is [3.95, 23.0], 
sim time next is 656400.0000, 
raw observation next is [-1.0, 58.00000000000001, 7.866666666666667, 260.0, 97.83333333333333, 62.16666666666667, 3.95, 19.4555790479704, 23.0, 21.32287971292582, 22.7, 1.0, 106.1906964362311], 
processed observation next is [1.0, 0.6086956521739131, 0.3076923076923077, 0.5800000000000001, 0.7151515151515152, 0.7222222222222222, 0.2588183421516755, 0.06216666666666667, 0.5658333333333334, 0.194555790479704, 0.7142857142857143, 0.47469710184654546, 0.6714285714285714, 1.0, 1.2493023110144834], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:53:40,865] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28000, global step 449774: loss -30.0217
[2017-11-02 10:53:40,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-78.12877655]
 [-75.94465637]
 [-79.71445465]
 [-79.94161987]
 [-75.72901154]], R is [[-75.78372955]
 [-76.02589417]
 [-76.26563263]
 [-76.50297546]
 [-76.73794556]].
[2017-11-02 10:53:44,134] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28000, global step 450182: loss -196.8661
[2017-11-02 10:53:44,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-87.29421234]
 [-87.2723999 ]
 [-84.9753952 ]
 [-88.76815033]
 [-87.8760376 ]], R is [[-86.44460297]
 [-85.6149826 ]
 [-85.28937531]
 [-84.93650055]
 [-84.57946777]].
[2017-11-02 10:53:55,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  0.00000000e+00   1.65735958e-30   3.66769856e-29   1.20528620e-31
   1.20241253e-29   1.18064654e-05   6.31526229e-04   2.83101399e-05
   9.99328375e-01], sum to 1.0000
[2017-11-02 10:53:55,190] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.3, 76.0, 5.266666666666667, 253.3333333333333, 0.0, 0.0, 2.7, 21.17821940400679, 25.0, 20.42497770120241, 21.5, 0.0, 53.34740353725905], 
actual action is [2.7, 25], 
sim time next is 711900.0000, 
raw observation next is [-2.3, 76.0, 5.35, 252.5, 0.0, 0.0, 2.7, 20.3593345456032, 25.0, 20.52159418652937, 21.5, 0.0, 48.95452111750554], 
processed observation next is [0.0, 0.21739130434782608, 0.27435897435897433, 0.76, 0.48636363636363633, 0.7013888888888888, 0.0, 0.0, 0.545, 0.203593345456032, 1.0, 0.36022774093276716, 0.5, 0.0, 0.5759355425588888], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:05,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99923348e-01   6.77357548e-06   6.55294280e-05   4.58030939e-07
   3.76454409e-06   3.56312940e-26   2.51745299e-23   6.12222820e-25
   1.48462895e-21], sum to 1.0000
[2017-11-02 10:54:05,412] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.2333333333333334, 54.66666666666667, 6.633333333333334, 250.0, 123.1666666666667, 504.0, -5.325, 16.97757794277556, 18.0, 22.1659705359722, 22.7, 1.0, 0.0], 
actual action is [-5.233333333333333, 18], 
sim time next is 735900.0000, 
raw observation next is [-0.1416666666666666, 54.08333333333333, 6.766666666666666, 250.0, 127.0833333333333, 476.5, -5.233333333333333, 18.27760755880023, 18.0, 22.07665773653276, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.32970085470085475, 0.5408333333333333, 0.6151515151515151, 0.6944444444444444, 0.33619929453262776, 0.4765, 0.41277777777777774, 0.1827760755880023, 0.0, 0.582379676647537, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:06,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  5.90259792e-29   4.48973387e-17   3.69438211e-16   8.18268000e-19
   5.15222018e-17   6.14082410e-06   7.69026438e-03   8.78958672e-05
   9.92215693e-01], sum to 1.0000
[2017-11-02 10:54:06,280] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 50.0, 7.7, 250.0, 110.0, 611.0, 5.408333333333333, 14.46190517834578, 23.0, 21.93260335395149, 22.7, 1.0, 89.49883674821017], 
actual action is [5.5, 25], 
sim time next is 738300.0000, 
raw observation next is [0.5, 49.58333333333333, 7.525, 251.6666666666667, 106.5, 638.0, 5.5, 13.03966414076225, 25.0, 22.10724001181314, 22.7, 1.0, 70.26607952054682], 
processed observation next is [0.0, 0.5652173913043478, 0.34615384615384615, 0.4958333333333333, 0.6840909090909091, 0.6990740740740742, 0.28174603174603174, 0.638, 0.5916666666666667, 0.1303966414076225, 1.0, 0.5867485731161628, 0.6714285714285714, 1.0, 0.8266597590652568], 
reward next is -0.7570. 
=============================================
[2017-11-02 10:54:07,752] A3C_AGENT_WORKER-Thread-6 INFO:Local step 28500, global step 453553: loss 263.2795
[2017-11-02 10:54:08,817] A3C_AGENT_WORKER-Thread-3 INFO:Local step 28500, global step 453754: loss 46.4178
[2017-11-02 10:54:10,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 28500, global step 454061: loss -61.6924
[2017-11-02 10:54:11,570] A3C_AGENT_WORKER-Thread-7 INFO:Local step 28500, global step 454274: loss -17.4010
[2017-11-02 10:54:17,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00125384
  0.35171038  0.00073342  0.6463024 ], sum to 1.0000
[2017-11-02 10:54:17,506] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-1.333333333333333, 67.33333333333334, 4.933333333333334, 260.0, 132.6666666666667, 64.83333333333334, 3.575, 10.92716608064029, 25.0, 22.99128726911747, 22.7, 1.0, 61.18570538172174], 
actual action is [3.666666666666667, 25], 
sim time next is 728700.0000, 
raw observation next is [-1.241666666666666, 67.16666666666666, 4.891666666666666, 260.0, 135.8333333333333, 66.41666666666666, 3.666666666666667, 10.73342113569212, 25.0, 23.06168200353858, 22.7, 1.0, 61.09310333495091], 
processed observation next is [0.0, 0.43478260869565216, 0.30149572649572653, 0.6716666666666665, 0.4446969696969696, 0.7222222222222222, 0.3593474426807759, 0.06641666666666665, 0.5611111111111111, 0.1073342113569212, 1.0, 0.7230974290769397, 0.6714285714285714, 1.0, 0.7187423921758931], 
reward next is -0.6576. 
=============================================
[2017-11-02 10:54:17,929] A3C_AGENT_WORKER-Thread-16 INFO:Local step 28500, global step 455093: loss 55.4026
[2017-11-02 10:54:20,203] A3C_AGENT_WORKER-Thread-17 INFO:Local step 28500, global step 455348: loss -97.5885
[2017-11-02 10:54:20,666] A3C_AGENT_WORKER-Thread-8 INFO:Local step 28500, global step 455402: loss 78.9232
[2017-11-02 10:54:20,956] A3C_AGENT_WORKER-Thread-5 INFO:Local step 28500, global step 455440: loss -49.9780
[2017-11-02 10:54:22,275] A3C_AGENT_WORKER-Thread-4 INFO:Local step 28500, global step 455600: loss 5.6491
[2017-11-02 10:54:28,003] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  8.59264135e-01   2.95779924e-03   1.33285031e-01   1.00156094e-03
   3.49152670e-03   1.59410828e-13   1.31535702e-11   1.64852981e-13
   2.56029850e-11], sum to 1.0000
[2017-11-02 10:54:28,100] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.300000000000001, 71.0, 3.25, 78.33333333333334, 0.0, 0.0, -2.3, 16.4482516255424, 24.0, 21.15666304457362, 21.5, 0.0, 46.08666069980757], 
actual action is [-2.3000000000000007, 19.0], 
sim time next is 798000.0000, 
raw observation next is [-7.3, 71.0, 3.2, 76.66666666666667, 0.0, 0.0, -2.300000000000001, 16.38414270970074, 19.0, 21.15572164823856, 21.5, 0.0, 46.00202700357101], 
processed observation next is [0.16666666666666666, 0.21739130434782608, 0.14615384615384616, 0.71, 0.29090909090909095, 0.21296296296296297, 0.0, 0.0, 0.46166666666666667, 0.16384142709700739, 0.14285714285714285, 0.45081737831979446, 0.5, 0.0, 0.5412003176890707], 
reward next is -0.5363. 
=============================================
[2017-11-02 10:54:28,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.02338059
  0.5622918   0.00890357  0.40542403], sum to 1.0000
[2017-11-02 10:54:28,279] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-7.25, 70.66666666666666, 2.958333333333333, 70.83333333333333, 0.0, 0.0, -2.3, 16.89762853655667, 20.0, 21.06681395491997, 21.5, 0.0, 45.69158292831853], 
actual action is [-2.25, 21.0], 
sim time next is 799800.0000, 
raw observation next is [-7.199999999999999, 70.33333333333334, 2.916666666666667, 71.66666666666667, 0.0, 0.0, -2.25, 17.02450936306293, 21.0, 21.07068544394284, 21.5, 0.0, 39.97391486832858], 
processed observation next is [0.16666666666666666, 0.2608695652173913, 0.14871794871794874, 0.7033333333333335, 0.2651515151515152, 0.1990740740740741, 0.0, 0.0, 0.4625, 0.17024509363062929, 0.42857142857142855, 0.4386693491346913, 0.5, 0.0, 0.4702813513921009], 
reward next is -0.4846. 
=============================================
[2017-11-02 10:54:31,934] A3C_AGENT_WORKER-Thread-2 INFO:Local step 28500, global step 456812: loss 31.8267
[2017-11-02 10:54:33,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.33809051e-03   1.70596298e-02   9.53745127e-01   8.12408049e-03
   1.92076024e-02   5.96429527e-06   4.26142098e-04   1.53634574e-06
   9.18900841e-05], sum to 1.0000
[2017-11-02 10:54:33,471] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-5.6, 61.0, 5.1, 350.0, 0.0, 0.0, -0.5499999999999998, 8.650947278101217, 25.0, 23.73094246485957, 21.5, 0.0, 39.31763537973384], 
actual action is [-0.5999999999999996, 24.0], 
sim time next is 767100.0000, 
raw observation next is [-5.649999999999999, 61.25, 4.975, 350.8333333333333, 0.0, 0.0, -0.5999999999999996, 8.670191011268855, 24.0, 23.69503028843591, 21.5, 0.0, 41.59519681586229], 
processed observation next is [0.0, 0.9130434782608695, 0.18846153846153849, 0.6125, 0.4522727272727272, 0.974537037037037, 0.0, 0.0, 0.49, 0.08670191011268855, 0.8571428571428571, 0.8135757554908442, 0.5, 0.0, 0.48935525665720336], 
reward next is -0.4404. 
=============================================
[2017-11-02 10:54:35,409] A3C_AGENT_WORKER-Thread-12 INFO:Local step 28500, global step 457247: loss 1.3591
[2017-11-02 10:54:35,856] A3C_AGENT_WORKER-Thread-14 INFO:Local step 28500, global step 457307: loss 71.8432
[2017-11-02 10:54:36,157] A3C_AGENT_WORKER-Thread-11 INFO:Local step 28500, global step 457346: loss 26.3134
[2017-11-02 10:54:37,194] A3C_AGENT_WORKER-Thread-9 INFO:Local step 28500, global step 457485: loss 32.9728
[2017-11-02 10:54:39,994] A3C_AGENT_WORKER-Thread-13 INFO:Local step 28500, global step 457857: loss 1.2635
[2017-11-02 10:54:41,323] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.00596023
  0.30088881  0.00133414  0.69181687], sum to 1.0000
[2017-11-02 10:54:41,462] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 71.0, 2.416666666666667, 60.0, 106.3333333333333, 0.0, 0.5, 13.27018611821652, 20.0, 22.60541471627734, 22.7, 1.0, 52.88679992050997], 
actual action is [0.5, 25.0], 
sim time next is 820500.0000, 
raw observation next is [-4.5, 71.0, 2.458333333333333, 60.0, 105.4166666666667, 0.0, 0.5, 13.21611162927438, 25.0, 22.61818845691355, 22.7, 1.0, 50.22892564751666], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.21794871794871795, 0.71, 0.22348484848484845, 0.16666666666666666, 0.2788800705467373, 0.0, 0.5083333333333333, 0.1321611162927438, 1.0, 0.6597412081305072, 0.6714285714285714, 1.0, 0.5909285370296078], 
reward next is -0.5451. 
=============================================
[2017-11-02 10:54:43,430] A3C_AGENT_WORKER-Thread-15 INFO:Local step 28500, global step 458287: loss 121.7998
[2017-11-02 10:54:55,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.69501970e-11   4.57683127e-05   1.86295286e-02   1.23480684e-04
   2.48147087e-04   3.58317536e-03   2.02535912e-01   1.98038784e-03
   7.72853613e-01], sum to 1.0000
[2017-11-02 10:54:55,926] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-0.65, 72.33333333333334, 2.958333333333333, 105.8333333333333, 0.0, 0.0, -5.7, 24.53698829652872, 18.0, 20.3135885135706, 21.5, 0.0, 0.0], 
actual action is [4.35, 23.0], 
sim time next is 882000.0000, 
raw observation next is [-0.6, 72.0, 3.0, 110.0, 0.0, 0.0, 4.35, 23.01371163868098, 23.0, 20.30612312656278, 21.5, 0.0, 48.37949434499764], 
processed observation next is [0.3333333333333333, 0.21739130434782608, 0.317948717948718, 0.72, 0.2727272727272727, 0.3055555555555556, 0.0, 0.0, 0.5725, 0.2301371163868098, 0.7142857142857143, 0.32944616093754014, 0.5, 0.0, 0.5691705217058546], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:54:57,086] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  1.06241349e-02   1.93768777e-02   8.97973001e-01   1.79031901e-02
   5.33577837e-02   3.58003632e-07   1.41143566e-04   1.72007503e-06
   6.21691230e-04], sum to 1.0000
[2017-11-02 10:54:57,153] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [-4.5, 79.0, 2.5, 80.0, 95.0, 0.0, 0.5, 14.83126693409174, 19.0, 22.23131677367121, 22.7, 1.0, 53.45768776261762], 
actual action is [-9.5, 18.0], 
sim time next is 824700.0000, 
raw observation next is [-4.45, 78.99999999999999, 2.5, 80.83333333333333, 94.33333333333333, 0.0, -9.5, 16.16216182131306, 18.0, 22.26615232075567, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.21923076923076926, 0.7899999999999998, 0.22727272727272727, 0.22453703703703703, 0.2495590828924162, 0.0, 0.3416666666666667, 0.1616216182131306, 0.0, 0.6094503315365242, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:02,368] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  1.10856972e-15   1.33794378e-10   1.67513303e-09   2.04904999e-11
   2.85150764e-10   2.75823497e-03   9.64594424e-01   1.89489557e-03
   3.07523981e-02], sum to 1.0000
[2017-11-02 10:55:02,435] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [3.25, 95.0, 3.6, 120.0, 104.0, 0.0, 8.158333333333333, 10.63304023310319, 24.0, 23.15791347228304, 22.7, 1.0, 32.30746746212602], 
actual action is [8.25, 25.0], 
sim time next is 909300.0000, 
raw observation next is [3.341666666666667, 94.66666666666666, 3.6, 118.3333333333333, 103.3333333333333, 0.0, 8.25, 10.78356316049828, 25.0, 23.14945417940487, 22.7, 1.0, 27.71936316175174], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.4190170940170941, 0.9466666666666665, 0.32727272727272727, 0.3287037037037036, 0.27336860670193996, 0.0, 0.6375, 0.1078356316049828, 1.0, 0.7356363113435529, 0.6714285714285714, 1.0, 0.32611015484413813], 
reward next is -0.3043. 
=============================================
[2017-11-02 10:55:03,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99872088e-01   3.07368691e-06   1.09161025e-04   2.60383194e-06
   1.30072212e-05   4.05934187e-17   2.51418628e-15   1.39169896e-17
   3.75300473e-16], sum to 1.0000
[2017-11-02 10:55:03,434] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 83.0, 3.975, 80.0, 44.0, 0.0, 1.100000000000001, 15.74407168085608, 20.0, 22.33465087620076, 22.7, 1.0, 33.03975633781224], 
actual action is [-8.9, 18], 
sim time next is 834600.0000, 
raw observation next is [-3.9, 82.66666666666667, 4.016666666666667, 80.0, 42.33333333333334, 0.0, -8.9, 17.56566034626146, 18.0, 22.28585291394512, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.23333333333333334, 0.8266666666666667, 0.36515151515151517, 0.2222222222222222, 0.11199294532627868, 0.0, 0.3516666666666667, 0.1756566034626146, 0.0, 0.6122647019921601, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:05,240] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-45.40746689]
 [-44.9893837 ]
 [-45.15505219]
 [-44.69604492]
 [-44.97864532]], R is [[-44.82010269]
 [-44.73168564]
 [-44.69838333]
 [-44.85802841]
 [-44.47412872]].
[2017-11-02 10:55:07,317] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29000, global step 461404: loss 7.4175
[2017-11-02 10:55:09,373] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   3.07650257e-37   8.91109522e-36   1.99594003e-37
   2.79716303e-36   1.04762517e-01   7.27862120e-01   3.05640213e-02
   1.36811331e-01], sum to 1.0000
[2017-11-02 10:55:09,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.608333333333333, 84.25, 3.6, 65.83333333333333, 0.0, 0.0, 1.35, 11.85269892970195, 25.0, 23.19195365428152, 22.7, 1.0, 60.93331626705335], 
actual action is [1.391666666666667, 25], 
sim time next is 848400.0000, 
raw observation next is [-3.566666666666666, 84.0, 3.6, 66.66666666666667, 0.0, 0.0, 1.391666666666667, 11.76790303089591, 25.0, 23.22276900574307, 22.7, 1.0, 60.91464629558472], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.24188034188034188, 0.84, 0.32727272727272727, 0.1851851851851852, 0.0, 0.0, 0.5231944444444444, 0.1176790303089591, 1.0, 0.7461098579632959, 0.6714285714285714, 1.0, 0.7166428975951143], 
reward next is -0.6567. 
=============================================
[2017-11-02 10:55:09,934] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [ 0.          0.          0.          0.          0.          0.06941216
  0.8551634   0.04394636  0.03147805], sum to 1.0000
[2017-11-02 10:55:10,038] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [3.433333333333334, 94.33333333333334, 3.6, 116.6666666666667, 102.6666666666667, 0.0, 8.341666666666667, 8.51363854768943, 25.0, 23.91939312522937, 22.7, 1.0, 62.275207198072], 
actual action is [8.433333333333334, 25], 
sim time next is 909900.0000, 
raw observation next is [3.524999999999999, 94.0, 3.6, 115.0, 102.0, 0.0, 8.433333333333334, 8.309281574636506, 25.0, 23.96266567561823, 22.7, 1.0, 62.35909997616904], 
processed observation next is [0.3333333333333333, 0.5217391304347826, 0.42371794871794866, 0.94, 0.32727272727272727, 0.3194444444444444, 0.2698412698412698, 0.0, 0.6405555555555557, 0.08309281574636505, 1.0, 0.8518093822311756, 0.6714285714285714, 1.0, 0.733636470307871], 
reward next is -0.6686. 
=============================================
[2017-11-02 10:55:10,764] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  0.00000000e+00   1.18754301e-36   1.17610613e-35   6.23275405e-37
   4.21303302e-36   5.57596833e-02   8.55723321e-01   3.84518988e-02
   5.00650965e-02], sum to 1.0000
[2017-11-02 10:55:10,803] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [0.0, 72.0, 2.916666666666667, 115.0, 9.666666666666664, 0.0, 5.0, 15.45171141768329, 22.5, 21.84110369120812, 22.7, 1.0, 29.34930081241493], 
actual action is [5.0, 23.5], 
sim time next is 892500.0000, 
raw observation next is [0.0, 72.0, 2.958333333333333, 117.5, 12.08333333333333, 0.0, 5.0, 15.92319905386214, 23.5, 21.78107771452243, 22.7, 1.0, 27.16864687729231], 
processed observation next is [0.3333333333333333, 0.30434782608695654, 0.3333333333333333, 0.72, 0.2689393939393939, 0.3263888888888889, 0.031966490299823624, 0.0, 0.5833333333333334, 0.1592319905386214, 0.7857142857142857, 0.5401539592174898, 0.6714285714285714, 1.0, 0.31963113973285073], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:10,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29000, global step 461813: loss 27.6451
[2017-11-02 10:55:13,242] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29000, global step 462125: loss 1.3057
[2017-11-02 10:55:14,310] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29000, global step 462284: loss 23.4551
[2017-11-02 10:55:21,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29000, global step 463348: loss 5.4169
[2017-11-02 10:55:21,591] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29000, global step 463413: loss 19.1555
[2017-11-02 10:55:23,843] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29000, global step 463685: loss 10.4881
[2017-11-02 10:55:25,402] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29000, global step 463877: loss 21.7880
[2017-11-02 10:55:26,032] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29000, global step 463939: loss 0.0678
[2017-11-02 10:55:32,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.97166574e-01   4.30048131e-05   2.15699896e-03   5.77051018e-04
   5.63135327e-05   2.55002391e-11   3.20694964e-11   4.07531344e-12
   4.53430072e-13], sum to 1.0000
[2017-11-02 10:55:32,209] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.324999999999999, 83.75, 5.1, 152.5, 0.0, 0.0, 11.23333333333333, 13.82408343787382, 19.5, 21.69439149228581, 21.5, 0.0, 15.82423531957514], 
actual action is [1.3249999999999993, 18], 
sim time next is 957000.0000, 
raw observation next is [6.416666666666666, 83.16666666666667, 5.1, 151.6666666666667, 0.0, 0.0, 1.324999999999999, 14.39670307077042, 18.0, 21.72198914383656, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.043478260869565216, 0.4978632478632478, 0.8316666666666667, 0.4636363636363636, 0.42129629629629645, 0.0, 0.0, 0.5220833333333333, 0.1439670307077042, 0.0, 0.5317127348337942, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:34,030] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29000, global step 465147: loss 11.2152
[2017-11-02 10:55:35,209] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29000, global step 465369: loss 111.2722
[2017-11-02 10:55:35,431] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99946833e-01   1.21405606e-06   4.18030104e-05   9.01408839e-06
   1.02386764e-06   2.86344329e-23   5.94139678e-23   4.19679760e-24
   1.36933710e-24], sum to 1.0000
[2017-11-02 10:55:35,516] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [8.708333333333334, 83.0, 5.1, 178.3333333333333, 0.0, 0.0, 3.616666666666667, 20.60523279664202, 18.0, 20.92067428167926, 21.5, 0.0, 0.0], 
actual action is [3.708333333333334, 18], 
sim time next is 968400.0000, 
raw observation next is [8.8, 83.0, 5.1, 180.0, 0.0, 0.0, 3.708333333333334, 20.85801750153198, 18.0, 20.89276481197653, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.21739130434782608, 0.558974358974359, 0.83, 0.4636363636363636, 0.5, 0.0, 0.0, 0.5618055555555556, 0.20858017501531978, 0.0, 0.4132521159966472, 0.5, 0.0, 0.0], 
reward next is -0.0867. 
=============================================
[2017-11-02 10:55:36,611] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29000, global step 465665: loss 29.3918
[2017-11-02 10:55:37,067] A3C_AGENT_WORKER-Thread-9 INFO:Local step 29000, global step 465774: loss -188.7698
[2017-11-02 10:55:38,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99999523e-01   1.08389941e-09   4.40463850e-07   1.87549229e-08
   2.33687536e-09   4.02116159e-37   1.32805449e-35   5.57295682e-37
   8.56828623e-36], sum to 1.0000
[2017-11-02 10:55:38,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.0, 96.33333333333334, 4.183333333333333, 120.0, 0.0, 0.0, 0.0, 22.73569619742262, 18.0, 20.96579806829638, 21.5, 0.0, 0.0], 
actual action is [0.0, 18], 
sim time next is 943200.0000, 
raw observation next is [5.0, 96.0, 4.1, 120.0, 0.0, 0.0, 0.0, 23.0278402629798, 18.0, 20.92608977211334, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.9565217391304348, 0.46153846153846156, 0.96, 0.3727272727272727, 0.3333333333333333, 0.0, 0.0, 0.5, 0.230278402629798, 0.0, 0.41801282458761996, 0.5, 0.0, 0.0], 
reward next is -0.0820. 
=============================================
[2017-11-02 10:55:39,256] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29000, global step 466265: loss 116.3443
[2017-11-02 10:55:40,227] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29000, global step 466430: loss -130.8849
[2017-11-02 10:55:43,776] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  1.49506249e-07   2.41689634e-07   1.67740257e-06   2.00673048e-06
   3.51838821e-07   1.71374977e-01   6.79064155e-01   1.19529538e-01
   3.00269052e-02], sum to 1.0000
[2017-11-02 10:55:43,810] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [11.7, 86.0, 6.433333333333334, 193.3333333333333, 112.0, 0.0, 6.65, 12.12618615587462, 18.0, 22.7498260794826, 22.7, 1.0, 0.0], 
actual action is [16.7, 19.0], 
sim time next is 990900.0000, 
raw observation next is [11.75, 86.0, 6.35, 195.0, 114.0, 0.0, 16.7, 11.87926601144798, 19.0, 22.73857695829786, 22.7, 1.0, 24.82544984532384], 
processed observation next is [0.5, 0.4782608695652174, 0.6346153846153846, 0.86, 0.5772727272727273, 0.5416666666666666, 0.30158730158730157, 0.0, 0.7783333333333334, 0.1187926601144798, 0.14285714285714285, 0.6769395654711227, 0.6714285714285714, 1.0, 0.29206411582733927], 
reward next is -0.2747. 
=============================================
[2017-11-02 10:55:43,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99757826e-01   8.53431629e-06   1.29107837e-04   9.63850034e-05
   8.18411081e-06   5.13046626e-19   1.88198044e-18   2.44941027e-19
   2.27829865e-19], sum to 1.0000
[2017-11-02 10:55:43,982] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29000, global step 467195: loss 5.7364
[2017-11-02 10:55:43,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  2.74828933e-13   6.26327046e-11   1.24191004e-08   7.42121742e-09
   2.23452576e-10   2.56565392e-01   6.17010474e-01   8.33352655e-02
   4.30888757e-02], sum to 1.0000
[2017-11-02 10:55:43,998] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [14.4, 75.0, 4.1, 180.8333333333333, 0.0, 0.0, 9.4, 11.08477991259621, 18.0, 22.6191233357144, 21.5, 0.0, 0.0], 
actual action is [9.4, 18], 
sim time next is 1033800.0000, 
raw observation next is [14.4, 75.0, 4.1, 181.6666666666667, 0.0, 0.0, 9.4, 11.12000425407401, 18.0, 22.61192722119225, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 1.0, 0.7025641025641025, 0.75, 0.3727272727272727, 0.5046296296296298, 0.0, 0.0, 0.6566666666666666, 0.11120004254074009, 0.0, 0.6588467458846071, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:44,092] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [5.0, 97.0, 4.35, 120.0, 0.0, 0.0, 0.0, 22.87980321091535, 18.0, 20.93565817832779, 21.5, 0.0, 0.0], 
actual action is [10.0, 19.0], 
sim time next is 942600.0000, 
raw observation next is [5.0, 96.66666666666666, 4.266666666666667, 120.0, 0.0, 0.0, 10.0, 21.19575147820858, 19.0, 20.85854108698798, 21.5, 0.0, 44.68898808800684], 
processed observation next is [0.3333333333333333, 0.9130434782608695, 0.46153846153846156, 0.9666666666666666, 0.3878787878787879, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.21195751478208583, 0.14285714285714285, 0.4083630124268543, 0.5, 0.0, 0.5257528010353746], 
reward next is -0.5648. 
=============================================
[2017-11-02 10:55:47,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-13.63201427]
 [-14.08394527]
 [-13.43881035]
 [-15.98387432]
 [-15.59074783]], R is [[-16.90137482]
 [-17.73236084]
 [-18.55503654]
 [-18.46552849]
 [-18.37391472]].
[2017-11-02 10:55:49,369] A3C_AGENT_WORKER-Thread-6 INFO:Local step 29500, global step 468640: loss 2.2609
[2017-11-02 10:55:49,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999285e-01   2.18066045e-08   3.75153860e-07   3.55307776e-07
   2.14142144e-08   1.22933372e-25   2.98478219e-25   2.35670146e-26
   2.92054734e-26], sum to 1.0000
[2017-11-02 10:55:49,574] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.791666666666667, 83.0, 5.1, 161.6666666666667, 0.0, 0.0, 2.7, 24.84309257456859, 18.0, 20.69837191821015, 21.5, 0.0, 0.0], 
actual action is [2.791666666666667, 18], 
sim time next is 965400.0000, 
raw observation next is [7.883333333333334, 83.0, 5.1, 163.3333333333333, 0.0, 0.0, 2.791666666666667, 25.58929569960825, 18.0, 20.688302879629, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.17391304347826086, 0.5354700854700855, 0.83, 0.4636363636363636, 0.45370370370370355, 0.0, 0.0, 0.5465277777777777, 0.2558929569960825, 0.0, 0.38404326851842846, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:50,419] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-23.26151276]
 [-20.69069862]
 [-20.80579758]
 [-22.27168274]
 [-21.04619789]], R is [[-20.47130585]
 [-20.28153038]
 [-20.09362984]
 [-19.90758514]
 [-19.72337532]].
[2017-11-02 10:55:50,968] A3C_AGENT_WORKER-Thread-10 INFO:Local step 29500, global step 469067: loss 10.7695
[2017-11-02 10:55:52,045] A3C_AGENT_WORKER-Thread-7 INFO:Local step 29500, global step 469325: loss 2.4135
[2017-11-02 10:55:52,489] A3C_AGENT_WORKER-Thread-3 INFO:Local step 29500, global step 469435: loss 6.2237
[2017-11-02 10:55:54,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99971390e-01   6.61963156e-07   1.15175208e-05   1.48679810e-05
   1.50235621e-06   1.34348611e-21   8.17553006e-21   6.28508228e-22
   2.15508305e-20], sum to 1.0000
[2017-11-02 10:55:54,088] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [15.13333333333333, 79.0, 6.100000000000001, 193.3333333333333, 0.0, 0.0, 10.225, 15.91943310656556, 18.0, 21.75670674581773, 22.7, 1.0, 0.0], 
actual action is [10.13333333333333, 18], 
sim time next is 1013100.0000, 
raw observation next is [15.04166666666667, 79.25, 6.1, 194.1666666666667, 0.0, 0.0, 10.13333333333333, 15.98207420583891, 18.0, 21.74331334121989, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.7190170940170941, 0.7925, 0.5545454545454546, 0.539351851851852, 0.0, 0.0, 0.6688888888888888, 0.1598207420583891, 0.0, 0.5347590487456984, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:55:55,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  9.62915301e-01   1.14814853e-02   1.07107423e-02   9.59885027e-03
   5.29355183e-03   3.24663052e-09   6.27382013e-09   2.29769626e-09
   3.16852033e-09], sum to 1.0000
[2017-11-02 10:55:55,314] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [18.95, 52.75, 3.525, 172.5, 147.75, 0.0, 13.9, 9.4950927638586, 18.0, 23.28388888572746, 21.5, 0.0, 0.0], 
actual action is [13.95, 18], 
sim time next is 1088400.0000, 
raw observation next is [19.0, 52.33333333333334, 3.7, 173.3333333333333, 145.1666666666667, 0.0, 13.95, 9.47259074401071, 18.0, 23.29160698668127, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.8205128205128205, 0.5233333333333334, 0.33636363636363636, 0.48148148148148134, 0.3840388007054675, 0.0, 0.7325, 0.09472590744010709, 0.0, 0.7559438552401814, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:55:57,555] A3C_AGENT_WORKER-Thread-5 INFO:Local step 29500, global step 470751: loss 56.1543
[2017-11-02 10:55:59,201] A3C_AGENT_WORKER-Thread-16 INFO:Local step 29500, global step 471163: loss 41.2171
[2017-11-02 10:55:59,416] A3C_AGENT_WORKER-Thread-8 INFO:Local step 29500, global step 471229: loss 15.8228
[2017-11-02 10:56:00,041] A3C_AGENT_WORKER-Thread-17 INFO:Local step 29500, global step 471413: loss 27.3806
[2017-11-02 10:56:00,115] A3C_AGENT_WORKER-Thread-4 INFO:Local step 29500, global step 471427: loss 39.3550
[2017-11-02 10:56:03,091] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.97942281e-01   1.76410511e-01   2.60994494e-01   1.38339490e-01
   1.26268402e-01   1.37555662e-05   1.92411117e-05   7.95934920e-06
   3.84460509e-06], sum to 1.0000
[2017-11-02 10:56:03,152] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [19.4, 49.0, 3.35, 171.6666666666667, 73.0, 0.0, 14.4, 10.61319242186473, 18.0, 22.97146217451743, 21.5, 0.0, 0.0], 
actual action is [14.399999999999999, 18], 
sim time next is 1094100.0000, 
raw observation next is [19.4, 49.0, 3.175, 170.8333333333333, 68.25, 0.0, 14.4, 10.59569458669045, 18.0, 22.97436289252872, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.8307692307692307, 0.49, 0.28863636363636364, 0.4745370370370369, 0.18055555555555555, 0.0, 0.74, 0.1059569458669045, 0.0, 0.7106232703612457, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 10:56:05,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.40034246e-01   1.96898039e-02   7.76504353e-02   3.04970946e-02
   3.21283974e-02   3.74719202e-15   8.20976096e-15   2.36819761e-15
   7.10170380e-15], sum to 1.0000
[2017-11-02 10:56:05,325] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [11.6, 78.0, 5.683333333333334, 108.3333333333333, 0.0, 0.0, 6.6, 19.64120016427876, 18.0, 20.8886229825848, 21.5, 0.0, 0.0], 
actual action is [6.6, 18], 
sim time next is 1142100.0000, 
raw observation next is [11.6, 78.5, 5.725, 107.5, 0.0, 0.0, 6.6, 19.674298483464, 18.0, 20.88570412418712, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.21739130434782608, 0.6307692307692309, 0.785, 0.5204545454545454, 0.2986111111111111, 0.0, 0.0, 0.61, 0.19674298483464, 0.0, 0.4122434463124459, 0.5, 0.0, 0.0], 
reward next is -0.0878. 
=============================================
[2017-11-02 10:56:05,393] A3C_AGENT_WORKER-Thread-2 INFO:Local step 29500, global step 473064: loss -14.7589
[2017-11-02 10:56:05,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.24028777e-03   1.61530264e-02   5.82650304e-01   2.98561990e-01
   9.93941724e-02   6.01475481e-10   8.24576389e-08   1.03592823e-08
   1.79544301e-07], sum to 1.0000
[2017-11-02 10:56:05,886] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [13.71666666666667, 60.33333333333333, 4.516666666666667, 158.3333333333333, 0.0, 0.0, 8.75833333333333, 12.89148617774649, 18.0, 22.18912745613947, 22.7, 1.0, 0.0], 
actual action is [8.71666666666667, 18], 
sim time next is 1109700.0000, 
raw observation next is [13.675, 60.5, 4.475, 157.5, 0.0, 0.0, 8.71666666666667, 12.97429674217101, 18.0, 22.16780145562853, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.683974358974359, 0.605, 0.4068181818181818, 0.4375, 0.0, 0.0, 0.6452777777777778, 0.1297429674217101, 0.0, 0.595400207946933, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 10:56:06,540] A3C_AGENT_WORKER-Thread-5 DEBUG:Value prediction is [[-18.83419418]
 [-15.74446011]
 [-17.36258888]
 [-15.58142185]
 [-20.43033791]], R is [[-17.55289841]
 [-17.46186829]
 [-17.36932945]
 [-17.27531433]
 [-17.17984962]].
[2017-11-02 10:56:07,169] A3C_AGENT_WORKER-Thread-9 INFO:Local step 29500, global step 473611: loss 46.5989
[2017-11-02 10:56:07,883] A3C_AGENT_WORKER-Thread-12 INFO:Local step 29500, global step 473835: loss 22.6060
[2017-11-02 10:56:08,094] A3C_AGENT_WORKER-Thread-14 INFO:Local step 29500, global step 473895: loss 7.3134
[2017-11-02 10:56:08,106] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  7.18288481e-01   4.65507507e-02   8.54320154e-02   9.62724313e-02
   5.34562729e-02   2.25720983e-12   2.75006341e-12   9.71999608e-13
   2.08452201e-12], sum to 1.0000
[2017-11-02 10:56:08,125] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.825, 77.5, 5.35, 120.0, 0.0, 0.0, 5.733333333333331, 22.2493542579693, 18.0, 20.34913074312558, 21.5, 0.0, 0.0], 
actual action is [5.824999999999999, 18], 
sim time next is 1133400.0000, 
raw observation next is [10.91666666666667, 77.33333333333334, 5.433333333333334, 120.0, 0.0, 0.0, 5.824999999999999, 22.298519127678, 18.0, 20.34163911921345, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.6132478632478634, 0.7733333333333334, 0.49393939393939396, 0.3333333333333333, 0.0, 0.0, 0.5970833333333334, 0.22298519127678, 0.0, 0.33451987417335005, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:56:10,307] A3C_AGENT_WORKER-Thread-11 INFO:Local step 29500, global step 474609: loss 16.0810
[2017-11-02 10:56:10,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 29500, global step 474760: loss 12.9180
[2017-11-02 10:56:13,259] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [ 0.20449628  0.18204173  0.25686887  0.18758404  0.15345979  0.00546287
  0.00508336  0.00329736  0.00170574], sum to 1.0000
[2017-11-02 10:56:13,267] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 2, 
current raw observation is [18.3, 65.0, 9.2, 140.0, 145.0, 0.0, 13.20833333333333, 18.55184417191404, 18.0, 21.06265302229817, 21.5, 0.0, 0.0], 
actual action is [13.3, 18], 
sim time next is 1163100.0000, 
raw observation next is [18.34166666666667, 64.83333333333333, 9.241666666666665, 141.6666666666667, 147.5, 0.0, 13.3, 18.41347748094165, 18.0, 21.08833532178769, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.4782608695652174, 0.8036324786324787, 0.6483333333333333, 0.840151515151515, 0.39351851851851866, 0.39021164021164023, 0.0, 0.7216666666666666, 0.1841347748094165, 0.0, 0.4411907602553841, 0.5, 0.0, 0.0], 
reward next is -0.0588. 
=============================================
[2017-11-02 10:56:15,000] A3C_AGENT_WORKER-Thread-15 INFO:Local step 29500, global step 475963: loss -1.2000
[2017-11-02 10:56:16,594] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30000, global step 476377: loss -1.2903
[2017-11-02 10:56:17,212] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30000, global step 476538: loss -1.2288
[2017-11-02 10:56:18,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  5.29320017e-02   1.45227388e-01   2.47693092e-01   3.44628483e-01
   2.09506705e-01   2.49369600e-06   5.17294029e-06   2.24775044e-06
   2.40751342e-06], sum to 1.0000
[2017-11-02 10:56:18,837] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [10.5, 77.0, 4.6, 140.0, 0.0, 0.0, 5.59166666666667, 17.67825816657993, 18.0, 21.47792984789867, 22.7, 1.0, 0.0], 
actual action is [5.5, 18], 
sim time next is 1127100.0000, 
raw observation next is [10.45833333333333, 77.16666666666666, 4.6, 138.3333333333333, 0.0, 0.0, 5.5, 17.78302016931792, 18.0, 21.45668452807584, 22.7, 1.0, 0.0], 
processed observation next is [0.8333333333333334, 0.043478260869565216, 0.6014957264957264, 0.7716666666666666, 0.41818181818181815, 0.38425925925925913, 0.0, 0.0, 0.5916666666666667, 0.17783020169317917, 0.0, 0.4938120754394057, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:56:20,127] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30000, global step 477271: loss -0.1618
[2017-11-02 10:56:21,441] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30000, global step 477619: loss 0.3031
[2017-11-02 10:56:24,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-16.74765015]
 [-15.43551731]
 [-15.46630096]
 [-15.17015266]
 [-13.75564957]], R is [[-17.57540512]
 [-17.41018486]
 [-17.24660683]
 [-17.08465195]
 [-16.92430305]].
[2017-11-02 10:56:24,397] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30000, global step 478478: loss 19.8735
[2017-11-02 10:56:26,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30000, global step 479146: loss 3.5705
[2017-11-02 10:56:27,247] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30000, global step 479211: loss -1.1349
[2017-11-02 10:56:27,472] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30000, global step 479278: loss 0.8608
[2017-11-02 10:56:28,514] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30000, global step 479595: loss -1.4952
[2017-11-02 10:56:33,571] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30000, global step 481101: loss 22.9031
[2017-11-02 10:56:36,101] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30000, global step 481737: loss -9.4140
[2017-11-02 10:56:36,455] A3C_AGENT_WORKER-Thread-9 INFO:Local step 30000, global step 481808: loss 2.7701
[2017-11-02 10:56:37,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30000, global step 481974: loss 1.6655
[2017-11-02 10:56:39,298] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30000, global step 482499: loss -1.7253
[2017-11-02 10:56:41,005] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30000, global step 482896: loss 0.0329
[2017-11-02 10:56:43,670] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30000, global step 483560: loss -10.8501
[2017-11-02 10:56:49,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  1.88203416e-30   8.30770576e-20   5.05722757e-21   6.82895999e-21
   8.41230598e-20   1.74539426e-04   5.32638398e-04   4.30410117e-04
   9.98862386e-01], sum to 1.0000
[2017-11-02 10:56:49,541] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 92.0, 6.141666666666666, 259.1666666666666, 7.499999999999999, 0.0, 6.1, 15.01116072841872, 25.0, 21.02450330685676, 22.7, 1.0, 61.59010346300193], 
actual action is [6.1, 25], 
sim time next is 1324800.0000, 
raw observation next is [1.1, 92.0, 6.1, 260.0, 9.0, 0.0, 6.1, 13.64639091135211, 25.0, 21.13453339687123, 22.7, 1.0, 72.21686873390469], 
processed observation next is [0.0, 0.34782608695652173, 0.36153846153846153, 0.92, 0.5545454545454546, 0.7222222222222222, 0.023809523809523808, 0.0, 0.6016666666666667, 0.1364639091135211, 1.0, 0.4477904852673186, 0.6714285714285714, 1.0, 0.8496102203988787], 
reward next is -0.7783. 
=============================================
[2017-11-02 10:56:56,071] A3C_AGENT_WORKER-Thread-6 INFO:Local step 30500, global step 485641: loss 9.3201
[2017-11-02 10:56:56,563] A3C_AGENT_WORKER-Thread-10 INFO:Local step 30500, global step 485719: loss 3.4317
[2017-11-02 10:57:00,689] A3C_AGENT_WORKER-Thread-7 INFO:Local step 30500, global step 486375: loss 25.1121
[2017-11-02 10:57:01,091] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-26.57824898]
 [-25.07042313]
 [-28.33364487]
 [-26.30947495]
 [-25.70636368]], R is [[-26.87946129]
 [-26.62017632]
 [-26.36319733]
 [-26.1084938 ]
 [-25.85603714]].
[2017-11-02 10:57:02,447] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.89214872e-04   3.89477878e-04   2.66511088e-05   8.74256293e-05
   6.88621891e-04   7.96529785e-05   1.85702404e-04   8.67082272e-05
   9.98266518e-01], sum to 1.0000
[2017-11-02 10:57:02,515] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.5, 96.0, 5.183333333333334, 280.0, 5.999999999999998, 0.0, -4.5, 10.75851658641164, 18.0, 22.42551198671069, 22.7, 1.0, 0.0], 
actual action is [5.5, 23.0], 
sim time next is 1358100.0000, 
raw observation next is [0.5, 96.0, 5.225, 280.0, 0.0, 0.0, 5.5, 9.963339324520755, 23.0, 22.41325879877046, 22.7, 1.0, 55.76166705121513], 
processed observation next is [0.0, 0.7391304347826086, 0.34615384615384615, 0.96, 0.475, 0.7777777777777778, 0.0, 0.0, 0.5916666666666667, 0.09963339324520755, 0.7142857142857143, 0.6304655426814944, 0.6714285714285714, 1.0, 0.6560196123672368], 
reward next is -0.6004. 
=============================================
[2017-11-02 10:57:02,590] A3C_AGENT_WORKER-Thread-3 INFO:Local step 30500, global step 486701: loss 50.4163
[2017-11-02 10:57:04,655] A3C_AGENT_WORKER-Thread-5 INFO:Local step 30500, global step 487022: loss 5.4575
[2017-11-02 10:57:05,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 30500, global step 487222: loss 2.6050
[2017-11-02 10:57:05,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.45478439e-01   2.64311340e-02   2.77750171e-03   6.00473350e-03
   1.93026438e-02   5.80624544e-08   1.18871306e-07   3.91422148e-08
   5.32076319e-06], sum to 1.0000
[2017-11-02 10:57:05,969] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 5.766666666666666, 274.1666666666666, 114.1666666666667, 0.0, 6.1, 9.286165261301615, 20.0, 22.4029345505784, 22.7, 1.0, 51.33628244997269], 
actual action is [-3.9, 18], 
sim time next is 1341000.0000, 
raw observation next is [1.1, 92.0, 5.6, 275.0, 113.0, 0.0, -3.9, 9.710856554133908, 18.0, 22.47329779034098, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.36153846153846153, 0.92, 0.509090909090909, 0.7638888888888888, 0.29894179894179895, 0.0, 0.435, 0.09710856554133908, 0.0, 0.6390425414772827, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0097. 
=============================================
[2017-11-02 10:57:07,280] A3C_AGENT_WORKER-Thread-4 INFO:Local step 30500, global step 487468: loss 4.4156
[2017-11-02 10:57:07,366] A3C_AGENT_WORKER-Thread-17 INFO:Local step 30500, global step 487487: loss -28.0824
[2017-11-02 10:57:07,453] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.61017549e-01   1.05152382e-02   2.22989102e-03   4.45773406e-03
   2.17796247e-02   8.80432359e-12   1.34118853e-11   5.40782306e-12
   9.07484576e-09], sum to 1.0000
[2017-11-02 10:57:07,468] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 96.0, 5.85, 280.0, 0.0, 0.0, 5.5, 15.39315546264628, 23.0, 21.08725000622811, 21.5, 0.0, 88.48180146881194], 
actual action is [-4.5, 18.0], 
sim time next is 1374600.0000, 
raw observation next is [0.5, 96.0, 5.933333333333333, 280.0, 0.0, 0.0, -4.5, 16.0878491716677, 18.0, 21.2057394738396, 21.5, 0.0, 0.0], 
processed observation next is [0.0, 0.9130434782608695, 0.34615384615384615, 0.96, 0.5393939393939393, 0.7777777777777778, 0.0, 0.0, 0.425, 0.16087849171667698, 0.0, 0.4579627819770857, 0.5, 0.0, 0.0], 
reward next is -0.0420. 
=============================================
[2017-11-02 10:57:08,783] A3C_AGENT_WORKER-Thread-8 INFO:Local step 30500, global step 487780: loss -0.0288
[2017-11-02 10:57:10,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99321222e-01   3.60753824e-04   2.79989090e-05   5.96274731e-05
   2.30368212e-04   1.22848487e-12   4.61622060e-13   2.21076765e-13
   2.81545516e-11], sum to 1.0000
[2017-11-02 10:57:10,354] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 4.975, 272.5, 97.25, 0.0, -3.9, 12.63074382314563, 18.0, 22.33422142489987, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1345800.0000, 
raw observation next is [1.1, 92.0, 5.016666666666667, 271.6666666666666, 94.33333333333333, 0.0, -3.9, 12.95345489020957, 18.0, 22.2806039005661, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5652173913043478, 0.36153846153846153, 0.92, 0.45606060606060606, 0.7546296296296293, 0.2495590828924162, 0.0, 0.435, 0.1295345489020957, 0.0, 0.6115148429380142, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0130. 
=============================================
[2017-11-02 10:57:15,605] A3C_AGENT_WORKER-Thread-2 INFO:Local step 30500, global step 488943: loss 2.1207
[2017-11-02 10:57:16,138] A3C_AGENT_WORKER-Thread-9 INFO:Local step 30500, global step 489042: loss 0.5291
[2017-11-02 10:57:16,247] A3C_AGENT_WORKER-Thread-12 INFO:Local step 30500, global step 489058: loss 22.6040
[2017-11-02 10:57:17,938] A3C_AGENT_WORKER-Thread-14 INFO:Local step 30500, global step 489350: loss 9.9361
[2017-11-02 10:57:18,156] A3C_AGENT_WORKER-Thread-11 INFO:Local step 30500, global step 489382: loss 0.4571
[2017-11-02 10:57:19,328] A3C_AGENT_WORKER-Thread-13 INFO:Local step 30500, global step 489602: loss -23.0091
[2017-11-02 10:57:22,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99984264e-01   7.66235917e-06   3.07854833e-07   7.32556998e-07
   6.98198255e-06   5.77355791e-21   5.79191138e-21   3.33618057e-21
   3.65375636e-17], sum to 1.0000
[2017-11-02 10:57:22,286] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 3.183333333333333, 318.3333333333334, 0.0, 0.0, 5.0, 16.00648159028368, 23.0, 21.06618806023646, 21.5, 0.0, 84.37645170497112], 
actual action is [-5.0, 18.0], 
sim time next is 1383300.0000, 
raw observation next is [0.0, 95.0, 3.275, 317.5, 0.0, 0.0, -5.0, 16.85907643833718, 18.0, 21.26128913227848, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.0, 0.3333333333333333, 0.95, 0.29772727272727273, 0.8819444444444444, 0.0, 0.0, 0.4166666666666667, 0.1685907643833718, 0.0, 0.46589844746835446, 0.5, 0.0, 0.0], 
reward next is -0.0341. 
=============================================
[2017-11-02 10:57:24,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.97710347e-01   7.65866309e-04   1.85304656e-04   2.43950315e-04
   1.09454466e-03   1.18265762e-13   8.27848329e-14   8.21857231e-14
   5.41568623e-10], sum to 1.0000
[2017-11-02 10:57:24,053] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 2.5, 50.0, 0.0, 0.0, -3.858333333333333, 19.96814855593551, 18.0, 21.43143470627172, 21.5, 0.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1461900.0000, 
raw observation next is [1.141666666666667, 92.0, 2.291666666666667, 45.83333333333333, 0.0, 0.0, -3.9, 21.14357657663186, 18.0, 21.3043953855979, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.36260683760683765, 0.92, 0.20833333333333337, 0.1273148148148148, 0.0, 0.0, 0.435, 0.21143576576631862, 0.0, 0.47205648365684283, 0.5, 0.0, 0.0], 
reward next is -0.0279. 
=============================================
[2017-11-02 10:57:24,781] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99995232e-01   2.40360146e-06   1.06646496e-07   3.71313888e-07
   1.95566531e-06   1.29135731e-16   1.46732417e-16   7.07778216e-17
   2.95412329e-14], sum to 1.0000
[2017-11-02 10:57:24,791] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.7000000000000001, 92.0, 3.0, 240.0, 91.0, 0.0, -4.35, 14.59487085491982, 18.0, 22.02466922249814, 22.7, 1.0, 0.0], 
actual action is [-4.3, 18], 
sim time next is 1430700.0000, 
raw observation next is [0.75, 92.0, 3.0, 215.0, 90.5, 0.0, -4.3, 14.84643356664425, 18.0, 21.97243018604327, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.3525641025641026, 0.92, 0.2727272727272727, 0.5972222222222222, 0.23941798941798942, 0.0, 0.42833333333333334, 0.14846433566644252, 0.0, 0.5674900265776098, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0148. 
=============================================
[2017-11-02 10:57:27,052] A3C_AGENT_WORKER-Thread-15 INFO:Local step 30500, global step 490962: loss 1.1290
[2017-11-02 10:57:27,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.85014975e-01   3.85892997e-03   4.65917954e-04   1.01353624e-03
   3.23825935e-03   2.05335746e-05   2.33102310e-05   1.17143254e-05
   6.35279343e-03], sum to 1.0000
[2017-11-02 10:57:27,445] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.5999999999999999, 100.0, 2.291666666666667, 218.3333333333333, 16.5, 0.0, -5.6, 14.8958443581833, 18.0, 21.7009522986098, 22.7, 1.0, 0.0], 
actual action is [-5.6, 18], 
sim time next is 1413000.0000, 
raw observation next is [-0.6, 100.0, 2.25, 190.0, 18.0, 0.0, -5.6, 15.92791550843665, 18.0, 21.69749030818885, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.317948717948718, 1.0, 0.20454545454545456, 0.5277777777777778, 0.047619047619047616, 0.0, 0.4066666666666666, 0.1592791550843665, 0.0, 0.5282129011698358, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:31,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99961376e-01   2.27275395e-05   1.62565800e-06   2.59565445e-06
   1.17170002e-05   1.26566794e-13   1.11072765e-13   3.63861502e-14
   3.91772075e-12], sum to 1.0000
[2017-11-02 10:57:31,985] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.0, 95.0, 1.541666666666667, 10.83333333333333, 82.5, 0.0, 5.0, 10.14219552772796, 25.0, 22.60354382294326, 22.7, 1.0, 69.46772599138359], 
actual action is [5.0, 20.0], 
sim time next is 1422600.0000, 
raw observation next is [0.0, 95.0, 1.583333333333333, 11.66666666666667, 84.0, 0.0, 5.0, 9.188074660783691, 20.0, 22.7912788441696, 22.7, 1.0, 49.0083060986646], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.3333333333333333, 0.95, 0.14393939393939392, 0.03240740740740741, 0.2222222222222222, 0.0, 0.5833333333333334, 0.0918807466078369, 0.2857142857142857, 0.6844684063099429, 0.6714285714285714, 1.0, 0.5765683070431129], 
reward next is -0.5281. 
=============================================
[2017-11-02 10:57:33,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.36343290e-35   6.27868594e-24   2.26872896e-25   1.56747907e-25
   3.59938929e-24   3.22682783e-02   6.24843175e-03   5.95120620e-03
   9.55532014e-01], sum to 1.0000
[2017-11-02 10:57:33,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.65, 92.0, 3.0, 265.0, 91.5, 0.0, -4.4, 13.8596288119105, 18.0, 22.2426216439714, 22.7, 1.0, 0.0], 
actual action is [5.65, 23.0], 
sim time next is 1430400.0000, 
raw observation next is [0.7000000000000001, 92.0, 3.0, 240.0, 91.0, 0.0, 5.65, 11.12635609115217, 23.0, 22.16944493751163, 22.7, 1.0, 92.73289020117288], 
processed observation next is [0.16666666666666666, 0.5652173913043478, 0.35128205128205126, 0.92, 0.2727272727272727, 0.6666666666666666, 0.24074074074074073, 0.0, 0.5941666666666666, 0.1112635609115217, 0.7142857142857143, 0.5956349910730901, 0.6714285714285714, 1.0, 1.090975178837328], 
reward next is -0.9930. 
=============================================
[2017-11-02 10:57:34,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99994159e-01   3.93514620e-06   1.63242817e-07   2.48983952e-07
   1.56811393e-06   1.32335200e-16   1.38259282e-16   1.00626164e-16
   8.74249471e-15], sum to 1.0000
[2017-11-02 10:57:34,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 3.0, 45.0, 78.0, 0.0, -3.9, 14.01920053229263, 18.0, 22.31826473366699, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1433700.0000, 
raw observation next is [1.1, 92.0, 3.0, 47.5, 76.5, 0.0, -3.9, 14.17948088111989, 18.0, 22.33319586580512, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6086956521739131, 0.36153846153846153, 0.92, 0.2727272727272727, 0.13194444444444445, 0.20238095238095238, 0.0, 0.435, 0.1417948088111989, 0.0, 0.6190279808293029, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0142. 
=============================================
[2017-11-02 10:57:37,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99965787e-01   2.09466307e-05   2.41942644e-06   2.87884518e-06
   7.94753305e-06   2.18635399e-13   2.13401318e-13   1.22669548e-13
   3.61051141e-12], sum to 1.0000
[2017-11-02 10:57:37,064] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 92.0, 3.6, 90.0, 9.0, 0.0, 6.1, 11.89823822285314, 25.0, 22.27697563022705, 22.7, 1.0, 23.98149246006061], 
actual action is [6.1, 20.0], 
sim time next is 1443900.0000, 
raw observation next is [1.1, 91.66666666666666, 3.425, 102.5, 7.499999999999999, 0.0, 6.1, 11.33223229135289, 20.0, 22.32764913919205, 22.7, 1.0, 47.94318730914927], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.36153846153846153, 0.9166666666666665, 0.31136363636363634, 0.2847222222222222, 0.01984126984126984, 0.0, 0.6016666666666667, 0.1133223229135289, 0.2857142857142857, 0.6182355913131501, 0.6714285714285714, 1.0, 0.5640374977546974], 
reward next is -0.5190. 
=============================================
[2017-11-02 10:57:40,441] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31000, global step 493420: loss 0.6016
[2017-11-02 10:57:41,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99999046e-01   4.20999385e-07   1.41962744e-07   1.22697401e-07
   2.67897633e-07   7.40084633e-21   2.35809305e-20   2.33069156e-20
   2.87133354e-18], sum to 1.0000
[2017-11-02 10:57:41,112] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [2.108333333333333, 96.33333333333333, 3.466666666666666, 144.1666666666667, 0.0, 0.0, 7.2, 18.00769241265751, 23.0, 20.49596616201097, 21.5, 0.0, 102.1057063759147], 
actual action is [-2.891666666666667, 18.0], 
sim time next is 1491000.0000, 
raw observation next is [2.016666666666667, 96.66666666666666, 3.333333333333333, 148.3333333333333, 0.0, 0.0, -2.891666666666667, 19.07718061040917, 18.0, 20.69539470666098, 21.5, 0.0, 0.0], 
processed observation next is [0.3333333333333333, 0.2608695652173913, 0.38504273504273506, 0.9666666666666666, 0.303030303030303, 0.4120370370370369, 0.0, 0.0, 0.45180555555555557, 0.1907718061040917, 0.0, 0.3850563866658544, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:41,248] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31000, global step 493598: loss 1.3241
[2017-11-02 10:57:46,070] A3C_AGENT_WORKER-Thread-7 INFO:Local step 31000, global step 494588: loss 1.5198
[2017-11-02 10:57:46,111] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  9.99992371e-01   4.55982899e-06   6.65054870e-07   7.17035903e-07
   1.67148858e-06   2.80733248e-14   4.85744969e-14   4.58031237e-14
   2.76034349e-13], sum to 1.0000
[2017-11-02 10:57:46,137] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 91.0, 3.075, 127.5, 0.0, 0.0, -3.9, 15.16872766271613, 18.0, 21.97864046895217, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1444800.0000, 
raw observation next is [1.1, 90.66666666666667, 2.9, 140.0, 0.0, 0.0, -3.9, 15.99971635024307, 18.0, 21.92784322389408, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.7391304347826086, 0.36153846153846153, 0.9066666666666667, 0.2636363636363636, 0.3888888888888889, 0.0, 0.0, 0.435, 0.1599971635024307, 0.0, 0.561120460556297, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 10:57:46,638] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31000, global step 494711: loss 1.0453
[2017-11-02 10:57:48,249] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.95971382e-01   2.24756286e-03   4.75447741e-04   4.89530619e-04
   8.15542531e-04   8.67781154e-08   1.42606496e-07   1.46646940e-07
   1.69667544e-07], sum to 1.0000
[2017-11-02 10:57:48,273] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [9.533333333333333, 64.66666666666666, 0.0, 0.0, 81.66666666666666, 688.3333333333333, 4.300000000000001, 9.682999594590422, 18.0, 23.02929150833421, 22.7, 1.0, 0.0], 
actual action is [4.533333333333333, 18], 
sim time next is 1518900.0000, 
raw observation next is [9.766666666666666, 63.83333333333334, 0.0, 0.0, 80.83333333333333, 685.1666666666667, 4.533333333333333, 9.560534107974032, 18.0, 23.06775522197395, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.5652173913043478, 0.5837606837606837, 0.6383333333333334, 0.0, 0.0, 0.21384479717813049, 0.6851666666666667, 0.5755555555555555, 0.09560534107974032, 0.0, 0.7239650317105644, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0096. 
=============================================
[2017-11-02 10:57:49,245] A3C_AGENT_WORKER-Thread-8 INFO:Local step 31000, global step 495359: loss 0.0466
[2017-11-02 10:57:49,277] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31000, global step 495364: loss 0.1926
[2017-11-02 10:57:49,572] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31000, global step 495430: loss 0.2476
[2017-11-02 10:57:50,747] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31000, global step 495741: loss 0.0447
[2017-11-02 10:57:51,499] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31000, global step 495884: loss 0.1727
[2017-11-02 10:57:53,263] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.92467821e-01   3.13968235e-03   1.86805078e-03   4.25870443e-04
   2.09844788e-03   6.18688503e-11   1.86986218e-10   4.46099380e-10
   1.65224748e-07], sum to 1.0000
[2017-11-02 10:57:53,287] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.85, 80.75, 3.45, 97.5, 0.0, 0.0, 9.9, 13.92691535992169, 23.0, 21.12063643262534, 21.5, 0.0, 101.9824930744197], 
actual action is [-0.15000000000000036, 18.0], 
sim time next is 1563600.0000, 
raw observation next is [4.800000000000001, 81.33333333333334, 3.4, 96.66666666666667, 0.0, 0.0, -0.1500000000000004, 14.78348298306067, 18.0, 21.33770856716995, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.08695652173913043, 0.45641025641025645, 0.8133333333333335, 0.3090909090909091, 0.26851851851851855, 0.0, 0.0, 0.49749999999999994, 0.1478348298306067, 0.0, 0.4768155095957073, 0.5, 0.0, 0.0], 
reward next is -0.0232. 
=============================================
[2017-11-02 10:57:56,413] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31000, global step 496986: loss 0.2888
[2017-11-02 10:57:57,219] A3C_AGENT_WORKER-Thread-9 INFO:Local step 31000, global step 497195: loss 0.2531
[2017-11-02 10:57:57,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-2.78498697]
 [-1.16457641]
 [-0.66412628]
 [-1.25901735]
 [-2.71473885]], R is [[-6.22731876]
 [-6.17446041]
 [-6.12188959]
 [-6.06961918]
 [-6.01741219]].
[2017-11-02 10:57:58,522] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31000, global step 497532: loss 0.0663
[2017-11-02 10:57:58,879] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31000, global step 497634: loss 0.0808
[2017-11-02 10:57:58,966] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31000, global step 497647: loss 0.0039
[2017-11-02 10:58:00,436] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31000, global step 498030: loss 0.0158
[2017-11-02 10:58:02,246] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99997139e-01   1.79741801e-06   4.43592370e-07   2.34421123e-07
   3.81433154e-07   2.35462111e-18   7.71014553e-18   4.57369006e-18
   5.68161709e-17], sum to 1.0000
[2017-11-02 10:58:02,263] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [5.125, 81.25, 2.625, 92.5, 0.0, 0.0, 10.08333333333333, 12.81915638846572, 23.0, 21.45924218073952, 21.5, 0.0, 63.90784339443122], 
actual action is [0.125, 18.0], 
sim time next is 1578000.0000, 
raw observation next is [5.166666666666667, 81.0, 2.666666666666667, 93.33333333333334, 0.0, 0.0, 0.125, 13.67523944935795, 18.0, 21.48991822913825, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.2608695652173913, 0.4658119658119658, 0.81, 0.24242424242424246, 0.2592592592592593, 0.0, 0.0, 0.5020833333333333, 0.13675239449357948, 0.0, 0.49855974701975014, 0.5, 0.0, 0.0], 
reward next is -0.0014. 
=============================================
[2017-11-02 10:58:04,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31000, global step 499135: loss 0.1261
[2017-11-02 10:58:07,556] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Starting

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus, Version 8.3.0-6d97d074ea, YMD=2017.11.02 10:25

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Processing Data Dictionary

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Processing Input File

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Initializing Simulation

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Reporting Surfaces

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Beginning Primary Simulation

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Initializing New Environment Parameters

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {1}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Instantiating Building Controls Virtual Test Bed

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:ExternalInterface initializes.

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Number of outputs in ExternalInterface = 13

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Number of inputs  in ExternalInterface = 2

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {2}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {3}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {4}

[2017-11-02 10:58:07,558] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {5}

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Warming up {6}

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Starting Simulation at 01/01 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:ExternalInterface starts first data exchange.

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=01/21

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 01/21 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=02/10

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 02/10 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/02

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/02 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Updating Shadowing Calculations, Start Date=03/22

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:Continuing Simulation at 03/22 for WHOLEYEAR

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:**FATAL:Error in ExternalInterface: Check EnergyPlus *.err file.

[2017-11-02 10:58:07,559] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 INFO:EnergyPlus Run Time=00hr 32min 41.87sec

[2017-11-02 10:58:07,576] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:58:07,576] EPLUS_ENV_IW-v570202_MainThread-EPLUSPROCESS_EPI_1 ERROR:Error: The server closed the socket while the client was reading.

[2017-11-02 10:58:08,558] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2017-11-02 10:58:08,561] EPLUS_ENV_IW-v570202_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/iw_ctrl_runs/29/Eplus-env-IW-v570202-res1/Eplus-env-sub_run3
[2017-11-02 10:58:49,498] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99563277e-01   2.41290763e-04   8.18648768e-05   3.88239496e-05
   7.47278682e-05   2.53773183e-11   5.06818199e-11   3.80540391e-11
   7.24343474e-10]
[2017-11-02 10:58:54,083] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.39233384e-06   8.23826198e-08   9.25009829e-08
   1.46921181e-07   1.09587920e-11   1.52138458e-11   8.00515470e-12
   1.08486501e-11]
[2017-11-02 10:58:54,390] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99989033e-01   8.95824905e-06   4.82953283e-07   5.37820483e-07
   9.61141609e-07   1.74137043e-08   2.29808741e-08   1.27572575e-08
   1.98767598e-08]
[2017-11-02 10:59:13,187] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.08914350e-10   1.06983566e-09   6.30251754e-11   4.61299055e-11
   1.56613666e-10   1.82280511e-01   2.58425325e-01   1.64797366e-01
   3.94496769e-01]
[2017-11-02 10:59:13,424] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964356e-01   2.82832389e-05   1.66091627e-06   1.44421858e-06
   3.41016357e-06   1.07414039e-07   1.94359288e-07   1.06263109e-07
   3.07257380e-07]
[2017-11-02 10:59:17,474] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.65930748e-07   5.14594376e-07   4.63241783e-08   2.87229884e-08
   9.37460527e-08   1.22890197e-01   1.99306160e-01   1.27046779e-01
   5.50755620e-01]
[2017-11-02 10:59:18,304] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.19495961e-06   2.36344840e-06   2.09294797e-07   1.32133579e-07
   4.24493663e-07   1.20527096e-01   2.00714663e-01   1.25251874e-01
   5.53497970e-01]
[2017-11-02 10:59:23,379] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.10750428e-12   4.27924673e-09   1.11022680e-09   4.72126838e-10
   1.80824600e-09   5.38974069e-02   8.24877694e-02   6.97590709e-02
   7.93855667e-01]
[2017-11-02 10:59:28,149] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.94685920e-09   5.81989346e-09   2.95344138e-10   2.60179350e-10
   7.87108323e-10   2.27438763e-01   2.94022381e-01   1.71391860e-01
   3.07147026e-01]
[2017-11-02 10:59:52,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994040e-01   5.05174830e-06   1.52001206e-07   1.75460286e-07
   4.60811407e-07   2.00089278e-08   3.63056465e-08   2.11646203e-08
   2.95505309e-08]
[2017-11-02 11:00:17,957] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  0.00000000e+00   2.14142014e-37   0.00000000e+00   0.00000000e+00
   4.20488415e-38   2.14338824e-01   2.28776053e-01   2.44528770e-01
   3.12356442e-01]
[2017-11-02 11:00:19,867] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.45809531e-05   1.22425217e-06   3.11321493e-08   2.89917974e-08
   1.10238403e-07   1.81100994e-01   3.37536782e-01   2.17584565e-01
   2.63741761e-01]
[2017-11-02 11:00:22,944] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.82845455e-04   4.40168424e-06   1.04488905e-07   1.02115159e-07
   3.80760923e-07   1.82008564e-01   3.36701423e-01   2.25554496e-01
   2.55547732e-01]
[2017-11-02 11:00:25,810] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.54513144e-09   3.18345683e-09   7.51791129e-11   6.88410093e-11
   2.91339036e-10   1.86331615e-01   3.22808087e-01   2.31872201e-01
   2.58988082e-01]
[2017-11-02 11:00:38,607] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.          0.          0.          0.          0.          0.06354453
  0.04386582  0.0791259   0.81346381]
[2017-11-02 11:00:49,675] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99405384e-01   1.89928556e-04   8.12177223e-06   8.89148396e-06
   2.05625802e-05   8.15029853e-05   1.15521376e-04   6.55975018e-05
   1.04415834e-04]
[2017-11-02 11:00:55,623] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.69931839e-03   1.10242225e-03   1.47620522e-04   7.99762711e-05
   2.46344251e-04   6.89894706e-02   1.19943887e-01   8.91510472e-02
   7.11639941e-01]
[2017-11-02 11:00:55,855] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996543e-01   2.37342783e-06   3.99506547e-07   2.40581414e-07
   4.67583902e-07   2.18470147e-15   4.64765157e-15   3.04726032e-15
   2.90717395e-14]
[2017-11-02 11:00:57,575] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99951363e-01   2.82535402e-05   8.30471163e-06   4.20464312e-06
   7.83495761e-06   4.69360641e-14   9.64830497e-14   7.02747051e-14
   1.14870179e-12]
[2017-11-02 11:01:12,399] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.96722389e-08   3.05973481e-06   8.85988129e-07   3.76297606e-07
   1.22035124e-06   5.14376387e-02   7.82370046e-02   6.91789016e-02
   8.01140845e-01]
[2017-11-02 11:01:16,590] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.58373845e-01   1.00388681e-03   5.36393381e-05   5.58442152e-05
   1.20609126e-04   9.81047656e-03   1.24353338e-02   6.88212924e-03
   1.12642543e-02]
[2017-11-02 11:01:41,884] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.84708362e-10   7.79273979e-09   7.67639952e-10   4.52803517e-10
   1.51498514e-09   1.22276574e-01   1.87105000e-01   1.27077684e-01
   5.63540697e-01]
[2017-11-02 11:02:04,006] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.52666539e-01   2.27342104e-03   2.02889045e-04   1.47948362e-04
   4.03345330e-04   1.15168430e-01   1.84933811e-01   1.05658695e-01
   4.38544959e-01]
[2017-11-02 11:02:06,328] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99372423e-01   4.02962178e-04   7.65180594e-05   4.36772498e-05
   1.04288192e-04   9.74164482e-09   1.91035081e-08   1.28886590e-08
   1.89559358e-07]
[2017-11-02 11:02:13,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.32418906e-03   6.95830167e-05   4.08160986e-06   4.13136149e-06
   9.37631739e-06   2.56243974e-01   3.01422834e-01   1.66050524e-01
   2.73871303e-01]
[2017-11-02 11:02:17,184] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993682e-01   5.00005854e-06   3.83158493e-07   3.64754271e-07
   6.47235481e-07   4.24083157e-10   6.34548858e-10   3.30578814e-10
   8.97236285e-10]
[2017-11-02 11:02:17,234] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.31389242e-01   2.57234625e-03   2.06555793e-04   1.66677783e-04
   3.92596528e-04   1.00479022e-01   1.40376776e-01   8.17786679e-02
   2.42638171e-01]
[2017-11-02 11:02:21,195] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   2.77033109e-06   6.87971408e-07   3.74306182e-07
   6.15753265e-07   1.38517564e-17   3.09838399e-17   2.11756202e-17
   3.43471940e-16]
[2017-11-02 11:02:21,954] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99903560e-01   5.65284427e-05   1.54719492e-05   8.60591899e-06
   1.58287094e-05   1.57514919e-12   3.09285193e-12   2.09311149e-12
   4.31092349e-11]
[2017-11-02 11:02:23,203] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995828e-01   3.36262929e-06   1.95328710e-07   2.25309620e-07
   3.67044152e-07   7.21415774e-11   9.68256031e-11   6.13791656e-11
   7.20425733e-11]
[2017-11-02 11:02:23,705] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.20400864e-06   1.33190738e-07   9.80439907e-08
   1.93921537e-07   9.11357137e-15   1.83046005e-14   1.14156418e-14
   4.95056368e-14]
[2017-11-02 11:02:24,870] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.42221573e-07   6.89278963e-08   5.42674812e-08
   1.07074101e-07   1.10088154e-13   2.02106506e-13   1.27883896e-13
   5.66925521e-13]
[2017-11-02 11:02:25,233] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.88428792e-07   7.13920585e-08   5.73896450e-08
   1.12281199e-07   3.73823992e-13   6.54421775e-13   4.04076783e-13
   1.68809075e-12]
[2017-11-02 11:02:25,924] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96836185e-01   2.07212847e-03   2.92057433e-04   3.00428481e-04
   4.98872658e-04   7.49958531e-08   9.52357055e-08   6.91801461e-08
   3.77592251e-08]
[2017-11-02 11:02:27,463] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964118e-01   2.21936662e-05   4.58327759e-06   3.30806870e-06
   5.82643088e-06   3.31872320e-14   6.93668349e-14   3.96200373e-14
   1.36162267e-13]
[2017-11-02 11:02:28,169] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   8.31578575e-07   7.79697871e-08   6.20511074e-08
   1.23042369e-07   3.99478844e-13   7.08117159e-13   4.34982101e-13
   1.93623264e-12]
[2017-11-02 11:02:29,647] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99823511e-01   1.14136164e-04   1.87663209e-05   1.78278842e-05
   2.58532764e-05   4.08779304e-12   5.68869084e-12   3.30010737e-12
   3.54482264e-12]
[2017-11-02 11:02:29,726] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99865055e-01   8.08096811e-05   1.81713876e-05   1.38608148e-05
   2.22175568e-05   6.34262675e-14   1.24986718e-13   7.13980741e-14
   1.57817295e-13]
[2017-11-02 11:02:29,979] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99896646e-01   6.12698714e-05   1.45395525e-05   1.04575956e-05
   1.71020038e-05   2.70542340e-14   5.70061441e-14   3.23091028e-14
   8.43486657e-14]
[2017-11-02 11:02:30,814] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99958515e-01   2.65026792e-05   4.80709241e-06   3.90486048e-06
   6.31263629e-06   3.55041348e-14   6.97996416e-14   4.03002725e-14
   1.09165376e-13]
[2017-11-02 11:02:31,295] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99954700e-01   2.99192943e-05   4.68948929e-06   4.27471741e-06
   6.47820707e-06   1.78426704e-13   3.03166888e-13   1.63711059e-13
   2.94467819e-13]
[2017-11-02 11:02:31,452] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99858618e-01   9.59178724e-05   1.24921598e-05   1.39858603e-05
   1.89430521e-05   4.76681229e-11   6.16664289e-11   3.37337484e-11
   2.64771139e-11]
[2017-11-02 11:02:31,501] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99784291e-01   1.45301077e-04   1.93683609e-05   2.15605305e-05
   2.94275105e-05   1.02786259e-10   1.30080807e-10   7.31493199e-11
   5.29809252e-11]
[2017-11-02 11:02:31,648] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99592841e-01   2.69795855e-04   3.79691446e-05   4.15992617e-05
   5.77821811e-05   3.03285480e-10   3.71309733e-10   2.15183066e-10
   1.40638973e-10]
[2017-11-02 11:02:33,457] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999404e-01   4.52314879e-07   4.71282888e-08   3.25006759e-08
   6.67786964e-08   2.03823012e-14   4.15875864e-14   2.70013368e-14
   1.66492078e-13]
[2017-11-02 11:02:35,508] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.55055177e-01   2.40953900e-02   7.95406476e-03   3.76733812e-03
   7.97618553e-03   3.94382769e-05   7.06396822e-05   5.49035394e-05
   9.86916479e-04]
[2017-11-02 11:02:38,332] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   1.03695484e-05   9.42980648e-07   9.88204988e-07
   1.36014717e-06   1.19803993e-11   1.86806057e-11   1.00714350e-11
   1.38606574e-11]
[2017-11-02 11:02:38,750] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99884963e-01   8.40637949e-05   7.84424628e-06   7.82822372e-06
   1.23988666e-05   6.75434819e-07   8.64421679e-07   5.12262318e-07
   8.79965739e-07]
[2017-11-02 11:02:41,571] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993443e-01   4.30322143e-06   8.52542200e-07   5.18182958e-07
   9.06225637e-07   2.08948408e-14   4.28067514e-14   2.81883908e-14
   2.70398450e-13]
[2017-11-02 11:02:43,662] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99947309e-01   3.03920860e-05   8.75757996e-06   4.82622136e-06
   8.78380979e-06   7.09792129e-14   1.40557216e-13   9.88279689e-14
   1.51140905e-12]
[2017-11-02 11:02:43,715] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.12150621e-04   8.82294495e-04   2.80205364e-04   1.26148225e-04
   3.47414694e-04   3.82583924e-02   6.17668480e-02   5.10084406e-02
   8.47218096e-01]
[2017-11-02 11:02:46,770] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   9.99087843e-06   1.04397543e-06   1.09147572e-06
   1.48378842e-06   3.43084838e-10   4.74744299e-10   2.15037974e-10
   3.45585810e-10]
[2017-11-02 11:02:51,087] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994278e-01   3.74395859e-06   6.67149891e-07   4.29785786e-07
   8.29344515e-07   1.00840370e-13   1.95433635e-13   1.20450945e-13
   1.14061169e-12]
[2017-11-02 11:02:53,751] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99991059e-01   5.26147460e-06   1.45044089e-06   8.04635533e-07
   1.38056123e-06   2.00191711e-16   4.19060127e-16   2.87155445e-16
   4.94903352e-15]
[2017-11-02 11:02:58,009] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99956250e-01   2.62342528e-05   5.51126232e-06   4.15479008e-06
   7.91043567e-06   2.32601828e-12   4.74812811e-12   2.64216665e-12
   1.10680649e-11]
[2017-11-02 11:02:58,763] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.21695434  0.13112445  0.04369258  0.0198531   0.05064408  0.01636913
  0.03005787  0.02371034  0.46759415]
[2017-11-02 11:03:01,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984860e-01   1.10737365e-05   1.14738612e-06   1.23055247e-06
   1.65301140e-06   4.80994029e-11   6.70377087e-11   3.05095289e-11
   3.92432163e-11]
[2017-11-02 11:03:01,794] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94098425e-01   3.64579749e-03   6.26326015e-04   6.30439376e-04
   9.98334261e-04   2.16416652e-07   2.69711165e-07   1.86491661e-07
   1.04554893e-07]
[2017-11-02 11:03:02,842] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99892712e-01   6.12471922e-05   1.51940749e-05   1.10935171e-05
   1.98249782e-05   4.26107148e-13   9.26778077e-13   5.07027200e-13
   1.73034016e-12]
[2017-11-02 11:03:04,042] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   3.02899275e-06   8.51815287e-07   4.50233330e-07
   7.57527744e-07   3.41810253e-17   7.77674316e-17   5.31607903e-17
   1.07410332e-15]
[2017-11-02 11:03:04,471] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   2.99342992e-06   8.25204609e-07   4.41835027e-07
   6.78132267e-07   7.19606767e-18   1.62032324e-17   1.10516682e-17
   1.91679043e-16]
[2017-11-02 11:03:19,754] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.80968189e-01   1.53989403e-03   7.40296164e-05   7.71620762e-05
   1.77983893e-04   5.25135621e-02   6.68876916e-02   3.95402461e-02
   5.82213104e-02]
[2017-11-02 11:03:20,829] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997854e-01   1.63237894e-06   1.02576855e-07   1.12270804e-07
   1.83159017e-07   1.11086253e-11   1.60019741e-11   8.09926518e-12
   1.23254315e-11]
[2017-11-02 11:03:24,515] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99813139e-01   1.33022608e-04   1.12929638e-05   8.08772984e-06
   2.03723012e-05   1.55245175e-06   2.73596925e-06   1.66848815e-06
   8.07515244e-06]
[2017-11-02 11:03:49,171] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.60584881e-27   9.17079015e-19   2.27562608e-19   7.78246223e-20
   4.36994968e-19   5.76740466e-02   7.83346593e-02   7.59477243e-02
   7.88043559e-01]
[2017-11-02 11:04:10,918] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.78073747e-10   3.13737947e-09   1.91591756e-10   1.71710299e-10
   4.65206901e-10   2.56050885e-01   2.93599606e-01   1.79501235e-01
   2.70848334e-01]
[2017-11-02 11:04:11,582] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99938488e-01   4.66043639e-05   3.90347168e-06   3.85528756e-06
   6.35396736e-06   1.72083276e-07   2.38658885e-07   1.18364866e-07
   2.57351871e-07]
[2017-11-02 11:04:14,206] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.88176095e-01   2.23554811e-03   2.13572232e-04   1.48235427e-04
   3.98421398e-04   1.02945358e-01   1.63779870e-01   9.79886279e-02
   4.44114268e-01]
[2017-11-02 11:04:25,130] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.28628372e-03   5.08722951e-05   3.37387382e-06   3.41760506e-06
   7.38047083e-06   2.58790135e-01   3.00807089e-01   1.57905832e-01
   2.81145602e-01]
[2017-11-02 11:04:29,312] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99341428e-01   4.12568334e-04   8.59737847e-05   4.80579656e-05
   1.11796100e-04   3.57872199e-09   6.88176627e-09   4.89048801e-09
   6.12598186e-08]
[2017-11-02 11:04:31,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93428648e-01   3.74473818e-03   1.05502771e-03   5.45789895e-04
   1.22269627e-03   1.55293463e-07   2.81019965e-07   2.09295678e-07
   2.42630881e-06]
[2017-11-02 11:04:31,679] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.97797204e-04   1.59559445e-03   4.54655004e-04   2.13209612e-04
   6.15212717e-04   5.68142124e-02   9.03935209e-02   7.34154359e-02
   7.76200294e-01]
[2017-11-02 11:04:39,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.55181077e-07   6.51901473e-07   4.87464149e-08   3.74528142e-08
   1.10116908e-07   1.89265102e-01   2.50911593e-01   1.53768167e-01
   4.06053483e-01]
[2017-11-02 11:04:43,855] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.97658970e-04   2.92362267e-04   4.85894998e-05   2.54094866e-05
   7.75581793e-05   6.99753985e-02   1.14001468e-01   8.62105265e-02
   7.28871107e-01]
[2017-11-02 11:04:46,720] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.19795078e-13   4.08918188e-09   1.19661125e-09   4.90010421e-10
   1.79555903e-09   5.55392355e-02   8.03885087e-02   7.20971897e-02
   7.91975081e-01]
[2017-11-02 11:04:49,015] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.08692030e-11   3.64057655e-08   1.03054481e-08   4.36653202e-09
   1.55945017e-08   5.56858256e-02   8.30425695e-02   7.25194812e-02
   7.88752019e-01]
[2017-11-02 11:04:55,672] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.47563929e-03   9.58843666e-05   8.34510956e-06   5.60041872e-06
   1.66530535e-05   1.22046851e-01   1.94952950e-01   1.22270532e-01
   5.59127569e-01]
[2017-11-02 11:05:08,254] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997616e-01   1.88684317e-06   1.04794879e-07   1.23659547e-07
   2.30723487e-07   9.51909107e-11   1.36738065e-10   7.24373200e-11
   1.11048573e-10]
[2017-11-02 11:05:08,325] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996185e-01   3.08158246e-06   1.71046025e-07   1.98513774e-07
   3.53716331e-07   2.50289678e-10   3.55711599e-10   1.86084634e-10
   2.88213509e-10]
[2017-11-02 11:05:10,239] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.89745200e-01   5.13617462e-03   8.18884699e-04   4.60573880e-04
   1.23927335e-03   1.49125437e-04   2.73372774e-04   1.91072220e-04
   1.98646635e-03]
[2017-11-02 11:05:14,023] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.64966914e-03   4.43811296e-03   1.16075797e-03   5.61562891e-04
   1.66646834e-03   5.35532907e-02   8.84616673e-02   7.15947375e-02
   7.76913762e-01]
[2017-11-02 11:05:20,292] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.18929844e-04   1.14219138e-05   3.32610824e-07   3.36121019e-07
   1.11887334e-06   1.93657339e-01   3.26439977e-01   2.29966775e-01
   2.49603704e-01]
[2017-11-02 11:05:21,138] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.88707900e-01   9.45112377e-04   3.66929853e-05   3.96455289e-05
   1.00003992e-04   2.03578710e-03   3.38938413e-03   2.46290816e-03
   2.28261901e-03]
[2017-11-02 11:05:24,371] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.55381358  0.04666441  0.00919802  0.00452592  0.01353543  0.01266579
  0.02450127  0.01881906  0.31627652]
[2017-11-02 11:05:24,875] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.93247829e-18   4.14139832e-13   7.97669290e-14   3.24745893e-14
   1.54337711e-13   4.26033586e-02   6.47683665e-02   5.84722906e-02
   8.34155977e-01]
[2017-11-02 11:05:25,209] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97882545e-01   1.38657843e-03   2.37672124e-04   1.27734122e-04
   3.50261136e-04   5.91381934e-07   1.22090307e-06   8.80135246e-07
   1.26315754e-05]
[2017-11-02 11:05:30,201] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98007357e-01   5.50417928e-04   4.49143517e-05   4.39690812e-05
   8.08961995e-05   2.69236421e-04   3.73318937e-04   1.78929185e-04
   4.51023778e-04]
[2017-11-02 11:05:31,070] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.76258925e-02   4.27888444e-04   3.23047352e-05   2.95334248e-05
   6.56388511e-05   2.15725690e-01   2.89185375e-01   1.78788304e-01
   2.98119366e-01]
[2017-11-02 11:05:32,920] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.33699604e-12   2.94141905e-10   3.27989927e-11   1.77153413e-11
   6.27584373e-11   1.06170967e-01   1.61713630e-01   1.19575411e-01
   6.12539947e-01]
[2017-11-02 11:05:37,161] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.94832240e-03   4.55507729e-03   1.18800905e-03   5.79325133e-04
   1.65044458e-03   5.63162118e-02   9.17792097e-02   7.19526336e-02
   7.70030737e-01]
[2017-11-02 11:05:37,321] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.66984552e-18   1.02426596e-12   2.97678413e-13   1.15810180e-13
   4.88860417e-13   4.92962413e-02   6.78711534e-02   6.29028678e-02
   8.19929779e-01]
[2017-11-02 11:05:41,544] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.10148806e-18   1.05876238e-14   7.16943668e-16   5.64644974e-16
   1.96509907e-15   2.45551318e-01   2.53423303e-01   1.42209649e-01
   3.58815730e-01]
[2017-11-02 11:05:44,119] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996543e-01   2.75734465e-06   1.48326507e-07   1.69456243e-07
   3.08790106e-07   2.93558476e-11   5.05940428e-11   2.73392888e-11
   3.35162245e-11]
[2017-11-02 11:05:44,814] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.50966001e-01   1.30034506e-03   4.87777070e-05   4.80478629e-05
   1.31066801e-04   8.70772451e-03   1.44590586e-02   1.18893413e-02
   1.24496603e-02]
[2017-11-02 11:05:48,396] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99394536e-01   3.72710114e-04   8.57242121e-05   4.56808812e-05
   1.01276346e-04   1.12852849e-09   2.20181073e-09   1.59220903e-09
   2.54441197e-08]
[2017-11-02 11:05:50,272] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.80332735e-10   8.27229414e-08   2.35901148e-08   1.03019842e-08
   3.54540468e-08   5.43759242e-02   8.31135139e-02   6.91478774e-02
   7.93362558e-01]
[2017-11-02 11:05:58,966] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99985933e-01   1.18593880e-05   4.08464842e-07   4.56761427e-07
   1.14577767e-06   1.83314022e-08   3.66113220e-08   2.51334047e-08
   2.60629243e-08]
[2017-11-02 11:05:59,075] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99984860e-01   1.29102118e-05   3.78737440e-07   4.20659489e-07
   1.12214173e-06   7.57199032e-08   1.55751678e-07   1.03065020e-07
   1.09114467e-07]
[2017-11-02 11:06:03,834] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994397e-01   3.94741573e-06   5.20132232e-07   3.97960321e-07
   8.50541937e-07   4.64220893e-12   8.52765254e-12   4.55436600e-12
   2.37933614e-11]
[2017-11-02 11:06:20,381] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990106e-01   6.05905643e-06   1.50119274e-06   8.38451456e-07
   1.43884472e-06   2.32056951e-17   5.29726729e-17   3.46598437e-17
   4.05770154e-16]
[2017-11-02 11:06:21,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990106e-01   7.92133324e-06   5.15531326e-07   5.73416798e-07
   9.33478191e-07   3.26356497e-09   4.41552750e-09   2.24595853e-09
   3.48849549e-09]
[2017-11-02 11:06:24,232] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993920e-01   4.77560570e-06   3.13259818e-07   3.57557496e-07
   5.66617416e-07   9.51553947e-10   1.20478716e-09   6.51622090e-10
   9.04742892e-10]
[2017-11-02 11:06:26,738] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993205e-01   4.23030360e-06   1.02054594e-06   5.76647551e-07
   9.62936497e-07   7.96311969e-18   1.87416313e-17   1.15460310e-17
   1.27553130e-16]
[2017-11-02 11:06:28,978] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.96403053e-18   2.02732406e-12   6.23776096e-13   2.23748564e-13
   9.39576216e-13   4.25375886e-02   5.93756475e-02   5.84301427e-02
   8.39656651e-01]
[2017-11-02 11:06:37,865] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.66040908e-03   1.29058360e-04   8.75764090e-06   7.54633356e-06
   1.92021416e-05   2.13729322e-01   2.81903774e-01   1.77231088e-01
   3.24310869e-01]
[2017-11-02 11:06:43,476] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.31220689e-07   2.98530285e-05   7.70371389e-06   3.63553590e-06
   1.17331465e-05   5.65814190e-02   8.81715342e-02   7.46113062e-02
   7.80582011e-01]
[2017-11-02 11:06:43,997] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.22976017e-06   1.23245438e-04   3.07597729e-05   1.48862619e-05
   4.70105297e-05   5.61624691e-02   8.91441107e-02   7.33995959e-02
   7.81069756e-01]
[2017-11-02 11:06:44,223] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99290586e-01   4.35457652e-04   9.04422777e-05   6.15803583e-05
   1.21881785e-04   5.53190516e-09   8.94525343e-09   5.53545121e-09
   4.74990287e-08]
[2017-11-02 11:06:45,974] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.73324299e-01   8.81375745e-04   3.10158757e-05   3.23016429e-05
   8.93729666e-05   4.75610141e-03   8.48462060e-03   6.25998620e-03
   6.14096830e-03]
[2017-11-02 11:06:46,191] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86206472e-01   7.08115578e-04   2.30932910e-05   2.44748881e-05
   6.77776698e-05   2.43547698e-03   4.31700051e-03   3.19746858e-03
   3.02001275e-03]
[2017-11-02 11:06:50,512] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995947e-01   2.57987040e-06   5.90990908e-07   3.28534668e-07
   5.48448611e-07   1.22009895e-16   2.75432218e-16   1.85340166e-16
   2.85591537e-15]
[2017-11-02 11:06:51,642] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94981468e-01   3.27681960e-03   4.99672198e-04   4.77482216e-04
   7.64366123e-04   7.38590131e-08   1.01407196e-07   7.40338990e-08
   5.15847205e-08]
[2017-11-02 11:06:51,976] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93558466e-01   4.15084278e-03   6.63244165e-04   6.24535605e-04
   1.00253825e-03   1.08512545e-07   1.48235344e-07   1.08894028e-07
   7.63259749e-08]
[2017-11-02 11:06:52,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99664307e-01   1.83706186e-04   2.24259493e-05   1.49758771e-05
   3.26076624e-05   7.56858844e-06   1.31658453e-05   8.71431621e-06
   5.24307070e-05]
[2017-11-02 11:06:52,896] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997377e-01   1.85855390e-06   2.50432635e-07   1.85041046e-07
   3.40062257e-07   1.04777406e-12   2.05720965e-12   1.18081543e-12
   6.57461325e-12]
[2017-11-02 11:07:00,206] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99753296e-01   1.48665029e-04   3.58933867e-05   1.98046764e-05
   4.23405290e-05   4.50542763e-11   8.83925433e-11   6.26070515e-11
   9.37433797e-10]
[2017-11-02 11:07:00,944] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.90237742e-27   1.40496275e-18   4.36833926e-19   1.49594515e-19
   7.89147572e-19   5.86179085e-02   6.98871985e-02   7.16537833e-02
   7.99841106e-01]
[2017-11-02 11:07:01,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.90179896e-01   5.52873733e-03   1.57870108e-03   8.31409416e-04
   1.87212415e-03   4.91607523e-07   8.68875361e-07   6.40336225e-07
   7.14714997e-06]
[2017-11-02 11:07:02,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.68345866e-17   6.14513171e-12   1.58820158e-12   6.57229588e-13
   2.79777785e-12   6.23941161e-02   8.67632329e-02   7.70346969e-02
   7.73808002e-01]
[2017-11-02 11:07:05,162] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997139e-01   2.34012941e-06   1.13739823e-07   1.32513506e-07
   2.61667338e-07   4.96032160e-10   8.18517920e-10   4.24343560e-10
   6.28173513e-10]
[2017-11-02 11:07:07,955] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   3.05126127e-06   3.81304545e-07   3.02669463e-07
   6.75427088e-07   5.35652599e-11   1.07061734e-10   5.69712229e-11
   3.18935489e-10]
[2017-11-02 11:07:08,818] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99795616e-01   1.30336004e-04   2.52028676e-05   1.49271928e-05
   3.39452308e-05   2.39028047e-10   4.64352223e-10   3.11551590e-10
   3.93440391e-09]
[2017-11-02 11:07:08,830] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91684675e-01   5.08876797e-03   1.02386146e-03   5.74264152e-04
   1.45511178e-03   8.60448654e-06   1.56302413e-05   1.09103357e-05
   1.38201387e-04]
[2017-11-02 11:07:09,012] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99953032e-01   3.01318269e-05   5.80329743e-06   3.45485319e-06
   7.55646306e-06   4.30983504e-12   8.62149935e-12   5.77232533e-12
   7.43761858e-11]
[2017-11-02 11:07:16,208] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97193515e-01   1.64732465e-03   4.40969539e-04   2.21990689e-04
   4.95780259e-04   1.71166867e-08   3.27285292e-08   2.48423877e-08
   3.88790113e-07]
[2017-11-02 11:07:18,659] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99256074e-01   5.21880749e-04   5.80808883e-05   6.15960817e-05
   1.02204569e-04   3.25057670e-08   4.52035280e-08   3.31039232e-08
   1.93453253e-08]
[2017-11-02 11:07:19,375] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95496035e-01   2.49195588e-03   6.62057952e-04   5.92352124e-04
   7.57595233e-04   1.23998785e-08   1.63306986e-08   9.27390964e-09
   7.70725261e-09]
[2017-11-02 11:07:21,134] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99151587e-01   4.98287205e-04   1.33630107e-04   6.99298471e-05
   1.46562554e-04   1.19149213e-09   2.25251462e-09   1.65402103e-09
   2.24352021e-08]
[2017-11-02 11:07:24,228] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99996066e-01   3.24102211e-06   1.53934138e-07   1.86281625e-07
   3.70567051e-07   3.90315225e-10   6.28537111e-10   3.54076157e-10
   4.44857068e-10]
[2017-11-02 11:07:24,531] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99961257e-01   3.05981812e-05   9.18082378e-07   1.05339006e-06
   2.70358714e-06   6.52529593e-07   1.18547928e-06   7.61558510e-07
   8.37532241e-07]
[2017-11-02 11:07:27,099] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  2.57104705e-03   3.16718477e-04   4.22747034e-05   2.59994213e-05
   7.42102638e-05   1.06008679e-01   1.67126611e-01   1.15116991e-01
   6.08717442e-01]
[2017-11-02 11:07:27,511] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98100817e-01   1.22518942e-03   2.26768709e-04   1.28152562e-04
   3.17383965e-04   9.28991994e-08   1.78991399e-07   1.24393026e-07
   1.41062878e-06]
[2017-11-02 11:07:29,387] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99977469e-01   1.41902437e-05   2.53143048e-06   2.58407772e-06
   3.19295577e-06   1.59971676e-14   2.40986515e-14   1.00282001e-14
   2.83362879e-14]
[2017-11-02 11:07:31,739] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99975681e-01   1.51617542e-05   3.50356027e-06   1.84692283e-06
   3.76209960e-06   1.87227621e-13   3.99725636e-13   2.86824140e-13
   4.88275045e-12]
[2017-11-02 11:07:35,517] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99981761e-01   1.52002985e-05   7.21285971e-07   7.77756952e-07
   1.56031365e-06   1.15155836e-11   2.34721270e-11   1.87507700e-11
   1.76801525e-11]
[2017-11-02 11:07:36,249] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99892712e-01   7.91618586e-05   7.57389944e-06   7.89413843e-06
   1.26263503e-05   5.52573889e-11   9.09706754e-11   6.31830005e-11
   6.53131021e-11]
[2017-11-02 11:07:39,235] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.01965998  0.02830032  0.00790032  0.00385878  0.01053576  0.04927156
  0.08101226  0.06345737  0.73600364]
[2017-11-02 11:07:41,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99983907e-01   1.32175664e-05   6.70838290e-07   7.69589406e-07
   1.48532513e-06   1.27771474e-10   2.36172415e-10   1.69991854e-10
   1.39558642e-10]
[2017-11-02 11:07:42,184] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99900818e-01   7.72320054e-05   5.37730239e-06   5.79441166e-06
   1.07350797e-05   1.01949682e-09   1.72188241e-09   1.32780931e-09
   8.91068219e-10]
[2017-11-02 11:07:47,074] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99896407e-01   7.45249927e-05   4.90391903e-06   5.25872929e-06
   9.76243427e-06   2.00539102e-06   2.88022716e-06   1.38135772e-06
   2.83661166e-06]
[2017-11-02 11:07:47,467] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99948978e-01   4.13135604e-05   2.10475901e-06   2.29692864e-06
   5.02737521e-06   4.95309216e-08   8.64717364e-08   6.57942678e-08
   6.13251316e-08]
[2017-11-02 11:07:47,525] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99978662e-01   1.73807002e-05   9.09176208e-07   1.03284447e-06
   2.08417578e-06   1.07996423e-09   1.94544358e-09   1.46038637e-09
   1.28529076e-09]
[2017-11-02 11:07:47,853] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99795258e-01   1.58221112e-04   8.31203488e-06   8.94531331e-06
   2.02343854e-05   1.70693033e-06   2.93449762e-06   2.30085470e-06
   2.11112524e-06]
[2017-11-02 11:07:48,111] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.78968164e-03   1.19673365e-04   7.19045420e-06   7.38324388e-06
   1.71959182e-05   2.50157654e-01   3.09516847e-01   1.83533818e-01
   2.51850516e-01]
[2017-11-02 11:07:57,726] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.48348791e-05   1.84591518e-05   1.71754505e-06   1.14200384e-06
   3.48737012e-06   1.29644960e-01   1.95775792e-01   1.34755954e-01
   5.39713621e-01]
[2017-11-02 11:07:59,484] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97890413e-01   1.32446643e-03   2.56477593e-04   1.53542875e-04
   3.70573864e-04   2.79172269e-07   5.10944119e-07   3.36653585e-07
   3.42486601e-06]
[2017-11-02 11:08:06,106] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.74386305  0.07797547  0.01995621  0.00974906  0.02537371  0.00559824
  0.00991044  0.0077686   0.09980522]
[2017-11-02 11:08:08,363] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994278e-01   3.93190612e-06   5.10211976e-07   5.03929357e-07
   7.96162340e-07   2.14196174e-12   2.89758235e-12   1.29398217e-12
   5.52792100e-12]
[2017-11-02 11:08:09,673] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99961615e-01   3.13658966e-05   1.58195382e-06   1.73701210e-06
   3.57108547e-06   1.76012929e-08   2.92954656e-08   2.33378579e-08
   1.93897307e-08]
[2017-11-02 11:08:12,735] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992728e-01   4.57851593e-06   1.10900930e-06   5.97444682e-07
   1.10566384e-06   5.27983323e-16   1.11866201e-15   7.94340298e-16
   1.13825295e-14]
[2017-11-02 11:08:12,874] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99956489e-01   2.64214650e-05   6.69018573e-06   3.51141398e-06
   6.96476445e-06   8.68708520e-14   1.81353034e-13   1.31716483e-13
   2.09987648e-12]
[2017-11-02 11:08:14,306] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99893069e-01   7.54930079e-05   4.10474831e-06   4.49732806e-06
   8.76860304e-06   3.34856213e-06   4.49184154e-06   2.54240354e-06
   3.59029082e-06]
[2017-11-02 11:08:15,025] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99583423e-01   3.10179748e-04   2.67952109e-05   2.87045459e-05
   5.08475969e-05   1.46932440e-08   2.08514681e-08   1.72806729e-08
   1.02169233e-08]
[2017-11-02 11:08:15,043] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99585569e-01   3.08387098e-04   2.66993557e-05   2.86503491e-05
   5.06247488e-05   1.45336205e-08   2.05595878e-08   1.70663572e-08
   1.01221334e-08]
[2017-11-02 11:08:15,103] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99281824e-01   5.16522734e-04   5.17131703e-05   5.51358135e-05
   9.48527522e-05   2.43474361e-08   3.30311067e-08   2.64071236e-08
   1.53379371e-08]
[2017-11-02 11:08:15,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98154104e-01   1.23950862e-03   1.62461685e-04   1.70006562e-04
   2.73696030e-04   7.35470849e-08   9.49825889e-08   6.89973234e-08
   3.92715229e-08]
[2017-11-02 11:08:15,512] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   8.03316993e-07   8.83459563e-08   6.04197794e-08
   1.27955516e-07   5.03914258e-15   1.05890477e-14   6.56125909e-15
   3.40673094e-14]
[2017-11-02 11:08:15,894] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998331e-01   1.09632936e-06   2.67897434e-07   1.39680708e-07
   2.23154643e-07   2.60681705e-19   6.83292648e-19   4.57803937e-19
   1.03387998e-17]
[2017-11-02 11:08:19,750] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99964714e-01   2.17451616e-05   4.41887642e-06   3.32020750e-06
   5.87966315e-06   3.65352497e-13   8.20512766e-13   4.97977581e-13
   2.22681444e-12]
[2017-11-02 11:08:21,630] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986410e-01   1.03165203e-05   8.72966552e-07   9.62136937e-07
   1.39815052e-06   7.83799206e-11   1.12870102e-10   5.89183285e-11
   6.86024432e-11]
[2017-11-02 11:08:22,980] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99704897e-01   1.87989950e-04   1.86544694e-05   1.26156983e-05
   3.14892241e-05   4.51242749e-06   7.90169179e-06   5.01006843e-06
   2.69777593e-05]
[2017-11-02 11:08:24,085] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99679327e-01   1.87715705e-04   5.31824626e-05   2.61000350e-05
   5.37781671e-05   4.68398480e-11   9.42387071e-11   6.95318178e-11
   1.26912281e-09]
[2017-11-02 11:08:24,779] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.93494213e-01   3.65923764e-03   1.10742101e-03   5.44046576e-04
   1.19328545e-03   6.18283593e-08   1.14741148e-07   8.76775914e-08
   1.47699211e-06]
[2017-11-02 11:08:27,815] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99915719e-01   6.39816571e-05   5.07995173e-06   5.73206080e-06
   9.37001732e-06   5.17357768e-10   7.77903242e-10   5.68926461e-10
   4.14189072e-10]
[2017-11-02 11:08:30,625] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86517966e-01   7.61234388e-03   2.10659462e-03   1.12661568e-03
   2.61092023e-03   1.28460806e-06   2.32435082e-06   1.71559554e-06
   2.02331048e-05]
[2017-11-02 11:08:31,853] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994397e-01   3.94898188e-06   4.18729456e-07   4.24674994e-07
   7.40928272e-07   8.33570366e-12   1.26523800e-11   5.53214115e-12
   1.93580377e-11]
[2017-11-02 11:08:32,375] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990940e-01   6.76473701e-06   5.98995371e-07   6.21717220e-07
   1.01678211e-06   3.36101563e-10   4.65237349e-10   2.27890123e-10
   5.15946119e-10]
[2017-11-02 11:08:33,502] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95045662e-01   2.90812110e-03   6.03007036e-04   6.01004460e-04
   8.41688190e-04   1.34207951e-07   1.74936034e-07   1.05431084e-07
   6.76045815e-08]
[2017-11-02 11:08:41,455] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.90499234e-01   5.78753874e-02   1.60925202e-02   7.91548379e-03
   1.95045117e-02   4.25799546e-04   7.28321320e-04   5.79606101e-04
   6.37912564e-03]
[2017-11-02 11:08:44,226] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99542475e-01   3.36441793e-04   2.42504575e-05   2.72006964e-05
   5.12615079e-05   4.12188365e-06   5.82850816e-06   4.57736223e-06
   3.98891461e-06]
[2017-11-02 11:08:48,694] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.30915480e-08   1.16258957e-06   2.05378399e-07   1.26283084e-07
   3.60670384e-07   9.84404981e-02   1.33244604e-01   8.56258199e-02
   6.82687163e-01]
[2017-11-02 11:08:50,429] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  4.26763892e-02   7.44191348e-04   2.90799744e-05   2.86369959e-05
   8.20110436e-05   1.82548329e-01   2.93891668e-01   2.64425457e-01
   2.15574220e-01]
[2017-11-02 11:08:51,585] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99937773e-01   4.62487078e-05   4.79490564e-06   3.20483628e-06
   7.99938243e-06   6.64820021e-09   1.31780205e-08   8.23427193e-09
   5.94993921e-08]
[2017-11-02 11:08:54,413] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.26446561e-10   1.06958929e-07   2.39957565e-08   1.13521015e-08
   3.75587206e-08   5.80166876e-02   9.18346569e-02   6.87599853e-02
   7.81388521e-01]
[2017-11-02 11:08:54,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.10205345e-04   9.05409921e-04   2.12243613e-04   1.05918116e-04
   2.94734025e-04   4.83018383e-02   8.35345387e-02   5.90327419e-02
   8.07002366e-01]
[2017-11-02 11:08:56,836] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.84636188e-01   8.80697463e-03   2.07179575e-03   1.89893972e-03
   2.58465461e-03   3.69170550e-07   4.90173477e-07   3.13672132e-07
   2.41361022e-07]
[2017-11-02 11:08:57,091] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997139e-01   2.00436943e-06   2.79753124e-07   2.04060555e-07
   3.93433027e-07   5.71281867e-12   1.14228323e-11   6.98754032e-12
   5.04229748e-11]
[2017-11-02 11:08:57,819] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99449432e-01   3.18278675e-04   8.69913056e-05   4.92480140e-05
   9.59913305e-05   2.77791096e-10   5.20345933e-10   3.51418117e-10
   4.95758856e-09]
[2017-11-02 11:08:58,851] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94877160e-01   2.96973065e-03   7.54863315e-04   4.33891808e-04
   9.62513499e-04   1.04226466e-07   1.86002339e-07   1.27451770e-07
   1.39785823e-06]
[2017-11-02 11:08:59,780] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99547541e-01   3.26844398e-04   3.24178254e-05   3.41221748e-05
   5.90100390e-05   1.59816782e-08   2.44820804e-08   1.82867748e-08
   1.17312258e-08]
[2017-11-02 11:09:00,226] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.91987586e-01   5.05302195e-03   8.40151974e-04   7.96168461e-04
   1.31980993e-03   8.42567488e-07   1.11775455e-06   8.10981874e-07
   4.50993895e-07]
[2017-11-02 11:09:01,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997020e-01   2.13181738e-06   2.59243052e-07   2.05604522e-07
   3.90991261e-07   1.00523832e-12   1.80630662e-12   9.22177157e-13
   3.83072567e-12]
[2017-11-02 11:09:01,356] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99968052e-01   1.72097734e-05   5.95116944e-06   3.39511939e-06
   5.31541855e-06   2.59346980e-17   6.11365816e-17   3.60292942e-17
   6.56959389e-16]
[2017-11-02 11:09:01,850] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98348832e-01   8.55075836e-04   2.76393665e-04   2.64817383e-04
   2.54905666e-04   5.28159572e-10   6.24492902e-10   2.57333738e-10
   2.75981932e-10]
[2017-11-02 11:09:01,932] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96069431e-01   2.00536172e-03   6.59403740e-04   6.34287600e-04
   6.31573726e-04   4.63598804e-09   5.06513498e-09   2.27434271e-09
   1.90076288e-09]
[2017-11-02 11:09:04,110] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.16612422e-05   4.44698613e-04   1.47773651e-04   6.40492726e-05
   1.85078359e-04   3.19219120e-02   5.24251498e-02   4.43232432e-02
   8.70456457e-01]
[2017-11-02 11:09:04,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  1.09000510e-04   1.01897412e-03   3.13637342e-04   1.41604905e-04
   4.06794512e-04   3.68100666e-02   6.00795858e-02   4.97181229e-02
   8.51402223e-01]
[2017-11-02 11:09:10,642] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.26268271e-08   8.91131003e-06   2.55968644e-06   1.14019520e-06
   3.64849961e-06   4.46963012e-02   6.99682385e-02   5.96355200e-02
   8.25683534e-01]
[2017-11-02 11:09:12,140] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993324e-01   5.17785975e-06   3.21246716e-07   3.79110702e-07
   6.76807986e-07   9.70620459e-11   1.51794022e-10   8.27079863e-11
   9.23942242e-11]
[2017-11-02 11:09:12,204] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99981403e-01   1.46803432e-05   9.12514281e-07   1.06910250e-06
   1.87170087e-06   1.93190672e-10   3.13900184e-10   2.07649550e-10
   1.81228491e-10]
[2017-11-02 11:09:12,931] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.83232200e-01   9.83696431e-03   1.98524888e-03   1.89624645e-03
   3.04370117e-03   1.54997895e-06   1.97249597e-06   1.34858828e-06
   7.10059965e-07]
[2017-11-02 11:09:13,403] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995947e-01   2.95377663e-06   3.27733574e-07   2.32596577e-07
   4.97482063e-07   2.69581614e-11   4.93828034e-11   3.07402437e-11
   1.94539454e-10]
[2017-11-02 11:09:16,937] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99527216e-01   3.45146284e-04   3.31055053e-05   3.49279871e-05
   5.95960992e-05   3.75264193e-08   5.44267671e-08   4.40304291e-08
   2.75245444e-08]
[2017-11-02 11:09:17,301] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.87234771e-01   7.68758683e-03   1.43497554e-03   1.39917014e-03
   2.23943545e-03   1.14096179e-06   1.44767967e-06   1.00592013e-06
   5.22824848e-07]
[2017-11-02 11:09:19,146] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992847e-01   4.42939654e-06   1.06711002e-06   5.95769677e-07
   1.07462643e-06   2.28354550e-16   4.88140905e-16   3.38879433e-16
   5.00157666e-15]
[2017-11-02 11:09:19,913] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.59738851e-01   2.16395818e-02   5.69311716e-03   5.34786237e-03
   7.54186744e-03   1.12565103e-05   1.36010640e-05   8.99476254e-06
   4.75795014e-06]
[2017-11-02 11:09:21,316] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.87985909e-01   6.33975631e-03   2.25052889e-03   1.10037392e-03
   2.30600894e-03   5.86053091e-07   1.05777781e-06   7.86913802e-07
   1.50441010e-05]
[2017-11-02 11:09:24,717] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99983311e-01   9.41594226e-06   2.94258325e-06   1.70928456e-06
   2.66864413e-06   3.14693545e-16   6.31329072e-16   3.98989205e-16
   6.05586799e-15]
[2017-11-02 11:09:25,984] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.21517789e-01   3.89750190e-02   1.29162958e-02   1.12811029e-02
   1.51127819e-02   5.82453504e-05   6.73742979e-05   4.60379124e-05
   2.52293885e-05]
[2017-11-02 11:09:27,216] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.62785125e-01   1.62327122e-02   8.09243880e-03   5.58693847e-03
   7.30288122e-03   8.66279097e-12   1.28359302e-11   5.85416351e-12
   7.86754689e-12]
[2017-11-02 11:09:27,369] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.64976013e-01   1.54705737e-02   7.42813153e-03   5.16179064e-03
   6.96351146e-03   7.39606206e-12   1.15969977e-11   5.51157167e-12
   8.08520698e-12]
[2017-11-02 11:09:29,553] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.03008819e-01   4.15085033e-02   2.09689885e-02   1.52932098e-02
   1.92205105e-02   6.21376395e-10   8.24950386e-10   3.82737120e-10
   3.42484430e-10]
[2017-11-02 11:09:29,738] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.60059023e-01   5.27155064e-02   2.98349503e-02   2.80333292e-02
   2.93549299e-02   7.80713037e-07   8.04301123e-07   3.93457697e-07
   2.59785025e-07]
[2017-11-02 11:09:30,123] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.72371519e-01   1.51991174e-02   3.77447926e-03   3.44069023e-03
   5.17585687e-03   1.09016964e-05   1.28721194e-05   9.36785545e-06
   5.20564981e-06]
[2017-11-02 11:09:32,056] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.11477089e-01   3.87931727e-02   1.63693912e-02   1.54847531e-02
   1.78440679e-02   1.02025442e-05   1.14656041e-05   6.19665980e-06
   3.55185148e-06]
[2017-11-02 11:09:32,603] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99756873e-01   1.14140748e-04   5.20338581e-05   3.05867907e-05
   4.63809629e-05   7.46618409e-16   1.82350163e-15   9.45846964e-16
   1.07449966e-14]
[2017-11-02 11:09:36,225] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99994993e-01   3.89381648e-06   3.14102579e-07   3.36993168e-07
   5.12897486e-07   1.99694931e-11   2.87774700e-11   1.36092864e-11
   2.05964794e-11]
[2017-11-02 11:09:38,012] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.02616835e-01   1.46292255e-03   7.30104366e-05   7.57290909e-05
   1.71865453e-04   1.71329603e-01   2.14954495e-01   1.34211659e-01
   1.75103784e-01]
[2017-11-02 11:09:40,026] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.65395689e-01   1.95684284e-02   5.57335420e-03   2.66321143e-03
   6.29561720e-03   2.17432771e-05   3.93035552e-05   3.09922034e-05
   4.11682762e-04]
[2017-11-02 11:09:47,416] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99908447e-01   5.60682747e-05   1.32707264e-05   7.41699159e-06
   1.48267200e-05   4.18074733e-12   8.60193080e-12   5.75237297e-12
   7.26234212e-11]
[2017-11-02 11:09:49,409] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98119771e-01   1.30622380e-03   1.60538912e-04   1.53948858e-04
   2.59513006e-04   1.19073000e-08   1.74217796e-08   1.33707925e-08
   1.02472066e-08]
[2017-11-02 11:09:50,101] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995470e-01   3.17746026e-06   4.31876828e-07   3.29458203e-07
   6.22270477e-07   9.00126490e-13   1.81730694e-12   9.76899117e-13
   4.49993732e-12]
[2017-11-02 11:09:51,904] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.86851513e-01   7.58731365e-03   2.00896594e-03   1.07093365e-03
   2.43959995e-03   1.70646172e-06   3.10010955e-06   2.22096423e-06
   3.46210654e-05]
[2017-11-02 11:09:51,915] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.30117378  0.10792232  0.03004495  0.01493018  0.03881348  0.020472
  0.03509504  0.02666958  0.42487866]
[2017-11-02 11:09:54,939] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99845266e-01   8.74877660e-05   2.30352653e-05   2.11728893e-05
   2.29896177e-05   5.92757790e-14   9.25917329e-14   3.31392628e-14
   7.18414382e-14]
[2017-11-02 11:09:55,762] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.74295020e-01   1.46232080e-02   3.31398356e-03   3.04523786e-03
   4.70947335e-03   3.63271602e-06   4.51261440e-06   3.24426901e-06
   1.79287247e-06]
[2017-11-02 11:09:55,908] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.64586794e-01   1.95542704e-02   4.83011641e-03   4.37808596e-03
   6.62135705e-03   8.10970414e-06   9.85287716e-06   7.28175883e-06
   4.10653820e-06]
[2017-11-02 11:09:56,368] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95400846e-01   2.21651746e-03   8.31772981e-04   5.95903432e-04
   9.54928342e-04   7.40443679e-11   1.52354018e-10   7.90293733e-11
   1.31696598e-10]
[2017-11-02 11:09:56,508] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.96928990e-01   1.49202230e-03   5.48474083e-04   3.92293878e-04
   6.38361031e-04   3.13038553e-11   6.73005124e-11   3.49715673e-11
   6.38015474e-11]
[2017-11-02 11:09:56,608] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98310089e-01   8.39580083e-04   2.93575809e-04   2.11674240e-04
   3.45099659e-04   8.91273427e-12   1.96106048e-11   1.02680477e-11
   2.05391988e-11]
[2017-11-02 11:09:57,009] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99756634e-01   1.54514579e-04   2.61463010e-05   2.83560003e-05
   3.44800210e-05   7.36108396e-11   9.76227293e-11   4.77258476e-11
   4.19313126e-11]
[2017-11-02 11:09:57,456] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.94485199e-01   3.23342439e-03   6.50605536e-04   6.57672179e-04
   9.72866896e-04   5.50784769e-08   6.70100135e-08   4.00391578e-08
   2.28926069e-08]
[2017-11-02 11:09:57,523] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95038807e-01   2.91218632e-03   5.92007767e-04   5.99269581e-04
   8.57589243e-04   4.35533600e-08   5.33545510e-08   3.13750981e-08
   1.86158129e-08]
[2017-11-02 11:09:57,881] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99911070e-01   5.10041609e-05   1.24067601e-05   9.21865558e-06
   1.63447494e-05   5.63641310e-13   1.19835587e-12   6.47372672e-13
   2.26538688e-12]
[2017-11-02 11:10:00,891] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99998927e-01   7.93279924e-07   8.21466841e-08   6.01163066e-08
   1.34962505e-07   9.17267022e-13   1.73255843e-12   1.00416713e-12
   6.11570560e-12]
[2017-11-02 11:10:02,181] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.34120262  0.06013218  0.01500101  0.00756557  0.02028177  0.02443464
  0.04216905  0.03224149  0.45697162]
[2017-11-02 11:10:04,238] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.43320061e-06   1.06047279e-04   2.72626366e-05   1.35844111e-05
   4.17472729e-05   5.97777180e-02   9.25516337e-02   7.34000579e-02
   7.74074495e-01]
[2017-11-02 11:10:06,546] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  5.81933796e-01   6.16527302e-03   3.50538176e-04   3.46909219e-04
   8.44575057e-04   8.21588039e-02   1.26491189e-01   1.10647894e-01
   9.10609290e-02]
[2017-11-02 11:10:06,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99855280e-01   1.11410714e-04   8.33285321e-06   8.97223435e-06
   1.59304345e-05   6.89876600e-09   1.08999174e-08   9.18607679e-09
   6.40460351e-09]
[2017-11-02 11:10:06,862] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99812901e-01   1.42851815e-04   1.11678673e-05   1.19186479e-05
   2.10748640e-05   8.61994298e-09   1.33156322e-08   1.12452705e-08
   7.57787788e-09]
[2017-11-02 11:10:07,644] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.82579470e-01   9.62053146e-03   3.00872209e-03   1.36602309e-03
   3.36077693e-03   1.05746142e-06   2.28628505e-06   1.71800139e-06
   5.93812074e-05]
[2017-11-02 11:10:12,126] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99999046e-01   6.80602227e-07   8.72687451e-08   5.41549880e-08
   1.12786054e-07   2.72930363e-15   6.18276114e-15   4.10167361e-15
   3.92315879e-14]
[2017-11-02 11:10:12,163] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99997735e-01   1.56553756e-06   2.71900205e-07   1.62592087e-07
   3.01195826e-07   2.36425583e-16   5.51487005e-16   3.52219328e-16
   4.01693729e-15]
[2017-11-02 11:10:12,883] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  6.01278957e-11   5.53682042e-08   1.86299793e-08   7.45472484e-09
   2.33173640e-08   3.56812030e-02   5.60385622e-02   4.92475256e-02
   8.59032631e-01]
[2017-11-02 11:10:14,212] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99993563e-01   4.86860563e-06   4.51388331e-07   4.50947738e-07
   6.34832986e-07   2.96835750e-10   4.03774764e-10   2.11783188e-10
   4.12719747e-10]
[2017-11-02 11:10:14,400] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99965787e-01   2.74344347e-05   1.74232855e-06   1.88606350e-06
   3.13977353e-06   1.55639095e-11   2.57928418e-11   1.99850674e-11
   1.88986847e-11]
[2017-11-02 11:10:17,217] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99850869e-01   8.44466049e-05   2.46647742e-05   1.39761514e-05
   2.60106772e-05   2.21733894e-12   4.30466340e-12   2.87286687e-12
   4.92702754e-11]
[2017-11-02 11:10:18,838] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99769509e-01   1.46101505e-04   2.56456115e-05   2.71363933e-05
   3.15629368e-05   4.28853619e-09   5.14894349e-09   2.65936140e-09
   3.64580321e-09]
[2017-11-02 11:10:21,755] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99990463e-01   5.89760566e-06   1.31854654e-06   7.89361081e-07
   1.54417387e-06   5.51178315e-15   1.22090355e-14   7.61949589e-15
   1.42276626e-13]
[2017-11-02 11:10:21,831] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [ 0.18302889  0.03500744  0.0078284   0.00383007  0.01122325  0.02717163
  0.05162882  0.03883021  0.64145136]
[2017-11-02 11:10:21,985] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  3.11613898e-04   9.22110223e-04   2.54572573e-04   1.23445599e-04
   3.48331319e-04   4.30601723e-02   7.21386299e-02   5.49623035e-02
   8.27878833e-01]
[2017-11-02 11:10:23,346] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99911547e-01   5.39805915e-05   1.06454791e-05   1.06954640e-05
   1.30875706e-05   2.78006199e-12   4.10891590e-12   1.65062939e-12
   3.20608731e-12]
[2017-11-02 11:10:24,142] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.28176498e-01   7.51366690e-02   3.35642509e-02   2.79470123e-02
   3.45877111e-02   1.81656884e-04   2.00243798e-04   1.29809967e-04
   7.61705742e-05]
[2017-11-02 11:10:24,234] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.80919015e-01   9.18439180e-02   4.47462983e-02   3.68955843e-02
   4.48245443e-02   2.38775057e-04   2.62721733e-04   1.69141931e-04
   9.99037220e-05]
[2017-11-02 11:10:24,703] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99447167e-01   2.49845936e-04   1.26152925e-04   7.36989605e-05
   1.03107646e-04   1.78657165e-17   4.45084745e-17   2.02361697e-17
   1.61112403e-16]
[2017-11-02 11:10:27,748] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.90241468e-01   5.61752217e-03   1.51840912e-03   8.00902722e-04
   1.80497230e-03   6.89291312e-07   1.27404519e-06   9.18192598e-07
   1.37891266e-05]
[2017-11-02 11:10:28,723] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.58581841e-01   6.44130483e-02   2.62758099e-02   2.16559805e-02
   2.87094396e-02   1.09784742e-04   1.23532285e-04   8.29919882e-05
   4.75801753e-05]
[2017-11-02 11:10:29,535] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.33455086e-01   6.77549914e-02   3.76963727e-02   2.84644850e-02
   3.26289684e-02   1.08536851e-08   1.27427962e-08   5.57767121e-09
   3.84583609e-09]
[2017-11-02 11:10:31,465] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.71184826e-01   5.54195940e-02   2.46717893e-02   2.24365145e-02
   2.62852330e-02   6.72170984e-07   7.33664933e-07   3.86938837e-07
   2.34980504e-07]
[2017-11-02 11:10:31,488] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  7.85850167e-01   8.52124467e-02   4.84855846e-02   3.77116688e-02
   4.27394398e-02   2.38149866e-07   2.74358854e-07   1.32036121e-07
   8.67573817e-08]
[2017-11-02 11:10:31,568] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.40948224e-01   6.57556802e-02   3.59559022e-02   2.64556408e-02
   3.08845025e-02   1.03649693e-08   1.29485169e-08   5.49162182e-09
   3.97131172e-09]
[2017-11-02 11:10:33,106] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  8.66418839e-01   6.12503551e-02   2.44771726e-02   2.04715822e-02
   2.70885937e-02   8.88901050e-05   1.01169295e-04   6.62781240e-05
   3.71562564e-05]
[2017-11-02 11:10:33,732] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.48849142e-01   2.23328471e-02   1.12551348e-02   7.57186394e-03
   9.99106746e-03   5.59569925e-11   8.06552672e-11   3.51527071e-11
   3.75333722e-11]
[2017-11-02 11:10:34,152] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99412537e-01   2.61659443e-04   1.36540708e-04   7.76029265e-05
   1.11614856e-04   1.72966404e-16   4.27325819e-16   2.17511973e-16
   1.74817870e-15]
[2017-11-02 11:10:35,029] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99902487e-01   5.75211743e-05   1.42760482e-05   1.31160405e-05
   1.24894677e-05   3.39160991e-13   5.08643962e-13   1.79822222e-13
   4.43187072e-13]
[2017-11-02 11:10:35,104] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.98860359e-01   6.51774870e-04   1.71869804e-04   1.61119562e-04
   1.54871537e-04   5.63844874e-11   7.41194051e-11   3.01445431e-11
   3.89665071e-11]
[2017-11-02 11:10:35,387] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.95117545e-01   2.88077118e-03   6.50760951e-04   6.40466576e-04
   7.10361230e-04   4.92258394e-08   5.91389799e-08   3.14862127e-08
   2.43414267e-08]
[2017-11-02 11:10:35,601] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.92244661e-01   4.54223342e-03   1.02764135e-03   9.99937765e-04
   1.18504802e-03   1.27612040e-07   1.57034961e-07   8.63367404e-08
   6.07630994e-08]
[2017-11-02 11:10:39,826] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.97074246e-01   1.97520782e-03   2.60649249e-04   2.61773210e-04
   4.27696941e-04   1.23143877e-07   1.65758777e-07   1.19544694e-07
   6.80096193e-08]
[2017-11-02 11:10:40,623] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99995589e-01   2.67291534e-06   6.84286135e-07   3.92976460e-07
   6.55445945e-07   2.16163470e-17   4.94259805e-17   3.16016908e-17
   6.18257130e-16]
[2017-11-02 11:10:43,172] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99986887e-01   1.00483685e-05   7.89021044e-07   9.00870361e-07
   1.35749383e-06   7.17608195e-10   8.91648144e-10   5.28348532e-10
   6.08208928e-10]
[2017-11-02 11:10:46,930] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99709904e-01   1.70222193e-04   3.77644174e-05   3.72925642e-05
   4.48559331e-05   5.60618609e-12   8.19575310e-12   3.34908815e-12
   4.59004102e-12]
[2017-11-02 11:10:50,946] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99980330e-01   1.14898894e-05   3.11110966e-06   1.85449960e-06
   3.25504607e-06   1.80299010e-15   3.66063753e-15   2.29027905e-15
   2.94822523e-14]
[2017-11-02 11:10:51,972] A3C_AGENT_WORKER-Thread-2 INFO:Softmax [  9.99992609e-01   4.95705581e-06   7.45030889e-07   7.14894838e-07
   1.00807097e-06   2.91202717e-12   3.77776976e-12   1.62138076e-12
   7.97511623e-12]
[2017-11-02 11:10:54,888] A3C_AGENT_WORKER-Thread-2 INFO:Evaluation: average reward by now is -18897.0845
[2017-11-02 11:10:54,889] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 500000, evaluation results [500000.0, -18897.08454706009]
[2017-11-02 11:10:55,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99328852e-01   3.63724743e-04   1.03282822e-04   7.95384476e-05
   1.24552447e-04   4.63268226e-12   9.42376125e-12   5.29795999e-12
   1.21742434e-11], sum to 1.0000
[2017-11-02 11:10:55,515] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.05833333333333, 54.58333333333334, 6.191666666666666, 140.8333333333333, 21.41666666666666, 15.41666666666667, 7.199999999999999, 8.322220854923621, 18.0, 23.89622098789852, 22.7, 1.0, 0.0], 
actual action is [7.05833333333333, 18], 
sim time next is 1617000.0000, 
raw observation next is [11.91666666666667, 55.16666666666666, 6.283333333333333, 141.6666666666667, 17.33333333333333, 12.33333333333333, 7.05833333333333, 8.653731313985595, 18.0, 23.82976498172837, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.7391304347826086, 0.6388888888888891, 0.5516666666666665, 0.5712121212121212, 0.39351851851851866, 0.04585537918871251, 0.01233333333333333, 0.6176388888888888, 0.08653731313985595, 0.0, 0.8328235688183386, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0087. 
=============================================
[2017-11-02 11:10:58,664] A3C_AGENT_WORKER-Thread-6 DEBUG:Value prediction is [[-15.97127247]
 [-14.93029308]
 [-14.33503628]
 [-14.83100414]
 [-15.04319954]], R is [[-15.3426218 ]
 [-15.18919563]
 [-15.03730392]
 [-14.88693142]
 [-15.8094883 ]].
[2017-11-02 11:10:59,081] A3C_AGENT_WORKER-Thread-10 INFO:Local step 31500, global step 500947: loss 4.6548
[2017-11-02 11:11:01,933] A3C_AGENT_WORKER-Thread-6 INFO:Local step 31500, global step 501619: loss 57.9607
[2017-11-02 11:11:03,565] A3C_AGENT_WORKER-Thread-7 INFO:Local step 31500, global step 502072: loss 0.2948
[2017-11-02 11:11:05,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.98018384e-01   9.10116651e-04   3.82397848e-04   2.78673280e-04
   4.10422072e-04   1.67462701e-08   2.91098843e-08   2.42955114e-08
   2.19297505e-08], sum to 1.0000
[2017-11-02 11:11:05,828] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [12.65833333333333, 52.75, 6.558333333333334, 148.3333333333333, 45.91666666666666, 33.91666666666666, 7.75, 7.870631192301595, 18.0, 23.97015822180994, 22.7, 1.0, 0.0], 
actual action is [7.65833333333333, 18], 
sim time next is 1615200.0000, 
raw observation next is [12.56666666666667, 53.0, 6.466666666666667, 146.6666666666667, 41.83333333333334, 30.83333333333334, 7.65833333333333, 7.874738283033852, 18.0, 23.94786981687016, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6956521739130435, 0.6555555555555557, 0.53, 0.5878787878787879, 0.40740740740740755, 0.11067019400352736, 0.030833333333333338, 0.6276388888888889, 0.07874738283033852, 0.0, 0.8496956881243085, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0079. 
=============================================
[2017-11-02 11:11:06,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  9.99965906e-01   1.35706741e-05   9.37806817e-06   4.58706381e-06
   6.59587886e-06   1.42106053e-13   2.76836930e-13   2.89335667e-13
   7.00784591e-13], sum to 1.0000
[2017-11-02 11:11:06,127] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [10.13333333333333, 62.66666666666667, 5.800000000000001, 156.6666666666667, 0.0, 0.0, 5.225, 10.8078372844667, 18.0, 22.77720998154225, 22.7, 1.0, 0.0], 
actual action is [5.133333333333329, 18], 
sim time next is 1621500.0000, 
raw observation next is [10.04166666666667, 63.08333333333333, 5.449999999999999, 158.3333333333333, 0.0, 0.0, 5.133333333333329, 10.99324793935213, 18.0, 22.69742941178695, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.782608695652174, 0.5908119658119659, 0.6308333333333332, 0.49545454545454537, 0.43981481481481466, 0.0, 0.0, 0.5855555555555554, 0.1099324793935213, 0.0, 0.6710613445409928, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0110. 
=============================================
[2017-11-02 11:11:07,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 31500, global step 503013: loss -4.6662
[2017-11-02 11:11:07,877] A3C_AGENT_WORKER-Thread-3 INFO:Local step 31500, global step 503183: loss -4.0870
[2017-11-02 11:11:07,887] A3C_AGENT_WORKER-Thread-8 INFO:Local step 31500, global step 503185: loss -5.4708
[2017-11-02 11:11:08,815] A3C_AGENT_WORKER-Thread-17 INFO:Local step 31500, global step 503414: loss 0.2725
[2017-11-02 11:11:08,963] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  9.99999166e-01   3.66206223e-07   2.60926271e-07   1.07591653e-07
   1.62785938e-07   1.33161423e-14   3.47699944e-14   3.36478248e-14
   1.78053861e-13], sum to 1.0000
[2017-11-02 11:11:09,062] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [4.15, 92.0, 7.7, 250.0, 0.0, 0.0, -0.7083333333333339, 13.93925040136167, 18.0, 20.99937646030371, 22.7, 1.0, 0.0], 
actual action is [-0.8499999999999996, 18], 
sim time next is 1668900.0000, 
raw observation next is [4.008333333333333, 92.0, 7.7, 250.0, 0.0, 0.0, -0.8499999999999996, 14.69538263682374, 18.0, 21.26768390222264, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.30434782608695654, 0.4361111111111111, 0.92, 0.7000000000000001, 0.6944444444444444, 0.0, 0.0, 0.4858333333333333, 0.1469538263682374, 0.0, 0.4668119860318057, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 11:11:10,544] A3C_AGENT_WORKER-Thread-5 INFO:Local step 31500, global step 503791: loss 17.1192
[2017-11-02 11:11:11,086] A3C_AGENT_WORKER-Thread-4 INFO:Local step 31500, global step 503911: loss 0.7107
[2017-11-02 11:11:11,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99493003e-01   9.58403762e-05   2.66479561e-04   3.23236964e-05
   5.95540623e-05   7.40647181e-07   1.46224863e-06   2.54588849e-06
   4.80623239e-05], sum to 1.0000
[2017-11-02 11:11:11,586] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.4166666666666667, 92.5, 8.7, 248.3333333333333, 0.0, 0.0, -4.625, 20.0139198184736, 18.0, 20.74222436039259, 21.5, 0.0, 0.0], 
actual action is [-4.583333333333333, 18], 
sim time next is 1727700.0000, 
raw observation next is [0.4583333333333333, 92.25, 8.7, 249.1666666666667, 0.0, 0.0, -4.583333333333333, 21.53002616947216, 18.0, 20.8184853082548, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 1.0, 0.3450854700854701, 0.9225, 0.7909090909090909, 0.6921296296296298, 0.0, 0.0, 0.4236111111111111, 0.21530026169472158, 0.0, 0.4026407583221143, 0.5, 0.0, 0.0], 
reward next is -0.0974. 
=============================================
[2017-11-02 11:11:12,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.99993920e-01   2.83732152e-06   1.62229117e-06   5.98448992e-07
   9.43534587e-07   4.29378921e-16   9.38966621e-16   8.57316457e-16
   1.70014516e-15], sum to 1.0000
[2017-11-02 11:11:12,268] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.516666666666667, 238.3333333333333, 93.33333333333333, 0.0, -3.9, 14.37653125511362, 18.0, 21.93457325964161, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1691700.0000, 
raw observation next is [1.1, 88.0, 6.558333333333334, 239.1666666666667, 91.66666666666666, 0.0, -3.9, 14.71743422724062, 18.0, 21.89178963790858, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.5652173913043478, 0.36153846153846153, 0.88, 0.5962121212121212, 0.664351851851852, 0.24250440917107582, 0.0, 0.435, 0.1471743422724062, 0.0, 0.5559699482726543, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0147. 
=============================================
[2017-11-02 11:11:12,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   2.76343766e-08   2.51138239e-08   4.87641749e-09
   7.28982785e-09   4.37746338e-18   1.27612818e-17   1.77362181e-17
   1.11550348e-16], sum to 1.0000
[2017-11-02 11:11:12,387] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [7.491666666666666, 74.83333333333333, 7.408333333333333, 120.0, 0.0, 0.0, 2.533333333333333, 14.76682178824176, 18.0, 21.20962209130304, 21.5, 0.0, 0.0], 
actual action is [2.4916666666666663, 18], 
sim time next is 1629000.0000, 
raw observation next is [7.45, 75.0, 7.45, 120.0, 0.0, 0.0, 2.491666666666666, 15.17573305257682, 18.0, 21.16396587568249, 21.5, 0.0, 0.0], 
processed observation next is [0.5, 0.8695652173913043, 0.5243589743589744, 0.75, 0.6772727272727272, 0.3333333333333333, 0.0, 0.0, 0.5415277777777778, 0.1517573305257682, 0.0, 0.45199512509749845, 0.5, 0.0, 0.0], 
reward next is -0.0480. 
=============================================
[2017-11-02 11:11:12,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999762e-01   5.86234883e-08   6.27519512e-08   1.14297229e-08
   1.51895936e-08   2.51846560e-20   6.31290026e-20   9.03674334e-20
   8.17745429e-19], sum to 1.0000
[2017-11-02 11:11:12,612] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [6.6, 97.0, 3.366666666666667, 166.6666666666667, 0.0, 0.0, 1.6, 16.76494674501678, 18.0, 21.39187752876706, 21.5, 0.0, 0.0], 
actual action is [1.5999999999999996, 18], 
sim time next is 1658700.0000, 
raw observation next is [6.6, 97.0, 3.15, 170.0, 0.0, 0.0, 1.6, 17.25771459978721, 18.0, 21.32185096724448, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.5025641025641026, 0.97, 0.2863636363636364, 0.4722222222222222, 0.0, 0.0, 0.5266666666666667, 0.1725771459978721, 0.0, 0.4745501381777828, 0.5, 0.0, 0.0], 
reward next is -0.0254. 
=============================================
[2017-11-02 11:11:15,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99999762e-01   1.03318492e-07   6.26084855e-08   1.25645938e-08
   1.86840889e-08   3.44708790e-22   6.09002436e-22   1.80531825e-21
   6.81590362e-21], sum to 1.0000
[2017-11-02 11:11:15,796] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-0.09999999999999999, 90.33333333333334, 9.2, 241.6666666666667, 0.0, 0.0, 4.95, 16.04627664087014, 25.0, 21.00018160739887, 21.5, 0.0, 58.28008277264994], 
actual action is [4.9, 20.0], 
sim time next is 1739700.0000, 
raw observation next is [-0.15, 90.0, 9.2, 242.5, 0.0, 0.0, 4.9, 15.24581568918282, 20.0, 21.10912679539893, 21.5, 0.0, 41.84361488032917], 
processed observation next is [0.8333333333333334, 0.13043478260869565, 0.3294871794871795, 0.9, 0.8363636363636363, 0.6736111111111112, 0.0, 0.0, 0.5816666666666667, 0.1524581568918282, 0.2857142857142857, 0.44416097077127553, 0.5, 0.0, 0.49227782212151966], 
reward next is -0.4989. 
=============================================
[2017-11-02 11:11:16,372] A3C_AGENT_WORKER-Thread-9 INFO:Local step 31500, global step 505004: loss -7.3659
[2017-11-02 11:11:17,330] A3C_AGENT_WORKER-Thread-12 INFO:Local step 31500, global step 505172: loss 44.8857
[2017-11-02 11:11:17,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 31500, global step 505196: loss 21.2693
[2017-11-02 11:11:17,663] A3C_AGENT_WORKER-Thread-11 INFO:Local step 31500, global step 505250: loss -6.1426
[2017-11-02 11:11:18,063] A3C_AGENT_WORKER-Thread-14 INFO:Local step 31500, global step 505344: loss -43.1001
[2017-11-02 11:11:19,095] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.58920614e-38   5.35566109e-24   7.87900388e-24   8.83217840e-25
   3.38303433e-24   2.08770391e-02   1.32556828e-02   4.32901531e-01
   5.32965720e-01], sum to 1.0000
[2017-11-02 11:11:19,214] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.2, 91.0, 9.0, 240.0, 0.0, 0.0, -4.775, 16.39106154434277, 18.0, 21.31383582525559, 21.5, 0.0, 0.0], 
actual action is [5.2, 23.0], 
sim time next is 1735500.0000, 
raw observation next is [0.1833333333333333, 90.99999999999999, 9.016666666666666, 240.0, 0.0, 0.0, 5.2, 14.82898402843525, 23.0, 21.34199806337767, 21.5, 0.0, 67.45521401088232], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.33803418803418805, 0.9099999999999998, 0.8196969696969696, 0.6666666666666666, 0.0, 0.0, 0.5866666666666667, 0.14828984028435252, 0.7142857142857143, 0.4774282947682385, 0.5, 0.0, 0.7935907530692037], 
reward next is -0.7368. 
=============================================
[2017-11-02 11:11:19,591] A3C_AGENT_WORKER-Thread-13 INFO:Local step 31500, global step 505655: loss 86.9913
[2017-11-02 11:11:20,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  9.99999285e-01   5.85785585e-07   9.98436747e-08   3.91590476e-08
   3.80458651e-08   2.42708896e-20   4.42125711e-20   6.54355131e-19
   1.62365731e-19], sum to 1.0000
[2017-11-02 11:11:20,134] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.1, 88.0, 6.749999999999999, 235.0, 85.0, 0.0, -3.9, 12.62348862318748, 18.0, 22.13049890240072, 22.7, 1.0, 0.0], 
actual action is [-3.9, 18], 
sim time next is 1693200.0000, 
raw observation next is [1.1, 88.0, 6.800000000000001, 233.3333333333334, 83.33333333333334, 0.0, -3.9, 12.93094408181867, 18.0, 22.26750851676432, 22.7, 1.0, 0.0], 
processed observation next is [0.6666666666666666, 0.6086956521739131, 0.36153846153846153, 0.88, 0.6181818181818183, 0.6481481481481484, 0.22045855379188714, 0.0, 0.435, 0.12930944081818668, 0.0, 0.6096440738234742, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0129. 
=============================================
[2017-11-02 11:11:24,631] A3C_AGENT_WORKER-Thread-15 INFO:Local step 31500, global step 506568: loss 7.2824
[2017-11-02 11:11:25,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  1.17347747e-06   8.69362091e-04   2.20352458e-03   1.02620490e-03
   5.09980950e-04   4.25570831e-03   1.14334412e-02   6.06112629e-02
   9.19089317e-01], sum to 1.0000
[2017-11-02 11:11:25,879] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.2, 91.0, 9.0, 240.0, 0.0, 0.0, -4.775, 14.48118387876521, 18.0, 21.86005953555101, 21.5, 0.0, 0.0], 
actual action is [5.2, 23.0], 
sim time next is 1735500.0000, 
raw observation next is [0.1833333333333333, 90.99999999999999, 9.016666666666666, 240.0, 0.0, 0.0, 5.2, 13.83524457304403, 23.0, 21.76565273380562, 21.5, 0.0, 53.48151272260165], 
processed observation next is [0.8333333333333334, 0.08695652173913043, 0.33803418803418805, 0.9099999999999998, 0.8196969696969696, 0.6666666666666666, 0.0, 0.0, 0.5866666666666667, 0.13835244573044028, 0.7142857142857143, 0.53795039054366, 0.5, 0.0, 0.6291942673247253], 
reward next is -0.5663. 
=============================================
[2017-11-02 11:11:27,304] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  1.00000000e+00   2.92716651e-09   3.84815735e-09   1.95766447e-09
   7.53619112e-10   1.58683568e-31   8.39704233e-31   2.79271898e-30
   1.06109002e-28], sum to 1.0000
[2017-11-02 11:11:27,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  4.82230632e-19   1.20901932e-13   1.22678492e-13   5.25287957e-14
   5.98161047e-14   7.68049434e-03   1.12912646e-02   1.04054585e-01
   8.76973629e-01], sum to 1.0000
[2017-11-02 11:11:27,323] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 92.0, 8.7, 246.6666666666667, 0.0, 0.0, 5.5, 12.4910600336449, 20.0, 21.89592894054031, 21.5, 0.0, 43.3418513386171], 
actual action is [-4.5, 18], 
sim time next is 1729500.0000, 
raw observation next is [0.5, 92.0, 8.7, 245.8333333333333, 0.0, 0.0, -4.5, 14.09234794276747, 18.0, 21.95607711092794, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.0, 0.34615384615384615, 0.92, 0.7909090909090909, 0.6828703703703702, 0.0, 0.0, 0.425, 0.1409234794276747, 0.0, 0.5651538729897057, 0.5, 0.0, 0.0], 
reward next is 0.0000. 
=============================================
[2017-11-02 11:11:27,394] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [1.1, 88.0, 7.200000000000001, 216.6666666666667, 0.0, 0.0, 6.1, 11.79146624026761, 20.0, 22.34050391230963, 22.7, 1.0, 71.88196719269284], 
actual action is [6.1, 25.0], 
sim time next is 1707900.0000, 
raw observation next is [1.1, 88.0, 7.199999999999999, 218.3333333333333, 0.0, 0.0, 6.1, 11.62493309932733, 25.0, 22.30651822580879, 22.7, 1.0, 38.95968381621063], 
processed observation next is [0.6666666666666666, 0.782608695652174, 0.36153846153846153, 0.88, 0.6545454545454544, 0.6064814814814814, 0.0, 0.0, 0.6016666666666667, 0.11624933099327331, 1.0, 0.6152168894012559, 0.6714285714285714, 1.0, 0.45834922136718387], 
reward next is -0.4241. 
=============================================
[2017-11-02 11:11:52,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-74.40496826]
 [-73.51778412]
 [-75.65777588]
 [-75.17462921]
 [-74.2240448 ]], R is [[-75.66401672]
 [-75.90737915]
 [-76.1483078 ]
 [-76.38682556]
 [-76.62295532]].
[2017-11-02 11:11:52,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 32000, global step 509928: loss -261.8994
[2017-11-02 11:11:55,033] A3C_AGENT_WORKER-Thread-6 INFO:Local step 32000, global step 510189: loss -140.7551
[2017-11-02 11:11:58,173] A3C_AGENT_WORKER-Thread-7 INFO:Local step 32000, global step 510565: loss 172.4965
[2017-11-02 11:12:01,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  5.28190415e-22   6.17785598e-15   2.08502960e-13   6.44892028e-16
   2.65673832e-15   2.80546847e-05   2.62256770e-04   2.78837886e-03
   9.96921301e-01], sum to 1.0000
[2017-11-02 11:12:01,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 85.0, 9.7, 250.0, 99.0, 0.0, -7.8, 18.72676151401176, 18.0, 22.04211858381231, 22.7, 1.0, 0.0], 
actual action is [2.2, 23.0], 
sim time next is 1780500.0000, 
raw observation next is [-2.8, 85.33333333333333, 9.616666666666665, 250.0, 96.25, 0.0, 2.2, 16.34305649234489, 23.0, 21.83476100588938, 22.7, 1.0, 99.76895133038518], 
processed observation next is [0.8333333333333334, 0.6086956521739131, 0.2615384615384615, 0.8533333333333333, 0.8742424242424242, 0.6944444444444444, 0.25462962962962965, 0.0, 0.5366666666666667, 0.1634305649234489, 0.7142857142857143, 0.54782300084134, 0.6714285714285714, 1.0, 1.1737523685927669], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:02,005] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99987125e-01   2.76019023e-07   1.24494254e-05   8.42941503e-08
   1.61020125e-07   2.67867755e-23   6.12444722e-23   3.79682919e-22
   1.12778865e-19], sum to 1.0000
[2017-11-02 11:12:02,012] A3C_AGENT_WORKER-Thread-8 INFO:Local step 32000, global step 511027: loss -158.1974
[2017-11-02 11:12:02,049] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-6.2, 79.0, 8.7, 245.0, 0.0, 0.0, -1.199999999999999, 21.71969082045766, 20.0, 20.12677350979494, 21.5, 0.0, 49.87907352401349], 
actual action is [-11.2, 18], 
sim time next is 1834500.0000, 
raw observation next is [-6.2, 79.0, 8.616666666666665, 245.8333333333333, 0.0, 0.0, -11.2, 24.56378177899338, 18.0, 20.18059319110866, 21.5, 0.0, 0.0], 
processed observation next is [1.0, 0.21739130434782608, 0.17435897435897435, 0.79, 0.7833333333333332, 0.6828703703703702, 0.0, 0.0, 0.31333333333333335, 0.2456378177899338, 0.0, 0.3115133130155228, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:02,251] A3C_AGENT_WORKER-Thread-16 INFO:Local step 32000, global step 511052: loss 36.4577
[2017-11-02 11:12:03,434] A3C_AGENT_WORKER-Thread-17 INFO:Local step 32000, global step 511179: loss 101.5985
[2017-11-02 11:12:05,693] A3C_AGENT_WORKER-Thread-3 INFO:Local step 32000, global step 511420: loss -29.4161
[2017-11-02 11:12:07,128] A3C_AGENT_WORKER-Thread-5 INFO:Local step 32000, global step 511577: loss 132.0305
[2017-11-02 11:12:08,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  2.09147041e-32   3.01724404e-20   5.00990665e-18   3.26312654e-21
   1.50517516e-20   5.83264511e-04   1.05101115e-03   5.87604009e-03
   9.92489636e-01], sum to 1.0000
[2017-11-02 11:12:09,129] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.541666666666667, 83.25, 9.616666666666665, 249.1666666666667, 0.0, 0.0, 0.5, 21.72408992234881, 23.0, 20.90952650040602, 21.5, 0.0, 94.08405833228082], 
actual action is [0.45833333333333304, 25], 
sim time next is 1800600.0000, 
raw observation next is [-4.583333333333333, 83.5, 9.533333333333333, 248.3333333333333, 0.0, 0.0, 0.458333333333333, 19.46619876594933, 25.0, 20.95262079016296, 21.5, 0.0, 63.15033568019498], 
processed observation next is [0.8333333333333334, 0.8695652173913043, 0.21581196581196585, 0.835, 0.8666666666666667, 0.6898148148148147, 0.0, 0.0, 0.5076388888888889, 0.1946619876594933, 1.0, 0.42180297002328004, 0.5, 0.0, 0.7429451256493527], 
reward next is -0.7468. 
=============================================
[2017-11-02 11:12:12,054] A3C_AGENT_WORKER-Thread-4 INFO:Local step 32000, global step 512156: loss -9.9427
[2017-11-02 11:12:16,692] A3C_AGENT_WORKER-Thread-14 INFO:Local step 32000, global step 512639: loss 37.4683
[2017-11-02 11:12:16,958] A3C_AGENT_WORKER-Thread-12 INFO:Local step 32000, global step 512669: loss 19.1070
[2017-11-02 11:12:17,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 32000, global step 512674: loss -46.0654
[2017-11-02 11:12:19,239] A3C_AGENT_WORKER-Thread-2 INFO:Local step 32000, global step 512898: loss -17.8577
[2017-11-02 11:12:19,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [  0.00000000e+00   4.93468120e-33   1.84264363e-30   3.41544292e-33
   2.37368294e-32   4.36905073e-03   1.76099967e-02   9.06595588e-03
   9.68955040e-01], sum to 1.0000
[2017-11-02 11:12:19,933] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.2, 80.66666666666666, 8.991666666666665, 244.1666666666667, 0.0, 0.0, -1.2, 16.15604753145966, 20.0, 21.05064592119252, 21.5, 0.0, 49.4335098002306], 
actual action is [-1.2000000000000002, 25.0], 
sim time next is 1831200.0000, 
raw observation next is [-6.199999999999999, 80.33333333333334, 9.033333333333333, 243.3333333333333, 0.0, 0.0, -1.2, 16.2732342876522, 25.0, 21.05795252007183, 21.5, 0.0, 43.24016676272986], 
processed observation next is [1.0, 0.17391304347826086, 0.17435897435897438, 0.8033333333333335, 0.8212121212121212, 0.6759259259259258, 0.0, 0.0, 0.48000000000000004, 0.16273234287652202, 1.0, 0.43685036001026134, 0.5, 0.0, 0.5087078442674101], 
reward next is -0.5210. 
=============================================
[2017-11-02 11:12:21,487] A3C_AGENT_WORKER-Thread-13 INFO:Local step 32000, global step 513149: loss -72.5619
[2017-11-02 11:12:21,771] A3C_AGENT_WORKER-Thread-11 INFO:Local step 32000, global step 513177: loss -128.2923
[2017-11-02 11:12:24,803] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  9.99999523e-01   3.45178131e-09   5.22298137e-07   6.41640630e-10
   1.77141046e-09   4.32720482e-33   1.44769380e-30   1.94316304e-31
   2.91442384e-28], sum to 1.0000
[2017-11-02 11:12:25,013] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.958333333333333, 71.0, 7.741666666666667, 240.0, 146.6666666666667, 33.75, 0.0, 15.32738161543833, 24.0, 21.72510083766306, 22.7, 1.0, 55.36117504438526], 
actual action is [0.04166666666666696, 19.0], 
sim time next is 1858200.0000, 
raw observation next is [-4.916666666666667, 71.0, 7.783333333333333, 240.0, 141.3333333333333, 26.99999999999999, 0.04166666666666696, 15.11282245241295, 19.0, 21.84852896824841, 22.7, 1.0, 57.1807339729309], 
processed observation next is [1.0, 0.5217391304347826, 0.20726495726495722, 0.71, 0.7075757575757575, 0.6666666666666666, 0.37389770723104043, 0.02699999999999999, 0.5006944444444444, 0.1511282245241295, 0.14285714285714285, 0.5497898526069156, 0.6714285714285714, 1.0, 0.6727145173285989], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:12:28,712] A3C_AGENT_WORKER-Thread-15 INFO:Local step 32000, global step 513860: loss 111.7255
[2017-11-02 11:12:34,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  3.55046911e-13   4.94011587e-09   2.70718124e-06   5.93097793e-09
   4.36496173e-09   8.34606035e-05   3.27573181e-03   6.20016304e-04
   9.96018112e-01], sum to 1.0000
[2017-11-02 11:12:34,790] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.666666666666667, 84.0, 4.433333333333334, 250.0, 0.0, 0.0, 0.291666666666667, 13.35861964669761, 24.0, 22.68582601464154, 22.7, 1.0, 62.82043011667013], 
actual action is [0.33333333333333304, 25], 
sim time next is 1881900.0000, 
raw observation next is [-4.625, 83.75, 4.475, 252.5, 0.0, 0.0, 0.333333333333333, 13.14943530791192, 25.0, 22.74332482475086, 22.7, 1.0, 63.05729968321976], 
processed observation next is [1.0, 0.782608695652174, 0.21474358974358973, 0.8375, 0.4068181818181818, 0.7013888888888888, 0.0, 0.0, 0.5055555555555555, 0.1314943530791192, 1.0, 0.6776178321072658, 0.6714285714285714, 1.0, 0.7418505845084677], 
reward next is -0.6808. 
=============================================
[2017-11-02 11:12:43,707] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  0.00000000e+00   1.07531170e-34   1.52263649e-32   8.33577942e-35
   1.29154365e-34   8.23125988e-03   3.10671896e-01   9.57235228e-03
   6.71524405e-01], sum to 1.0000
[2017-11-02 11:12:43,805] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-8.9, 82.0, 3.275, 222.5, 0.0, 0.0, -3.9, 16.54548636215656, 25.0, 20.82667691506166, 21.5, 0.0, 46.12684784264881], 
actual action is [-3.9000000000000004, 25], 
sim time next is 1921800.0000, 
raw observation next is [-8.9, 82.0, 3.183333333333333, 221.6666666666667, 0.0, 0.0, -3.9, 16.58669090625938, 25.0, 20.81529180013327, 21.5, 0.0, 46.05329927872049], 
processed observation next is [0.0, 0.21739130434782608, 0.10512820512820512, 0.82, 0.28939393939393937, 0.6157407407407409, 0.0, 0.0, 0.435, 0.16586690906259383, 1.0, 0.40218454287618144, 0.5, 0.0, 0.5418035209261234], 
reward next is -0.5854. 
=============================================
[2017-11-02 11:13:06,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 32500, global step 517836: loss 3.7471
[2017-11-02 11:13:08,781] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  7.34339833e-01   1.37076462e-02   2.28503719e-01   2.36493768e-03
   5.16959932e-03   1.34857937e-05   1.33971020e-03   2.18288274e-04
   1.43427113e-02], sum to 1.0000
[2017-11-02 11:13:08,838] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.083333333333333, 65.0, 4.766666666666666, 228.3333333333333, 197.0, 2.666666666666667, 0.8250000000000002, 11.65760165703091, 23.0, 22.53092890922721, 22.7, 1.0, 54.17288319573777], 
actual action is [-9.083333333333332, 18.0], 
sim time next is 1947300.0000, 
raw observation next is [-3.991666666666667, 65.0, 4.683333333333333, 229.1666666666667, 189.5, 2.333333333333333, -9.083333333333332, 12.54480397097314, 18.0, 22.54319540293011, 22.7, 1.0, 0.0], 
processed observation next is [0.0, 0.5217391304347826, 0.23098290598290597, 0.65, 0.4257575757575757, 0.6365740740740742, 0.5013227513227513, 0.002333333333333333, 0.34861111111111115, 0.1254480397097314, 0.0, 0.6490279147043013, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:13:10,600] A3C_AGENT_WORKER-Thread-6 INFO:Local step 32500, global step 518308: loss 41.0949
[2017-11-02 11:13:11,299] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   1.38164943e-33   2.36240980e-32   1.32714322e-34
   8.68581133e-34   2.64786230e-03   1.89117461e-01   2.66577210e-02
   7.81576991e-01], sum to 1.0000
[2017-11-02 11:13:11,428] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-3.25, 62.0, 5.225, 235.0, 118.25, 0.0, -8.3, 15.20100919163793, 18.0, 22.08342828722517, 22.7, 1.0, 0.0], 
actual action is [1.75, 20.0], 
sim time next is 1952400.0000, 
raw observation next is [-3.2, 62.0, 5.266666666666667, 236.6666666666667, 116.1666666666667, 0.0, 1.75, 13.07478241464459, 20.0, 22.10645214055955, 22.7, 1.0, 67.81404137271335], 
processed observation next is [0.0, 0.6086956521739131, 0.2512820512820513, 0.62, 0.47878787878787876, 0.6574074074074076, 0.30731922398589073, 0.0, 0.5291666666666667, 0.1307478241464459, 0.2857142857142857, 0.5866360200799358, 0.6714285714285714, 1.0, 0.7978122514436864], 
reward next is -0.7311. 
=============================================
[2017-11-02 11:13:12,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  9.97196317e-01   1.13053829e-04   2.53761164e-03   6.43728927e-05
   8.85124828e-05   1.59571436e-11   5.70530567e-10   6.70816944e-11
   3.07345371e-09], sum to 1.0000
[2017-11-02 11:13:12,770] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-8.733333333333334, 80.66666666666667, 4.766666666666667, 233.3333333333333, 0.0, 0.0, -3.691666666666666, 13.49231489750756, 25.0, 21.34002194349998, 21.5, 0.0, 47.11511156155684], 
actual action is [-3.7333333333333343, 20.0], 
sim time next is 1917900.0000, 
raw observation next is [-8.775, 81.0, 4.6, 232.5, 0.0, 0.0, -3.733333333333334, 13.55170295026523, 20.0, 21.32262813233478, 21.5, 0.0, 47.00935625273269], 
processed observation next is [0.0, 0.17391304347826086, 0.10833333333333332, 0.81, 0.41818181818181815, 0.6458333333333334, 0.0, 0.0, 0.43777777777777777, 0.13551702950265232, 0.2857142857142857, 0.4746611617621116, 0.5, 0.0, 0.5530512500321493], 
reward next is -0.5231. 
=============================================
[2017-11-02 11:13:14,126] A3C_AGENT_WORKER-Thread-16 INFO:Local step 32500, global step 518775: loss 78.6777
[2017-11-02 11:13:14,429] A3C_AGENT_WORKER-Thread-7 INFO:Local step 32500, global step 518819: loss 24.0859
[2017-11-02 11:13:16,221] A3C_AGENT_WORKER-Thread-8 INFO:Local step 32500, global step 519031: loss 71.5072
[2017-11-02 11:13:17,568] A3C_AGENT_WORKER-Thread-3 INFO:Local step 32500, global step 519205: loss 33.7830
[2017-11-02 11:13:19,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 32500, global step 519429: loss 31.2195
[2017-11-02 11:13:20,813] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  3.54675422e-09   2.68483102e-08   8.25898951e-07   1.09715481e-08
   3.69760791e-08   1.81700557e-03   4.37755138e-02   4.34363168e-03
   9.50062931e-01], sum to 1.0000
[2017-11-02 11:13:20,911] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-3.166666666666667, 66.33333333333334, 4.433333333333334, 260.0, 37.33333333333333, 0.0, 1.925, 13.94209625245087, 20.0, 22.21191848380469, 22.7, 1.0, 35.32469943422323], 
actual action is [1.833333333333333, 25.0], 
sim time next is 1959900.0000, 
raw observation next is [-3.258333333333333, 67.41666666666666, 4.391666666666666, 260.0, 33.66666666666667, 0.0, 1.833333333333333, 13.94015071729297, 25.0, 22.25191075660713, 22.7, 1.0, 25.57856674498662], 
processed observation next is [0.0, 0.6956521739130435, 0.2497863247863248, 0.6741666666666666, 0.3992424242424242, 0.7222222222222222, 0.08906525573192241, 0.0, 0.5305555555555556, 0.1394015071729297, 1.0, 0.6074158223724473, 0.6714285714285714, 1.0, 0.3009243146469014], 
reward next is -0.2848. 
=============================================
[2017-11-02 11:13:21,045] A3C_AGENT_WORKER-Thread-5 INFO:Local step 32500, global step 519613: loss 17.0956
[2017-11-02 11:13:22,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[-53.89064407]
 [-52.26286316]
 [-53.04340363]
 [-52.17170715]
 [-51.96595383]], R is [[-52.61081696]
 [-52.76852036]
 [-52.9285965 ]
 [-53.09786224]
 [-53.28142929]].
[2017-11-02 11:13:28,412] A3C_AGENT_WORKER-Thread-4 INFO:Local step 32500, global step 520610: loss 10.6998
[2017-11-02 11:13:28,773] A3C_AGENT_WORKER-Thread-12 INFO:Local step 32500, global step 520665: loss -51.1408
[2017-11-02 11:13:32,711] A3C_AGENT_WORKER-Thread-9 INFO:Local step 32500, global step 521138: loss 0.8371
[2017-11-02 11:13:33,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 32500, global step 521205: loss 150.3241
[2017-11-02 11:13:35,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 32500, global step 521392: loss 45.3164
[2017-11-02 11:13:35,452] A3C_AGENT_WORKER-Thread-13 INFO:Local step 32500, global step 521416: loss -3.3106
[2017-11-02 11:13:37,584] A3C_AGENT_WORKER-Thread-11 INFO:Local step 32500, global step 521681: loss -28.7263
[2017-11-02 11:13:37,708] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  2.29168119e-29   9.69853048e-20   2.10693511e-18   5.66608768e-20
   1.06715636e-18   8.48536380e-03   8.98362994e-01   7.71894166e-03
   8.54327902e-02], sum to 1.0000
[2017-11-02 11:13:37,736] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-4.4, 85.33333333333334, 5.266666666666667, 253.3333333333333, 82.0, 0.0, 0.5499999999999998, 10.60143378121585, 21.0, 23.0171582009579, 22.7, 1.0, 22.77842188326439], 
actual action is [0.5999999999999996, 22.0], 
sim time next is 2042100.0000, 
raw observation next is [-4.35, 85.0, 5.35, 255.0, 79.25, 0.0, 0.5999999999999996, 10.79101787814651, 22.0, 22.98749246420834, 22.7, 1.0, 20.83270321023534], 
processed observation next is [0.16666666666666666, 0.6521739130434783, 0.2217948717948718, 0.85, 0.48636363636363633, 0.7083333333333334, 0.20965608465608465, 0.0, 0.51, 0.1079101787814651, 0.5714285714285714, 0.7124989234583344, 0.6714285714285714, 1.0, 0.2450906260027687], 
reward next is -0.2314. 
=============================================
[2017-11-02 11:13:39,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  0.00000000e+00   4.74464878e-25   1.47435137e-23   7.78854007e-25
   6.40177112e-24   7.59547725e-02   8.11720967e-01   1.80045404e-02
   9.43197682e-02], sum to 1.0000
[2017-11-02 11:13:39,233] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-5.6, 83.0, 4.199999999999999, 257.5, 0.0, 0.0, -0.6000000000000014, 10.84194975405874, 25.0, 22.47617074872006, 21.5, 0.0, 45.53840290903693], 
actual action is [-0.5999999999999996, 25], 
sim time next is 1984800.0000, 
raw observation next is [-5.6, 83.0, 4.066666666666666, 256.6666666666667, 0.0, 0.0, -0.5999999999999996, 10.83531802590931, 25.0, 22.46942170374908, 21.5, 0.0, 45.46159060986911], 
processed observation next is [0.0, 1.0, 0.18974358974358976, 0.83, 0.3696969696969697, 0.712962962962963, 0.0, 0.0, 0.49, 0.10835318025909309, 1.0, 0.6384888148212973, 0.5, 0.0, 0.5348422424690484], 
reward next is -0.4814. 
=============================================
[2017-11-02 11:13:43,089] A3C_AGENT_WORKER-Thread-15 INFO:Local step 32500, global step 522440: loss 8.1789
[2017-11-02 11:13:47,044] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   1.77944736e-30   8.48794521e-29   4.37871157e-30
   6.00784337e-29   7.42938695e-03   8.64980102e-01   7.48857018e-03
   1.20101988e-01], sum to 1.0000
[2017-11-02 11:13:47,142] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 6, 
current raw observation is [-6.066666666666666, 86.33333333333333, 4.933333333333333, 240.0, 35.66666666666666, 0.0, -1.083333333333333, 12.12027852655193, 19.0, 22.01725263777491, 22.7, 1.0, 63.92427859404962], 
actual action is [-1.0666666666666664, 20.0], 
sim time next is 2018700.0000, 
raw observation next is [-6.05, 86.25, 4.975, 240.0, 39.0, 0.0, -1.066666666666666, 12.1794804484776, 20.0, 21.99881771172628, 22.7, 1.0, 38.60976194407841], 
processed observation next is [0.16666666666666666, 0.34782608695652173, 0.1782051282051282, 0.8625, 0.4522727272727272, 0.6666666666666666, 0.10317460317460317, 0.0, 0.4822222222222222, 0.121794804484776, 0.2857142857142857, 0.5712596731037541, 0.6714285714285714, 1.0, 0.454232493459746], 
reward next is -0.4210. 
=============================================
[2017-11-02 11:13:51,249] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  4.18915610e-25   7.56062668e-16   5.14376478e-14   5.16485921e-15
   3.17837594e-14   3.09781153e-02   2.84426451e-01   2.02905405e-02
   6.64304912e-01], sum to 1.0000
[2017-11-02 11:13:51,307] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.5, 90.16666666666667, 5.1, 261.6666666666667, 0.0, 0.0, 0.5, 9.8327648286689, 25.0, 22.44065917983294, 21.5, 0.0, 45.79684702772398], 
actual action is [0.5, 25], 
sim time next is 2078100.0000, 
raw observation next is [-4.5, 89.75, 5.1, 262.5, 0.0, 0.0, 0.5, 9.793109271171732, 25.0, 22.44546583473726, 21.5, 0.0, 45.78987689716251], 
processed observation next is [0.3333333333333333, 0.043478260869565216, 0.21794871794871795, 0.8975, 0.4636363636363636, 0.7291666666666666, 0.0, 0.0, 0.5083333333333333, 0.09793109271171732, 1.0, 0.6350665478196085, 0.5, 0.0, 0.5387044340842648], 
reward next is -0.4848. 
=============================================
[2017-11-02 11:14:07,128] A3C_AGENT_WORKER-Thread-10 INFO:Local step 33000, global step 525491: loss 14.6892
[2017-11-02 11:14:09,058] A3C_AGENT_WORKER-Thread-6 INFO:Local step 33000, global step 525679: loss 20.4266
[2017-11-02 11:14:13,598] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  9.99999642e-01   4.60169041e-08   1.19071359e-07   2.35771296e-08
   7.68266517e-08   3.23153651e-23   8.55981735e-23   6.39147159e-23
   5.07832149e-22], sum to 1.0000
[2017-11-02 11:14:13,624] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.149999999999999, 72.25, 4.85, 252.5, 271.75, 90.75, -12.2, 11.88666893818693, 18.0, 22.56334430732191, 22.7, 1.0, 0.0], 
actual action is [-12.149999999999999, 18], 
sim time next is 2114400.0000, 
raw observation next is [-7.100000000000001, 71.33333333333334, 4.766666666666667, 253.3333333333333, 278.8333333333334, 94.16666666666667, -12.15, 12.45688525897274, 18.0, 22.54600573520039, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.4782608695652174, 0.15128205128205124, 0.7133333333333334, 0.43333333333333335, 0.7037037037037036, 0.7376543209876546, 0.09416666666666668, 0.29750000000000004, 0.1245688525897274, 0.0, 0.6494293907429126, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0125. 
=============================================
[2017-11-02 11:14:14,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[-42.59101868]
 [-41.422966  ]
 [-40.61299133]
 [-40.88613892]
 [-41.05667877]], R is [[-41.58870316]
 [-42.17281723]
 [-41.76583481]
 [-41.36219788]
 [-40.96178436]].
[2017-11-02 11:14:14,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 33000, global step 526282: loss -17.0299
[2017-11-02 11:14:16,682] A3C_AGENT_WORKER-Thread-7 INFO:Local step 33000, global step 526684: loss -0.4559
[2017-11-02 11:14:17,120] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.33862779e-22   1.34621216e-14   5.34504793e-14   1.94698671e-14
   2.54664420e-14   2.33533442e-01   3.25617313e-01   1.27973586e-01
   3.12875658e-01], sum to 1.0000
[2017-11-02 11:14:17,180] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.6, 83.0, 4.333333333333333, 260.0, 0.0, 0.0, -0.5999999999999996, 17.36425787068436, 20.0, 21.4953899531721, 21.5, 0.0, 48.50616742963331], 
actual action is [-0.5999999999999996, 22.0], 
sim time next is 2148900.0000, 
raw observation next is [-5.6, 83.0, 4.466666666666666, 260.0, 0.0, 0.0, -0.5999999999999996, 17.51170649176602, 22.0, 21.39021173767012, 21.5, 0.0, 29.83406472762032], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.18974358974358976, 0.83, 0.406060606060606, 0.7222222222222222, 0.0, 0.0, 0.49, 0.17511706491766021, 0.5714285714285714, 0.48431596252430303, 0.5, 0.0, 0.3509889967955332], 
reward next is -0.3316. 
=============================================
[2017-11-02 11:14:17,658] A3C_AGENT_WORKER-Thread-3 INFO:Local step 33000, global step 526851: loss -121.6852
[2017-11-02 11:14:17,903] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-42.7748642 ]
 [-41.29005051]
 [-41.68781281]
 [-41.73126984]
 [-42.09475327]], R is [[-42.62950134]
 [-42.83296967]
 [-42.41733932]
 [-42.55105972]
 [-42.88235474]].
[2017-11-02 11:14:19,103] A3C_AGENT_WORKER-Thread-8 INFO:Local step 33000, global step 527074: loss 80.0743
[2017-11-02 11:14:21,253] A3C_AGENT_WORKER-Thread-17 INFO:Local step 33000, global step 527355: loss -7.0701
[2017-11-02 11:14:22,757] A3C_AGENT_WORKER-Thread-5 INFO:Local step 33000, global step 527562: loss -77.6363
[2017-11-02 11:14:27,067] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  6.54393807e-05   4.59899381e-02   2.13591889e-01   2.51618981e-01
   3.76275212e-01   1.54499477e-03   3.84201705e-02   2.82352697e-03
   6.96697906e-02], sum to 1.0000
[2017-11-02 11:14:27,148] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 4, 
current raw observation is [-6.7, 78.0, 3.0, 252.5, 0.0, 0.0, -1.700000000000001, 14.56713221232979, 24.0, 21.32904516237883, 21.5, 0.0, 45.92293477690157], 
actual action is [-1.7000000000000002, 24.0], 
sim time next is 2172000.0000, 
raw observation next is [-6.700000000000001, 78.0, 3.0, 253.3333333333333, 0.0, 0.0, -1.7, 14.40648215059858, 24.0, 21.34841784215532, 21.5, 0.0, 45.74094782631899], 
processed observation next is [0.5, 0.13043478260869565, 0.16153846153846152, 0.78, 0.2727272727272727, 0.7037037037037036, 0.0, 0.0, 0.4716666666666667, 0.1440648215059858, 0.8571428571428571, 0.4783454060221887, 0.5, 0.0, 0.538128797956694], 
reward next is -0.5060. 
=============================================
[2017-11-02 11:14:30,582] A3C_AGENT_WORKER-Thread-12 INFO:Local step 33000, global step 528586: loss -1.3172
[2017-11-02 11:14:31,506] A3C_AGENT_WORKER-Thread-4 INFO:Local step 33000, global step 528673: loss 93.6985
[2017-11-02 11:14:34,321] A3C_AGENT_WORKER-Thread-14 INFO:Local step 33000, global step 529044: loss -40.4951
[2017-11-02 11:14:35,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[-48.65523529]
 [-49.60780334]
 [-49.07776642]
 [-47.9052124 ]
 [-49.49046326]], R is [[-49.27331161]
 [-49.33863068]
 [-49.21385956]
 [-49.13039398]
 [-49.19465637]].
[2017-11-02 11:14:36,536] A3C_AGENT_WORKER-Thread-9 INFO:Local step 33000, global step 529330: loss 76.4537
[2017-11-02 11:14:37,149] A3C_AGENT_WORKER-Thread-13 INFO:Local step 33000, global step 529409: loss 10.6066
[2017-11-02 11:14:40,567] A3C_AGENT_WORKER-Thread-2 INFO:Local step 33000, global step 529828: loss -9.1652
[2017-11-02 11:14:42,900] A3C_AGENT_WORKER-Thread-11 INFO:Local step 33000, global step 530115: loss 0.3579
[2017-11-02 11:14:45,697] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99996901e-01   1.95847542e-06   2.03413890e-07   3.86471413e-07
   4.71280146e-07   4.97169960e-20   1.20306306e-18   9.64095754e-19
   9.12756666e-18], sum to 1.0000
[2017-11-02 11:14:45,742] A3C_AGENT_WORKER-Thread-15 INFO:Local step 33000, global step 530474: loss -25.5381
[2017-11-02 11:14:45,757] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.9, 68.0, 7.2, 250.0, 138.5, 142.5, -8.9, 9.806035607646225, 18.0, 23.19050361299978, 22.7, 1.0, 0.0], 
actual action is [-8.9, 18], 
sim time next is 2214300.0000, 
raw observation next is [-3.899999999999999, 68.0, 7.149999999999999, 250.0, 141.5833333333333, 166.25, -8.9, 10.51161443880792, 18.0, 23.28542093968844, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.6521739130434783, 0.23333333333333336, 0.68, 0.6499999999999999, 0.6944444444444444, 0.3745590828924161, 0.16625, 0.3516666666666667, 0.1051161443880792, 0.0, 0.7550601342412057, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0105. 
=============================================
[2017-11-02 11:14:49,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  8.95678997e-01   5.80931343e-02   6.91667153e-03   1.84220597e-02
   1.76440217e-02   9.71050667e-06   3.30522365e-04   2.11533887e-04
   2.69327615e-03], sum to 1.0000
[2017-11-02 11:14:49,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 1, 
current raw observation is [-4.45, 70.75, 7.108333333333333, 261.6666666666666, 132.1666666666667, 0.0, -9.5, 13.67123306200142, 18.0, 22.30463990144864, 22.7, 1.0, 0.0], 
actual action is [-9.45, 18], 
sim time next is 2200200.0000, 
raw observation next is [-4.4, 70.5, 7.016666666666667, 263.3333333333334, 134.3333333333333, 0.0, -9.45, 14.56322879017609, 18.0, 22.28846390261349, 22.7, 1.0, 0.0], 
processed observation next is [0.5, 0.4782608695652174, 0.2205128205128205, 0.705, 0.6378787878787878, 0.7314814814814817, 0.35537918871252194, 0.0, 0.3425, 0.14563228790176092, 0.0, 0.6126377003733557, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:14:50,984] A3C_AGENT_WORKER-Thread-4 DEBUG:Policy network output: [  0.00000000e+00   8.18029615e-37   3.45657463e-37   1.20319082e-36
   3.87814377e-36   4.22183331e-03   9.81872156e-02   6.11558929e-02
   8.36435080e-01], sum to 1.0000
[2017-11-02 11:14:51,064] A3C_AGENT_WORKER-Thread-4 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-6.700000000000001, 78.0, 3.0, 251.6666666666667, 0.0, 0.0, -1.7, 13.31186146124496, 25.0, 21.62779670887647, 21.5, 0.0, 45.21027678015864], 
actual action is [-1.700000000000001, 25], 
sim time next is 2171700.0000, 
raw observation next is [-6.7, 78.0, 3.0, 252.5, 0.0, 0.0, -1.700000000000001, 13.28829204737482, 25.0, 21.62631654430332, 21.5, 0.0, 45.06848766816866], 
processed observation next is [0.5, 0.13043478260869565, 0.16153846153846155, 0.78, 0.2727272727272727, 0.7013888888888888, 0.0, 0.0, 0.4716666666666666, 0.1328829204737482, 1.0, 0.5180452206147602, 0.5, 0.0, 0.5302175019784547], 
reward next is -0.4772. 
=============================================
[2017-11-02 11:14:59,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  5.51614262e-28   5.26222428e-17   7.74676895e-18   7.06404567e-17
   1.84298527e-16   4.27469751e-03   1.22422747e-01   1.53904893e-02
   8.57912123e-01], sum to 1.0000
[2017-11-02 11:14:59,599] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.675, 85.0, 3.85, 245.0, 0.0, 0.0, -2.633333333333333, 13.5678264230063, 25.0, 21.54494085803055, 21.5, 0.0, 46.09771665036101], 
actual action is [-2.675, 25], 
sim time next is 2256600.0000, 
raw observation next is [-7.716666666666667, 85.33333333333334, 3.766666666666667, 243.3333333333333, 0.0, 0.0, -2.675, 13.60568332672334, 25.0, 21.52948899497262, 21.5, 0.0, 46.04435116607841], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.13547008547008546, 0.8533333333333334, 0.34242424242424246, 0.6759259259259258, 0.0, 0.0, 0.45541666666666664, 0.13605683326723342, 1.0, 0.5042127135675172, 0.5, 0.0, 0.5416982490126871], 
reward next is -0.4875. 
=============================================
[2017-11-02 11:15:08,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[-44.6688652 ]
 [-44.19784546]
 [-44.09685898]
 [-44.32813263]
 [-44.56735992]], R is [[-44.2796936 ]
 [-44.8368988 ]
 [-45.38853073]
 [-44.94941711]
 [-44.51405334]].
[2017-11-02 11:15:08,332] A3C_AGENT_WORKER-Thread-10 INFO:Local step 33500, global step 533325: loss -30.4601
[2017-11-02 11:15:09,905] A3C_AGENT_WORKER-Thread-6 INFO:Local step 33500, global step 533521: loss -76.5478
[2017-11-02 11:15:14,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99998450e-01   6.02097202e-07   7.20376434e-08   3.11117617e-07
   4.68170185e-07   1.65828060e-23   3.90319717e-22   3.57140606e-22
   1.21569515e-20], sum to 1.0000
[2017-11-02 11:15:14,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.5, 68.5, 6.016666666666666, 276.6666666666667, 0.0, 0.0, 0.5, 12.56974063345286, 25.0, 21.90142380173065, 22.7, 1.0, 65.81815148609884], 
actual action is [0.5, 20.0], 
sim time next is 2224500.0000, 
raw observation next is [-4.5, 68.25, 6.058333333333333, 278.3333333333333, 0.0, 0.0, 0.5, 11.84927661810737, 20.0, 22.07915543225088, 22.7, 1.0, 66.10306134247826], 
processed observation next is [0.5, 0.7391304347826086, 0.21794871794871795, 0.6825, 0.5507575757575757, 0.7731481481481481, 0.0, 0.0, 0.5083333333333333, 0.1184927661810737, 0.2857142857142857, 0.5827364903215541, 0.6714285714285714, 1.0, 0.7776830746173913], 
reward next is -0.7118. 
=============================================
[2017-11-02 11:15:14,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 33500, global step 534066: loss -113.1180
[2017-11-02 11:15:15,005] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.46577591e-21   5.21700088e-13   1.03578794e-13   4.61087657e-13
   1.68751525e-12   9.84646939e-03   7.66583905e-02   1.21420413e-01
   7.92074680e-01], sum to 1.0000
[2017-11-02 11:15:15,062] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-8.775, 90.0, 2.775, 252.5, 0.0, 0.0, -3.733333333333334, 15.06683020429963, 25.0, 21.09211027218772, 21.5, 0.0, 45.5851028334779], 
actual action is [-3.7750000000000004, 25], 
sim time next is 2263800.0000, 
raw observation next is [-8.816666666666666, 90.33333333333334, 2.683333333333334, 251.6666666666667, 0.0, 0.0, -3.775, 15.11779317650542, 25.0, 21.07798045838677, 21.5, 0.0, 45.51440368489014], 
processed observation next is [0.6666666666666666, 0.17391304347826086, 0.10726495726495727, 0.9033333333333334, 0.243939393939394, 0.6990740740740742, 0.0, 0.0, 0.4370833333333334, 0.1511779317650542, 1.0, 0.43971149405525267, 0.5, 0.0, 0.5354635727634134], 
reward next is -0.5422. 
=============================================
[2017-11-02 11:15:18,335] A3C_AGENT_WORKER-Thread-7 INFO:Local step 33500, global step 534616: loss -99.1644
[2017-11-02 11:15:19,271] A3C_AGENT_WORKER-Thread-8 INFO:Local step 33500, global step 534750: loss -121.5492
[2017-11-02 11:15:19,272] A3C_AGENT_WORKER-Thread-3 INFO:Local step 33500, global step 534750: loss -1.3667
[2017-11-02 11:15:21,877] A3C_AGENT_WORKER-Thread-17 INFO:Local step 33500, global step 535063: loss -26.7690
[2017-11-02 11:15:25,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  9.99879718e-01   3.87285363e-05   1.39497088e-05   2.26046395e-05
   4.49176696e-05   8.13818980e-21   6.96622922e-19   7.19262701e-19
   7.02705895e-18], sum to 1.0000
[2017-11-02 11:15:25,279] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.25, 81.41666666666666, 4.558333333333333, 260.8333333333333, 0.0, 0.0, -2.199999999999999, 16.35365956673979, 20.0, 21.16337830420619, 21.5, 0.0, 47.39586862190762], 
actual action is [-12.25, 18], 
sim time next is 2253600.0000, 
raw observation next is [-7.3, 82.0, 4.6, 260.0, 0.0, 0.0, -12.25, 18.77411458683407, 18.0, 21.18078837539126, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.14615384615384616, 0.82, 0.41818181818181815, 0.7222222222222222, 0.0, 0.0, 0.29583333333333334, 0.1877411458683407, 0.0, 0.45439833934160845, 0.5, 0.0, 0.0], 
reward next is -0.0456. 
=============================================
[2017-11-02 11:15:25,676] A3C_AGENT_WORKER-Thread-4 DEBUG:Value prediction is [[-61.58578491]
 [-61.51700974]
 [-61.44451523]
 [-63.19597244]
 [-61.3844986 ]], R is [[-61.31842041]
 [-60.72665405]
 [-60.63731003]
 [-60.55662918]
 [-60.48739243]].
[2017-11-02 11:15:26,615] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  7.70510733e-01   8.09959024e-02   2.82402616e-02   3.42226364e-02
   8.60304460e-02   9.61764522e-12   1.47967794e-09   9.94622051e-10
   9.65990754e-09], sum to 1.0000
[2017-11-02 11:15:26,732] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-7.425, 83.0, 4.35, 255.0, 0.0, 0.0, -2.383333333333333, 19.815850357867, 25.0, 20.73357164908276, 21.5, 0.0, 41.78024802877477], 
actual action is [-2.425, 20.0], 
sim time next is 2254800.0000, 
raw observation next is [-7.466666666666667, 83.33333333333334, 4.266666666666667, 253.3333333333333, 0.0, 0.0, -2.425, 19.32340419665688, 20.0, 20.70677683094854, 21.5, 0.0, 49.83921433183559], 
processed observation next is [0.6666666666666666, 0.08695652173913043, 0.14188034188034188, 0.8333333333333335, 0.3878787878787879, 0.7037037037037036, 0.0, 0.0, 0.45958333333333334, 0.19323404196656882, 0.2857142857142857, 0.3866824044212202, 0.5, 0.0, 0.5863436980215952], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:15:27,961] A3C_AGENT_WORKER-Thread-5 INFO:Local step 33500, global step 536004: loss 17.5039
[2017-11-02 11:15:28,558] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  2.44166131e-07   1.02065627e-04   1.19984884e-06   4.12094414e-06
   2.17442939e-05   2.82474281e-03   2.00498641e-01   2.76620328e-01
   5.19926965e-01], sum to 1.0000
[2017-11-02 11:15:28,594] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [0.55, 43.5, 3.05, 240.0, 138.0, 42.0, 5.641666666666667, 14.27105013347023, 19.0, 22.29577583522854, 22.7, 1.0, 59.91052512591175], 
actual action is [5.55, 24.0], 
sim time next is 2302500.0000, 
raw observation next is [0.4583333333333333, 43.58333333333333, 3.225, 240.0, 129.9166666666667, 38.5, 5.55, 13.58630752751804, 24.0, 22.36231396952862, 22.7, 1.0, 28.27399094148715], 
processed observation next is [0.6666666666666666, 0.6521739130434783, 0.3450854700854701, 0.4358333333333333, 0.2931818181818182, 0.6666666666666666, 0.3436948853615521, 0.0385, 0.5924999999999999, 0.1358630752751804, 0.8571428571428571, 0.6231877099326601, 0.6714285714285714, 1.0, 0.33263518754690763], 
reward next is -0.3130. 
=============================================
[2017-11-02 11:15:32,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-45.35417175]
 [-46.00423813]
 [-45.49516296]
 [-45.50273514]
 [-45.37244034]], R is [[-45.44679642]
 [-45.72625732]
 [-46.06330109]
 [-46.22526169]
 [-45.97801208]].
[2017-11-02 11:15:33,332] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-54.21287537]
 [-53.97615051]
 [-55.15063858]
 [-53.60837173]
 [-54.15990829]], R is [[-54.79888535]
 [-55.25089645]
 [-55.69838715]
 [-56.1414032 ]
 [-56.57999039]].
[2017-11-02 11:15:33,593] A3C_AGENT_WORKER-Thread-12 INFO:Local step 33500, global step 536821: loss 15.4391
[2017-11-02 11:15:33,975] A3C_AGENT_WORKER-Thread-4 INFO:Local step 33500, global step 536870: loss 6.8334
[2017-11-02 11:15:34,141] A3C_AGENT_WORKER-Thread-14 INFO:Local step 33500, global step 536893: loss -18.1914
[2017-11-02 11:15:36,236] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99995470e-01   2.07500852e-06   4.64553835e-07   4.78175423e-07
   1.56171654e-06   3.55250453e-24   1.15349791e-22   1.55594761e-22
   6.09446016e-22], sum to 1.0000
[2017-11-02 11:15:36,267] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 56.0, 0.0, 0.0, 0.0, 0.0, -6.7, 22.1972623117565, 18.0, 21.09230785899088, 21.5, 0.0, 0.0], 
actual action is [-6.7, 18], 
sim time next is 2325900.0000, 
raw observation next is [-1.75, 56.24999999999999, 0.1666666666666667, 30.0, 0.0, 0.0, -6.7, 23.72501420868716, 18.0, 20.96609774034092, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.28846153846153844, 0.5624999999999999, 0.015151515151515155, 0.08333333333333333, 0.0, 0.0, 0.38833333333333336, 0.2372501420868716, 0.0, 0.42372824862013153, 0.5, 0.0, 0.0], 
reward next is -0.0763. 
=============================================
[2017-11-02 11:15:37,881] A3C_AGENT_WORKER-Thread-9 INFO:Local step 33500, global step 537410: loss -11.6099
[2017-11-02 11:15:39,753] A3C_AGENT_WORKER-Thread-13 INFO:Local step 33500, global step 537665: loss -9.5039
[2017-11-02 11:15:42,637] A3C_AGENT_WORKER-Thread-2 INFO:Local step 33500, global step 538074: loss -76.4845
[2017-11-02 11:15:44,977] A3C_AGENT_WORKER-Thread-11 INFO:Local step 33500, global step 538411: loss -82.5987
[2017-11-02 11:15:45,521] A3C_AGENT_WORKER-Thread-15 INFO:Local step 33500, global step 538483: loss -36.8111
[2017-11-02 11:15:48,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[-73.05911255]
 [-74.56413269]
 [-73.37625885]
 [-72.98335266]
 [-73.34286499]], R is [[-72.98299408]
 [-72.88421631]
 [-72.15927124]
 [-71.93481445]
 [-71.72483063]].
[2017-11-02 11:15:52,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  0.00000000e+00   4.01288241e-34   1.02981082e-35   1.97233158e-35
   5.77985108e-34   2.48494535e-03   1.38963368e-02   9.29570869e-02
   8.90661657e-01], sum to 1.0000
[2017-11-02 11:15:52,473] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.7, 55.66666666666667, 1.5, 245.0, 0.0, 0.0, 3.3, 16.84466205889256, 23.0, 21.79342566594594, 21.5, 0.0, 48.58525672326319], 
actual action is [3.3, 25], 
sim time next is 2319300.0000, 
raw observation next is [-1.7, 55.5, 1.5, 247.5, 0.0, 0.0, 3.3, 16.08741156398257, 25.0, 21.74317083290424, 21.5, 0.0, 44.22823081445809], 
processed observation next is [0.6666666666666666, 0.8695652173913043, 0.28974358974358977, 0.555, 0.13636363636363635, 0.6875, 0.0, 0.0, 0.5549999999999999, 0.1608741156398257, 1.0, 0.5347386904148915, 0.5, 0.0, 0.5203321272289186], 
reward next is -0.4683. 
=============================================
[2017-11-02 11:15:57,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  9.99998212e-01   1.30881483e-06   4.21746229e-08   4.37717702e-08
   4.84315592e-07   3.69024861e-28   8.96496970e-27   1.20239905e-26
   8.74175226e-25], sum to 1.0000
[2017-11-02 11:15:57,212] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.133333333333334, 43.33333333333334, 5.266666666666666, 70.0, 0.0, 0.0, -9.041666666666666, 26.52310638895977, 18.0, 20.98607490772583, 21.5, 0.0, 0.0], 
actual action is [-9.133333333333333, 18], 
sim time next is 2411100.0000, 
raw observation next is [-4.225, 43.5, 5.225, 70.0, 0.0, 0.0, -9.133333333333333, 28.23940535695683, 18.0, 20.76122131564021, 21.5, 0.0, 0.0], 
processed observation next is [0.8333333333333334, 0.9130434782608695, 0.225, 0.435, 0.475, 0.19444444444444445, 0.0, 0.0, 0.3477777777777778, 0.2823940535695683, 0.0, 0.39446018794860144, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:01,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [  9.04687215e-04   7.95147102e-03   3.65405213e-05   1.48354666e-04
   1.41150737e-03   1.90101448e-03   5.02180494e-02   1.97178870e-01
   7.40249515e-01], sum to 1.0000
[2017-11-02 11:16:01,180] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-1.15, 47.58333333333333, 6.1, 51.66666666666666, 216.5833333333333, 374.8333333333333, -6.2, 20.10189031090241, 18.0, 21.68607307161016, 22.7, 1.0, 0.0], 
actual action is [3.85, 20.0], 
sim time next is 2376600.0000, 
raw observation next is [-1.1, 48.16666666666667, 6.1, 53.33333333333334, 223.6666666666667, 384.6666666666666, 3.85, 17.33924885372593, 20.0, 21.57188122951064, 22.7, 1.0, 79.7099369075688], 
processed observation next is [0.8333333333333334, 0.5217391304347826, 0.30512820512820515, 0.4816666666666667, 0.5545454545454546, 0.14814814814814817, 0.5917107583774252, 0.38466666666666655, 0.5641666666666667, 0.1733924885372593, 0.2857142857142857, 0.5102687470729487, 0.6714285714285714, 1.0, 0.9377639636184565], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:01,515] A3C_AGENT_WORKER-Thread-10 INFO:Local step 34000, global step 540788: loss -84.1171
[2017-11-02 11:16:01,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  9.99975920e-01   1.20769446e-05   1.94717109e-06   2.47508888e-06
   7.63778280e-06   3.54813650e-27   2.39901599e-25   1.51609082e-25
   9.30360464e-24], sum to 1.0000
[2017-11-02 11:16:01,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.7, 55.83333333333333, 0.1250000000000001, 22.50000000000001, 0.0, 0.0, -6.7, 20.20411598273667, 18.0, 21.38852247859424, 21.5, 0.0, 0.0], 
actual action is [-6.7, 18], 
sim time next is 2325600.0000, 
raw observation next is [-1.7, 56.0, 0.0, 0.0, 0.0, 0.0, -6.7, 21.8811307016955, 18.0, 21.25023310383886, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.9565217391304348, 0.28974358974358977, 0.56, 0.0, 0.0, 0.0, 0.0, 0.38833333333333336, 0.218811307016955, 0.0, 0.4643190148341227, 0.5, 0.0, 0.0], 
reward next is -0.0357. 
=============================================
[2017-11-02 11:16:05,086] A3C_AGENT_WORKER-Thread-6 INFO:Local step 34000, global step 541324: loss -22.9086
[2017-11-02 11:16:08,689] A3C_AGENT_WORKER-Thread-16 INFO:Local step 34000, global step 541871: loss 19.7120
[2017-11-02 11:16:10,561] A3C_AGENT_WORKER-Thread-8 INFO:Local step 34000, global step 542114: loss 0.2239
[2017-11-02 11:16:13,992] A3C_AGENT_WORKER-Thread-3 INFO:Local step 34000, global step 542551: loss 13.5106
[2017-11-02 11:16:14,109] A3C_AGENT_WORKER-Thread-7 INFO:Local step 34000, global step 542564: loss 12.4586
[2017-11-02 11:16:18,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 34000, global step 543046: loss 4.8101
[2017-11-02 11:16:21,111] A3C_AGENT_WORKER-Thread-7 DEBUG:Value prediction is [[-70.28113556]
 [-72.90218353]
 [-71.90699768]
 [-73.14645386]
 [-73.90107727]], R is [[-71.84207153]
 [-72.1236496 ]
 [-72.40241241]
 [-72.6783905 ]
 [-72.95160675]].
[2017-11-02 11:16:26,194] A3C_AGENT_WORKER-Thread-5 INFO:Local step 34000, global step 544090: loss 25.5211
[2017-11-02 11:16:32,112] A3C_AGENT_WORKER-Thread-12 INFO:Local step 34000, global step 545104: loss -50.7881
[2017-11-02 11:16:32,134] A3C_AGENT_WORKER-Thread-4 INFO:Local step 34000, global step 545106: loss -16.6439
[2017-11-02 11:16:32,294] A3C_AGENT_WORKER-Thread-14 INFO:Local step 34000, global step 545135: loss -6.4753
[2017-11-02 11:16:33,521] A3C_AGENT_WORKER-Thread-9 INFO:Local step 34000, global step 545311: loss -39.4612
[2017-11-02 11:16:33,679] A3C_AGENT_WORKER-Thread-8 DEBUG:Value prediction is [[-70.60302734]
 [-69.98405457]
 [-71.01931   ]
 [-70.93572998]
 [-70.09384155]], R is [[-70.68405151]
 [-69.99146271]
 [-69.99996185]
 [-69.85289001]
 [-69.54738617]].
[2017-11-02 11:16:35,950] A3C_AGENT_WORKER-Thread-13 INFO:Local step 34000, global step 545731: loss 8.9888
[2017-11-02 11:16:36,362] A3C_AGENT_WORKER-Thread-2 INFO:Local step 34000, global step 545800: loss -24.1884
[2017-11-02 11:16:38,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-79.50973511]
 [-80.67836761]
 [-80.10007477]
 [-77.88137817]
 [-79.98265839]], R is [[-77.98591614]
 [-78.20605469]
 [-78.42399597]
 [-78.63975525]
 [-78.85335541]].
[2017-11-02 11:16:41,152] A3C_AGENT_WORKER-Thread-11 INFO:Local step 34000, global step 546621: loss 133.2520
[2017-11-02 11:16:41,161] A3C_AGENT_WORKER-Thread-15 INFO:Local step 34000, global step 546623: loss -46.9446
[2017-11-02 11:16:42,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [  0.00000000e+00   5.35712630e-25   4.68916987e-27   1.75525958e-26
   1.03482142e-24   1.23704367e-05   6.33514894e-04   8.55795108e-03
   9.90796089e-01], sum to 1.0000
[2017-11-02 11:16:42,184] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-7.425, 53.5, 4.35, 80.0, 0.0, 0.0, -12.38333333333333, 27.46402715820573, 18.0, 20.47572873202412, 21.5, 0.0, 0.0], 
actual action is [-2.425, 23.0], 
sim time next is 2427600.0000, 
raw observation next is [-7.466666666666667, 53.66666666666667, 4.433333333333334, 80.0, 0.0, 0.0, -2.425, 26.46587003397979, 23.0, 20.34464749143876, 21.5, 0.0, 56.08121668064394], 
processed observation next is [1.0, 0.08695652173913043, 0.14188034188034188, 0.5366666666666667, 0.40303030303030307, 0.2222222222222222, 0.0, 0.0, 0.45958333333333334, 0.2646587003397979, 0.7142857142857143, 0.33494964163410856, 0.5, 0.0, 0.6597790197722817], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:51,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  5.96120834e-01   5.06741814e-02   3.65631531e-05   1.45717568e-04
   3.87621787e-03   1.17248655e-05   6.17928337e-04   1.03467386e-02
   3.38170052e-01], sum to 1.0000
[2017-11-02 11:16:51,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 34500, global step 548096: loss -98.5244
[2017-11-02 11:16:51,988] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-1.025, 32.25, 4.6, 65.0, 87.0, 833.0, -6.166666666666667, 15.69851988868507, 18.0, 22.24812386133678, 22.7, 1.0, 0.0], 
actual action is [-6.025, 18], 
sim time next is 2461800.0000, 
raw observation next is [-0.8833333333333332, 31.83333333333334, 4.6, 63.33333333333333, 87.33333333333334, 834.3333333333334, -6.025, 17.00689198682602, 18.0, 22.26156686121228, 22.7, 1.0, 0.0], 
processed observation next is [1.0, 0.4782608695652174, 0.3106837606837607, 0.3183333333333334, 0.41818181818181815, 0.1759259259259259, 0.23104056437389772, 0.8343333333333334, 0.39958333333333335, 0.1700689198682602, 0.0, 0.6087952658874686, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:16:55,892] A3C_AGENT_WORKER-Thread-6 INFO:Local step 34500, global step 548750: loss 11.6265
[2017-11-02 11:16:58,472] A3C_AGENT_WORKER-Thread-16 INFO:Local step 34500, global step 549204: loss 0.6443
[2017-11-02 11:17:00,613] A3C_AGENT_WORKER-Thread-8 INFO:Local step 34500, global step 549637: loss 13.6353
[2017-11-02 11:17:04,385] A3C_AGENT_WORKER-Thread-7 INFO:Local step 34500, global step 550417: loss -23.1790
[2017-11-02 11:17:04,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 34500, global step 550445: loss -13.7993
[2017-11-02 11:17:07,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [  0.00000000e+00   2.46646486e-32   3.06264092e-32   8.20606259e-32
   5.83766511e-33   2.34619225e-03   1.03263627e-03   1.03584886e-01
   8.93036306e-01], sum to 1.0000
[2017-11-02 11:17:08,135] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-2.8, 54.0, 2.458333333333333, 39.16666666666666, 0.0, 0.0, 2.2, 23.24554789192361, 23.0, 20.18497056116225, 22.7, 1.0, 104.1418102152653], 
actual action is [2.2, 25], 
sim time next is 2531400.0000, 
raw observation next is [-2.8, 54.0, 2.416666666666667, 38.33333333333334, 0.0, 0.0, 2.2, 20.89587136148423, 25.0, 20.26092015724389, 22.7, 1.0, 76.5296685818242], 
processed observation next is [0.0, 0.30434782608695654, 0.2615384615384615, 0.54, 0.21969696969696972, 0.10648148148148151, 0.0, 0.0, 0.5366666666666667, 0.20895871361484228, 1.0, 0.3229885938919845, 0.6714285714285714, 1.0, 0.9003490421391082], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:09,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 34500, global step 551141: loss 23.9571
[2017-11-02 11:17:10,803] A3C_AGENT_WORKER-Thread-7 DEBUG:Policy network output: [  1.73956676e-06   2.63072993e-03   3.67981778e-03   3.83728044e-03
   4.85271798e-04   5.24543750e-04   1.20974053e-03   1.38942702e-02
   9.73736584e-01], sum to 1.0000
[2017-11-02 11:17:10,938] A3C_AGENT_WORKER-Thread-7 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-4.708333333333333, 64.5, 3.891666666666666, 270.0, 0.0, 0.0, -9.666666666666668, 24.51121733602368, 18.0, 20.83823440433104, 21.5, 0.0, 0.0], 
actual action is [0.29166666666666696, 23.0], 
sim time next is 2593800.0000, 
raw observation next is [-4.75, 65.0, 3.85, 270.0, 0.0, 0.0, 0.291666666666667, 21.10688518107541, 23.0, 20.63733026857078, 21.5, 0.0, 87.32567179423378], 
processed observation next is [0.16666666666666666, 0.0, 0.21153846153846154, 0.65, 0.35000000000000003, 0.75, 0.0, 0.0, 0.5048611111111111, 0.21106885181075408, 0.7142857142857143, 0.3767614669386826, 0.5, 0.0, 1.0273608446380444], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:16,866] A3C_AGENT_WORKER-Thread-5 INFO:Local step 34500, global step 552309: loss -58.9500
[2017-11-02 11:17:17,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [  9.99995589e-01   3.00496436e-06   4.32364828e-07   7.96989866e-07
   9.96880303e-08   7.32187191e-17   4.99445400e-17   7.66737824e-16
   5.80353984e-15], sum to 1.0000
[2017-11-02 11:17:17,797] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-3.233333333333333, 58.66666666666666, 8.283333333333333, 235.8333333333333, 218.0, 179.6666666666667, 1.633333333333333, 14.68548130824203, 25.0, 22.13918765301202, 22.7, 1.0, 48.81861831106453], 
actual action is [1.766666666666667, 20.0], 
sim time next is 2633400.0000, 
raw observation next is [-3.1, 58.0, 8.2, 235.0, 224.0, 171.0, 1.766666666666667, 13.40696590150689, 20.0, 22.23836128787744, 22.7, 1.0, 45.20553766876398], 
processed observation next is [0.16666666666666666, 0.4782608695652174, 0.25384615384615383, 0.58, 0.7454545454545454, 0.6527777777777778, 0.5925925925925926, 0.171, 0.5294444444444444, 0.1340696590150689, 0.2857142857142857, 0.6054801839824913, 0.6714285714285714, 1.0, 0.531829854926635], 
reward next is -0.4921. 
=============================================
[2017-11-02 11:17:20,305] A3C_AGENT_WORKER-Thread-4 INFO:Local step 34500, global step 552974: loss 141.6868
[2017-11-02 11:17:21,497] A3C_AGENT_WORKER-Thread-12 INFO:Local step 34500, global step 553156: loss -43.1868
[2017-11-02 11:17:21,842] A3C_AGENT_WORKER-Thread-14 INFO:Local step 34500, global step 553201: loss 10.7330
[2017-11-02 11:17:22,254] A3C_AGENT_WORKER-Thread-9 INFO:Local step 34500, global step 553258: loss 9.9034
[2017-11-02 11:17:25,713] A3C_AGENT_WORKER-Thread-13 INFO:Local step 34500, global step 553809: loss 19.5704
[2017-11-02 11:17:25,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[-109.00382996]
 [-112.72373962]
 [-106.69056702]
 [-113.29626465]
 [-111.8473053 ]], R is [[-110.18507385]
 [-110.08322144]
 [-109.98239136]
 [-109.88256836]
 [-109.78374481]].
[2017-11-02 11:17:27,465] A3C_AGENT_WORKER-Thread-2 INFO:Local step 34500, global step 554112: loss -74.1897
[2017-11-02 11:17:31,636] A3C_AGENT_WORKER-Thread-15 INFO:Local step 34500, global step 554854: loss 142.7859
[2017-11-02 11:17:33,621] A3C_AGENT_WORKER-Thread-11 INFO:Local step 34500, global step 555170: loss -26.9842
[2017-11-02 11:17:35,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [  0.00000000e+00   3.14596009e-35   1.44476705e-34   5.50969998e-34
   4.31790184e-35   1.30730559e-05   1.69023097e-05   1.51778746e-03
   9.98452187e-01], sum to 1.0000
[2017-11-02 11:17:35,710] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 8, 
current raw observation is [-1.2, 62.0, 7.999999999999999, 240.0, 0.0, 0.0, -6.2, 16.50292173104057, 18.0, 22.34058282130578, 22.7, 1.0, 0.0], 
actual action is [3.8, 23.0], 
sim time next is 2663100.0000, 
raw observation next is [-1.2, 62.25, 8.174999999999999, 240.0, 0.0, 0.0, 3.8, 14.79787300271493, 23.0, 22.13269957719751, 22.7, 1.0, 80.58893076072609], 
processed observation next is [0.16666666666666666, 0.8260869565217391, 0.3025641025641026, 0.6225, 0.743181818181818, 0.6666666666666666, 0.0, 0.0, 0.5633333333333332, 0.14797873002714929, 0.7142857142857143, 0.5903856538853586, 0.6714285714285714, 1.0, 0.9481050677732481], 
reward next is -0.8681. 
=============================================
[2017-11-02 11:17:35,822] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  9.99987245e-01   1.29213220e-06   4.62370372e-06   6.28484941e-06
   5.28770897e-07   3.87818098e-19   1.87404365e-18   6.29563591e-17
   5.95889237e-14], sum to 1.0000
[2017-11-02 11:17:36,210] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-15.0, 83.0, 1.5, 60.0, 0.0, 0.0, -10.08333333333333, 27.6714039839788, 25.0, 19.44902091807529, 21.5, 0.0, 45.88960262901475], 
actual action is [-10.0, 20.0], 
sim time next is 2703900.0000, 
raw observation next is [-15.0, 83.0, 1.55, 68.33333333333333, 0.0, 0.0, -10.0, 27.21144784734129, 20.0, 19.43181750449951, 22.7, 1.0, 73.91983482520617], 
processed observation next is [0.3333333333333333, 0.30434782608695654, -0.05128205128205128, 0.83, 0.1409090909090909, 0.1898148148148148, 0.0, 0.0, 0.3333333333333333, 0.2721144784734129, 0.2857142857142857, 0.2045453577856442, 0.6714285714285714, 1.0, 0.8696451155906608], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:44,648] A3C_AGENT_WORKER-Thread-10 INFO:Local step 35000, global step 556517: loss 1.3237
[2017-11-02 11:17:47,110] A3C_AGENT_WORKER-Thread-6 INFO:Local step 35000, global step 556888: loss -39.4309
[2017-11-02 11:17:48,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99817789e-01   7.58617034e-06   2.31159684e-05   6.01305073e-05
   2.91563924e-06   1.35672599e-06   1.96171996e-07   7.85734883e-05
   8.38227425e-06], sum to 1.0000
[2017-11-02 11:17:48,481] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.708333333333334, 69.16666666666667, 7.2, 228.3333333333333, 97.91666666666667, 106.3333333333333, -10.85, 14.4269624125592, 18.0, 22.87396366517746, 22.7, 1.0, 0.0], 
actual action is [-10.708333333333334, 18], 
sim time next is 2626800.0000, 
raw observation next is [-5.566666666666666, 68.33333333333333, 7.2, 226.6666666666667, 102.8333333333333, 121.6666666666667, -10.70833333333333, 15.96880520408269, 18.0, 22.65390754655226, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.391304347826087, 0.19059829059829062, 0.6833333333333332, 0.6545454545454545, 0.6296296296296298, 0.27204585537918863, 0.1216666666666667, 0.32152777777777786, 0.1596880520408269, 0.0, 0.6648439352217517, 0.6714285714285714, 1.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:17:49,521] A3C_AGENT_WORKER-Thread-16 INFO:Local step 35000, global step 557276: loss -27.1257
[2017-11-02 11:17:55,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [  1.00000000e+00   7.29920180e-10   8.79807172e-10   1.04696729e-09
   8.89149310e-11   2.04692129e-27   5.86468702e-27   3.56230332e-25
   8.11249468e-25], sum to 1.0000
[2017-11-02 11:17:55,750] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [0.5, 50.0, 8.174999999999999, 225.0, 95.0, 144.5, -4.5, 14.25515216896056, 18.0, 22.84897683057725, 22.7, 1.0, 0.0], 
actual action is [-4.5, 18], 
sim time next is 2650800.0000, 
raw observation next is [0.5, 50.0, 8.0, 226.6666666666667, 88.33333333333333, 137.6666666666667, -4.5, 14.64377743582213, 18.0, 22.69859262709048, 22.7, 1.0, 0.0], 
processed observation next is [0.16666666666666666, 0.6956521739130435, 0.34615384615384615, 0.5, 0.7272727272727273, 0.6296296296296298, 0.23368606701940034, 0.13766666666666671, 0.425, 0.1464377743582213, 0.0, 0.671227518155783, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:17:56,510] A3C_AGENT_WORKER-Thread-8 INFO:Local step 35000, global step 558245: loss 75.2227
[2017-11-02 11:17:59,975] A3C_AGENT_WORKER-Thread-7 INFO:Local step 35000, global step 558772: loss 34.2218
[2017-11-02 11:18:01,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 35000, global step 559006: loss -35.2985
[2017-11-02 11:18:02,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [  9.99999881e-01   8.55733351e-09   8.31404492e-08   3.38965940e-08
   6.62511823e-09   1.56950257e-32   4.84724500e-31   1.70725339e-29
   6.51545374e-28], sum to 1.0000
[2017-11-02 11:18:02,671] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.366666666666666, 69.0, 6.766666666666667, 266.6666666666667, 0.0, 0.0, -9.208333333333334, 20.37147647866438, 18.0, 20.91221337158052, 21.5, 0.0, 0.0], 
actual action is [-9.366666666666667, 18], 
sim time next is 2673900.0000, 
raw observation next is [-4.525, 69.0, 6.7, 267.5, 0.0, 0.0, -9.366666666666667, 22.52274267744745, 18.0, 20.95393842025853, 21.5, 0.0, 0.0], 
processed observation next is [0.16666666666666666, 0.9565217391304348, 0.21730769230769229, 0.69, 0.6090909090909091, 0.7430555555555556, 0.0, 0.0, 0.34388888888888886, 0.2252274267744745, 0.0, 0.4219912028940759, 0.5, 0.0, 0.0], 
reward next is -0.0780. 
=============================================
[2017-11-02 11:18:04,911] A3C_AGENT_WORKER-Thread-8 DEBUG:Policy network output: [  9.99380708e-01   2.81565299e-05   2.96403625e-04   2.60269386e-04
   3.07507398e-05   4.67987142e-11   1.72477232e-09   6.19709226e-07
   3.11846156e-06], sum to 1.0000
[2017-11-02 11:18:04,967] A3C_AGENT_WORKER-Thread-8 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.5, 61.5, 1.5, 60.0, 0.0, 0.0, -0.4166666666666661, 18.5997894549416, 25.0, 20.90782002486354, 21.5, 0.0, 49.72067686789039], 
actual action is [-0.5, 20.0], 
sim time next is 2752500.0000, 
raw observation next is [-5.583333333333333, 61.91666666666667, 1.5, 60.0, 0.0, 0.0, -0.5, 17.65308096198769, 20.0, 21.05203572567817, 21.5, 0.0, 47.23772451093294], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.1901709401709402, 0.6191666666666668, 0.13636363636363635, 0.16666666666666666, 0.0, 0.0, 0.49166666666666664, 0.1765308096198769, 0.2857142857142857, 0.43600510366831, 0.5, 0.0, 0.5557379354227405], 
reward next is -0.5642. 
=============================================
[2017-11-02 11:18:05,080] A3C_AGENT_WORKER-Thread-17 INFO:Local step 35000, global step 559617: loss -86.6719
[2017-11-02 11:18:08,505] A3C_AGENT_WORKER-Thread-6 DEBUG:Policy network output: [  8.09515419e-14   2.99659908e-10   3.90125843e-09   1.76316362e-09
   3.26550842e-10   6.05190326e-05   1.54460105e-03   1.80845678e-01
   8.17549169e-01], sum to 1.0000
[2017-11-02 11:18:08,599] A3C_AGENT_WORKER-Thread-6 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.5, 61.5, 2.85, 60.0, 0.0, 0.0, -1.416666666666666, 20.94554600333245, 20.0, 20.63733086026711, 21.5, 0.0, 41.87367806770916], 
actual action is [-1.5, 22.0], 
sim time next is 2781300.0000, 
raw observation next is [-6.583333333333334, 61.91666666666667, 2.891666666666667, 60.0, 0.0, 0.0, -1.5, 20.93493168910573, 22.0, 20.652282517368, 21.5, 0.0, 39.40940454522079], 
processed observation next is [0.5, 0.17391304347826086, 0.16452991452991453, 0.6191666666666668, 0.26287878787878793, 0.16666666666666666, 0.0, 0.0, 0.475, 0.20934931689105732, 0.5714285714285714, 0.3788975024811429, 0.5, 0.0, 0.46364005347318576], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:15,263] A3C_AGENT_WORKER-Thread-4 INFO:Local step 35000, global step 560918: loss -48.0029
[2017-11-02 11:18:15,381] A3C_AGENT_WORKER-Thread-5 INFO:Local step 35000, global step 560930: loss 34.2036
[2017-11-02 11:18:19,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 35000, global step 561538: loss 10.6904
[2017-11-02 11:18:20,005] A3C_AGENT_WORKER-Thread-12 INFO:Local step 35000, global step 561575: loss -87.6859
[2017-11-02 11:18:20,782] A3C_AGENT_WORKER-Thread-14 INFO:Local step 35000, global step 561673: loss -4.0787
[2017-11-02 11:18:23,302] A3C_AGENT_WORKER-Thread-13 INFO:Local step 35000, global step 561999: loss -71.6008
[2017-11-02 11:18:26,600] A3C_AGENT_WORKER-Thread-2 INFO:Local step 35000, global step 562543: loss -30.6885
[2017-11-02 11:18:27,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[-52.93047333]
 [-53.09712219]
 [-52.94266891]
 [-52.2115593 ]
 [-53.17524338]], R is [[-53.81832504]
 [-54.28014374]
 [-54.73734283]
 [-55.18996811]
 [-55.63806915]].
[2017-11-02 11:18:27,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [  1.00000000e+00   3.20645836e-11   2.20597762e-10   1.96827415e-10
   1.59022101e-11   1.62489650e-28   8.86465651e-29   1.32716480e-26
   5.54258564e-27], sum to 1.0000
[2017-11-02 11:18:27,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-5.0, 59.0, 1.5, 40.0, 0.0, 0.0, 0.0, 20.00992439188169, 25.0, 20.69245220825187, 22.7, 1.0, 83.52229632122788], 
actual action is [0.0, 20.0], 
sim time next is 2748300.0000, 
raw observation next is [-5.0, 59.0, 1.5, 42.5, 0.0, 0.0, 0.0, 19.45859834967811, 20.0, 20.81583366747455, 22.7, 1.0, 63.26371506241276], 
processed observation next is [0.3333333333333333, 0.8260869565217391, 0.20512820512820512, 0.59, 0.13636363636363635, 0.11805555555555555, 0.0, 0.0, 0.5, 0.19458598349678108, 0.2857142857142857, 0.40226195249636426, 0.6714285714285714, 1.0, 0.7442790007342678], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:28,029] A3C_AGENT_WORKER-Thread-15 INFO:Local step 35000, global step 562760: loss 22.6006
[2017-11-02 11:18:29,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [  1.00000000e+00   4.03444805e-10   3.00005931e-09   7.97366229e-10
   2.90466262e-10   2.39251705e-28   1.91366141e-28   5.70334417e-26
   2.05693355e-26], sum to 1.0000
[2017-11-02 11:18:29,564] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [1.0, 88.33333333333334, 4.600000000000001, 130.0, 0.0, 0.0, -4.0, 23.98262664249792, 18.0, 20.6235117376203, 21.5, 0.0, 0.0], 
actual action is [-4.0, 18], 
sim time next is 2863500.0000, 
raw observation next is [1.0, 88.91666666666666, 4.475, 130.0, 0.0, 0.0, -4.0, 26.10713771749109, 18.0, 20.56878146068549, 21.5, 0.0, 0.0], 
processed observation next is [0.6666666666666666, 0.13043478260869565, 0.358974358974359, 0.8891666666666665, 0.4068181818181818, 0.3611111111111111, 0.0, 0.0, 0.43333333333333335, 0.2610713771749109, 0.0, 0.36696878009792705, 0.5, 0.0, 0.0], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:29,725] A3C_AGENT_WORKER-Thread-11 INFO:Local step 35000, global step 563023: loss -90.2604
[2017-11-02 11:18:30,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  1.00000000e+00   8.22632587e-12   9.61872335e-12   5.51245421e-12
   1.79740391e-12   2.05909615e-30   1.19477227e-30   1.47012360e-28
   1.05685993e-29], sum to 1.0000
[2017-11-02 11:18:30,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 0, 
current raw observation is [-4.666666666666667, 55.66666666666667, 1.5, 36.66666666666667, 104.3333333333333, 751.3333333333334, -9.733333333333334, 14.26000030718883, 18.0, 22.38925063646795, 22.7, 1.0, 0.0], 
actual action is [-9.666666666666668, 18], 
sim time next is 2729700.0000, 
raw observation next is [-4.6, 55.5, 1.5, 35.0, 103.75, 746.75, -9.666666666666668, 14.6042559069148, 18.0, 22.46589271664525, 22.7, 1.0, 0.0], 
processed observation next is [0.3333333333333333, 0.6086956521739131, 0.2153846153846154, 0.555, 0.13636363636363635, 0.09722222222222222, 0.2744708994708995, 0.74675, 0.33888888888888885, 0.14604255906914798, 0.0, 0.6379846738064643, 0.6714285714285714, 1.0, 0.0], 
reward next is -0.0146. 
=============================================
[2017-11-02 11:18:32,760] A3C_AGENT_WORKER-Thread-10 INFO:Local step 35500, global step 563528: loss -153.4928
[2017-11-02 11:18:34,250] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[-81.55034637]
 [-77.36566925]
 [-78.87939453]
 [-77.33055115]
 [-77.95808411]], R is [[-77.36257172]
 [-77.58894348]
 [-77.81305695]
 [-78.03492737]
 [-78.25457764]].
[2017-11-02 11:18:39,452] A3C_AGENT_WORKER-Thread-5 DEBUG:Policy network output: [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00
   0.00000000e+00   8.68446901e-02   9.57872771e-07   9.13154006e-01
   3.66463723e-07], sum to 1.0000
[2017-11-02 11:18:39,673] A3C_AGENT_WORKER-Thread-5 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-6.583333333333333, 64.0, 1.85, 50.0, 0.0, 0.0, -1.666666666666667, 20.46264697256441, 25.0, 20.66267439253393, 22.7, 1.0, 79.50826485823913], 
actual action is [-1.583333333333333, 25], 
sim time next is 2791800.0000, 
raw observation next is [-6.5, 64.0, 1.8, 50.0, 0.0, 0.0, -1.583333333333333, 20.345814123751, 25.0, 20.72930771430421, 22.7, 1.0, 79.45683945897814], 
processed observation next is [0.5, 0.30434782608695654, 0.16666666666666666, 0.64, 0.16363636363636364, 0.1388888888888889, 0.0, 0.0, 0.47361111111111115, 0.20345814123751002, 1.0, 0.38990110204345846, 0.6714285714285714, 1.0, 0.9347863465762134], 
reward next is -1.0000. 
=============================================
[2017-11-02 11:18:39,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [  4.60478463e-24   1.40753169e-19   4.02955710e-19   5.34188121e-19
   1.87397522e-19   3.70644666e-02   5.70019416e-04   9.59880829e-01
   2.48468062e-03], sum to 1.0000
[2017-11-02 11:18:40,027] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>Environment debug: raw action idx is 7, 
current raw observation is [-5.5, 61.5, 1.5, 60.0, 0.0, 0.0, -0.4166666666666661, 11.15511845472745, 25.0, 22.90456439556811, 21.5, 0.0, 43.42389741371376], 
actual action is [-0.5, 25], 
sim time next is 2752500.0000, 
raw observation next is [-5.583333333333333, 61.91666666666667, 1.5, 60.0, 0.0, 0.0, -0.5, 11.05902267139329, 25.0, 22.9260941679229, 21.5, 0.0, 43.29402899396401], 
processed observation next is [0.3333333333333333, 0.8695652173913043, 0.1901709401709402, 0.6191666666666668, 0.13636363636363635, 0.16666666666666666, 0.0, 0.0, 0.49166666666666664, 0.1105902267139329, 1.0, 0.7037277382747001, 0.5, 0.0, 0.5093415175760472], 
reward next is -0.4584. 
=============================================
[2017-11-02 11:18:40,818] A3C_AGENT_WORKER-Thread-16 INFO:Local step 35500, global step 564564: loss 3.1624
[2017-11-02 11:18:42,237] A3C_AGENT_WORKER-Thread-6 INFO:Local step 35500, global step 564748: loss 0.2845
[2017-11-02 11:18:48,110] A3C_AGENT_WORKER-Thread-8 INFO:Local step 35500, global step 565466: loss -2.2984
[2017-11-02 11:18:50,866] A3C_AGENT_WORKER-Thread-7 INFO:Local step 35500, global step 565917: loss 1.2345
